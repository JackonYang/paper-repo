{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "To extend the approach in [5] to track articulated human motion we approximate the limbs as planar regions and recover the motions of these planes while constraining the motion of the connected patches to be the same at the points of articulation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "The method extends previous work on facial motion tracking [5] to more general animate motion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 105
                            }
                        ],
                        "text": "Cardboard People: A Parameterized Model of Articulated Image Motion\nShanon X. Ju Michael J. Blacky Yaser Yacoobz Department of Computer Science, University of Toronto, Toronto, Ontario M5S 1A4 Canaday Xerox Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA 94304z Computer Vision Laboratory, University of Maryland, College Park, MD 20742. juxuan@vis.toronto.edu, black@parc.xerox.com, yaser@umiacs.umd.edu"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "In the case of faces, Black and Yacoob [5] showed that a planar model could well approximate the motion of a human head and that it provides a concise description of the optical flow within a region."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "In this paper we extend the work of Black and Yacoob [5] on tracking and recognition of human facial expressions to the problem of tracking and recognizing the articulated motion of human limbs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "An advantage of the 2D parameterized flow models is that recovered flow parameters can be interprated and used for recognition as described in [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3175562,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4ef915fa9e5b2260d4b45927c0033a7ba53bf66e",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces. Parametric flow models (for example affine) are popular for estimating motion in rigid scenes. We observe that within local regions in space and time, such models not only accurately model non-rigid facial motions but also provide a concise description of the motion in terms of a small number of parameters. These parameters are intuitively related to the motion of facial features during facial expressions and we show how expressions such as anger, happiness, surprise, fear, disgust and sadness can be recognized from the local parametric motions in the presence of significant head motion. The motion tracking and expression recognition approach performs with high accuracy in extensive laboratory experiments involving 40 subjects as well as in television and movie sequences.<<ETX>>"
            },
            "slug": "Tracking-and-recognizing-rigid-and-non-rigid-facial-Black-Yacoob",
            "title": {
                "fragments": [],
                "text": "Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces and shows how expressions can be recognized from the local parametric motions in the presence of significant head motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 113
                            }
                        ],
                        "text": "These methods typically attempt to match the projection of a detailed articulated 3D body model to the edge data [9, 10, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5697345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc9b263c1af95ea803c4f5c8888ef8e37f0cef80",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a vision system for the 3-D model-based tracking of unconstrained human movement. Using image sequences acquired simultaneously from multiple views, we recover the 3-D body pose at each time instant without the use of markers. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. The models used for this purpose are acquired from the images. We use a decomposition approach and a best-first technique to search through the high dimensional pose parameter space. A robust variant of chamfer matching is used as a fast similarity measure between synthesized and real edge images. We present initial tracking results from a large new Humans-in-Action (HIA) database containing more than 2500 frames in each of four orthogonal views. They contain subjects involved in a variety of activities, of various degrees of complexity, ranging from the more simple one-person hand waving to the challenging two-person close interaction in the Argentine Tango."
            },
            "slug": "3-D-model-based-tracking-of-humans-in-action:-a-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "3-D model-based tracking of humans in action: a multi-view approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A vision system for the 3-D model-based tracking of unconstrained human movement and initial tracking results from a large new Humans-in-Action database containing more than 2500 frames in each of four orthogonal views are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 113
                            }
                        ],
                        "text": "These methods typically attempt to match the projection of a detailed articulated 3D body model to the edge data [9, 10, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122238372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ab4fc76e2f085dde81626794b79b5e9d1d00e0",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The interpretation of the movements of articulated bodies in image sequences is one of the most challenging problems in computer vision. In this contribution, we introduce a model-based approach for the recognition of pedestrians. We represent the human body by a 3D-model consisting of cylinders, whereas for modelling the movement of walking we use data from medical motion studies. The estimation of model parameters in consecutive images is done by applying a Kalman filter. Experimental results are shown for synthetic as well as for real image data."
            },
            "slug": "Towards-model-based-recognition-of-human-movements-Rohr",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians is introduced and the human body is represented by a 3D-model consisting of cylinders, whereas for modelling the movement of walking the authors use data from medical motion studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706204"
                        ],
                        "name": "I. Kakadiaris",
                        "slug": "I.-Kakadiaris",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Kakadiaris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kakadiaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784213"
                        ],
                        "name": "R. Bajcsy",
                        "slug": "R.-Bajcsy",
                        "structuredName": {
                            "firstName": "Ruzena",
                            "lastName": "Bajcsy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bajcsy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 84
                            }
                        ],
                        "text": "A number of authors have extended active contour models to model articulated motion [6, 12, 13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1098914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d0a4a2b5333c3cbffdb3cb82062772c5aea9a29",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel, robust, integrated approach to segmentation shape and motion estimation of articulated objects. Initially, we assume the object consists of a single part, and we fit a deformable model to the given data using our physics-based framework. As the object attains new postures, we decide based on certain criteria if and when to replace the initial model with two new models. These criteria are based on the model's state and the given data. We then fit the models to the data using a novel algorithm for assigning forces from the data to the two models, which allows partial overlap between them and determination of joint location. This approach is applied iteratively until all the object's moving parts are identified. Furthermore, we define new global deformations and we demonstrate our technique in a series of experiments, where Kalman filtering is employed to account for noise and occlusion.<<ETX>>"
            },
            "slug": "Active-part-decomposition,-shape-and-motion-of-a-Kakadiaris-Metaxas",
            "title": {
                "fragments": [],
                "text": "Active part-decomposition, shape and motion estimation of articulated objects: a physics-based approach"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel, robust, integrated approach to segmentation shape and motion estimation of articulated objects using a novel algorithm for assigning forces from the data to the two models, which allows partial overlap between them and determination of joint location."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46614172"
                        ],
                        "name": "Enrico Ursella",
                        "slug": "Enrico-Ursella",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Ursella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Ursella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 113
                            }
                        ],
                        "text": "These methods typically attempt to match the projection of a detailed articulated 3D body model to the edge data [9, 10, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19164875,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d91d26d47289d5633693cb6e91cb23b26195486",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the position and motion of a human arm in 3D without any constraints on its behavior and without the use of special markers. We model the arm as two truncated right-circular cones connected with spherical joints. We propose to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image. The system is demonstrated and tested on a real image sequence.<<ETX>>"
            },
            "slug": "Monocular-tracking-of-the-human-arm-in-3D-Bernardo-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular tracking of the human arm in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7771830,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69b22ec0935d6996470a369cbd54e53548e6e2f5",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new method for estimating optical flow that strikes a balance between the flexibility of local dense computations and the robustness and accuracy of global parameterized flow models. An affine model of image motion is used within local image patches while a spatial smoothness constraint on the affine flow parameters of neighboring patches enforces continuity of the motion. We refer to this as a \"Skin and Bones\" model in which the affine patches can be thought of as rigid \"bones\" connected by a flexible \"skin\". Since local image patches may contain multiple motions we use a layered representation for the affine bones. To regularize this layered motion representation we develop a new framework for regularization with transparency."
            },
            "slug": "Skin-and-bones:-multi-layer,-locally-affine,-flow-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Skin and bones: multi-layer, locally affine, optical flow and regularization with transparency"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new method for estimating optical flow that strikes a balance between the flexibility of local dense computations and the robustness and accuracy of global parameterized flow models is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3054345"
                        ],
                        "name": "C. Kervrann",
                        "slug": "C.-Kervrann",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Kervrann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kervrann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34617817"
                        ],
                        "name": "F. Heitz",
                        "slug": "F.-Heitz",
                        "structuredName": {
                            "firstName": "Fabrice",
                            "lastName": "Heitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Heitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 84
                            }
                        ],
                        "text": "A number of authors have extended active contour models to model articulated motion [6, 12, 13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15150256,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d61401ba48a4aef1a9ec6cf61f66e8fc115521b8",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new statistical framework for modeling and extracting 2D moving deformable objects from image sequences. The object representation relies on a hierarchical description of the deformations applied to a template. Global deformations are modeled using a Karhunen Loeve expansion of the distortions observed on a representative population. Local deformations are modeled by a (first-order) MarKov process. The optimal bayesian estimate of the global and local deformations is obtained by maximizing a non-linear joint probability distribution using stochastic and deterministic optimization techniques. The use of global optimization techniques yields robust and reliable segmentations in adverse situations such as low signal-to-noise ratio, non-gaussian noise or occlusions. Moreover, no human interaction is required to initialize the model. The approach is demonstrated on synthetic as well as on real-world image sequences showing moving hands with partial occlusions.<<ETX>>"
            },
            "slug": "A-hierarchical-statistical-framework-for-the-of-in-Kervrann-Heitz",
            "title": {
                "fragments": [],
                "text": "A hierarchical statistical framework for the segmentation of deformable objects in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new statistical framework for modeling and extracting 2D moving deformable objects from image sequences that yields robust and reliable segmentations in adverse situations such as low signal-to-noise ratio, non-gaussian noise or occlusions is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058487"
                        ],
                        "name": "D. Reynard",
                        "slug": "D.-Reynard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Reynard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reynard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 84
                            }
                        ],
                        "text": "A number of authors have extended active contour models to model articulated motion [6, 12, 13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56546270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2956ec610ffebb1638b07a53a9b0c954c3c07fdc",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in video-tracking allow the outlines of moving, natural objects in a video-camera input stream to be tracked live, at full video-rate. The system used here is based on Kalman filtering with a B-spline representation of curves to track the silhouettes of moving non-polyhedral objects. For example hands, lips, legs, vehicles, fruit can be tracked at video-rate without any special hardware beyond a desktop workstation and a video-camera and framestore. The novel contribution of this paper is a tracking algorithm that uses a bootstrapping technique to learn a stochastic, dynamic model for given motions from example video-streams. Incorporating such a model into the tracking algorithm greatly enhances maximum tracking speed and robustness to distraction from background objects. Experiments with learning both rigid and non-rigid motions, using moving hands and lips, clearly show the increased tracking power resulting from the learned dynamics.<<ETX>>"
            },
            "slug": "Learning-to-track-curves-in-motion-Blake-Isard",
            "title": {
                "fragments": [],
                "text": "Learning to track curves in motion"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The novel contribution of this paper is a tracking algorithm that uses a bootstrapping technique to learn a stochastic, dynamic model for given motions from example video-streams that greatly enhances maximum tracking speed and robustness to distraction from background objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 33rd IEEE Conference on Decision and Control"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679223"
                        ],
                        "name": "S. Seitz",
                        "slug": "S.-Seitz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Seitz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724754"
                        ],
                        "name": "C. Dyer",
                        "slug": "C.-Dyer",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Dyer",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Seitz and Dyer [18] proposed an approach for determin-\ning whether an observed motion is periodic and computing its period."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "The goal of recognition of human movement encompasses answering: When does the activity begin and end? What class does the observed activity most closely resemble? What is the period (if cyclical) of the activity? Seitz and Dyer [18] proposed an approach for determinFigure 4: Walking parallel to the imaging plane."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43510695,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6ef8d03cb6628f4da97a24d005a0ded8ef5d7e0b",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Current approaches for detecting periodic motion assume a stationary camera and place limits on an object's motion. These approaches rely on the assumption that a periodic motion projects to a set of periodic image curves, an assumption that fails in general. Using affine-invariance, we derive necessary and sufficient conditions for an image sequence to be the projection of a periodic motion. No restrictions are placed on either the motion of the camera or the object. Our algorithm is shown to be provably-correct for noise-free data and is easily extended to be robust with respect to occlusions and noise. The extended algorithm is evaluated with real and synthetic image sequences.<<ETX>>"
            },
            "slug": "Affine-invariant-detection-of-periodic-motion-Seitz-Dyer",
            "title": {
                "fragments": [],
                "text": "Affine invariant detection of periodic motion"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work derives necessary and sufficient conditions for an image sequence to be the projection of a periodic motion using affine-invariance and shows the algorithm to be provably-correct for noise-free data and easily extended to be robust with respect to occlusions and noise."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "which is the robust error norm used in [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 91
                            }
                        ],
                        "text": "We minimize Equation 6 using the simple gradient descent scheme with a continuation method [4, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 99
                            }
                        ],
                        "text": "Equation 6 is minimized using continuation method that begins with a large and lowers it gradually [4, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14070356,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eee90c038f43370a29b07e46f38dfe6527143a2c",
            "isKey": false,
            "numCitedBy": 1786,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper focuses on the recovery of multiple parametric motion models within a region, as well as the recovery of piecewise-smooth flow fields, and provides examples with natural and synthetic image sequences."
            },
            "slug": "The-Robust-Estimation-of-Multiple-Motions:-and-Flow-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A framework based on robust estimation is presented that addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions of optical flow, and is applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "For example, Baumberg and Hogg [2] track the outline of a moving body using a modal-based flexible shape model which captures the considerable outline variations in the human silhouette during movement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62491650,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "67eac618325d5f5f31ce17922d51fad995a57749",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been considerable research interest recently, in the areas of real time contour tracking and active shape models. This paper demonstrates how dynamic filtering can be used in combination with a modal-based flexible shape model to track an articulated non-rigid body in motion. The results show the method being used to track the silhouette of a walking pedestrian in real time. The active shape model used was generated automatically from real image data and incorporates variability in shape due to orientation as well as object flexibility. A Kalman filter is used to control spatial scale for feature search over successive frames. Iterative refinement allows accurate contour localisation where feasible. The shape model incorporates knowledge of the likely shape of the contour and speeds up tracking by reducing the number of system parameters. A further increase in speed is obtained by filtering the shape parameters independently.<<ETX>>"
            },
            "slug": "An-efficient-method-for-contour-tracking-using-Baumberg-Hogg",
            "title": {
                "fragments": [],
                "text": "An efficient method for contour tracking using active shape models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper demonstrates how dynamic filtering can be used in combination with a modal-based flexible shape model to track an articulated non-rigid body in motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104544307"
                        ],
                        "name": "A. G. Bharatkumar",
                        "slug": "A.-G.-Bharatkumar",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bharatkumar",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. G. Bharatkumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98601092"
                        ],
                        "name": "K. Daigle",
                        "slug": "K.-Daigle",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Daigle",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Daigle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2907655"
                        ],
                        "name": "M. Pandy",
                        "slug": "M.-Pandy",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Pandy",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pandy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100783416"
                        ],
                        "name": "Q. Cai",
                        "slug": "Q.-Cai",
                        "structuredName": {
                            "firstName": "Q.",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 66
                            }
                        ],
                        "text": "Stickfigure models of humans have also been matched to image data [1, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15629036,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3fa24cb0c974161184b6f6b3c88a47eead8c4384",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a simple model for free-speed human walking and compares ordinary images of a walking person to the model. Three dimensional kinematic data were obtained from subjects walking with markers over the joints of their limbs. The average of these data was used to derive a model stick figure of the lower limbs, based on the average anthropometric data of the population. Stick figures were obtained from ordinary images of persons dressed in tight fitting clothes without any markers by using the medial axis transformation. The two dimensional information from the image stick figures was compared with the projection of the three dimensional information of the model onto the relevant plane. A high degree of correlation was noted between the rotational patterns of the model and image stick figures.<<ETX>>"
            },
            "slug": "Lower-limb-kinematics-of-human-walking-with-the-Bharatkumar-Daigle",
            "title": {
                "fragments": [],
                "text": "Lower limb kinematics of human walking with the medial axis transformation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Pentland and Horowitz [15], however, describe the fitting of a 3D physically-based articulated model to optical flow data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28815139,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f706f1babe84c0728be3a06a4d3023cdc44f61c2",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors introduce a physically correct model of elastic nonrigid motion. This model is based on the finite element method, but decouples the degrees of freedom by breaking down object motion into rigid and nonrigid vibration or deformation modes. The result is an accurate representation for both rigid and nonrigid motion that has greatly reduced dimensionality, capturing the intuition that nonrigid motion is normally coherent and not chaotic. Because of the small number of parameters involved, this representation is used to obtain accurate overstrained estimates of both rigid and nonrigid global motion. It is also shown that these estimates can be integrated over time by use of an extended Kalman filter, resulting in stable and accurate estimates of both three-dimensional shape and three-dimensional velocity. The formulation is then extended to include constrained nonrigid motion. Examples of tracking single nonrigid objects and multiple constrained objects are presented. >"
            },
            "slug": "Recovery-of-Nonrigid-Motion-and-Structure-Pentland-Horowitz",
            "title": {
                "fragments": [],
                "text": "Recovery of Nonrigid Motion and Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This model is based on the finite element method, but decouples the degrees of freedom by breaking down object motion into rigid and nonrigid vibration or deformation modes, resulting in an accurate representation for both rigid andnonrigid motion that has greatly reduced dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Pentland and Horowitz [15], however, describe the fitting of a 3D physically-based articulated model to optical flow data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5863271,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f244c6d0f9abe7564a48653eb6726c814bb5fd27",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The elastic properties of real materials provide constraint on the types of non-rigid motion that can occur, and thus allow overconstrained estimates of 3-D non-rigid motion from optical flow data. It is shown that by modeling and simulating the physics of non-rigid motion it is possible to obtain good estimates of both object shape and velocity. Examples using grey-scale and X-ray imagery are presented, including an example of tracking a complex articulated figure.<<ETX>>"
            },
            "slug": "Recovery-of-non-rigid-motion-and-structure-Horowitz-Pentland",
            "title": {
                "fragments": [],
                "text": "Recovery of non-rigid motion and structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that by modeling and simulating the physics of non-rigid motion it is possible to obtain good estimates of both object shape and velocity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874997"
                        ],
                        "name": "S. Niyogi",
                        "slug": "S.-Niyogi",
                        "structuredName": {
                            "firstName": "Sourabh",
                            "lastName": "Niyogi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 66
                            }
                        ],
                        "text": "Stickfigure models of humans have also been matched to image data [1, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18566850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57854a0e8309af7ad6f5d9612e20e2ba1a171a96",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel algorithm for gait analysis. A person walking frontoparallel to the image plane generates a characteristic \"braided\" pattern in a spatiotemporal (XYT) volume. Our algorithm detects this pattern, and fits it with a set of spatiotemporal snakes. The snakes can be used to find the bounding contours of the walker. The contours vary over time in a manner characteristic of each walker. Individual gaits can be recognized by applying standard pattern recognition techniques to the contour signals.<<ETX>>"
            },
            "slug": "Analyzing-and-recognizing-walking-figures-in-XYT-Niyogi-Adelson",
            "title": {
                "fragments": [],
                "text": "Analyzing and recognizing walking figures in XYT"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A novel algorithm for gait analysis that fits a characteristic \"braided\" pattern in a spatiotemporal volume, and fits it with a set of spatiotsemporal snakes that can be used to find the bounding contours of the walker."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Since 1:4826 is the median value of the absolute values of a one-dimensional normal distribution [17], the robust estimation of from residuals can be defined as: est = 1:4826medianxjrI u(x; as) + Itj (8)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123831778,
            "fieldsOfStudy": [],
            "id": "ae3f31c841c460b15a81bf51655f4c0e39cacc79",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Regression and Outlier Detection"
            },
            "venue": {
                "fragments": [],
                "text": "Wiley Series in Probability and Statistics"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Agganval, \u201cLower limb kinematics of human walking with the medial axis tranfromation,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Workshop on Motion of Non-rigid and Articulated Objects,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] use a 3D articulated model of a human leg to constrain the optical flow and they recover the motion of the articulated parts directly from changing image brightness without first com-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis of human motion: A model-based approach"
            },
            "venue": {
                "fragments": [],
                "text": "In 7th Scandinavian Conf. Image Analysis, Aalborg,"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Cardboard-people:-a-parameterized-model-of-image-Ju-Black/8e3b20fb94803d71910043059f402554aa5137b2?sort=total-citations"
}