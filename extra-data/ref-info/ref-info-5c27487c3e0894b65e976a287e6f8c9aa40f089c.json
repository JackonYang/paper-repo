{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7299252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dd0b40a28f49ac51fdcb7dd07fd054e5564dec1",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The system presented here is a specialized version of a general object recognition system. Images of faces are represented as graphs, labeled with topographical information and local templates. Different poses are represented by different graphs. New graphs of faces are generated by an elastic graph matching procedure comparing the new face with a set of precomputed graphs: the \"general face knowledge\". The final phase of the matching process can be used to generate composite images of faces and to determine certain features represented in the general face knowledge, such as gender or the presence of glasses or a beard. The graphs can be compared by a similarity function which makes the system efficient in recognizing faces."
            },
            "slug": "Face-Recognition-and-Gender-determination-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face Recognition and Gender determination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The system presented here is a specialized version of a general object recognition system that can be used to generate composite images of faces and to determine certain features represented in the general face knowledge, such as gender or the presence of glasses or a beard."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [10] the bunch graph technique has been used to fairly reliably determine facial attributes from single images, such as sex or the presence of glasses or a beard."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5127417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c36a366d67b02937f78da39672e2ed485d3a17c8",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The system presented is a specialized version of a general object recognition system. Images of faces are represented as graphs, labeled with topographical information and local features. New graphs of faces are generated by an elastic graph matching procedure comparing the new face with a set of stored model graphs: the face bunch graph. The result of this matching process can be used to generate composite images of faces and to determine facial attributes represented in the face bunch graph, such as sex or the presence of glasses or a beard."
            },
            "slug": "Phantom-faces-for-face-analysis-Wiskott",
            "title": {
                "fragments": [],
                "text": "Phantom faces for face analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The system presented is a specialized version of a general object recognition system, labeled with topographical information and local features, that can be used to generate composite images of faces and to determine facial attributes represented in the face bunch graph."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "The manual selection of fiducial points could be replaced by grouping salient points on the basis of common motion [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46325945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a735c80fd1a467d82efb3960faf88a522f690be2",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A feature-based approach to face recognition in which the features are derived from the intensity data without assuming any knowledge of the face structure is presented. The feature extraction model is biologically motivated, and the locations of the features often correspond to salient facial features such as the eyes, nose, etc. Topological graphs are used to represent relations between features, and a simple deterministic graph-matching scheme that exploits the basic structure is used to recognize familiar faces from a database. Each of the stages in the system can be fully implemented in parallel to achieve real-time recognition. Experimental results for a 128*128 image with very little noise are evaluated.<<ETX>>"
            },
            "slug": "A-feature-based-approach-to-face-recognition-Manjunath-Chellappa",
            "title": {
                "fragments": [],
                "text": "A feature based approach to face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A feature-based approach to face recognition in which the features are derived from the intensity data without assuming any knowledge of the face structure is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 781,
                                "start": 25
                            }
                        ],
                        "text": "positions need to be searched only once instead of in each attempted match to a gallery image, as was previously necessary. The ability of the new system to refer to object- xed ducial points irrespective of pose represents an advantage in itself and is essential for some interesting graph operations; cf. Section 4.2. Computational e ciency, the ability to deal with di erent poses explicitly, and greater potential for further developments are the major advantages of the new system compared to the preceding one. We did not expect and experiments do not show an immediate improvement of recognition performance on faces of similar orientation. 4.1.2 Recognizing Faces of the Same View Some face recognition systems are based on user-de ned face-speci c features. Yuille (1991), for example, represented eyes by a circle within an almond-shape and de ned an energy function to optimize a total of 9 model parameters for matching it to an image."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17312452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce5f297cb037b2101da175344e2597a52c0e5908",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate a system capable of tracking in real world image sequences, landmarks such as eyes, mouth, or chin on a face. In the standard version, knowledge previously collected about faces is used for finding the landmarks in the first frame. In a second version, the system is able to track the face without any prior knowledge about faces and is thus applicable to other object classes. By using Gabor filters as visual features, and by both avoiding limiting assumptions and many parameters our tracking tool is simple and easy to use. As a first application the tracking results are used to estimate the pose of a face."
            },
            "slug": "Tracking-and-learning-graphs-and-pose-on-image-of-Maurer-Malsburg",
            "title": {
                "fragments": [],
                "text": "Tracking and learning graphs and pose on image sequences of faces"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A system capable of tracking in real world image sequences, landmarks such as eyes, mouth, or chin on a face, and is applicable to other object classes by using Gabor filters as visual features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144928357"
                        ],
                        "name": "Y. Vardi",
                        "slug": "Y.-Vardi",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Vardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Vardi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59638118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e615167186c4ebbff64304ec36d208e56d2a091",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation presents solutions to four problems from face recognition and medical imaging. The first problem identifies an unknown face from a large database of facial images. The algorithm is based on matching pursuit filters, a small set of facial features, and simple geometric model. The set of features consists of the nose and eye regions of the face, and the interior of the face at a reduced scale. The algorithm uses coarse to fine processing to estimate the location of the facial features. Based on the hypothesized locations of the facial features the identification module searches the database for the identity of the unknown face. The identification is made by matching pursuit filters--a self-organizing technique for creating efficient and compact models from data. This technique is based on an adapted wavelet expansion, which is adapted to both the data and the goals of the algorithm. Thus, the filters can automatically find the subtle differences between facial features needed to identify unknown individuals. The algorithm is demonstrated on a database of photographs of 311 individuals and on a database of infrared facial images. The second problem adjusts for illumination differences between two facial images. The algorithm transforms the histogram of pixel values on one face to the histogram of another face. The algorithm, which is computationally efficient, nonlinear, and data-driven, corrects for variations between two different facial images or changes within an image of a face. The third problem uses a sieve algorithm to find the correspondence between pairs of images taken with an electron microscope. A sieve algorithm uses a sequence of approximations to generate increasingly accurate estimates of the correspondence. Initially, the approximations are computationally inexpensive, and at later stages both accuracy and complexity increase. The fourth problem presents an automatic registration algorithm for MR and PET slices of the brain that does not require manual intervention. The algorithm takes an integrated approach and simultaneous segments the brain in both modalities and registers the slices. A sequence of templates from the PET slice is constructed and registered in the MR slice using an energy function. The template with minimum energy gives the final registration."
            },
            "slug": "Representation-and-registration-in-face-recognition-Phillips-Vardi",
            "title": {
                "fragments": [],
                "text": "Representation and registration in face recognition and medical imaging"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This dissertation presents solutions to four problems from face recognition and medical imaging, which identifies an unknown face from a large database of facial images, a small set of facial features, and simple geometric model based on matching pursuit filters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "Monitoring a rotating object by continuously applying elastic bunch graph matching can then reveal which nodes refer to corresponding ducial points in di erent poses [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 71883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e9d6994013fcff41bc1d03ec19d02c00c733418",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate a system capable of tracking, in real world image sequences, landmarks such as eyes, mouth, or chin on a face. In a first version knowledge previously collected about faces is used for finding the landmarks in the first frame. In a second version the system is able to track the face without any prior knowledge about faces and is thus applicable to other object classes."
            },
            "slug": "Tracking-and-Learning-Graphs-on-Image-Sequences-of-Maurer-Malsburg",
            "title": {
                "fragments": [],
                "text": "Tracking and Learning Graphs on Image Sequences of Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A system capable of tracking, in real world image sequences, landmarks such as eyes, mouth, or chin on a face without any prior knowledge about faces is demonstrated, thus applicable to other object classes."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "The similarity function Sa(J ;J 0) = Pj aja0j rPj a2jPj a02 j (2) ignores phase [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "The system di ers from the preceding one [1] in three respects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "1 Introduction The system presented here is based on a face recognition system described in [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2069,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Beymer & Poggio (1995) have used a warping transformation derived from sequences of rotating sample faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1097,
                                "start": 0
                            }
                        ],
                        "text": "Beymer & Poggio (1995) have used a warping transformation derived from sequences of rotating sample faces. Another interesting approach is the concept of linear object classes (Vetter & Poggio, 1997). It is assumed that objects in one view can be linearly decomposed with respect to images of a set of prototype objects of the same view. When images of these prototypes are available in another view, the object can be linearly synthesized in that view with the same coe cients as used for the decomposition. Vetter (1998) tested this method on images rendered from 3D face data. Shape and texture were processed separately, the texture being processed as a whole or broken down into four local regions. Recognition was based on a simple similarity measure, e.g. Euclidean distance, applied directly to the image grey values. The recognition rates of 100% for this and the warping method described above are remarkable. Although, it has to be taken into account that the images were rendered from 3D face representations and that the galleries were correspondingly perfect. Beymer & Poggio (1995) also used this method, but they did the decomposition with respect to eigenfaces and did not use shape information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 523,
                                "start": 0
                            }
                        ],
                        "text": "Beymer & Poggio (1995) have used a warping transformation derived from sequences of rotating sample faces. Another interesting approach is the concept of linear object classes (Vetter & Poggio, 1997). It is assumed that objects in one view can be linearly decomposed with respect to images of a set of prototype objects of the same view. When images of these prototypes are available in another view, the object can be linearly synthesized in that view with the same coe cients as used for the decomposition. Vetter (1998) tested this method on images rendered from 3D face data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 80
                            }
                        ],
                        "text": "A similar data structure based on templates has been developed independently by Beymer (1994). Assume for a particular pose that there are M model graphs GBm (m = 1; :::;M ) of identical structure, taken from di erent model faces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 510,
                                "start": 487
                            }
                        ],
                        "text": "(1997) Gabor jets, no speci c transformation Bochum database 108 0 108 11 94 108 0 108 22 88 FERET database 250 0 250 45 18 250 45 250 0 17 250 45 250 90 9 250 90 250 45 12 Maurer & von der Malsburg (1995) Gabor jets, learned normal vectors for geometrical rotation transformation Bochum database, no transformation 110 0 110 22 88 transforming 22 to 0 110 0 110 22 96 FERET database, no transformation 90 0 90 45 36 transforming 45 to 0 90 0 90 45 50 transforming 0 to 45 90 0 90 45 53 Beymer & Poggio (1995) well-controlled gallery, little hair information warping between di erent views 62 ( )20 620 range 40 82 linear decomposition, no shape info."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1199,
                                "start": 49
                            }
                        ],
                        "text": "Even more extreme in this sense are the systems (Beymer & Poggio, 1995; Vetter & Poggio, 1997; Vetter, 1998). They use an image- ow algorithm to match each pixel of a face image to a pixel in a di erent image. The warping is correspondingly accurate. These latter systems, however, require carefully taken images of high quality and are less robust against perturbations, such as occlusions or glasses. A second problem of the original PCA approach is its sensitivity to occlusions or other localized perturbations, such as variations in hair style or facial hair. In a more localized feature representation, some regions can be explicitly treated as occluded, yielding good recognition results despite large occlusions (Wiskott & von der Malsburg, 1993). In the holistic representation of PCA, any local image perturbation will have an e ect on all expansion coe cients and cannot be easily disregarded. One way this problem has been dealt with was by treating small image regions centered on ducial points (eyes, nose, mouth) as additional pixel vectors from which to extract more features by PCA (Moghaddam & Pentland, 1997). A more systematic approach has been developed by Penev & Atick (1996). They explore spatial correlations within the set of eigenvectors found by PCA and generate a redundant set of localized kernels, one for each pixel location."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1184,
                                "start": 487
                            }
                        ],
                        "text": "(1997) Gabor jets, no speci c transformation Bochum database 108 0 108 11 94 108 0 108 22 88 FERET database 250 0 250 45 18 250 45 250 0 17 250 45 250 90 9 250 90 250 45 12 Maurer & von der Malsburg (1995) Gabor jets, learned normal vectors for geometrical rotation transformation Bochum database, no transformation 110 0 110 22 88 transforming 22 to 0 110 0 110 22 96 FERET database, no transformation 90 0 90 45 36 transforming 45 to 0 90 0 90 45 50 transforming 0 to 45 90 0 90 45 53 Beymer & Poggio (1995) well-controlled gallery, little hair information warping between di erent views 62 ( )20 620 range 40 82 linear decomposition, no shape info. 62 ( )20 620 range 40 70 Vetter (1998) images rendered from 3D face data, no hair information mapping onto 3D-model 100 0 100 24 100 linear decomposition and synthesis 100 0 100 24 100 linear decomposition on four subregions 100 0 100 24 100 Table 4: Methods and performances of the di erent systems discussed. Our results are repeated for comparison. When comparing the results, notice that the rst rank recognition rates depend on gallery size as well as on the quality of the databases. The system by Moghaddam & Pentland (1997) simply applies several recognition subsystems in parallel, each of which is specialized to one view and is based on the PCA approach described above for recognition of the same views."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 691,
                                "start": 487
                            }
                        ],
                        "text": "(1997) Gabor jets, no speci c transformation Bochum database 108 0 108 11 94 108 0 108 22 88 FERET database 250 0 250 45 18 250 45 250 0 17 250 45 250 90 9 250 90 250 45 12 Maurer & von der Malsburg (1995) Gabor jets, learned normal vectors for geometrical rotation transformation Bochum database, no transformation 110 0 110 22 88 transforming 22 to 0 110 0 110 22 96 FERET database, no transformation 90 0 90 45 36 transforming 45 to 0 90 0 90 45 50 transforming 0 to 45 90 0 90 45 53 Beymer & Poggio (1995) well-controlled gallery, little hair information warping between di erent views 62 ( )20 620 range 40 82 linear decomposition, no shape info. 62 ( )20 620 range 40 70 Vetter (1998) images rendered from 3D face data, no hair information mapping onto 3D-model 100 0 100 24 100 linear decomposition and synthesis 100 0 100 24 100 linear decomposition on four subregions 100 0 100 24 100 Table 4: Methods and performances of the di erent systems discussed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1489,
                                "start": 0
                            }
                        ],
                        "text": "Beymer & Poggio (1995) have used a warping transformation derived from sequences of rotating sample faces. Another interesting approach is the concept of linear object classes (Vetter & Poggio, 1997). It is assumed that objects in one view can be linearly decomposed with respect to images of a set of prototype objects of the same view. When images of these prototypes are available in another view, the object can be linearly synthesized in that view with the same coe cients as used for the decomposition. Vetter (1998) tested this method on images rendered from 3D face data. Shape and texture were processed separately, the texture being processed as a whole or broken down into four local regions. Recognition was based on a simple similarity measure, e.g. Euclidean distance, applied directly to the image grey values. The recognition rates of 100% for this and the warping method described above are remarkable. Although, it has to be taken into account that the images were rendered from 3D face representations and that the galleries were correspondingly perfect. Beymer & Poggio (1995) also used this method, but they did the decomposition with respect to eigenfaces and did not use shape information. Their model gallery included 20 rotated faces plus the mirror-re ected images, and they tested on probe faces randomly drawn from a range of approximately 40 rotation angle. They also considered rotation around horizontal axes. This system as well as the one by Vetter (1998) used an image- ow algorithm to nd correspondences between di erent faces."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2546027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e5949d95c53dd041c721bf40e67b3966805e385",
            "isKey": true,
            "numCitedBy": 488,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in computer vision and pattern recognition have worked on automatic techniques for recognizing human faces for the last 20 years. While some systems, especially template-based ones, have been quite successful on expressionless, frontal views of faces with controlled lighting, not much work has taken face recognizers beyond these narrow imaging conditions. Our goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth. Building on successful template-based systems, our basic approach is to represent faces with templates from multiple model views that cover different poses from the viewing sphere. To recognize a novel view, the recognizer locates the eyes and nose features, uses these locations to geometrically register the input with model views, and then uses correlation on model templates to find the best match in the data base of people. Our system has achieved a recognition rate of 98% on a data base of 62 people containing 10 testing and 15 modeling views per person.<<ETX>>"
            },
            "slug": "Face-recognition-under-varying-pose-Beymer",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16413347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37d46a2355a95abee6576986a460399adbebf6b9",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach for extracting facial features from images and for determining the spatial organization between these features using the concept of a deformable template. This is a parameterized geometric model of the object to be recognized together with a measure of how well it fits the image data. Variations in the parameters correspond to allowable deformations of the object and can be specified by a probabilistic model. After the extraction stage the parameters of the deformable template can be used for object description and recognition."
            },
            "slug": "Deformable-Templates-for-Face-Recognition-Yuille",
            "title": {
                "fragments": [],
                "text": "Deformable Templates for Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An approach for extracting facial features from images and for determining the spatial organization between these features using the concept of a deformable template using a parameterized geometric model of the object to be recognized together with a measure of how well it fits the image data."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40302807"
                        ],
                        "name": "G. Gordon",
                        "slug": "G.-Gordon",
                        "structuredName": {
                            "firstName": "Gaile",
                            "lastName": "Gordon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gordon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1610286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de997e1c284584eb799b672e19108d84528d546e",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a unique face recognition sys tem which considers information from both frontal and pro le view images This system represents the rst step toward the development of a face recogni tion solution for the intensity image domain based on a D context In the current system we construct a D face centered model from the two independent images Geometric information is used for view nor malization and at the lowest level the comparison is based on general pattern matching techniques We also discuss the use of geometric information to index the reference database to quickly eliminate impossi ble matches from further consideration The system has been tested using subjects from the FERET program database and has shown excellent results For example we consider the problem of identifying the of the database which is most similar to the target The correct match is included in this list of the time in the system s fully automated mode and of the time in the manually assisted mode The International Workshop on Automatic Face and Gesture Recognition Zurich June"
            },
            "slug": "Face-recognition-from-frontal-and-profile-views-Gordon",
            "title": {
                "fragments": [],
                "text": "Face recognition from frontal and profile views"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A unique face recognition system which considers information from both frontal and pro le view images is presented and the problem of identifying the of the database which is most similar to the target is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144013393"
                        ],
                        "name": "A. Samal",
                        "slug": "A.-Samal",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Samal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32130323"
                        ],
                        "name": "Prasana A. Iyengar",
                        "slug": "Prasana-A.-Iyengar",
                        "structuredName": {
                            "firstName": "Prasana",
                            "lastName": "Iyengar",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasana A. Iyengar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205013679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0be360a2964c4bb91aaad0cc6d1baa6639746028",
            "isKey": false,
            "numCitedBy": 1067,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-recognition-and-analysis-of-human-faces-a-Samal-Iyengar",
            "title": {
                "fragments": [],
                "text": "Automatic recognition and analysis of human faces and facial expressions: a survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 215
                            }
                        ],
                        "text": "Another study on face recognition was also based on face bunch graphs (including the correct face) and Gabor jets, but the matching algorithm was much simpler and constrained to a sparse grid of points in the image (Wiskott, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12885298,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "596195cbc66097f17f9211e848ab253ce72147ec",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-role-of-topographical-constraints-in-face-Wiskott",
            "title": {
                "fragments": [],
                "text": "The role of topographical constraints in face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6226080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dd5a3055a17d037d21cec9e57f481304f0100a9",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition systems based on model matching using low level features often fail due to a variation in background. As a solution, I present a system for the recognition of human faces independent of hairstyle. Correspondence maps between an image and a model are established by coarse-fine matching in a Gabor pyramid. These are used for hierarchical recognition."
            },
            "slug": "Object-Recognition-Robust-Under-Translations,-and-W\u00fcrtz",
            "title": {
                "fragments": [],
                "text": "Object Recognition Robust Under Translations, Deformations, and Changes in Background"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents a system for the recognition of human faces independent of hairstyle, established by coarse-fine matching in a Gabor pyramid for hierarchical recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47284853"
                        ],
                        "name": "M. P\u00f6tzsch",
                        "slug": "M.-P\u00f6tzsch",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "P\u00f6tzsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P\u00f6tzsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16559239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2382359da7a5cae09cd7f675829239306487c757",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Determination-of-face-position-and-pose-with-a-on-Kr\u00fcger-P\u00f6tzsch",
            "title": {
                "fragments": [],
                "text": "Determination of face position and pose with a learned representation based on labelled graphs"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 0
                            }
                        ],
                        "text": "C. Jain et al. eds., Intelligent Biometric Techniques in Fingerprint and Face Recognition. Springer-Verlag, ISBN 0-8493-2055-0, (1999). Face Recognition by Elastic Bunch Graph Matching y Laurenz Wiskott1z, Jean-Marc Fellous2x, Norbert Kr\u007f uger1{, and Christoph von der Malsburg1;2 1 Institute for Neural Computation Ruhr-University Bochum D-44780 Bochum, Germany 2 Computer Science Department University of Southern California Los Angeles, CA 90089, USA Abstract We present a system for recognizing human faces from single images out of a large database containing one image per person."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2841459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bcdca49ed64ec6b15d975adaea49508e9e941d2",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe experiments using eigenfaces for recognition and interactive search in the FERET face database. A recognition accuracy of 99.35% is obtained using frontal views of 155 individuals. This figure is consistent with the 95% recognition rate obtained previously on a much larger database of 7,562 `mugshots' of approximately 3,000 individuals, consisting of a mix of all age and ethnic groups. We also demonstrate that we can automatically determine head pose without significantly lowering recognition accuracy; this is accomplished by use of a view-based multiple-observer eigenspace technique. In addition, a modular eigenspace description is used which incorporates salient facial features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields slightly higher recognition rates as well as a more robust framework for face recognition. In addition, a robust and automatic feature detection technique using eigentemplates is demonstrated."
            },
            "slug": "Face-recognition-using-view-based-and-modular-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Face recognition using view-based and modular eigenspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A modular eigenspace description is used which incorporates salient facial features such as the eyes, nose and mouth, in an eigenfeature layer, which yields slightly higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 235
                            }
                        ],
                        "text": "1 we already argued that the simple spring model used here for the grid has too many degrees of freedom, which could be considerably reduced by using only a small number of typical distortions found by PCA on manually controlled grids (Lanitis et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10293011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bc436d2892be45fd16ba2620ca0a620bf9f52d7",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the use of flexible models for representing the shape and grey-level appearance of human faces. These models are controlled by a small number of parameters which can be used to code the overall appearance of a face for image compression and classification purposes. The model parameters control both inter-class and within-class variation. Discriminant analysis techniques are employed to enhance the effect of those parameters affecting inter-class variation, which are useful for classification. We have performed experiments on face coding and reconstruction and automatic face identification. Good recognition rates are obtained even when significant variation in lighting, expression and 3D viewpoint, is allowed. Human faces display significant variation in appearance due to changes in expression, 3D orientation, lighting conditions, hairstyles and so on. A successful automatic face identification system should be capable of suppressing the effect of these factors allowing any face image to be rendered expression-free with standardised 3D orientation and lighting. We describe how the variations in shape and grey-level appearance in face images can be modelled, and present results for a fully automatic face identification system which tolerates changes in expression, viewpoint and lighting."
            },
            "slug": "An-Automatic-Face-Identification-System-Using-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "An Automatic Face Identification System Using Flexible Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "How the variations in shape and grey-level appearance in face images can be modelled are described, and results for a fully automatic face identification system which tolerates changes in expression, viewpoint and lighting are presented."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400601690"
                        ],
                        "name": "A. O'Toole",
                        "slug": "A.-O'Toole",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "O'Toole",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Toole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144319186"
                        ],
                        "name": "H. Abdi",
                        "slug": "H.-Abdi",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Abdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Abdi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4666577"
                        ],
                        "name": "K. Deffenbacher",
                        "slug": "K.-Deffenbacher",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Deffenbacher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Deffenbacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145391215"
                        ],
                        "name": "D. Valentin",
                        "slug": "D.-Valentin",
                        "structuredName": {
                            "firstName": "Dominique",
                            "lastName": "Valentin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Valentin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121463712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af78b1232828f187a61cf144a4265ff98182af87",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Faces can be represented efficiently as a weighted linear combination of the eigenvectors of a covariance matrix of face images. It has also been shown [ J. Opt. Soc. Am.4, 519\u2013 524 ( 1987)] that identifiable faces can be made by using only a subset of the eigenvectors, i.e., those with the largest eigenvalues. This low-dimensional representation is optimal in that it minimizes the squared error between the representation of the face image and the original face image. The present study demonstrates that, whereas this low-dimensional representation is optimal for identifying the physical categories of face, like sex, it is not optimal for recognizing the faces (i.e., discriminating known from unknown faces). Various low-dimensional representations of the faces in the higher dimensions of the face space (i.e., the eigenvectors with smaller eigenvalues) provide better information for face recognition."
            },
            "slug": "Low-dimensional-representation-of-faces-in-higher-O'Toole-Abdi",
            "title": {
                "fragments": [],
                "text": "Low-dimensional representation of faces in higher dimensions of the face space"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Various low-dimensional representations of the faces in the higher dimensions of the face space (i.e., the eigenvectors with smaller eigenvalues) provide better information for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47284853"
                        ],
                        "name": "M. P\u00f6tzsch",
                        "slug": "M.-P\u00f6tzsch",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "P\u00f6tzsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P\u00f6tzsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38975400"
                        ],
                        "name": "Michael Rinne",
                        "slug": "Michael-Rinne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Rinne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Rinne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 203
                            }
                        ],
                        "text": "Each image has a label which indicates the pose, so that pose does not need to be determined automatically, though our system is able to determine pose automatically in the same way as size is estimated [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 489528,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "91faf7f49a0aa219289cbc73b9555251a4dd7255",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new system for the automatic determination of the position , size and pose of the head of a human gure in a camera image. The system is an extension of the well{known face recognition system WFK] to pose estimation. The pose estimation system is characterized by a certain reliability and speed. We improve this performance and speed with the help of statistical estimation methods. In order to make these applicable, we reduce the originally very high dimensionality of our system with the help of a number of a priori principles."
            },
            "slug": "Estimation-of-Face-Position-and-Pose-with-Labeled-Kr\u00fcger-P\u00f6tzsch",
            "title": {
                "fragments": [],
                "text": "Estimation of Face Position and Pose with Labeled Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A new system for the automatic determination of the position, size and pose of the head of a human gure in a camera image with the help of statistical estimation methods is presented."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144286385"
                        ],
                        "name": "Charles L. Wilson",
                        "slug": "Charles-L.-Wilson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Wilson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles L. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503366"
                        ],
                        "name": "S. Sirohey",
                        "slug": "S.-Sirohey",
                        "structuredName": {
                            "firstName": "Saad",
                            "lastName": "Sirohey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sirohey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Craw et al. (1995) have shown that this technique is advantageous for recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 150
                            }
                        ],
                        "text": "1 Comparison to Other Systems There is a considerable literature on face recognition, and many di erent techniques have been applied to the task; see (Samal & Iyengar, 1992; Valentin et al., 1994; Chellappa et al., 1995) for reviews."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 0
                            }
                        ],
                        "text": "Craw et al. (1995) have shown that this technique is advantageous for recognition. They used manually de ned ducial points for warping. Lanitis et al. (1995) apply a graph-matching algorithm similar to ours to nd the ducial points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62185766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa1755e87301af36485ca01e3454bf8888dde8d1",
            "isKey": false,
            "numCitedBy": 3007,
            "numCiting": 177,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this paper is to present a critical survey of existing literature on human and machine recognition of faces. Machine recognition of faces has several applications, ranging from static matching of controlled photographs as in mug shots matching and credit card verification to surveillance video images. Such applications have different constraints in terms of complexity of processing requirements and thus present a wide range of different technical challenges. Over the last 20 years researchers in psychophysics, neural sciences and engineering, image processing analysis and computer vision have investigated a number of issues related to face recognition by humans and machines. Ongoing research activities have been given a renewed emphasis over the last five years. Existing techniques and systems have been tested on different sets of images of varying complexities. But very little synergism exists between studies in psychophysics and the engineering literature. Most importantly, there exists no evaluation or benchmarking studies using large databases with the image quality that arises in commercial and law enforcement applications In this paper, we first present different applications of face recognition in commercial and law enforcement sectors. This is followed by a brief overview of the literature on face recognition in the psychophysics community. We then present a detailed overview of move than 20 years of research done in the engineering community. Techniques for segmentation/location of the face, feature extraction and recognition are reviewed. Global transform and feature based methods using statistical, structural and neural classifiers are summarized. >"
            },
            "slug": "Human-and-machine-recognition-of-faces:-a-survey-Chellappa-Wilson",
            "title": {
                "fragments": [],
                "text": "Human and machine recognition of faces: a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A critical survey of existing literature on human and machine recognition of faces is presented, followed by a brief overview of the literature on face recognition in the psychophysics community and a detailed overview of move than 20 years of research done in the engineering community."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14814282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66505cb708b098a93331471f079965f6ded4ea7f",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "To create a pose-invariant face recognizer, one strategy is the view-based approach, which uses a set of real example views at different poses. But what if we only have one real view available, such as a scanned passport photo-can we still recognize faces under different poses? Given one real view at a known pose, it is still possible to use the view-based approach by exploiting prior knowledge of faces to generate virtual views, or views of the face as seen from different poses. To represent prior knowledge, we use 2D example views of prototype faces under different rotations. We develop example-based techniques for applying the rotation seen in the prototypes to essentially \"rotate\" the single real view which is available. Next, the combined set of one real and multiple virtual views is used as example views for a view-based, pose-invariant face recognizer. Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques.<<ETX>>"
            },
            "slug": "Face-recognition-from-one-example-view-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Face recognition from one example view"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10047234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "617b34332fcd1cb196f93656ee1d49561b81ebf8",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, simpler techniques are applicable under restricted conditions. The approach exploits image transformations that are specific to the relevant object class, and learnable from example views of other \"prototypical\" objects of the same class. In this paper, we introduce such a technique by extending the notion of linear class proposed by the authors (1992). For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views. We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view."
            },
            "slug": "Linear-Object-Classes-and-Image-Synthesis-From-a-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "Linear Object Classes and Image Synthesis From a Single Example Image"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views and preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view is shown."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17779599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc8b25e35a3acb812beb499844734081722319b4",
            "isKey": false,
            "numCitedBy": 2398,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-FERET-database-and-evaluation-procedure-for-Phillips-Wechsler",
            "title": {
                "fragments": [],
                "text": "The FERET database and evaluation procedure for face-recognition algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074669015"
                        ],
                        "name": "J. Kopecz",
                        "slug": "J.-Kopecz",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Kopecz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kopecz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726089898"
                        ],
                        "name": "Rolf Ekkehard Schulze-Kr\u00fcger",
                        "slug": "Rolf-Ekkehard-Schulze-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Schulze-Kr\u00fcger",
                            "middleNames": [
                                "Ekkehard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rolf Ekkehard Schulze-Kr\u00fcger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18450035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "616e7a38b0cc6125d40c2fd23a681fd5a2a21edd",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a biometric access control device which is based on the identification of human faces. The system combines a console for semi-automated image acquisition with the necessary algorithms for face recognition. Facial features are stored in a relatively compact data format (1.6 kB). ZN-Face runs on a Pentium 90 without any special accelerator hardware where it performs image acquisition, face localization and identification in less than 3 seconds. ZN-Face not only allows robust identification of stored persons (despite changes in facial expression or size), but also reliable rejection of unknown persons. With an acceptance criterion which safely rejects all unknown persons we achieve an identification rate above 99% (FRR< 1%). The ZN Bochum GmbH has sold more than 100 licences to various institutions and companies, among them the Kremlin in Moscow. The ZN Bochum GmbH holds the relevant patents for ZN-Face."
            },
            "slug": "ZN-Face:-A-system-for-access-control-using-face-Kopecz-Konen",
            "title": {
                "fragments": [],
                "text": "ZN-Face: A system for access control using automated face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "ZN-Face not only allows robust identification of stored persons (despite changes in facial expression or size), but also reliable rejection of unknown persons, with an acceptance criterion which safely rejects all unknown persons."
            },
            "venue": {
                "fragments": [],
                "text": "SNN Symposium on Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47284853"
                        ],
                        "name": "M. P\u00f6tzsch",
                        "slug": "M.-P\u00f6tzsch",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "P\u00f6tzsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P\u00f6tzsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46714951"
                        ],
                        "name": "C. von der Malsburg",
                        "slug": "C.-von-der-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "von der Malsburg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. von der Malsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A more detailed description of this system is given in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22460012,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8379a36e07f871c6addec689085615f53b4bf6b2",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work described a biologically motivated object recognition system with Gabor wavelets as basic feature type. These features are robust against slight distortion, rotation and variation in illumination. We here describe extensions of the system that address image variance due to arbitrary in-plane rotation, substantial scale changes and moderate depth rotation of objects, and to background variation, using simple linear transformation of the Gabor filter responses. The performance of the system is enhanced significantly."
            },
            "slug": "Improving-object-recognition-by-transforming-Gabor-P\u00f6tzsch-Kr\u00fcger",
            "title": {
                "fragments": [],
                "text": "Improving object recognition by transforming Gabor filter responses."
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Extensions of the biologically motivated object recognition system with Gabor wavelets are described that address image variance due to arbitrary in-plane rotation, substantial scale changes and moderate depth rotation of objects, and to background variation, using simple linear transformation of the Gabor filter responses."
            },
            "venue": {
                "fragments": [],
                "text": "Network"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1477,
                                "start": 72
                            }
                        ],
                        "text": "Phillips & Vardi (1995) and Phillips (1996) have trained two sets of matching pursuit lters for the tasks of face location and identi cation. The lters focus on di erent regions: the interior of the face, the eyes, and the nose for location; tip of the nose, bridge of the nose, left eye, right eye, and interior of the face for identi cation. The performance is high and comparable to that of our system. The small performance di erence between the fully automatic system and the identi cation module indicates that the location module works reliably. For none of the systems were results across di erent poses reported. In the next section we will therefore summarize systems which have been tested for rotation in depth on di erent databases. 4.1.4 Recognizing Faces Rotated in Depth While there is a considerable literature on face recognition in the same pose, there are few systems which deal with large rotation in depth. It is di cult to compare these systems in terms of performance, because they have been tested on di erent galleries. Furthermore, the recognition rates are a result of complete systems and do not necessarily re ect the usefulness of a particular method to compensate for rotation in depth. However, we think it may still be useful to give an overview and to brie y discuss the di erent approaches. Results are given in Table 4. First Reference Database and Method Model gallery Probe images rank # angle(s) # angle(s) % Moghaddam & Pentland (1997) PCA approach separately for di erent views, no speci c transformation interpolation performance 23 21 90 , 45 , 0 21 68 , 23 90 extrapolation performance 23 21 e."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1221,
                                "start": 8
                            }
                        ],
                        "text": "automatically to perform the recognition. This system has been tested on galleries of 21 persons in di erent views. The results listed in Table 4 are averages over several di erent combinations of training and testing views. The recognition rates are an example of how well a system can perform if it does not compensate for e ects of rotation in depth but relies only on the robustness of the subsystem which is closest to the view of the probe image. Our basic system compensates for rotation in depth only in that matching is done with a bunch graph of the new view and correspondences are de ned between ducial points of the new view and ducial points of the standard view for which the model graphs are available. Thus, corresponding jets are compared across di erent views, but the jets are not modi ed in any way to compensate for the e ects of rotation in depth. There are at least three di erent approaches to compensating for the e ects of rotation in depth more explicitly: transforming feature vectors, warping images of faces, and linear decomposition and synthesis of faces in di erent views. Let us rst consider transforming feature vectors. As an extension to our system, Maurer & von der Malsburg (1995) have applied linear vector transformations to the jets to compensate for the e ect of rotation in depth."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2493,
                                "start": 8
                            }
                        ],
                        "text": "automatically to perform the recognition. This system has been tested on galleries of 21 persons in di erent views. The results listed in Table 4 are averages over several di erent combinations of training and testing views. The recognition rates are an example of how well a system can perform if it does not compensate for e ects of rotation in depth but relies only on the robustness of the subsystem which is closest to the view of the probe image. Our basic system compensates for rotation in depth only in that matching is done with a bunch graph of the new view and correspondences are de ned between ducial points of the new view and ducial points of the standard view for which the model graphs are available. Thus, corresponding jets are compared across di erent views, but the jets are not modi ed in any way to compensate for the e ects of rotation in depth. There are at least three di erent approaches to compensating for the e ects of rotation in depth more explicitly: transforming feature vectors, warping images of faces, and linear decomposition and synthesis of faces in di erent views. Let us rst consider transforming feature vectors. As an extension to our system, Maurer & von der Malsburg (1995) have applied linear vector transformations to the jets to compensate for the e ect of rotation in depth. The assumption was that faces can be locally treated as plane surfaces and that the texture transforms accordingly. Since the total rotation of the faces is known, only the normal of the surface at each node has to be estimated, which is done on a training set of faces available in both views. This results in a signi cant improvement. Notice that transformations of feature vectors can only be an approximation to the true transformations of images. This is due to the xed and limited support of the kernels which are used to extract the features. For instance, a circular region on a plane becomes an ellipse if the plane is tilted. Feature vectors based on kernels with circular support can only represent a circular region. If this circular region needs to be transformed into an elliptic region, some information is lost or incorrect information is added to obtain a circular region again. An advantage of this method is that transformations can be performed without reference to the original image. More accurate results can be obtained if the grey-value distributions of faces are warped from one view to another view directly on a pixel level. Vetter (1998) has done this by means of a 3D-model onto which the texture of a face is projected and from which it is then back-projected onto the image plane in a di erent view."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1759,
                                "start": 72
                            }
                        ],
                        "text": "Phillips & Vardi (1995) and Phillips (1996) have trained two sets of matching pursuit lters for the tasks of face location and identi cation. The lters focus on di erent regions: the interior of the face, the eyes, and the nose for location; tip of the nose, bridge of the nose, left eye, right eye, and interior of the face for identi cation. The performance is high and comparable to that of our system. The small performance di erence between the fully automatic system and the identi cation module indicates that the location module works reliably. For none of the systems were results across di erent poses reported. In the next section we will therefore summarize systems which have been tested for rotation in depth on di erent databases. 4.1.4 Recognizing Faces Rotated in Depth While there is a considerable literature on face recognition in the same pose, there are few systems which deal with large rotation in depth. It is di cult to compare these systems in terms of performance, because they have been tested on di erent galleries. Furthermore, the recognition rates are a result of complete systems and do not necessarily re ect the usefulness of a particular method to compensate for rotation in depth. However, we think it may still be useful to give an overview and to brie y discuss the di erent approaches. Results are given in Table 4. First Reference Database and Method Model gallery Probe images rank # angle(s) # angle(s) % Moghaddam & Pentland (1997) PCA approach separately for di erent views, no speci c transformation interpolation performance 23 21 90 , 45 , 0 21 68 , 23 90 extrapolation performance 23 21 e.g. 90 , ..., +45 21 e.g. +68 83 extrapolation performance 45 21 e.g. 90 , ..., +45 21 e.g. +90 50 Wiskott et al. (1997) Gabor jets, no speci c transformation Bochum database 108 0 108 11 94 108 0 108 22 88 FERET database 250 0 250 45 18 250 45 250 0 17 250 45 250 90 9 250 90 250 45 12 Maurer & von der Malsburg (1995) Gabor jets, learned normal vectors for geometrical rotation transformation Bochum database, no transformation 110 0 110 22 88 transforming 22 to 0 110 0 110 22 96 FERET database, no transformation 90 0 90 45 36 transforming 45 to 0 90 0 90 45 50 transforming 0 to 45 90 0 90 45 53 Beymer & Poggio (1995) well-controlled gallery, little hair information warping between di erent views 62 ( )20 620 range 40 82 linear decomposition, no shape info."
                    },
                    "intents": []
                }
            ],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": true,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145391215"
                        ],
                        "name": "D. Valentin",
                        "slug": "D.-Valentin",
                        "structuredName": {
                            "firstName": "Dominique",
                            "lastName": "Valentin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Valentin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144319186"
                        ],
                        "name": "H. Abdi",
                        "slug": "H.-Abdi",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Abdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Abdi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400601690"
                        ],
                        "name": "A. O'Toole",
                        "slug": "A.-O'Toole",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "O'Toole",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Toole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 121
                            }
                        ],
                        "text": "There is a considerable literature on face recognition, and many different techniques have been applied to the task; see (Samal & Iyengar, 1992; Valentin et al., 1994; Chellappa et al., 1995) for reviews."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5315848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd05aa5ea9aa8d8e34342362bddd2fe56eb1ae72",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionist-models-of-face-processing:-A-survey-Valentin-Abdi",
            "title": {
                "fragments": [],
                "text": "Connectionist models of face processing: A survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 982857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a62d0cca2fabf1d6f6ee15e4c14cef415b657d1",
            "isKey": false,
            "numCitedBy": 2592,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented for the representation of (pictures of) faces. Within a specified framework the representation is ideal. This results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector. The method is illustrated in detail by the use of an ensemble of pictures taken for this purpose."
            },
            "slug": "Low-dimensional-procedure-for-the-characterization-Sirovich-Kirby",
            "title": {
                "fragments": [],
                "text": "Low-dimensional procedure for the characterization of human faces."
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A method is presented for the representation of faces that results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781325"
                        ],
                        "name": "J. Daugman",
                        "slug": "J.-Daugman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Daugman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Daugman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "A jet is based on a wavelet transform, de ned as a convolution of the image with a family of Gabor kernels [3]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1984348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6513888c5ef473bdbb3167c7b52f0985be071f7a",
            "isKey": false,
            "numCitedBy": 1899,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A three-layered neural network is described for transforming two-dimensional discrete signals into generalized nonorthogonal 2-D Gabor representations for image analysis, segmentation, and compression. These transforms are conjoint spatial/spectral representations, which provide a complete image description in terms of locally windowed 2-D spectral coordinates embedded within global 2-D spatial coordinates. In the present neural network approach, based on interlaminar interactions involving two layers with fixed weights and one layer with adjustable weights, the network finds coefficients for complete conjoint 2-D Gabor transforms without restrictive conditions. In wavelet expansions based on a biologically inspired log-polar ensemble of dilations, rotations, and translations of a single underlying 2-D Gabor wavelet template, image compression is illustrated with ratios up to 20:1. Also demonstrated is image segmentation based on the clustering of coefficients in the complete 2-D Gabor transform. >"
            },
            "slug": "Complete-discrete-2-D-Gabor-transforms-by-neural-Daugman",
            "title": {
                "fragments": [],
                "text": "Complete discrete 2-D Gabor transforms by neural networks for image analysis and compression"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A three-layered neural network based on interlaminar interactions involving two layers with fixed weights and one layer with adjustable weights finds coefficients for complete conjoint 2-D Gabor transforms without restrictive conditions for image analysis, segmentation, and compression."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145699982"
                        ],
                        "name": "S. Gutta",
                        "slug": "S.-Gutta",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Gutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gutta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47204595"
                        ],
                        "name": "D. Singh",
                        "slug": "D.-Singh",
                        "structuredName": {
                            "firstName": "Dig",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50608273"
                        ],
                        "name": "Imran Shah",
                        "slug": "Imran-Shah",
                        "structuredName": {
                            "firstName": "Imran",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Imran Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34948290"
                        ],
                        "name": "B. Tak\u00e1cs",
                        "slug": "B.-Tak\u00e1cs",
                        "structuredName": {
                            "firstName": "Barnab\u00e1s",
                            "lastName": "Tak\u00e1cs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Tak\u00e1cs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12553705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a55cdc165952d0dc99b4fe71f0e88ec977d5aa",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe herein benchmark studies aimed at advancing the state-of-the-art in automated face recognition. We address three complementary problems: (A) development of a representative data base set of facial images to train, test, and evaluate alternative face recognition schemes; (B) bench marking of both simple but well known algorithms, and of novel automated and integrated face recognition schemes; and (C) training and testing of human subjects to evaluate human performance using the same data base developed to test the automated face recognition component. The major results of our R&D program indicate that (i) future advances in automated face recognition are predicated on the development of hybrid recognition systems, (ii) that holistic (connectionist) methods outperform discrete (and direct) feature and correlation methods, (iii) that if the test beds are random and contextual cues are lacking human performance is quite poor, not consistent, and degrades rapidly when compared with machine performance, and (iv) that extensive and proper testing is crucial for bench marking."
            },
            "slug": "Benchmark-Studies-on-Face-Recognition-Gutta-Huang",
            "title": {
                "fragments": [],
                "text": "Benchmark Studies on Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The major results of the R&D program indicate that future advances in automated face recognition are predicated on the development of hybrid recognition systems, and that holistic (connectionist) methods outperform discrete (and direct) feature and correlation methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231915"
                        ],
                        "name": "S. Der",
                        "slug": "S.-Der",
                        "structuredName": {
                            "firstName": "Sandor",
                            "lastName": "Der",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Der"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 84
                            }
                        ],
                        "text": "Results of a blind test of di erent systems on the FERET database were published in [6, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14238832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39577ba5d7020bc1750b3a417b7d6432ebb7f00c",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As part of the Face Recognition Technology (FERET) program, the U.S. Army Research Laboratory (ARL) conducted supervised government tests and evaluations of automatic face recognition algorithms. The goal of the tests was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition. This report describes the design and presents the results of the August 1994 and March 1995 FERET tests. Results for FERET tests administered by ARL between August 1994 and August 1996 are reported."
            },
            "slug": "FERET-(Face-Recognition-Technology)-Recognition-and-Phillips-Rauss",
            "title": {
                "fragments": [],
                "text": "FERET (Face Recognition Technology) Recognition Algorithm Development and Test Results."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The design and results of the August 1994 and March 1995 FERET tests are described and the goal was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1325911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e4ba33f614ae0578b3d6c2015df536a2795048f",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for the interpretation of camera images of scenes composed of several known objects with mutual occlusion. The scenes are analyzed by the recognition of the objects present and by the determination of their occlusion relations. Objects are internally represented by stored model graphs. These are formed in a semi-automatic way by showing objects against a varying background. Objects are recognized by dynamic link matching. Our experiments show that our system is very successful in analyzing cluttered scenes. The system architecture goes beyond classical neural networks by making extensive use of flexible links between units, as proposed in the dynamic link architecture. The present implementation is, however, rather algorithmic in style and is to be regarded as a pilot study that is preparing the way for a detailed implementation of the architecture."
            },
            "slug": "A-Neural-System-for-the-Recognition-of-Partially-in-Wiskott-Malsburg",
            "title": {
                "fragments": [],
                "text": "A Neural System for the Recognition of Partially Occluded Objects in Cluttered Scenes: A Pilot Study"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The system architecture goes beyond classical neural networks by making extensive use of flexible links between units, as proposed in the dynamic link architecture, and is to be regarded as a pilot study that is preparing the way for a detailed implementation of the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107584303"
                        ],
                        "name": "J. P. Jones",
                        "slug": "J.-P.-Jones",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Jones",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3459632"
                        ],
                        "name": "L. Palmer",
                        "slug": "L.-Palmer",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Palmer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16809045,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "0dbf797d5b34f40d16eeadfa7a5b4543c2af2c11",
            "isKey": false,
            "numCitedBy": 1709,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Using the two-dimensional (2D) spatial and spectral response profiles described in the previous two reports, we test Daugman's generalization of Marcelja's hypothesis that simple receptive fields belong to a class of linear spatial filters analogous to those described by Gabor and referred to here as 2D Gabor filters. 2. In the space domain, we found 2D Gabor filters that fit the 2D spatial response profile of each simple cell in the least-squared error sense (with a simplex algorithm), and we show that the residual error is devoid of spatial structure and statistically indistinguishable from random error. 3. Although a rigorous statistical approach was not possible with our spectral data, we also found a Gabor function that fit the 2D spectral response profile of each simple cell and observed that the residual errors are everywhere small and unstructured. 4. As an assay of spatial linearity in two dimensions, on which the applicability of Gabor theory is dependent, we compare the filter parameters estimated from the independent 2D spatial and spectral measurements described above. Estimates of most parameters from the two domains are highly correlated, indicating that assumptions about spatial linearity are valid. 5. Finally, we show that the functional form of the 2D Gabor filter provides a concise mathematical expression, which incorporates the important spatial characteristics of simple receptive fields demonstrated in the previous two reports. Prominent here are 1) Cartesian separable spatial response profiles, 2) spatial receptive fields with staggered subregion placement, 3) Cartesian separable spectral response profiles, 4) spectral response profiles with axes of symmetry not including the origin, and 5) the uniform distribution of spatial phase angles. 6. We conclude that the Gabor function provides a useful and reasonably accurate description of most spatial aspects of simple receptive fields. Thus it seems that an optimal strategy has evolved for sampling images simultaneously in the 2D spatial and spatial frequency domains."
            },
            "slug": "An-evaluation-of-the-two-dimensional-Gabor-filter-Jones-Palmer",
            "title": {
                "fragments": [],
                "text": "An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It seems that an optimal strategy has evolved for sampling images simultaneously in the 2D spatial and spatial frequency domains and the Gabor function provides a useful and reasonably accurate description of most spatial aspects of simple receptive fields."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A more detailed description of this system is given in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49053294"
                        ],
                        "name": "K. Okada",
                        "slug": "K.-Okada",
                        "structuredName": {
                            "firstName": "Kazunori",
                            "lastName": "Okada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Okada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49072208"
                        ],
                        "name": "J. Steffens",
                        "slug": "J.-Steffens",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Steffens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Steffens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49072208"
                        ],
                        "name": "J. Steffens",
                        "slug": "J.-Steffens",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Steffens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Steffens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093215944"
                        ],
                        "name": "Hai Hong",
                        "slug": "Hai-Hong",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889830"
                        ],
                        "name": "Egor Elagin",
                        "slug": "Egor-Elagin",
                        "structuredName": {
                            "firstName": "Egor",
                            "lastName": "Elagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Egor Elagin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665814"
                        ],
                        "name": "H. Neven",
                        "slug": "H.-Neven",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Neven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9076139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9579768d142a7020d095090183805c98a2f78e5",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the Bochum/USC face recognition system, our preparations for the FERET Phase III test, and test results as far as they have been made known to us. Our technology is based on Gabor wavelets and elastic bunch graph matching. We briefly discuss our technology in relation to biological and PCA based systems and indicate current activities in the lab and potential future applications."
            },
            "slug": "The-Bochum/USC-Face-Recognition-System-And-How-it-Okada-Steffens",
            "title": {
                "fragments": [],
                "text": "The Bochum/USC Face Recognition System And How it Fared in the FERET Phase III Test"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper summarizes the Bochum/USC face recognition system, the preparations for the FERET Phase III test, and test results as far as they have been made known to us."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2852,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 263
                            }
                        ],
                        "text": "Besides the ability to handle larger galleries and larger rotation in depth, the main achievement of the system presented here is that the increased matching accuracy, the object adapted graphs, and the face bunch graph provide the basis for further developments [2, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7344551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41d74145ec66ff0e0128d06ad647aab38e7d6281",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a learning algorithm for the weights in a very common class of discrimination functions usually called \"weighted average.\" The learning algorithm can reduce the number of free variables by simple but effective a priori criteria about significant features. Here we apply our algorithm to three tasks of different dimensionality all concerned with face recognition."
            },
            "slug": "An-Algorithm-for-the-Learning-of-Weights-in-Using-a-Kr\u00fcger",
            "title": {
                "fragments": [],
                "text": "An Algorithm for the Learning of Weights in Discrimination Functions Using a Priori Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A learning algorithm for the weights in a very common class of discrimination functions usually called \"weighted average\" is introduced and applied to three tasks of different dimensionality all concerned with face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": false,
            "numCitedBy": 5639,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52361605"
                        ],
                        "name": "Norbert Kr uger",
                        "slug": "Norbert-Kr-uger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "uger",
                            "middleNames": [
                                "Kr"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norbert Kr uger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060802745"
                        ],
                        "name": "Eric Ma el",
                        "slug": "Eric-Ma-el",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "el",
                            "middleNames": [
                                "Ma"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Ma el"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38456483"
                        ],
                        "name": "Mike Pagel",
                        "slug": "Mike-Pagel",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Pagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Pagel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31909135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30d888e608d134baff71941c6e52ebdee244fe19",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an object recognition system based on bent and stretched Gabor wavelets, called banana wavelets. Banana wavelets can be metrically organized. Utilizing this metric, representations of objects are learned autonomously on training data generated by a robot arm combined with a camera. We discuss possible analogies to learning of object representations by infants."
            },
            "slug": "Autonomous-Learning-of-Object-Representations-Self-uger-el",
            "title": {
                "fragments": [],
                "text": "Autonomous Learning of Object Representations Utilizing Self { Controlled Movements 1"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "An object recognition system based on bent and stretched Gabor wavelets, called banana wavelet, is introduced, using this metric to learn representations of objects autonomously on training data generated by a robot arm combined with a camera."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302763"
                        ],
                        "name": "W. Theimer",
                        "slug": "W.-Theimer",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Theimer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Theimer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038637"
                        ],
                        "name": "H. Mallot",
                        "slug": "H.-Mallot",
                        "structuredName": {
                            "firstName": "Hanspeter",
                            "lastName": "Mallot",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mallot"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 158
                            }
                        ],
                        "text": "This can be done by maximizing S in its Taylor expansion around ~ d = 0, which is a constrained t of the two-dimensional ~ d to the 40 phase di erences j 0 j [2, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64142044,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "4f2ac80621b8214374d41ce33e1a20df9a3c4a06",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We present a technique for guiding vergence movements for an active stereo camera system and for calculating dense disparity maps. Both processes are described in the same theoretical framework based on phase differences in complex Gabor filter responses, modeling receptive field properties in the visual cortex. While the camera movements are computed with input images of coarse spatial resolution, the disparity map calculation uses a finer resolution in the scale space. The correspondence problem is solved implicitly by restricting the disparity range around zero disparity (Panum\u2032s area in the human visual system). The vergence process is interpreted as a mechanism to minimize global disparity, thereby setting a 3D region of interest for subsequent disparity detection. The disparity map represents smaller local disparities as an important cue for depth perception. Experimental data for the integrated performance of vergence in natural scenes followed by disparity map calculations are presented."
            },
            "slug": "Phase-based-binocular-vergence-control-and-depth-Theimer-Mallot",
            "title": {
                "fragments": [],
                "text": "Phase-based binocular vergence control and depth reconstruction using active vision"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A technique for guiding vergence movements for an active stereo camera system and for calculating dense disparity maps described in the same theoretical framework based on phase differences in complex Gabor filter responses, modeling receptive field properties in the visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925241"
                        ],
                        "name": "D. Pollen",
                        "slug": "D.-Pollen",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Pollen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pollen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1992154"
                        ],
                        "name": "S. Ronner",
                        "slug": "S.-Ronner",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Ronner",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ronner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11912279,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "818e8a5f1e8b3cc5d0cb72a60ecbef2ba4549b81",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Adjacent simple cells recorded and \"isolated\" simultaneously from the same microelectrode placement were usually tuned to the same orientation and spatial frequency. The responses of the members of these \"spatial frequency pairs\" to drifting sine-wave gratings were cross-correlates. Within the middle range of the spatial frequency selectivity curves, the responses of the paired cells differed in phase by approximately 90 percent. This phase relationship suggests that adjacent simple cells tuned to the same spatial frequency and orientation represent paired sine and cosine filters in terms of their processing of afferent spatial inputs and truncated sine and cosine filters in terms of the output of simple cells."
            },
            "slug": "Phase-relationships-between-adjacent-simple-cells-Pollen-Ronner",
            "title": {
                "fragments": [],
                "text": "Phase relationships between adjacent simple cells in the visual cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This phase relationship suggests that adjacent simple cells tuned to the same spatial frequency and orientation represent paired sine and cosine filters in terms of their processing of afferent spatial inputs and truncated sines and cosines in Terms of the output of simple cells."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939761"
                        ],
                        "name": "P. S. Penev",
                        "slug": "P.-S.-Penev",
                        "structuredName": {
                            "firstName": "Penio",
                            "lastName": "Penev",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. S. Penev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9885372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75c979c57b2319f98d793920c92a5ac51207791b",
            "isKey": false,
            "numCitedBy": 774,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Low-dimensional representations of sensory signals are key to solving many of the computational problems encountered in high-level vision. Principal component analysis (PCA) has been used in the pa..."
            },
            "slug": "Local-feature-analysis:-A-general-statistical-for-Penev-Atick",
            "title": {
                "fragments": [],
                "text": "Local feature analysis: A general statistical theory for object representation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Low-dimensional representations of sensory signals are key to solving many of the computational problems encountered in high-level vision."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145606123"
                        ],
                        "name": "P. O. Bishop",
                        "slug": "P.-O.-Bishop",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Bishop",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. O. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088293"
                        ],
                        "name": "G. Henry",
                        "slug": "G.-Henry",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Henry",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Henry"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9441172,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "d228cc6646749aa701cba4d6fd7e55a89fd24874",
            "isKey": false,
            "numCitedBy": 1199,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "And how this book will influence you to do better future? It will relate to how the readers will get the lessons that are coming. As known, commonly many people will believe that reading can be an entrance to enter the new perception. The perception will influence how you step you life. Even that is difficult enough; people with high sprit may not feel bored or give up realizing that concept. It's what spatial vision will give the thoughts for you."
            },
            "slug": "Spatial-vision.-Bishop-Henry",
            "title": {
                "fragments": [],
                "text": "Spatial vision."
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "How this book will influence you to do better future will relate to how the readers will get the lessons that are coming."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of psychology"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "On the same galleries the preceding system [1] achieved 92%, 97%, and 85%."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "In comparison to the system [1] on the basis of which we have developed the system presented here we have made several major modi cations."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "The system presented here is based on a face recognition system described in [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "It contains neutral frontal views (fa), frontal views with di erent facial expression (fb), 11 rotated poses (refered to as 15 in [1] because the gaze is at 15 , but the head rotation is less), 22 rotated poses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "The system di ers from the preceding one [1] in three respects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "A second set of tests has been done on the Bochum database [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": true,
            "numCitedBy": 672691,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 93
                            }
                        ],
                        "text": "It should be noted that we could not nd results for the face recognition system developed by Atick et al. (1995) and Penev & Atick (1996). Their system performed well in one of the o cial tests (Phillips et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 93
                            }
                        ],
                        "text": "It should be noted that we could not nd results for the face recognition system developed by Atick et al. (1995) and Penev & Atick (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1404,
                                "start": 93
                            }
                        ],
                        "text": "It should be noted that we could not nd results for the face recognition system developed by Atick et al. (1995) and Penev & Atick (1996). Their system performed well in one of the o cial tests (Phillips et al., 1998). Gordon (1995) has developed a system which automatically selects regions around left eye, right eye, nose, and mouth for frontal views and a region covering the pro le for pro le views. The faces are then normalized for scale and rotation. The recognition is based on normalized cross-correlation of these ve regions compared to reference models. Results are given for the fully automatic system, also for frontal views only, and for a system in which the normalization points, i.e. pupil centers, nose tip, and chin tip, are selected by hand. For the combined gallery (fa + pl), there is a great di erence between the performance of the fully automatic system and that with manually located normalization points. This indicates that the automatic location of the normalization points is the main weakness of this system. Gutta et al. (1995) have collected the images for the FERET database. They have tested the performance of a standard RBF (radial basis function) network and a system based on geometrical relationships between facial features, such as eyes, nose, mouth, etc. The performance of the latter was very low and is not summarized in Table 3. Moghaddam & Pentland (1994) have presented results based on the PCA approach discussed in the previous section."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 93
                            }
                        ],
                        "text": "It should be noted that we could not nd results for the face recognition system developed by Atick et al. (1995) and Penev & Atick (1996). Their system performed well in one of the o cial tests (Phillips et al., 1998). Gordon (1995) has developed a system which automatically selects regions around left eye, right eye, nose, and mouth for frontal views and a region covering the pro le for pro le views."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1061,
                                "start": 93
                            }
                        ],
                        "text": "It should be noted that we could not nd results for the face recognition system developed by Atick et al. (1995) and Penev & Atick (1996). Their system performed well in one of the o cial tests (Phillips et al., 1998). Gordon (1995) has developed a system which automatically selects regions around left eye, right eye, nose, and mouth for frontal views and a region covering the pro le for pro le views. The faces are then normalized for scale and rotation. The recognition is based on normalized cross-correlation of these ve regions compared to reference models. Results are given for the fully automatic system, also for frontal views only, and for a system in which the normalization points, i.e. pupil centers, nose tip, and chin tip, are selected by hand. For the combined gallery (fa + pl), there is a great di erence between the performance of the fully automatic system and that with manually located normalization points. This indicates that the automatic location of the normalization points is the main weakness of this system. Gutta et al. (1995) have collected the images for the FERET database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face-recognition from live video for real-world"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 670,
                                "start": 38
                            }
                        ],
                        "text": "It is worth considering the system by Lanitis et al. (1995) in more detail because of its close relationship to our system. Both systems apply a graph-matching process for nding ducial points and extract local features for recognition. The system by Lanitis et al. (1995) in addition warps the face to average geometry and applies PCA to it. There are two di erences we want to point out. Firstly, the matching process di ers in the way in which distortions are treated. Our system assumes a simple spring model, which introduces a large number of degrees of freedom and also includes distortions which are unrealistic, cf. mismatches in Figure 4. Lanitis et al. (1995), on the other hand, use PCA also to analyze distortion patterns of sample face images, the rst eigenvectors providing a relatively small set of plausible geometrical distortions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 38
                            }
                        ],
                        "text": "It is worth considering the system by Lanitis et al. (1995) in more detail because of its close relationship to our system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 38
                            }
                        ],
                        "text": "It is worth considering the system by Lanitis et al. (1995) in more detail because of its close relationship to our system. Both systems apply a graph-matching process for nding ducial points and extract local features for recognition. The system by Lanitis et al. (1995) in addition warps the face to average geometry and applies PCA to it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Determination of face position"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69880604"
                        ],
                        "name": "Rolf P. Wrtz",
                        "slug": "Rolf-P.-Wrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Wrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rolf P. Wrtz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60473668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239c94ee334e4e1e23700e718201e87393487cc9",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Object-recognition-with-Gabor-functions-in-the-link-Buhmann-Lange",
            "title": {
                "fragments": [],
                "text": "Object recognition with Gabor functions in the dynamic link architecture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "A more detailed description of this system is given in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "See [2] for a more detailed discussion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "40 phase differences fj - f\u2019j [2], [4]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30523165,
            "fieldsOfStudy": [],
            "id": "6f01963039d0a921b1930b4563d1601ff36b971f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Elastic Bunch Graph Matching"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686726016"
                        ],
                        "name": "WiskottLaurenz",
                        "slug": "WiskottLaurenz",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "WiskottLaurenz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "WiskottLaurenz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644047601"
                        ],
                        "name": "FellousJean-Marc",
                        "slug": "FellousJean-Marc",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "FellousJean-Marc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "FellousJean-Marc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644039936"
                        ],
                        "name": "Kr\u00fcgerNorbert",
                        "slug": "Kr\u00fcgerNorbert",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Kr\u00fcgerNorbert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kr\u00fcgerNorbert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644047205"
                        ],
                        "name": "von der MalsburgChristopher",
                        "slug": "von-der-MalsburgChristopher",
                        "structuredName": {
                            "firstName": "von",
                            "lastName": "MalsburgChristopher",
                            "middleNames": [
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "von der MalsburgChristopher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215900517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14a0c0e79183e4aa343b2aefc5d88f3b17436c23",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transfo..."
            },
            "slug": "Face-Recognition-by-Elastic-Bunch-Graph-Matching-WiskottLaurenz-FellousJean-Marc",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Elastic Bunch Graph Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, represented by labeled graphs, based on a Gabor wavelet transfo..."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 263
                            }
                        ],
                        "text": "Besides the ability to handle larger galleries and larger rotation in depth, the main achievement of the system presented here is that the increased matching accuracy, the object adapted graphs, and the face bunch graph provide the basis for further developments [2, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear feature transformations to recognize faces rotated in depth"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the International Conference on Arti cial Neural Networks,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Autonomous learning of object"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "In an extension of the system presented here,Kr\u007f uger has developed a method for learning weights emphasizing those nodes which are more discriminative and more robust against noise [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "uger, \\An algorithm for the learning of weights in discrimination functions using a priori constraints.\" accepted for publication"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving object recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An evaluation of the two-dimensional Gabor lter model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear feature transformations to recognize faces rotated"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Data driven methods in face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Workshop on Automatic Face-and Gesture-Recognition, IWAFGR'95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 38
                            }
                        ],
                        "text": "O cial results have been published in (Phillips & Rauss, 1997;Phillips et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 55
                            }
                        ],
                        "text": "Their system performed well in one of the o cial tests (Phillips et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The FERET database and evaluation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Lo eve procedure for the characterization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic face recogni"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face-recognition from live video for real-world applications | now"
            },
            "venue": {
                "fragments": [],
                "text": "Advanced Imaging"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist models of faceprocessing : A survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition technology (FERET program)"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. OOce of National Drug Control Policy. (in press)"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "The manual selection of ducial points could be replaced by grouping salient points on the basis of common motion [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and C"
            },
            "venue": {
                "fragments": [],
                "text": "von der Malsburg, \\A feature based approach to face recognition,\" Tech. Rep. CAR-TR-604 or CS-TR-2834, Computer Vision Laboratory, University of Maryland, Colledge Park, MD 20742{3411"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An automatic face identi cation system using exible appearance models"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Personal use of this material is permitted"
            },
            "venue": {
                "fragments": [],
                "text": "Personal use of this material is permitted"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phase relationship between adjacent simple cells in the visualcortex"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic face recognition: Combining connguration and texture"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Workshop on Automatic Face-and Gesture-Recognition, IWAFGR'95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear fea-  ture transformations to recognize faces rotated in  depth,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Con-  ference on Arti cial Neural Networks,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DePersia, \\FERET (face-recognition technol-  ogy) recognition"
            },
            "venue": {
                "fragments": [],
                "text": "algorithms,\" in Proc. of the Fifth  Automatic Target Recognizer System and Technology  Symposium,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive eld properties by learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human and machine recognition of faces : Asurvey"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . of the IEEE"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An automatic face identi cation system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen - Lo \u0012 eve procedure for the characterizationof human faces"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . on Pattern Analysis and Machine Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phase relationship between adjacent simple cells"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic recognition and analysis of human faces and facialexpressions : A survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A feature based approach to face recog-  nition,"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep. CAR-TR-604 or CS-TR-2834,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "uger, \\An algorithm for the learning of weights  in discrimination functions using a priori con-  straints.\" accepted for publication"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transac-  tions on Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face-recognition from live video for real-world applications \u2014 now"
            },
            "venue": {
                "fragments": [],
                "text": "Advanced Imaging"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 84
                            }
                        ],
                        "text": "Results of a blind test of di erent systems on the FERET database were published in [5, 6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "FERET (face-recognition technology) recognition algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. of the Fifth Automatic Target Recognizer System and Technology Symposium"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic recognition and analysis of human faces and facial"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An automatic face identiication system using exible appearance models"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A neural system for the recognition of partially occludedobjects in cluttered scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Int ' l J . of Pattern Recognition and Arti cial Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A more detailed description of this system is given in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An evaluation of the two-dimensional Gabor lter model of simple receptive elds in cat striate cortex"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Neurophysiology"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face - recognition from live video for real - worldapplications | now"
            },
            "venue": {
                "fragments": [],
                "text": "Advanced Imaging"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic face recognition: Combining configuration and texture"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Workshop on Automatic Face-and Gesture-Recognition, IWAFGR'95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An evaluation of the two - dimensional Gabor lter model ofsimple receptive elds in cat striate cortex"
            },
            "venue": {
                "fragments": [],
                "text": "J . of Neurophysiology"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wiskott , \u201c Phantom Faces for Face Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 150
                            }
                        ],
                        "text": "1 Comparison to Other Systems There is a considerable literature on face recognition, and many di erent techniques have been applied to the task; see (Samal & Iyengar, 1992; Valentin et al., 1994; Chellappa et al., 1995) for reviews."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist models of face"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 133
                            }
                        ],
                        "text": "Gabor wavelets are biologically motivated convolution kernels in the shape of plane waves restricted by a Gaussian envelope function (Daugman, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Complete discrete 2-D Gabor transform by neural networks for image analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wiskott , \u201c Phantom faces for face analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Inter - national Conference o n Image Processing , Santa Barbara"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 22,
            "methodology": 12,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 90,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Face-recognition-by-elastic-bunch-graph-matching-Wiskott-Fellous/5c27487c3e0894b65e976a287e6f8c9aa40f089c?sort=total-citations"
}