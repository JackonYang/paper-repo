{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758714"
                        ],
                        "name": "S. Fahlman",
                        "slug": "S.-Fahlman",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Fahlman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fahlman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The first problem to be described is the 10-5-10 Encoder task, for it is also discussed largely in [ 5 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For our study we implemented several learning procedures: Ordinary gradient descent by backpropagation (BP), SuperSAB (SSAB) [4], Quickprop (QP) [ 5 ] and RPROP."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Especially in more difficult problems, this technique worked far more stable than adding a small constant value to the derivation of the activation function, as proposed in [ 5 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 284549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "722a3c365a134a9f9b9ae1511f018d9b1ecff3de",
            "isKey": true,
            "numCitedBy": 1016,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Most connectionist or \"neural network\" learning systems use some form of the back-propagation algorithm. However, back-propagation learning is too slow for many applications, and it scales up poorly as tasks become larger and more complex. The factors governing learning speed are poorly understood. I have begun a systematic, empirical study of learning speed in backprop-like algorithms, measured against a variety of benchmark problems. The goal is twofold: to develop faster learning algorithms and to contribute to the development of a methodology that will be of value in future studies of this kind. This paper is a progress report describing the results obtained during the first six months of this study. To date I have looked only at a limited set of benchmark problems, but the results on these are encouraging: I have developed a new learning algorithm that is faster than standard backprop by an order of magnitude or more and that appears to scale up very well as the problem size increases. This research was sponsored in part by the National Science Foundation under Contract Number EET-8716324 and by the Defense Advanced Research Projects Agency (DOD), ARPA Order No. 4976 under Contract F33615-87C-1499 and monitored by the Avionics Laboratory, Air Force Wright Aeronautical Laboratories, Aeronautical Systems Division (AFSC), Wright-Patterson AFB, OH 45433-6543. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of these agencies or of the U.S. Government."
            },
            "slug": "An-empirical-study-of-learning-speed-in-networks-Fahlman",
            "title": {
                "fragments": [],
                "text": "An empirical study of learning speed in back-propagation networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new learning algorithm is developed that is faster than standard backprop by an order of magnitude or more and that appears to scale up very well as the problem size increases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510971"
                        ],
                        "name": "T. Tollenaere",
                        "slug": "T.-Tollenaere",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Tollenaere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tollenaere"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29674798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa79c269b31af3834b6db801bb0ad9690e13631c",
            "isKey": false,
            "numCitedBy": 407,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SuperSAB:-Fast-adaptive-back-propagation-with-good-Tollenaere",
            "title": {
                "fragments": [],
                "text": "SuperSAB: Fast adaptive back propagation with good scaling properties"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774458"
                        ],
                        "name": "W. Schiffmann",
                        "slug": "W.-Schiffmann",
                        "structuredName": {
                            "firstName": "Wolfram",
                            "lastName": "Schiffmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Schiffmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71278113"
                        ],
                        "name": "M. Joost",
                        "slug": "M.-Joost",
                        "structuredName": {
                            "firstName": "Merten",
                            "lastName": "Joost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Joost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33116683"
                        ],
                        "name": "R. Werner",
                        "slug": "R.-Werner",
                        "structuredName": {
                            "firstName": "Randolf",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Werner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60155324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3561e38060e41d48cedffa93699a676b05812e8",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "5 Global learning rate adaptation 8 5.1 Fixed calculating of the learning rate 8 5.2 Decreasing learning rate 8 5.3 Learning rate adaptation for each training pattern 12 5.4 Evolutionarily adapted learning rate 12 5.5 Angle driven learning rate adaptation 15 5.6 Nearly optimal learning rate adjust using line search 15 5.6.1 Polak\u2013Ribiere method and line search 17 5.6.2 Conjugate gradient method and line search 18"
            },
            "slug": "Optimization-of-the-Backpropagation-Algorithm-for-Schiffmann-Joost",
            "title": {
                "fragments": [],
                "text": "Optimization of the Backpropagation Algorithm for Training Multilayer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Learning rate adaptation for each training pattern 12 and nearly optimal learning rate adjust using line search 15 5.6.1 Polak\u2013Ribiere method and line search 17 5.4 Evolutionarily adapted learning rate 12 5.5 Global learning rate adaptation 8 5.1 Fixed calculating of the learning rate."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144215175"
                        ],
                        "name": "R. Jacobs",
                        "slug": "R.-Jacobs",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Examples of such algorithms are the Delta-Bar-Delta technique [3] or the SuperSAB algorithm [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9947500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9ef2995e8e1bd57a74343073219364811c2ace0",
            "isKey": false,
            "numCitedBy": 1988,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Increased-rates-of-convergence-through-learning-Jacobs",
            "title": {
                "fragments": [],
                "text": "Increased rates of convergence through learning rate adaptation"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46442363"
                        ],
                        "name": "K. Lang",
                        "slug": "K.-Lang",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Lang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59803371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de8f292d456f8541b53587f46f30ea22a9b8ad52",
            "isKey": false,
            "numCitedBy": 508,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Alexis P. Wieland recently proposed a useful benchmark task for neural networks: distinguishing between two intertwined spirals. Although this task is easy to visualize, it is hard for a network to learn due to its extreme nonlinearity. In this report we exhibit a networkarchitecture that facilitates the learning of the spiral task, and then compare the leaming speed of several variants of the back-propagation algorithm."
            },
            "slug": "Learning-to-tell-two-spirals-apart-Lang",
            "title": {
                "fragments": [],
                "text": "Learning to tell two spirals apart"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A networkarchitecture is exhibited that facilitates the learning of the spiral task, and the leaming speed of several variants of the back-propagation algorithm is compared."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "The basic idea of the backpropagation learning algorithm [l] is the repeated application of the chain rule to compute the influence of each weight in the network with respect to an arbitrary errorfunction E:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "McClelland"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel Distributed Processing."
            },
            "year": 1986
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 6,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/A-direct-adaptive-method-for-faster-backpropagation-Riedmiller-Braun/916ceefae4b11dadc3ee754ce590381c568c90de?sort=total-citations"
}