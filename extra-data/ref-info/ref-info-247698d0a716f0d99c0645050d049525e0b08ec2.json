{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144158372"
                        ],
                        "name": "F. Wilczek",
                        "slug": "F.-Wilczek",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Wilczek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wilczek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 221
                            }
                        ],
                        "text": "The interpre tat ion of target activities as probability distr ibution s leads to measuring network perform ance in processing in pu t 0:' by t he relative entropy of the target to the out put proba bility distr ibutions [1] [2] [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10578219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d9ed799fcc2ba2f929532a4f403091198bcfd83",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose that the back propagation algorithm for supervised learning can be generalized, put on a satisfactory conceptual footing, and very likely made more efficient by defining the values of the output and input neurons as probabilities and varying the synaptic weights in the gradient direction of the log likelihood, rather than the 'error'."
            },
            "slug": "Supervised-Learning-of-Probability-Distributions-by-Baum-Wilczek",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Probability Distributions by Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The back propagation algorithm for supervised learning can be generalized, put on a satisfactory conceptual footing, and very likely made more efficient by defining the values of the output and input neurons as probabilities and varying the synaptic weights in the gradient direction of the log likelihood, rather than the 'error'."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 225
                            }
                        ],
                        "text": "The interpre tat ion of target activities as probability distr ibution s leads to measuring network perform ance in processing in pu t 0:' by t he relative entropy of the target to the out put proba bility distr ibutions [1] [2] [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19920501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c8293e7054230cc6cc6e3172f761d89d267f7a7",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning algorithms have been used both on feed-forward deterministic networks and on feed-back statistical networks to capture input-output relations and do pattern classification. These learning algorithms are examined for a class of problems characterized by noisy or statistical data, in which the networks learn the relation between input data and probability distributions of answers. In simple but nontrivial networks the two learning rules are closely related. Under some circumstances the learning problem for the statistical networks can be solved without Monte Carlo procedures. The usual arbitrary learning goals of feed-forward networks can be given useful probabilistic meaning."
            },
            "slug": "Learning-algorithms-and-probability-distributions-Hopfield",
            "title": {
                "fragments": [],
                "text": "Learning algorithms and probability distributions in feed-forward and feed-back networks."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "These learning algorithms are examined for a class of problems characterized by noisy or statistical data, in which the networks learn the relation between input data and probability distributions of answers, in simple but nontrivial networks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62359231,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f1277592f221ea26fa1d2321a38b64c58b33d75b",
            "isKey": false,
            "numCitedBy": 8009,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This completely revised second edition presents an introduction to statistical pattern recognition. Pattern recognition in general covers a wide range of problems: it is applied to engineering problems, such as character readers and wave form analysis as well as to brain modeling in biology and psychology. Statistical decision and estimation, which are the main subjects of this book, are regarded as fundamental to the study of pattern recognition. This book is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field. Each chapter contains computer projects as well as exercises."
            },
            "slug": "Introduction-to-Statistical-Pattern-Recognition-Fukunaga",
            "title": {
                "fragments": [],
                "text": "Introduction to Statistical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This completely revised second edition presents an introduction to statistical pattern recognition, which is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 67
                            }
                        ],
                        "text": "The err or functi on EL(\\\u00b7\\i ) of equat ion (2.16) has been used by Hopfield [2] to com p are layered network learning wit h Boltzmann machine learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 216
                            }
                        ],
                        "text": "The interpre tat ion of target activities as probability distr ibutions leads to measuring network performance in processing inpu t 0:' by the relative entropy of the target to the out put probability distr ibutions [1-3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "16) has been used by Hopfield [2] to compare layered network learning wit h Boltzmann machine learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hopfie ld , \"Learn ing Algorithms an d Probabili ty Distributions in Feedforward and Feed-back Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Natl. Acad. Sci. USA,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principles of Digital Comm unication and Coding"
            },
            "venue": {
                "fragments": [],
                "text": "Principles of Digital Comm unication and Coding"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learni ng by Choice of Intern al Representa tions\" } to be published"
            },
            "venue": {
                "fragments": [],
                "text": "Learni ng by Choice of Intern al Representa tions\" } to be published"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generaliza tion in Neural Networ ks: the Contiguity Problem"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of th e IEEE First [ntem ational Conference OJl Neural Netwo rks"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pa rallel Networks t ha t Learn to Pronoun ce Englis h Text"
            },
            "venue": {
                "fragments": [],
                "text": "Pa rallel Networks t ha t Learn to Pronoun ce Englis h Text"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Intern al Rep resentation s by Error Propagation"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel Distribu ted Processing: Explorations ill the Microstructure of Cognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning and Geueraliza .tion in Layered Neural Net works: the Cont iguity Problem"
            },
            "venue": {
                "fragments": [],
                "text": "Learning and Geueraliza .tion in Layered Neural Net works: the Cont iguity Problem"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Con nect ionist Learnin g P rocedures"
            },
            "venue": {
                "fragments": [],
                "text": "Con nect ionist Learnin g P rocedures"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wilczek } \" Superv ised Learni ng of Probability Distributions by Neural Networks \" } to appear in Proceedings of tile IEEE Con ference on Neural In formation Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Natural and Sy nthet ic } ( Denver }"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rosenb erg } \" Parallel Networks t ha t Learn to Pronoun ce English Text \""
            },
            "venue": {
                "fragments": [],
                "text": "Learning Intern al Rep resentations by Error Propagation \" , in Parallel Distribu ted Processing : Explorations ill the Microstructure of Cognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Learning} Rule Extraction , and Generali zation"
            },
            "venue": {
                "fragments": [],
                "text": "Automatic Learning} Rule Extraction , and Generali zation"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 14,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Accelerated-Learning-in-Layered-Neural-Networks-Solla-Levin/247698d0a716f0d99c0645050d049525e0b08ec2?sort=total-citations"
}