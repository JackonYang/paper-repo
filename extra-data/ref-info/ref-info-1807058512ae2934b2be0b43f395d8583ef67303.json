{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2603520"
                        ],
                        "name": "M. Fukumoto",
                        "slug": "M.-Fukumoto",
                        "structuredName": {
                            "firstName": "Masaaki",
                            "lastName": "Fukumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fukumoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722602"
                        ],
                        "name": "K. Mase",
                        "slug": "K.-Mase",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Mase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34857543"
                        ],
                        "name": "Y. Suenaga",
                        "slug": "Y.-Suenaga",
                        "structuredName": {
                            "firstName": "Yasuhito",
                            "lastName": "Suenaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Suenaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14584017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce8b0e2c27bb503163a00c735ef1e70883f89baa",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "With the growing popularity of information systems, we want to develop new interfaces that are easier for everyone to use. The keyboard is the most common computer inter- face, but it requires a lot of practice to master. We think that a good Human-to-Computer interface for the general population should be so simple to use that no practice is re- quired. It must also allow the operator to communicate in a manner similar to Human-to-Human interaction. Human- to-Human interaction is composed of verbal and non-verbal modes. The role of the non-verbal-mode, which encom- passes posture, gesture, gaze, facial expression and so on, is"
            },
            "slug": "Real-Time-Detection-of-Pointing-Actions-for-a-Fukumoto-Mase",
            "title": {
                "fragments": [],
                "text": "Real-Time Detection of Pointing Actions for a Glove-Free Interface"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A good Human-to-Computer interface for the general population should be so simple to use that no practice is needed and it must also allow the operator to communicate in a manner similar to Human- to-Human interaction."
            },
            "venue": {
                "fragments": [],
                "text": "MVA"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2188267"
                        ],
                        "name": "A. Torige",
                        "slug": "A.-Torige",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Torige",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torige"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063008342"
                        ],
                        "name": "T. Kono",
                        "slug": "T.-Kono",
                        "structuredName": {
                            "firstName": "Tetsuya",
                            "lastName": "Kono",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kono"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61487799,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "6138d1da9433a18ed15fd97e879da173e6190dd3",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors developed a human-interface system to specify the moving direction by recognition of beckon motion. In this system, the recognition of gesture is performed by using a colour image processing system. The communication between persons are performed by using not only voice but also the gesture. In noisy environment, if machines can recognize the human gesture as a command, one operates the machine easily like making command to another person by his gesture. Then, the authors propose a communication method from human to machines by recognition of human gesture with an image processing system. This system makes communication with machines similar to communication with another person. This system needs no special environment, for example a data glove, data suit or a black background for monochrome image processing. It is necessary only that the operator wear a glove of a colour not found in the background.<<ETX>>"
            },
            "slug": "Human-interface-by-recognition-of-human-gesture-of-Torige-Kono",
            "title": {
                "fragments": [],
                "text": "Human-interface by recognition of human gesture with image processing-recognition of gesture to specify moving direction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A communication method from human to machines by recognition of human gesture with an image processing system is proposed, which makes communication with machines similar to communication with another person."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings IEEE International Workshop on Robot and Human Communication"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29530521"
                        ],
                        "name": "Y. Okamoto",
                        "slug": "Y.-Okamoto",
                        "structuredName": {
                            "firstName": "Yasukazu",
                            "lastName": "Okamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Okamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737913"
                        ],
                        "name": "Y. Kuno",
                        "slug": "Y.-Kuno",
                        "structuredName": {
                            "firstName": "Yoshinori",
                            "lastName": "Kuno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kuno"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13611871,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "641187a901e907247a2ebfb214598cfffffd8f29",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an eficient and gmrnetricdly intuitive Problems with this approach algorithm to reliably interpret the image velocities of moving objects in 31). rt is well known that in a small neighbourbood the image motion of points on a plane ia characterised by an afine transformation. We show th& the relative image motion of a nearby non-coplanar point and its projection on the plane is equivalent to motion pamE1nr and that it is a sehble geometric cue to 3D shape and viewer/ot>ject motion. In particular we ahow how to interpret the motion parallax vector of a fourth point and the turf, diue~gence and defownalion compw nents of the affine transformation (defined by the Ehree points of the plane) in order to recover the projection of the axis of rotation of a moving object: the change in relative poaition of the object; the rotation about the say; the till of the surface and a one parameter family of solutions for the slant as a function of the magnitude af tllc rotation of the object. The latter is a manifmtation of the bas-relief ambiguity. These measurements, allhough representing an incomplete solution to structure from motion, can be relierhly extracted from 2 views evcn when perspective effects are small. We present a real-time example in which the 3D vie sun1 interpretat ion of hand gestures or a hand-held object is used as part of a man-machine interface. Thin is an alternative to the Polhemua coil instrumented Datagfav~ commonly uspd in sensing manual gestures."
            },
            "slug": "Qualitative-Visual-Interpretation-of-3d-Hand-Using-Cipolla-Okamoto",
            "title": {
                "fragments": [],
                "text": "Qualitative Visual Interpretation of 3d Hand Gestures Using Motion Parallax"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The relative image motion of a nearby non-coplanar point and its projection on the plane is equivalent to motion pamE1nr and that it is a geometric cue to 3D shape and viewer/ot>ject motion."
            },
            "venue": {
                "fragments": [],
                "text": "MVA"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2169048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9afc90112c201b5c3531a11ab17123bd65d8bbc",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose view-based recognition, a method for 3D\u00a0object recognition based on multi-view representations. We analyze view-based recognition and compare its performance theoretically and empirically with one of the most commonly used method for 3D\u00a0object recognition, 3D\u00a0bounded error recognition. In particular, we show that the probability of false positive or false negative matches in a view-based recognition system is not substantially different from the probability of similar errors in other commonly used recognition systems. Furthermore, we derive an upper bound on the number of views needed to be stored by a view-based recognition system in order to achieve zero probability of false negative matches. Simulations and experiments on real images suggest that these estimates are conservative and that view-based recognition is a robust and simple alternative to the more traditional 3D\u00a0shape based recognition methods."
            },
            "slug": "View-Based-Recognition-Breuel",
            "title": {
                "fragments": [],
                "text": "View-Based Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An upper bound on the number of views needed to be stored by a view-based recognition system in order to achieve zero probability of false negative matches is derived."
            },
            "venue": {
                "fragments": [],
                "text": "MVA"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4361875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50899b2355d6908a304bacb5e406f800f3dde558",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "THE visual recognition of three-dimensional (3-D) objects on the basis of their shape poses at least two difficult problems. First, there is the problem of variable illumination, which can be addressed by working with relatively stable features such as intensity edges rather than the raw intensity images1,2. Second, there is the problem of the initially unknown pose of the object relative to the viewer. In one approach to this problem, a hypothesis is first made about the viewpoint, then the appearance of a model object from such a viewpoint is computed and compared with the actual image3\u20137. Such recognition schemes generally employ 3-D models of objects, but the automatic learning of 3-D models is itself a difficult problem8,9. To address this problem in computational vision, we have developed a scheme, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view. A network equivalent to this scheme will thus 'recognize' the object on which it was trained from any viewpoint."
            },
            "slug": "A-network-that-learns-to-recognize-objects-Poggio-Edelman",
            "title": {
                "fragments": [],
                "text": "A network that learns to recognize three-dimensional objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A scheme is developed, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view, and a network equivalent to this scheme will 'recognize' the object on which it was trained from any viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34971456"
                        ],
                        "name": "K. Ishibuchi",
                        "slug": "K.-Ishibuchi",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Ishibuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ishibuchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72769744"
                        ],
                        "name": "H. Takemura",
                        "slug": "H.-Takemura",
                        "structuredName": {
                            "firstName": "Hidetaka",
                            "lastName": "Takemura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Takemura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289052"
                        ],
                        "name": "F. Kishino",
                        "slug": "F.-Kishino",
                        "structuredName": {
                            "firstName": "Fumio",
                            "lastName": "Kishino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kishino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61138978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a9e0f134e439232fa88000f204df63e071ecd24",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new hand shape recognition method for man-machine interfaces using a pipeline image process. The basic strategy is to use simple but effective real time dynamical image processing to enhance the reliability of hand shape recognition since motion between frames is minimized. The algorithm for a noncontact-type hand shape recognizer has been developed for incorporation into a virtual reality environment.<<ETX>>"
            },
            "slug": "Real-time-hand-shape-recognition-using-pipe-line-Ishibuchi-Takemura",
            "title": {
                "fragments": [],
                "text": "Real time hand shape recognition using pipe-line image processor"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new hand shape recognition method for man-machine interfaces using a pipeline image process and the algorithm for a noncontact-type hand shape recognizer has been developed for incorporation into a virtual reality environment."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings IEEE International Workshop on Robot and Human Communication"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779846"
                        ],
                        "name": "H. Sakoe",
                        "slug": "H.-Sakoe",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Sakoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35805230"
                        ],
                        "name": "S. Chiba",
                        "slug": "S.-Chiba",
                        "structuredName": {
                            "firstName": "Seibi",
                            "lastName": "Chiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chiba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17900407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18f355d7ef4aa9f82bf5c00f84e46714efa5fd77",
            "isKey": false,
            "numCitedBy": 5373,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm."
            },
            "slug": "Dynamic-programming-algorithm-optimization-for-word-Sakoe-Chiba",
            "title": {
                "fragments": [],
                "text": "Dynamic programming algorithm optimization for spoken word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition, in which the warping function slope is restricted so as to improve discrimination between words in different categories."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145251724"
                        ],
                        "name": "G. Sperling",
                        "slug": "G.-Sperling",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Sperling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sperling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3239730"
                        ],
                        "name": "M. Landy",
                        "slug": "M.-Landy",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Landy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Landy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068024025"
                        ],
                        "name": "Yoav Cohen",
                        "slug": "Yoav-Cohen",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800603"
                        ],
                        "name": "M. Pavel",
                        "slug": "M.-Pavel",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Pavel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pavel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6590807,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5264b4f102784722406cf0778568347fe640391",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Intelligible-encoding-of-ASL-image-sequences-at-low-Sperling-Landy",
            "title": {
                "fragments": [],
                "text": "Intelligible encoding of ASL image sequences at extremely low information rates"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793645"
                        ],
                        "name": "H. Gish",
                        "slug": "H.-Gish",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Gish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18820742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3f073ac7513183a9bf3a76154dcd245748d2ab6",
            "isKey": false,
            "numCitedBy": 903,
            "numCiting": 154,
            "paperAbstract": {
                "fragments": [],
                "text": "Quantization, the process of approximating continuous-amplitude signals by digital (discrete-amplitude) signals, is an important aspect of data compression or coding, the field concerned with the reduction of the number of bits necessary to transmit or store analog data, subject to a distortion or fidelity criterion. The independent quantization of each signal value or parameter is termed scalar quantization, while the joint quantization of a block of parameters is termed block or vector quantization. This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization. Vector quantization is presented as a process of redundancy removal that makes effective use of four interrelated properties of vector parameters: linear dependency (correlation), nonlinear dependency, shape of the probability density function (pdf), and vector dimensionality itself. In contrast, scalar quantization can utilize effectively only linear dependency and pdf shape. The basic concepts are illustrated by means of simple examples and the theoretical limits of vector quantizer performance are reviewed, based on results from rate-distortion theory. Practical issues relating to quantizer design, implementation, and performance in actual applications are explored. While many of the methods presented are quite general and can be used for the coding of arbitrary signals, this paper focuses primarily on the coding of speech signals and parameters."
            },
            "slug": "Vector-quantization-in-speech-coding-Makhoul-Roukos",
            "title": {
                "fragments": [],
                "text": "Vector quantization in speech coding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization, and focuses primarily on the coding of speech signals and parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic Pmgramming"
            },
            "venue": {
                "fragments": [],
                "text": "\u201cView-based Recognition\u201d,"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic Programming optimization for spoken word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. ASSP,"
            },
            "year": 1980
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 12,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Space-time-gestures-Darrell-Pentland/1807058512ae2934b2be0b43f395d8583ef67303?sort=total-citations"
}