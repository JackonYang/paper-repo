{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3009522"
                        ],
                        "name": "M. Henrion",
                        "slug": "M.-Henrion",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Henrion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Henrion"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "I am indebted to Max Henrion for rekindling my interest in stochastic simulation and helping me regain confidence in its viability as a practical inferencing technique."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Recently, Henrion [8] applied Bundy's proposal to evidential reasoning tasks, using Bayesian networks as a formalism for representing causal relationships [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Henrion's scheme, called logic sampling, uses an uninstantiated Bayesian network as a scenario generator which, in each simulation run, assigns random values to all system variables."
                    },
                    "intents": []
                }
            ],
            "corpusId": 20172223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "262f353855b0e6cbeda26ba3b19fff5df1d7c1a2",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Propagating-uncertainty-in-bayesian-networks-by-Henrion",
            "title": {
                "fragments": [],
                "text": "Propagating uncertainty in bayesian networks by probabilistic logic sampling"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 93
                            }
                        ],
                        "text": "We shall illustrate the operation of the proposed scheme with a simple example borrowed from Spiegelhalter [11], originally given by Cooper [4]: Metastatic cancer is a possible cause of a brain tumor and is also an explanation for increased total serum calcium."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Illustrating the Proposed Scheme We shall illustrate the operation of the proposed scheme with a simple example borrowed from Spiegelhalter [11], originally given by Cooper [4]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41744030,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e9c168f6d744174efad3764e03522fe55be5ada",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-Reasoning-in-Predictive-Expert-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Probabilistic Reasoning in Predictive Expert Systems"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13723620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb0419bccc2244ed33c9c42341f342511262daa3",
            "isKey": false,
            "numCitedBy": 2148,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief networks are directed acyclic graphs in which the nodes represent propositions (or variables), the arcs signify direct dependencies between the linked propositions, and the strengths of these dependencies are quantified by conditional probabilities. A network of this sort can be used to represent the generic knowledge of a domain expert, and it turns into a computational architecture if the links are used not merely for storing factual knowledge but also for directing and activating the data flow in the computations which manipulate this knowledge. The first part of the paper deals with the task of fusing and propagating the impacts of new information through the networks in such a way that, when equilibrium is reached, each proposition will be assigned a measure of belief consistent with the axioms of probability theory. It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network. The second part of the paper deals with the problem of finding a tree-structured representation for a collection of probabilistically coupled propositions using auxiliary (dummy) variables, colloquially called \"hidden causes.\" It is shown that if such a tree-structured representation exists, then it is possible to uniquely uncover the topology of the tree by observing pairwise dependencies among the available propositions (i.e., the leaves of the tree). The entire tree structure, including the strengths of all internal relationships, can be reconstructed in time proportional to n log n, where n is the number of leaves."
            },
            "slug": "Fusion,-Propagation,-and-Structuring-in-Belief-Pearl",
            "title": {
                "fragments": [],
                "text": "Fusion, Propagation, and Structuring in Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network."
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685359"
                        ],
                        "name": "V. Barbosa",
                        "slug": "V.-Barbosa",
                        "structuredName": {
                            "firstName": "Valmir",
                            "lastName": "Barbosa",
                            "middleNames": [
                                "Carneiro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Barbosa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "Moreover, every processor is activated the same number of times in any such cycle [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "The problem of achieving maximum concurrency with edge reversal was analyzed by Barbosa [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 63
                            }
                        ],
                        "text": "Also appreciated are the discussions with Eli Gafni and Valmir Barbosa who, during the latter's oral examination, pointed out both the danger of concurrently activating neighboring variables and the remarkable features of the edge-reversal policy."
                    },
                    "intents": []
                }
            ],
            "corpusId": 116060672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4806ab0910e95b2d1730ee8c2c60b155f9d6ec2b",
            "isKey": true,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A collection of processes is considered, and each two of them are classified as either neighbors or nonneighbors, according to a symmetric neighborbhood relation. This system can be represented by an undirected graph G whose set of nodes is determined by the set of processes and set of edges by the neighborhood relation. Neighborhood is meant to stand for resource sharing of some type, and therefore we restrict ourselves to considering computations in which neighboring processes are precluded from being concurrently active. This dissertation contains studies on this type of system when the processes are scheduled for operation according to a scheme that we refer to as Scheduling by Edge Reversal. This scheme is derived from similar techniques previously employed in other contexts, and is based on the manipulation of acyclic orientations of G. \nWe present an analysis of Scheduling by Edge Reversal under synchronous and asynchronous models of computation. This analysis includes studies of the graph structures involved and definitions of concurrency measures. The chief concurrency measure that we analyze is a number depicting a property of G. This number is related to G's chromatic and multichromatic numbers, being in some cases distinct from both of them. We show, in addition, that the problem of maximizing concurrency is NP-complete. \nA second contribution is the definition and solution of a problem on the precedence graphs generated by general asynchronous computations. This is the problem of identifying an optimal global state, according to a criterion that we specify. We show that this problem can be solved through the use of Max-Flow techniques on variations of the precedence graph, despite the known NP-completeness of similar problems on precedence systems. The special case in which the precedence graph is generated by Scheduling by Edge Reversal admits efficient implementations. \nA combination of the previous two contributions yields a proposal to implement the Simulated Annealing method distributedly for some types of functions. The approach is applicable to approximating the solution to a number of NP-complete problems, as for example the problem of finding a maximum independent set of a graph."
            },
            "slug": "Concurrency-in-systems-with-neighborhood-systems,-Barbosa",
            "title": {
                "fragments": [],
                "text": "Concurrency in systems with neighborhood constraints (distributed systems, parallel processing, dining philosophers, simulated annealing)"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This dissertation contains studies on this type of system when the processes are scheduled for operation according to a scheme that is derived from similar techniques previously employed in other contexts, and is based on the manipulation of acyclic orientations of G."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732486"
                        ],
                        "name": "K. M. Chandy",
                        "slug": "K.-M.-Chandy",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Chandy",
                            "middleNames": [
                                "Mani"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M. Chandy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771370"
                        ],
                        "name": "J. Misra",
                        "slug": "J.-Misra",
                        "structuredName": {
                            "firstName": "Jayadev",
                            "lastName": "Misra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Misra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 175
                            }
                        ],
                        "text": "This problem is a version of the \"dining philosophers\" dilemma originally posed by Dijkstra [5] and later solved independently by Gafni and Bertsekas [6] and Chandy and Misra [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5922362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e9b24417378323edfa0b3211126c847067b66ba",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of resolving conflicts between processes in distributed systems is of practical importance. A conflict between a set of processes must be resolved in favor of some (usually one) process and against the others: a favored process must have some property that distinguishes it from others. To guarantee fairness, the distinguishing property must be such that the process selected for favorable treatment is not always the same. A distributed implementation of an acyclic precedence graph, in which the depth of a process (the longest chain of predecessors) is a distinguishing property, is presented. A simple conflict resolution rule coupled with the acyclic graph ensures fair resolution of all conflicts. To make the problem concrete, two paradigms are presented: the well-known distributed dining philosophers problem and a generalization of it, the distributed drinking philosophers problem."
            },
            "slug": "The-drinking-philosophers-problem-Chandy-Misra",
            "title": {
                "fragments": [],
                "text": "The drinking philosophers problem"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Two paradigms are presented: the well-known distributed dining philosophers problem and a generalization of it, the distributed drinking philosophers problem, in which the depth of a process is a distinguishing property and a distributed implementation of an acyclic precedence graph is presented."
            },
            "venue": {
                "fragments": [],
                "text": "TOPL"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 133
                            }
                        ],
                        "text": "We shall illustrate the operation of the proposed scheme with a simple example borrowed from Spiegelhalter [11], originally given by Cooper [4]: Metastatic cancer is a possible cause of a brain tumor and is also an explanation for increased total serum calcium."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "Illustrating the Proposed Scheme We shall illustrate the operation of the proposed scheme with a simple example borrowed from Spiegelhalter [11], originally given by Cooper [4]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58660085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "373b1817afebdced6119cb6564a6be187b4823a9",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In order to address some existing problems in computer-aided medical decision making, a computer program called NESTOR has been developed to aid physicians in determining the most likely diagnostic hypothesis to account for a set of patient findings. The domain of hypercalcemic disorders is used to test solution methods that should be applicable to other medical areas. A key design philosophy underlying NESTOR is that the physicians should have control of the computer interaction to determine what is done and when. In order to provide such controllable, interactive aid, specific technical tasks to be addressed. The unifying philosophy in addressing them is the use of knowledge-based methods within a formal probability theory framework. A user interface module gives the physician control over when and how these tasks are used to aid in diagnosing the cause of a patient's condition. This dissertation presents the problems that are addressed by each of the three tasks, and the details of the methods used to address them. In addition, the results of an evaluation of the hypothesis scoring and search techniques are presented and discussed. Additional keywords: artificial intelligence; expert systems; medical applications; computer aided diagnosis; medical computer applications."
            },
            "slug": "NESTOR:-A-Computer-Based-Medical-Diagnostic-Aid-and-Cooper",
            "title": {
                "fragments": [],
                "text": "NESTOR: A Computer-Based Medical Diagnostic Aid That Integrates Causal and Probabilistic Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This dissertation presents the problems that are addressed by each of the three tasks of NESTOR, the use of knowledge-based methods within a formal probability theory framework, and the details of the methods used to address them."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18711,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1953280"
                        ],
                        "name": "E. Gafni",
                        "slug": "E.-Gafni",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Gafni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gafni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786249"
                        ],
                        "name": "D. Bertsekas",
                        "slug": "D.-Bertsekas",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Bertsekas",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bertsekas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "This problem is a version of the \"dining philosophers\" dilemma originally posed by Dijkstra [5] and later solved independently by Gafni and Bertsekas [6] and Chandy and Misra [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9173265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c779f855137fe3e3525ac5d8cc7566980c0048df",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of maintaining communication between the nodes of a data network and a central station in the presence of frequent topological changes as, for example, in mobile packet radio networks. We argue that flooding schemes have significant drawbacks for such networks, and propose a general class of distributed algorithms for establishing new loop-free routes to the station for any node left without a route due to changes in the network topology. By virtue of built-in redundancy, the algorithms are typically activated very infrequently and, even when they are, they do not involve any communication within the portion of the network that has not been materially affected by a topological change."
            },
            "slug": "Distributed-Algorithms-for-Generating-Loop-Free-in-Gafni-Bertsekas",
            "title": {
                "fragments": [],
                "text": "Distributed Algorithms for Generating Loop-Free Routes in Networks with Frequently Changing Topology"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that flooding schemes have significant drawbacks for such networks, and a general class of distributed algorithms for establishing new loop-free routes to the station for any node left without a route due to changes in the network topology is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745619"
                        ],
                        "name": "S. German",
                        "slug": "S.-German",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "German",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. German"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121982077"
                        ],
                        "name": "D. German",
                        "slug": "D.-German",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "German",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. German"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Geman and Geman [7] combined probabilistic sampling with simulated annealing to restore noisy images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "The \"nondeprivation\" feature is important because it constitutes a necessary condition for the convergence of the entire process [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "[9] and Geman and Geman [7] in that it takes as input both the structure of a causal model provided by a domain expert and the forward conditional probabilities reflecting the expert's direct experience; thus, the simulation is conducted at a conceptually meaningful level of description."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 90
                            }
                        ],
                        "text": "This scheme offers an advantage over the Markov-field approaches of Hinton et al. [9] and Geman and Geman [7] in that it takes as input both the structure of a causal model provided by a domain expert and the forward conditional probabilities reflecting the expert's direct experience; thus, the simulation is conducted at a conceptually meaningful level of description."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59916588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1f9fcf2ccc313a5018e536e76e75d1f7992937b",
            "isKey": true,
            "numCitedBy": 2214,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-relaxation,-Gibbs-distributions,-and-the-German-German",
            "title": {
                "fragments": [],
                "text": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] as one of the tasks executable on the Boltzmann machine."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] and Geman and Geman [7] in that it takes as input both the structure of a causal model provided by a domain expert and the forward conditional probabilities reflecting the expert's direct experience; thus, the simulation is conducted at a conceptually meaningful level of description."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boltzman machines: Constraint satisfaction networks that learn"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rept. CMU-CS-84-119,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "This problem is a version of the \"dining philosophers\" dilemma originally posed by Dijkstra [5] and later solved independently by Gafni and Bertsekas [6] and Chandy and Misra [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical ordering of sequential processes, in: C.A.R. Hoare and R.H. Perrott (Eds.), Operating Systems Techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Received September"
            },
            "venue": {
                "fragments": [],
                "text": "Received September"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The drinking philosophers problem , ACM Trans . Program"
            },
            "venue": {
                "fragments": [],
                "text": "Lang . Syst . G"
            },
            "year": 1984
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 13,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Evidential-Reasoning-Using-Stochastic-Simulation-of-Pearl/5669148e6026516720940558086def2ab92b04e2?sort=total-citations"
}