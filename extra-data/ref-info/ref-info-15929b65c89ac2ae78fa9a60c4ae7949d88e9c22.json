{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "However, when image matching is feasible, the use of drop out methods [2] is applicable."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38916969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c41d71ca5ae222ab72d16f254edb5fbd4e2de93",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in intelligent character recognition are enabling us to address many challenging problems in document image analysis. One of them is intelligent form analysis. This paper describes a generic system for form dropout when the filled-in characters or symbols are either touching or crossing the form frames. We propose a method to separate these characters from form frames whose locations are unknown. Since some of the character strokes are either touching or crossing the form frames, we need to address the following three issues: 1) localization of form frames; 2) separation of characters and form frames; and 3) reconstruction of broken strokes introduced during separation. The form frame is automatically located by finding long straight lines based on the block adjacency graph. Form frame separation and character reconstruction are implemented by means of this graph. The proposed system includes form structure learning and form dropout. First, a form structure-based template is automatically generated from a blank form which includes form frames, preprinted data areas and skew angle. With this form template, our system can then extract both handwritten and machine-typed filled-in data. Experimental results on three different types of forms show the performance of our system. Further, the proposed method is robust to noise and skew that is introduced during scanning."
            },
            "slug": "A-Generic-System-for-Form-Dropout-Yu-Jain",
            "title": {
                "fragments": [],
                "text": "A Generic System for Form Dropout"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A generic system for form dropout when the filled-in characters or symbols are either touching or crossing the form frames and a method to separate these characters from form frames whose locations are unknown is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1957622"
                        ],
                        "name": "H. Sako",
                        "slug": "H.-Sako",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Sako",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sako"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2386732"
                        ],
                        "name": "M. Seki",
                        "slug": "M.-Seki",
                        "structuredName": {
                            "firstName": "Minenobu",
                            "lastName": "Seki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2353717"
                        ],
                        "name": "N. Furukawa",
                        "slug": "N.-Furukawa",
                        "structuredName": {
                            "firstName": "Naohiro",
                            "lastName": "Furukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Furukawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2440116"
                        ],
                        "name": "H. Ikeda",
                        "slug": "H.-Ikeda",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Ikeda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ikeda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32811532"
                        ],
                        "name": "Atsuhiro Imaizumi",
                        "slug": "Atsuhiro-Imaizumi",
                        "structuredName": {
                            "firstName": "Atsuhiro",
                            "lastName": "Imaizumi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Atsuhiro Imaizumi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 92
                            }
                        ],
                        "text": "Others are based on the location of the field with respect to instruction fields (keywords) [6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13457314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bfe4e6e91f8a21dc4227b55c77b43f2f6b8f264",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Form reading technology based on form-typeidentification and form-data recognition is proposed. Thistechnology can solve difficulties in variety for readingdifferent items on fairly large number of different types offorms. The form-type identification consists of two parts:(i) extraction of targets such as important keywords in aform by matching between recogised characters and wordstrings in a keyword dictionary, and (ii) analysis ofpositional or semantic relationship between the targets byconstellation matching between these targets and wordlocation information in the keyword dictionary. The formdatarecognition consists of two parts: (i) extraction of aregion of interest (ROI) contained a character string of theitem by using a layout knowledge of the very form-type,and (ii) character string recognition of the item by usingthe linguistic constraint which can be obtained from acontent knowledge of the form-type. A experiment using642 sample forms with 107 different types in totalconfirmed that the form-type identification method cancorrectly identify 97% of 642 form samples at a rejectionrate 3%. Another experiment confirmed that the form-data recognition method can correctly read 95% of thenumber of items on the form samples."
            },
            "slug": "Form-reading-based-on-form-type-identification-and-Sako-Seki",
            "title": {
                "fragments": [],
                "text": "Form reading based on form-type identification and form-data recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Form reading technology based on form-type identification and form- data recognition and character string recognition is proposed, which confirmed that the form-data recognition method can correctly read 95% of thenumber of items on the form samples."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34878566"
                        ],
                        "name": "H. Fujisawa",
                        "slug": "H.-Fujisawa",
                        "structuredName": {
                            "firstName": "Hiromichi",
                            "lastName": "Fujisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fujisawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737939"
                        ],
                        "name": "Y. Nakano",
                        "slug": "Y.-Nakano",
                        "structuredName": {
                            "firstName": "Yasuaki",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nakano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6572034"
                        ],
                        "name": "K. Kurino",
                        "slug": "K.-Kurino",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kurino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kurino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 92
                            }
                        ],
                        "text": "Others are based on the location of the field with respect to instruction fields (keywords) [6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62753568,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "118c2465b0f00736c743883be62a45eca580cf8c",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A pattern-oriented segmentation method for optical character recognition that leads to document structure analysis is presented. As a first example, segmentation of handwritten numerals that touch are treated. Connected pattern components are extracted, and spatial interrelations between components are measured and grouped into meaningful character patterns. Stroke shapes are analyzed and a method of finding the touching positions that separates about 95% of connected numerals correctly is described. Ambiguities are handled by multiple hypotheses and verification by recognition. An extended form of pattern-oriented segmentation, tabular form recognition, is considered. Images of tabular forms are analyzed, and frames in the tabular structure are extracted. By identifying semantic relationships between label frames and data frames, information on the form can be properly recognized. >"
            },
            "slug": "Segmentation-methods-for-character-recognition:-to-Fujisawa-Nakano",
            "title": {
                "fragments": [],
                "text": "Segmentation methods for character recognition: from segmentation to document structure analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A pattern- oriented segmentation method for optical character recognition that leads to document structure analysis is presented, and an extended form of pattern-oriented segmentation, tabular form recognition, is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150346589"
                        ],
                        "name": "Y. Belaid",
                        "slug": "Y.-Belaid",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Belaid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Belaid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2372756"
                        ],
                        "name": "A. Belaid",
                        "slug": "A.-Belaid",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Belaid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Belaid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1835956"
                        ],
                        "name": "E. Turolla",
                        "slug": "E.-Turolla",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Turolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Turolla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 56
                            }
                        ],
                        "text": "Some of them are based on horizontal and vertical lines [3,4,5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61246191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "790ab04473896bc8a2f810646d63a25c8952c2cf",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Cell searching is an important step in form analysis. Information in a form is contained mainly inside its cells. The goal of this paper is to describe a robust method to locate the items whose boundaries are lines without using any a priori information about the form. Our method is based on the detection of lines by Hough transform and on searching of cycles, corresponding to cell location, in a graph. Thanks to Hough transform, our approach is robust, skew independent and can be applied to several kind of lines such as continuous, dashed, doubled, etc."
            },
            "slug": "Item-searching-in-forms:-Application-to-French-tax-Belaid-Belaid",
            "title": {
                "fragments": [],
                "text": "Item searching in forms: Application to French tax form"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper describes a robust method to locate the items whose boundaries are lines without using any a priori information about the form, based on the detection of lines by Hough transform and on searching of cycles, corresponding to cell location, in a graph."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1927318"
                        ],
                        "name": "Y. Navon",
                        "slug": "Y.-Navon",
                        "structuredName": {
                            "firstName": "Yaakov",
                            "lastName": "Navon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Navon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 117
                            }
                        ],
                        "text": "Since most of the interesting information is in the form of text and graphics, we use dedicated binarization methods [9,10] to create proper"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5314730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ed99f06d4c1f9c14766cdb4b3a1276378e2a317",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We developed a binarization approach to handle a large variety of images, from scanned flatbed images to images acquired by mobile phone cameras. The binarization is targeted at creating layers of binary images for processing by OCR engines. The layers are classified spatially and by intensity and color. First textual pixels are classified by a text operator. The text kernel is then segmented by intensity/color levels and layout analysis techniques to create regions of similar text. Finally, adaptive binarization is applied to each region to obtain superior binary images. Our experimental results show the advantages of our method over local binarization methods."
            },
            "slug": "Layer-based-binarization-for-textual-images-Navon",
            "title": {
                "fragments": [],
                "text": "Layer-based binarization for textual images"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This work developed a binarization approach to handle a large variety of images, from scanned flatbed images to images acquired by mobile phone cameras, and shows the advantages of the method over localbinarization methods."
            },
            "venue": {
                "fragments": [],
                "text": "2008 19th International Conference on Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143961578"
                        ],
                        "name": "Kuo-Chin Fan",
                        "slug": "Kuo-Chin-Fan",
                        "structuredName": {
                            "firstName": "Kuo-Chin",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kuo-Chin Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47235730"
                        ],
                        "name": "Mei-Lin Chang",
                        "slug": "Mei-Lin-Chang",
                        "structuredName": {
                            "firstName": "Mei-Lin",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mei-Lin Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31023244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b481dead5e727026824909291dab2d82cc398a2a",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel form recognition method by analyzing the line structure embedded in an input form document. First, all vertical and horizontal lines embedded in the form image are extracted. Experimental results demonstrate the feasibility and efficiency of our proposed method in recognizing form documents."
            },
            "slug": "Form-document-identification-using-line-structure-Fan-Chang",
            "title": {
                "fragments": [],
                "text": "Form document identification using line structure based features"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Experimental results demonstrate the feasibility and efficiency of the proposed method in recognizing form documents, and the line structure embedded in an input form document is analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 56
                            }
                        ],
                        "text": "Some of them are based on horizontal and vertical lines [3,4,5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Form Understanding System Based on Form Description Language"
            },
            "venue": {
                "fragments": [],
                "text": "Int. Conf. on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 117
                            }
                        ],
                        "text": "Since most of the interesting information is in the form of text and graphics, we use dedicated binarization methods [9,10] to create proper"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Method for OCR Oriented Image Binarization"
            },
            "venue": {
                "fragments": [],
                "text": "European Patent No. 98480038.3-2201,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Methods based on lexical information only, such as in [8], first require performing optical character recognition (OCR) on the entire image (the runtime issue) and expect to receive fixed templates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A System for Exploiting Syntactic and Semantic Knowledge in Automatic Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IAPR Workshop on Doc. Analysis Systems"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 9,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Generic-Form-Processing-Approach-for-Large-Navon-Barkan/15929b65c89ac2ae78fa9a60c4ae7949d88e9c22?sort=total-citations"
}