{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7593950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ab0de951cc9cdf16887b1f841f8da6affc9c0de",
            "isKey": false,
            "numCitedBy": 647,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply Convolutional Networks (ConvNets) to the task of traffic sign classification as part of the GTSRB competition. ConvNets are biologically-inspired multi-stage architectures that automatically learn hierarchies of invariant features. While many popular vision approaches use hand-crafted features such as HOG or SIFT, ConvNets learn features at every level from data that are tuned to the task at hand. The traditional ConvNet architecture was modified by feeding 1st stage features in addition to 2nd stage features to the classifier. The system yielded the 2nd-best accuracy of 98.97% during phase I of the competition (the best entry obtained 98.98%), above the human performance of 98.81%, using 32\u00d732 color input images. Experiments conducted after phase 1 produced a new record of 99.17% by increasing the network capacity, and by using greyscale images instead of color. Interestingly, random features still yielded competitive results (97.33%)."
            },
            "slug": "Traffic-sign-recognition-with-multi-scale-Networks-Sermanet-LeCun",
            "title": {
                "fragments": [],
                "text": "Traffic sign recognition with multi-scale Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work applies Convolutional Networks (ConvNets) to the task of traffic sign classification as part of the GTSRB competition, and yields the 2nd-best accuracy above the human performance."
            },
            "venue": {
                "fragments": [],
                "text": "The 2011 International Joint Conference on Neural Networks"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748488"
                        ],
                        "name": "F. Moutarde",
                        "slug": "F.-Moutarde",
                        "structuredName": {
                            "firstName": "Fabien",
                            "lastName": "Moutarde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Moutarde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695979"
                        ],
                        "name": "A. Bargeton",
                        "slug": "A.-Bargeton",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Bargeton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bargeton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2396705"
                        ],
                        "name": "A. Herbin",
                        "slug": "A.-Herbin",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Herbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Herbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3294314"
                        ],
                        "name": "L. Chanussot",
                        "slug": "L.-Chanussot",
                        "structuredName": {
                            "firstName": "Lowik",
                            "lastName": "Chanussot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chanussot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "speed limit signs based on single digit recognition [2] using a neural network."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7417898,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5b1fcb0cb6db6f611e24ae6aaf1aea8e0217fa28",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new modular traffic signs recognition system, successfully applied to both American and European speed limit signs. Our sign detection step is based only on shape-detection (rectangles or circles). This enables it to work on grayscale images, contrary to most European competitors, which eases robustness to illumination conditions (notably night operation). Speed sign candidates are classified (or rejected) by segmenting potential digits inside them (which is rather original and has several advantages), and then applying a neural digit recognition. The global detection rate is ~90% for both (standard) U.S. and E.U. speed signs, with a misclassification rate 150 minutes of video. The system processes in real-time ~20 frames/s on a standard high-end laptop."
            },
            "slug": "Modular-Traffic-Sign-Recognition-applied-to-visual-Moutarde-Bargeton",
            "title": {
                "fragments": [],
                "text": "Modular Traffic Sign Recognition applied to on-vehicle real-time visual detection of American and European speed limit signs"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new modular traffic signs recognition system, successfully applied to both American and European speed limit signs, based only on shape-detection, which enables it to work on grayscale images, contrary to most European competitors, which eases robustness to illumination conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688865"
                        ],
                        "name": "A. Broggi",
                        "slug": "A.-Broggi",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Broggi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Broggi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32432440"
                        ],
                        "name": "Pietro Cerri",
                        "slug": "Pietro-Cerri",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Cerri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pietro Cerri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2187833"
                        ],
                        "name": "P. Medici",
                        "slug": "P.-Medici",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Medici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Medici"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136631"
                        ],
                        "name": "P. Porta",
                        "slug": "P.-Porta",
                        "structuredName": {
                            "firstName": "Pier",
                            "lastName": "Porta",
                            "middleNames": [
                                "Paolo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Porta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9428531"
                        ],
                        "name": "G. Ghisio",
                        "slug": "G.-Ghisio",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Ghisio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ghisio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] use several neural networks to classify different traffic signs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16032526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dd776a4ff82b05c0b53d569d2acaa5b3f1c0a2c",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a road signs detection and classification system based on a three-step algorithm composed of color segmentation, shape recognition, and a neural network. The final goal of this algorithm is to detect and classify almost all road signs present along Italian roads. Color segmentation was suggested by the aim to achieve real time execution, since color-based segmentation is faster than the one based on shape. In order to save computational time, only the RGB color space, directly supplied by the chosen camera, or color spaces that can be obtained with linear transformations, are considered. Two different methods are used for shape detection, one is based on pattern matching with simple models and the other one is based on edge detection and geometrical cues. The complete set of signs taken in account has been divided in several categories according to their shape and color. Finally for each road signs set a neural network is built and trained."
            },
            "slug": "Real-Time-Road-Signs-Recognition-Broggi-Cerri",
            "title": {
                "fragments": [],
                "text": "Real Time Road Signs Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This paper presents a road signs detection and classification system based on a three-step algorithm composed of color segmentation, shape recognition, and a neural network to achieve real time execution."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Intelligent Vehicles Symposium"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "\u201d More details concerning this approach can be found in [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1983697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd7f8b53e6802787179a961e766760cbbe2d5011",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the approach that won the preliminary phase of the German traffic sign recognition benchmark with a better-than-human recognition rate of 98.98%.We obtain an even better recognition rate of 99.15% by further training the nets. Our fast, fully parameterizable GPU implementation of a Convolutional Neural Network does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. A CNN/MLP committee further boosts recognition performance."
            },
            "slug": "A-committee-of-neural-networks-for-traffic-sign-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "A committee of neural networks for traffic sign classification"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This work describes the approach that won the preliminary phase of the German traffic sign recognition benchmark with a better-than-human recognition rate, and obtains an even better recognition rate by further training the nets."
            },
            "venue": {
                "fragments": [],
                "text": "The 2011 International Joint Conference on Neural Networks"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398470117"
                        ],
                        "name": "S. Maldonado-Basc\u00f3n",
                        "slug": "S.-Maldonado-Basc\u00f3n",
                        "structuredName": {
                            "firstName": "Saturnino",
                            "lastName": "Maldonado-Basc\u00f3n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maldonado-Basc\u00f3n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402975934"
                        ],
                        "name": "F. J. Acevedo-Rodr\u00edguez",
                        "slug": "F.-J.-Acevedo-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Acevedo-Rodr\u00edguez",
                            "middleNames": [
                                "Javier"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. J. Acevedo-Rodr\u00edguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398957464"
                        ],
                        "name": "S. Lafuente-Arroyo",
                        "slug": "S.-Lafuente-Arroyo",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Lafuente-Arroyo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lafuente-Arroyo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397896370"
                        ],
                        "name": "A. Fern\u00e1ndez-Caballero",
                        "slug": "A.-Fern\u00e1ndez-Caballero",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Fern\u00e1ndez-Caballero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fern\u00e1ndez-Caballero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398470120"
                        ],
                        "name": "F. L\u00f3pez-Ferreras",
                        "slug": "F.-L\u00f3pez-Ferreras",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "L\u00f3pez-Ferreras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. L\u00f3pez-Ferreras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [6], a classification performance of 95."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10377184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ee8bb9a438a43a38ef0a2c7cc3b0383c555e27f",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-optimization-on-pictogram-identification-for-the-Maldonado-Basc\u00f3n-Acevedo-Rodr\u00edguez",
            "title": {
                "fragments": [],
                "text": "An optimization on pictogram identification for the road-sign recognition task using SVMs"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149601"
                        ],
                        "name": "A. Muhammad",
                        "slug": "A.-Muhammad",
                        "structuredName": {
                            "firstName": "Azam",
                            "lastName": "Muhammad",
                            "middleNames": [
                                "Sheikh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Muhammad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47454543"
                        ],
                        "name": "N. Lavesson",
                        "slug": "N.-Lavesson",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Lavesson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lavesson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2731968"
                        ],
                        "name": "P. Davidsson",
                        "slug": "P.-Davidsson",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Davidsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Davidsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052887309"
                        ],
                        "name": "M. Nilsson",
                        "slug": "M.-Nilsson",
                        "structuredName": {
                            "firstName": "Mikael",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "Various approaches are compared on a dataset containing 1,300 preprocessed examples from 6 classes (5 speed limits and 1 noise class) in [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5993189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca3c319f75e1a8823c270ec285af828335945f80",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Traffic Sign Recognition is a widely studied problem and its dynamic nature calls for the application of a broad range of preprocessing, segmentation, and recognition techniques but few databases are available for evaluation. We have produced a database consisting of 1,300 images captured by a video camera. On this database we have conducted a systematic experimental study. We used four different preprocessing techniques and designed a generic speed sign segmentation algorithm. Then we selected a range of contemporary speed sign classification algorithms using shape based segmented binary images for training and evaluated their results using four metrics, including accuracy and processing speed. The results indicate that Naive Bayes and Random Forest seem particularly well suited for this recognition task. Moreover, we show that two specific preprocessing techniques appear to provide a better basis for concept learning than the others."
            },
            "slug": "Analysis-of-Speed-Sign-Classification-Algorithms-of-Muhammad-Lavesson",
            "title": {
                "fragments": [],
                "text": "Analysis of Speed Sign Classification Algorithms Using Shape Based Segmentation of Binary Images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The results indicate that Naive Bayes and Random Forest seem particularly well suited for this recognition task and it is shown that two specific preprocessing techniques appear to provide a better basis for concept learning than the others."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "96619180"
                        ],
                        "name": "C. Bahlmann",
                        "slug": "C.-Bahlmann",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Bahlmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bahlmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102597462"
                        ],
                        "name": "Y. Zhu",
                        "slug": "Y.-Zhu",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1914656"
                        ],
                        "name": "M. Pellkofer",
                        "slug": "M.-Pellkofer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Pellkofer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pellkofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056672793"
                        ],
                        "name": "T. Koehler",
                        "slug": "T.-Koehler",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Koehler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Koehler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [1], an integrated system for speed limit detection, tracking, and recognition is presented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1366876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eedb1d70d3fd4c0ce5c9b6512a3bfe65e49df055",
            "isKey": false,
            "numCitedBy": 429,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computer vision based system for real-time robust traffic sign detection, tracking, and recognition. Such a framework is of major interest for driver assistance in an intelligent automotive cockpit environment. The proposed approach consists of two components. First, signs are detected using a set of Haar wavelet features obtained from AdaBoost training. Compared to previously published approaches, our solution offers a generic, joint modeling of color and shape information without the need of tuning free parameters. Once detected, objects are efficiently tracked within a temporal information propagation framework. Second, classification is performed using Bayesian generative modeling. Making use of the tracking information, hypotheses are fused over multiple frames. Experiments show high detection and recognition accuracy and a frame rate of approximately 10 frames per second on a standard PC."
            },
            "slug": "A-system-for-traffic-sign-detection,-tracking,-and-Bahlmann-Zhu",
            "title": {
                "fragments": [],
                "text": "A system for traffic sign detection, tracking, and recognition using color, shape, and motion information"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper describes a computer vision based system for real-time robust traffic sign detection, tracking, and recognition that offers a generic, joint modeling of color and shape information without the need of tuning free parameters."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Proceedings. Intelligent Vehicles Symposium, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Convolutional Neural Networks: \u201dConvolutional Networks (ConvNets) [16] are a biologically-inspired architecture that can learn invariant features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35279,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1884105"
                        ],
                        "name": "Rafael Uetz",
                        "slug": "Rafael-Uetz",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Uetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafael Uetz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "With respect to other implementations of similar neural network architectures on GPUs [11], [12] that are hard-coded to satisfy the hardware constraints of the GPUs, our implementation [13] is flexible and fully on-line (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6779371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fa5450f1c0795527939cfef5fbe3912c4dab3ab",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Robust recognition of arbitrary object classes in natural visual scenes is an aspiring goal with numerous practical applications, for instance, in the area of autonomous robotics and autonomous vehicles. One obstacle on the way towards human-like recognition performance is the limitation of computational power, restricting the size of the training and testing dataset as well as the complexity of the object recognition system. In this work, we present a hierarchical, locally-connected neural network model that is well-suited for large-scale, high-performance object recognition. By using the NVIDIA CUDA framework, we create a massively parallel implementation of the model which is executed on a state-of-the-art graphics card. This implementation is up to 82 times faster than a single-core CPU version of the system. This significant gain in computational performance allows us to evaluate the model on a very large, realistic, and challenging set of natural images which we extracted from the LabelMe dataset. To compare our model to other approaches, we also evaluate the recognition performance using the well-known MNIST and NORB datasets, achieving a testing error rate of 0.76% and 2.87 %, respectively."
            },
            "slug": "Large-scale-object-recognition-with-hierarchical-Uetz-Behnke",
            "title": {
                "fragments": [],
                "text": "Large-scale object recognition with CUDA-accelerated hierarchical neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents a hierarchical, locally-connected neural network model that is well-suited for large-scale, high-performance object recognition and creates a massively parallel implementation of the model which is executed on a state-of-the-art graphics card."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Intelligent Computing and Intelligent Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "a) IK-SVM based method: \u201dThe method employs a fast Intersection Kernel Support Vector Machine (IK-SVM) [19] over concatenated HOG features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "We used computed pyramidal HOG features over resized 28\u00d728 pixels patches using the same settings used in [19] for handwritten digits classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 148
                            }
                        ],
                        "text": "3) Team VISICS: Team VISICS consists of Radu Timofte and Luc van Gool from ESAT-PSI-VISICS/IBBT at the Katholieke Universiteit Leuven, Belgium7.\na) IK-SVM based method: \u201dThe method employs a fast Intersection Kernel Support Vector Machine (IK-SVM) [19] over concatenated HOG features."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61625749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36a5417dec6460afaf1b0394dff088b2a928970f",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the use of certain image features, blockwise histograms of local orientations, used in many current object recognition algorithms, for the task of handwritten digit recognition. Existing approaches find that polynomial kernel SVMs trained on raw pixels achieve state of the art performance. However such kernel SVM approaches are impractical as they have a huge complexity at runtime. We demonstrate that with improved features a low complexity classifier, in particular an additive-kernel SVM, can achieve state of the art performance. Our approach achieves an error of 0.79% on the MNIST dataset and 3.4% error on the USPS dataset, while running at speeds comparable to the fastest algorithms on these datasets which are based on multilayer neural networks and are significantly faster and easier to train."
            },
            "slug": "Fast-and-Accurate-Digit-Classification-Maji-Malik",
            "title": {
                "fragments": [],
                "text": "Fast and Accurate Digit Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This work explores the use of certain image features, blockwise histograms of local orientations, used in many current object recognition algorithms, for the task of handwritten digit recognition and demonstrates that with improved features a low complexity classifier, in particular an additive-kernel SVM, can achieve state of the art performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31778202"
                        ],
                        "name": "C. G. Keller",
                        "slug": "C.-G.-Keller",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Keller",
                            "middleNames": [
                                "Gustav"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Keller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704594"
                        ],
                        "name": "C. Sprunk",
                        "slug": "C.-Sprunk",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Sprunk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sprunk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "96619180"
                        ],
                        "name": "C. Bahlmann",
                        "slug": "C.-Bahlmann",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Bahlmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bahlmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4837721"
                        ],
                        "name": "J. Giebel",
                        "slug": "J.-Giebel",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Giebel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Giebel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800882"
                        ],
                        "name": "G. Baratoff",
                        "slug": "G.-Baratoff",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Baratoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Baratoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [4], a number-based speed limit classifier is trained on 2,880 images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15752127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e34083ee15dc10da522b17cd2d6a7bb5996c517",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a camera-based system for detection, tracking, and classification of U.S. speed signs is presented. The implemented application uses multiple connected stages and iteratively reduces the number of pixels to process for recognition. Possible sign locations are detected using a fast, shape-based interest operator. Remaining objects other than speed signs are discarded using a classifier similar to the Viola-Jones detector. Classification results from tracked candidates are utilized to improve recognition accuracy. On a standard PC the system reached a detection speed of 27 fps with an accuracy of 98.8%. Including classification, speed sign recognition rates of 96.3% were achieved with a frame rate of approximately 11 fps and one false alarm every 42 s."
            },
            "slug": "Real-time-recognition-of-U.S.-speed-signs-Keller-Sprunk",
            "title": {
                "fragments": [],
                "text": "Real-time recognition of U.S. speed signs"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A camera-based system for detection, tracking, and classification of U.S. speed signs using multiple connected stages and iteratively reduces the number of pixels to process for recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Intelligent Vehicles Symposium"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "The following features are included: 1) HOG features: Three sets of differently configured HOG features (histograms of oriented gradients) [9] are provided."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29266,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070963479"
                        ],
                        "name": "Dominik Scherer",
                        "slug": "Dominik-Scherer",
                        "structuredName": {
                            "firstName": "Dominik",
                            "lastName": "Scherer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominik Scherer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113785713"
                        ],
                        "name": "Andreas C. M\u00fcller",
                        "slug": "Andreas-C.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "M\u00fcller",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas C. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "CNNs with a maxpooling layer consistently outperform conventional nets [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18388506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33",
            "isKey": false,
            "numCitedBy": 1285,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A common practice to gain invariant features in object recognition models is to aggregate multiple low-level features over a small neighborhood. However, the differences between those models makes a comparison of the properties of different aggregation functions hard. Our aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks. Empirical results show that a maximum pooling operation significantly outperforms subsampling operations. Despite their shift-invariant properties, overlapping pooling windows are no significant improvement over nonoverlapping pooling windows. By applying this knowledge, we achieve state-of-the-art error rates of 4.57% on the NORB normalized-uniform dataset and 5.6% on the NORB jittered-cluttered dataset."
            },
            "slug": "Evaluation-of-Pooling-Operations-in-Convolutional-Scherer-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks, and empirical results show that a maximum pooling operation significantly outperforms subsampling operations."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809791"
                        ],
                        "name": "K. Chellapilla",
                        "slug": "K.-Chellapilla",
                        "structuredName": {
                            "firstName": "Kumar",
                            "lastName": "Chellapilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chellapilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2568084"
                        ],
                        "name": "Sidd Puri",
                        "slug": "Sidd-Puri",
                        "structuredName": {
                            "firstName": "Sidd",
                            "lastName": "Puri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sidd Puri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "With respect to other implementations of similar neural network architectures on GPUs [11], [12] that are hard-coded to satisfy the hardware constraints of the GPUs, our implementation [13] is flexible and fully on-line (i.e. weight updates after each image)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "With respect to other implementations of similar neural network architectures on GPUs [11], [12] that are hard-coded to satisfy the hardware constraints of the GPUs, our implementation [13] is flexible and fully on-line (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14936779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2cc157afda51873c30b195fff56e917b9c06b853",
            "isKey": false,
            "numCitedBy": 416,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks (CNNs) are well known for producing state-of-the-art recognizers for document processing [1]. However, they can be difficult to implement and are usually slower than traditional multi-layer perceptrons (MLPs). We present three novel approaches to speeding up CNNs: a) unrolling convolution, b) using BLAS (basic linear algebra subroutines), and c) using GPUs (graphic processing units). Unrolled convolution converts the processing in each convolutional layer (both forward-propagation and back-propagation) into a matrix-matrix product. The matrix-matrix product representation of CNNs makes their implementation as easy as MLPs. BLAS is used to efficiently compute matrix products on the CPU. We also present a pixel shader based GPU implementation of CNNs. Results on character recognition problems indicate that unrolled convolution with BLAS produces a dramatic 2.4X\u22123.0X speedup. The GPU implementation is even faster and produces a 3.1X\u22124.1X speedup."
            },
            "slug": "High-Performance-Convolutional-Neural-Networks-for-Chellapilla-Puri",
            "title": {
                "fragments": [],
                "text": "High Performance Convolutional Neural Networks for Document Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Three novel approaches to speeding up CNNs are presented: a) unrolling convolution, b) using BLAS (basic linear algebra subroutines), and c) using GPUs (graphic processing units)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40984420"
                        ],
                        "name": "A. Yang",
                        "slug": "A.-Yang",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Yang",
                            "middleNames": [
                                "Yuqing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144797536"
                        ],
                        "name": "S. Sastry",
                        "slug": "S.-Sastry",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sastry",
                            "middleNames": [
                                "Shankar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sastry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701028"
                        ],
                        "name": "Arvind Ganesh",
                        "slug": "Arvind-Ganesh",
                        "structuredName": {
                            "firstName": "Arvind",
                            "lastName": "Ganesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arvind Ganesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50032052"
                        ],
                        "name": "Yi Ma",
                        "slug": "Yi-Ma",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "l1-minimization problem formulated as in [20]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7845570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1310ea938f9bdca75a5d5347b380a5c4a1d2cc0a",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide a comprehensive review of five representative \u21131-minimization methods, i.e., gradient projection, homotopy, iterative shrinkage-thresholding, proximal gradient, and augmented Lagrange multiplier. The repository is intended to fill in a gap in the existing literature to systematically benchmark the performance of these algorithms using a consistent experimental setting. The experiment will be focused on the application of face recognition, where a sparse representation framework has recently been developed to recover human identities from facial images that may be affected by illumination change, occlusion, and facial disguise. The paper also provides useful guidelines to practitioners working in similar fields."
            },
            "slug": "Fast-\u21131-minimization-algorithms-and-an-application-Yang-Sastry",
            "title": {
                "fragments": [],
                "text": "Fast \u21131-minimization algorithms and an application in robust face recognition: A review"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A comprehensive review of five representative \u21131-minimization methods, i.e., gradient projection, homotopy, iterative shrinkage-thresholding, proximal gradient, and augmented Lagrange multiplier, for face recognition is provided."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Conference on Image Processing"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784512"
                        ],
                        "name": "A. Vashist",
                        "slug": "A.-Vashist",
                        "structuredName": {
                            "firstName": "Akshay",
                            "lastName": "Vashist",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vashist"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "In contrast, the training set preserves the temporal structure of the images, which could be exploited by approaches capable of using privileged information [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12342641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58059409e131f2a854367052636138e835f14f60",
            "isKey": false,
            "numCitedBy": 590,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-learning-paradigm:-Learning-using-privileged-Vapnik-Vashist",
            "title": {
                "fragments": [],
                "text": "A new learning paradigm: Learning using privileged information"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "We use the C++ open-source implementation of ConvNets called EBLearn(6) [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 61
                            }
                        ],
                        "text": "We use the C++ open-source implementation of ConvNets called EBLearn6 [17]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15064817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78e5bca056ffc6186400ba540a0c0f43df909a12",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Energy-based learning (EBL) is a general framework to describe supervised and unsupervised training methods for probabilistic and non-probabilistic factor graphs. An energy-based model associates a scalar energy to configurations of inputs, outputs, and latent variables. Learning machines can be constructed by assembling modules and loss functions. Gradient-based learning procedures are easily implemented through semi-automatic differentiation of complex models constructed by assembling predefined modules. We introduce an open-source and cross-platform C++ library called EBLearn to enable the construction of energy-based learning models. EBLearn is composed of two major components, libidx: an efficient and flexible multi-dimensional tensor library, and libeblearn: an object-oriented library of trainable modules and learning algorithms. The latter has facilities for such models as convolutional networks, as well as for image processing. It also provides graphical display functions."
            },
            "slug": "EBLearn:-Open-Source-Energy-Based-Learning-in-C++-Sermanet-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "EBLearn: Open-Source Energy-Based Learning in C++"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An open-source and cross-platform C++ library called EBLearn is introduced to enable the construction of energy-based learning models and is composed of two major components, libidx: an efficient and flexible multi-dimensional tensor library, and libeblearn: an object-oriented library of trainable modules and learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2009 21st IEEE International Conference on Tools with Artificial Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "With respect to other implementations of similar neural network architectures on GPUs [11], [12] that are hard-coded to satisfy the hardware constraints of the GPUs, our implementation [13] is flexible and fully on-line (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1918673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b98cd08b75ebf2bd1d1ec47c51ef75777a7e64bd",
            "isKey": false,
            "numCitedBy": 876,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35 error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning."
            },
            "slug": "Deep,-Big,-Simple-Neural-Nets-for-Handwritten-Digit-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Deep, Big, Simple Neural Nets for Handwritten Digit Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35 error rate on the MNIST handwritten digits benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704103"
                        ],
                        "name": "H. Malvar",
                        "slug": "H.-Malvar",
                        "structuredName": {
                            "firstName": "Henrique",
                            "lastName": "Malvar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Malvar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689581"
                        ],
                        "name": "Li-wei He",
                        "slug": "Li-wei-He",
                        "structuredName": {
                            "firstName": "Li-wei",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-wei He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145952419"
                        ],
                        "name": "Ross Cutler",
                        "slug": "Ross-Cutler",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Cutler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross Cutler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 128
                            }
                        ],
                        "text": "The video sequences are stored in raw Bayer-pattern format, but extracted traffic sign images are converted to RGB color images [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1453748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31d0492ca9bee4352ef40430b9c58d8d2dfe2ff2",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new interpolation technique for demosaicing of color images produced by single-CCD digital cameras. We show that the proposed simple linear filter can lead to an improvement in PSNR of over 5.5 dB when compared to bilinear demosaicing, and about 0.7 dB improvement in R and B interpolation when compared to a recently introduced linear interpolator. The proposed filter also outperforms most nonlinear demosaicing algorithms, without the artifacts due to nonlinear processing, and a much reduced computational complexity."
            },
            "slug": "High-quality-linear-interpolation-for-demosaicing-Malvar-He",
            "title": {
                "fragments": [],
                "text": "High-quality linear interpolation for demosaicing of Bayer-patterned color images"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A new interpolation technique for demosaicing of color images produced by single-CCD digital cameras shows that the proposed simple linear filter can lead to an improvement in PSNR and improvement in R and B interpolation when compared to a recently introduced linear interpolator."
            },
            "venue": {
                "fragments": [],
                "text": "2004 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27996204"
                        ],
                        "name": "M. Salman Asif",
                        "slug": "M.-Salman-Asif",
                        "structuredName": {
                            "firstName": "M. Salman",
                            "lastName": "Asif",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Salman Asif"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "We use the Homotopy solver [21] stopped after reaching a sparse support of less than 20 nonzeroes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115603371,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "20f99af4789403c0d89b708513893b7f3f404faf",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "To My parents with utmost respect, Haiqa and Dayan with best dreams. iii ACKNOWLEDGEMENTS First and foremost, I would like to thank my advisor, Justin Romberg, for all the inspiration, motivation and guidance. Without his invaluable insight and constant mentoring this thesis would have not been possible. I will always be grateful to him for introducing me to this research area with so many new and exciting problems and helping me all along the way. I cannot thank him enough for the long hours of discussion on any problem I brought to him; anytime, anywhere. I also want to thank him for reading all the drafts of this thesis, his suggestions helped a lot in improving its content and presentation. I am grateful to him for being so friendly, patient and kind to me all the time (not to mention all the squash games he beats me in, ruthlessly!). I want to thank my thesis committee members Prof. James McClellan and Prof. Russell Mersereau for their encouraging remarks about this work. I would like to thank my teachers here at Georgia Tech., all of whom influenced me a lot. I would like to thank Profs. William Green and Michael Westdickenberg who taught me about mathematical analysis. I would also like to thank Profs. John Barry and Faramarz Fekri for their exciting classes in my first semester here. I would like to extend my gratitude towards my undergraduate advisor, Amjad Luna, whose guidance has been instrumental in every possible way, Thankyou! I would also like to thank all my teachers (and later colleagues) at UET Lahore, without whom I would not have been here. Many thanks to all my friends who made my time here a lot more enjoyable than I had anticipated. First of all, I must thank Farasat Munir and Mohammad Omer for being a huge support to me whenever I needed them. I cherish their friendship iv a lot. I especially want to thank Omer for his help and consideration at all those times when I have nobody else to talk to. I also want to thank my roommate Umair Bin Altaf (\" patti \") for all the great time so far, for forcing me to learn L A T E X (along with many other things) and carefully reading the initial drafts of my thesis. William Mantzel, with whom I discuss almost all of my research problems \u2026"
            },
            "slug": "Primal-dual-pursuit:-a-homotopy-based-algorithm-for-Asif",
            "title": {
                "fragments": [],
                "text": "Primal dual pursuit: a homotopy based algorithm for the Dantzig selector"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [5], a number-based speed limit classifier is trained on 2,880 images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A alysis of speed sign classification algorithms using shape based se gmentation of binary images"
            },
            "venue": {
                "fragments": [],
                "text": "inProceedings of the International Conference on Computer Analysis of Images and Patterns  , 2009, pp. 1220\u20131227."
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "Various approaches are compared on a dataset containing 1,300 preprocessed examples from 6 classes (5 speed limits and 1 noise class) in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An optimization on p ictogram identification for the road-sign recognition task using SVM s"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Image Understanding  , vol. 114, no. 3, pp. 373\u2013383, 2010."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "It is interesting to note that superior networks have since then been obtained without the use of color information (fully described in [18])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolutional neural networks applied to traffic sign recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Joint Conference on Neural Networks, 2011, accepted."
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "It is interesting to note that supe rior networks have since then been obtained without the use of color information (fully described in [19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast and accurate digit classifica tion"
            },
            "venue": {
                "fragments": [],
                "text": "EECS Department, University of California, Berkeley, Tech. Rep  . UCB/EECS- 2009-159, Nov 2009."
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "1) HOG features:Three sets of differently configured HOG features (histograms of oriented gradients) [10] are provi ded."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sha  rk"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Machine Learning Research  , vol. 9, pp. 993\u2013996, 2008."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "We use the Homotopy solver [23] stopped after reaching a sparse suppor t of less than 20 nonzeroes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminant anal ysis on histogram of oriented gradients and vector quantization fo r traffic sign recognition"
            },
            "venue": {
                "fragments": [],
                "text": "insubmitted to International Joint Conference on Neural Networks, 2011."
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast approaches to large-scale classification"
            },
            "venue": {
                "fragments": [],
                "text": "submitted to International Joint Conference on Neural Networks"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "The video sequences are stored in rawBayer-pattern format, but extracted traffic sign images are converted to RGBcolor images [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A new learning paradigm: Learn  ing using privileged information,\u201dNeural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "vol. 22,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "We used computed pyramidal HOG features over resized 28\u00d728 pixels patches using the same settings used in [20] for handwritten digits classifica t on."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 148
                            }
                        ],
                        "text": "3) Team VISICS: Team VISICS consists of Radu Timofte and Luc van Gool from ESAT-PSI-VISICS/IBBT at the Katholieke Universiteit Leuven, Belgium7.\na) IK-SVM based method: \u201dThe method employs a fast Intersection Kernel Support Vector Machine (IK-SVM) [19] over concatenated HOG features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "a) IK-SVM based method: The method employs a fast Intersection Kernel Support Vector Machine (IK-SVM) [20] over concatenated HOG features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast approaches to large-sca le classification"
            },
            "venue": {
                "fragments": [],
                "text": "submitted to International Joint Conference on Neural Networks, 2011."
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminant analysis on histogram of oriented gradients and vector quantization for traffic sign recognition"
            },
            "venue": {
                "fragments": [],
                "text": "submitted to International Joint Conference on Neural Networks"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "We use the C++ open-source implementation of ConvNets called EBLearn6 [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 61
                            }
                        ],
                        "text": "We use the C++ open-source implementation of ConvNets called EBLearn6 [17]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolutional neural networ ks applied to traffic sign recognition"
            },
            "venue": {
                "fragments": [],
                "text": "inProceedings of the International Joint Conference on Neural Networks (IJCNN\u201911)  . IEEE, 2011."
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "In contrast, the training set preserves th temporal structure of the images, which could be exploited b y approaches capable of using privileged information [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradient s for human detection"
            },
            "venue": {
                "fragments": [],
                "text": "inProceedings of the IEEE Conference on Computer Vision and Pattern Recognition  , 2005, pp. 886\u2013893."
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/The-German-Traffic-Sign-Recognition-Benchmark:-A-Stallkamp-Schlipsing/22fe619996b59c09cb73be40103a123d2e328111?sort=total-citations"
}