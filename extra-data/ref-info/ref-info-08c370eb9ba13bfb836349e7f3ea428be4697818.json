{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231485"
                        ],
                        "name": "S. Aji",
                        "slug": "S.-Aji",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Aji",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11355291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e8933300a20f3d799dc9f19e352967f41d8efcc",
            "isKey": false,
            "numCitedBy": 773,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss a general message passing algorithm, which we call the generalized distributive law (GDL). The GDL is a synthesis of the work of many authors in information theory, digital communications, signal processing, statistics, and artificial intelligence. It includes as special cases the Baum-Welch algorithm, the fast Fourier transform (FFT) on any finite Abelian group, the Gallager-Tanner-Wiberg decoding algorithm, Viterbi's algorithm, the BCJR algorithm, Pearl's \"belief propagation\" algorithm, the Shafer-Shenoy probability propagation algorithm, and the turbo decoding algorithm. Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "slug": "The-generalized-distributive-law-Aji-McEliece",
            "title": {
                "fragments": [],
                "text": "The generalized distributive law"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 361,
                                "start": 333
                            }
                        ],
                        "text": "Our original motivation for introducing factor graphs was to make explicit the commonalities between Bayesian networks (also known as belief networks, causal networks, and in uence diagrams) and Tanner graphs, both of which had previously been used to explain the iterative decoding of turbo codes and low-density parity check codes [11, 22, 25, 26, 30, 38, 39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "[19] F. R. Kschischang and B. J. Frey, \u201cIterative decoding of compound codes by probability propagation in graphical models,\u201dIEEE J. Select."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Descriptions of the way in which the sum-product algorithm is applied to a variety of \\compound codes\" are given in [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "More recently, at least two papers [22, 30] develop a view of the \\turbo decoding\" algorithm [7] as an instance of probability propagation in a Bayesian network code model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": ") In the opposite direction, a factor graph F that represents a joint probability distribution can be converted to a Markov random eld via a component of the second higher power graph F 2 [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "[10] B. J. Frey,Graphical Models for Machine Learning and Digital Communication."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "For example, the schedule in which Li = (S Q)[ (Q S) for all i, is called the ooding schedule [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "B. J. Frey is with the Faculty of Computer Science, University of Waterloo, Waterloo, ON N2L 3G1, Canada, and the Faculty of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL 61801-2307 USA (e-mail: frey@.uwaterloo.ca)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "[9] B. J. Frey and F. R. Kschischang, \u201cProbability propagation and iterative decoding,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Kschischang and Frey [22] give a brief discussion of the use of MRFs to describe codes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "(An example in a coding context of this MRF ambiguity is given in [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "The work of B. J. Frey was supported, while a Beckman Fellow at the Beckman Institute of Advanced Science and Technology, University of Illinois at Urbana-Champaign, by a grant from the Arnold and Mabel Beckman Foundation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6522238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbd45449e1cdadbf1f0c06a9510b5ac247cb70b9",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified graphical model framework for describing compound codes and deriving iterative decoding algorithms. After reviewing a variety of graphical models (Markov random fields, Tanner graphs, and Bayesian networks), we derive a general distributed marginalization algorithm for functions described by factor graphs. From this general algorithm, Pearl's (1986) belief propagation algorithm is easily derived as a special case. We point out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code. We focus on Bayesian network descriptions of codes, which give a natural input/state/output/channel description of a code and channel, and we indicate how iterative decoders can be developed for parallel-and serially concatenated coding systems, product codes, and low-density parity-check codes."
            },
            "slug": "Iterative-Decoding-of-Compound-Codes-by-Probability-Kschischang-Frey",
            "title": {
                "fragments": [],
                "text": "Iterative Decoding of Compound Codes by Probability Propagation in Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is pointed out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2718299"
                        ],
                        "name": "N. Wiberg",
                        "slug": "N.-Wiberg",
                        "structuredName": {
                            "firstName": "Niclas",
                            "lastName": "Wiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wiberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "As mentioned in Section II (see also [31], [2]), the codomain of the global function represented by a factor graph may in general be any semiring with two operations \u201c \u201d and \u201c \u201d that satisfy the distributive law"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Note, however, that Wiberg [31] had earlier described"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 87
                            }
                        ],
                        "text": "In Tanner\u2019s original formulation, all variables are codeword symbols and hence \u201cvisible\u201d; Wiberg et al., introduced \u201chidden\u201d (latent) state variables and also suggested applications beyond coding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 31
                            }
                        ],
                        "text": "Such graphs were introduced by Wiberget al. [31], [32] and may be called Wiberg-type graphs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[31], [32] and may be called Wiberg-type graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 20
                            }
                        ],
                        "text": "Note, however, that Wiberg [31] had earlier described these decoding algorithms as instances of the sum-product algorithm; see also [7]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 91
                            }
                        ],
                        "text": "Genealogically, factor graphs are a straightforward generalization of the \u201cTanner graphs\u201d of Wiberget al. [31], [32]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 37
                            }
                        ],
                        "text": "The corresponding factor node in the Wiberg-type graph is the indicator function\n."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Indeed, the \u201ccut-set bound\u201d of [31] (see also [8]) strongly motivates the study of graph representations with cycles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 29
                            }
                        ],
                        "text": "9(b) shows the corresponding Wiberg-type graph."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "[31] N. Wiberg, \u201cCodes and decoding on general graphs,\u201d Ph.D. dissertation, Link\u00f6ping Univ., Link\u00f6ping, Sweden, 1996."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "[32] N. Wiberg, H.-A. Loeliger, and R. K\u00f6tter, \u201cCodes and iterative decoding on general graphs,\u201dEur."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 36
                            }
                        ],
                        "text": "In our factor graph diagrams, as in Wiberg, hidden variable nodes are indicated by a double circle."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 261
                            }
                        ],
                        "text": "In communication systems, for example, channel modeling and estimation, separation of multiple users, and decoding can be treated in a unified way using a single graphical model that represents the interactions of these various elements, as suggested by Wiberg [31]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 243
                            }
                        ],
                        "text": "ACKNOWLEDGMENT\nThe concept of factor graphs as a generalization of Tanner graphs was devised by a group at ISIT \u201997 in Ulm, Germany, that included the authors, G. D. Forney, Jr., R. K\u00f6tter, D. J. C. MacKay, R. J. McEliece, R. M. Tanner, and N. Wiberg."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "(While it may even be feasible to model complicated channels with memory [31], in this paper we will model only memoryless channels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115168171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb44d50bce92b4ce2c0ea53bd8ede95f628ee3cb",
            "isKey": true,
            "numCitedBy": 1007,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative decoding techniques have become a viable alternative for constructing high performance coding systems. In particular, the recent success of turbo codes indicates that performance close to the Shannon limit may be achieved. In this thesis, it is showed that many iterative decoding algorithms are special cases of two generic algorithms, the min-sum and sum-product algorithms, which also include non-iterative algorithms such as Viterbi decoding. The min-sum and sum-product algorithms are developed and presented as generalized trellis algorithms, where the time axis of the trellis is replaced by an arbitrary graph, the \u201cTanner graph\u201d. With cycle-free Tanner graphs, the resulting decoding algorithms (e.g., Viterbi decoding) are maximum-likelihood but suffer from an exponentially increasing complexity. Iterative decoding occurs when the Tanner graph has cycles (e.g., turbo codes); the resulting algorithms are in general suboptimal, but significant complexity reductions are possible compared to the cycle-free case. Several performance estimates for iterative decoding are developed, including a generalization of the union bound used with Viterbi decoding and a characterization of errors that are uncorrectable after infinitely many decoding iterations."
            },
            "slug": "Codes-and-Decoding-on-General-Graphs-Wiberg",
            "title": {
                "fragments": [],
                "text": "Codes and Decoding on General Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is showed that many iterative decoding algorithms are special cases of two generic algorithms, the min-sum and sum-product algorithms, which also include non-iterative algorithms such as Viterbi decoding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144018201"
                        ],
                        "name": "G. Forney",
                        "slug": "G.-Forney",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Forney",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Forney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195868257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74a8959a5971b56dcda05cdde57b724906bf28aa",
            "isKey": false,
            "numCitedBy": 498,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Wiberg et al. (see European Transactions on Telelecommunications, vol.6, p.513-25, Sept./Oct. 1995) proposed graphical code realizations using three kinds of elements: symbol variables, state variables and local constraints. We focus on normal realizations, namely Wiberg-type realizations in which all symbol variables have degree 1 and state variables have degree 2. A natural graphical model of a normal realization represents states by leaf edges, states by ordinary edges, and local constraints by vertices. Any such graph may be decoded by message-passing (the sum-product algorithm). We show that any Wiberg-type realization may be put into normal form without essential change in its graph or its decoding complexity. Group or linear codes are realized by group or linear realizations. We show that an appropriately defined dual of a group or linear normal realization realizes the dual group or linear code. The symbol variables, state variables and graph topology of the dual realization are unchanged, while local constraints are replaced by their duals."
            },
            "slug": "Codes-on-graphs:-normal-realizations-Forney",
            "title": {
                "fragments": [],
                "text": "Codes on graphs: normal realizations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work shows that any Wiberg-type realization may be put into normal form without essential change in its graph or its decoding complexity, and shows that an appropriately defined dual of a group or linear normal realization realizes the dual group orlinear code."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Symposium on Information Theory (Cat. No.00CH37060)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14553992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26d953005dd08a863c157b528bbabdf5671d18b6",
            "isKey": false,
            "numCitedBy": 1004,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the close connection between the now celebrated iterative turbo decoding algorithm of Berrou et al. (1993) and an algorithm that has been well known in the artificial intelligence community for a decade, but which is relatively unknown to information theorists: Pearl's (1982) belief propagation algorithm. We see that if Pearl's algorithm is applied to the \"belief network\" of a parallel concatenation of two or more codes, the turbo decoding algorithm immediately results. Unfortunately, however, this belief diagram has loops, and Pearl only proved that his algorithm works when there are no loops, so an explanation of the experimental performance of turbo decoding is still lacking. However, we also show that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's (1962) low-density parity-check codes, serially concatenated codes, and product codes. Thus, belief propagation provides a very attractive general methodology for devising low-complexity iterative decoding algorithms for hybrid coded systems."
            },
            "slug": "Turbo-Decoding-as-an-Instance-of-Pearl's-\"Belief-McEliece-Mackay",
            "title": {
                "fragments": [],
                "text": "Turbo Decoding as an Instance of Pearl's \"Belief Propagation\" Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's low-density parity-check codes, serially concatenated codes, and product codes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3637824"
                        ],
                        "name": "R. M. Tanner",
                        "slug": "R.-M.-Tanner",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tanner",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. M. Tanner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "A factor graph obtained in this way is often called a T nner graph, after [29]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Tanner [29] introduced bipartite graphs to describe families of codes which are generalizations of the low-density parity-check (LDPC) codes of Gallager [11], and also described the sum-product algorithm in this setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 754232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "157218bae792b6ef550dfd0f73e688d83d98b3d7",
            "isKey": false,
            "numCitedBy": 2971,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for constructing long error-correcting codes from one or more shorter error-correcting codes, referred to as subcodes, and a bipartite graph. A graph is shown which specifies carefully chosen subsets of the digits of the new codes that must be codewords in one of the shorter subcodes. Lower bounds to the rate and the minimum distance of the new code are derived in terms of the parameters of the graph and the subeodes. Both the encoders and decoders proposed are shown to take advantage of the code's explicit decomposition into subcodes to decompose and simplify the associated computational processes. Bounds on the performance of two specific decoding algorithms are established, and the asymptotic growth of the complexity of decoding for two types of codes and decoders is analyzed. The proposed decoders are able to make effective use of probabilistic information supplied by the channel receiver, e.g., reliability information, without greatly increasing the number of computations required. It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities. The construction principles"
            },
            "slug": "A-recursive-approach-to-low-complexity-codes-Tanner",
            "title": {
                "fragments": [],
                "text": "A recursive approach to low complexity codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2718299"
                        ],
                        "name": "N. Wiberg",
                        "slug": "N.-Wiberg",
                        "structuredName": {
                            "firstName": "Niclas",
                            "lastName": "Wiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wiberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 361,
                                "start": 333
                            }
                        ],
                        "text": "Our original motivation for introducing factor graphs was to make explicit the commonalities between Bayesian networks (also known as belief networks, causal networks, and in uence diagrams) and Tanner graphs, both of which had previously been used to explain the iterative decoding of turbo codes and low-density parity check codes [11, 22, 25, 26, 30, 38, 39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 234
                            }
                        ],
                        "text": "2 Prior Art We will see in Section 2 that factor graphs subsume many other graphical models in signal processing, probability theory, and coding, including Markov random elds [19, 21, 32], Bayesian networks [20, 31] and Tanner graphs [35, 38, 39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36630145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c7bdd4738189e8e5a370f858eedba3426b0c859",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, most known decoding procedures for error-correcting codes were based either on algebraically calculating the error pattern or on some sort of tree or trellis search. With the advent of turbo coding, a third decoding principle has finally had its breakthrough: iterative decoding. With respect to Viterbi decoding, a code is most naturally described by means of a trellis diagram. The main thesis of the present paper is that, with respect to iterative decoding, the natural way of describing a code is by means of a Tanner graph, which may be viewed as a generalized trellis. More precisely, it is the \"time axis\" of a trellis that is generalized to a Tanner graph."
            },
            "slug": "Codes-and-iterative-decoding-on-general-graphs-Wiberg-Loeliger",
            "title": {
                "fragments": [],
                "text": "Codes and iterative decoding on general graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The main thesis of the present paper is that, with respect to iterative decoding, the natural way of describing a code is by means of a Tanner graph, which may be viewed as a generalized trellis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1995 IEEE International Symposium on Information Theory"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144267648"
                        ],
                        "name": "C. Berzuini",
                        "slug": "C.-Berzuini",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Berzuini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berzuini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150235143"
                        ],
                        "name": "M. Stefanelli",
                        "slug": "M.-Stefanelli",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stefanelli",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stefanelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61439629,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e58973bc34aee7643be6eadc2e92574009ced678",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A causal network is used in a number of areas as a depiction of patterns of `influence' among sets of variables. In expert systems it is common to perform `inference' by means of local computations on such large but sparse networks. In general, non-probabilistic methods are used to handle uncertainty when propagating the effects of evidence, and it has appeared that exact probabilistic methods are not computationally feasible. Motivated by an application in electromyography, we counter this claim by exploiting a range of local representations for the joint probability distribution, combined with topological changes to the original network termed `marrying' and `filling-in'. The resulting structure allows efficient algorithms for transfer between representations, providing rapid absorption and propagation of evidence. The scheme is first illustrated on a small, fictitious but challenging example, and the underlying theory and computational aspects are then discussed."
            },
            "slug": "Contribution-to-the-discussion-of-the-paper-by-L.-Berzuini-Stefanelli",
            "title": {
                "fragments": [],
                "text": "Contribution to the discussion of the paper by Steffen L. Lauritzen and David Spiegelhalter: \"Local Computations with Probabilities on Graphical Structures and their Application to Expert Systems\""
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work exploits a range of local representations for the joint probability distribution, combined with topological changes to the original network termed `marrying' and `filling-in', which allows efficient algorithms for transfer between representations, providing rapid absorption and propagation of evidence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46404423"
                        ],
                        "name": "J. Hagenauer",
                        "slug": "J.-Hagenauer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Hagenauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hagenauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549634"
                        ],
                        "name": "E. Offer",
                        "slug": "E.-Offer",
                        "structuredName": {
                            "firstName": "Elke",
                            "lastName": "Offer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Offer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38915382"
                        ],
                        "name": "L. Papke",
                        "slug": "L.-Papke",
                        "structuredName": {
                            "firstName": "Lutz",
                            "lastName": "Papke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Papke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14954804,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7b350b6d469ac30c02f10aa4e62f77f79c0106b",
            "isKey": false,
            "numCitedBy": 2523,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative decoding of two-dimensional systematic convolutional codes has been termed \"turbo\" (de)coding. Using log-likelihood algebra, we show that any decoder can be used which accepts soft inputs-including a priori values-and delivers soft outputs that can be split into three terms: the soft channel and a priori inputs, and the extrinsic value. The extrinsic value is used as an a priori value for the next iteration. Decoding algorithms in the log-likelihood domain are given not only for convolutional codes but also for any linear binary systematic block code. The iteration is controlled by a stop criterion derived from cross entropy, which results in a minimal number of iterations. Optimal and suboptimal decoders with reduced complexity are presented. Simulation results show that very simple component codes are sufficient, block codes are appropriate for high rates and convolutional codes for lower rates less than 2/3. Any combination of block and convolutional component codes is possible. Several interleaving techniques are described. At a bit error rate (BER) of 10/sup -4/ the performance is slightly above or around the bounds given by the cutoff rate for reasonably simple block/convolutional component codes, interleaver sizes less than 1000 and for three to six iterations."
            },
            "slug": "Iterative-decoding-of-binary-block-and-codes-Hagenauer-Offer",
            "title": {
                "fragments": [],
                "text": "Iterative decoding of binary block and convolutional codes"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Using log-likelihood algebra, it is shown that any decoder can be used which accepts soft inputs-including a priori values-and delivers soft outputs that can be split into three terms: the soft channel and aPriori inputs, and the extrinsic value."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7707909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "763aa50583ed047528ba4ef471d72bfbe34471e6",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We view perceptual tasks such as vision and speech recognition as inference problems where the goal is to estimate the posterior distribution over latent variables (e.g., depth in stereo vision) given the sensory input. The recent flurry of research in independent component analysis exemplifies the importance of inferring the continuous-valued latent variables of input data. The latent variables found by this method are linearly related to the input, but perception requires nonlinear inferences such as classification and depth estimation. In this article, we present a unifying framework for stochastic neural networks with nonlinear latent variables. Nonlinear units are obtained by passing the outputs of linear gaussian units through various nonlinearities. We present a general variational method that maximizes a lower bound on the likelihood of a training set and give results on two visual feature extraction problems. We also show how the variational method can be used for pattern classification and compare the performance of these nonlinear networks with other methods on the problem of handwritten digit recognition."
            },
            "slug": "Variational-Learning-in-Nonlinear-Gaussian-Belief-Frey-Hinton",
            "title": {
                "fragments": [],
                "text": "Variational Learning in Nonlinear Gaussian Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This article presents a general variational method that maximizes a lower bound on the likelihood of a training set and gives results on two visual feature extraction problems."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "For example, the canonical NP-complete problemSAT (Boolean satisfiability) [13] is simply the problem of determining whether or not a collection of Boolean variables satisfies all clauses in a given set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2211006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdede1e17c947540b50e6e2db9e8467ddc6e7336",
            "isKey": false,
            "numCitedBy": 47653,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Horn formulae play a prominent role in artificial intelligence and logic programming. In this paper we investigate the problem of optimal compression of propositional Horn production rule knowledge bases. The standard approach to this problem, consisting in the removal of redundant rules from a knowledge base, leads to an \"irredundant\" but not necessarily optimal knowledge base. We prove here that the number of rules in any irredundant Horn knowledge base involving n propositional variables is at most n 0 1 times the minimum possible number of rules. In order to formalize the optimal compression problem, we define a Boolean function of a knowledge base as being the function whose set of true points is the set of models of the knowledge base. In this way the optimal compression of production rule knowledge bases becomes a problem of Boolean function minimization. In this paper we prove that the minimization of Horn functions (i.e. Boolean functions associated to Horn knowledge bases) is..."
            },
            "slug": "Computers-and-Intractability:-A-Guide-to-the-Theory-Garey-Johnson",
            "title": {
                "fragments": [],
                "text": "Computers and Intractability: A Guide to the Theory of NP-Completeness"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is the second edition of a quarterly column the purpose of which is to provide a continuing update to the list of problems (NP-complete and harder) presented by M. R. Garey and myself in the authors' book \u2018\u2018Computers and Intractability: A Guide to the Theory of NP-Completeness\u2019\u2019."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770859"
                        ],
                        "name": "R. Gallager",
                        "slug": "R.-Gallager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gallager",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gallager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These simplifications are well known, some dating back to the work of Gallager [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we restrict ourselves to three examples: turbo codes [5], LDPC codes [11], and repeat\u2013accumulate (RA) codes [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LDPC codes were introduced by Gallager [11] in the early"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Tanner [29] introduced bipartite graphs to describe families of codes which are generalizations of the low-density parity-check (LDPC) codes of Gallager [11], and also described the sum-product algorithm in this setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12709402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "206f827fad201506c315d40c1469b41a45141893",
            "isKey": true,
            "numCitedBy": 10568,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A low-density parity-check code is a code specified by a parity-check matrix with the following properties: each column contains a small fixed number j \\geq 3 of l's and each row contains a small fixed number k > j of l's. The typical minimum distance of these codes increases linearly with block length for a fixed rate and fixed j . When used with maximum likelihood decoding on a sufficiently quiet binary-input symmetric channel, the typical probability of decoding error decreases exponentially with block length for a fixed rate and fixed j . A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described. Both the equipment complexity and the data-handling capacity in bits per second of this decoder increase approximately linearly with block length. For j > 3 and a sufficiently low rate, the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length. Some experimental results show that the actual probability of decoding error is much smaller than this theoretical bound."
            },
            "slug": "Low-density-parity-check-codes-Gallager",
            "title": {
                "fragments": [],
                "text": "Low-density parity-check codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described and the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In [20, 24], similar general procedures are described for transforming a graphical probability model into cycle-free form."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58792451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a3767909649cf31d32e087693d93171af28ebe0",
            "isKey": false,
            "numCitedBy": 4303,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Local-computations-with-probabilities-on-graphical-Lauritzen-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127159"
                        ],
                        "name": "D. Divsalar",
                        "slug": "D.-Divsalar",
                        "structuredName": {
                            "firstName": "Dariush",
                            "lastName": "Divsalar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Divsalar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we restrict ourselves to three examples: turbo codes [5], LDPC codes [11], and repeat\u2010accumulate (RA) codes [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1045655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5ccc94d4f9ea6df991190f17359ddd7ac47f005",
            "isKey": false,
            "numCitedBy": 564,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we discuss AWGN coding theorems for ensembles of coding systems which are built from fixed convolutional codes interconnected with random interleavers. We call these systems \u201cturbo-like\u201d codes and they include as special cases both the classical turbo codes [1,2,3] and the serial concatentation of interleaved convolutional codes [4]. We offer a general conjecture about the behavior of the ensemble (maximum-likelihood decoder) word error probability as the word length approches infinity. We prove this conjecture for a simple class of rate 1/q serially concatenated codes where the outer code is a q-fold repetition code and the inner code is a rate 1 convolutional code with transfer function 1/(1 + D). We believe this represents the first rigorous proof of a coding theorem for turbo-like codes."
            },
            "slug": "Coding-theorems-for-'turbo-like'-codes-Divsalar",
            "title": {
                "fragments": [],
                "text": "Coding theorems for 'turbo-like' codes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper offers a general conjecture about the behavior of the ensemble (maximum-likelihood decoder) word error probability as the word length approches infinity and proves the first rigorous proof of a coding theorem for turbo-like codes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695714"
                        ],
                        "name": "B. Anderson",
                        "slug": "B.-Anderson",
                        "structuredName": {
                            "firstName": "Brian.",
                            "lastName": "Anderson",
                            "middleNames": [
                                "D.",
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109008954"
                        ],
                        "name": "J. Moore",
                        "slug": "J.-Moore",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moore",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48841496"
                        ],
                        "name": "M. Eslami",
                        "slug": "M.-Eslami",
                        "structuredName": {
                            "firstName": "Mansour",
                            "lastName": "Eslami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Eslami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 513,
                                "start": 510
                            }
                        ],
                        "text": "The simpli ed form of the message is fj+1!xj+1(xj+1) / N xj+1;[Aj Aj jC 0 j( j + Cj jC 0 j) 1Cj](x\u0302j + jC 0 j 1 j yj); j +Aj[ j jC 0 j( j + Cj jC 0 j) 1Cj j ]A0j : Inserting the de nitions for j and j given in (33), we nd that the mean and covariance of the message fj+1!xj+1(xj+1) can be expressed x\u0302j+1 = Ajx\u0302j +Kj(yj Cjx\u0302j); and j+1 = Bj jB0 j +Aj[ j jC 0 j(Dj jD0 j + Cj jC 0 j) 1Cj j]A0j; where Kj = Aj jC 0 j(Dj jD0 j + Cj jC 0 j) 1: These updates are exactly equal to the updates used by Kalman ltering [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "5 Kalman Filtering In this section, we derive the Kalman lter [3] as the optimal predictor given by the sumproduct algorithm in a factor graph for a time-varying discrete-time linear dynamical system (cf."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39637449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a544d9c589367a470e96f9fd0a01587b4cdec2ce",
            "isKey": false,
            "numCitedBy": 3563,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Estimation theory has had a tremendous impact on many problem areas over the past two decades. Beginning with its original use in the aerospace industry, its applications can now be found in many different areas such as control and communjcations, power systems, transportation systems, bioengineering, image processing, etc. Along with linear system theory and optimal control, a course in estimation theorycan be found in the graduate system and control curriculum,of most schools in the country. In fact, it is probably one of the most,salable courses as far as employment is concerned. However, despite its economic value and the amount of activities in the field, very few books on estimation theory have appeared recently. This book helps to fill the void in the market and does that in a superb manner. Although the book is called OptimalFiltering, the coverage is restricted to discrete time filtering. A more appropriate title would thus be Optimal Discrete Time ,Filtering. The authors\u2019 decision to concentrate on discrete time f lters is due to \u201crecent technological developments as well as the easier path offered students and instructors.\u201d This is probably a wise move since a thorough treatment of continuous time filtering will require a better knowledge o f stochastic processes than most graduate students or engineers will have. As it stands now, the text requires little background beyond that of linear system theory and probability theory. Written by active researchers, in the area, the book covers the  standard  topics  such  as  Kalman filtering, innovations processes, smoothing, and adaptive and nonlinear estimation. Much of the material in the book has been around for a long time and has been widely used, by practitioners in the area: Some results are more recent. However,-it .has been difficult to locate all of them presented in a n organized manner within a single text. This is especially true of the chapters dealing with the computation aspects and nonlinear and adaptive estimation. After a short introductory chapter, Chapter 2 introduces the mathematical model to be used throughout most of the book. The discrete time Kalman filter is 1 hen presented in Chapter 3, along with some applications. Chapter 4 contains a treatment"
            },
            "slug": "Optimal-Filtering-Anderson-Moore",
            "title": {
                "fragments": [],
                "text": "Optimal Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book helps to fill the void in the market and does that in a superb manner by covering the standard topics such as Kalman filtering, innovations processes, smoothing, and adaptive and nonlinear estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11006356,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "279bf08d1795c6d10c0232a809341f0da2fc06ed",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the \\wake-sleep\" algorithm that allows a multilayer, unsupervised, neural network to build a hierarchy of representations of sensory input. The network has bottom-up \\recognition\" connections that are used to convert sensory input into underlying representations. Unlike most arti cial neural networks, it also has top-down \\generative\" connections that can be used to reconstruct the sensory input from the representations. In the \\wake\" phase of the learning algorithm, the network is driven by the bottom-up recognition connections and the top-down generative connections are trained to be better at reconstructing the sensory input from the representation chosen by the recognition process. In the \\sleep\" phase, the network is driven top-down by the generative connections to produce a fantasized representation and a fantasized sensory input. The recognition connections are then trained to be better at recovering the fantasized representation from the fantasized sensory input. In both phases, the synaptic learning rule is simple and local. The combined e ect of the two phases is to create representations of the sensory input that are e cient in the following sense: On average, it takes more bits to describe each sensory input vector directly than to rst describe the representation of the sensory input chosen by the recognition process and then describe the di erence between the sensory input and its reconstruction from the chosen representation."
            },
            "slug": "A-simple-algorithm-that-discovers-efficient-codes-Frey-Dayan",
            "title": {
                "fragments": [],
                "text": "A simple algorithm that discovers efficient perceptual codes"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The \\wake-sleep\" algorithm that allows a multilayer, unsupervised, neural network to build a hierarchy of representations of sensory input is described, which is driven top-down by the generative connections to produce a fantasized representation and a fantasizing sensory input."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231485"
                        ],
                        "name": "S. Aji",
                        "slug": "S.-Aji",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Aji",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An important observation due to Aji and McEliece [ 1 ], [2] is that various fast transform algorithms may be developed using a graph-based approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "While it may seem intuitively reasonable that some algorithms should exploit the manner in which a global function factors into a product of local functions, the fundamental insight that many well-known algorithms essentially solve the \u201cMPF\u201d (marginalize product-of-functions) problem, each in their own particular setting, was first made explicit in the work of Aji and McEliece [ 1 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41359839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61e625eb3ab78a2e00e941a85ed41e342d110e7c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general \"message-passing\" algorithm for distributing information in a graph. This algorithm may help us to understand the approximate correctness of both the Gallager-Tanner-Wiberg algorithm, and the turbo-decoding algorithm."
            },
            "slug": "A-general-algorithm-for-distributing-information-in-Aji-McEliece",
            "title": {
                "fragments": [],
                "text": "A general algorithm for distributing information in a graph"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A general \"message-passing\" algorithm for distributing information in a graph that may help to understand the approximate correctness of both the Gallager-Tanner-Wiberg algorithm, and the turbo-decoding algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Symposium on Information Theory"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2204972"
                        ],
                        "name": "M. V. Rossum",
                        "slug": "M.-V.-Rossum",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Rossum",
                            "middleNames": [
                                "C.",
                                "W.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. V. Rossum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2281536,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6",
            "isKey": false,
            "numCitedBy": 1657,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Lecture Notes for the MSc/DTC module. The brain is a complex computing machine which has evolved to give the ttest output to a given input. Neural computation has as goal to describe the function of the nervous system in mathematical and computational terms. By analysing or simulating the resulting equations, one can better understand its function, research how changes in parameters would eect the function, and try to mimic the nervous system in hardware or software implementations. Neural Computation is a bit like physics, that has been successful in describing numerous physical phenomena. However, approaches developed in those elds not always work for neural computation, because: 1. Physical systems are best studied in reduced, simplied circumstances, but the nervous system is hard to study in isolation. Neurons require a narrow range of operating conditions (temperature, oxygen, presence of other neurons, ion concentrations, ...) under which they work as they should. These conditions are hard to reproduce outside the body. Secondly, the neurons form a highly interconnected network. The function of the nervous systems depends on this connectivity and interaction, by trying to isolate the components, you are likely to alter the function. 2. It is not clear how much detail one needs to describe the computations in the brain. In these lectures we shall see various description levels. 3. Neural signals and neural connectivity are hard to measure, especially, if disturbance and damage to the nervous system is to be kept minimal. Perhaps Neural Computation has more in common with trying to gure out how a complicated machine, such as a computer or car works. Knowledge of the basic physics helps, but is not sucient. Luckily there are factors which perhaps make understanding the brain easier than understanding an arbitrary complicated machine: 1. There is a high degree of conservation across species. This means that animal studies can be used to gain information about the human brain. Furthermore, study of, say, the visual system might help to understand the auditory system. 2. The nervous system is able to develop by combining on one hand a only limited amount of genetic information and, on the other hand, the input it receives. Therefore it might be possible to nd the organising principles and develop a brain from there. This would be easier than guring out the complete 'wiring diagram'. 3. The nervous system is exible and robust, neurons die everyday. This stands \u2026"
            },
            "slug": "Neural-Computation-Rossum",
            "title": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The nervous system is able to develop by combining on one hand a only limited amount of genetic information and, on the other hand, the input it receives, and it might be possible to develop a brain from there."
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205001834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "isKey": false,
            "numCitedBy": 20330,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1."
            },
            "slug": "Learning-representations-by-back-propagating-errors-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning representations by back-propagating errors"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Back-propagation repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector, which helps to represent important features of the task domain."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572614"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 361,
                                "start": 333
                            }
                        ],
                        "text": "Our original motivation for introducing factor graphs was to make explicit the commonalities between Bayesian networks (also known as belief networks, causal networks, and in uence diagrams) and Tanner graphs, both of which had previously been used to explain the iterative decoding of turbo codes and low-density parity check codes [11, 22, 25, 26, 30, 38, 39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "LDPC codes, like turbo codes, are very effectively decoded using the sum-product algorithm; for example MacKay and Neal report excellent performance results approaching that of turbo codes using what amounts to a flooding schedule [21], [22]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "[21] D. J. C. MacKay and R. M. Neal, \u201cGood codes based on very sparse matrices,\u201d inCryptography and Coding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "The rst to connect Bayesian networks and belief propagation with applications in coding theory were MacKay and Neal [25], who independently re-discovered Gallager's earlier work on low-density parity-check codes [14] (including Gallager's decoding algorithm)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 102
                            }
                        ],
                        "text": "The first to connect Bayesian networks and belief propagation with applications in coding theory were MacKay and Neal [21]; more recently, [19], [24] develop a view of the \u201cturbo decoding\u201d algorithm [5] as an instance of probability propagation in a Bayesian network model of a code."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 2
                            }
                        ],
                        "text": ", [7, 25, 26]) show that sum-product based decoding algorithms with very long codes can astonishing performance (within a fraction of a decibel of the Shannon limit in some cases), even though the underlying factor graph has cycles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 248
                            }
                        ],
                        "text": "Low-density parity-check codes, like turbo codes, are very e ectively decoded using the sum-product algorithm; for example MacKay and Neal report excellent performance results approaching that of turbo codes using what amounts to a ooding schedule [25, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17285553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9ae39a71308a0bfe12fd5c1ba13165547be3cbd",
            "isKey": true,
            "numCitedBy": 494,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new family of error-correcting codes for the binary symmetric channel. These codes are designed to encode a sparse source, and are defined in terms of very sparse invertible matrices, in such a way that the decoder can treat the signal and the noise symmetrically. The decoding problem involves only very sparse matrices and sparse vectors, and so is a promising candidate for practical decoding."
            },
            "slug": "Good-Codes-Based-on-Very-Sparse-Matrices-Mackay",
            "title": {
                "fragments": [],
                "text": "Good Codes Based on Very Sparse Matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new family of error-correcting codes for the binary symmetric channel is presented, designed to encode a sparse source, and are defined in terms of very sparse invertible matrices, in such a way that the decoder can treat the signal and the noise symmetrically."
            },
            "venue": {
                "fragments": [],
                "text": "IMACC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4640201"
                        ],
                        "name": "V. Isham",
                        "slug": "V.-Isham",
                        "structuredName": {
                            "firstName": "Valerie",
                            "lastName": "Isham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Isham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 175
                            }
                        ],
                        "text": "2 Prior Art We will see in Section 2 that factor graphs subsume many other graphical models in signal processing, probability theory, and coding, including Markov random elds [19, 21, 32], Bayesian networks [20, 31] and Tanner graphs [35, 38, 39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121854003,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "c5632b40077a9783b5afaa65f0bbe918eb63cec0",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Binary-valued Markov random fields may be used as models for point processes with interactions (e.g. repulsion or attraction) between their points. This paper aims to provide a simple nontechnical introduction to Markov random fields in this context. The underlying spaces on which points occur are taken to be countable (e.g. lattice vertices) or continuous (Euclidean space). The role of Markov random fields as equilibrium processes for the temporal evolution of spatial processes is also discussed and various applications and examples are given."
            },
            "slug": "An-Introduction-to-Spatial-Point-Processes-and-Isham",
            "title": {
                "fragments": [],
                "text": "An Introduction to Spatial Point Processes and Markov Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The role of Markov random fields as equilibrium processes for the temporal evolution of spatial processes is discussed and various applications and examples are given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145980949"
                        ],
                        "name": "S. Verd\u00fa",
                        "slug": "S.-Verd\u00fa",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Verd\u00fa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Verd\u00fa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40228025"
                        ],
                        "name": "V. Poor",
                        "slug": "V.-Poor",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Poor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Poor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 8
                            }
                        ],
                        "text": "\" As in [1, 2, 23, 28, 37, 38], we will insist that the summary operator + satisfy the distributive law inR, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121014287,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a0a5b8eff2a7039b867045bbb58392751d3e4d1",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The unifying purpose of the abstract dynamic programming models is to find sufficient conditions on the recursive definition of the objective function that guarantee the validity of the dynamic programming iteration. This paper presents backward, forward, and backward-forward models that weaken previous sufficient conditions and that include, but are not restricted to, optimization problems. The backward-forward model is devoted to the simultaneous solution of a collection of interrelated sequential problems based on the independent computation of a cost-to-arrive function and a cost-to-go function. Several extremization and nonextremization problems illustrate the applicability of the proposed models."
            },
            "slug": "Abstract-dynamic-programming-models-under-Verd\u00fa-Poor",
            "title": {
                "fragments": [],
                "text": "Abstract dynamic programming models under commutativity conditions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572614"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Bayesian networks and belief propagation have been used previously to explain the iterative decoding of turbo codes and LDPC codes [9], [10], [19], [21], [ 22 ], [24], the most powerful practically decodable codes known."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LDPC codes, like turbo codes, are very effectively decoded using the sum-product algorithm; for example MacKay and Neal report excellent performance results approaching that of turbo codes using what amounts to a flooding schedule [21], [ 22 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Extensive simulation results (see, e.g., [5], [21], [ 22 ]) show that with very long codes such decoding algorithms can achieve astonishing performance (within a small fraction of a decibel of the Shannon limit on a Gaussian channel) even though the underlying factor graph has cycles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16406992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e28fc01c3f8ca4151abf9b61296b56dc318d3b26",
            "isKey": true,
            "numCitedBy": 2319,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We report theoretical and empirical properties of Gallager's (1963) low density parity check codes on Gaussian channels. It can be proved that, given an optimal decoder, these codes asymptotically approach the Shannon limit. With a practical 'belief propagation' decoder, performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed the performance is almost as close to the Shannon limit as that of turbo codes."
            },
            "slug": "Good-error-correcting-codes-based-on-very-sparse-Mackay",
            "title": {
                "fragments": [],
                "text": "Good error-correcting codes based on very sparse matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "It can be proved that, given an optimal decoder, Gallager's low density parity check codes asymptotically approach the Shannon limit."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Symposium on Information Theory"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9144776"
                        ],
                        "name": "R. Garello",
                        "slug": "R.-Garello",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Garello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714533"
                        ],
                        "name": "G. Montorsi",
                        "slug": "G.-Montorsi",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Montorsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Montorsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30050592"
                        ],
                        "name": "S. Benedetto",
                        "slug": "S.-Benedetto",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Benedetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Benedetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1978985"
                        ],
                        "name": "G. Cancellieri",
                        "slug": "G.-Cancellieri",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Cancellieri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cancellieri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, trellis representations of turbo codes have enormous state spaces [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8053505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e96d59c1a43a0429950150cc39360ccf0bdb3175",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the basic theory of interleavers is revisited in a semi-tutorial manner, and extended to encompass noncausal interleavers. The parameters that characterize the interleaver behavior (like delay, latency, and period) are clearly defined. The input-output interleaver code is introduced and its complexity studied. Connections among various interleaver parameters are explored. The classes of convolutional and block interleavers are considered, and their practical implementation discussed. The trellis complexity of turbo codes is tied to the complexity of the constituent interleaver. A procedure of complexity reduction by coordinate permutation is also presented, together with some examples of its application."
            },
            "slug": "Interleaver-properties-and-their-applications-to-of-Garello-Montorsi",
            "title": {
                "fragments": [],
                "text": "Interleaver properties and their applications to the trellis complexity analysis of turbo codes"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The basic theory of interleaver behavior is revisited in a semi-tutorial manner, and extended to encompass noncausal interleavers, and a procedure of complexity reduction by coordinate permutation is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30050592"
                        ],
                        "name": "S. Benedetto",
                        "slug": "S.-Benedetto",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Benedetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Benedetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714533"
                        ],
                        "name": "G. Montorsi",
                        "slug": "G.-Montorsi",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Montorsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Montorsi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14586830,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "c994706101df350cea61917aa204175e1c0a18a0",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Serial concatenation of convolutional codes separated by an interleaver has recently been shown, through the use of upper bounds to the maximum likelihood performance, to be competitive with parallel concatenated coding schemes known in the literature as \u2018turbo codes\u2019. The most important feature of turbo codes consists in their relatively simple, yet high performance, iterative decoding algorithm. The authors propose a new iterative decoding algorithm for serial concatenation, and show that the new coding scheme can yield a significant advantage with respect to turbo codes."
            },
            "slug": "Iterative-decoding-of-serially-concatenated-codes-Benedetto-Montorsi",
            "title": {
                "fragments": [],
                "text": "Iterative decoding of serially concatenated convolutional codes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new iterative decoding algorithm for serial concatenation is proposed, and it is shown that the new coding scheme can yield a significant advantage with respect to turbo codes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16512130"
                        ],
                        "name": "J. Raviv",
                        "slug": "J.-Raviv",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Raviv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Raviv"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28594190,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b51c6a5610be2c5648d1476b6f70e8037e0e8cb8",
            "isKey": false,
            "numCitedBy": 6485,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The general problem of estimating the a posteriori probabilities of the states and transitions of a Markov source observed through a discrete memoryless channel is considered. The decoding of linear block and convolutional codes to minimize symbol error probability is shown to be a special case of this problem. An optimal decoding algorithm is derived."
            },
            "slug": "Optimal-decoding-of-linear-codes-for-minimizing-Bahl-Cocke",
            "title": {
                "fragments": [],
                "text": "Optimal decoding of linear codes for minimizing symbol error rate (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The general problem of estimating the a posteriori probabilities of the states and transitions of a Markov source observed through a discrete memoryless channel is considered and an optimal decoding algorithm is derived."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26980954"
                        ],
                        "name": "Kenneth H. Rosen",
                        "slug": "Kenneth-H.-Rosen",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Rosen",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth H. Rosen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 64154474,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "142dad2d2e8e5060eb9561b7744cbc5b4bb90990",
            "isKey": false,
            "numCitedBy": 1342,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis text is designed for the sophomore/junior level introduction to discrete mathematics taken by students preparing for future coursework in areas such as math,computer science and engineering. Rosen has become a bestseller largely due to how effectively it addresses the main portion of the discrete market,which is typically characterized as the mid to upper level in rigor. The strength of Rosen's approach has been the effective balance of theory with relevant applications,as well as the overall comprehensive nature of the topic coverage."
            },
            "slug": "Discrete-mathematics-and-its-applications-Rosen",
            "title": {
                "fragments": [],
                "text": "Discrete mathematics and its applications"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This text is designed for the sophomore/junior level introduction to discrete mathematics taken by students preparing for future coursework in areas such as math, computer science and engineering."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50167999"
                        ],
                        "name": "C. Preston",
                        "slug": "C.-Preston",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Preston",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Preston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118732645,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "057cfbe5b54f91c6823205692c1f72fe7a0f65ab",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Gibbs-States-on-Countable-Sets-Preston",
            "title": {
                "fragments": [],
                "text": "Gibbs States on Countable Sets"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 142
                            }
                        ],
                        "text": "(Computer vision and neural network models) Graphical models have found an impressive place in the eld of neural network models of perception [18, 17, 9, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58779360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8592e46a5435d18bba70557846f47290b34c1aa5",
            "isKey": false,
            "numCitedBy": 1336,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References"
            },
            "slug": "Learning-and-relearning-in-Boltzmann-machines-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Learning and relearning in Boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, and an Example of the Effects of Damage."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46831169"
                        ],
                        "name": "G. Hinton",
                        "slug": "G.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145572884"
                        ],
                        "name": "R. Neal",
                        "slug": "R.-Neal",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Neal",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 871473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dd01cd9c17d1491ead8c9f97597fbc61dead8ea",
            "isKey": false,
            "numCitedBy": 1001,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representation in the layer above. In the \"wake\" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the \"sleep\" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above."
            },
            "slug": "The-\"wake-sleep\"-algorithm-for-unsupervised-neural-Hinton-Dayan",
            "title": {
                "fragments": [],
                "text": "The \"wake-sleep\" algorithm for unsupervised neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described, where bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representations in the layer above."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1833925"
                        ],
                        "name": "C. Berrou",
                        "slug": "C.-Berrou",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Berrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berrou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870588"
                        ],
                        "name": "A. Glavieux",
                        "slug": "A.-Glavieux",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Glavieux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Glavieux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952051"
                        ],
                        "name": "P. Thitimajshima",
                        "slug": "P.-Thitimajshima",
                        "structuredName": {
                            "firstName": "Punya",
                            "lastName": "Thitimajshima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thitimajshima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17770377,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "3ba9baa534a8ea39a31c69e72ada959aaa6a4dc1",
            "isKey": false,
            "numCitedBy": 8239,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A new class of convolutional codes called turbo-codes, whose performances in terms of bit error rate (BER) are close to the Shannon limit, is discussed. The turbo-code encoder is built using a parallel concatenation of two recursive systematic convolutional codes, and the associated decoder, using a feedback decoding rule, is implemented as P pipelined identical elementary decoders.<<ETX>>"
            },
            "slug": "Near-Shannon-limit-error-correcting-coding-and-1-Berrou-Glavieux",
            "title": {
                "fragments": [],
                "text": "Near Shannon limit error-correcting coding and decoding: Turbo-codes. 1"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new class of convolutional codes called turbo-codes, whose performances in terms of bit error rate (BER) are close to the Shannon limit, is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICC '93 - IEEE International Conference on Communications"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There are also close connections between factor graphs and graphical representations (graphical models) for multidimensional probability distributions such as Markov random fields [16], [18], [26] and Bayesian (belief) networks [25], [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similar general procedures are described in [17], [20], and in the construction of junction trees in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is a straightforward exercise to translate the update rules that govern the operation of the sum-product algorithm to Pearl\u2019s belief propagation rules [25], [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", [25], [17], [10]) are graphical models for a collection of random variables that are based on"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61412478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3febde16cb99b8107fecff79905ca61a5e8cd170",
            "isKey": true,
            "numCitedBy": 1493,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational modelling of probability has become a major part of automated decision support systems. In this book, the principal ideas of probabilistic reasoning - known as Bayesian networks - are outlined and their practical implications illustrated. The book is intended for MSc students in knowledge-based systems, artificial intelligence and statistics, and for professionals in decision support systems applications and research."
            },
            "slug": "An-introduction-to-Bayesian-networks-Jensen",
            "title": {
                "fragments": [],
                "text": "An introduction to Bayesian networks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The principal ideas of probabilistic reasoning - known as Bayesian networks - are outlined and their practical implications illustrated and are intended for MSc students in knowledge-based systems, artificial intelligence and statistics, and for professionals in decision support systems applications and research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Bayesian networks and belief propagation have been used previously to explain the iterative decoding of turbo codes and LDPC codes [9], [10], [19], [21], [22], [24], the most powerful practically decodable codes known."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", [25], [17], [10]) are graphical models for a collection of random variables that are based on"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62488180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "629cc74dcaf655feea40f64cd74617ac884ed0f8",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic inference in graphical models pattern classification unsupervised learning data compression channel coding future research directions."
            },
            "slug": "Graphical-Models-for-Machine-Learning-and-Digital-Frey",
            "title": {
                "fragments": [],
                "text": "Graphical Models for Machine Learning and Digital Communication"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "Probabilistic inference in graphical models pattern classification unsupervised learning data compression channel coding future research directions and how this affects research directions is investigated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": ", see [27] for a tutorial emphasizing applications in signal processing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 2
                            }
                        ],
                        "text": ", [31, 20, 11]) are graphical models for a collection of random variables that are based on directed acyclic graphs (DAGs)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [31], a message sent from p to c is denoted c(p), while a message sent from c to p is denoted as c(p), as shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 207
                            }
                        ],
                        "text": "2 Prior Art We will see in Section 2 that factor graphs subsume many other graphical models in signal processing, probability theory, and coding, including Markov random elds [19, 21, 32], Bayesian networks [20, 31] and Tanner graphs [35, 38, 39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Bayesian networks, combined with Pearl's \\belief propagation algorithm\" [31], have become an important tool in expert systems over the past decade."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "It turns out that Pearl's belief propagation algorithm [31] operating on a Bayesian network is equivalent to the sum-product algorithm operating on the corresponding factor graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In this case, motivated by a similar convention in Bayesian networks [20, 31] (see example 8, below), we will sometimes indicate the child, i."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 213
                            }
                        ],
                        "text": "Pearl's belief propagation and belief revision algorithms, widely applied in expert systems and in arti cial intelligence, turn out to be examples of the sum-product algorithm operating in a Bayesian network; see [31, 20] for textbook treatments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Pearl also presents an algorithm called \\belief revision\" in [31]; in our terms, belief revision is the \\max-product\" version of the sum-product algorithm, applied to the factor graph corresponding to a Bayesian network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 272
                            }
                        ],
                        "text": "We will have, for every a 2 a(x), x(a) = 0@ Y d2d(x) d(x)f(xja(x)) Y p2a(x)nfag x(p)1A # a: (28) and, for every d 2 d(x), d(x) = Y c2d(x)nfdg c(x)0@f(xja(x)) Y a2a(x) x(a)1A # x: (29) The termination condition for cycle-free graphs, called the \\belief update\" equation in [31], is given by the product of the messages received by x in the factor graph: BEL(x) = Y d2d(x) d(x)0@f(xja(x)) Y a2a(x) x(a)1A # x: (30) Pearl also introduces a scale factor in (29) and (30) so that the resulting messages properly represent probability mass functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57437891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bf6f01402e1648b7d1e6c9200ede6cb1af30123",
            "isKey": true,
            "numCitedBy": 4579,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806485"
                        ],
                        "name": "J. Willems",
                        "slug": "J.-Willems",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Willems",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Willems"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 11
                            }
                        ],
                        "text": "[33] J. C. Willems, \u201cModels for Dynamics,\u201d inDynamics Reported, Volume 2, U. Kirchgraber and H. O. Walther, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "Since a system is specified via its behavior , this approach is known as behavioral modeling [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Likewise, in \u201cbehavioral\u201d modeling of systems\u2014as in the work of Willems [33]\u2014system behavior is specified in set-theoretic terms by specifying which particular configurations of variables are valid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 5
                            }
                        ],
                        "text": "Both Willems\u2019 behavioral approach to systems and the traditional input/output or state-space approaches fit naturally in the factor graph framework."
                    },
                    "intents": []
                }
            ],
            "corpusId": 116334516,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ed553fcc0fb5752d56f38e10ae835bebdfed7aba",
            "isKey": true,
            "numCitedBy": 431,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is to give a tutorial exposition of what we consider to be the basic mathematical concepts in the theory of dynamical systems."
            },
            "slug": "Models-for-Dynamics-Willems",
            "title": {
                "fragments": [],
                "text": "Models for Dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The purpose of this paper is to give a tutorial exposition of what the authors consider to be the basic mathematical concepts in the theory of dynamical systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [25], [17], [10]) are graphical models for a collection of random variables that are based on"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "(32) The termination condition for cycle-free graphs, called the \u201cbelief update\u201d equation in [25], is given by the product of the messages received by in the factor graph"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "It is a straightforward exercise to translate the update rules that govern the operation of the sum-product algorithm to Pearl\u2019s belief propagation rules [25], [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 228
                            }
                        ],
                        "text": "There are also close connections between factor graphs and graphical representations (graphical models) for multidimensional probability distributions such as Markov random fields [16], [18], [26] and Bayesian (belief) networks [25], [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Bayesian networks, combined with Pearl\u2019s \u201cbelief propagation algorithm\u201d [25], have become an important tool in expert systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [25], a message sent fromto is denoted , while a message sent fromto is denoted as , as shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Pearl\u2019s powerful \u201cbelief propagation\u201d algorithm [25], which operates by \u201cmessage-passing\u201d in a Bayesian network, translates immediately into an instance of the sum-product algorithm operating in a factor graph that expresses the same factorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reasoning in Intelligent Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "[24] R. J. McEliece, D. J. C. MacKay, and J.-F. Cheng, \u201cTurbo decoding as an instance of Pearl\u2019s \u2018belief propagation\u2019 algorithm,\u201dIEEE J. Select."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 377,
                                "start": 361
                            }
                        ],
                        "text": "While it may seem intuitively reasonable that some algorithms should exploit the manner in which a global function factors into a product of local functions, the fundamental insight that many well-known algorithms essentially solve the \u201cMPF\u201d (marginalize product-of-functions) problem, each in their own particular setting, was first made explicit in the work of Aji and McEliece [1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 58
                            }
                        ],
                        "text": "4 An FFT An important observation due to Aji and McEliece [1, 2] is that various fast transform algorithms can be developed using a graph-based approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "An important observation due to Aji and McEliece [1], [2] is that various fast transform algorithms may be developed using a graph-based approach."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 25
                            }
                        ],
                        "text": "In a landmark paper [2], Aji and McEliece develop a \u201cgeneralized distributive law\u201d (GDL) that in some cases solves the MPF problem using a \u201cjunction tree\u201d representation of the global function."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "RA codes are a special, low-complexity class of turbo codes introduced by Divsalar, McEliece, and others, who initially devised these codes because their ensemble weight distributions are relatively easy to derive."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 65
                            }
                        ],
                        "text": "In parallel with the development of this paper, Aji and McEliece [1, 2] develop the closely related \\generalized distributive law,\" an alternative approach based on the properties of junction trees (and not factor graphs)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 212
                            }
                        ],
                        "text": "ACKNOWLEDGMENT\nThe concept of factor graphs as a generalization of Tanner graphs was devised by a group at ISIT \u201997 in Ulm, Germany, that included the authors, G. D. Forney, Jr., R. K\u00f6tter, D. J. C. MacKay, R. J. McEliece, R. M. Tanner, and N. Wiberg."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 8
                            }
                        ],
                        "text": "\" As in [1, 2, 23, 28, 37, 38], we will insist that the summary operator + satisfy the distributive law inR, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "REFERENCES\n[1] S. M. Aji and R. J. McEliece, \u201cA general algorithm for distributing information on a graph,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "[6] D. Divsalar, H. Jin, and R. J. McEliece, \u201cCoding theorems for \u2018turbolike\u2019 codes,\u201d inProc."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The generalized distributive law,\" preprint available  on-line from http://www.systems.caltech.edu/EE/faculty/rjm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102278025"
                        ],
                        "name": "Ross Kindermann",
                        "slug": "Ross-Kindermann",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Kindermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross Kindermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34296841"
                        ],
                        "name": "J. Snell",
                        "slug": "J.-Snell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Snell",
                            "middleNames": [
                                "Laurie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Snell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A Markov random field (see, e.g., [ 18 ]) is a graphical model based on an undirected graph in which each node corresponds to a random variable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There are also close connections between factor graphs and graphical representations (graphical models) for multidimensional probability distributions such as Markov random fields [16], [ 18 ], [26] and Bayesian (belief) networks [25], [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "MRFs are well developed in statistics, and have been used in a variety of applications (see, e.g., [ 18 ], [26], [16], [15])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117120661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "870234e41be333eb8ab128cbd1ca1623838b8d7f",
            "isKey": true,
            "numCitedBy": 1314,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-Random-Fields-and-Their-Applications-Kindermann-Snell",
            "title": {
                "fragments": [],
                "text": "Markov Random Fields and Their Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "In this section, we restrict ourselves to three examples: turbo codes [5], LDPC codes [11], and repeat\u2013accumulate (RA) codes [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "[11] R. G. Gallager,Low-Density Parity-Check Codes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "LDPC codes were introduced by Gallager [11] in the early 1960s."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "Tanner [29] introduced bipartite graphs to describe families of codes which are generalizations of the low-density parity-check (LDPC) codes of Gallager [11], and also described the sum-product algorithm in this setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "These simplifications are well known, some dating back to the work of Gallager [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gallager,Low-Density Parity-Check Codes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "This algorithm was developed earlier in the statistics literature [5] and perhaps even earlier in classi ed work due to L."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120208815,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "603bdbb17ba1f909280405a076455ac4f878fbf3",
            "isKey": false,
            "numCitedBy": 2773,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Inference-for-Probabilistic-Functions-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "Statistical Inference for Probabilistic Functions of Finite State Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116303595"
                        ],
                        "name": "S. Yau",
                        "slug": "S.-Yau",
                        "structuredName": {
                            "firstName": "Shing-Tung",
                            "lastName": "Yau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120049639,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a0703ed83e9c890c97510ad365be00700a42ef9c",
            "isKey": false,
            "numCitedBy": 1406,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mathematics-and-its-applications-Yau",
            "title": {
                "fragments": [],
                "text": "Mathematics and its applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1902488"
                        ],
                        "name": "U. Bertel\u00e8",
                        "slug": "U.-Bertel\u00e8",
                        "structuredName": {
                            "firstName": "Umberto",
                            "lastName": "Bertel\u00e8",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Bertel\u00e8"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075112170"
                        ],
                        "name": "F. Brioschi",
                        "slug": "F.-Brioschi",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Brioschi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Brioschi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61409023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "599fecdb5fec6bf5c99de76088a9a3c37af6f11e",
            "isKey": false,
            "numCitedBy": 450,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonserial-Dynamic-Programming-Bertel\u00e8-Brioschi",
            "title": {
                "fragments": [],
                "text": "Nonserial Dynamic Programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206397124,
            "fieldsOfStudy": [],
            "id": "186a35c7f42e356519931ab8851108eab58385a5",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Codes on graphs: Normal realizations"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "Bayesian networks and belief propagation have been used previously to explain the iterative decoding of turbo codes and LDPC codes [9], [10], [19], [21], [22], [24], the most powerful practically decodable codes known."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18822496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ee14128a8a604b00f8a0d872b60538d7277df7d",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probability-Propagation-and-Iterative-Decoding-Frey-Kschischang",
            "title": {
                "fragments": [],
                "text": "Probability Propagation and Iterative Decoding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": ") Traditional arti cial neural networks called \\multilayer perceptrons\" [34] treat perceptual inference as a function approximation problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "J. Williams, \\Learning representations by  back-propagating errors,\" Nature, vol. 323, pp. 533{536"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "An important class of models with hidden variables are the trellis representations (see [30] for an excellent survey)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Trellis structure of codes"
            },
            "venue": {
                "fragments": [],
                "text": "inHandbook of Coding Theory  , V. S. Pless and W. C. Huffman, Eds. Amsterdam, The Netherlands: Elsevier, 1998, vol. 2."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Trellis Structure of Codes,\" to appear as a chapter in Handbook of Coding Theory"
            },
            "venue": {
                "fragments": [],
                "text": "\\Trellis Structure of Codes,\" to appear as a chapter in Handbook of Coding Theory"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Concrete Mathematics"
            },
            "venue": {
                "fragments": [],
                "text": "New York,  NY: Addison-Wesley"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 8
                            }
                        ],
                        "text": "\" As in [1, 2, 23, 28, 37, 38], we will insist that the summary operator + satisfy the distributive law inR, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the BJCR trellis for linear block codes,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on  Information Theory,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Willems, \\Models for Dynamics"
            },
            "venue": {
                "fragments": [],
                "text": "Dynamics Reported"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Threshold Decoding"
            },
            "venue": {
                "fragments": [],
                "text": "Cambridge, MA: MIT Press"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On iterative decoding and the two-way algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Symp. Turbo Codes and Related Topics"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Since every code can be represented by a trellis (see [36] for a recent survey of results in the theory of the trellis structure of codes), this shows that a cycle-free factor graph exists for every code (in fact, for every set membership function)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Trellis Structure of Codes,\" to appear as a chapter in Handbook of Coding  Theory, (V"
            },
            "venue": {
                "fragments": [],
                "text": "eds). Amsterdam: Elsevier  Science Publishers,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "Bayesian networks and belief propagation with applications in coding theory were MacKay and Neal [21]; more recently, [19], [24] develop a view of the \u201cturbo decoding\u201d algorithm [5] as an instance of probability propagation in a Bayesian network model of a code."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [5], [21], [22]) show that with very long codes such decoding algorithms can achieve astonishing performance (within a small fraction of a decibel of the Shannon limit on a Gaussian channel) even though the underlying factor graph has cycles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "In this section, we restrict ourselves to three examples: turbo codes [5], LDPC codes [11], and repeat\u2013accumulate (RA) codes [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Near Shannonlimit error-correcting coding and decoding: Turbo codes"
            },
            "venue": {
                "fragments": [],
                "text": " Proc. 1993 IEEE Int. Conf. Communications  , Geneva, Switzerland, May 1993, pp. 1064\u20131070."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Trellis structure of codes , \u201d in Handbook of Coding Theory ,"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 142
                            }
                        ],
                        "text": "(Computer vision and neural network models) Graphical models have found an impressive place in the eld of neural network models of perception [18, 17, 9, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "M. Neal, \\The wake-sleep algorithm for  unsupervised neural networks,\" Science, vol. 268, pp. 1158{1161"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "See [13] for the details of a model and a learning algorithm for real-valued variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variational learning in non-linear Gaussian belief  networks,\" to appear in"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 142
                            }
                        ],
                        "text": "(Computer vision and neural network models) Graphical models have found an impressive place in the eld of neural network models of perception [18, 17, 9, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and G"
            },
            "venue": {
                "fragments": [],
                "text": "E. Hinton, \\A simple algorithm that discovers e cient  perceptual codes,\" in Computational and Psychophysical Mechanisms of Visual Cod-  ing, (M. Jenkin and L. R. Harris, eds). New York, NY: Cambridge University Press,  pp. 296{315"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": ", [3], [23]) as an instance of the sum-product algorithm operating in the factor graph corresponding to a discrete-time linear dynamical system similar to that given by (11)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maybeck,Stochastic Models, Estimation, and Control"
            },
            "venue": {
                "fragments": [],
                "text": "New York: Academic,"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "In this section, we restrict ourselves to three examples: turbo codes [5], LDPC codes [11], and repeat\u2013accumulate (RA) codes [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Coding theorems for \u2018turbolike\u2019 codes"
            },
            "venue": {
                "fragments": [],
                "text": "inProc. 36th Allerton Conf. Communications, Control, and Computing, Urbana, IL, Sept. 23\u201325, 1998, pp. 201\u2013210."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 142
                            }
                        ],
                        "text": "(Computer vision and neural network models) Graphical models have found an impressive place in the eld of neural network models of perception [18, 17, 9, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "S. Zemel, \\The Helmholtz machine,\"  Neural Computation, vol. 7, pp. 889{904"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Englewood Cliis, N.J"
            },
            "venue": {
                "fragments": [],
                "text": "Englewood Cliis, N.J"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "For example, Willems' system theory [40] starts from the view that a \\system\" (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Models for Dynamics,\" in Dynamics Reported, Volume 2 (U"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "these decoding algorithms as instances of the sum-product algorithm; see also [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On iterative decoding and the two-way algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Symp. Turbo Codes and Related Topics , Brest, France, Sept. 1997."
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 31,
            "methodology": 22
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 65,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Factor-graphs-and-the-sum-product-algorithm-Kschischang-Frey/08c370eb9ba13bfb836349e7f3ea428be4697818?sort=total-citations"
}