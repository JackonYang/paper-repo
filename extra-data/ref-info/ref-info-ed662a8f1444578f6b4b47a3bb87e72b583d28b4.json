{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1906895"
                        ],
                        "name": "M. Andriluka",
                        "slug": "M.-Andriluka",
                        "structuredName": {
                            "firstName": "Mykhaylo",
                            "lastName": "Andriluka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andriluka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 67
                            }
                        ],
                        "text": "In this section we introduce the Pictorial Structures (PS) version [2, 3] that we are building on and that will serve as a baseline in the experiments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "We refer the reader to [2, 3] for details on training and descriptors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "In contrast we show the generic prior [3] (e) and the corresponding pose prediction (f)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 153
                            }
                        ],
                        "text": "The pairwise term is then a Gaussian on the difference vector between the two transformations Tmn(ln) \u2212 Tnm(lm), as is standard practice in all PS works [2, 3, 26, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "tained by our method (row 1), PS [3] and the method of [26] (row 3)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "For comparison we show the deformation model of [3] (a generic pose prior being the same for all images) along with the corresponding pose estimate in the last two columns."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "Shown are the results by our method (row 1) and PS [3] (row 2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "2 we show example pose estimation results using our method (row 1) and comparison to both [3] (row 2) and [26] (row 3)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "Following [2, 3], we train AdaBoost detectors on dense shape context features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1430002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9279fe29ae1e4ecd0ee34d546560f8a70d17d1d",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Non-rigid object detection and articulated pose estimation are two related and challenging problems in computer vision. Numerous models have been proposed over the years and often address different special cases, such as pedestrian detection or upper body pose estimation in TV footage. This paper shows that such specialization may not be necessary, and proposes a generic approach based on the pictorial structures framework. We show that the right selection of components for both appearance and spatial modeling is crucial for general applicability and overall performance of the model. The appearance of body parts is modeled using densely sampled shape context descriptors and discriminatively trained AdaBoost classifiers. Furthermore, we interpret the normalized margin of each classifier as likelihood in a generative model. Non-Gaussian relationships between parts are represented as Gaussians in the coordinate system of the joint between parts. The marginal posterior of each part is inferred using belief propagation. We demonstrate that such a model is equally suitable for both detection and pose estimation tasks, outperforming the state of the art on three recently proposed datasets."
            },
            "slug": "Pictorial-structures-revisited:-People-detection-Andriluka-Roth",
            "title": {
                "fragments": [],
                "text": "Pictorial structures revisited: People detection and articulated pose estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a generic approach based on the pictorial structures framework, and demonstrates that such a model is equally suitable for both detection and pose estimation tasks, outperforming the state of the art on three recently proposed datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143685864"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "The PS model then takes the form\nE(L;D,\u03b2) = M\u2211 m=1 Eu(lm;D,\u03b2 u) + \u2211 n\u223cm Ep(ln, lm;\u03b2 p)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Poselets go beyond standard pairwise part-part configurations and capture the configuration of multiple body parts jointly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "This corresponds to a max-pooling step in a local region for every poselet p."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Stateof-the-art approaches in this area [2, 15, 26] are based on the pictorial structures model (PS) and are composed of unary terms modelling body part appearance and pairwise terms between adjacent body parts and/or joints capturing their preferred spatial arrangement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3.3) can be enhanced using poselet information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "It can be seen that using only dataset-specific poselets already improves the results over the baseline PS model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our result is only slightly worse than the result of the model from [15] that was trained on a significantly larger training set of 10000 images."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 3509338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf49f2789c72a8301c4dfbb5eabca76c92ed35ef",
            "isKey": true,
            "numCitedBy": 1117,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for human pose estimation in static images based on a novel representation of part models. Notably, we do not use articulated limb parts, but rather capture orientation with a mixture of templates for each part. We describe a general, flexible mixture model for capturing contextual co-occurrence relations between parts, augmenting standard spring models that encode spatial relations. We show that such relations can capture notions of local rigidity. When co-occurrence and spatial relations are tree-structured, our model can be efficiently optimized with dynamic programming. We present experimental results on standard benchmarks for pose estimation that indicate our approach is the state-of-the-art system for pose estimation, outperforming past work by 50% while being orders of magnitude faster."
            },
            "slug": "Articulated-pose-estimation-with-flexible-Yang-Ramanan",
            "title": {
                "fragments": [],
                "text": "Articulated pose estimation with flexible mixtures-of-parts"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A general, flexible mixture model for capturing contextual co-occurrence relations between parts, augmenting standard spring models that encode spatial relations, and it is shown that such relations can capture notions of local rigidity."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119296787"
                        ],
                        "name": "Sam Johnson",
                        "slug": "Sam-Johnson",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sam Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7318714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c32715b5106f46eb6761531704cd2a9b5571832e",
            "isKey": false,
            "numCitedBy": 673,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the task of 2D articulated human pose estimation in unconstrained still images. This is extremely challenging because of variation in pose, anatomy, clothing, and imaging conditions. Current methods use simple models of body part appearance and plausible configurations due to limitations of available training data and constraints on computational expense. We show that such models severely limit accuracy. Building on the successful pictorial structure model (PSM) we propose richer models of both appearance and pose, using state-of-the-art discriminative classifiers without introducing unacceptable computational expense. We introduce a new annotated database of challenging consumer images, an order of magnitude larger than currently available datasets, and demonstrate over 50% relative improvement in pose estimation accuracy over a stateof-the-art method."
            },
            "slug": "Clustered-Pose-and-Nonlinear-Appearance-Models-for-Johnson-Everingham",
            "title": {
                "fragments": [],
                "text": "Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new annotated database of challenging consumer images is introduced, an order of magnitude larger than currently available datasets, and over 50% relative improvement in pose estimation accuracy over a state-of-the-art method is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299109"
                        ],
                        "name": "L. Pishchulin",
                        "slug": "L.-Pishchulin",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Pishchulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pishchulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49147969"
                        ],
                        "name": "Arjun Jain",
                        "slug": "Arjun-Jain",
                        "structuredName": {
                            "firstName": "Arjun",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arjun Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1906895"
                        ],
                        "name": "M. Andriluka",
                        "slug": "M.-Andriluka",
                        "structuredName": {
                            "firstName": "Mykhaylo",
                            "lastName": "Andriluka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andriluka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2543070"
                        ],
                        "name": "Thorsten Thorm\u00e4hlen",
                        "slug": "Thorsten-Thorm\u00e4hlen",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Thorm\u00e4hlen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thorsten Thorm\u00e4hlen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Torso prediction is done using the detector from [16] that we augment with a spatial prior learned on the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "Our approach performs slightly worse compared to our approach [16], where we extended the tree-structured pictorial structures model with additional repulsive factors between non-adjacent parts and a stronger torso detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "The extended model corresponds to \u201cours + [16]\u201d and achieves 66."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "We extend the approach in this paper with the repulsive factors and employ the same two-stage inference procedure as in [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15634635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25a7ea26685c856a10f47243e10c5f8be384d320",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art methods for human detection and pose estimation require many training samples for best performance. While large, manually collected datasets exist, the captured variations w.r.t. appearance, shape and pose are often uncontrolled thus limiting the overall performance. In order to overcome this limitation we propose a new technique to extend an existing training set that allows to explicitly control pose and shape variations. For this we build on recent advances in computer graphics to generate samples with realistic appearance and background while modifying body shape and pose. We validate the effectiveness of our approach on the task of articulated human detection and articulated pose estimation. We report close to state of the art results on the popular Image Parsing [25] human pose estimation benchmark and demonstrate superior performance for articulated human detection. In addition we define a new challenge of combined articulated human detection and pose estimation in real-world scenes."
            },
            "slug": "Articulated-people-detection-and-pose-estimation:-Pishchulin-Jain",
            "title": {
                "fragments": [],
                "text": "Articulated people detection and pose estimation: Reshaping the future"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a new technique to extend an existing training set that allows to explicitly control pose and shape variations and defines a new challenge of combined articulated human detection and pose estimation in real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9133363"
                        ],
                        "name": "Benjamin Sapp",
                        "slug": "Benjamin-Sapp",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Sapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Sapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053283925"
                        ],
                        "name": "Christopher T. Jordan",
                        "slug": "Christopher-T.-Jordan",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Jordan",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher T. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7492606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0206ebe8a7d587548ce8f4507ab919c43a369014",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Pictorial structure (PS) models are extensively used for part-based recognition of scenes, people, animals and multi-part objects. To achieve tractability, the structure and parameterization of the model is often restricted, for example, by assuming tree dependency structure and unimodal, data-independent pairwise interactions. These expressivity restrictions fail to capture important patterns in the data. On the other hand, local methods such as nearest-neighbor classification and kernel density estimation provide non-parametric flexibility but require large amounts of data to generalize well. We propose a simple semi-parametric approach that combines the tractability of pictorial structure inference with the flexibility of non-parametric methods by expressing a subset of model parameters as kernel regression estimates from a learned sparse set of exemplars. This yields query-specific, image-dependent pose priors. We develop an effective shape-based kernel for upper-body pose similarity and propose a leave-one-out loss function for learning a sparse subset of exemplars for kernel regression. We apply our techniques to two challenging datasets of human figure parsing and advance the state-of-the-art (from 80% to 86% on the Buffy dataset [8]), while using only 15% of the training data as exemplars."
            },
            "slug": "Adaptive-pose-priors-for-pictorial-structures-Sapp-Jordan",
            "title": {
                "fragments": [],
                "text": "Adaptive pose priors for pictorial structures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work develops an effective shape-based kernel for upper-body pose similarity and proposes a leave-one-out loss function for learning a sparse subset of exemplars for kernel regression estimates from a learned sparse set of exemplar."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9320620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55b29a2505149d06d8c1d616cd30edca40cb029c",
            "isKey": false,
            "numCitedBy": 1048,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the classic problems of detection, segmentation and pose estimation of people in images with a novel definition of a part, a poselet. We postulate two criteria (1) It should be easy to find a poselet given an input image (2) it should be easy to localize the 3D configuration of the person conditioned on the detection of a poselet. To permit this we have built a new dataset, H3D, of annotations of humans in 2D photographs with 3D joint information, inferred using anthropometric constraints. This enables us to implement a data-driven search procedure for finding poselets that are tightly clustered in both 3D joint configuration space as well as 2D image appearance. The algorithm discovers poselets that correspond to frontal and profile faces, pedestrians, head and shoulder views, among others. Each poselet provides examples for training a linear SVM classifier which can then be run over the image in a multiscale scanning mode. The outputs of these poselet detectors can be thought of as an intermediate layer of nodes, on top of which one can run a second layer of classification or regression. We show how this permits detection and localization of torsos or keypoints such as left shoulder, nose, etc. Experimental results show that we obtain state of the art performance on people detection in the PASCAL VOC 2007 challenge, among other datasets. We are making publicly available both the H3D dataset as well as the poselet parameters for use by other researchers."
            },
            "slug": "Poselets:-Body-part-detectors-trained-using-3D-pose-Bourdev-Malik",
            "title": {
                "fragments": [],
                "text": "Poselets: Body part detectors trained using 3D human pose annotations"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new dataset, H3D, is built of annotations of humans in 2D photographs with 3D joint information, inferred using anthropometric constraints, to address the classic problems of detection, segmentation and pose estimation of people in images with a novel definition of a part, a poselet."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718481"
                        ],
                        "name": "Min Sun",
                        "slug": "Min-Sun",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702137"
                        ],
                        "name": "S. Savarese",
                        "slug": "S.-Savarese",
                        "structuredName": {
                            "firstName": "Silvio",
                            "lastName": "Savarese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Savarese"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10906781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4a7c54390a3be6822e22e3ead0ad88399cbb188",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite recent successes, pose estimators are still somewhat fragile, and they frequently rely on a precise knowledge of the location of the object. Unfortunately, articulated objects are also very difficult to detect. Knowledge about the articulated nature of these objects, however, can substantially contribute to the task of finding them in an image. It is somewhat surprising, that these two tasks are usually treated entirely separately. In this paper, we propose an Articulated Part-based Model (APM) for jointly detecting objects and estimating their poses. APM recursively represents an object as a collection of parts at multiple levels of detail, from coarse-to-fine, where parts at every level are connected to a coarser level through a parent-child relationship (Fig. 1(b)-Horizontal). Parts are further grouped into part-types (e.g., left-facing head, long stretching arm, etc) so as to model appearance variations (Fig. 1(b)-Vertical). By having the ability to share appearance models of part types and by decomposing complex poses into parent-child pairwise relationships, APM strikes a good balance between model complexity and model richness. Extensive quantitative and qualitative experiment results on public datasets show that APM outperforms state-of-the-art methods. We also show results on PASCAL 2007 - cats and dogs - two highly challenging articulated object categories."
            },
            "slug": "Articulated-part-based-model-for-joint-object-and-Sun-Savarese",
            "title": {
                "fragments": [],
                "text": "Articulated part-based model for joint object detection and pose estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An Articulated Part-based Model for jointly detecting objects and estimating their poses is proposed and extensive quantitative and qualitative experiment results on public datasets show that APM outperforms state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9133363"
                        ],
                        "name": "Benjamin Sapp",
                        "slug": "Benjamin-Sapp",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Sapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Sapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064379349"
                        ],
                        "name": "David J. Weiss",
                        "slug": "David-J.-Weiss",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Weiss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 128
                            }
                        ],
                        "text": "Yet, several recent approaches considered nontree models that allow to capture cues such as appearance similarity between limbs [22, 23, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1439872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54cccfb90d24e383ca8bb6e786f907b0cfa23aa4",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of articulated human pose estimation in videos using an ensemble of tractable models with rich appearance, shape, contour and motion cues. In previous articulated pose estimation work on unconstrained videos, using temporal coupling of limb positions has made little to no difference in performance over parsing frames individually [8, 28]. One crucial reason for this is that joint parsing of multiple articulated parts over time involves intractable inference and learning problems, and previous work has resorted to approximate inference and simplified models. We overcome these computational and modeling limitations using an ensemble of tractable submodels which couple locations of body joints within and across frames using expressive cues. Each submodel is responsible for tracking a single joint through time (e.g., left elbow) and also models the spatial arrangement of all joints in a single frame. Because of the tree structure of each submodel, we can perform efficient exact inference and use rich temporal features that depend on image appearance, e.g., color tracking and optical flow contours. We propose and experimentally investigate a hierarchy of submodel combination methods, and we find that a highly efficient max-marginal combination method outperforms much slower (by orders of magnitude) approximate inference using dual decomposition. We apply our pose model on a new video dataset of highly varied and articulated poses from TV shows. We show significant quantitative and qualitative improvements over state-of-the-art single-frame pose estimation approaches."
            },
            "slug": "Parsing-human-motion-with-stretchable-models-Sapp-Weiss",
            "title": {
                "fragments": [],
                "text": "Parsing human motion with stretchable models"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This work addresses the problem of articulated human pose estimation in videos using an ensemble of tractable models with rich appearance, shape, contour and motion cues, and proposes and experimentally investigates a hierarchy of submodel combination methods."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119296787"
                        ],
                        "name": "Sam Johnson",
                        "slug": "Sam-Johnson",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sam Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1690193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50f3cd71a30ac6155e032c636d37d50e31cb09c2",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The task of 2-D articulated human pose estimation in natural images is extremely challenging due to the high level of variation in human appearance. These variations arise from different clothing, anatomy, imaging conditions and the large number of poses it is possible for a human body to take. Recent work has shown state-of-the-art results by partitioning the pose space and using strong nonlinear classifiers such that the pose dependence and multi-modal nature of body part appearance can be captured. We propose to extend these methods to handle much larger quantities of training data, an order of magnitude larger than current datasets, and show how to utilize Amazon Mechanical Turk and a latent annotation update scheme to achieve high quality annotations at low cost. We demonstrate a significant increase in pose estimation accuracy, while simultaneously reducing computational expense by a factor of 10, and contribute a dataset of 10,000 highly articulated poses."
            },
            "slug": "Learning-effective-human-pose-estimation-from-Johnson-Everingham",
            "title": {
                "fragments": [],
                "text": "Learning effective human pose estimation from inaccurate annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A significant increase in pose estimation accuracy is demonstrated, while simultaneously reducing computational expense by a factor of 10, and a dataset of10,000 highly articulated poses is contributed."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1906895"
                        ],
                        "name": "M. Andriluka",
                        "slug": "M.-Andriluka",
                        "structuredName": {
                            "firstName": "Mykhaylo",
                            "lastName": "Andriluka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andriluka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16956687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b8f87a454b80da5800337ccb5579cc7afbef45e",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider people detection and articulated pose estimation, two closely related and challenging problems in computer vision. Conceptually, both of these problems can be addressed within the pictorial structures framework (Felzenszwalb and Huttenlocher in Int. J. Comput. Vis. 61(1):55\u201379, 2005; Fischler and Elschlager in IEEE Trans. Comput. C-22(1):67\u201392, 1973), even though previous approaches have not shown such generality. A principal difficulty for such a general approach is to model the appearance of body parts. The model has to be discriminative enough to enable reliable detection in cluttered scenes and general enough to capture highly variable appearance. Therefore, as the first important component of our approach, we propose a discriminative appearance model based on densely sampled local descriptors and AdaBoost classifiers. Secondly, we interpret the normalized margin of each classifier as likelihood in a generative model and compute marginal posteriors for each part using belief propagation. Thirdly, non-Gaussian relationships between parts are represented as Gaussians in the coordinate system of the joint between the parts. Additionally, in order to cope with shortcomings of tree-based pictorial structures models, we augment our model with additional repulsive factors in order to discourage overcounting of image evidence. We demonstrate that the combination of these components within the pictorial structures framework results in a generic model that yields state-of-the-art performance for several datasets on a variety of tasks: people detection, upper body pose estimation, and full body pose estimation."
            },
            "slug": "Discriminative-Appearance-Models-for-Pictorial-Andriluka-Roth",
            "title": {
                "fragments": [],
                "text": "Discriminative Appearance Models for Pictorial Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The combination of these components within the pictorial structures framework results in a generic model that yields state-of-the-art performance for several datasets on a variety of tasks: people detection, upper body pose estimation, and full body Pose estimation."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273228"
                        ],
                        "name": "Catalin Ionescu",
                        "slug": "Catalin-Ionescu",
                        "structuredName": {
                            "firstName": "Catalin",
                            "lastName": "Ionescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catalin Ionescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141988"
                        ],
                        "name": "Fuxin Li",
                        "slug": "Fuxin-Li",
                        "structuredName": {
                            "firstName": "Fuxin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fuxin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8421376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb8a894914efa597f47f71ccc9968b9308048180",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for automatic 3D human pose reconstruction from monocular images, based on a discriminative formulation with latent segmentation inputs. We advanced the field of structured prediction and human pose reconstruction on several fronts. First, by working with a pool of figure-ground segment hypotheses, the prediction problem is formulated in terms of combined learning and inference over segment hypotheses and 3D human articular configurations. Beside constructing tractable formulations for the combined segment selection and pose estimation problem, we propose new augmented kernels that can better encode complex dependencies between output variables. Furthermore, we provide primal linear re-formulations based on Fourier kernel approximations, in order to scale-up the non-linear latent structured prediction methodology. The proposed models are shown to be competitive in the HumanEva benchmark and are also illustrated in a clip collected from a Hollywood movie, where the model can infer human poses from monocular images captured in complex environments."
            },
            "slug": "Latent-structured-models-for-human-pose-estimation-Ionescu-Li",
            "title": {
                "fragments": [],
                "text": "Latent structured models for human pose estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work presents an approach for automatic 3D human pose reconstruction from monocular images, based on a discriminative formulation with latent segmentation inputs, and provides primal linear re-formulations based on Fourier kernel approximations in order to scale-up the non-linear latent structured prediction methodology."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40277674"
                        ],
                        "name": "C. Desai",
                        "slug": "C.-Desai",
                        "structuredName": {
                            "firstName": "Chaitanya",
                            "lastName": "Desai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Desai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 149
                            }
                        ],
                        "text": "Our model is related to recent work aiming to increase the flexibility of the PS approach by jointly training a mixture of tree-structured PS models [14, 26, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9614716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eec68953568b1a184d6a6c41f1241fc95d4347b6",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to modeling human pose, together with interacting objects, based on compositional models of local visual interactions and their relations. Skeleton models, while flexible enough to capture large articulations, fail to accurately model self-occlusions and interactions. Poselets and Visual Phrases address this limitation, but do so at the expense of requiring a large set of templates. We combine all three approaches with a compositional model that is flexible enough to model detailed articulations but still captures occlusions and object interactions. Unlike much previous work on action classification, we do not assume test images are labeled with a person, and instead present results for \"action detection\" in an unlabeled image. Notably, for each detection, our model reports back a detailed description including an action label, articulated human pose, object poses, and occlusion flags. We demonstrate that modeling occlusion is crucial for recognizing human-object interactions. We present results on the PASCAL Action Classification challenge that shows our unified model advances the state-of-the-art for detection, action classification, and articulated pose estimation."
            },
            "slug": "Detecting-Actions,-Poses,-and-Objects-with-Desai-Ramanan",
            "title": {
                "fragments": [],
                "text": "Detecting Actions, Poses, and Objects with Relational Phraselets"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A novel approach to modeling human pose, together with interacting objects, based on compositional models of local visual interactions and their relations is presented, demonstrating that modeling occlusion is crucial for recognizing human-object interactions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46396571"
                        ],
                        "name": "Yang Wang",
                        "slug": "Yang-Wang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828154"
                        ],
                        "name": "Duan Tran",
                        "slug": "Duan-Tran",
                        "structuredName": {
                            "firstName": "Duan",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duan Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2928799"
                        ],
                        "name": "Zicheng Liao",
                        "slug": "Zicheng-Liao",
                        "structuredName": {
                            "firstName": "Zicheng",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zicheng Liao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2 and wp is the weighting parameter estimated on the validation set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 1
                            }
                        ],
                        "text": "A key challenge in designing models for pose estimation is thus to encode the higher-order part dependencies while still allowing efficient inference."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "For a reference body part, we cluster the relative positions of a subset of related body parts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "We phrase the PS model as a conditional random field (CRF), modelling the conditional probability of a body pose configuration given image evidence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Such a model structure inevitably introduces cycles and requires an approximate inference."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15097822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13784695d22601ac2e202e125e9bb00949e91d66",
            "isKey": true,
            "numCitedBy": 169,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of human parsing with part-based models. Most previous work in part-based models only considers rigid parts (e.g. torso, head, half limbs) guided by human anatomy. We argue that this representation of parts is not necessarily appropriate for human parsing. In this paper, we introduce hierarchical poselets\u2013a new representation for human parsing. Hierarchical poselets can be rigid parts, but they can also be parts that cover large portions of human bodies (e.g. torso + left arm). In the extreme case, they can be the whole bodies. We develop a structured model to organize poselets in a hierarchical way and learn the model parameters in a max-margin framework. We demonstrate the superior performance of our proposed approach on two datasets with aggressive pose variations."
            },
            "slug": "Learning-hierarchical-poselets-for-human-parsing-Wang-Tran",
            "title": {
                "fragments": [],
                "text": "Learning hierarchical poselets for human parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A structured model to organize poselets in a hierarchical way and learn the model parameters in a max-margin framework and demonstrates the superior performance of the proposed approach on two datasets with aggressive pose variations."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144277218"
                        ],
                        "name": "Kun Duan",
                        "slug": "Kun-Duan",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Duan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Duan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746610"
                        ],
                        "name": "Dhruv Batra",
                        "slug": "Dhruv-Batra",
                        "structuredName": {
                            "firstName": "Dhruv",
                            "lastName": "Batra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dhruv Batra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821130"
                        ],
                        "name": "David J. Crandall",
                        "slug": "David-J.-Crandall",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Crandall",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Crandall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9209108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8403a80743b6d96ee68bdca8e0958359b5a235c1",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new approach for part-based human pose estimation using multi-layer composite models, in which each layer is a tree-structured pictorial structure that models pose at a different scale and with a different graphical structure. At the highest level, the submodel acts as a person detector, while at the lowest level, the body is decomposed into a collection of many local parts. Edges between adjacent layers of the composite model encode cross-model constraints. This multi-layer composite model is able to relax the independence assumptions of traditional tree-structured pictorial-structure models while permitting efficient inference using dual-decomposition. We propose an optimization procedure for joint learning of the entire composite model. Our approach outperforms the state-of-the-art on the challenging Parse and UIUC Sport datasets."
            },
            "slug": "A-Multi-layer-Composite-Model-for-Human-Pose-Duan-Batra",
            "title": {
                "fragments": [],
                "text": "A Multi-layer Composite Model for Human Pose Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This multi-layer composite model is able to relax the independence assumptions of traditional tree-structured pictorial-structure models while permitting efficient inference using dual-decomposition and outperforms the state-of-the-art on the challenging Parse and UIUC Sport datasets."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984136"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": "However, in our work we perform classification on the level of each body joint which allows the set of pose classes to be exponentially large."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2887541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b51d606db06e178c5dff1e9d8c1460352bdb85db",
            "isKey": false,
            "numCitedBy": 835,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a learning-based method for recovering 3D human body pose from single images and monocular image sequences. Our approach requires neither an explicit body model nor prior labeling of body parts in the image. Instead, it recovers pose by direct nonlinear regression against shape descriptor vectors extracted automatically from image silhouettes. For robustness against local silhouette segmentation errors, silhouette shape is encoded by histogram-of-shape-contexts descriptors. We evaluate several different regression methods: ridge regression, relevance vector machine (RVM) regression, and support vector machine (SVM) regression over both linear and kernel bases. The RVMs provide much sparser regressors without compromising performance, and kernel bases give a small but worthwhile improvement in performance. The loss of depth and limb labeling information often makes the recovery of 3D pose from single silhouettes ambiguous. To handle this, the method is embedded in a novel regressive tracking framework, using dynamics from the previous state estimate together with a learned regression value to disambiguate the pose. We show that the resulting system tracks long sequences stably. For realism and good generalization over a wide range of viewpoints, we train the regressors on images resynthesized from real human motion capture data. The method is demonstrated for several representations of full body pose, both quantitatively on independent but similar test data and qualitatively on real image sequences. Mean angular errors of 4-6/spl deg/ are obtained for a variety of walking motions."
            },
            "slug": "Recovering-3D-human-pose-from-monocular-images-Agarwal-Triggs",
            "title": {
                "fragments": [],
                "text": "Recovering 3D human pose from monocular images"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A learning-based method for recovering 3D human body pose from single images and monocular image sequences, embedded in a novel regressive tracking framework, using dynamics from the previous state estimate together with a learned regression value to disambiguate the pose."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 169
                            }
                        ],
                        "text": "Note that for the task of people detection the best performing approaches are those which rely on a representation that jointly models appearance of multiple body parts [4, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "In order to satisfy these requirements we rely on the non-parametric poselet representation introduced in [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 918485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8d905b121e3e1f27d1f72195e27b7c8ac1a4386",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Bourdev and Malik (ICCV 09) introduced a new notion of parts, poselets, constructed to be tightly clustered both in the configuration space of keypoints, as well as in the appearance space of image patches. In this paper we develop a new algorithm for detecting people using poselets. Unlike that work which used 3D annotations of keypoints, we use only 2D annotations which are much easier for naive human annotators. The main algorithmic contribution is in how we use the pattern of poselet activations. Individual poselet activations are noisy, but considering the spatial context of each can provide vital disambiguating information, just as object detection can be improved by considering the detection scores of nearby objects in the scene. This can be done by training a two-layer feed-forward network with weights set using a max margin technique. The refined poselet activations are then clustered into mutually consistent hypotheses where consistency is based on empirically determined spatial keypoint distributions. Finally, bounding boxes are predicted for each person hypothesis and shape masks are aligned to edges in the image to provide a segmentation. To the best of our knowledge, the resulting system is the current best performer on the task of people detection and segmentation with an average precision of 47.8% and 40.5% respectively on PASCAL VOC 2009."
            },
            "slug": "Detecting-People-Using-Mutually-Consistent-Poselet-Bourdev-Maji",
            "title": {
                "fragments": [],
                "text": "Detecting People Using Mutually Consistent Poselet Activations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new algorithm for detecting people using poselets is developed which uses only 2D annotations which are much easier for naive human annotators and is the current best performer on the task of people detection and segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31786895"
                        ],
                        "name": "M. Eichner",
                        "slug": "M.-Eichner",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Eichner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Eichner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6198815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e9881380ba8a6d31deba615fe488ac6ef92fb2e",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "While human pose estimation (HPE) techniques usually process each test image independently, in real applications images come in collections containing interdependent images. Often several images have similar backgrounds or show persons wearing similar clothing (foreground). We present a novel human pose estimation technique to exploit these dependencies by sharing appearance models between images. Our technique automatically determines which images in the collection should share appearance. We extend the state-of-the art HPE model of Yang and Ramanan to include our novel appearance sharing cues and demonstrate on the highly challenging Leeds Sports Poses dataset that they lead to better results than traditional single-image pose estimation."
            },
            "slug": "Appearance-Sharing-for-Collective-Human-Pose-Eichner-Ferrari",
            "title": {
                "fragments": [],
                "text": "Appearance Sharing for Collective Human Pose Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The state-of-the art HPE model of Yang and Ramanan is extended to include the novel appearance sharing cues and these lead to better results than traditional single-image pose estimation on the highly challenging Leeds Sports Poses dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ACCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2277383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd9ab441df8b24f473a3635370c69620b00c1e60",
            "isKey": false,
            "numCitedBy": 2423,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images."
            },
            "slug": "Pictorial-Structures-for-Object-Recognition-Felzenszwalb-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Pictorial Structures for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A computationally efficient framework for part-based modeling and recognition of objects, motivated by the pictorial structure models introduced by Fischler and Elschlager, that allows for qualitative descriptions of visual appearance and is suitable for generic recognition problems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321919"
                        ],
                        "name": "Gr\u00e9gory Rogez",
                        "slug": "Gr\u00e9gory-Rogez",
                        "structuredName": {
                            "firstName": "Gr\u00e9gory",
                            "lastName": "Rogez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gr\u00e9gory Rogez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1856452"
                        ],
                        "name": "Jonathan Rihan",
                        "slug": "Jonathan-Rihan",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Rihan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Rihan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145686644"
                        ],
                        "name": "S. Ramalingam",
                        "slug": "S.-Ramalingam",
                        "structuredName": {
                            "firstName": "Srikumar",
                            "lastName": "Ramalingam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ramalingam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398367150"
                        ],
                        "name": "C. Orrite-Uru\u00f1uela",
                        "slug": "C.-Orrite-Uru\u00f1uela",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Orrite-Uru\u00f1uela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Orrite-Uru\u00f1uela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13351972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ab12d3270214cc1c327260ac0b26be544923bd8",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses human pose recognition from video sequences by formulating it as a classification problem. Unlike much previous work we do not make any assumptions on the availability of clean segmentation. The first step of this work consists in a novel method of aligning the training images using 3D Mocap data. Next we define classes by discretizing a 2D manifold whose two dimensions are camera viewpoint and actions. Our main contribution is a pose detection algorithm based on random forests. A bottom-up approach is followed to build a decision tree by recursively clustering and merging the classes at each level. For each node of the decision tree we build a list of potentially discriminative features using the alignment of training images; in this paper we consider Histograms of Orientated Gradient (HOG). We finally grow an ensemble of trees by randomly sampling one of the selected HOG blocks at each node. Our proposed approach gives promising results with both fixed and moving cameras."
            },
            "slug": "Randomized-trees-for-human-pose-detection-Rogez-Rihan",
            "title": {
                "fragments": [],
                "text": "Randomized trees for human pose detection"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper addresses human pose recognition from video sequences by formulating it as a classification problem and considers Histograms of Orientated Gradient (HOG), a pose detection algorithm based on random forests."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9981819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef9b6db5e02f1db18069cf8f42cd39c16446a740",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative approaches to human pose inference involve mapping visual observations to articulated body configurations. Current probabilistic approaches to learn this mapping have been limited in their ability to handle domains with a large number of activities that require very large training sets. We propose an online probabilistic regression scheme for efficient inference of complex, high- dimensional, and multimodal mappings. Our technique is based on a local mixture of Gaussian processes, where locality is defined based on both appearance and pose, and where the mapping hyperparameters can vary across local neighborhoods to better adapt to specific regions in the pose space. The mixture components are defined online in very small neighborhoods, so learning and inference is extremely efficient. When the mapping is one-to-one, we derive a bound on the approximation error of local regression (vs. global regression) for monotonically decreasing co- variance functions. Our method can determine when training examples are redundant given the rest of the database, and use this criteria for pruning. We report results on synthetic (Poser) and real (Humaneva) pose databases, obtaining fast and accurate pose estimates using training set sizes up to 105."
            },
            "slug": "Sparse-probabilistic-regression-for-human-pose-Urtasun-Darrell",
            "title": {
                "fragments": [],
                "text": "Sparse probabilistic regression for activity-independent human pose inference"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An online probabilistic regression scheme for efficient inference of complex, high- dimensional, and multimodal mappings, based on a local mixture of Gaussian processes, where locality is defined based on both appearance and pose, and where the mapping hyperparameters can vary across local neighborhoods to better adapt to specific regions in the pose space."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3198903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e79272fe3d65197100eae8be9fec6469107969ae",
            "isKey": false,
            "numCitedBy": 9374,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function."
            },
            "slug": "Object-Detection-with-Discriminatively-Trained-Part-Felzenszwalb-Girshick",
            "title": {
                "fragments": [],
                "text": "Object Detection with Discriminatively Trained Part Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An object detection system based on mixtures of multiscale deformable part models that is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828154"
                        ],
                        "name": "Duan Tran",
                        "slug": "Duan-Tran",
                        "structuredName": {
                            "firstName": "Duan",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duan Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 520,
                                "start": 516
                            }
                        ],
                        "text": "For evaluation we use the following publicly available pose estimation benchmarks exhibiting strong variations in articulation and viewpoint: the recently proposed \u201cLeeds Sports Poses\u201d (LSP) dataset [14] that includes 1000 images for training and 1000 for testing showing people involved in various sports; the \u201cImage Parsing\u201d (IP) [17] dataset consisting of 100 train images and 205 test images of fully visible people performing various activities such as sports, dancing and acrobatics; the \u201cUIUC People\u201d dataset [23] consisting of 346 training and 247 test images of people in highly variable body poses playing different sports such as Frisbee or badminton."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 150
                            }
                        ],
                        "text": "The second approach is to add more pairwise terms including non-adjacent body parts leading to a loopy part graph that requires approximate inference [2, 23, 21, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 128
                            }
                        ],
                        "text": "Yet, several recent approaches considered nontree models that allow to capture cues such as appearance similarity between limbs [22, 23, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15049670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "deae19c928571d3c1101660b0d643d7a7ee893b2",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We show quantitative evidence that a full relational model of the body performs better at upper body parsing than the standard tree model, despite the need to adopt approximate inference and learning procedures. Our method uses an approximate search for inference, and an approximate structure learning method to learn. We compare our method to state of the art methods on our dataset (which depicts a wide range of poses), on the standard Buffy dataset, and on the reduced PASCAL dataset published recently. Our results suggest that the Buffy dataset over emphasizes poses where the arms hang down, and that leads to generalization problems."
            },
            "slug": "Improved-Human-Parsing-with-a-Full-Relational-Model-Tran-Forsyth",
            "title": {
                "fragments": [],
                "text": "Improved Human Parsing with a Full Relational Model"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown quantitative evidence that a full relational model of the body performs better at upper body parsing than the standard tree model, despite the need to adopt approximate inference and learning procedures."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3394928"
                        ],
                        "name": "R. Elschlager",
                        "slug": "R.-Elschlager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Elschlager",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Elschlager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14554383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "719da2a0ddd38e78151e1cb2db31703ea8b2e490",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "slug": "The-Representation-and-Matching-of-Pictorial-Fischler-Elschlager",
            "title": {
                "fragments": [],
                "text": "The Representation and Matching of Pictorial Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The primary problem dealt with in this paper is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095482"
                        ],
                        "name": "T. Tian",
                        "slug": "T.-Tian",
                        "structuredName": {
                            "firstName": "Tai-Peng",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Yet, several recent approaches considered nontree models that allow to capture cues such as appearance similarity between limbs [22, 23, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9696478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "199aabb19ea78576a74d573739a7f35cf04fac6e",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an algorithm for recovering the globally optimal 2D human figure detection using a loopy graph model. This is computationally challenging because the time complexity scales exponentially in the size of the largest clique in the graph. The proposed algorithm uses Branch and Bound (BB) to search for the globally optimal solution. The algorithm converges rapidly in practice and this is due to a novel method for quickly computing tree based lower bounds. The key idea is to recycle the dynamic programming (DP) tables associated with the tree model to look up the tree based lower bound rather than recomputing the lower bound from scratch. This technique is further sped up using Range Minimum Query data structures to provide O(1) cost for computing the lower bound for most iterations of the BB algorithm. The algorithm is evaluated on the Iterative Parsing dataset and it is shown to run fast empirically."
            },
            "slug": "Fast-globally-optimal-2D-human-detection-with-loopy-Tian-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Fast globally optimal 2D human detection with loopy graph models"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An algorithm for recovering the globally optimal 2D human figure detection using a loopy graph model by recycling the dynamic programming tables associated with the tree model to look up the tree based lower bound rather than recomputing the lower bound from scratch."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40318952"
                        ],
                        "name": "L. Clemmensen",
                        "slug": "L.-Clemmensen",
                        "structuredName": {
                            "firstName": "Line",
                            "lastName": "Clemmensen",
                            "middleNames": [
                                "Harder"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Clemmensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115376"
                        ],
                        "name": "D. Witten",
                        "slug": "D.-Witten",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Witten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Witten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065245105"
                        ],
                        "name": "Bjarne K. Ersb\u00f8ll",
                        "slug": "Bjarne-K.-Ersb\u00f8ll",
                        "structuredName": {
                            "firstName": "Bjarne",
                            "lastName": "Ersb\u00f8ll",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bjarne K. Ersb\u00f8ll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "To this end we train a classifier using sparse linear discriminant analysis (SLDA) [6] on the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Similar to unary terms, we learn a SLDA classifier that predicts, given the feature f , into the set of clusters."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1322047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2648618ac4048ce2424cc8155dea0ee214ee7356",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of performing interpretable classification in the high-dimensional setting, in which the number of features is very large and the number of observations is limited. This setting has been studied extensively in the chemometrics literature, and more recently has become commonplace in biological and medical applications. In this setting, a traditional approach involves performing feature selection before classification. We propose sparse discriminant analysis, a method for performing linear discriminant analysis with a sparseness criterion imposed such that classification and feature selection are performed simultaneously. Sparse discriminant analysis is based on the optimal scoring interpretation of linear discriminant analysis, and can be extended to perform sparse discrimination via mixtures of Gaussians if boundaries between classes are nonlinear or if subgroups are present within each class. Our proposal also provides low-dimensional views of the discriminative directions."
            },
            "slug": "Sparse-Discriminant-Analysis-Clemmensen-Hastie",
            "title": {
                "fragments": [],
                "text": "Sparse Discriminant Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes sparse discriminantAnalysis, a method for performing linear discriminant analysis with a sparseness criterion imposed such that classification and feature selection are performed simultaneously in the high-dimensional setting."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123458029"
                        ],
                        "name": "J. Beard",
                        "slug": "J.-Beard",
                        "structuredName": {
                            "firstName": "Jill",
                            "lastName": "Beard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059774797"
                        ],
                        "name": "D. Ball",
                        "slug": "D.-Ball",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ball",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ball"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 110309864,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "b1137fd35c394ec8044ade93ec6fdbebf5b32bf3",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A 5.3 million pounds sterling refurbishment and new build library project was undertaken by Bournemouth University. First inception to latest adaptation spans 2000\u20132008. The project gave equal weight to the refurbishment and new build and the building was opened in 2003. The philosophy was one of seeking a design that would allow adaptation and change. Winning the SCONUL building award 2007 is testament to the success of designing and implementing space and service delivery in a way that is sympathetic to developing pedagogy, student expectations and the University's plans."
            },
            "slug": "Reshaping-the-Future-Beard-Ball",
            "title": {
                "fragments": [],
                "text": "Reshaping the Future"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "First we show the performance of our model assuming that the correct component for every potential is chosen by an oracle."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to parse images of articulated objects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 161
                            }
                        ],
                        "text": "The pairwise term is then a Gaussian on the difference vector between the two transformations Tmn(ln) \u2212 Tnm(lm), as is standard practice in all PS works [2, 3, 26, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "Most recent methods for human pose estimation are based on the pictorial structures (PS) model [12, 11] that represents the body configuration as a collection of rigid parts and a set of pairwise part connections."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pictorial structures for object recognition. IJCV'05"
            },
            "venue": {
                "fragments": [],
                "text": "Pictorial structures for object recognition. IJCV'05"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local probabilistic regression for activityindependent human pose inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to parse images of articulated objects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Articulated partbased model for joint object detection and pose estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 10,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Poselet-Conditioned-Pictorial-Structures-Pishchulin-Andriluka/ed662a8f1444578f6b4b47a3bb87e72b583d28b4?sort=total-citations"
}