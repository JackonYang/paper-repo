{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2910032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fa15f525a9814247ecd7cd93636f278d6d9ab3b",
            "isKey": false,
            "numCitedBy": 2521,
            "numCiting": 220,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides a comprehensive survey of the technical achievements in the research area of image retrieval, especially content-based image retrieval, an area that has been so active and prosperous in the past few years. The survey includes 100+ papers covering the research aspects of image feature representation and extraction, multidimensional indexing, and system design, three of the fundamental bases of content-based image retrieval. Furthermore, based on the state-of-the-art technology available now and the demand from real-world applications, open research issues are identified and future promising research directions are suggested."
            },
            "slug": "Image-Retrieval:-Current-Techniques,-Promising-and-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Current Techniques, Promising Directions, and Open Issues"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The survey includes 100+ papers covering the research aspects of image feature representation and extraction, multidimensional indexing, and system design, three of the fundamental bases of content-based image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2827898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b7c4096ed697696a5f4fc8f3a6a750dc0cdecfe",
            "isKey": false,
            "numCitedBy": 6727,
            "numCiting": 410,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap."
            },
            "slug": "Content-Based-Image-Retrieval-at-the-End-of-the-Smeulders-Worring",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval at the End of the Early Years"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap are discussed, as well as aspects of system engineering: databases, system architecture, and evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115686218"
                        ],
                        "name": "Ye Lu",
                        "slug": "Ye-Lu",
                        "structuredName": {
                            "firstName": "Ye",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ye Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716389"
                        ],
                        "name": "C. Hu",
                        "slug": "C.-Hu",
                        "structuredName": {
                            "firstName": "Chunhui",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116313118"
                        ],
                        "name": "Xingquan Zhu",
                        "slug": "Xingquan-Zhu",
                        "structuredName": {
                            "firstName": "Xingquan",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingquan Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 658477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1fadc4e802829c18adbcf154efffbdf35618089",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The relevance feedback approach to image retrieval is a powerful technique and has been an active research direction for the past few years. Various ad hoc parameter estimation techniques have been proposed for relevance feedback. In addition, methods that perform optimization on multi-level image content model have been formulated. However, these methods only perform relevance feedback on the low-level image features and fail to address the images' semantic content. In this paper, we propose a relevance feedback technique, iFind, to take advantage of the semantic contents of the images in addition to the low-level features. By forming a semantic network on top of the keyword association on the images, we are able to accurately deduce and utilize the images' semantic contents for retrieval purposes. The accuracy and effectiveness of our method is demonstrated with experimental results on real-world image collections."
            },
            "slug": "A-unified-framework-for-semantics-and-feature-based-Lu-Hu",
            "title": {
                "fragments": [],
                "text": "A unified framework for semantics and feature based relevance feedback in image retrieval systems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "iFind is a relevance feedback technique to take advantage of the semantic contents of the images in addition to the low-level features to accurately deduce and utilize the images' semantic contents for retrieval purposes."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934880"
                        ],
                        "name": "M. L. Kherfi",
                        "slug": "M.-L.-Kherfi",
                        "structuredName": {
                            "firstName": "Mohammed",
                            "lastName": "Kherfi",
                            "middleNames": [
                                "Lamine"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L. Kherfi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712019"
                        ],
                        "name": "D. Ziou",
                        "slug": "D.-Ziou",
                        "structuredName": {
                            "firstName": "Djemel",
                            "lastName": "Ziou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ziou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20394053"
                        ],
                        "name": "A. Bernardi",
                        "slug": "A.-Bernardi",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bernardi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17248708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aaad884f570bec9977cedc90714e58dc0f16d080",
            "isKey": false,
            "numCitedBy": 330,
            "numCiting": 151,
            "paperAbstract": {
                "fragments": [],
                "text": "With the explosive growth of the World Wide Web, the public is gaining access to massive amounts of information. However, locating needed and relevant information remains a difficult task, whether the information is textual or visual. Text search engines have existed for some years now and have achieved a certain degree of success. However, despite the large number of images available on the Web, image search engines are still rare. In this article, we show that in order to allow people to profit from all this visual information, there is a need to develop tools that help them to locate the needed images with good precision in a reasonable time, and that such tools are useful for many applications and purposes. The article surveys the main characteristics of the existing systems most often cited in the literature, such as ImageRover, WebSeek, Diogenes, and Atlas WISE. It then examines the various issues related to the design and implementation of a Web image search engine, such as data gathering and digestion, indexing, query specification, retrieval and similarity, Web coverage, and performance evaluation. A general discussion is given for each of these issues, with examples of the ways they are addressed by existing engines, and 130 related references are given. Some concluding remarks and directions for future research are also presented."
            },
            "slug": "Image-Retrieval-from-the-World-Wide-Web:-Issues,-Kherfi-Ziou",
            "title": {
                "fragments": [],
                "text": "Image Retrieval from the World Wide Web: Issues, Techniques, and Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that in order to allow people to profit from all this visual information, there is a need to develop tools that help them to locate the needed images with good precision in a reasonable time and that such tools are useful for many applications and purposes."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7838848"
                        ],
                        "name": "Weina Ge",
                        "slug": "Weina-Ge",
                        "structuredName": {
                            "firstName": "Weina",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weina Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "Net 1993], an approach that has been followed in [Datta et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": "As explored in [Datta et al. 2006], it is possible to effectively bridge the paradigms of keyword and contentbased search through a unified framework to provide the user the flexibility of both, without losing out on the search scope."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": "Image classification based on a generative model for the purpose of retrieval is explored in [Datta et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 85
                            }
                        ],
                        "text": "To this end, a recent attempt at bridging the retrieval-annotation gap has been made [Datta et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 138
                            }
                        ],
                        "text": "More recently, image annotation using a novel structure-composition model, and a WordNet-based word saliency measure has been proposed in [Datta et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 175
                            }
                        ],
                        "text": "What, in CBIR, is analogous to such ranking, given that a large subset of the images are determined to be semantically relevant ? This question has been recently addressed in [Datta et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In [Datta et al. 2006], probabilistic modeling of class-wise color segment interactions has been employed for the purpose of image categorization and retrieval, to reduce sensitivity to segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7044354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d81c9503f35ea60ca6f011086d41d4f12a1912a",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "While automatic image annotation remains an actively pursued research topic, enhancement of image search through its use has not been extensively explored. We propose an annotation-driven image retrieval approach and argue that under a number of different scenarios, this is very effective for semantically meaningful image search. In particular, our system is demonstrated to effectively handle cases of partially tagged and completely untagged image databases, multiple keyword queries, and example based queries with or without tags, all in near-realtime. Because our approach utilizes extra knowledge from a training dataset, it outperforms state-of-the-art visual similarity based retrieval techniques. For this purpose, a novel structure-composition model constructed from Beta distributions is developed to capture the spatial relationship among segmented regions of images. This model combined with the Gaussian mixture model produces scalable categorization of generic images. The categorization results are found to surpass previously reported results in speed and accuracy. Our novel annotation framework utilizes the categorization results to select tags based on term frequency, term saliency, and a WordNet-based measure of congruity, to boost salient tags while penalizing potentially unrelated ones. A bag of words distance measure based on WordNet is used to compute semantic similarity. The effectiveness of our approach is shown through extensive experiments."
            },
            "slug": "Toward-bridging-the-annotation-retrieval-gap-in-by-Datta-Ge",
            "title": {
                "fragments": [],
                "text": "Toward bridging the annotation-retrieval gap in image search by a generative modeling approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An annotation-driven image retrieval approach that is demonstrated to effectively handle cases of partially tagged and completely untagged image databases, multiple keyword queries, and example based queries with or without tags, all in near-realtime."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745185"
                        ],
                        "name": "Feng Jing",
                        "slug": "Feng-Jing",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49846744"
                        ],
                        "name": "Bo Zhang",
                        "slug": "Bo-Zhang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6310875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "345062b6f389dd99a36b98067a576195dfca3a21",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback and region-based representations are two effective ways to improve the accuracy of content-based image retrieval systems. Although these two techniques have been successfully investigated and developed in the last few years, little attention has been paid to combining them together. We argue that integrating these two approaches and allowing them to benefit from each other will yield better performance than using either of them alone. To do that, on the one hand, two relevance feedback algorithms are proposed based on region representations. One is inspired from the query point movement method. By assembling all of the segmented regions of positive examples together and reweighting the regions to emphasize the latest ones, a pseudo image is formed as the new query. An incremental clustering technique is also considered to improve the retrieval efficiency. The other is the introduction of existing support vector machine-based algorithms. A new kernel is proposed so as to enable the algorithms to be applicable to region-based representations. On the other hand, a rational region weighting scheme based on users' feedback information is proposed. The region weights that somewhat coincide with human perception not only can be used in a query session, but can also be memorized and accumulated for future queries. Experimental results on a database of 10 000 general-purpose images demonstrate the effectiveness of the proposed framework."
            },
            "slug": "Relevance-feedback-in-region-based-image-retrieval-Jing-Li",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in region-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work argues that integrating these two approaches and allowing them to benefit from each other will yield better performance than using either of them alone."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Circuits and Systems for Video Technology"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726249"
                        ],
                        "name": "T. Quack",
                        "slug": "T.-Quack",
                        "structuredName": {
                            "firstName": "Till",
                            "lastName": "Quack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Quack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23144093"
                        ],
                        "name": "Ullrich J. M\u00f6nich",
                        "slug": "Ullrich-J.-M\u00f6nich",
                        "structuredName": {
                            "firstName": "Ullrich",
                            "lastName": "M\u00f6nich",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ullrich J. M\u00f6nich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065641340"
                        ],
                        "name": "L. Thiele",
                        "slug": "L.-Thiele",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Thiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Thiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 104
                            }
                        ],
                        "text": "More recently, Cortina, a combined content-and metadata-based \nimage search engine has been made public [Quack et al. 2004]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13338212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f5104f5ad7e29d0782cda10e274fc87b89333bc",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in processing and networking capabilities of computers have led to an accumulation of immense amounts of multimedia data such as images. One of the largest repositories for such data is the World Wide Web (WWW). We present Cortina, a large-scale image retrieval system for the WWW. It handles over 3 million images to date. The system retrieves images based on visual features and collateral text. We show that a search process which consists of an initial query-by-keyword or query-by-image and followed by relevance feedback on the visual appearance of the results is possible for large-scale data sets. We also show that it is superior to the pure text retrieval commonly used in large-scale systems. Semantic relationships in the data are explored and exploited by data mining, and multiple feature spaces are included in the search process."
            },
            "slug": "Cortina:-a-system-for-large-scale,-content-based-Quack-M\u00f6nich",
            "title": {
                "fragments": [],
                "text": "Cortina: a system for large-scale, content-based web image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Cortina is presented, a large-scale image retrieval system for the WWW that retrieves images based on visual features and collateral text and is superior to the pure text retrieval commonly used in large- scale systems."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731570"
                        ],
                        "name": "M. Lew",
                        "slug": "M.-Lew",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lew",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143866184"
                        ],
                        "name": "E. Bakker",
                        "slug": "E.-Bakker",
                        "structuredName": {
                            "firstName": "Erwin",
                            "lastName": "Bakker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bakker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5371770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "408d4796b821fb00fe81802c5538710d242c018d",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Image and video retrieval continues to be one of the most exciting and fastest-growing research areas in the field of multimedia technology. What are the main challenges in image and video retrieval? Despite the sustained efforts in the last years, we think that the paramount challenge remains bridging the semantic gap. By this we mean that low level features are easily measured and computed, but the starting point of the retrieval process is typically the high level query from a human. Translating or converting the question posed by a human to the low level features seen by the computer illustrates the problem in bridging the semantic gap. However, the semantic gap is not merely translating high level features to low level features. The essence of a semantic query is understanding the meaning behind the query. This can involve understanding both the intellectual and emotional sides of the human, not merely the distilled logical portion of the query but also the personal preferences and emotional subtons of the query and the preferential form of the results."
            },
            "slug": "The-State-of-the-Art-in-Image-and-Video-Retrieval-Sebe-Lew",
            "title": {
                "fragments": [],
                "text": "The State of the Art in Image and Video Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work thinks that the paramount challenge in image and video retrieval remains bridging the semantic gap, which means that low level features are easily measured and computed, but the starting point of the retrieval process is typically the high level query from a human."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146356312"
                        ],
                        "name": "Junwei Han",
                        "slug": "Junwei-Han",
                        "structuredName": {
                            "firstName": "Junwei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junwei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684869"
                        ],
                        "name": "K. Ngan",
                        "slug": "K.-Ngan",
                        "structuredName": {
                            "firstName": "King",
                            "lastName": "Ngan",
                            "middleNames": [
                                "Ngi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ngan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17440809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40ebc4dea656a0afab617fa690c8f0a88b01f877",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current content-based image retrieval systems are still incapable of providing users with their desired results. The major difficulty lies in the gap between low-level image features and high-level image semantics. To address the problem, this study reports a framework for effective image retrieval by employing a novel idea of memory learning. It forms a knowledge memory model to store the semantic information by simply accumulating user-provided interactions. A learning strategy is then applied to predict the semantic relationships among images according to the memorized knowledge. Image queries are finally performed based on a seamless combination of low-level features and learned semantics. One important advantage of our framework is its ability to efficiently annotate images and also propagate the keyword annotation from the labeled images to unlabeled images. The presented algorithm has been integrated into a practical image retrieval system. Experiments on a collection of 10 000 general-purpose images demonstrate the effectiveness of the proposed framework."
            },
            "slug": "A-memory-learning-framework-for-effective-image-Han-Ngan",
            "title": {
                "fragments": [],
                "text": "A memory learning framework for effective image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A framework for effective image retrieval is reported by employing a novel idea of memory learning that forms a knowledge memory model to store the semantic information by simply accumulating user-provided interactions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3878480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f762a30f17a3a1e2844d2c919491bd846e476657",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Combining learning with vision techniques in interactive image retrieval has been an active research topic during the past few years. However, existing learning techniques either are based on heuristics or fail to analyze the working conditions. Furthermore, there is almost no in depth study on how to effectively learn from the users when there are multiple visual features in the retrieval system. To address these limitations, in this paper we present a vigorous optimization formulation of the learning process and solve the problem in a principled way. By using Lagrange multipliers, we have derived explicit solutions, which are both optimal and fast to compute. Extensive comparisons against state-of-the-art techniques have been performed. Experiments were carried out on a large-size heterogeneous image collection consisting of 17,000 images. Retrieval performance was tested under a wide range of conditions. Various evaluation criteria, including precision-recall curve and rank measure, have demonstrated the effectiveness and robustness of the proposed technique."
            },
            "slug": "Optimizing-learning-in-image-retrieval-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Optimizing learning in image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A vigorous optimization formulation of the learning process is presented and explicit solutions, which are both optimal and fast to compute, are derived by using Lagrange multipliers are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687433"
                        ],
                        "name": "Deok\u2010Hwan Kim",
                        "slug": "Deok\u2010Hwan-Kim",
                        "structuredName": {
                            "firstName": "Deok\u2010Hwan",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deok\u2010Hwan Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733783"
                        ],
                        "name": "C. Chung",
                        "slug": "C.-Chung",
                        "structuredName": {
                            "firstName": "Chin-Wan",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1407365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04b7033586885677248dce7daef0233c321efbdc",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The learning-enhanced relevance feedback has been one of the most active research areas in content-based image retrieval in recent years. However, few methods using the relevance feedback are currently available to process relatively complex queries on large image databases. In the case of complex image queries, the feature space and the distance function of the user's perception are usually different from those of the system. This difference leads to the representation of a query with multiple clusters (i.e., regions) in the feature space. Therefore, it is necessary to handle disjunctive queries in the feature space.In this paper, we propose a new content-based image retrieval method using adaptive classification and cluster-merging to find multiple clusters of a complex image query. When the measures of a retrieval method are invariant under linear transformations, the method can achieve the same retrieval quality regardless of the shapes of clusters of a query. Our method achieves the same high retrieval quality regardless of the shapes of clusters of a query since it uses such measures. Extensive experiments show that the result of our method converges to the user's true information need fast, and the retrieval quality of our method is about 22% in recall and 20% in precision better than that of the query expansion approach, and about 34% in recall and about 33% in precision better than that of the query point movement approach, in MARS."
            },
            "slug": "QCluster:-relevance-feedback-using-adaptive-for-Kim-Chung",
            "title": {
                "fragments": [],
                "text": "QCluster: relevance feedback using adaptive clustering for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a new content-based image retrieval method using adaptive classification and cluster-merging to find multiple clusters of a complex image query when the measures of a retrieval method are invariant under linear transformations, and the method can achieve the same retrieval quality regardless of the shapes of clusters of the query."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401302503"
                        ],
                        "name": "Michael Ortega-Binderberger",
                        "slug": "Michael-Ortega-Binderberger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ortega-Binderberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ortega-Binderberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144156242"
                        ],
                        "name": "S. Mehrotra",
                        "slug": "S.-Mehrotra",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mehrotra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3888393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "460c7b1c0d13a403b3a25a31a86692bb0443002b",
            "isKey": false,
            "numCitedBy": 2027,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval (CBIR) has become one of the most active research areas in the past few years. Many visual feature representations have been explored and many systems built. While these research efforts establish the basis of CBIR, the usefulness of the proposed approaches is limited. Specifically, these efforts have relatively ignored two distinct characteristics of CBIR systems: (1) the gap between high-level concepts and low-level features, and (2) the subjectivity of human perception of visual content. This paper proposes a relevance feedback based interactive retrieval approach, which effectively takes into account the above two characteristics in CBIR. During the retrieval process, the user's high-level query and perception subjectivity are captured by dynamically updated weights based on the user's feedback. The experimental results over more than 70000 images show that the proposed approach greatly reduces the user's effort of composing a query, and captures the user's information need more precisely."
            },
            "slug": "Relevance-feedback:-a-power-tool-for-interactive-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Relevance feedback: a power tool for interactive content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A relevance feedback based interactive retrieval approach that effectively takes into account the subjectivity of human perception of visual content and the gap between high-level concepts and low-level features in CBIR."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7692065"
                        ],
                        "name": "K. Tieu",
                        "slug": "K.-Tieu",
                        "structuredName": {
                            "firstName": "Kinh",
                            "lastName": "Tieu",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 85
                            }
                        ],
                        "text": "Some of the other recent, \nmore generic feature selection proposals involve boosting [Tieu and Viola 2004], evolutionary searching \n[Kim et al. 2000], Bayes classi.cation error [Carneiro and Vasconcelos 2005], and feature dependency/similarity \nmeasures [Mitra et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 87
                            }
                        ],
                        "text": "Some of the other recent, more generic feature selection propositions involve boosting [Tieu and Viola 2004], evolutionary searching [Kim et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 510936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bab4b6bbd10d264caf9ac01b79750d113efe03bd",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for image retrieval using a very large number of highly selective features and efficient learning of queries. Our approach is predicated on the assumption that each image is generated by a sparse set of visual \u201ccauses\u201d and that images which are visually similar share causes. We propose a mechanism for computing a very large number of highly selective features which capture some aspects of this causal structure (in our implementation there are over 46,000 highly selective features). At query time a user selects a few example images, and the AdaBoost algorithm is used to learn a classification function which depends on a small number of the most appropriate features. This yields a highly efficient classification function. In addition we show that the AdaBoost framework provides a natural mechanism for the incorporation of relevance feedback. Finally we show results on a wide variety of image queries."
            },
            "slug": "Boosting-Image-Retrieval-Tieu-Viola",
            "title": {
                "fragments": [],
                "text": "Boosting Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work proposes a mechanism for computing a very large number of highly selective features which capture some aspects of this causal structure and shows results on a wide variety of image queries."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151194032"
                        ],
                        "name": "H. M\u00fcller",
                        "slug": "H.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Henning",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145866011"
                        ],
                        "name": "W. M\u00fcller",
                        "slug": "W.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760329"
                        ],
                        "name": "D. Squire",
                        "slug": "D.-Squire",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Squire",
                            "middleNames": [
                                "McG."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Squire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398659765"
                        ],
                        "name": "S. Marchand-Maillet",
                        "slug": "S.-Marchand-Maillet",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Marchand-Maillet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marchand-Maillet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809085"
                        ],
                        "name": "T. Pun",
                        "slug": "T.-Pun",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Pun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 65
                            }
                        ],
                        "text": "A comprehensive overview of benchmarking in CBIR can be found in [Muller et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13096664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90c7798c0a1168ff96e68f19e53ec733da74e2ba",
            "isKey": false,
            "numCitedBy": 634,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Performance-evaluation-in-content-based-image-and-M\u00fcller-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Performance evaluation in content-based image retrieval: overview and proposals"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683311"
                        ],
                        "name": "M. Nakazato",
                        "slug": "M.-Nakazato",
                        "structuredName": {
                            "firstName": "Munehiro",
                            "lastName": "Nakazato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nakazato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804874"
                        ],
                        "name": "Charlie K. Dagli",
                        "slug": "Charlie-K.-Dagli",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Dagli",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie K. Dagli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 82
                            }
                        ],
                        "text": "Surveys also exist on closely related \ntopics such as relevance feedback [Zhou and Huang 2003], high-dimensional indexing of multimedia data \n[Bohm et al. 2001], face recognition [Zhao et al. 2003] (useful for face-based image retrieval), applications \nof CBIR to medicine [Muller et al. 2004], and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 915746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da2c1c1e1ff63c9c47395e450835e8063ed44edc",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "New relevance feedback algorithms have been developed for content-based image retrieval (CBIR) that allow the user to achieve more flexible query. In conjunction with the new user interface, called group-oriented user interface, the user's interest can be expressed with multiple groups of positive and negative image examples. This provides users with greater flexibility as compared with previous systems that consider image query as one or two-class problems. In this paper, we analyze our new algorithm qualitatively and quantitatively. For comparison with previous approaches, the systems are tested on both toy problems and real image retrieval tasks. From the results of our experiments, we suggest when and how our algorithm has advantages over the previous methods."
            },
            "slug": "Evaluating-group-based-relevance-feedback-for-image-Nakazato-Dagli",
            "title": {
                "fragments": [],
                "text": "Evaluating group-based relevance feedback for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper analyzes a new relevance feedback algorithm for content-based image retrieval, called group-oriented user interface, and suggests when and how the algorithm has advantages over the previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804874"
                        ],
                        "name": "Charlie K. Dagli",
                        "slug": "Charlie-K.-Dagli",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Dagli",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie K. Dagli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10917455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efe1e06e7921513e1939be16ca8a9b353188fb33",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a grid-based framework for image retrieval. In order to represent the intricate composition of images, the grid-based approach partitions each image into blocks from which a feature representation is derived from the local low-level content. Since the background often dominates the subject in the foreground, a special query selection method was developed. It combines the salient region-of-interest/query-by-example paradigm with coarse segmentation to remove the irrelevant background regions. The proposed search method looks for similar features across all block positions and at several scales. Existing local grid-based methods are constrained by searching for objects in the same position as the query object. Using this framework, the spatial constraint can be eliminated, and steps toward scale invariance can be taken. Promising results show that the grid-based method performs better than global search."
            },
            "slug": "A-framework-for-grid-based-image-retrieval-Dagli-Huang",
            "title": {
                "fragments": [],
                "text": "A framework for grid-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A grid-based framework for image retrieval that combines the salient region-of-interest/query-by-example paradigm with coarse segmentation to remove the irrelevant background regions and looks for similar features across all block positions and at several scales."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679686"
                        ],
                        "name": "R. Torres",
                        "slug": "R.-Torres",
                        "structuredName": {
                            "firstName": "Ricardo",
                            "lastName": "Torres",
                            "middleNames": [
                                "da",
                                "Silva"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Torres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109915091"
                        ],
                        "name": "C. G. Silva",
                        "slug": "C.-G.-Silva",
                        "structuredName": {
                            "firstName": "Celmar",
                            "lastName": "Silva",
                            "middleNames": [
                                "Guimar\u00e3es",
                                "da"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802371"
                        ],
                        "name": "C. B. Medeiros",
                        "slug": "C.-B.-Medeiros",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Medeiros",
                            "middleNames": [
                                "Bauzer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. B. Medeiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153139816"
                        ],
                        "name": "Heloisa Vieira da Rocha",
                        "slug": "Heloisa-Vieira-da-Rocha",
                        "structuredName": {
                            "firstName": "Heloisa Vieira da",
                            "lastName": "Rocha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heloisa Vieira da Rocha"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 154
                            }
                        ],
                        "text": "Thinking beyond the typical grid-based arrangement of top matching images, spiral and concentric visualization of retrieval results have been explored in [Torres et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3588803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4ac0407738ef286b27d8af93e5229206b64c1fb",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-Based Image Retrieval (CBIR) presents several challenges and has been subject to extensive research from many domains, such as image processing or database systems. Database researchers are concerned with indexing and querying, whereas image processing experts worry about extracting appropriate image descriptors. Comparatively little work has been done on designing user interfaces for CBIR systems. This, in turn, has a profound effect on these systems since the concept of image similarity is strongly influenced by user perception. This paper describes an initial effort to fill this gap, combining recent research in CBIR and Information Visualization, studied from a Human-Computer Interface perspective. It presents two visualization techniques based on Spiral and Concentric Rings implemented in a CBIR system to explore query results. The approach is centered on keeping user focus on both the query image, and the most similar retrieved images. Experiments conducted so far suggest that the proposed visualization strategies improves system usability."
            },
            "slug": "Visual-structures-for-image-browsing-Torres-Silva",
            "title": {
                "fragments": [],
                "text": "Visual structures for image browsing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper presents two visualization techniques based on Spiral and Concentric Rings implemented in a CBIR system to explore query results, centered on keeping user focus on both the query image, and the most similar retrieved images."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125542987"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17632661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bdd0753190024c0338a03d108ca82976b603ba8",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-scale image retrieval system is developed to provide efficient search in large-scale databases as well as flexibility for users to incorporate ubjective preferences during retrieval. A new clustering method is developed for images each characterized by a varying number of weighted feature vectors. Furthermore, significant meta-information is mined within every cluster. A scanning mode of retrieval is created using cluster centers, which serve as a low scale version of a database in contrast to original images. In particular, users are presented with representative images of highly ranked clusters along with prominent meta-information. This retrieval approach enables users to quickly examine a large and diverse portion of a database surrounding a query and to learn about hidden connections between visual patterns and non-imagery types of data. The clusters formed also facilitate fast search in the case of individual image-based retrieval by filtering out images whose cluster centers are far from the query. The two-scale retrieval system has been implemented on a fine art painting database. Advantages of the system have been demonstrated by quantitative evaluation of the retrieval performance."
            },
            "slug": "Two-scale-image-retrieval-with-significant-feedback-Li",
            "title": {
                "fragments": [],
                "text": "Two-scale image retrieval with significant meta-information feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A two-scale image retrieval system is developed to provide efficient search in large-scale databases as well as flexibility for users to incorporate ubjective preferences during retrieval to learn about hidden connections between visual patterns and non-imagery types of data."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745185"
                        ],
                        "name": "Feng Jing",
                        "slug": "Feng-Jing",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49846744"
                        ],
                        "name": "Bo Zhang",
                        "slug": "Bo-Zhang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14890038,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "a4b2233f28cb75860193f67d875884418f64788c",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a unified image retrieval framework based on both keyword annotations and visual features is proposed. In this framework, a set of statistical models are built based on visual features of a small set of manually labeled images to represent semantic concepts and used to propagate keywords to other unlabeled images. These models are updated periodically when more images implicitly labeled by users become available through relevance feedback. In this sense, the keyword models serve the function of accumulation and memorization of knowledge learned from user-provided relevance feedback. Furthermore, two sets of effective and efficient similarity measures and relevance feedback schemes are proposed for query by keyword scenario and query by image example scenario, respectively. Keyword models are combined with visual features in these schemes. In particular, a new, entropy-based active learning strategy is introduced to improve the efficiency of relevance feedback for query by keyword. Furthermore, a new algorithm is proposed to estimate the keyword features of the search concept for query by image example. It is shown to be more appropriate than two existing relevance feedback algorithms. Experimental results demonstrate the effectiveness of the proposed framework."
            },
            "slug": "A-unified-framework-for-image-retrieval-using-and-Jing-Li",
            "title": {
                "fragments": [],
                "text": "A unified framework for image retrieval using keyword and visual features"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "In this paper, a unified image retrieval framework based on both keyword annotations and visual features is proposed, and a new, entropy-based active learning strategy is introduced to improve the efficiency of relevance feedback for query by keyword."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143701488"
                        ],
                        "name": "Bin Gao",
                        "slug": "Bin-Gao",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110264337"
                        ],
                        "name": "Tie-Yan Liu",
                        "slug": "Tie-Yan-Liu",
                        "structuredName": {
                            "firstName": "Tie-Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tie-Yan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826487"
                        ],
                        "name": "T. Qin",
                        "slug": "T.-Qin",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Qin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Qin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110134649"
                        ],
                        "name": "Xin Zheng",
                        "slug": "Xin-Zheng",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758097"
                        ],
                        "name": "Qiansheng Cheng",
                        "slug": "Qiansheng-Cheng",
                        "structuredName": {
                            "firstName": "Qiansheng",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiansheng Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 926315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ca9b9f70575f874fe0115c28f6b4e235b304723",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Image clustering, an important technology for image processing, has been actively researched for a long period of time. Especially in recent years, with the explosive growth of the Web, image clustering has even been a critical technology to help users digest the large amount of online visual information. However, as far as we know, many previous works on image clustering only used either low-level visual features or surrounding texts, but rarely exploited these two kinds of information in the same framework. To tackle this problem, we proposed a novel method named consistent bipartite graph co-partitioning in this paper, which can cluster Web images based on the consistent fusion of the information contained in both low-level features and surrounding texts. In particular, we formulated it as a constrained multi-objective optimization problem, which can be efficiently solved by semi-definite programming (SDP). Experiments on a real-world Web image collection showed that our proposed method outperformed the methods only based on low-level features or surround texts."
            },
            "slug": "Web-image-clustering-by-consistent-utilization-of-Gao-Liu",
            "title": {
                "fragments": [],
                "text": "Web image clustering by consistent utilization of visual features and surrounding texts"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel method named consistent bipartite graph co-partitioning is proposed, which can cluster Web images based on the consistent fusion of the information contained in both low-level features and surrounding texts and can be efficiently solved by semi-definite programming (SDP)."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710961"
                        ],
                        "name": "B. Smolka",
                        "slug": "B.-Smolka",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Smolka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Smolka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121593"
                        ],
                        "name": "M. Szczepa\u0144ski",
                        "slug": "M.-Szczepa\u0144ski",
                        "structuredName": {
                            "firstName": "Marek",
                            "lastName": "Szczepa\u0144ski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szczepa\u0144ski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716010"
                        ],
                        "name": "R. Lukac",
                        "slug": "R.-Lukac",
                        "structuredName": {
                            "firstName": "Rastislav",
                            "lastName": "Lukac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lukac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707519"
                        ],
                        "name": "A. Venetsanopoulos",
                        "slug": "A.-Venetsanopoulos",
                        "structuredName": {
                            "firstName": "Anastasios",
                            "lastName": "Venetsanopoulos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Venetsanopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14149010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a09466b37ec4df3a6089f6993bce377bc52679fe",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The rapid growth of image archives increases the need for efficient and fast tools that can retrieve and search through a large amount of visual data. In this paper, we propose an efficient method of extracting the image color content, which serves as an image digital signature, allowing us to efficiently index and retrieve the content of large, heterogeneous multimedia Internet based databases. We apply the proposed method for the retrieval of images from the WEBMUSEUM Internet database, containing a collection of fine art images and show that the new method of image color representation is robust to image distorsions caused by resizing and compression and can be incorporated into existing retrieval systems which exploit the information on color content in digital images."
            },
            "slug": "Robust-color-image-retrieval-for-the-World-Wide-Web-Smolka-Szczepa\u0144ski",
            "title": {
                "fragments": [],
                "text": "Robust color image retrieval for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An efficient method of extracting the image color content, which serves as an image digital signature, is proposed, allowing us to efficiently index and retrieve the content of large, heterogeneous multimedia Internet based databases."
            },
            "venue": {
                "fragments": [],
                "text": "2004 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37395525"
                        ],
                        "name": "Jingrui He",
                        "slug": "Jingrui-He",
                        "structuredName": {
                            "firstName": "Jingrui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingrui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8163721"
                        ],
                        "name": "Hanghang Tong",
                        "slug": "Hanghang-Tong",
                        "structuredName": {
                            "firstName": "Hanghang",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanghang Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14966740"
                        ],
                        "name": "Changshui Zhang",
                        "slug": "Changshui-Zhang",
                        "structuredName": {
                            "firstName": "Changshui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changshui Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "this is to learn a generalized Mahalanobis distance metric, such as the general-purpose methods proposed in Xing et al. [2003] and Bar-Hillel et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 317,
                                "start": 108
                            }
                        ],
                        "text": "this is to learn a generalized Mahalanobis distance metric, such as the general-purpose methods proposed in Xing et al. [2003] and Bar-Hillel et al. [2005]. On the other hand, kernel-based learning of image similarity, using context information, with applications to image clustering was explored in Wu et al. [2005]. This method could potentially be used for more generic cases of metric learning when given side-information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 108
                            }
                        ],
                        "text": "this is to learn a generalized Mahalanobis distance metric, such as the general-purpose methods proposed in Xing et al. [2003] and Bar-Hillel et al. [2005]. On the other hand, kernel-based learning of image similarity, using context information, with applications to image clustering was explored in Wu et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 757348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a355e9cfd2d60ce2364f579340fe65077ce8629",
            "isKey": true,
            "numCitedBy": 45,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In content-based image retrieval, relevance feedback has been introduced to narrow the gap between low-level image feature and high-level semantic concept. Furthermore, to speed up the convergence to the query concept, several active learning methods have been proposed instead of random sampling to select images for labeling by the user. In this paper, we propose a novel active learning method named mean version space, aiming to select the optimal image in each round of relevance feedback. Firstly, by diving into the lemma that motivates support vector machine active learning method (SVM<i><inf>active</inf></i>), we come up with a new criterion which is tailored for each specific learning task and will lead to the fastest shrinkage of the version space in all cases. The criterion takes both the size of the version space and the posterior probabilities into consideration, while existing methods are only based on one of them. Moreover, although our criterion is designed for SVM, it can be justified in a general framework. Secondly, to reduce processing time, we design two schemes to construct a small candidate set and evaluate the criterion for images in the set instead of all the unlabeled images. Systematic experimental results demonstrate the superiority of our method over existing active learning methods"
            },
            "slug": "Mean-version-space:-a-new-active-learning-method-He-Tong",
            "title": {
                "fragments": [],
                "text": "Mean version space: a new active learning method for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a novel active learning method named mean version space, aiming to select the optimal image in each round of relevance feedback, and proposes a new criterion which will lead to the fastest shrinkage of the version space in all cases."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144156242"
                        ],
                        "name": "S. Mehrotra",
                        "slug": "S.-Mehrotra",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mehrotra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3852078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74dffa61d7039fadc70bd92284960e78681707ba",
            "isKey": false,
            "numCitedBy": 893,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Technology advances in the areas of image processing (IP) and information retrieval (IR) have evolved separately for a long time. However, successful content-based image retrieval systems require the integration of the two. There is an urgent need to develop integration mechanisms to link the image retrieval model to text retrieval model, such that the well established text retrieval techniques can be utilized. Approaches of converting image feature vectors (IF domain) to weighted-term vectors (IR domain) are proposed in this paper. Furthermore, the relevance feedback technique from the IR domain is used in content-based image retrieval to demonstrate the effectiveness of this conversion. Experimental results show that the image retrieval precision increases considerably by using the proposed integration approach."
            },
            "slug": "Content-based-image-retrieval-with-relevance-in-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Content-based image retrieval with relevance feedback in MARS"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results show that the image retrieval precision increases considerably by using the proposed integration approach, and the relevance feedback technique from the IR domain is used in content-based image retrieval to demonstrate the effectiveness of this conversion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901762"
                        ],
                        "name": "D. P. Huijsmans",
                        "slug": "D.-P.-Huijsmans",
                        "structuredName": {
                            "firstName": "Dionysius",
                            "lastName": "Huijsmans",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. P. Huijsmans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9486078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbf1a099933bdfa7a63a8a387be0e399aadc4469",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of a content-based image retrieval (CBIR) system, presented in the form of precision-recall or precision-scope graphs, offers an incomplete overview of the system under study: the influence of the irrelevant items (embedding) is obscured. We propose a comprehensive and well-normalized description of the ranking performance compared to the performance of an ideal retrieval system defined by ground-truth for a large number of predefined queries. We advocate normalization with respect to relevant class size and restriction to specific normalized scope values (the number of retrieved items). We also propose new three and two-dimensional performance graphs for total recall studies in a range of embeddings."
            },
            "slug": "How-to-complete-performance-graphs-in-content-based-Huijsmans-Sebe",
            "title": {
                "fragments": [],
                "text": "How to complete performance graphs in content-based image retrieval: add generality and normalize scope"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A comprehensive and well-normalized description of the ranking performance compared to the performance of an ideal retrieval system defined by ground-truth for a large number of predefined queries is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151194032"
                        ],
                        "name": "H. M\u00fcller",
                        "slug": "H.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Henning",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398659765"
                        ],
                        "name": "S. Marchand-Maillet",
                        "slug": "S.-Marchand-Maillet",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Marchand-Maillet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marchand-Maillet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809085"
                        ],
                        "name": "T. Pun",
                        "slug": "T.-Pun",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Pun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 60
                            }
                        ],
                        "text": "The pitfalls of using Corel pictures have been discussed in [Muller et al. 2002], and a more rigorous CBIR benchmarking is suggested."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13507478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8d5814e795b1a9ea7c1b5652d03b572ee418c98",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "To demonstrate the performance of content-based image retrieval systems (CBIRSs), there is not yet any standard data set that is widely used. The only dataset used by a large number of research groups are the Corel Photo CDs. There are more than 800 of those CDs, each containing 100 pictures roughly similar in theme. Unfortunately, basically every evaluation is done on a different subset of the image sets thus making comparison impossible.In this article, we compare different ways of evaluating the performance using a subset of the Corel images with the same CBIRSan d the same set of evaluation measures. The aim is to show how easy it is to get differing results, even when using the same image collection, the same CBIRS and the same performance measures. This pinpoints the fact that we need a standard database of images with a query set and corresponding relevance judgments (RJs) to really compare systems.The techniques used in this article to \"enhance\" the apparent performance of a CBIRSa re commonly used, sometimes described, sometimes not. They all have a justification and seem to change the performance of a CBIRS but they do actually not. With a larger subset of images it is of course much easier to generate even bigger differences in performance. The goal of this article is not to be a guide of how to make the \"apparent\" performance of systems look good, but rather to make readers aware of CBIRS evaluations and the importance of standardized image databases, queries and RJ."
            },
            "slug": "The-Truth-about-Corel-Evaluation-in-Image-Retrieval-M\u00fcller-Marchand-Maillet",
            "title": {
                "fragments": [],
                "text": "The Truth about Corel - Evaluation in Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This article compares different ways of evaluating the performance of content-based image retrieval systems using a subset of the Corel images with the same CBIRSan d the same set of evaluation measures to show how easy it is to get differing results, even when using the same image collection, thesame CBIRS and the same performance measures."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334383"
                        ],
                        "name": "Yohan Jin",
                        "slug": "Yohan-Jin",
                        "structuredName": {
                            "firstName": "Yohan",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yohan Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145155297"
                        ],
                        "name": "L. Khan",
                        "slug": "L.-Khan",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Khan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Khan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145131936"
                        ],
                        "name": "Lei Wang",
                        "slug": "Lei-Wang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34756361"
                        ],
                        "name": "M. Awad",
                        "slug": "M.-Awad",
                        "structuredName": {
                            "firstName": "Mamoun",
                            "lastName": "Awad",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Awad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17047961,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "a6fb03a73a5b91617a2fa022e64e9021a1a2a676",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The development of technology generates huge amounts of non-textual information, such as images. An efficient image annotation and retrieval system is highly desired. Clustering algorithms make it possible to represent visual features of images with finite symbols. Based on this, many statistical models, which analyze correspondence between visual features and words and discover hidden semantics, have been published. These models improve the annotation and retrieval of large image databases. However, current state of the art including our previous work produces too many irrelevant keywords for images during annotation. In this paper, we propose a novel approach that augments the classical model with generic knowledge-based, WordNet. Our novel approach strives to prune irrelevant keywords by the usage of WordNet. To identify irrelevant keywords, we investigate various semantic similarity measures between keywords and finally fuse outcomes of all these measures together to make a final decision using Dempster-Shafer evidence combination. We have implemented various models to link visual tokens with keywords based on knowledge-based, WordNet and evaluated performance using precision, and recall using benchmark dataset. The results show that by augmenting knowledge-based with classical model we can improve annotation accuracy by removing irrelevant keywords."
            },
            "slug": "Image-annotations-by-combining-multiple-evidence-&-Jin-Khan",
            "title": {
                "fragments": [],
                "text": "Image annotations by combining multiple evidence & wordNet"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes a novel approach that augments the classical model with generic knowledge-based, WordNet to prune irrelevant keywords by the usage of WordNet and shows that by augmenting knowledge- based with classical model the authors can improve annotation accuracy by removing irrelevant keywords."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9276896"
                        ],
                        "name": "Liu Wenyin",
                        "slug": "Liu-Wenyin",
                        "structuredName": {
                            "firstName": "Liu",
                            "lastName": "Wenyin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liu Wenyin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716389"
                        ],
                        "name": "C. Hu",
                        "slug": "C.-Hu",
                        "structuredName": {
                            "firstName": "Chunhui",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13231550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad585ac75503b40cb5b4e243ae36218f90f4191e",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "iFind\u00a9 (v 1.0) is a web based image retrieval system developed at Microsoft Research China. It provides the functionalities of keyword based image search, query by image example, category based image browsing, relevance feedback, and semi-automatic image annotation. The key technology in the system is the integrated semantics and feature based image retrieval and relevance feedback approach, which will be presented in our paper in the ACM Multimedia 2000 Proceedings [1]. When the user provides feedback images, the system can refine the retrieval result based on the user's feedback. In the meantime, the system updates the annotation of feedback images by increasing the linkage to the positive examples' annotation and decreasing the linkage to the negative examples' annotation. The updated annotation can further help to improve image retrieval results of the system in later use."
            },
            "slug": "iFind\u2014a-system-for-semantics-and-feature-based-over-Zhang-Wenyin",
            "title": {
                "fragments": [],
                "text": "iFind\u2014a system for semantics and feature based image retrieval over Internet"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The key technology in the iFind\u00a9 system is the integrated semantics and feature based image retrieval and relevance feedback approach, which will be presented in the paper in the ACM Multimedia 2000 Proceedings."
            },
            "venue": {
                "fragments": [],
                "text": "MM 2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056048"
                        ],
                        "name": "A. Csillaghy",
                        "slug": "A.-Csillaghy",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Csillaghy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Csillaghy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1864967"
                        ],
                        "name": "H. Hinterberger",
                        "slug": "H.-Hinterberger",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Hinterberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hinterberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92708085"
                        ],
                        "name": "A. Benz",
                        "slug": "A.-Benz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Benz",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Benz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14865624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89b6569295473becef8385e8900aadebbf27b222",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval in astronomy needs methods that can deal with an image content made of noisy and diffuse structures. This motivates investigations on how information should be summarized and indexed for this specific kind of images. The method we present first summarizes the image information content by partitioning the image in regions with same texture. We call this process texture summarization. Second, indexing features are generated by examining the distribution of parameters describing image regions. Indexing features can be associated with global or local image characteristics. Both kinds of indexing features are evaluated on the retrieval system of the Zurich archive of solar radio spectrograms. The evaluation shows that generating local indexing features using self-organizing maps yields the best effectiveness of all tested methods."
            },
            "slug": "Content-Based-Image-Retrieval-in-Astronomy-Csillaghy-Hinterberger",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval in Astronomy"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The method presented first summarizes the image information content by partitioning the image in regions with same texture and generates local indexing features using self-organizing maps yields the best effectiveness of all tested methods."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065116855"
                        ],
                        "name": "A. Natsev",
                        "slug": "A.-Natsev",
                        "structuredName": {
                            "firstName": "Apostol",
                            "lastName": "Natsev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Natsev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696519"
                        ],
                        "name": "R. Rastogi",
                        "slug": "R.-Rastogi",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Rastogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rastogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144232630"
                        ],
                        "name": "Kyuseok Shim",
                        "slug": "Kyuseok-Shim",
                        "structuredName": {
                            "firstName": "Kyuseok",
                            "lastName": "Shim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyuseok Shim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12939740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0891e06d61c187e5e81971d0cb0a1f81ec9d5475",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Approaches for content-based image querying typically extract a single signature from each image based on color, texture, or shape features. The images returned as the query result are then the ones whose signatures are closest to the signature of the query image. While efficient for simple images, such methods do not work well for complex scenes since they fail to retrieve images that match the query only partially, that is, only certain regions of the image match. This inefficiency leads to the discarding of images that may be semantically very similar to the query image since they may contain the same objects. The problem becomes even more apparent when we consider scaled or translated versions of the similar objects. We propose WALRUS (wavelet-based retrieval of user-specified scenes), a novel similarity retrieval algorithm that is robust to scaling and translation of objects within an image. WALRUS employs a novel similarity model in which each image is first decomposed into its regions and the similarity measure between a pair of images is then defined to be the fraction of the area of the two images covered by matching regions from the images. In order to extract regions for an image, WALRUS considers sliding windows of varying sizes and then clusters them based on the proximity of their signatures. An efficient dynamic programming algorithm is used to compute wavelet-based signatures for the sliding windows. Experimental results on real-life data sets corroborate the effectiveness of WALRUS'S similarity model."
            },
            "slug": "WALRUS:-a-similarity-retrieval-algorithm-for-image-Natsev-Rastogi",
            "title": {
                "fragments": [],
                "text": "WALRUS: a similarity retrieval algorithm for image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "WALRUS (wavelet-based retrieval of user-specified scenes), a novel similarity retrieval algorithm that is robust to scaling and translation of objects within an image, is proposed and Experimental results on real-life data sets corroborate the effectiveness of WALR US'S similarity model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808594"
                        ],
                        "name": "A. Lippman",
                        "slug": "A.-Lippman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lippman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lippman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 112
                            }
                        ],
                        "text": "A number of probabilistic \nframeworks for CBIR have been proposed in the last few years [Jin and Hauptmann 2002; Vasconcelos and \nLippman 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3037471,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43b294c251401728d0c731288664dbf3f08cf7fc",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of an effective architecture for content-based retrieval from visual libraries requires careful consideration of the interplay between feature selection, feature representation, and similarity metric. We present a solution where all the modules strive to optimize the same performance criteria: the probability of retrieval error. This solution consists of a Bayesian retrieval criteria (shown to generalize the most prevalent similarity metrics in current use) and an embedded mixture representation over a multiresolution feature space (shown to provide a good trade-off between retrieval accuracy, invariance, perceptual relevance of similarity, and complexity). The new representation extends standard models (histogram and Gaussian) by providing simultaneous support for high-dimensional features and multi-modal densities and performs well on color texture, and generic image databases."
            },
            "slug": "A-probabilistic-architecture-for-content-based-Vasconcelos-Lippman",
            "title": {
                "fragments": [],
                "text": "A probabilistic architecture for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A solution where all the modules strive to optimize the same performance criteria: the probability of retrieval error is presented, which consists of a Bayesian retrieval criteria and an embedded mixture representation over a multiresolution feature space."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144132688"
                        ],
                        "name": "Lei Zhu",
                        "slug": "Lei-Zhu",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473373"
                        ],
                        "name": "A. Zhang",
                        "slug": "A.-Zhang",
                        "structuredName": {
                            "firstName": "Aidong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38912099"
                        ],
                        "name": "A. Rao",
                        "slug": "A.-Rao",
                        "structuredName": {
                            "firstName": "Aibing",
                            "lastName": "Rao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14459745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c127a5ff69f0d63a7b4ac0e66de90f6434070e2",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 211,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new framework termed Keyblock for content-based image retrieval, which is a generalization of the text-based information retrieval technology in the image domain. In this framework, methods for extracting comprehensive image features are provided, which are based on the frequency of representative blocks, termed keyblocks, of the image database. Keyblocks, which are analogous to index terms in text document retrieval, can be constructed by exploiting the vector quantization (VQ) method which has been used for image compression. By comparing the performance of our approach with the existing techniques using color feature and wavelet texture feature, the experimental results demonstrate the effectiveness of the framework in image retrieval."
            },
            "slug": "Keyblock:-an-approach-for-content-based-image-Zhu-Zhang",
            "title": {
                "fragments": [],
                "text": "Keyblock: an approach for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "By comparing the performance of the proposed framework, Keyblock for content-based image retrieval, with the existing techniques using color feature and wavelet texture feature, the experimental results demonstrate the effectiveness of the framework in image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3945955"
                        ],
                        "name": "Xiaofei He",
                        "slug": "Xiaofei-He",
                        "structuredName": {
                            "firstName": "Xiaofei",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofei He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 69
                            }
                        ],
                        "text": "This idea is explored and applied to image similarity and ranking in [He 2004; Vasconcelos and Lippman 2005; He et al. 2004; He et al. 2004a; Zhou et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5723803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "150f30df466f6c9af320d99e7474999745226aa5",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Subspace learning techniques are widespread in pattern recognition research. They include Principal Component Analysis (PCA), Locality Preserving Projection (LPP), etc. These techniques are generally unsupervised which allows them to model data in the absence of labels or categories. In relevance feedback driven image retrieval system, the user provided information can be used to better describe the intrinsic semantic relationships between images. In this paper, we propose a semi-supervised subspace learning algorithm which incrementally learns an adaptive subspace by preserving the semantic structure of the image space, based on user interactions in a relevance feedback driven query-by-example system. Our algorithm is capable of accumulating knowledge from users, which could result in new feature representations for images in the database so that the system's future retrieval performance can be enhanced. Experiments on a large collection of images have shown the effectiveness and efficiency of our proposed algorithm."
            },
            "slug": "Incremental-semi-supervised-subspace-learning-for-He",
            "title": {
                "fragments": [],
                "text": "Incremental semi-supervised subspace learning for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A semi-supervised subspace learning algorithm which incrementally learns an adaptive subspace by preserving the semantic structure of the image space, based on user interactions in a relevance feedback driven query-by-example system is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144893429"
                        ],
                        "name": "ByoungChul Ko",
                        "slug": "ByoungChul-Ko",
                        "structuredName": {
                            "firstName": "ByoungChul",
                            "lastName": "Ko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ByoungChul Ko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144036125"
                        ],
                        "name": "H. Byun",
                        "slug": "H.-Byun",
                        "structuredName": {
                            "firstName": "Hyeran",
                            "lastName": "Byun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Byun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 107
                            }
                        ],
                        "text": "With an increased popularity of region-based \nimage re\u00adtrieval [Carson et al. 2002; Wang et al. 2001; Ko and Byun 2002], attempts have been made to \nincorporate the region factor into RF."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38619878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b9195e8a60f399ab466e082fefa1670cb65459c",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Among representative content-based image retrieval schemes, region-based retrieval has shown promise in retrieving similar images that exhibit considerable local variations. However, since humans are accustomed to relying on object-level concepts rather than low-level regions, robust and accurate object segmentation is an essential step. We propose a new multiple-region level image retrieval algorithm based on region-level image segmentation and its spatial relationship. To capture spatial similarity, we apply Hausdorff distance (HD) to our region-based image retrieval system, FRIP (finding region in the pictures). In contrast to other object or multiple region-based retrieval systems, we update classical HD to retrieve similar regions regardless of their spatial translation, insertion, and deletion. Furthermore, we incorporate relevance feedback to reflect the user's high-level query and subjectivity to the system and to compensate for performance degradation due to imperfect image segmentation. The efficacy of our method is validated using a set of 3000 images from Corel-photo CD."
            },
            "slug": "Integrated-region-based-image-retrieval-using-Ko-Byun",
            "title": {
                "fragments": [],
                "text": "Integrated region-based image retrieval using region's spatial relationships"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a new multiple-region level image retrieval algorithm based on region-level image segmentation and its spatial relationship, and applies Hausdorff distance to this region-based image retrieval system, FRIP (finding region in the pictures)."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14715074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fedf7729b620ec2cf4e79705d2898f82e9a2ba66",
            "isKey": false,
            "numCitedBy": 1629,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. We present a new image representation that provides a transformation from the raw pixel data to a small set of image regions that are coherent in color and texture. This \"Blobworld\" representation is created by clustering pixels in a joint color-texture-position feature space. The segmentation algorithm is fully automatic and has been run on a collection of 10,000 natural images. We describe a system that uses the Blobworld representation to retrieve images from this collection. An important aspect of the system is that the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, query results from these systems can be inexplicable, despite the availability of knobs for adjusting the similarity metrics. By finding image regions that roughly correspond to objects, we allow querying at the level of objects rather than global image properties. We present results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects."
            },
            "slug": "Blobworld:-Image-Segmentation-Using-and-Its-to-Carson-Belongie",
            "title": {
                "fragments": [],
                "text": "Blobworld: Image Segmentation Using Expectation-Maximization and Its Application to Image Querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 82
                            }
                        ],
                        "text": "Surveys also exist on closely related \ntopics such as relevance feedback [Zhou and Huang 2003], high-dimensional indexing of multimedia data \n[Bohm et al. 2001], face recognition [Zhao et al. 2003] (useful for face-based image retrieval), applications \nof CBIR to medicine [Muller et al. 2004], and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9664339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62cec1ef9f1d9135884c2a61919d20fbb8eda589",
            "isKey": false,
            "numCitedBy": 981,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We analyze the nature of the relevance feedback problem in a continuous representation space in the context of content-based image retrieval. Emphasis is put on exploring the uniqueness of the problem and comparing the assumptions, implementations, and merits of various solutions in the literature. An attempt is made to compile a list of critical issues to consider when designing a relevance feedback algorithm. With a comprehensive review as the main portion, this paper also offers some novel solutions and perspectives throughout the discussion."
            },
            "slug": "Relevance-feedback-in-image-retrieval:-A-review-Zhou-Huang",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in image retrieval: A comprehensive review"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The nature of the relevance feedback problem in a continuous representation space in the context of content-based image retrieval is analyzed and a list of critical issues to consider when designing a relevance feedback algorithm is compiled."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735710"
                        ],
                        "name": "Zhong-Ming Su",
                        "slug": "Zhong-Ming-Su",
                        "structuredName": {
                            "firstName": "Zhong-Ming",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhong-Ming Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118867754"
                        ],
                        "name": "Shaoping Ma",
                        "slug": "Shaoping-Ma",
                        "structuredName": {
                            "firstName": "Shaoping",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoping Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8572491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a03a1a186e4c73a36f33d4d5d0c6257066384ca3",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Research has been devoted in the past few years to relevance feedback as an effective solution to improve performance of content-based image retrieval (CBIR). In this paper, we propose a new feedback approach with progressive learning capability combined with a novel method for the feature subspace extraction. The proposed approach is based on a Bayesian classifier and treats positive and negative feedback examples with different strategies. Positive examples are used to estimate a Gaussian distribution that represents the desired images for a given query; while the negative examples are used to modify the ranking of the retrieved candidates. In addition, feature subspace is extracted and updated during the feedback process using a principal component analysis (PCA) technique and based on user's feedback. That is, in addition to reducing the dimensionality of feature spaces, a proper subspace for each type of features is obtained in the feedback process to further improve the retrieval accuracy. Experiments demonstrate that the proposed method increases the retrieval speed, reduces the required memory and improves the retrieval accuracy significantly."
            },
            "slug": "Relevance-feedback-in-content-based-image-Bayesian-Su-Zhang",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in content-based image retrieval: Bayesian framework, feature subspaces, and progressive learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new feedback approach with progressive learning capability combined with a novel method for the feature subspace extraction based on a Bayesian classifier that treats positive and negative feedback examples with different strategies to improve the retrieval accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872595"
                        ],
                        "name": "Robert Krovetz",
                        "slug": "Robert-Krovetz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Krovetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Krovetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10338450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7db898aadd5c0cbc3c98fd3e47a5657aab2260e0",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "In a typical content-based image retrieval (CBIR) system, target images (images in the database) are sorted by feature similarities with respect to the query. Similarities among target images are usually ignored. This paper introduces a new technique, cluster-based retrieval of images by unsupervised learning (CLUE), for improving user interaction with image retrieval systems by fully exploiting the similarity information. CLUE retrieves image clusters by applying a graph-theoretic clustering algorithm to a collection of images in the vicinity of the query. Clustering in CLUE is dynamic. In particular, clusters formed depend on which images are retrieved in response to the query. CLUE can be combined with any real-valued symmetric similarity measure (metric or nonmetric). Thus, it may be embedded in many current CBIR systems, including relevance feedback systems. The performance of an experimental image retrieval system using CLUE is evaluated on a database of around 60,000 images from COREL. Empirical results demonstrate improved performance compared with a CBIR system using the same image similarity measure. In addition, results on images returned by Google's Image Search reveal the potential of applying CLUE to real-world image data and integrating CLUE as a part of the interface for keyword-based image retrieval systems."
            },
            "slug": "CLUE:-cluster-based-retrieval-of-images-by-learning-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "CLUE: cluster-based retrieval of images by unsupervised learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results on images returned by Google's Image Search reveal the potential of applying CLUE to real-world image data and integrating CLUE as a part of the interface for keyword-based image retrieval systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108212723"
                        ],
                        "name": "Xin-Jing Wang",
                        "slug": "Xin-Jing-Wang",
                        "structuredName": {
                            "firstName": "Xin-Jing",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin-Jing Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806958"
                        ],
                        "name": "Xing Li",
                        "slug": "Xing-Li",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 579452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24a418cdee8750b38bc911d2c0d5ef4c95c5152c",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose an iterative similarity propagation approach to explore the inter-relationships between Web images and their textual annotations for image retrieval. By considering Web images as one type of objects, their surrounding texts as another type, and constructing the links structure between them via webpage analysis, we can iteratively reinforce the similarities between images. The basic idea is that if two objects of the same type are both related to one object of another type, these two objects are similar; likewise, if two objects of the same type are related to two different, but similar objects of another type, then to some extent, these two objects are also similar. The goal of our method is to fully exploit the mutual reinforcement between images and their textual annotations. Our experiments based on 10,628 images crawled from the Web show that our proposed approach can significantly improve Web image retrieval performance."
            },
            "slug": "Multi-model-similarity-propagation-and-its-for-web-Wang-Ma",
            "title": {
                "fragments": [],
                "text": "Multi-model similarity propagation and its application for web image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An iterative similarity propagation approach to explore the inter-relationships between Web images and their textual annotations for image retrieval and shows that the proposed approach can significantly improve Web image retrieval performance."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34792252"
                        ],
                        "name": "J. Amores",
                        "slug": "J.-Amores",
                        "structuredName": {
                            "firstName": "Jaume",
                            "lastName": "Amores",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Amores"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143601910"
                        ],
                        "name": "P. Radeva",
                        "slug": "P.-Radeva",
                        "structuredName": {
                            "firstName": "Petia",
                            "lastName": "Radeva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Radeva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15691135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "864e4984ef872146bc7229c593c568608908bf41",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new framework for characterizing and retrieving objects in cluttered scenes. Objects are best represented by characterizing both their parts and the mutual spatial relations among them. This CBIR system is based on a new representation describing every object taking into account the local properties of its parts and their mutual spatial relations, without relying on accurate segmentation. For this purpose, a new multi-dimensional histogram is used that measures the joint distribution of local properties and relative spatial positions. Instead of using a single descriptor for all the image, we represent the image by a set of histograms covering the object from different perspectives. We integrate this representation in a whole framework which has two stages. The first one is to allow an efficient retrieval based on the geometric properties (shape) of objects in images with clutter. This is achieved by i) using a contextual descriptor that incorporates the distribution of local structures, and ii) taking a proper distance that disregards the clutter of the images. At a second stage, we introduce a more discriminative descriptor that characterizes the parts of the objects by their color and their local tructure. By sing relevant-feedback and boosting as a feature selection algorithm, the system is able to learn simultaneously the information that characterize each part of the object along with their mutual spatial relations. Results are reported on two known databases and are quantitatively compared to other successful approaches"
            },
            "slug": "Boosting-contextual-information-in-content-based-Amores-Sebe",
            "title": {
                "fragments": [],
                "text": "Boosting contextual information in content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new framework for characterizing and retrieving objects in cluttered scenes based on a new representation describing every object taking into account the local properties of its parts and their mutual spatial relations, without relying on accurate segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694199"
                        ],
                        "name": "R. Sukthankar",
                        "slug": "R.-Sukthankar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sukthankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sukthankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144952241"
                        ],
                        "name": "Larry Huston",
                        "slug": "Larry-Huston",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Huston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Larry Huston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2810933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d86a6366a66a5b6e84142c7edb8f2d255f267bb",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new Bayesian approach to object-based image retrieval with relevance feedback. Although estimating the object posterior probability density from few examples seems infeasible, we are able to approximate this density by exploiting statistics of the image database domain. Unlike previous approaches that assume an arbitrary distribution for the unconditional density of the feature vector (the density of the features taken over the entire image domain), we learn both the structure and the parameters of this density. These density estimates enable us to construct a Bayesian classifier. Using this Bayesian classifier, we perform a windowed scan over images for objects of interest and employ the user's feedback on the search results to train a second classifier that focuses on eliminating difficult false positives. We have incorporated this algorithm into an object-based image retrieval system. We demonstrate the effectiveness of our approach with experiments using a set of categories from the Corel database."
            },
            "slug": "Object-based-image-retrieval-using-the-statistical-Hoiem-Sukthankar",
            "title": {
                "fragments": [],
                "text": "Object-based image retrieval using the statistical structure of images"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new Bayesian approach to object-based image retrieval with relevance feedback is proposed, able to approximate the object posterior probability density by exploiting statistics of the image database domain."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680223"
                        ],
                        "name": "A. Smeaton",
                        "slug": "A.-Smeaton",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Smeaton",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeaton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143645506"
                        ],
                        "name": "P. Over",
                        "slug": "P.-Over",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Over",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Over"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740640"
                        ],
                        "name": "Wessel Kraaij",
                        "slug": "Wessel-Kraaij",
                        "structuredName": {
                            "firstName": "Wessel",
                            "lastName": "Kraaij",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wessel Kraaij"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7079119,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3f6968e06972695b8240f3f4ff4a7cf6ef2ee3e",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "TRECVID is an annual exercise which encourages research in information retrieval from digital video by providing a large video test collection, uniform scoring procedures, and a forum for organizations interested in comparing their results. TRECVID benchmarking covers both interactive and manual searching by end users, as well as the benchmarking of some supporting technologies including shot boundary detection, extraction of some semantic features, and the automatic segmentation of TV news broadcasts into non-overlapping news stories. TRECVID has a broad range of over 40 participating groups from across the world and as it is now (2004) in its 4th annual cycle it is opportune to stand back and look at the lessons we have learned from the cumulative activity. In this paper we shall present a brief and high-level overview of the TRECVID activity covering the data, the benchmarked tasks, the overall results obtained by groups to date and an overview of the approaches taken by selective groups in some tasks. While progress from one year to the next cannot be measured directly because of the changing nature of the video data we have been using, we shall present a summary of the lessons we have learned from TRECVID and include some pointers on what we feel are the most important of these lessons."
            },
            "slug": "TRECVID:-evaluating-the-effectiveness-of-retrieval-Smeaton-Over",
            "title": {
                "fragments": [],
                "text": "TRECVID: evaluating the effectiveness of information retrieval tasks on digital video"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A brief and high-level overview of the TRECVID activity covering the data, the benchmarked tasks, the overall results obtained by groups to date and an Overview of the approaches taken by selective groups in some tasks is presented."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791802"
                        ],
                        "name": "J. Jeon",
                        "slug": "J.-Jeon",
                        "structuredName": {
                            "firstName": "Jiwoon",
                            "lastName": "Jeon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jeon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61867173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "149ba98b4573e39308b93b6fe3dc288a194cf9d2",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Libraries have traditionally used manual image annotation for indexing and then later retrieving their image collections. However, manual image annotation is an expensive and labor intensive procedure and hence there has been great interest in coming up with automatic ways to retrieve images based on content. Here, we propose an automatic approach to annotating and retrieving images based on a training set of images. We assume that regions in an image can be described using a small vocabulary of blobs. Blobs are generated from image features using clustering. Given a training set of images with annotations, we show that probabilistic models allow us to predict the probability of generating a word given the blobs in an image. This may be used to automatically annotate and retrieve images given a word as a query. We show that relevance models. allow us to derive these probabilities in a natural way. Experiments show that the annotation performance of this cross-media relevance model is almost six times as good (in terms of mean precision) than a model based on word-blob co-occurrence model and twice as good as a state of the art model derived from machine translation. Our approach shows the usefulness of using formal information retrieval models for the task of image annotation and retrieval."
            },
            "slug": "Automatic-Image-Annotation-and-Retrieval-using-Jeon-Lavrenko",
            "title": {
                "fragments": [],
                "text": "Automatic Image Annotation and Retrieval using CrossMedia Relevance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The approach shows the usefulness of using formal information retrieval models for the task of image annotation and retrieval by assuming that regions in an image can be described using a small vocabulary of blobs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7995574"
                        ],
                        "name": "Huamin Feng",
                        "slug": "Huamin-Feng",
                        "structuredName": {
                            "firstName": "Huamin",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huamin Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056571224"
                        ],
                        "name": "Rui Shi",
                        "slug": "Rui-Shi",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6565916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b0b4896f2914dc69e9179f2a9c2227b7286049a",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current image retrieval systems and commercial search engines use mainly text annotations to index and retrieve WWW images. This research explores the use of machine learning approaches to automatically annotate WWW images based on a predefined list of concepts by fusing evidences from image contents and their associated HTML text. One major practical limitation of employing supervised machine learning approaches is that for effective learning, a large set of labeled training samples is needed. This is tedious and severely impedes the practical development of effective search techniques for WWW images, which are dynamic and fast-changing. As web-based images possess both intrinsic visual contents and text annotations, they provide a strong basis to bootstrap the learning process by adopting a co-training approach involving classifiers based on two orthogonal set of features -- visual and text. The idea of co-training is to start from a small set of labeled training samples, and successively annotate a larger set of unlabeled samples using the two orthogonal classifiers. We carry out experiments using a set of over 5,000 images acquired from the Web. We explore the use of different combinations of HTML text and visual representations. We find that our bootstrapping approach can achieve a performance comparable to that of the supervised learning approach with an F1 measure of over 54%. At the same time, it offers the added advantage of requiring only a small initial set of training samples."
            },
            "slug": "A-bootstrapping-framework-for-annotating-and-WWW-Feng-Shi",
            "title": {
                "fragments": [],
                "text": "A bootstrapping framework for annotating and retrieving WWW images"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This research explores the use of machine learning approaches to automatically annotate WWW images based on a predefined list of concepts by fusing evidences from image contents and their associated HTML text by exploiting different combinations of HTML text and visual representations."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40603954"
                        ],
                        "name": "Kingshy Goh",
                        "slug": "Kingshy-Goh",
                        "structuredName": {
                            "firstName": "Kingshy",
                            "lastName": "Goh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kingshy Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2917344"
                        ],
                        "name": "Wei-Cheng Lai",
                        "slug": "Wei-Cheng-Lai",
                        "structuredName": {
                            "firstName": "Wei-Cheng",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Cheng Lai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 54
                            }
                        ],
                        "text": "Extensions to active learning have also been proposed [Goh et al. 2004; He et al. 2004b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 55
                            }
                        ],
                        "text": "Ex\u00adtensions to active learning have also been proposed [Goh et al. 2004; He et al. 2004b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14022622,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75263a6f4bd22ada0eb937cdde99fb5dc7109e93",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been established that active learning is effective for learning complex, subjective query concepts for image retrieval. However, active learning has been applied in a concept independent way, (i.e., the kernel-parameters and the sampling strategy are identically chosen) for learning query concepts of differing <i>complexity</i>. In this work, we first characterize a concept's complexity using three measures: <i>hit-rate</i>, <i>isolation</i> and <i>diversity</i>. We then propose a multimodal learning approach that uses images' semantic labels to guide a <i>concept-dependent</i>, <i>active-learning</i> process. Based on the complexity of a concept, we make intelligent adjustments to the sampling strategy and the sampling pool from which images are to be selected and labeled, to improve concept learnability. Our empirical study on a $300$K-image dataset shows that concept-dependent learning is highly effective for image-retrieval accuracy."
            },
            "slug": "Multimodal-concept-dependent-active-learning-for-Goh-Chang",
            "title": {
                "fragments": [],
                "text": "Multimodal concept-dependent active learning for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work first characterize a concept's complexity using three measures: hit-rate, isolation and diversity, and proposes a multimodal learning approach that uses images' semantic labels to guide a concept-dependent, active-learning process."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110064127"
                        ],
                        "name": "Ruofei Zhang",
                        "slug": "Ruofei-Zhang",
                        "structuredName": {
                            "firstName": "Ruofei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruofei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720488"
                        ],
                        "name": "Zhongfei Zhang",
                        "slug": "Zhongfei-Zhang",
                        "structuredName": {
                            "firstName": "Zhongfei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhongfei Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 124
                            }
                        ],
                        "text": "Region based image retrieval, under the assumption of a hidden semantic concept underlying image generation, is explored in [Zhang and Zhang 2004]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1226784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1474cfca9f8aaf214e6d7217bf08b29f61df076f",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This work addresses content based image retrieval (CBIR), focusing on developing a hidden semantic concept discovery methodology to address effective semantics-intensive image retrieval. In our approach, each image in the database is segmented to region; associated with homogenous color, texture, and shape features. By exploiting regional statistical information in each image and employing a vector quantization method, a uniform and sparse region-based representation is achieved. With this representation a probabilistic model based on statistical-hidden-class assumptions of the image database is obtained, to which expectation-maximization (EM) technique is applied to analyze semantic concepts hidden in the database. An elaborated retrieval algorithm is designed to support the probabilistic model. The semantic similarity is measured through integrating the posterior probabilities of the transformed query image, as well as a constructed negative example, to the discovered semantic concepts. The proposed approach has a solid statistical foundation and the experimental evaluations on a database of 10,000 general-purposed images demonstrate its promise of the effectiveness."
            },
            "slug": "Hidden-semantic-concept-discovery-in-region-based-Zhang-Zhang",
            "title": {
                "fragments": [],
                "text": "Hidden semantic concept discovery in region based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This work addresses content based image retrieval (CBIR), focusing on developing a hidden semantic concept discovery methodology to address effective semantics-intensive image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398826846"
                        ],
                        "name": "V. Gouet-Brunet",
                        "slug": "V.-Gouet-Brunet",
                        "structuredName": {
                            "firstName": "Val\u00e9rie",
                            "lastName": "Gouet-Brunet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Gouet-Brunet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741155"
                        ],
                        "name": "N. Boujemaa",
                        "slug": "N.-Boujemaa",
                        "structuredName": {
                            "firstName": "Nozha",
                            "lastName": "Boujemaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Boujemaa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9393576,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "c46a9d420061d2860fe911a1c35c78abf47d8689",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "For content-based image retrieval (CBIR), traditional approaches of image matching involve global descriptions of the color image. When considering particular tasks like object recognition or partial queries, more local characterizations must be employed. In this context, image description based on points of interest appear best adapted. The point characterization which proved reliable is based on combinations of the Hilbert's differential invariants. For gray value images, such a description used to be considered up to third order. Generalizations to color images were previously proposed for stereovision and image retrieval. Some of them propose to consider the invariants only at first order, while others consider higher order invariants and compute some combinations of them to achieve illumination changes invariance. We discuss the advantages and drawbacks of these different choices, with the aim of proposing an optimal use of color points of interest for image retrieval."
            },
            "slug": "On-the-robustness-of-color-points-of-interest-for-Gouet-Brunet-Boujemaa",
            "title": {
                "fragments": [],
                "text": "On the robustness of color points of interest for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work discusses the advantages and drawbacks of different choices of generalizations to color images, with the aim of proposing an optimal use of color points of interest for image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2338248"
                        ],
                        "name": "Nikhil V. Shirahatti",
                        "slug": "Nikhil-V.-Shirahatti",
                        "structuredName": {
                            "firstName": "Nikhil",
                            "lastName": "Shirahatti",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikhil V. Shirahatti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 15
                            }
                        ],
                        "text": "As observed in [Shirahatti and Barnard 2005], CBIR is meaningful only in its service to human users."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 68
                            }
                        ],
                        "text": "An interesting user driven evaluation criteria has been proposed in [Shirahatti and Barnard 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7723425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6ac303e6581a86fdecae02d7caec8f59edec72d",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a comprehensive strategy for evaluating image retrieval algorithms. Because automated image retrieval is only meaningful in its service to people, performance characterization must be grounded in human evaluation. Thus we have collected a large data set of human evaluations of retrieval results, both for query by image example and query by text. The data is independent of any particular image retrieval algorithm and can be used to evaluate and compare many such algorithms without further data collection. The data and calibration software are available on-line. We develop and validate methods for generating sensible evaluation data, calibrating for disparate evaluators, mapping image retrieval system scores to the human evaluation results, and comparing retrieval systems. We demonstrate the process by providing grounded comparison results for several algorithms."
            },
            "slug": "Evaluating-image-retrieval-Shirahatti-Barnard",
            "title": {
                "fragments": [],
                "text": "Evaluating image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A large data set of human evaluations of retrieval results, both for query by image example and query by text, is collected, independent of any particular image retrieval algorithm and can be used to evaluate and compare many such algorithms without further data collection."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719780"
                        ],
                        "name": "Yan Ke",
                        "slug": "Yan-Ke",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Ke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Ke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694199"
                        ],
                        "name": "R. Sukthankar",
                        "slug": "R.-Sukthankar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sukthankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sukthankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144952241"
                        ],
                        "name": "Larry Huston",
                        "slug": "Larry-Huston",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Huston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Larry Huston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16694322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cdd7368d49a14983ceb4254e8f43cc807468adc",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a system for near-duplicate detection and sub-image retrieval. Such a system is useful for finding copyright violations and detecting forged images. We define near-duplicate as images altered with common transformations such as changing contrast, saturation, scaling, cropping, framing, etc. Our system builds a parts-based representation of images using <i>distinctive local descriptors</i> which give high quality matches even under severe transformations. To cope with the large number of features extracted from the images, we employ <i>locality-sensitive hashing</i> to index the local descriptors. This allows us to make approximate similarity queries that only examine a small fraction of the database. Although locality-sensitive hashing has excellent theoretical performance properties, a standard implementation would still be unacceptably slow for this application. We show that, by optimizing layout and access to the index data on disk, we can efficiently query indices containing millions of keypoints. Our system achieves near-perfect accuracy (100% precision at 99.85% recall) on the tests presented in Meng <i>et al.</i> [16], and consistently strong results on our own, significantly more challenging experiments. Query times are interactive even for collections of thousands of images."
            },
            "slug": "An-efficient-parts-based-near-duplicate-and-system-Ke-Sukthankar",
            "title": {
                "fragments": [],
                "text": "An efficient parts-based near-duplicate and sub-image retrieval system"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that, by optimizing layout and access to the index data on disk, the system can efficiently query indices containing millions of keypoints and make approximate similarity queries that only examine a small fraction of the database."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803127"
                        ],
                        "name": "Yunqiang Chen",
                        "slug": "Yunqiang-Chen",
                        "structuredName": {
                            "firstName": "Yunqiang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunqiang Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14712495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "746cf281d8198310b1242048bf4fd90e0486f1a9",
            "isKey": false,
            "numCitedBy": 637,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback schemes using linear/quadratic estimators have been applied in content-based image retrieval to improve retrieval performance significantly. One major difficulty in relevance feedback is to estimate the support of target images in high dimensional feature space with a relatively small number of training samples. We develop a novel scheme based on one-class SVM, which fits a tight hyper-sphere in the nonlinearly transformed feature space to include most of the target images based on positive examples. The use of a kernel provides us an elegant way to deal with nonlinearity in the distribution of the target images, while the regularization term in SVM provides good generalization ability. To validate the efficacy of the proposed approach, we test it on both synthesized data and real-world images. Promising results are achieved in both cases."
            },
            "slug": "One-class-SVM-for-learning-in-image-retrieval-Chen-Zhou",
            "title": {
                "fragments": [],
                "text": "One-class SVM for learning in image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel scheme based on one-class SVM is developed, which fits a tight hyper-sphere in the nonlinearly transformed feature space to include most of the target images based on positive examples and provides an elegant way to deal with nonlinearity in the distribution of thetarget images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791802"
                        ],
                        "name": "J. Jeon",
                        "slug": "J.-Jeon",
                        "structuredName": {
                            "firstName": "Jiwoon",
                            "lastName": "Jeon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jeon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 132
                            }
                        ],
                        "text": "Probabilistic graphical models such as 2D multiresolution hidden Markov models [Li \nand Wang 2003] and cross-media relevance models [Jeon et al. 2003], though primarily used for image annotation \napplications, are contributions to machine learn\u00ading research."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 131
                            }
                        ],
                        "text": "Probabilistic graphical models such as 2D multiresolution hidden Markov models [Li and Wang 2003] and cross-media relevance models [Jeon et al. 2003], though primarily used for image annotation applications, are contributions to machine learning research."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 75
                            }
                        ],
                        "text": "Cross-Media relevance models models have been used for image annotation in [Jeon et al. 2003; Lavrenko et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14303727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "228029e7533e32a025071e31e3f4f08d2bea5f5a",
            "isKey": true,
            "numCitedBy": 1301,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Libraries have traditionally used manual image annotation for indexing and then later retrieving their image collections. However, manual image annotation is an expensive and labor intensive procedure and hence there has been great interest in coming up with automatic ways to retrieve images based on content. Here, we propose an automatic approach to annotating and retrieving images based on a training set of images. We assume that regions in an image can be described using a small vocabulary of blobs. Blobs are generated from image features using clustering. Given a training set of images with annotations, we show that probabilistic models allow us to predict the probability of generating a word given the blobs in an image. This may be used to automatically annotate and retrieve images given a word as a query. We show that relevance models allow us to derive these probabilities in a natural way. Experiments show that the annotation performance of this cross-media relevance model is almost six times as good (in terms of mean precision) than a model based on word-blob co-occurrence model and twice as good as a state of the art model derived from machine translation. Our approach shows the usefulness of using formal information retrieval models for the task of image annotation and retrieval."
            },
            "slug": "Automatic-image-annotation-and-retrieval-using-Jeon-Lavrenko",
            "title": {
                "fragments": [],
                "text": "Automatic image annotation and retrieval using cross-media relevance models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The approach shows the usefulness of using formal information retrieval models for the task of image annotation and retrieval by assuming that regions in an image can be described using a small vocabulary of blobs."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744044"
                        ],
                        "name": "Yen-Yu Lin",
                        "slug": "Yen-Yu-Lin",
                        "structuredName": {
                            "firstName": "Yen-Yu",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yen-Yu Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805102"
                        ],
                        "name": "Tyng-Luh Liu",
                        "slug": "Tyng-Luh-Liu",
                        "structuredName": {
                            "firstName": "Tyng-Luh",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tyng-Luh Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803730"
                        ],
                        "name": "Hwann-Tzong Chen",
                        "slug": "Hwann-Tzong-Chen",
                        "structuredName": {
                            "firstName": "Hwann-Tzong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hwann-Tzong Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6716050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7438604d467c64156fcb3e86556d80f0ca72342d",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning the user's semantics for CBIR involves two different sources of information: the similarity relations entailed by the content-based features, and the relevance relations specified in the feedback. Given that, we propose an augmented relation embedding (ARE) to map the image space into a semantic manifold that faithfully grasps the user's preferences. Besides ARE, we also look into the issues of selecting a good feature set for improving the retrieval performance. With these two aspects of efforts we have established a system that yields far better results than those previously reported. Overall, our approach can be characterized by three key properties: 1) The framework uses one relational graph to describe the similarity relations, and the other two to encode the relevant/irrelevant relations indicated in the feedback. 2) With the relational graphs so defined, learning a semantic manifold can be transformed into solving a constrained optimization problem, and is reduced to the ARE algorithm accounting for both the representation and the classification points of views. 3) An image representation based on augmented features is introduced to couple with the ARE learning. The use of these features is significant in capturing the semantics concerning different scales of image regions. We conclude with experimental results and comparisons to demonstrate the effectiveness of our method."
            },
            "slug": "Semantic-manifold-learning-for-image-retrieval-Lin-Liu",
            "title": {
                "fragments": [],
                "text": "Semantic manifold learning for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An augmented relation embedding to map the image space into a semantic manifold that faithfully grasps the user's preferences and is reduced to the ARE algorithm accounting for both the representation and the classification points of views."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 86
                            }
                        ],
                        "text": "To this end, a recent attempt at bridging the retrieval-annotation gap has been made \n[Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7665222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bef9e21f9f46f41ccdfbbb495180f5ece7feb675",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "While personal and community-based image collections grow by the day, the demand for novel photo management capabilities grows with it. Recent research has shown that it is possible to learn the consensus on visual quality measures such as aesthetics with a moderate degree of success. Here, we seek to push this performance to more realistic levels and use it to (a) help select high-quality pictures from collections, and (b) eliminate low-quality ones, introducing appropriate performance metrics in each case. To achieve this, we propose a sequential arrangement of a weighted linear least squares regressor and a naive Bayes' classifier, applied to a set of visual features previously found useful for quality prediction. Experiments on real-world data for these tasks show promising performance, with significant improvements over a previously proposed SVM-based method."
            },
            "slug": "Learning-the-consensus-on-visual-quality-for-image-Datta-Li",
            "title": {
                "fragments": [],
                "text": "Learning the consensus on visual quality for next-generation image management"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a sequential arrangement of a weighted linear least squares regressor and a naive Bayes' classifier, applied to a set of visual features previously found useful for quality prediction, which shows promising performance."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16418860,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e9e0cf8587dedbef0d161db736dedc76e6c4f36",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We present a new system for querying for images by regions and their spatial and feature attributes. The system enables the user to find the images that contain arrangements of regions similar to those diagrammed in a query image. By indexing the attributes of regions, such as sizes, locations and visual features, a wide variety of complex joint spatial and feature queries are efficiently computed. In order to demonstrate the utility of the system, we develop a process for the extracting color regions from photographic images. We demonstrate that integrated spatial and feature querying using color regions improves image search capabilities over non-spatial content-based image retrieval methods."
            },
            "slug": "Integrated-spatial-and-feature-image-query-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "Integrated spatial and feature image query"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated that integrated spatial and feature querying using color regions improves image search capabilities over non-spatial content-based image retrieval methods."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3174044"
                        ],
                        "name": "L. H. Armitage",
                        "slug": "L.-H.-Armitage",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Armitage",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. H. Armitage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137152"
                        ],
                        "name": "P. Enser",
                        "slug": "P.-Enser",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Enser",
                            "middleNames": [
                                "G.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Enser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45350741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "316440b3a78715902ebdf9a433867143c70f1b85",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a project in which an analysis was undertaken of user queries addressed to seven libraries which manage archives of widely varying still and moving image material. The sampling procedure is described, in which queries obtained from each library were broadly categorised by image content, identification and accessibility. Attention is focused on the image content requests, for which a categorisation based on facet analysis is developed. The analytical tool which is used for this purpose is based on a schema already well established for the analysis of levels of meaning in images. The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material. The paper concludes with observations on the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "slug": "Analysis-of-user-need-in-image-archives-Armitage-Enser",
            "title": {
                "fragments": [],
                "text": "Analysis of user need in image archives"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material, and the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Inf. Sci."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719710"
                        ],
                        "name": "Sougata Mukherjea",
                        "slug": "Sougata-Mukherjea",
                        "structuredName": {
                            "firstName": "Sougata",
                            "lastName": "Mukherjea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sougata Mukherjea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178243"
                        ],
                        "name": "K. Hirata",
                        "slug": "K.-Hirata",
                        "structuredName": {
                            "firstName": "Kyoji",
                            "lastName": "Hirata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hirata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31893760"
                        ],
                        "name": "Y. Hara",
                        "slug": "Y.-Hara",
                        "structuredName": {
                            "firstName": "Yoshinori",
                            "lastName": "Hara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hara"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1410735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95d92241fa1dbc4ad74377cf0c0bfe14eeed7739",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Advanced Multimedia Oriented Retrieval Engine (AMORE) [2] is a World-Wide Web image retrieval engine integrating several techniques to facilitate effective retrieval of images from the Web. With the explosive growth of information that is available through the WWW, it is becoming increasingly difficult for the users to find the information of interest. Therefore, search engines are becoming very popular and useful. However, most of the popular search engines today are textual. Although most Web pages have images, the current image search engines on the WWW are primitive.For traditional text retrieval the only way to search for relevant documents is by specifying keywords. However, for multimedia retrieval it is essential that the user is provided with various options for retrieving the target image. AMORE allows the user to retrieve images of interest using various techniques.The effectiveness of an information retrieval engine is also dependent on the user interface to show the retrieved images. In AMORE, the retrieved images are shown using thumbnails. Like traditional WWW search engines the user can browse through pages of results. We also allow the user to click on an interesting thumbnail and retrieve similar images. This visual navigation strategy is helpful in quickly retrieving the target images. To help the user if many images are retrieved we have also developed a Query Result Visualization Environment. This interface allows the search results to be organized in various ways. We believe that the integration of information retrieval with visualization is helpful for the user's retrieval tasks."
            },
            "slug": "AMORE:-a-world-wide-web-image-retrieval-engine-Mukherjea-Hirata",
            "title": {
                "fragments": [],
                "text": "AMORE: a world-wide web image retrieval engine"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "AMORE is a World-Wide Web image retrieval engine integrating several techniques to facilitate effective retrieval of images from the Web and believes that the integration of information retrieval with visualization is helpful for the user's retrieval tasks."
            },
            "venue": {
                "fragments": [],
                "text": "CHI Extended Abstracts"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37395525"
                        ],
                        "name": "Jingrui He",
                        "slug": "Jingrui-He",
                        "structuredName": {
                            "firstName": "Jingrui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingrui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8163721"
                        ],
                        "name": "Hanghang Tong",
                        "slug": "Hanghang-Tong",
                        "structuredName": {
                            "firstName": "Hanghang",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanghang Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14966740"
                        ],
                        "name": "Changshui Zhang",
                        "slug": "Changshui-Zhang",
                        "structuredName": {
                            "firstName": "Changshui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changshui Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15033764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a61414239dd76b5e936e492def93774cce96bfd7",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel transductive learning framework named manifold-ranking based image retrieval (MRBIR). Given a query image, MRBIR first makes use of a manifold ranking algorithm to explore the relationship among all the data points in the feature space, and then measures relevance between the query and all the images in the database accordingly, which is different from traditional similarity metrics based on pair-wise distance. In relevance feedback, if only positive examples are available, they are added to the query set to improve the retrieval result; if examples of both labels can be obtained, MRBIR discriminately spreads the ranking scores of positive and negative examples, considering the asymmetry between these two types of images. Furthermore, three active learning methods are incorporated into MRBIR, which select images in each round of relevance feedback according to different principles, aiming to maximally improve the ranking result. Experimental results on a general-purpose image database show that MRBIR attains a significant improvement over existing systems from all aspects."
            },
            "slug": "Manifold-ranking-based-image-retrieval-He-Li",
            "title": {
                "fragments": [],
                "text": "Manifold-ranking based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "MRBIR first makes use of a manifold ranking algorithm to explore the relationship among all the data points in the feature space, and then measures relevance between the query and all the images in the database accordingly, which is different from traditional similarity metrics based on pair-wise distance."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48219905"
                        ],
                        "name": "A. Chalechale",
                        "slug": "A.-Chalechale",
                        "structuredName": {
                            "firstName": "Abdolah",
                            "lastName": "Chalechale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chalechale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145316713"
                        ],
                        "name": "G. Naghdy",
                        "slug": "G.-Naghdy",
                        "structuredName": {
                            "firstName": "Golshah",
                            "lastName": "Naghdy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Naghdy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759099"
                        ],
                        "name": "A. Mertins",
                        "slug": "A.-Mertins",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Mertins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mertins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8722832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "016bae9f81f091386af39605a0da89b7de1c683c",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This work presents a novel method for image similarity measure, where a hand-drawn rough black and white sketch is compared with an existing data base of full color images (art works and photographs). The proposed system creates ambient intelligence in terms of the evaluation of nonprecise, easy to input sketched information. The system can then provide the user with options of either retrieving similar images in the database or ranking the quality of the sketch against a given standard, i.e., the original image model. Alternatively, the inherent pattern-matching capability of the system can be utilized to allow detection of distortion in any given real time-image sequences in vision-driven ambient intelligence applications. The proposed method can cope with images containing several complex objects in an inhomogeneous background. Two abstract images are obtained using strong edges of the model image and the morphologically thinned outline of the sketched image. The angular-spatial distribution of pixels in the abstract images is then employed to extract new compact and effective features using the Fourier transform. The extracted features are rotation and scale invariant and robust against translation. Experimental results from seven different approaches confirm the efficacy of the proposed method in both the retrieval performance and the time required for feature extraction and search."
            },
            "slug": "Sketch-based-image-matching-Using-Angular-Chalechale-Naghdy",
            "title": {
                "fragments": [],
                "text": "Sketch-based image matching Using Angular partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work presents a novel method for image similarity measure, where a hand-drawn rough black and white sketch is compared with an existing data base of full color images (art works and photographs) to create ambient intelligence in terms of the evaluation of nonprecise, easy to input sketched information."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763890"
                        ],
                        "name": "M. De Marsico",
                        "slug": "M.-De-Marsico",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "De Marsico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. De Marsico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729018"
                        ],
                        "name": "L. Cinque",
                        "slug": "L.-Cinque",
                        "structuredName": {
                            "firstName": "Luigi",
                            "lastName": "Cinque",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cinque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990702"
                        ],
                        "name": "S. Levialdi",
                        "slug": "S.-Levialdi",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Levialdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levialdi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40260099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffcd4a3949d3d0375636e63a756ced73bb3fc825",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Indexing-pictorial-documents-by-their-content:-a-of-Marsico-Cinque",
            "title": {
                "fragments": [],
                "text": "Indexing pictorial documents by their content: a survey of current techniques"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765960"
                        ],
                        "name": "J. Assfalg",
                        "slug": "J.-Assfalg",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Assfalg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Assfalg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14709786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e3b85fc20433611bc29fc6034987e94ed40ced5",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Image databases are widely exploited in a number of different contexts, ranging from history of art, through medicine, to education. Existing querying paradigms are based either on the usage of textual strings, for high-level semantic queries or on 2D visual examples for the expression of perceptual queries. Semantic queries require manual annotation of the database images. Instead, perceptual queries only require that image analysis is performed on the database images in order to extract salient perceptual features that are matched with those of the example. However, usage of 2D examples is generally inadequate as effective authoring of query images, attaining a realistic reproduction of complex scenes, needs manual editing and sketching ability. Investigation of new querying paradigms is therefore an important-yet still marginally investigated-factor for the success of content-based image retrieval. In this paper, a novel querying paradigm is presented which is based on usage of 3D interfaces exploiting navigation and editing of 3D virtual environments. Query images are obtained by taking a snapshot of the framed environment and by using the snapshot as an example to retrieve similar database images. A comparative analysis is carried out between the usage of 3D and 2D interfaces and their related query paradigms. This analysis develops on a user test on retrieval efficiency and effectiveness, as well as on an evaluation of users' satisfaction."
            },
            "slug": "Three-Dimensional-Interfaces-for-Querying-by-in-Assfalg-Bimbo",
            "title": {
                "fragments": [],
                "text": "Three-Dimensional Interfaces for Querying by Example in Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel querying paradigm is presented which is based on usage of 3D interfaces exploiting navigation and editing of3D virtual environments and their related query paradigms and develops on a user test on retrieval efficiency and effectiveness, as well as on an evaluation of users' satisfaction."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Vis. Comput. Graph."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 868535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e",
            "isKey": false,
            "numCitedBy": 1760,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data."
            },
            "slug": "Matching-Words-and-Pictures-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Matching Words and Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text, is presented, and a number of models for the joint distribution of image regions and words are developed, including several which explicitly learn the correspondence between regions and Words."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876831"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731570"
                        ],
                        "name": "M. Lew",
                        "slug": "M.-Lew",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lew",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2167525"
                        ],
                        "name": "E. Loupias",
                        "slug": "E.-Loupias",
                        "structuredName": {
                            "firstName": "Etienne",
                            "lastName": "Loupias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Loupias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3118027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecfb0f664309fb1dcf167aaff15277f2aa340264",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval (CBIR) has become one of the most active research areas in the past few years. Most of the attention from the research has been focused on indexing techniques based on global feature distributions. However, these global distributions have limited discriminating power because they are unable to capture local image information. The use of interest points in content-based image retrieval allow image index to represent local properties of the image. Classic corner detectors can be used for this purpose. However, they have drawbacks when applied to various natural images for image retrieval, because visual features need not be corners and corners may gather in small regions. In this paper, we present a salient point detector. The detector is based on wavelet transform to detect global variations as well as local ones. The wavelet-based salient points are evaluated for image retrieval with a retrieval system using color and texture features. The results show that salient points with Gabor feature perform better than the other point detectors from the literature and the randomly chosen points. Significant improvements are achieved in terms of retrieval accuracy, computational complexity when compared to the global feature approaches."
            },
            "slug": "Image-retrieval-using-wavelet-based-salient-points-Tian-Sebe",
            "title": {
                "fragments": [],
                "text": "Image retrieval using wavelet-based salient points"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A salient point detector based on wavelet transform to detect global variations as well as local ones is presented and shows that salient points with Gabor feature perform better than the other point detectors from the literature and the randomly chosen points."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49025046"
                        ],
                        "name": "Jing Huang",
                        "slug": "Jing-Huang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31641718"
                        ],
                        "name": "S. R. Kumar",
                        "slug": "S.-R.-Kumar",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Ravi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. R. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798723"
                        ],
                        "name": "Mandar Mitra",
                        "slug": "Mandar-Mitra",
                        "structuredName": {
                            "firstName": "Mandar",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mandar Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152348371"
                        ],
                        "name": "Wei-Jing Zhu",
                        "slug": "Wei-Jing-Zhu",
                        "structuredName": {
                            "firstName": "Wei-Jing",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Jing Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In [Huang et al. 1999] color correlograms were proposed as enhancements to histograms, that take into consideration spatial distribution of colors as well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14467275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e9e79871b079b9d16245956ee651d14a69e7e7f",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a new image feature called the color correlogram and use it for image indexing and comparison. This feature distills the spatial correlation of colors and when computed efficiently, turns out to be both effective and inexpensive for content-based image retrieval. The correlogram is robust in tolerating large changes in appearance and shape caused by changes in viewing position, camera zoom, etc. Experimental evidence shows that this new feature outperforms not only the traditional color histogram method but also the recently proposed histogram refinement methods for image indexing/retrieval. We also provide a technique to cut down the storage requirement of the correlogram so that it is the same as that of histograms, with only negligible performance penalty compared to the original correlogram.We also suggest the use of color correlogram as a generic indexing tool to tackle various problems arising from image retrieval and video browsing. We adapt the correlogram to handle the problems of image subregion querying, object localization, object tracking, and cut detection. Experimental results again suggest that the color correlogram is more effective than the histogram for these applications, with insignificant additional storage or processing cost."
            },
            "slug": "Spatial-Color-Indexing-and-Applications-Huang-Kumar",
            "title": {
                "fragments": [],
                "text": "Spatial Color Indexing and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental evidence shows that the color correlogram outperforms not only the traditional color histogram method but also the recently proposed histogram refinement methods for image indexing/retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820908"
                        ],
                        "name": "A. Natsev",
                        "slug": "A.-Natsev",
                        "structuredName": {
                            "firstName": "Apostol",
                            "lastName": "Natsev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Natsev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10957008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f51d4cc631d0f8ee5ef0222c0c48a21c2131803",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Anchoring is a technique for representing objects by their distances to a few well chosen anchors, or vantage points. It can be used in content-based image retrieval for computing image similarity as a function of distances to a fixed set of representative images. Since the number of anchors is usually small, this leads to a reduced dimensionality for similarity searching, enables efficient indexing, and avoids potentially expensive similarity computations in the original feature domain, while guaranteeing lack of false dismissals. Anchoring is therefore surprisingly simple, yet effective, and flavors of it have seen application in speech recognition, audio classification, protein homology detection, and shape matching. In this paper, we describe the anchoring technique in some detail and study its properties, both from an empirical and an analytical standpoint. In particular, we investigate issues in baseline distance selection, anchor selection, and number of anchors. We compare different approaches and evaluate performance of different parameter settings. We also propose two new anchor selection heuristics which may overcome some of the drawbacks of the currently used greedy selection methods."
            },
            "slug": "A-study-of-image-retrieval-by-anchoring-Natsev-Smith",
            "title": {
                "fragments": [],
                "text": "A study of image retrieval by anchoring"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates issues in baseline distance selection, anchor selection, and number of anchors, and proposes two new anchor selection heuristics which may overcome some of the drawbacks of the currently used greedy selection methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE International Conference on Multimedia and Expo"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1862649,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "1a972eef0721fd5cc5accdd5656de3c5cb86539d",
            "isKey": false,
            "numCitedBy": 762,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We present here an implementation of NeTra, a prototype image retrieval system that uses color, texture, shape and spatial location information in segmented image regions to search and retrieve similar regions from the database. A distinguishing aspect of this system is its incorporation of a robust automated image segmentation algorithm that allows object- or region-based search. Image segmentation significantly improves the quality of image retrieval when images contain multiple complex objects. Images are segmented into homogeneous regions at the time of ingest into the database, and image attributes that represent each of these regions are computed. In addition to image segmentation, other important components of the system include an efficient color representation, and indexing of color, texture, and shape features for fast search and retrieval. This representation allows the user to compose interesting queries such as \u201cretrieve all images that contain regions that have the color of object A, texture of object B, shape of object C, and lie in the upper of the image\u201d, where the individual objects could be regions belonging to different images. A Java-based web implementation of NeTra is available at http://vivaldi.ece.ucsb.edu/Netra."
            },
            "slug": "NeTra:-A-toolbox-for-navigating-large-image-Ma-Manjunath",
            "title": {
                "fragments": [],
                "text": "NeTra: A toolbox for navigating large image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An implementation of NeTra, a prototype image retrieval system that uses color, texture, shape and spatial location information in segmented image regions to search and retrieve similar regions from the database, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50118130"
                        ],
                        "name": "Ying Wu",
                        "slug": "Ying-Wu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876831"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3725761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0743e7624ce2bef071f35cf8605c0d296c95d293",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many vision applications, the practice of supervised learning faces several difficulties, one of which is that insufficient labeled training data result in poor generalization. In image retrieval, we have very few labeled images from query and relevance feedback so that it is hard to automatically weight image features and select similarity metrics for image classification. This paper investigates the possibility of including an unlabeled data set to make up the insufficiency of labeled data. Different from most current research in image retrieval, the proposed approach tries to cast image retrieval as a transductive learning problem, in which the generalization of an image classifier is only defined on a set of images such as the given image database. Formulating this transductive problem in a probabilistic framework the proposed algorithm, Discriminant EM (D-EM) not only estimates the parameters of a generative model but also finds a linear transformation to relax the assumption of probabilistic structure of data distributions as well as select good features automatically. Our experiments show that D-EM has a satisfactory performance in image retrieval applications. D-EM algorithm has the potential to many other applications."
            },
            "slug": "Discriminant-EM-algorithm-with-application-to-image-Wu-Tian",
            "title": {
                "fragments": [],
                "text": "Discriminant-EM algorithm with application to image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The possibility of including an unlabeled data set to make up the insufficiency of labeled data is investigated and the proposed algorithm, Discriminant EM (D-EM) not only estimates the parameters of a generative model but also finds a linear transformation to relax the assumption of probabilistic structure of data distributions as well as select good features automatically."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38076717"
                        ],
                        "name": "K. Yee",
                        "slug": "K.-Yee",
                        "structuredName": {
                            "firstName": "Ka-Ping",
                            "lastName": "Yee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29002252"
                        ],
                        "name": "Kirsten Swearingen",
                        "slug": "Kirsten-Swearingen",
                        "structuredName": {
                            "firstName": "Kirsten",
                            "lastName": "Swearingen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kirsten Swearingen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149141641"
                        ],
                        "name": "Kevin Li",
                        "slug": "Kevin-Li",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 367518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e4d44dfb73374d7a3b13549b927f75a6f9cc7e",
            "isKey": false,
            "numCitedBy": 1094,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "There are currently two dominant interface types for searching and browsing large image collections: keyword-based search, and searching by overall similarity to sample images. We present an alternative based on enabling users to navigate along conceptual dimensions that describe the images. The interface makes use of hierarchical faceted metadata and dynamically generated query previews. A usability study, in which 32 art history students explored a collection of 35,000 fine arts images, compares this approach to a standard image search interface. Despite the unfamiliarity and power of the interface (attributes that often lead to rejection of new search interfaces), the study results show that 90% of the participants preferred the metadata approach overall, 97% said that it helped them learn more about the collection, 75% found it more flexible, and 72% found it easier to use than a standard baseline system. These results indicate that a category-based approach is a successful way to provide access to image collections."
            },
            "slug": "Faceted-metadata-for-image-search-and-browsing-Yee-Swearingen",
            "title": {
                "fragments": [],
                "text": "Faceted metadata for image search and browsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An alternative based on enabling users to navigate along conceptual dimensions that describe the images is presented, which makes use of hierarchical faceted metadata and dynamically generated query previews."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152883679"
                        ],
                        "name": "J. Ashley",
                        "slug": "J.-Ashley",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Ashley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ashley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1391129943"
                        ],
                        "name": "Qian Huang",
                        "slug": "Qian-Huang",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087139"
                        ],
                        "name": "M. Gorkani",
                        "slug": "M.-Gorkani",
                        "structuredName": {
                            "firstName": "Monika",
                            "lastName": "Gorkani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gorkani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39311329"
                        ],
                        "name": "J. Hafner",
                        "slug": "J.-Hafner",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Hafner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hafner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499047"
                        ],
                        "name": "Denis Lee",
                        "slug": "Denis-Lee",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144028064"
                        ],
                        "name": "David Steele",
                        "slug": "David-Steele",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Steele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70341848"
                        ],
                        "name": "P. Yanker",
                        "slug": "P.-Yanker",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yanker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 110716,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "dc139f901c869f80b54b41f89d5b7f35c7dfa3c7",
            "isKey": false,
            "numCitedBy": 4258,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Research on ways to extend and improve query methods for image databases is widespread. We have developed the QBIC (Query by Image Content) system to explore content-based retrieval methods. QBIC allows queries on large image and video databases based on example images, user-constructed sketches and drawings, selected color and texture patterns, camera and object motion, and other graphical information. Two key properties of QBIC are (1) its use of image and video content-computable properties of color, texture, shape and motion of images, videos and their objects-in the queries, and (2) its graphical query language, in which queries are posed by drawing, selecting and other graphical means. This article describes the QBIC system and demonstrates its query capabilities. QBIC technology is part of several IBM products. >"
            },
            "slug": "Query-by-Image-and-Video-Content:-The-QBIC-System-Flickner-Sawhney",
            "title": {
                "fragments": [],
                "text": "Query by Image and Video Content: The QBIC System"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The QBIC system is described and its query capabilities are demonstrated, which allows queries on large image and video databases based on example images, user-constructed sketches and drawings, selected color and texture patterns, camera and object motion, and other graphical information."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151194032"
                        ],
                        "name": "H. M\u00fcller",
                        "slug": "H.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Henning",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075011"
                        ],
                        "name": "N. Michoux",
                        "slug": "N.-Michoux",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Michoux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Michoux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123173"
                        ],
                        "name": "D. Bandon",
                        "slug": "D.-Bandon",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bandon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bandon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792536"
                        ],
                        "name": "A. Geissb\u00fchler",
                        "slug": "A.-Geissb\u00fchler",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Geissb\u00fchler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Geissb\u00fchler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 56
                            }
                        ],
                        "text": "feature weights based on user logs has been explored in [Muller et al. 2004]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 80
                            }
                        ],
                        "text": "2003] (useful for face based image retrieval), applications of CBIR to medicine [Muller et al. 2004], and applications to art and cultural imaging [Chen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 208
                            }
                        ],
                        "text": "\u2026feedback [Zhou and Huang 2003], high-dimensional indexing of multimedia data \n[Bohm et al. 2001], face recognition [Zhao et al. 2003] (useful for face-based image retrieval), applications \nof CBIR to medicine [Muller et al. 2004], and applications to art and cultural imaging [Chen et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5314914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb8704210358d0cbf5113c97e1f9f9f03f67e6fc",
            "isKey": false,
            "numCitedBy": 1601,
            "numCiting": 215,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-review-of-content-based-image-retrieval-systems-M\u00fcller-Michoux",
            "title": {
                "fragments": [],
                "text": "A review of content-based image retrieval systems in medical applications - clinical benefits and future directions"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Medical Informatics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 29
                            }
                        ],
                        "text": "The complexity is reduced in [Vasconcelos 2004] using VQ to approximately model the probability distribution of the image features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14760348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f56b2f5ad446c165375635d21a8eeb67cbd0ce1d",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic approaches are a promising solution to the image retrieval problem that, when compared to standard retrieval methods, can lead to a significant gain in retrieval accuracy. However, this occurs at the cost of a significant increase in computational complexity. In fact, closed-form solutions for probabilistic retrieval are currently available only for simple probabilistic models such as the Gaussian or the histogram. We analyze the case of mixture densities and exploit the asymptotic equivalence between likelihood and Kullback-Leibler (KL) divergence to derive solutions for these models. In particular, 1) we show that the divergence can be computed exactly for vector quantizers (VQs) and 2) has an approximate solution for Gauss mixtures (GMs) that, in high-dimensional feature spaces, introduces no significant degradation of the resulting similarity judgments. In both cases, the new solutions have closed-form and computational complexity equivalent to that of standard retrieval approaches."
            },
            "slug": "On-the-efficient-evaluation-of-probabilistic-for-Vasconcelos",
            "title": {
                "fragments": [],
                "text": "On the efficient evaluation of probabilistic similarity functions for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that the divergence can be computed exactly for vector quantizers (VQs) and has an approximate solution for Gauss mixtures (GMs) that, in high-dimensional feature spaces, introduces no significant degradation of the resulting similarity judgments."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731570"
                        ],
                        "name": "M. Lew",
                        "slug": "M.-Lew",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lew",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705776"
                        ],
                        "name": "C. Djeraba",
                        "slug": "C.-Djeraba",
                        "structuredName": {
                            "firstName": "Chabane",
                            "lastName": "Djeraba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Djeraba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 387449,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "cabe73e89b6389a163393ecbf1b82d20ba4ea10f",
            "isKey": false,
            "numCitedBy": 1725,
            "numCiting": 225,
            "paperAbstract": {
                "fragments": [],
                "text": "Extending beyond the boundaries of science, art, and culture, content-based multimedia information retrieval provides new paradigms and methods for searching through the myriad variety of media all over the world. This survey reviews 100+ recent articles on content-based multimedia information retrieval and discusses their role in current research directions which include browsing and search paradigms, user studies, affective computing, learning, semantic queries, new features and media types, high performance indexing, and evaluation techniques. Based on the current state of the art, we discuss the major challenges for the future."
            },
            "slug": "Content-based-multimedia-information-retrieval:-of-Lew-Sebe",
            "title": {
                "fragments": [],
                "text": "Content-based multimedia information retrieval: State of the art and challenges"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This survey reviews 100+ recent articles on content-based multimedia information retrieval and discusses their role in current research directions which include browsing and search paradigms, user studies, affective computing, learning, semantic queries, new features and media types, high performance indexing, and evaluation techniques."
            },
            "venue": {
                "fragments": [],
                "text": "TOMCCAP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145208646"
                        ],
                        "name": "H. Ma\u00eetre",
                        "slug": "H.-Ma\u00eetre",
                        "structuredName": {
                            "firstName": "Henri",
                            "lastName": "Ma\u00eetre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ma\u00eetre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1946526"
                        ],
                        "name": "F. Schmitt",
                        "slug": "F.-Schmitt",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Schmitt",
                            "middleNames": [
                                "J.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Schmitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3168715"
                        ],
                        "name": "C. Lahanier",
                        "slug": "C.-Lahanier",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lahanier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lahanier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29800956,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a3bad675e12b04afc16bed1717d915c83375273",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the last 20 years, several efforts have been devoted to the application of image processing and digital imaging techniques to art research in a context of close collaboration between the Centre de Recherche et de Restauration des Muse/spl acute/es de France (C2RMF) and the Ecole Nationale Superieure des Telecommunications (ENST). These efforts often found developments within National or European projects and were only made possible by the strong support of many partners throughout Europe. This set of projects and some of its results are presented, covering acquisition of information (from photos, or directly from paintings or objects), as well as storage management, database consulting, and image processing for pattern recognition and feature extraction."
            },
            "slug": "15-years-of-image-processing-and-the-fine-arts-Ma\u00eetre-Schmitt",
            "title": {
                "fragments": [],
                "text": "15 years of image processing and the fine arts"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This set of projects and some of its results are presented, covering acquisition of information (from photos, or directly from paintings or objects), as well as storage management, database consulting, and image processing for pattern recognition and feature extraction."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3300216"
                        ],
                        "name": "Anlei Dong",
                        "slug": "Anlei-Dong",
                        "structuredName": {
                            "firstName": "Anlei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anlei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144452270"
                        ],
                        "name": "B. Bhanu",
                        "slug": "B.-Bhanu",
                        "structuredName": {
                            "firstName": "Bir",
                            "lastName": "Bhanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bhanu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 607655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae60d481d0546501edaa4afc4e798159e2f3eeef",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 139,
            "paperAbstract": {
                "fragments": [],
                "text": "Concept learning in content-based image retrieval (CBIR) systems is a challenging task. We present an active concept learning approach based on mixture model to deal with the two basic aspects of a database system: changing (image insertion or removal) nature of a database and user queries. To achieve concept learning, we develop a novel model selection method based on Bayesian analysis that evaluates the consistency of hypothesized models with the available information. The analysis of exploitation vs. exploration in the search space helps to find optimal model efficiently. Experimental results on Corel database show the efficacy of our approach."
            },
            "slug": "Active-concept-learning-for-image-retrieval-in-Dong-Bhanu",
            "title": {
                "fragments": [],
                "text": "Active concept learning for image retrieval in dynamic databases"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work develops a novel model selection method based on Bayesian analysis that evaluates the consistency of hypothesized models with the available information to achieve concept learning in content-based image retrieval systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741126"
                        ],
                        "name": "S. Hoi",
                        "slug": "S.-Hoi",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Hoi",
                            "middleNames": [
                                "C.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785083"
                        ],
                        "name": "Michael R. Lyu",
                        "slug": "Michael-R.-Lyu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lyu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 751695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "269e4b325ae331b7ddba491dbe34a2164edfd627",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback has been proposed as an important technique to boost the retrieval performance in content-based image retrieval (CBIR). However, since there exists a semantic gap between low-level features and high-level semantic concepts in CBIR, typical relevance feedback techniques need to perform a lot of rounds of feedback for achieving satisfactory results. These procedures are time-consuming and may make the users bored in the retrieval tasks. For a long-term study purpose in CBIR, we notice that the users' feedback logs can be available and employed for helping the retrieval tasks in CBIR systems. In this paper, we propose a novel scheme to study the log-based relevance feedback (LRF) technique for improving retrieval performance and reducing the semantic gap in CBIR. In order to effectively incorporate the users' feedback logs, we propose a modified support vector machine (SVM) technique called soft label support vector machine (SLSVM) to construct the LRF algorithm in CBIR. We conduct extensive experiments to evaluate the performance of our proposed algorithm. Compared with the typical approach using query expansion (QEX) technique, we demonstrate that our proposed scheme can significantly improve the retrieval performance of semantic image retrieval from detailed experiments."
            },
            "slug": "A-novel-log-based-relevance-feedback-technique-in-Hoi-Lyu",
            "title": {
                "fragments": [],
                "text": "A novel log-based relevance feedback technique in content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel scheme to study the log-based relevance feedback technique for improving retrieval performance and reducing the semantic gap in CBIR is proposed and it is demonstrated that the proposed scheme can significantly improve the retrieval performance of semantic image retrieval from detailed experiments."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791802"
                        ],
                        "name": "J. Jeon",
                        "slug": "J.-Jeon",
                        "structuredName": {
                            "firstName": "Jiwoon",
                            "lastName": "Jeon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jeon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 575890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18f8820e2a5ca6273a39123c27c0745870cda057",
            "isKey": false,
            "numCitedBy": 798,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries. We do this using a formalism that models the generation of annotated images. We assume that every image is divided into regions, each described by a continuous-valued feature vector. Given a training set of images with annotations, we compute a joint probabilistic model of image features and words which allow us to predict the probability of generating a word given the image regions. This may be used to automatically annotate and retrieve images given a word as a query. Experiments show that our model significantly outperforms the best of the previously reported results on the tasks of automatic image annotation and retrieval."
            },
            "slug": "A-Model-for-Learning-the-Semantics-of-Pictures-Lavrenko-Manmatha",
            "title": {
                "fragments": [],
                "text": "A Model for Learning the Semantics of Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries using a formalism that models the generation of annotated images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6477258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37217f11b576b2b43f245295553f1aca413d59ae",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval using region segmentation has been an active research area. We present IRM (Integrated Region Matching), a novel similarity measure for region-based image similarity comparison. The targeted image retrieval systems represent an image by a set of regions, roughly corresponding to objects, which are characterized by features reflecting color, texture, shape, and location properties. The IRM measure for evaluating overall similarity between images incorporates properties of all the regions in the images by a region-matching scheme. Compared with retrieval based on individual regions, the overall similarity approach reduces the influence of inaccurate segmentation, helps to clarify the semantics of a particular region, and enables a simple querying interface for region-based image retrieval systems. The IRM has been implemented as a part of our experimental SIMPLIcity image retrieval system. The application to a database of about 200,000 general-purpose images shows exceptional robustness to image alterations such as intensity variation, sharpness variation, color distortions, shape distortions, cropping, shifting, and rotation. Compared with several existing systems, our system in general achieves more accurate retrieval at higher speed."
            },
            "slug": "IRM:-integrated-region-matching-for-image-retrieval-Li-Wang",
            "title": {
                "fragments": [],
                "text": "IRM: integrated region matching for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The IRM measure for evaluating overall similarity between images incorporates properties of all the regions in the images by a region-matching scheme, which achieves more accurate retrieval at higher speed than several existing systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151194032"
                        ],
                        "name": "H. M\u00fcller",
                        "slug": "H.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Henning",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809085"
                        ],
                        "name": "T. Pun",
                        "slug": "T.-Pun",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Pun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760329"
                        ],
                        "name": "D. Squire",
                        "slug": "D.-Squire",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Squire",
                            "middleNames": [
                                "McG."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Squire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 208
                            }
                        ],
                        "text": "\u2026feedback [Zhou and Huang 2003], high-dimensional indexing of multimedia data \n[Bohm et al. 2001], face recognition [Zhao et al. 2003] (useful for face-based image retrieval), applications \nof CBIR to medicine [Muller et al. 2004], and applications to art and cultural imaging [Chen et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6521286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d38e7479a077db2d3e9abbd0ea0cb421249cbebc",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes an approach to learn feature weights for content-based image retrieval (CBIR) from user interaction log files. These usage log files are analyzed for images marked together by a user in the same query step. The problem is somewhat similar to one of the traditional data mining problems, the market basket analysis problem, where items bought together in a supermarket are analyzed. This paper outlines similarities and differences between the two fields and explains how to use the interaction data for deriving a better feature weighting.Experiments with existing log files are done and a significant improvement in performance is reached with a feature weighting calculated from the information contained in the log files. Even with several steps of relevance feedback the results remain much better than without the learning, which means that not only information from feedback is taken into account earlier, but a better quality of retrieval is reached in all steps."
            },
            "slug": "Learning-from-User-Behavior-in-Image-Retrieval:-of-M\u00fcller-Pun",
            "title": {
                "fragments": [],
                "text": "Learning from User Behavior in Image Retrieval: Application of Market Basket Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "In this article, an approach to learn feature weights for content-based image retrieval (CBIR) from user interaction log files is described and a significant improvement in performance is reached with a feature weighting calculated from the information contained in the log files."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1824057"
                        ],
                        "name": "Florent Monay",
                        "slug": "Florent-Monay",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Monay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Monay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1007967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c253729d6170b31972ded6bfec1ea502f3ff86e",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Image auto-annotation, i.e., the association of words to whole images, has attracted considerable attention. In particular, unsupervised, probabilistic latent variable models of text and image features have shown encouraging results, but their performance with respect to other approaches remains unknown. In this paper, we apply and compare two simple latent space models commonly used in text analysis, namely Latent Semantic Analysis (LSA) and Probabilistic LSA (PLSA). Annotation strategies for each model are discussed. Remarkably, we found that, on a 8000-image dataset, a classic LSA model defined on keywords and a very basic image representation performed as well as much more complex, state-of-the-art methods. Furthermore, non-probabilistic methods (LSA and direct image matching) outperformed PLSA on the same dataset."
            },
            "slug": "On-image-auto-annotation-with-latent-space-models-Monay-G\u00e1tica-P\u00e9rez",
            "title": {
                "fragments": [],
                "text": "On image auto-annotation with latent space models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper applies and compares two simple latent space models commonly used in text analysis, namely Latent Semantic Analysis (LSA) and Probabilistic LSA (PLSA), and found that, on a 8000-image dataset, a classic LSA model defined on keywords and a very basic image representation performed as well as much more complex, state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799970"
                        ],
                        "name": "C. Theoharatos",
                        "slug": "C.-Theoharatos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Theoharatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Theoharatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769222"
                        ],
                        "name": "N. Laskaris",
                        "slug": "N.-Laskaris",
                        "structuredName": {
                            "firstName": "Nikolaos",
                            "lastName": "Laskaris",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laskaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145354366"
                        ],
                        "name": "G. Economou",
                        "slug": "G.-Economou",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Economou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Economou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769294"
                        ],
                        "name": "S. Fotopoulos",
                        "slug": "S.-Fotopoulos",
                        "structuredName": {
                            "firstName": "Spiros",
                            "lastName": "Fotopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fotopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17299180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "411eaed729660cfd56a2b9add224013c35cb1318",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this study, a conceptually simple, yet flexible and extendable strategy to contrast two different color images is introduced. The proposed approach is based on the multivariate Wald-Wolfowitz test, a nonparametric test that assesses the commonality between two different sets of multivariate observations. It provides an aggregate gauge of the match between color images, taking into consideration all the (selected) low-level characteristics, while alleviating correspondence issues. We show that a powerful measure of similarity between two color images can emerge from the statistical comparison of their representations in a properly formed feature space. For the sake of simplicity, the RGB-space is selected as the feature space, while we are experimenting with different ways to represent the images within this space. By altering the feature-extraction implementation, complementary ways to portray the image content appear. The reported results, from the application on a diverse collection of images, clearly demonstrate the effectiveness of our method, its superiority over previous methods, and suggest that even further improvements can be achieved along the same line of research. It is not only the unifying character that makes our strategy appealing, but also the fact that the retrieval performance does not increase continuously with the amount of details in the image representation. The latter sets an upper limit to the computational demands and reminds of performance plateaus reached by novel approaches in information retrieval."
            },
            "slug": "A-generic-scheme-for-color-image-retrieval-based-on-Theoharatos-Laskaris",
            "title": {
                "fragments": [],
                "text": "A generic scheme for color image retrieval based on the multivariate Wald-Wolfowitz test"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that a powerful measure of similarity between two color images can emerge from the statistical comparison of their representations in a properly formed feature space, and sets an upper limit to the computational demands and reminds of performance plateaus reached by novel approaches in information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058177533"
                        ],
                        "name": "Simon Tong",
                        "slug": "Simon-Tong",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 64
                            }
                        ],
                        "text": "Active learning using SVMs \nwas proposed for relevance feedback [Tong and Chang 2001] and helped to popularize active learning in \nother domains as well."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "Active learning using SVMs were proposed for relevance feedback [Tong and Chang 2001] and helped popularize active learning in other domains as well."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 53
                            }
                        ],
                        "text": "Active learning using SVMs was introduced into RF in [Tong and Chang 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10743717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63861fbeb7ec41986b85965b9780b428d919919e",
            "isKey": true,
            "numCitedBy": 1510,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is often a critical component when designing image databases. With these databases it is difficult to specify queries directly and explicitly. Relevance feedback interactively determinines a user's desired output or query concept by asking the user whether certain proposed images are relevant or not. For a relevance feedback algorithm to be effective, it must grasp a user's query concept accurately and quickly, while also only asking the user to label a small number of images. We propose the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval. The algorithm selects the most informative images to query a user and quickly learns a boundary that separates the images that satisfy the user's query concept from the rest of the dataset. Experimental results show that our algorithm achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback."
            },
            "slug": "Support-vector-machine-active-learning-for-image-Tong-Chang",
            "title": {
                "fragments": [],
                "text": "Support vector machine active learning for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval and achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09932c4c63a2b15987baec125eb70440aaa9c9d6",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Developing effective methods for automated annotation of digital pictures continues to challenge computer scientists. The capability of annotating pictures by computers can lead to breakthroughs in a wide range of applications, including Web image search, online picture-sharing communities, and scientific experiments. In this work, the authors developed new optimization and estimation techniques to address two fundamental problems in machine learning. These new techniques serve as the basis for the automatic linguistic indexing of pictures - real time (ALIPR) system of fully automatic and high-speed annotation for online pictures. In particular, the D2-clustering method, in the same spirit as K-Means for vectors, is developed to group objects represented by bags of weighted vectors. Moreover, a generalized mixture modeling technique (kernel smoothing as a special case) for nonvector data is developed using the novel concept of hypothetical local mapping (HLM). ALIPR has been tested by thousands of pictures from an Internet photo-sharing site, unrelated to the source of those pictures used in the training process. Its performance has also been studied at an online demonstration site, where arbitrary users provide pictures of their choices and indicate the correctness of each annotation word. The experimental results show that a single computer processor can suggest annotation terms in real time and with good accuracy."
            },
            "slug": "Real-Time-Computerized-Annotation-of-Pictures-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Real-Time Computerized Annotation of Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "New optimization and estimation techniques to address two fundamental problems in machine learning are developed that serve as the basis for the automatic linguistic indexing of pictures - real time (ALIPR) system of fully automatic and high-speed annotation for online pictures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7661726"
                        ],
                        "name": "Alexander Hauptmann",
                        "slug": "Alexander-Hauptmann",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hauptmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hauptmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772930"
                        ],
                        "name": "Michael G. Christel",
                        "slug": "Michael-G.-Christel",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Christel",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael G. Christel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 113
                            }
                        ],
                        "text": "It has been observed and reported that multi\u00admodal fusion almost always enhances retrieval performance \nfor video [Hauptmann and Christel 2004]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 112
                            }
                        ],
                        "text": "It has been observed and reported that multimodal fusion almost always enhances retrieval performance for video [Hauptmann and Christel 2004]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5885906,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11a2592244e2d737fc87572db55dc4bbfe95897b",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews successful approaches in evaluations of video retrieval over the last three years. The task involves the search and retrieval of shots from MPEG digitized video recordings using a combination of automatic speech, image and video analysis and information retrieval technologies. The search evaluations are grouped into interactive (with a human in the loop) and non-interactive (where the human merely enters the query into the system) submissions. Most non-interactive search approaches have relied extensively on text retrieval, and only recently have image-based features contributed reliably to improved search performance. Interactive approaches have substantially outperformed all non-interactive approaches, with most systems relying heavily on the user's ability to refine queries and reject spurious answers. We will examine both the successful automatic search approaches and the user interface techniques that have enabled high performance video retrieval."
            },
            "slug": "Successful-approaches-in-the-TREC-video-retrieval-Hauptmann-Christel",
            "title": {
                "fragments": [],
                "text": "Successful approaches in the TREC video retrieval evaluations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Interactive approaches have substantially outperformed all non-interactive approaches, with most systems relying heavily on the user's ability to refine queries and reject spurious answers."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2836317"
                        ],
                        "name": "O. Firschein",
                        "slug": "O.-Firschein",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Firschein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Firschein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8776998"
                        ],
                        "name": "S. Wei",
                        "slug": "S.-Wei",
                        "structuredName": {
                            "firstName": "Sha",
                            "lastName": "Wei",
                            "middleNames": [
                                "Xin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2269151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "647801bdf050f6046f98d9b97b56fc1df4d06af6",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. This paper describes WBIIS (Wavelet-Based Image Indexing and Searching), a new image indexing and retrieval algorithm with partial sketch image searching capability for large image databases. The algorithm characterizes the color variations over the spatial extent of the image in a manner that provides semantically meaningful image comparisons. The indexing algorithm applies a Daubechies' wavelet transform for each of the three opponent color components. The wavelet coefficients in the lowest few frequency bands, and their variances, are stored as feature vectors. To speed up retrieval, a two-step procedure is used that first does a crude selection based on the variances, and then refines the search by performing a feature vector match between the selected images and the query. For better accuracy in searching, two-level multiresolution matching may also be used. Masks are used for partial-sketch queries. This technique performs much better in capturing coherence of image, object granularity, local color/texture, and bias avoidance than traditional color layout algorithms. WBIIS is much faster and more accurate than traditional algorithms. When tested on a database of more than 10 000 general-purpose images, the best 100 matches were found in 3.3 seconds."
            },
            "slug": "Content-based-image-indexing-and-searching-using-Wang-Wiederhold",
            "title": {
                "fragments": [],
                "text": "Content-based image indexing and searching using Daubechies' wavelets"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "WBIIS (Wavelet-Based Image Indexing and Searching), a new image indexing and retrieval algorithm with partial sketch image searching capability for large image databases, which performs much better in capturing coherence of image, object granularity, local color/texture, and bias avoidance than traditional color layout algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Digital Libraries"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068300013"
                        ],
                        "name": "Rong Jin",
                        "slug": "Rong-Jin",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7661726"
                        ],
                        "name": "Alexander Hauptmann",
                        "slug": "Alexander-Hauptmann",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hauptmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hauptmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15436082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88fd1a06f27f49215018fe1c621195265f8d9686",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a probabilistic model for image retrieval. To obtain the similarity between the query image IQ and any image I' in the collection, the model computes the probability of generating the image I' given the observation of the query image I/sub Q/. We compare our probabilistic model for image retrieval with a color histogram based image retrieval method and the IBM QBIC image search engine. The evaluation used the 11-hour video retrieval collection (80,000 extracted images) and associated queries from the 2001 TREC-10 information retrieval evaluations. The experimental results show that the probabilistic model dramatically outperforms the color histogram based image retrieval method and the IBM QBIC image search engine by 40%."
            },
            "slug": "Using-a-probabilistic-source-model-for-comparing-Jin-Hauptmann",
            "title": {
                "fragments": [],
                "text": "Using a probabilistic source model for comparing images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The experimental results show that the probabilistic model dramatically outperforms the color histogram based image retrieval method and the IBM QBIC image search engine by 40%."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2167589788"
                        ],
                        "name": "Youngok Choi",
                        "slug": "Youngok-Choi",
                        "structuredName": {
                            "firstName": "Youngok",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Youngok Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34066017"
                        ],
                        "name": "E. Rasmussen",
                        "slug": "E.-Rasmussen",
                        "structuredName": {
                            "firstName": "Edie",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rasmussen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 23051652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a48cbf10b80b93db98c1b6ac6bbd11974887c9b",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Users'-relevance-criteria-in-image-retrieval-in-Choi-Rasmussen",
            "title": {
                "fragments": [],
                "text": "Users' relevance criteria in image retrieval in American history"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47903949"
                        ],
                        "name": "Ying-Hong Wang",
                        "slug": "Ying-Hong-Wang",
                        "structuredName": {
                            "firstName": "Ying-Hong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying-Hong Wang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14522474,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49448acafba545d3cb273cd4d71b4b9d181a5207",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-indexing-and-similarity-retrieval-based-on-Wang",
            "title": {
                "fragments": [],
                "text": "Image indexing and similarity retrieval based on spatial relationship model"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Sci."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84635637"
                        ],
                        "name": "Feng Jing",
                        "slug": "Feng-Jing",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Feng Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83641876"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mingjing Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1455809482"
                        ],
                        "name": "Hong-Jiang Zhang",
                        "slug": "Hong-Jiang-Zhang",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Hong-Jiang Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong-Jiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080457053"
                        ],
                        "name": "Bo Zhang",
                        "slug": "Bo-Zhang",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Bo Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6302008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f6bfec1255a9d1434dde6d27866ca91392fadc0",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "An image retrieval framework that integrates efficient region-based representation in terms of storage and complexity and effective on-line learning capability is proposed. The framework consists of methods for region-based image representation and comparison, indexing using modified inverted files, relevance feedback, and learning region weighting. By exploiting a vector quantization method, both compact and sparse (vector) region-based image representations are achieved. Using the compact representation, an indexing scheme similar to the inverted file technology and an image similarity measure based on Earth Mover's Distance are presented. Moreover, the vector representation facilitates a weighted query point movement algorithm and the compact representation enables a classification-based algorithm for relevance feedback. Based on users' feedback information, a region weighting strategy is also introduced to optimally weight the regions and enable the system to self-improve. Experimental results on a database of 10 000 general-purposed images demonstrate the efficiency and effectiveness of the proposed framework."
            },
            "slug": "An-efficient-and-effective-region-based-image-Jing-Li",
            "title": {
                "fragments": [],
                "text": "An efficient and effective region-based image retrieval framework"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An image retrieval framework that integrates efficient region-based representation in terms of storage and complexity and effective on-line learning capability and a region weighting strategy is introduced to optimally weight the regions and enable the system to self-improve."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110134649"
                        ],
                        "name": "Xin Zheng",
                        "slug": "Xin-Zheng",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724421"
                        ],
                        "name": "Deng Cai",
                        "slug": "Deng-Cai",
                        "structuredName": {
                            "firstName": "Deng",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deng Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3945955"
                        ],
                        "name": "Xiaofei He",
                        "slug": "Xiaofei-He",
                        "structuredName": {
                            "firstName": "Xiaofei",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofei He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2693354"
                        ],
                        "name": "X. Lin",
                        "slug": "X.-Lin",
                        "structuredName": {
                            "firstName": "Xueyin",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1473802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f06435ec19b5cfd168c92c3ef2728f4a7aad12cd",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "It is important and challenging to make the growing image repositories easy to search and browse. Image clustering is a technique that helps in several ways, including image data preprocessing, user interface designing, and search result representation. Spectral clustering method has been one of the most promising clustering methods in the last few years, because it can cluster data with complex structure, and the (near) global optimum is guaranteed. However, existing spectral clustering algorithms, like Normalized Cut, are difficult to handle data points out of training set. In this paper, we propose a clustering algorithm named Locality Preserving Clustering (LPC), which shares many of the data representation properties of nonlinear spectral method. Yet LPC provides an explicit mapping function which is defined everywhere, both on training data points and testing points. Experimental results show that LPC is more accurate than both \"direct Kmeans\" and \"PCA + Kmeans\". We also show that LPC produces in general comparable results with Normalized Cut, yet is more efficient than Normalized Cut."
            },
            "slug": "Locality-preserving-clustering-for-image-database-Zheng-Cai",
            "title": {
                "fragments": [],
                "text": "Locality preserving clustering for image database"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a clustering algorithm named Locality Preserving Clustering (LPC), which shares many of the data representation properties of nonlinear spectral method, yet provides an explicit mapping function which is defined everywhere, both on training data points and testing points."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109078020"
                        ],
                        "name": "Li-Qun Chen",
                        "slug": "Li-Qun-Chen",
                        "structuredName": {
                            "firstName": "Li-Qun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Qun Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144076239"
                        ],
                        "name": "Xing Xie",
                        "slug": "Xing-Xie",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117800912"
                        ],
                        "name": "X. Fan",
                        "slug": "X.-Fan",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2457832"
                        ],
                        "name": "He-Qin Zhou",
                        "slug": "He-Qin-Zhou",
                        "structuredName": {
                            "firstName": "He-Qin",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He-Qin Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14354903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "929958ab2b7c86095c9c6aadd4848f44ebba0500",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Image adaptation, one of the essential problems in adaptive content delivery for universal access, has been actively explored for some time. Most existing approaches have focused on generic adaptation with a view to saving file size under constraints in client environment and have hardly paid attention to user perceptions of the adapted result. Meanwhile, the major limitation on the user\u2019s delivery context is moving away from data volume (or time-to-wait) to screen size because of the galloping development of hardware technologies. In this paper, we propose a novel method for adapting images based on user attention. A generic and extensible image attention model is introduced based on three attributes (region of interest, attention value, and minimal perceptible size) associated with each attention object. A set of automatic modeling methods are presented to support this approach. A branch-and-bound algorithm is also developed to find the optimal adaptation efficiently. Experimental results demonstrate the usefulness of the proposed scheme and its potential application in the future."
            },
            "slug": "A-visual-attention-model-for-adapting-images-on-Chen-Xie",
            "title": {
                "fragments": [],
                "text": "A visual attention model for adapting images on small displays"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A generic and extensible image attention model is introduced based on three attributes (region of interest, attention value, and minimal perceptible size) associated with each attention object and a branch-and-bound algorithm is developed to find the optimal adaptation efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111935840"
                        ],
                        "name": "Yanping Du",
                        "slug": "Yanping-Du",
                        "structuredName": {
                            "firstName": "Yanping",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanping Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10726926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d29d58a02e8756cdd6707ae47f51d01f2c95bf61",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a scalable algorithm for indexing and retrieving images based on region segmentation. The method uses statistical clustering on region features and IRM (integrated region matching), a measure developed to evaluate overall similarity between images. It incorporates properties of all the regions in the images by a region-matching scheme. The algorithm has been implemented as a part of our experimental SIMPLIcity (Semantics-sensitive Integrated Matching for Picture LIbraries) image retrieval system and tested on large-scale image databases of both general-purpose images and pathology slides. Experiments have demonstrated that this technique maintains the accuracy of the original system while reducing the matching time significantly."
            },
            "slug": "A-scalable-integrated-region-based-image-retrieval-Du-Wang",
            "title": {
                "fragments": [],
                "text": "A scalable integrated region-based image retrieval system"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A scalable algorithm for indexing and retrieving images based on region segmentation using statistical clustering on region features and IRM (integrated region matching), a measure developed to evaluate overall similarity between images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5113463"
                        ],
                        "name": "D. Joshi",
                        "slug": "D.-Joshi",
                        "structuredName": {
                            "firstName": "Dhiraj",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 86
                            }
                        ],
                        "text": "To this end, a recent attempt at bridging the retrieval-annotation gap has been made \n[Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14555993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12ea92a54a8c67934aa8740863ef0d3e48cb681d",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic image annotation has been a hot-pursuit among multimedia researchers of late. Modest performance guarantees and limited adaptability often restrict its applicability to real-world settings. We propose tagging over time (T/T) to push the technology toward real-world applicability. Of particular interest are online systems that receive user-provided images and feedback over time, with user focus possibly changing and evolving. The T/T framework consists of a principled probabilistic approach to meta-learning, which acts as a go-between for a 'black-box' annotation system and the users. Inspired by inductive transfer, the approach attempts to harness available information, including the black-box model's performance, the image representations, and the WordNet ontology. Being computationally 'lightweight', this meta-learner efficiently re-trains over time, to improve and/or adapt to changes. The black-box annotation model is not required to be re-trained, allowing computationally intensive algorithms to be used. We experiment with standard image datasets and real-world data streams, using two existing annotation systems as black-boxes. Both batch and online annotation settings are experimented with. It is observed that the addition of this meta-learning layer produces much improved results that outperform best-known results. For the online setting, the T/T approach produces progressively better annotation with time, significantly outperforming the black-box as well as the static form of the meta-learner, on real-world data."
            },
            "slug": "Tagging-over-time:-real-world-image-annotation-by-Datta-Joshi",
            "title": {
                "fragments": [],
                "text": "Tagging over time: real-world image annotation by lightweight meta-learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is observed that the addition of this meta-learning layer produces much improved results that outperform best-known results, and the T/T approach produces progressively better annotation with time, significantly outperforming the black-box as well as the static form of the meta-learner, on real-world data."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507859"
                        ],
                        "name": "S. Berretti",
                        "slug": "S.-Berretti",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Berretti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Berretti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680785"
                        ],
                        "name": "E. Vicario",
                        "slug": "E.-Vicario",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Vicario",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vicario"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2548004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fd8b558eb2251d6f8da7f44bdb28bd12a76c95a",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "In retrieval from image databases, evaluation of similarity, based both on the appearance of spatial entities and on their mutual relationships, depends on content representation based on attributed relational graphs. This kind of modeling entails complex matching and indexing, which presently prevents its usage within comprehensive applications. In this paper, we provide a graph-theoretical formulation for the problem of retrieval based on the joint similarity of individual entities and of their mutual relationships and we expound its implications on indexing and matching. In particular, we propose the usage of metric indexing to organize large archives of graph models, and we propose an original look-ahead method which represents an efficient solution for the (sub)graph error correcting isomorphism problem needed to compute object distances. Analytic comparison and experimental results show that the proposed lookahead improves the state-of-the-art in state-space search methods and that the combined use of the proposed matching and indexing scheme permits for the management of the complexity of a typical application of retrieval by spatial arrangement."
            },
            "slug": "Efficient-Matching-and-Indexing-of-Graph-Models-in-Berretti-Bimbo",
            "title": {
                "fragments": [],
                "text": "Efficient Matching and Indexing of Graph Models in Content-Based Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Analytic comparison and experimental results show that the proposed lookahead improves the state-of-the-art in state-space search methods and that the combined use of the proposed matching and indexing scheme permits for the management of the complexity of a typical application of retrieval by spatial arrangement."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "Lecture Notes in Computer Science, vol. 3246, 131 133."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 68
                            }
                        ],
                        "text": "The TRECVID workshop, conducted yearly by the National Institute of Science \nand Technology (NIST), attracts research teams from all over the world for addressing competitive problems \nin content-based video search and retrieval."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "Lecture \nNotes in Computer Science, vol. 2383."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 52
                            }
                        ],
                        "text": "Authors addresses: R. Datta, Department of Computer Science and Engineering, \nThe Pennsylvania State University, University Park, PA 16802; email: {datta,djoshi}@cse.psu.edu; D. Joshi, \nKodak Research Labs, Rochester, NY 146050; email: dhiraj.joshi@kodak.com; J. Li, Department of Statistics, \nThe Pennsylva\u00adnia State University, University Park, PA 16802; email: jiali@stat.psu.edu; J. Z. Wang, \nCollege of Infor\u00ad mation Sciences and Technology, The Pennsylvania State University, University Park, \nPA 16802; email: jwang@ist.psu.edu."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "Lecture Notes in Computer Science, vol. 3408."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 121
                            }
                        ],
                        "text": "Any attempt to express \nwhat makes a portrait perfect may end up This material is based on work supported by the National Science \nFoundation under Grant Numbers 0347148 and 0705210."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 194
                            }
                        ],
                        "text": "\u2026dhiraj.joshi@kodak.com; J. Li, Department of Statistics, \nThe Pennsylva\u00adnia State University, University Park, PA 16802; email: jiali@stat.psu.edu; J. Z. Wang, \nCollege of Infor\u00ad mation Sciences and Technology, The Pennsylvania State University, University Park, \nPA 16802; email: jwang@ist.psu.edu."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "Lecture Notes in Computer Science, Vol. 3538."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1608216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6182e4e462fd25ac6e1744415b481d422c861b2",
            "isKey": true,
            "numCitedBy": 474,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Effective image retrieval by content from database requires that visual image properties are used instead of textual labels to properly index and recover pictorial data. Retrieval by shape similarity, given a user-sketched template is particularly challenging, owing to the difficulty to derive a similarity measure that closely conforms to the common perception of similarity by humans. In this paper, we present a technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks. The degree of matching achieved and the elastic deformation energy spent by the sketch to achieve such a match are used to derive a measure of similarity between the sketch and the images in the database and to rank images to be displayed. The elastic matching is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries. Examples from a prototype system are expounded with considerations about the effectiveness of the approach and comparative performance analysis."
            },
            "slug": "Visual-Image-Retrieval-by-Elastic-Matching-of-User-Bimbo-Pala",
            "title": {
                "fragments": [],
                "text": "Visual Image Retrieval by Elastic Matching of User Sketches"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks and is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772930"
                        ],
                        "name": "Michael G. Christel",
                        "slug": "Michael-G.-Christel",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Christel",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael G. Christel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3287942"
                        ],
                        "name": "R. Conescu",
                        "slug": "R.-Conescu",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Conescu",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Conescu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17335974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "105f61be8e4dd066410b078f3f9cff25ac970d85",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "While it would seem that digital video libraries should benefit from access mechanisms directed to their visual contents, years of TREC video retrieval evaluation (TRECVID) research have shown that text search against transcript narrative text provides almost all the retrieval capability, even with visually oriented generic topics. A within-subjects study involving 24 novice participants on TRECVID 2004 tasks again confirms this result. The study shows that satisfaction is greater and performance is significantly better on specific and generic information retrieval tasks from news broadcasts when transcripts are available for search. Additional runs with 7 expert users reveal different novice and expert interaction patterns with the video library interface, helping explain the novices' lack of success with image search and visual feature browsing for visual information needs. Analysis of TRECVID visual features well suited for particular tasks provides additional insights into the role of automated feature classification for digital image and video libraries"
            },
            "slug": "Addressing-the-challenge-of-visual-information-from-Christel-Conescu",
            "title": {
                "fragments": [],
                "text": "Addressing the challenge of visual information access from digital image and video libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Analysis of TRECVID visual features well suited for particular tasks provides additional insights into the role of automated feature classification for digital image and video libraries."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 5th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL '05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185984"
                        ],
                        "name": "Beitao Li",
                        "slug": "Beitao-Li",
                        "structuredName": {
                            "firstName": "Beitao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beitao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40603954"
                        ],
                        "name": "Kingshy Goh",
                        "slug": "Kingshy-Goh",
                        "structuredName": {
                            "firstName": "Kingshy",
                            "lastName": "Goh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kingshy Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16514895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ee039908281e7a745eca4baccf0d1bbf95e8fcf",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Providing accurate and scalable solutions to map low-level perceptual features to high-level semantics is critical for multimedia information organization and retrieval. In this paper, we propose a confidence-based dynamic ensemble (CDE) to overcome the shortcomings of the traditional static classifiers. In contrast to the traditional models, CDE can make dynamic adjustments to accommodate new semantics, to assist the discovery of useful low-level features, and to improve class-prediction accuracy. We depict two key components of CDE: a multi-level function that asserts class-prediction confidence, and the dynamic ensemble method based upon the confidence function. Through theoretical analysis and empirical study, we demonstrate that CDE is effective in annotating large-scale, real-world image datasets."
            },
            "slug": "Confidence-based-dynamic-ensemble-for-image-and-Li-Goh",
            "title": {
                "fragments": [],
                "text": "Confidence-based dynamic ensemble for image annotation and semantics discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a confidence-based dynamic ensemble (CDE) to overcome the shortcomings of the traditional static classifiers and demonstrates that CDE is effective in annotating large-scale, real-world image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144044737"
                        ],
                        "name": "Peng Wu",
                        "slug": "Peng-Wu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7414742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04d1fd9e1a57b41727f1e85751294605c4b72723",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is often used in refining similarity retrievals in image and video databases. Typically this involves modification to the similarity metrics based on the user feedback and recomputing a set of nearest neighbors using the modified similarity values. Such nearest neighbor computations are expensive given that typical image features, such as color and texture, are represented in high dimensional spaces. Search complexity is a ciritcal issue while dealing with large databases and this issue has not received much attention in relevance feedback research. Most of the current methods report results on very small data sets, of the order of few thousand items, where a sequential (and hence exhaustive search) is practical. The main contribution of this paper is a novel algorithm for adaptive nearest neigbor computations for high dimensional feature vectors and when the number of items in the databse is large. The proposed method exploits the correlations between two consecutive nearest neighbor searches when the underlying similarity metric is changing, and filters out a significant number of candidates ina two stage search and retrieval process, thus reducing the number of I/O accesses to the database. Detailed experimental results are provided using a set of about 700,000 images. Comparision to the existing method shows an order of magnitude overall imporovement."
            },
            "slug": "Adaptive-nearest-neighbor-search-for-relevance-in-Wu-Manjunath",
            "title": {
                "fragments": [],
                "text": "Adaptive nearest neighbor search for relevance feedback in large image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel algorithm for adaptive nearest neigbor computations for high dimensional feature vectors and when the number of items in the databse is large, which exploits the correlations between two consecutive nearest neighbor searches when the underlying similarity metric is changing."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9590512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a41681900f295a3098592c1040b35b6e3767c96",
            "isKey": false,
            "numCitedBy": 1739,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "We present here SIMPLIcity (semantics-sensitive integrated matching for picture libraries), an image retrieval system, which uses semantics classification methods, a wavelet-based approach for feature extraction, and integrated region matching based upon image segmentation. An image is represented by a set of regions, roughly corresponding to objects, which are characterized by color, texture, shape, and location. The system classifies images into semantic categories. Potentially, the categorization enhances retrieval by permitting semantically-adaptive searching methods and narrowing down the searching range in a database. A measure for the overall similarity between images is developed using a region-matching scheme that integrates properties of all the regions in the images. The application of SIMPLIcity to several databases has demonstrated that our system performs significantly better and faster than existing ones. The system is fairly robust to image alterations."
            },
            "slug": "SIMPLIcity:-Semantics-Sensitive-Integrated-Matching-Wang-Li",
            "title": {
                "fragments": [],
                "text": "SIMPLIcity: Semantics-sensitive Integrated Matching for Picture Libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "SIMPLIcity (semantics-sensitive integrated matching for picture libraries), an image retrieval system, which uses semantics classification methods, a wavelet-based approach for feature extraction, and integrated region matching based upon image segmentation to improve retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820908"
                        ],
                        "name": "A. Natsev",
                        "slug": "A.-Natsev",
                        "structuredName": {
                            "firstName": "Apostol",
                            "lastName": "Natsev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Natsev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780080"
                        ],
                        "name": "M. Naphade",
                        "slug": "M.-Naphade",
                        "structuredName": {
                            "firstName": "Milind",
                            "lastName": "Naphade",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Naphade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789352"
                        ],
                        "name": "Jelena Tesic",
                        "slug": "Jelena-Tesic",
                        "structuredName": {
                            "firstName": "Jelena",
                            "lastName": "Tesic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jelena Tesic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8064903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15ad1172c85adb4a067b156d0624474b4bf8bc94",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we unify two supposedly distinct tasks in multimedia retrieval. One task involves answering queries with a few examples. The other involves learning models for semantic concepts, also with a few examples. In our view these two tasks are identical with the only differentiation being the number of examples that are available for training. Once we adopt this unified view, we then apply identical techniques for solving both problems and evaluate the performance using the NIST TRECVID benchmark evaluation data [15]. We propose a combination hypothesis of two complementary classes of techniques, a nearest neighbor model using only positive examples and a discriminative support vector machine model using both positive and negative examples. In case of queries, where negative examples are rarely provided to seed the search, we create pseudo-negative samples. We then combine the ranked lists generated by evaluating the test database using both methods, to create a final ranked list of retrieved multimedia items. We evaluate this approach for rare concept and query topic modeling using the NIST TRECVID video corpus.In both tasks we find that applying the combination hypothesis across both modeling techniques and a variety of features results in enhanced performance over any of the baseline models, as well as in improved robustness with respect to training examples and visual features. In particular, we observe an improvement of 6% for rare concept detection and 17% for the search task."
            },
            "slug": "Learning-the-semantics-of-multimedia-queries-and-a-Natsev-Naphade",
            "title": {
                "fragments": [],
                "text": "Learning the semantics of multimedia queries and concepts from a small number of examples"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In both tasks, applying the combination hypothesis across both modeling techniques and a variety of features results in enhanced performance over any of the baseline models, as well as in improved robustness with respect to training examples and visual features."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424352"
                        ],
                        "name": "M. Beigi",
                        "slug": "M.-Beigi",
                        "structuredName": {
                            "firstName": "Mandis",
                            "lastName": "Beigi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beigi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143761956"
                        ],
                        "name": "A. Benitez",
                        "slug": "A.-Benitez",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Benitez",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Benitez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5601548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72341893ede4bcb44dd8344d562798c5eb6adace",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital images and video are becoming an integral part of human communications. The ease of capturing and creating digital images has caused most on-line information sources look more \u201cvisual\u201d. We use more and more visual content in expressing ideas, reporting, education, and entertainment. With the tremendous amount of visual information becoming on-line, how does one find visual information from distributed repositories efficiently, at least to the same extent as that of existing information retrieval systems. With the growing number of on-line users, how does one design a system with performance scalable to a large extent?"
            },
            "slug": "Visual-information-retrieval-from-large-distributed-Chang-Smith",
            "title": {
                "fragments": [],
                "text": "Visual information retrieval from large distributed online repositories"
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5493306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a8660582f5b07727906a43d737fda902a312eb",
            "isKey": false,
            "numCitedBy": 786,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the Photobook system, which is a set of interactive tools for browsing and searching images and image sequences. These tools differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations. Direct search on image content is made possible by use of semantics-preserving image compression, which reduces images to a small set of perceptually-significant coefficients. We describe three Photobook tools in particular: one that allows search based on grey-level appearance, one that uses 2D shape, and a third that allows search based on textural properties."
            },
            "slug": "Photobook:-tools-for-content-based-manipulation-of-Pentland-Picard",
            "title": {
                "fragments": [],
                "text": "Photobook: tools for content-based manipulation of image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The Photobook system is described, which is a set of interactive tools for browsing and searching images and image sequences that differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808594"
                        ],
                        "name": "A. Lippman",
                        "slug": "A.-Lippman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lippman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lippman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 112
                            }
                        ],
                        "text": "A number of probabilistic \nframeworks for CBIR have been proposed in the last few years [Jin and Hauptmann 2002; Vasconcelos and \nLippman 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1379036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "130bbc1b2594b2c5ceb370af0dd860279b4d7403",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We formulate the problem of retrieving images from visual databases as a problem of Bayesian inference. This leads to natural and effective solutions for two of the most challenging issues in the design of a retrieval system: providing support for region-based queries without requiring prior image segmentation, and accounting for user-feedback during a retrieval session. We present a new learning algorithm that relies on belief propagation to account for both positive and negative examples of the user's interests."
            },
            "slug": "Learning-from-User-Feedback-in-Image-Retrieval-Vasconcelos-Lippman",
            "title": {
                "fragments": [],
                "text": "Learning from User Feedback in Image Retrieval Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A new learning algorithm is presented that relies on belief propagation to account for both positive and negative examples of the user's interests in order to solve two of the most challenging issues in the design of a retrieval system."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145404204"
                        ],
                        "name": "Cees G. M. Snoek",
                        "slug": "Cees-G.-M.-Snoek",
                        "structuredName": {
                            "firstName": "Cees",
                            "lastName": "Snoek",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cees G. M. Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 162180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdcc29fa24093cf9122c0fd21481bfe2dcfdfb97",
            "isKey": false,
            "numCitedBy": 549,
            "numCiting": 127,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient and effective handling of video documents depends on the availability of indexes. Manual indexing is unfeasible for large video collections. In this paper we survey several methods aiming at automating this time and resource consuming process. Good reviews on single modality based video indexing have appeared in literature. Effective indexing, however, requires a multimodal approach in which either the most appropriate modality is selected or the different modalities are used in collaborative fashion. Therefore, instead of separately treating the different information sources involved, and their specific algorithms, we focus on the similarities and differences between the modalities. To that end we put forward a unifying and multimodal framework, which views a video document from the perspective of its author. This framework forms the guiding principle for identifying index types, for which automatic methods are found in literature. It furthermore forms the basis for categorizing these different methods."
            },
            "slug": "Multimodal-Video-Indexing:-A-Review-of-the-Snoek-Worring",
            "title": {
                "fragments": [],
                "text": "Multimodal Video Indexing: A Review of the State-of-the-art"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A unifying and multimodal framework is put forward, which views a video document from the perspective of its author, which forms the guiding principle for identifying index types, for which automatic methods are found in literature."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Tools and Applications"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3064190"
                        ],
                        "name": "K. Rodden",
                        "slug": "K.-Rodden",
                        "structuredName": {
                            "firstName": "Kerry",
                            "lastName": "Rodden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rodden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163053"
                        ],
                        "name": "W. Basalaj",
                        "slug": "W.-Basalaj",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Basalaj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Basalaj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91234459"
                        ],
                        "name": "D. Sinclair",
                        "slug": "D.-Sinclair",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sinclair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sinclair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053320673"
                        ],
                        "name": "Kenneth R. Wood",
                        "slug": "Kenneth-R.-Wood",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Wood",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth R. Wood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5519056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb702a069ca07f7136d46f6040e7ce9add31f1c6",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In current systems for browsing image collections, users are presented with sets of thumbnail images arranged in some default order on the screen. We are investigating whether it benefits users to have sets of thumbnails arranged according to their mutual similarity, so images that are alike are placed together. There are, of course, many possible definitions of \u201csimilarity\u201d: so far we have explored measurements based on low-level visual features, and on the textual captions assigned to the images. Here we describe two experiments, both involving designers as the participants, examining whether similarity-based arrangements of the candidate images are helpful for a picture selection task. Firstly, the two types of similarity-based arrangement were informally compared. Then, an arrangement based on visual similarity was more formally compared with a control of a random arrangement. We believe this work should be of interest to anyone designing a system that involves presenting sets of images to users."
            },
            "slug": "Does-organisation-by-similarity-assist-image-Rodden-Basalaj",
            "title": {
                "fragments": [],
                "text": "Does organisation by similarity assist image browsing?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Two experiments are described, both involving designers as the participants, examining whether similarity-based arrangements of the candidate images are helpful for a picture selection task, and an arrangement based on visual similarity was more formally compared with a control of a random arrangement."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108212723"
                        ],
                        "name": "Xin-Jing Wang",
                        "slug": "Xin-Jing-Wang",
                        "structuredName": {
                            "firstName": "Xin-Jing",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin-Jing Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2941896"
                        ],
                        "name": "Qi-Cai He",
                        "slug": "Qi-Cai-He",
                        "structuredName": {
                            "firstName": "Qi-Cai",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi-Cai He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806958"
                        ],
                        "name": "Xing Li",
                        "slug": "Xing-Li",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15083897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8a7ce4cd53796e5ccb05d7eea7811da2f3ef9e1",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a Web image search result organizing method to facilitate user browsing. We formalize this problem as a salient image region pattern extraction problem. Given the images returned by Web search engine, we first segment the images into homogeneous regions and quantize the environmental regions into image codewords. The salient codeword \"phrases\" are then extracted and ranked based on a regression model learned from human labeled training data. According to the salient \"phrases\", images are assigned to different clusters, with the one nearest to the centroid as the entry for the corresponding cluster. Satisfying experimental results show the effectiveness of our proposed method."
            },
            "slug": "Grouping-web-image-search-result-Wang-Ma",
            "title": {
                "fragments": [],
                "text": "Grouping web image search result"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A Web image search result organizing method to facilitate user browsing by segmenting the images into homogeneous regions and quantizing the environmental regions into image codewords, which are then extracted and ranked based on a regression model learned from human labeled training data."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8589942"
                        ],
                        "name": "Yuchun Fang",
                        "slug": "Yuchun-Fang",
                        "structuredName": {
                            "firstName": "Yuchun",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuchun Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 6
                            }
                        ],
                        "text": "2004] [Fang and Geman 2005] Same low level features, increased user involvement"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 23
                            }
                        ],
                        "text": "New approaches such as [Jaimes et al. 2004; Fang and Geman 2005] have started incorporating this aspect of the user\u2019s mind in the RF process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 7
                            }
                        ],
                        "text": "2004] [Fang and Geman 2005] Same low level features, increased user involvement Unsupervised clustering \ntechniques are a natural .t when handling large, unstruc\u00adtured image repositories such as the Web."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 38
                            }
                        ],
                        "text": "A similar search paradigm proposed in [Fang and Geman 2005; Fang et al. 2005b] models successive user response using a Bayesian, information-theoretic framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16153703,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa128b989a5f11513eb72977dd4497095311a5fd",
            "isKey": true,
            "numCitedBy": 38,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a relevance feedback system for retrieving a mental face picture from a large image database. This scenario differs from standard image retrieval since the target image exists only in the mind of the user, who responds to a sequence of machine-generated queries designed to display the person in mind as quickly as possible. At each iteration the user declares which of several displayed faces is \u201cclosest\u201d to his target. The central limiting factor is the \u201csemantic gap\u201d between the standard intensity-based features which index the images in the database and the higher-level representation in the mind of the user which drives his answers. We explore a Bayesian, information-theoretic framework for choosing which images to display and for modeling the response of the user. The challenge is to account for psycho-visual factors and sources of variability in human decision-making. We present experiments with real users which illustrate and validate the proposed algorithms."
            },
            "slug": "Experiments-in-Mental-Face-Retrieval-Fang-Geman",
            "title": {
                "fragments": [],
                "text": "Experiments in Mental Face Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A Bayesian, information-theoretic framework for choosing which images to display and for modeling the response of the user is explored, to account for psycho-visual factors and sources of variability in human decision-making."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684865"
                        ],
                        "name": "Guillaume Bouchard",
                        "slug": "Guillaume-Bouchard",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Bouchard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Bouchard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 169
                            }
                        ],
                        "text": "\u2026sparser topologies have been proposed, \nsuch as the star topology [Fergus et al. 2005], a hierarchy with the lowest levels corresponding to local \nfeatures [Bouchard and Triggs 2005], and a geometry where local features are spatially dependent on their \nnearest neighbors [Carneiro and Lowe 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6193293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3452d42804cbea13b8b252d08ec249b008e8df93",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a generative model that codes the geometry and appearance of generic visual object categories as a loose hierarchy of parts, with probabilistic spatial relations linking parts to subparts, soft assignment of subparts to parts, and scale invariant keypoint based local features at the lowest level of the hierarchy. The method is designed to efficiently handle categories containing hundreds of redundant local features, such as those returned by current key-point detectors. This robustness allows it to outperform constellation style models, despite their stronger spatial models. The model is initialized by robust bottom-up voting over location-scale pyramids, and optimized by expectation-maximization. Training is rapid, and objects do not need to be marked in the training images. Experiments on several popular datasets show the method's ability to capture complex natural object classes."
            },
            "slug": "Hierarchical-part-based-visual-object-Bouchard-Triggs",
            "title": {
                "fragments": [],
                "text": "Hierarchical part-based visual object categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A generative model that codes the geometry and appearance of generic visual object categories as a loose hierarchy of parts, with probabilistic spatial relations linking parts to subparts, soft assignment of subparts to parts, and scale invariant keypoint based local features at the lowest level of the hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257525"
                        ],
                        "name": "N. Gunther",
                        "slug": "N.-Gunther",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gunther",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gunther"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232863"
                        ],
                        "name": "G. Beretta",
                        "slug": "G.-Beretta",
                        "structuredName": {
                            "firstName": "Giordano",
                            "lastName": "Beretta",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Beretta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7501844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ab038de893fd6270809a03cb25fb8e3055e887c",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Comparing the performance of CBIR (Content-Based Image Retrieval) algorithms is difficult. Private data sets are used so it is controversial to compare CBIR algorithms developed by different researchers. Also, the performance of CBIR algorithms is usually measured on an isolated, well- tuned PC or workstation. In a real-world environment, however, the CBIR algorithms would only constitute a minor component among the many interacting components needed to facilitate a useful CBIR application e.g., Web-based applications on the Internet. The Internet, being a shared medium, dramatically changes many of the usual assumptions about measuring CBIR performance. Any CBIR benchmark should be designed form a networked systems standpoint. Networked system benchmarks have been developed for other applications e.g., text retrieval, and relational database management. These benchmarks typically introduce communication overhead because the real systems they model are distributed applications e.g., and airline reservation system. The most common type of distributed computing architecture uses a client/server model. We present our implementation of a client/server CBIR benchmark called BIRDS-I (Benchmark for Image Retrieval using Distributed Systems over the Internet) to measure image retrieval performance over the Internet. The BIRDS-I benchmark has been designed with the trend toward the use of small personalized wireless-internet systems in mind. Web-based CBIR implies the use of heterogeneous image sets and this, in turn, imposes certain constraints on how the images are organized and the type of performance metrics that are applicable. Surprisingly, BIRDS-I only requires controlled human intervention for the compilation of the image collection and none for the generation of ground truth in the measurement of retrieval accuracy. Benchmark image collections need to be evolved incrementally toward the storage of millions of images and that scaleup can only be achieved through the use of computer-incrementally toward the storage of millions of images and that scaleup can only be achieved through the use of computer-aided compilation. Finally, the BIRDS-I scoring metric introduces a tightly optimized image-ranking window, which is important for the future benchmarking of large- scale personalized wireless-internet CBIR systems."
            },
            "slug": "Benchmark-for-image-retrieval-using-distributed-the-Gunther-Beretta",
            "title": {
                "fragments": [],
                "text": "Benchmark for image retrieval using distributed systems over the Iinternet: BIRDS-I"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The BIRDS-I benchmark has been designed with the trend toward the use of small personalized wireless-internet CBIR systems in mind, and only requires controlled human intervention for the compilation of the image collection and none for the generation of ground truth in the measurement of retrieval accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507859"
                        ],
                        "name": "S. Berretti",
                        "slug": "S.-Berretti",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Berretti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Berretti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680785"
                        ],
                        "name": "E. Vicario",
                        "slug": "E.-Vicario",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Vicario",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vicario"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 3
                            }
                        ],
                        "text": "In [Berretti et al. 2003], a novel alternative to the previously discussed class of spatial models, weighted walkthroughs, is proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9947016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbafc64ec7bbb0b7b3b5a58d2ef2379c95530851",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In the access to image databases, queries based on the appearing visual features of searched data reduce the gap between the user and the engineering representation. To support this access modality, image content can be modeled in terms of different types of features such as shape, texture, color, and spatial arrangement. An original framework is presented which supports quantitative nonsymbolic representation and comparison of the mutual positioning of extended nonrectangular spatial entities. Properties of the model are expounded to develop an efficient computation technique and to motivate and assess a metric of similarity for quantitative comparison of spatial relationships. Representation and comparison of binary relationships between entities is then embedded into a graph-theoretical framework supporting representation and comparison of the spatial arrangements of a picture. Two prototype applications are described."
            },
            "slug": "Weighted-walkthroughs-between-extended-entities-for-Berretti-Bimbo",
            "title": {
                "fragments": [],
                "text": "Weighted walkthroughs between extended entities for retrieval by spatial arrangement"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An original framework is presented which supports quantitative nonsymbolic representation and comparison of the mutual positioning of extended nonrectangular spatial entities and properties of the model are expounded to develop an efficient computation technique and to motivate and assess a metric of similarity for quantitative comparison of spatial relationships."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multim."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48048725"
                        ],
                        "name": "Qasim Iqbal",
                        "slug": "Qasim-Iqbal",
                        "structuredName": {
                            "firstName": "Qasim",
                            "lastName": "Iqbal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qasim Iqbal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2590846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "708931faa2db940a43b3fc6ed4649df08376b18e",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Retrieval-by-classification-of-images-containing-Iqbal-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Retrieval by classification of images containing large manmade objects using perceptual grouping"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118397881"
                        ],
                        "name": "Jin Li",
                        "slug": "Jin-Li",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47217802"
                        ],
                        "name": "Honghui Sun",
                        "slug": "Honghui-Sun",
                        "structuredName": {
                            "firstName": "Honghui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honghui Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18398162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c937f575cb5820639b874ee38dfaba3961b8b370",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A new effective mechanism is proposed for the browsing of large compressed images over the Internet. The image is compressed with the JPEG 2000 into one single bitstream and put on the server. During the browsing process, the user specifies a region of interest (ROI) with certain spatial and resolution constraint. The browser only downloads the portion of the compressed bitstream that covers the current ROI, and the download is performed in a progressive fashion so that a coarse view of the ROI can be rendered very quickly and then gradually refined as more and more bitstream arrives. In the case of the switch of ROI, e.g., zooming in/out or panning around, the browser uses existing compressed bitstream in cache to quickly render a coarse view of the new ROI, and in the same time, request a new set of compressed bitstream corresponding to the updated view. The system greatly improves the experience of browsing large images over the slow networks."
            },
            "slug": "On-interactive-browsing-of-large-images-Li-Sun",
            "title": {
                "fragments": [],
                "text": "On interactive browsing of large images"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A new effective mechanism is proposed for the browsing of large compressed images over the Internet where the user specifies a region of interest (ROI) with certain spatial and resolution constraint and the browser only downloads the portion of the compressed bitstream that covers the current ROI."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multim."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118965263"
                        ],
                        "name": "John R. Smith",
                        "slug": "John-R.-Smith",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17464838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa8af1c28f8ab2011339627bf8e13e267c57abdb",
            "isKey": false,
            "numCitedBy": 2203,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a highly functional prototype system for searching by visual features in an image database. The VisualSEEk system is novel in that the user forms the queries by diagramming spatial arrangements of color regions. The system nds the images that contain the most similar arrangements of similar regions. Prior to the queries, the system automatically extracts and indexes salient color regions from the images. By utilizing e cient indexing techniques for color information, region sizes and absolute and relative spatial locations, a wide variety of complex joint color/spatial queries may be computed."
            },
            "slug": "VisualSEEk:-a-fully-automated-content-based-image-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "VisualSEEk: a fully automated content-based image query system"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The VisualSEEk system is novel in that the user forms the queries by diagramming spatial arrangements of color regions by utilizing color information, region sizes and absolute and relative spatial locations."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '96"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2350432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9da15b932df57a8f959471ebc977d620efb18cc1",
            "isKey": false,
            "numCitedBy": 575,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We aim at combining color and shape invariants for indexing and retrieving images. To this end, color models are proposed independent of the object geometry, object pose, and illumination. From these color models, color invariant edges are derived from which shape invariant features are computed. Computational methods are described to combine the color and shape invariants into a unified high-dimensional invariant feature set for discriminatory object retrieval. Experiments have been conducted on a database consisting of 500 images taken from multicolored man-made objects in real world scenes. From the theoretical and experimental results it is concluded that object retrieval based on composite color and shape invariant features provides excellent retrieval accuracy. Object retrieval based on color invariants provides very high retrieval accuracy whereas object retrieval based entirely on shape invariants yields poor discriminative power. Furthermore, the image retrieval scheme is highly robust to partial occlusion, object clutter and a change in the object's pose. Finally, the image retrieval scheme is integrated into the PicToSeek system on-line at http://www.wins.uva.nl/research/isis/PicToSeek/ for searching images on the World Wide Web."
            },
            "slug": "PicToSeek:-combining-color-and-shape-invariant-for-Gevers-Smeulders",
            "title": {
                "fragments": [],
                "text": "PicToSeek: combining color and shape invariant features for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is concluded that object retrieval based on composite color and shape invariant features provides excellent retrieval accuracy and the image retrieval scheme is highly robust to partial occlusion, object clutter and a change in the object's pose."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8167136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b1e1696564e5a3021ac3a501c9deeb6c0fbc637",
            "isKey": false,
            "numCitedBy": 5039,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision is embracing a new research focus in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, realistic environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the location of a known object. Color can be successfully used for both tasks.This article demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique calledHistogram Intersection, which matches model and image histograms and a fast incremental version of Histogram Intersection, which allows real-time indexing into a large database of stored models. For solving the location problem it introduces an algorithm calledHistogram Backprojection, which performs this task efficiently in crowded scenes."
            },
            "slug": "Color-indexing-Swain-Ballard",
            "title": {
                "fragments": [],
                "text": "Color indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models and that they can differentiate among a large number of objects."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736928"
                        ],
                        "name": "G. Petraglia",
                        "slug": "G.-Petraglia",
                        "structuredName": {
                            "firstName": "Gennaro",
                            "lastName": "Petraglia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Petraglia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746385"
                        ],
                        "name": "M. Sebillo",
                        "slug": "M.-Sebillo",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Sebillo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sebillo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704351"
                        ],
                        "name": "Maurizio Tucci",
                        "slug": "Maurizio-Tucci",
                        "structuredName": {
                            "firstName": "Maurizio",
                            "lastName": "Tucci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maurizio Tucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695827"
                        ],
                        "name": "G. Tortora",
                        "slug": "G.-Tortora",
                        "structuredName": {
                            "firstName": "Genny",
                            "lastName": "Tortora",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tortora"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206453270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10370122ed8ad5e8f6078c07abc508489252a23a",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the virtual image, an iconic index suited for pictorial information access in a pictorial database, and a similarity retrieval approach based on virtual images to perform content-based retrieval. A virtual image represents the spatial information contained in a real image in explicit form by means of a set of spatial relations. This is useful to efficiently compute the similarity between a query and an image in the database. We also show that virtual images support real-world applications that require translation, reflection, and/or rotation invariance of image representation."
            },
            "slug": "Virtual-Images-for-Similarity-Retrieval-in-Image-Petraglia-Sebillo",
            "title": {
                "fragments": [],
                "text": "Virtual Images for Similarity Retrieval in Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The virtual image is introduced, an iconic index suited for pictorial information access in a pictorial database, and a similarity retrieval approach based on virtual images to perform content-based retrieval to efficiently compute similarity between a query and an image in the database."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808594"
                        ],
                        "name": "A. Lippman",
                        "slug": "A.-Lippman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lippman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lippman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 69
                            }
                        ],
                        "text": "This idea is explored and applied to image similarity and ranking in [He 2004; Vasconcelos and Lippman 2005; He et al. 2004; He et al. 2004a; Zhou et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15164796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24cae1c5a0f7af56f2acae0f7648d9e88656b91c",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Accounting for spatial image transformations is a requirement for multimedia problems such as video classification and retrieval, face/object recognition or the creation of image mosaics from video sequences. We analyze a transformation invariant metric recently proposed in the machine learning literature to measure the distance between image manifolds - the tangent distance (TD) - and show that it is closely related to alignment techniques from the motion analysis literature. Exposing these relationships results in benefits for the two domains. On one hand, it allows leveraging on the knowledge acquired in the alignment literature to build better classifiers. On the other, it provides a new interpretation of alignment techniques as one component of a decomposition that has interesting properties for the classification of video. In particular, we embed the TD into a multiresolution framework that makes it significantly less prone to local minima. The new metric - multiresolution tangent distance (MRTD) - can be easily combined with robust estimation procedures, and exhibits significantly higher invariance to image transformations than the TD and the Euclidean distance (ED). For classification, this translates into significant improvements in face recognition accuracy. For video characterization, it leads to a decomposition of image dissimilarity into \"differences due to camera motion\" plus \"differences due to scene activity\" that is useful for classification. Experimental results on a movie database indicate that the distance could be used as a basis for the extraction of semantic primitives such as action and romance."
            },
            "slug": "A-multiresolution-manifold-distance-for-invariant-Vasconcelos-Lippman",
            "title": {
                "fragments": [],
                "text": "A multiresolution manifold distance for invariant image similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A transformation invariant metric recently proposed in the machine learning literature to measure the distance between image manifolds - the tangent distance (TD) - is analyzed and shows that it is closely related to alignment techniques from the motion analysis literature."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Multimedia"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729390"
                        ],
                        "name": "Euripides G. M. Petrakis",
                        "slug": "Euripides-G.-M.-Petrakis",
                        "structuredName": {
                            "firstName": "Euripides",
                            "lastName": "Petrakis",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Euripides G. M. Petrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2457943"
                        ],
                        "name": "King-Ip Lin",
                        "slug": "King-Ip-Lin",
                        "structuredName": {
                            "firstName": "King-Ip",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "King-Ip Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 259778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f4781c7d019187fb739f7e9a5714f404126dca0",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce ImageMap, as a method for indexing and similarity searching in image databases (IDBs). ImageMap answers \"queries by example\" involving any number of objects or regions and taking into account their interrelationships. We adopt the most general image content representation, that is, Attributed Relational Graphs (ARGs), in conjunction with the well-accepted ARG editing distance on ARGs. We tested ImageMap on real and realistic medical images. Our method not only provides for visualization of the data set, clustering and data mining, but it also achieves up to 1,000-fold speed-up in search over sequential scanning, with zero or very few false dismissals."
            },
            "slug": "ImageMap:-An-Image-Indexing-Method-Based-on-Spatial-Petrakis-Faloutsos",
            "title": {
                "fragments": [],
                "text": "ImageMap: An Image Indexing Method Based on Spatial Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The most general image content representation is adopted, that is, Attributed Relational Graphs (ARGs), in conjunction with the well-accepted ARG editing distance on ARGs, as a method for indexing and similarity searching in image databases (IDBs)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731122"
                        ],
                        "name": "Qi Zhang",
                        "slug": "Qi-Zhang",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32150954"
                        ],
                        "name": "S. Goldman",
                        "slug": "S.-Goldman",
                        "structuredName": {
                            "firstName": "Sally",
                            "lastName": "Goldman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144323104"
                        ],
                        "name": "Wei Yu",
                        "slug": "Wei-Yu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145724062"
                        ],
                        "name": "J. Fritts",
                        "slug": "J.-Fritts",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Fritts",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fritts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 145
                            }
                        ],
                        "text": "\u2026prior accurate retrieval, models, Bayesian \nbias, many classes training data, not automatic classi.ers, k-NN, trees unseen interactive) organization \n[Zhang et al. 2002] [Hastie et al. 2001] [Panda and Chang 2006] Relevance Feedback (signi.cant, interactive) \nCapture user and query speci.c\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 152
                            }
                        ],
                        "text": "When images are conceived as bags of feature vectors corresponding to regions, multiple-instance \nlearning (MIL) can be used for similarity computation [Zhang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 151
                            }
                        ],
                        "text": "When images are conceived as bags of feature vectors corresponding to regions, multiple-instance learning (MIL) can be used for similarity computation [Zhang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 191
                            }
                        ],
                        "text": "Classification (requires prior training data, not interactive) Pre-processing, fast/accurate retrieval, automatic organization SVM, MIL, statistical models, Bayesian classifiers, k-NN, trees [Zhang et al. 2002] [Hastie et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5129992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "614c5b171b9926d5a3d3228da809c114821aef27",
            "isKey": true,
            "numCitedBy": 273,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the application of machine learning techniques to the problem of content-based image retrieval (CBIR). Unlike most existing CBIR systems in which only global information is used or in which a user must explicitly indicate what part of the image is of interest, we apply the multiple-instance (MI) learning model to use a small number of training images to learn what images from the database are of interest to the user."
            },
            "slug": "Content-Based-Image-Retrieval-Using-Learning-Zhang-Goldman",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval Using Multiple-Instance Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The multiple-instance (MI) learning model is applied to use a small number of training images to learn what images from the database are of interest to the user."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2572455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69401bfdafab7cde00bb8e5b2f6c28e9d72d8cfb",
            "isKey": false,
            "numCitedBy": 3666,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "slug": "A-performance-evaluation-of-local-descriptors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "A performance evaluation of local descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is observed that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best and Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145913175"
                        ],
                        "name": "C. B\u00f6hm",
                        "slug": "C.-B\u00f6hm",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "B\u00f6hm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. B\u00f6hm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35122748"
                        ],
                        "name": "Stefan Berchtold",
                        "slug": "Stefan-Berchtold",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Berchtold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Berchtold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9106757"
                        ],
                        "name": "D. Keim",
                        "slug": "D.-Keim",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keim",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Keim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7602997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ce1355a4e7ca5669057891bc2ee006b8f628b3f",
            "isKey": false,
            "numCitedBy": 931,
            "numCiting": 191,
            "paperAbstract": {
                "fragments": [],
                "text": "During the last decade, multimedia databases have become increasingly important in many application areas such as medicine, CAD, geography, and molecular biology. An important research issue in the field of multimedia databases is the content-based retrieval of similar multimedia objects such as images, text, and videos. However, in contrast to searching data in a relational database, a content-based retrieval requires the search of similar objects as a basic functionality of the database system. Most of the approaches addressing similarity search use a so-called feature transformation that transforms important properties of the multimedia objects into high-dimensional points (feature vectors). Thus, the similarity search is transformed into a search of points in the feature space that are close to a given query point in the high-dimensional feature space. Query processing in high-dimensional spaces has therefore been a very active research area over the last few years. A number of new index structures and algorithms have been proposed. It has been shown that the new index structures considerably improve the performance in querying large multimedia databases. Based on recent tutorials [Berchtold and Keim 1998], in this survey we provide an overview of the current state of the art in querying multimedia databases, describing the index structures and algorithms for an efficient query processing in high-dimensional spaces. We identify the problems of processing queries in high-dimensional space, and we provide an overview of the proposed approaches to overcome these problems."
            },
            "slug": "Searching-in-high-dimensional-spaces:-Index-for-the-B\u00f6hm-Berchtold",
            "title": {
                "fragments": [],
                "text": "Searching in high-dimensional spaces: Index structures for improving the performance of multimedia databases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An overview of the current state of the art in querying multimedia databases is provided, describing the index structures and algorithms for an efficient query processing in high-dimensional spaces."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22188121,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "979089260419884b43cfeb3b23df23b6a7734f9f",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution develops a new technique for content-based image retrieval. Where most existing image retrieval systems mainly focus on color and color distribution or texture, we classify the images based on local invariants. These features represent the image in a very compact way and allow fast comparison and feature matching with images in the database. Using local features makes the system robust to occlusions and changes in the background. Using invariants makes it robust to changes in viewpoint and illumination."
            },
            "slug": "Content-Based-Image-Retrieval-Based-on-Local-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval Based on Local Affinely Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This contribution develops a new technique for content-based image retrieval that classify the images based on local invariants that represent the image in a very compact way and allow fast comparison and feature matching with images in the database."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2363818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d582df7250124b0523e07f61766cfa422eb5cde2",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Sets of local features that are invariant to common image transformations are an effective representation to use when comparing images; current methods typically judge feature sets' similarity via a voting scheme (which ignores co-occurrence statistics) or by comparing histograms over a set of prototypes (which must be found by clustering). We present a method for efficiently comparing images based on their discrete distributions (bags) of distinctive local invariant features, without clustering descriptors. Similarity between images is measured with an approximation of the Earth Mover's Distance (EMD), which quickly computes minimal-cost correspondences between two bags of features. Each image's feature distribution is mapped into a normed space with a low-distortion embedding of EMD. Examples most similar to a novel query image are retrieved in time sublinear in the number of examples via approximate nearest neighbor search in the embedded space. We evaluate our method with scene, object, and texture recognition tasks."
            },
            "slug": "Efficient-image-matching-with-distributions-of-Grauman-Darrell",
            "title": {
                "fragments": [],
                "text": "Efficient image matching with distributions of local invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a method for efficiently comparing images based on their discrete distributions of distinctive local invariant features, without clustering descriptors, and evaluates the method with scene, object, and texture recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 42
                            }
                        ],
                        "text": "The normalized cut segmentation method in [Shi and Malik 2000] is also extended to textured image segmentation by using cues of contour and texture differences [Malik et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 115
                            }
                        ],
                        "text": "One of the most important new advances in segmentation employs the normalized \ncuts 5:18 R. Datta et al. criterion [Shi and Malik 2000]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": ", [Zhu and Yuille 1996], where snake and region growing ideas were combined within a principled framework, and [Shi and Malik 2000], where spectral graph partitioning was employed for this purpose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 93
                            }
                        ],
                        "text": "One of the most important new advances in segmentation employs the Normalized Cuts criterion [Shi and Malik 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 83
                            }
                        ],
                        "text": "In this respect, Chen et al. [2005] proposes the use of a new spectral clustering-[Shi and \nMalik 2000] based approach to incorporate such in\u00adformation into the retrieval process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 52
                            }
                        ],
                        "text": "2005] proposes the use of a new spectral clustering [Shi and Malik 2000] based approach to incorporate such information into the retrieval process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": true,
            "numCitedBy": 12811,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 183
                            }
                        ],
                        "text": "While most algorithms treat RF as a two-class problem, it is \noften intuitive to consider multiple groups of images as relevant or irrelevant [Hoi and Lyu 2004a; Nakazato \net al. 2003; Zhou and Huang 2001a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2838173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "637fd567b10046d1b5b3f1462592d8a9d7e8ba40",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "All positive examples are alike; each negative example is negative in its own way. During interactive multimedia information retrieval, the number of training samples fed-back by the user is usually small; furthermore, they are not representative for the true distributions-especially the negative examples. Adding to the difficulties is the nonlinearity in real-world distributions. Existing solutions fail to address these problems in a principled way. This paper proposes biased discriminant analysis and transforms specifically designed to address the asymmetry between the positive and negative examples, and to trade off generalization for robustness under a small training sample. The kernel version, namely \"BiasMap \", is derived to facilitate nonlinear biased discrimination. Extensive experiments are carried out for performance evaluation as compared to the state-of-the-art methods."
            },
            "slug": "Small-sample-learning-during-multimedia-retrieval-Zhou-Huang",
            "title": {
                "fragments": [],
                "text": "Small sample learning during multimedia retrieval using BiasMap"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes biased discriminant analysis and transforms specifically designed to address the asymmetry between the positive and negative examples, and to trade off generalization for robustness under a small training sample."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14106275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d13a04844e4a781e5180987118f732d93aa9f398",
            "isKey": false,
            "numCitedBy": 4139,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval. The EMD is based on the minimal cost that must be paid to transform one distribution into the other, in a precise sense, and was first proposed for certain vision problems by Peleg, Werman, and Rom. For image retrieval, we combine this idea with a representation scheme for distributions that is based on vector quantization. This combination leads to an image comparison framework that often accounts for perceptual similarity better than other previously proposed methods. The EMD is based on a solution to the transportation problem from linear optimization, for which efficient algorithms are available, and also allows naturally for partial matching. It is more robust than histogram matching techniques, in that it can operate on variable-length representations of the distributions that avoid quantization and other binning problems typical of histograms. When used to compare distributions with the same overall mass, the EMD is a true metric. In this paper we focus on applications to color and texture, and we compare the retrieval performance of the EMD with that of other distances."
            },
            "slug": "The-Earth-Mover's-Distance-as-a-Metric-for-Image-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "The Earth Mover's Distance as a Metric for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper investigates the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval, and compares the retrieval performance of the EMD with that of other distances."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18648233,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b7934a6f3a23940b7562df4cf58366b1adce55a3",
            "isKey": false,
            "numCitedBy": 1779,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new distance between two distributions that we call the Earth Mover's Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving \"distribution mass\" around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search."
            },
            "slug": "A-metric-for-distributions-with-applications-to-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "A metric for distributions with applications to image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses the Earth Mover's Distance to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays, and proposes a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144633617"
                        ],
                        "name": "A. Jaimes",
                        "slug": "A.-Jaimes",
                        "structuredName": {
                            "firstName": "Alejandro",
                            "lastName": "Jaimes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jaimes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2869396"
                        ],
                        "name": "Kengo Omura",
                        "slug": "Kengo-Omura",
                        "structuredName": {
                            "firstName": "Kengo",
                            "lastName": "Omura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kengo Omura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467521"
                        ],
                        "name": "Takeshi Nagamine",
                        "slug": "Takeshi-Nagamine",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Nagamine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Nagamine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263781"
                        ],
                        "name": "K. Hirata",
                        "slug": "K.-Hirata",
                        "structuredName": {
                            "firstName": "Kazutaka",
                            "lastName": "Hirata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hirata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14298482,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "e7f0e5795c1f45446f4b55f05c2fb8ee866d165f",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We advocate a new approach to meeting video retrieval based on the use of memory cues. First we present a new survey involving 519 people in which we investigate the types of items people use to review meeting contents (e.g., minutes, video, etc.). Then we present a novel memory study involving 15 subjects in which we investigate what people remember about past meetings (e.g., seating position, etc). Based on these studies and related research we propose a novel framework for meeting video retrieval based on memory cues. Our proposed system graphically represents important memory retrieval cues such as room layout, participant's faces and sitting positions, etc.. Queries are formulated dynamically: as the user graphically manipulates the cues, the query results are shown. Our system (1) helps users easily express the <i>cues</i> they recall about a particular meeting, and (2) helps users <i>remember</i> new cues for meeting video retrieval. Finally, we present our approach to automatic indexing of meeting videos, present experiments, and discuss research issues in automatic indexing for retrieval using memory cues."
            },
            "slug": "Memory-cues-for-meeting-video-retrieval-Jaimes-Omura",
            "title": {
                "fragments": [],
                "text": "Memory cues for meeting video retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The proposed system graphically represents important memory retrieval cues such as room layout, participant's faces and sitting positions, etc.."
            },
            "venue": {
                "fragments": [],
                "text": "CARPE'04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 81
                            }
                        ],
                        "text": "Viewpoint-and occlusion-invariant local features for image retrieval [Schmid and Mohr 1997] \nreceived signi.cant attention as a means to bridge the sensorial gap."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145575177"
                        ],
                        "name": "G. Carneiro",
                        "slug": "G.-Carneiro",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Carneiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Carneiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7953463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "073388a5b42a5692217f668c374410530fa53f7e",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years there has been growing interest in recognition models using local image features for applications ranging from long range motion matching to object class recognition systems. Currently, many state-of-the-art approaches have models involving very restrictive priors in terms of the number of local features and their spatial relations. The adoption of such priors in those models are necessary for simplifying both the learning and inference tasks. Also, most of the state-of-the-art learning approaches are semi-supervised batch processes, which considerably reduce their suitability in dynamic environments, where unannotated new images are continuously presented to the learning system. In this work we propose: 1) a new model representation that has a less restrictive prior on the geometry and number of local features, where the geometry of each local feature is influenced by its k closest neighbors and models may contain hundreds of features; and 2) a novel unsupervised on-line learning algorithm that is capable of estimating the model parameters efficiently and accurately. We implement a visual class recognition system using the new model and learning method proposed here, and demonstrate that our system produces competitive classification and localization results compared to state-of-the-art methods. Moreover, we show that the learning algorithm is able to model not only classes with consistent texture (e.g., faces), but also classes with shape only (e.g., leaves), classes with a common shape but with a great variability in terms of internal texture (e.g., cups), and classes of flexible objects (e.g., snake)."
            },
            "slug": "Sparse-Flexible-Models-of-Local-Features-Carneiro-Lowe",
            "title": {
                "fragments": [],
                "text": "Sparse Flexible Models of Local Features"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a new model representation that has a less restrictive prior on the geometry and number of local features, where the geometry of each local feature is influenced by its k closest neighbors, and proposes a novel unsupervised on-line learning algorithm that is capable of estimating the model parameters efficiently and accurately."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723700"
                        ],
                        "name": "Changbo Yang",
                        "slug": "Changbo-Yang",
                        "structuredName": {
                            "firstName": "Changbo",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changbo Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964053"
                        ],
                        "name": "Ming Dong",
                        "slug": "Ming-Dong",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9517808"
                        ],
                        "name": "F. Fotouhi",
                        "slug": "F.-Fotouhi",
                        "structuredName": {
                            "firstName": "Farshad",
                            "lastName": "Fotouhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fotouhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6278801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6907370c383792adca1e8addc6cdea63fc677c46",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a semantic image retrieval system with integrated feedback mechanism. In our system, we propose a novel feedback solution for semantic retrieval: semantic feedback, which allows our system to interact with users directly at the semantic level. The learning process of the semantic feedback substantially improves the image retrieval performance of the proposed system. We demonstrate the effectiveness of our approach with experiments using 5,000 images from Corel database."
            },
            "slug": "Semantic-feedback-for-interactive-image-retrieval-Yang-Dong",
            "title": {
                "fragments": [],
                "text": "Semantic feedback for interactive image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This system proposes a novel feedback solution for semantic retrieval: semantic feedback, which allows the system to interact with users directly at the semantic level and substantially improves the image retrieval performance of the proposed system."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708642"
                        ],
                        "name": "Jorma T. Laaksonen",
                        "slug": "Jorma-T.-Laaksonen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Laaksonen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorma T. Laaksonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758971"
                        ],
                        "name": "M. Koskela",
                        "slug": "M.-Koskela",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Koskela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Koskela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 113
                            }
                        ],
                        "text": "The use of the MPEG-7 content descriptors to train self-organizing maps (SOM) for image retrieval is explored in [Laaksonen et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 112
                            }
                        ],
                        "text": "A tree-structured SOM has been used as an underlying technique \nfor RF [Laaksonen et al. 2001] in a CBIR system [Laaksonen et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1021379,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7746ab4f35b7f3237063fac29b619f56298f022c",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Development of content-based image retrieval (CBIR) techniques has suffered from the lack of standardized ways for describing visual image content. Luckily, the MPEG-7 international standard is now emerging as both a general framework for content description and a collection of specific agreed-upon content descriptors. We have developed a neural, self-organizing technique for CBIR. Our system is named PicSOM and it is based on pictorial examples and relevance feedback (RF). The name stems from \"picture\" and the self-organizing map (SOM). The PicSOM system is implemented by using tree structured SOMs. In this paper, we apply the visual content descriptors provided by MPEG-7 in the PicSOM system and compare our own image indexing technique with a reference system based on vector quantization (VQ). The results of our experiments show that the MPEG-7-defined content descriptors can be used as such in the PicSOM system even though Euclidean distance calculation, inherently used in the PicSOM system, is not optimal for all of them. Also, the results indicate that the PicSOM technique is a bit slower than the reference system in starting to find relevant images. However, when the strong RF mechanism of PicSOM begins to function, its retrieval precision exceeds that of the reference system."
            },
            "slug": "PicSOM-self-organizing-image-retrieval-with-MPEG-7-Laaksonen-Koskela",
            "title": {
                "fragments": [],
                "text": "PicSOM-self-organizing image retrieval with MPEG-7 content descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results of the experiments show that the MPEG-7-defined content descriptors can be used as such in thePicSOM system even though Euclidean distance calculation, inherently used in the PicSom system, is not optimal for all of them."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3028284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f39d3e88cce063ccd3ca01100efd44dcabc9d3b4",
            "isKey": false,
            "numCitedBy": 1187,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic linguistic indexing of pictures is an important but highly challenging problem for researchers in computer vision and content-based image retrieval. In this paper, we introduce a statistical modeling approach to this problem. Categorized images are used to train a dictionary of hundreds of statistical models each representing a concept. Images of any given concept are regarded as instances of a stochastic process that characterizes the concept. To measure the extent of association between an image and the textual description of a concept, the likelihood of the occurrence of the image based on the characterizing stochastic process is computed. A high likelihood indicates a strong association. In our experimental implementation, we focus on a particular group of stochastic processes, that is, the two-dimensional multiresolution hidden Markov models (2D MHMMs). We implemented and tested our ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images. The system is evaluated quantitatively using more than 4,600 images outside the training database and compared with a random annotation scheme. Experiments have demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "slug": "Automatic-Linguistic-Indexing-of-Pictures-by-a-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Automatic Linguistic Indexing of Pictures by a Statistical Modeling Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper implemented and tested the ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images and demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692121"
                        ],
                        "name": "Matthew L. Miller",
                        "slug": "Matthew-L.-Miller",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew L. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2838104"
                        ],
                        "name": "T. Papathomas",
                        "slug": "T.-Papathomas",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Papathomas",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papathomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 550483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a60d352b1477fb9cd650510e3185104d82596221",
            "isKey": false,
            "numCitedBy": 809,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the theory, design principles, implementation and performance results of PicHunter, a prototype content-based image retrieval (CBIR) system. In addition, this document presents the rationale, design and results of psychophysical experiments that were conducted to address some key issues that arose during PicHunter's development. The PicHunter project makes four primary contributions to research on CBIR. First, PicHunter represents a simple instance of a general Bayesian framework which we describe for using relevance feedback to direct a search. With an explicit model of what users would do, given the target image they want, PicHunter uses Bayes's rule to predict the target they want, given their actions. This is done via a probability distribution over possible image targets, rather than by refining a query. Second, an entropy-minimizing display algorithm is described that attempts to maximize the information obtained from a user at each iteration of the search. Third, PicHunter makes use of hidden annotation rather than a possibly inaccurate/inconsistent annotation structure that the user must learn and make queries in. Finally, PicHunter introduces two experimental paradigms to quantitatively evaluate the performance of the system, and psychophysical experiments are presented that support the theoretical claims."
            },
            "slug": "The-Bayesian-image-retrieval-system,-PicHunter:-and-Cox-Miller",
            "title": {
                "fragments": [],
                "text": "The Bayesian image retrieval system, PicHunter: theory, implementation, and psychophysical experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The theory, design principles, implementation and performance results of PicHunter are presented, two experimental paradigms to quantitatively evaluate the performance of the system are introduced, and psychophysical experiments are presented that support the theoretical claims."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3309354"
                        ],
                        "name": "L. Kotoulas",
                        "slug": "L.-Kotoulas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Kotoulas",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kotoulas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177298"
                        ],
                        "name": "I. Andreadis",
                        "slug": "I.-Andreadis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Andreadis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Andreadis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62734371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8eccf1e99cc1fba22669a4614739edf6c2ac179",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "With the ongoing development of multimedia technology, the number of information systems containing image retrieval functions is increasing rapidly. Techniques of colour histogram content-based image retrieval are compared in terms of speed and efficiency, and a modified approach based on a composite colour image histogram processing is introduced. The proposed approach is fast and provides results comparable to those of much slower algorithms. Furthermore, a novel pipelined hardware structure has been designed and implemented on an FPGA, to increase the operation speed and make the technique suitable for real-time applications. The typical clock frequency of this device is 35 MHz and it can perform over 50 comparisons of 640/spl times/480-pixel images per second"
            },
            "slug": "Colour-histogram-content-based-image-retrieval-and-Kotoulas-Andreadis",
            "title": {
                "fragments": [],
                "text": "Colour histogram content-based image retrieval and hardware implementation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel pipelined hardware structure has been designed and implemented on an FPGA, to increase the operation speed and make the technique suitable for real-time applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49663591"
                        ],
                        "name": "Wei Liu",
                        "slug": "Wei-Liu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1603473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ed8beefb1b2f5e9f3c95f7ce5813a99de482df",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent Semantic Analysis (LSA) has shown encouraging performance for the problem of unsupervised image automatic annotation. LSA conducts annotation by keywords propagation on a linear Latent Space, which accounts for the underlying semantic structure of word and image features. In this paper, we formulate a more general nonlinear model, called Nonlinear Latent Space model, to reveal the latent variables of word and visual features more precisely. Instead of the basic propagation strategy, we present a novel inference strategy for image annotation via Image-Word Embedding (IWE). IWE simultaneously embeds images and words and captures the dependencies between them from a probabilistic viewpoint. Experiments show that IWE-based annotation on the nonlinear latent space outperforms previous unsupervised annotation methods."
            },
            "slug": "Learning-an-image-word-embedding-for-image-on-the-Liu-Tang",
            "title": {
                "fragments": [],
                "text": "Learning an image-word embedding for image auto-annotation on the nonlinear latent space"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper forms a more general nonlinear model, called Nonlinear Latent Space model, to reveal the latent variables of word and visual features more precisely and presents a novel inference strategy for image annotation via Image-Word Embedding (IWE)."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745185"
                        ],
                        "name": "Feng Jing",
                        "slug": "Feng-Jing",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1906061249"
                        ],
                        "name": "Changhu Wang",
                        "slug": "Changhu-Wang",
                        "structuredName": {
                            "firstName": "Changhu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changhu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49483587"
                        ],
                        "name": "Yuhuan Yao",
                        "slug": "Yuhuan-Yao",
                        "structuredName": {
                            "firstName": "Yuhuan",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhuan Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796862"
                        ],
                        "name": "Kefeng Deng",
                        "slug": "Kefeng-Deng",
                        "structuredName": {
                            "firstName": "Kefeng",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kefeng Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39089563"
                        ],
                        "name": "Lei Zhang",
                        "slug": "Lei-Zhang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1688639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ca8c870bb00553984e774c36d2a55557c61b6ee",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose, IGroup, an efficient and effective algorithm that organizes Web image search results into clusters. IGroup is different from all existing Web image search results clustering algorithms that only cluster the top few images using visual or textual features. Our proposed algorithm first identifies several query-related semantic clusters based on a key phrases extraction algorithm originally proposed for clustering general Web search results. Then, all the resulting images are separated and assigned to corresponding clusters. As a result, all the resulting images are organized into a clustering structure with semantic level. To make the best use of the clustering results, a new user interface (UI) is proposed. Different from existing Web image search interfaces, which show only a limited number of suggested query terms or representative image thumbnails of some clusters, the proposed interface displays both representative thumbnails and appropriate titles of semantically coherent image clusters. Comprehensive user studies have been completed to evaluate both the clustering algorithm and the new UI."
            },
            "slug": "IGroup:-web-image-search-results-clustering-Jing-Wang",
            "title": {
                "fragments": [],
                "text": "IGroup: web image search results clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "IGroup, an efficient and effective algorithm that organizes Web image search results into clusters based on a key phrases extraction algorithm originally proposed for clustering general Web search results is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729390"
                        ],
                        "name": "Euripides G. M. Petrakis",
                        "slug": "Euripides-G.-M.-Petrakis",
                        "structuredName": {
                            "firstName": "Euripides",
                            "lastName": "Petrakis",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Euripides G. M. Petrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3244748"
                        ],
                        "name": "A. Diplaros",
                        "slug": "A.-Diplaros",
                        "structuredName": {
                            "firstName": "Aristeidis",
                            "lastName": "Diplaros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Diplaros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736641"
                        ],
                        "name": "E. Milios",
                        "slug": "E.-Milios",
                        "structuredName": {
                            "firstName": "Evangelos",
                            "lastName": "Milios",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Milios"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12175147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d3e4d25cea1a8adc3cb4e726de634319b47d15b",
            "isKey": false,
            "numCitedBy": 247,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach for matching distorted and possibly occluded shapes using dynamic programming (DP). We distinguish among various cases of matching such as cases where the shapes are scaled with respect to each other and cases where an open shape matches the whole or only a part of another open or closed shape. Our algorithm treats noise and shape distortions by allowing matching of merged sequences of consecutive small segments in a shape with larger segments of another shape, while being invariant to translation, scale, orientation, and starting point selection. We illustrate the effectiveness of our algorithm in retrieval of shapes on two data sets of two-dimensional open and closed shapes of marine life species. We demonstrate the superiority of our approach over traditional approaches to shape matching and retrieval based on Fourier descriptors and moments. We also compare our method with SQUID, a well-known method which is available on the Internet. Our evaluation is based on human relevance judgments following a well-established methodology from the information retrieval field."
            },
            "slug": "Matching-and-Retrieval-of-Distorted-and-Occluded-Petrakis-Diplaros",
            "title": {
                "fragments": [],
                "text": "Matching and Retrieval of Distorted and Occluded Shapes Using Dynamic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The algorithm treats noise and shape distortions by allowing matching of merged sequences of consecutive small segments in a shape with larger segments of another shape, while being invariant to translation, scale, orientation, and starting point selection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 183
                            }
                        ],
                        "text": "While most algorithms treat RF as a two-class problem, it is \noften intuitive to consider multiple groups of images as relevant or irrelevant [Hoi and Lyu 2004a; Nakazato \net al. 2003; Zhou and Huang 2001a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14237930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d045aec8585cae8e5ccba56db1d64820cf73773",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "On-line learning or \"relevance feedback\" techniques for multimedia information retrieval have been explored from many different points of view: from early heuristic-based feature weighting schemes to recently proposed optimal learning algorithms, probabilistic/Bayesian learning algorithms, boosting techniques, discriminant-EM algorithm, support vector machine, and other kernel-based learning machines. Based on a careful examination of the problem and a detailed analysis of the existing solutions, we propose several discriminating transforms as the learning machine during the user interaction. We argue that relevance feedback problem is best represented as a biased classification problem, or a (1+x)-class classification problem. Biased Discriminant Transform (BDT) is shown to outperform all the others. A kernel form is proposed to capture non-linearity in the class distributions."
            },
            "slug": "Comparing-discriminating-transformations-and-SVM-Zhou-Huang",
            "title": {
                "fragments": [],
                "text": "Comparing discriminating transformations and SVM for learning during multimedia retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is argued that relevance feedback problem is best represented as a biased classification problem, or a (1+x-class classification problem), and Biased Discriminant Transform (BDT) is shown to outperform all the others."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1265628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a8665ada37b8a26f2a68c0b9c3f3ceb1e0f655a",
            "isKey": false,
            "numCitedBy": 685,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing computer programs to automatically categorize images using low-level features is a challenging research topic in computer vision. In this paper, we present a new learning technique, which extends Multiple-Instance Learning (MIL), and its application to the problem of region-based image categorization. Images are viewed as bags, each of which contains a number of instances corresponding to regions obtained from image segmentation. The standard MIL problem assumes that a bag is labeled positive if at least one of its instances is positive; otherwise, the bag is negative. In the proposed MIL framework, DD-SVM, a bag label is determined by some number of instances satisfying various properties. DD-SVM first learns a collection of instance prototypes according to a Diverse Density (DD) function. Each instance prototype represents a class of instances that is more likely to appear in bags with the specific label than in the other bags. A nonlinear mapping is then defined using the instance prototypes and maps every bag to a point in a new feature space, named the bag feature space. Finally, standard support vector machines are trained in the bag feature space. We provide experimental results on an image categorization problem and a drug activity prediction problem."
            },
            "slug": "Image-Categorization-by-Learning-and-Reasoning-with-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "Image Categorization by Learning and Reasoning with Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a new learning technique, which extends Multiple-Instance Learning (MIL), and its application to the problem of region-based image categorization, and provides experimental results on an image categorizing problem and a drug activity prediction problem."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730023"
                        ],
                        "name": "B. L. Saux",
                        "slug": "B.-L.-Saux",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Saux",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. L. Saux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741155"
                        ],
                        "name": "N. Boujemaa",
                        "slug": "N.-Boujemaa",
                        "structuredName": {
                            "firstName": "Nozha",
                            "lastName": "Boujemaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Boujemaa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17378637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084eef722905ad7c2f1bde81c2aa71abb053e1d1",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval can be dramatically improved by providing a good initial database overview to the user. To address this issue, we present in this paper an adaptive robust competition. This algorithm relies on a non-supervised database categorization, coupled with a selection of prototypes in each resulting category. In our approach, each image is represented by a high-dimensional signature in the feature space, and a principal component analysis is performed for every feature to reduce dimensionality. Image database overview is computed in challenging conditions since clusters are overlapping with outliers and the number of clusters is unknown."
            },
            "slug": "Unsupervised-robust-clustering-for-image-database-Saux-Boujemaa",
            "title": {
                "fragments": [],
                "text": "Unsupervised robust clustering for image database categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An adaptive robust competition relies on a non-supervised database categorization, coupled with a selection of prototypes in each resulting category, and a principal component analysis is performed for every feature to reduce dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723884"
                        ],
                        "name": "Rong Jin",
                        "slug": "Rong-Jin",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707259"
                        ],
                        "name": "J. Chai",
                        "slug": "J.-Chai",
                        "structuredName": {
                            "firstName": "Joyce",
                            "lastName": "Chai",
                            "middleNames": [
                                "Yue"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145388187"
                        ],
                        "name": "Luo Si",
                        "slug": "Luo-Si",
                        "structuredName": {
                            "firstName": "Luo",
                            "lastName": "Si",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luo Si"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9904485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c678c5626f9bc264b8d7626bb08630c76f77fa08",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Image annotations allow users to access a large image database with textual queries. There have been several studies on automatic image annotation utilizing machine learning techniques, which automatically learn statistical models from annotated images and apply them to generate annotations for unseen images. One common problem shared by most previous learning approaches for automatic image annotation is that each annotated word is predicated for an image independently from other annotated words. In this paper, we proposed a coherent language model for automatic image annotation that takes into account the word-to-word correlation by estimating a coherent language model for an image. This new approach has two important advantages: 1) it is able to automatically determine the annotation length to improve the accuracy of retrieval results, and 2) it can be used with active learning to significantly reduce the required number of annotated image examples. Empirical studies with Corel dataset are presented to show the effectiveness of the coherent language model for automatic image annotation."
            },
            "slug": "Effective-automatic-image-annotation-via-a-coherent-Jin-Chai",
            "title": {
                "fragments": [],
                "text": "Effective automatic image annotation via a coherent language model and active learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A coherent language model for automatic image annotation is proposed that takes into account the word-to-word correlation by estimating a coherent language models for an image to significantly reduce the required number of annotated image examples."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8589942"
                        ],
                        "name": "Yuchun Fang",
                        "slug": "Yuchun-Fang",
                        "structuredName": {
                            "firstName": "Yuchun",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuchun Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741155"
                        ],
                        "name": "N. Boujemaa",
                        "slug": "N.-Boujemaa",
                        "structuredName": {
                            "firstName": "Nozha",
                            "lastName": "Boujemaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Boujemaa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 96
                            }
                        ],
                        "text": "Certain new interaction-based querying paradigms which statistically model the \nuser s interest [Fang et al. 2005], or help the user re.ne her queries by providing cues and hints [Jaimes \net al. 2004; Nagamine et al. 2004], have been explored for image retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8252322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8430c4347fdbb0ae477ea4261bee585b9dc03d27",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a system to \"retrieve\" the mental image of a face from a large database using Bayesian inference and relevance feedback. Since the \"target image\" exists only in the mind of the user, mental image retrieval differs sharply from standard, example-based retrieval and has not been widely studied. In designing the relevance feedback engine, we adopt probabilistic models for the display and answer processes. The answer model is designed to capture properties of human cognition in choosing among displayed faces. The images in each display are selected according to heuristics inspired by maximizing the conditional mutual information between the answer and the target given the previous feedback. Simulations and real tests validate show that the relevance feedback engine operates in real-time and locates the target in a reasonable number of displays."
            },
            "slug": "An-interactive-system-for-mental-face-retrieval-Fang-Geman",
            "title": {
                "fragments": [],
                "text": "An interactive system for mental face retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Simulations and real tests validate show that the relevance feedback engine operates in real-time and locates the target in a reasonable number of displays."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686678"
                        ],
                        "name": "L. Latecki",
                        "slug": "L.-Latecki",
                        "structuredName": {
                            "firstName": "Longin",
                            "lastName": "Latecki",
                            "middleNames": [
                                "Jan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Latecki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889149"
                        ],
                        "name": "Rolf Lak\u00e4mper",
                        "slug": "Rolf-Lak\u00e4mper",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Lak\u00e4mper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rolf Lak\u00e4mper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1625245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4900c089f06ebd4d55c9a9255d6ea586bb95e54",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A cognitively motivated similarity measure is presented and its properties are analyzed with respect to retrieval of similar objects in image databases of silhouettes of 2D objects. To reduce influence of digitization noise, as well as segmentation errors, the shapes are simplified by a novel process of digital curve evolution. To compute our similarity measure, we first establish the best possible correspondence of visual parts (without explicitly computing the visual parts). Then, the similarity between corresponding parts is computed and aggregated. We applied our similarity measure to shape matching of object contours in various image databases and compared it to well-known approaches in the literature. The experimental results justify that our shape matching procedure gives an intuitive shape correspondence and is stable with respect to noise distortions."
            },
            "slug": "Shape-Similarity-Measure-Based-on-Correspondence-of-Latecki-Lak\u00e4mper",
            "title": {
                "fragments": [],
                "text": "Shape Similarity Measure Based on Correspondence of Visual Parts"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work applied a cognitively motivated similarity measure to shape matching of object contours in various image databases and compared it to well-known approaches in the literature, justifying that the shape matching procedure gives an intuitive shape correspondence and is stable with respect to noise distortions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2594941"
                        ],
                        "name": "E. Hadjidemetriou",
                        "slug": "E.-Hadjidemetriou",
                        "structuredName": {
                            "firstName": "Efstathios",
                            "lastName": "Hadjidemetriou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hadjidemetriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143973111"
                        ],
                        "name": "M. Grossberg",
                        "slug": "M.-Grossberg",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Grossberg",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Grossberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17401708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a574787aad58643373d4bfc0a7e5c64a5b69d6d",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "The histogram of image intensities is used extensively for recognition and for retrieval of images and video from visual databases. A single image histogram, however, suffers from the inability to encode spatial image variation. An obvious way to extend this feature is to compute the histograms of multiple resolutions of an image to form a multiresolution histogram. The multiresolution histogram shares many desirable properties with the plain histogram, including that they are both fast to compute, space efficient, invariant to rigid motions, and robust to noise. In addition, the multiresolution histogram directly encodes spatial information. We describe a simple yet novel matching algorithm based on the multiresolution histogram that uses the differences between histograms of consecutive image resolutions. We evaluate it against five widely used image features. We show that with our simple feature we achieve or exceed the performance obtained with more complicated features. Further, we show our algorithm to be the most efficient and robust."
            },
            "slug": "Multiresolution-histograms-and-their-use-for-Hadjidemetriou-Grossberg",
            "title": {
                "fragments": [],
                "text": "Multiresolution histograms and their use for recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple yet novel matching algorithm based on the multiresolution histogram that uses the differences between histograms of consecutive image resolutions to achieve or exceed the performance obtained with more complicated features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3945955"
                        ],
                        "name": "Xiaofei He",
                        "slug": "Xiaofei-He",
                        "structuredName": {
                            "firstName": "Xiaofei",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofei He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9650912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2772c2bab5609f194cbb3e2cf4cf383d03f57987",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning a mapping function from low-level feature space to high-level semantic space. Under the assumption that the data lie on a submanifold embedded in a high dimensional Euclidean space, we propose a relevance feedback scheme which is naturally conducted only on the image manifold in question rather than the total ambient space. While images are typically represented by feature vectors in Rn, the natural distance is often different from the distance induced by the ambient space Rn. The geodesic distances on manifold are used to measure the similarities between images. However, when the number of data points is small, it is hard to discover the intrinsic manifold structure. Based on user interactions in a relevance feedback driven query-by-example system, the intrinsic similarities between images can be accurately estimated. We then develop an algorithmic framework to approximate the optimal mapping function by a Radial Basis Function (RBF) neural network. The semantics of a new image can be inferred by the RBF neural network. Experimental results show that our approach is effective in improving the performance of content-based image retrieval systems."
            },
            "slug": "Learning-an-image-manifold-for-retrieval-He-Ma",
            "title": {
                "fragments": [],
                "text": "Learning an image manifold for retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A relevance feedback scheme which is naturally conducted only on the image manifold in question rather than the total ambient space, and an algorithmic framework to approximate the optimal mapping function by a Radial Basis Function (RBF) neural network."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054072700"
                        ],
                        "name": "Michael Schr\u00f6der",
                        "slug": "Michael-Schr\u00f6der",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schr\u00f6der",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Schr\u00f6der"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1959681"
                        ],
                        "name": "H. Rehrauer",
                        "slug": "H.-Rehrauer",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Rehrauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rehrauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145671776"
                        ],
                        "name": "K. Seidel",
                        "slug": "K.-Seidel",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Seidel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Seidel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777167"
                        ],
                        "name": "M. Datcu",
                        "slug": "M.-Datcu",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Datcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Datcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 169
                            }
                        ],
                        "text": "It is also interesting to note that CBIR technology is being applied to domains as diverse as family album management, Botany, Astronomy, Mineralogy, and Remote sensing [Zhang et al. 2003; Wang et al. 2002; Csillaghy et al. 2000; Painter et al. 2003; Schroder et al. 2000]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 251
                            }
                        ],
                        "text": "It is also interesting to note that CBIR technology is being applied \nto domains as diverse as family album management, botany, astronomy, mineralogy, and remote sensing [Zhang \net al. 2003; Wang et al. 2002; Csillaghy et al. 2000; Painter et al. 2003; Schroder et al. 2000]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7875373,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "493ab63701dc34d54f40e6a381890a543acd2aa5",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a concept of interactive learning and probabilistic retrieval of user-specific cover types in a content-based remote sensing image archive. A cover type is incrementally defined via user-provided positive and negative examples. From these examples, we infer probabilities of the Bayesian network that link the user interests to a pre-extracted content index. Due to the stochastic nature of the cover type definitions, the database system not only retrieves images according to the estimated coverage but also according to the accuracy of that estimation given the current state of learning. For the latter, we introduce the concept of separability. We expand on the steps of Bayesian inference to compute the application-free content index using a family of data models, and on the description of the stochastic link using hyperparameters. In particular, we focus on the interactive nature of our approach, which provides instantaneous feedback to the user in the form of an immediate update of the posterior map, and a very fast, approximate search in the archive. A java-based demonstrator using the presented concept of content-based access to a test archive of Landsat TM, X-SAR, and aerial images are available over the Internet [http://www.vision.ee.ethz.ch/\u223crsia/ClickBayes]."
            },
            "slug": "Interactive-learning-and-probabilistic-retrieval-in-Schr\u00f6der-Rehrauer",
            "title": {
                "fragments": [],
                "text": "Interactive learning and probabilistic retrieval in remote sensing image archives"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work presents a concept of interactive learning and probabilistic retrieval of user-specific cover types in a content-based remote sensing image archive, which provides instantaneous feedback to the user in the form of an immediate update of the posterior map, and a very fast, approximate search in the archive."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Geosci. Remote. Sens."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98902637"
                        ],
                        "name": "Wen Zhao",
                        "slug": "Wen-Zhao",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 149
                            }
                        ],
                        "text": "\u2026related \ntopics such as relevance feedback [Zhou and Huang 2003], high-dimensional indexing of multimedia data \n[Bohm et al. 2001], face recognition [Zhao et al. 2003] (useful for face-based image retrieval), applications \nof CBIR to medicine [Muller et al. 2004], and applications to art and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 24
                            }
                        ],
                        "text": "2001], face recognition [Zhao et al. 2003] (useful for face based image retrieval), applications of CBIR to medicine [Muller et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12331515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28312c3a47c1be3a67365700744d3d6665b86f22",
            "isKey": false,
            "numCitedBy": 6984,
            "numCiting": 418,
            "paperAbstract": {
                "fragments": [],
                "text": "As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered."
            },
            "slug": "Face-recognition:-A-literature-survey-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "Face recognition: A literature survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper provides an up-to-date critical survey of still- and video-based face recognition research, and categorizes existing recognition techniques but also presents detailed descriptions of representative methods within each category."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3328108"
                        ],
                        "name": "Luis von Ahn",
                        "slug": "Luis-von-Ahn",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Ahn",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis von Ahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784365"
                        ],
                        "name": "Laura A. Dabbish",
                        "slug": "Laura-A.-Dabbish",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Dabbish",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura A. Dabbish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 338469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2d4a6e4900ec0f096c87bb2b1272eeceaa584a6",
            "isKey": false,
            "numCitedBy": 2386,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained."
            },
            "slug": "Labeling-images-with-a-computer-game-Ahn-Dabbish",
            "title": {
                "fragments": [],
                "text": "Labeling images with a computer game"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new interactive system: a game that is fun and can be used to create valuable output that addresses the image-labeling problem and encourages people to do the work by taking advantage of their desire to be entertained."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16139971,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "fdf26c9a42c0e293bb3a56d234f921301e65380d",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A texture-based image retrieval system for browsing large-scale aerial photographs is presented. The salient components of this system include texture feature extraction, image segmentation and grouping, learning similarity measure, and a texture thesaurus model for fast search and indexing. The texture features are computed by filtering the image with a bank of Gabor filters. This is followed by a texture gradient computation to segment each large airphoto into homogeneous regions. A hybrid neural network algorithm is used to learn the visual similarity by clustering patterns in the feature space. With learning similarity, the retrieval performance improves significantly. Finally, a texture image thesaurus is created by combining the learning similarity algorithm with a hierarchical vector quantization scheme. This thesaurus facilitates the indexing process while maintaining a good retrieval performance. Experimental results demonstrate the robustness of the overall system in searching over a large collection of airphotos and in selecting a diverse collection of geographic features such as housing developments, parking lots, highways, and airports."
            },
            "slug": "A-Texture-Thesaurus-for-Browsing-Large-Aerial-Ma-Manjunath",
            "title": {
                "fragments": [],
                "text": "A Texture Thesaurus for Browsing Large Aerial Photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experimental results demonstrate the robustness of the overall system in searching over a large collection of airphotos and in selecting a diverse collection of geographic features such as housing developments, parking lots, highways, and airports."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8243889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162065fb9de1928f7abd593ee9a1b7d41b5a4310",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a \"parts and structure\" model for object category recognition that can be learnt efficiently and in a semi-supervised manner: the model is learnt from example images containing category instances, without requiring segmentation from background clutter. The model is a sparse representation of the object, and consists of a star topology configuration of parts modeling the output of a variety of feature detectors. The optimal choice of feature types (whose repertoire includes interest points, curves and regions) is made automatically. In recognition, the model may be applied efficiently in an exhaustive manner, bypassing the need for feature detectors, to give the globally optimal match within a query image. The approach is demonstrated on a wide variety of categories, and delivers both successful classification and localization of the object within the image."
            },
            "slug": "A-sparse-object-category-model-for-efficient-and-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "A sparse object category model for efficient learning and exhaustive recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A \"parts and structure\" model for object category recognition that can be learnt efficiently and in a semi-supervised manner is presented, learnt from example images containing category instances, without requiring segmentation from background clutter."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120431052"
                        ],
                        "name": "Hong Wu",
                        "slug": "Hong-Wu",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694235"
                        ],
                        "name": "Hanqing Lu",
                        "slug": "Hanqing-Lu",
                        "structuredName": {
                            "firstName": "Hanqing",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanqing Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38450168"
                        ],
                        "name": "Songde Ma",
                        "slug": "Songde-Ma",
                        "structuredName": {
                            "firstName": "Songde",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Songde Ma"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60676384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f254fca9a8660a6492dec060899508edd4f1ce6",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback has become a key component in CBIR system. Although most current relevance feedback approaches are based on dichotomous relevance measurement, this coarse measurement is a distortion of the reality. We study relevance feedback with multi-level relevance measurement to better identify the user needs and preferences. To validate the use of multi-level relevance measurement and our relevance feedback algorithm, we developed a CBIR prototype system - WillHunter.There are two novelties in our system, one is our SVM-based fast learning algorithm; another is the easy-to-use graphical user interface, especially the relevance-measuring instrument. Not only experiments are conducted to assess the algorithm, but also usability study is carried out to evaluate the user interface."
            },
            "slug": "WillHunter:-Interactive-Image-Retrieval-with-Wu-Lu",
            "title": {
                "fragments": [],
                "text": "WillHunter: Interactive Image Retrieval with Multilevel Relevance Measurement"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "To validate the use of multi-level relevance measurement and the relevance feedback algorithm, a CBIR prototype system is developed - WillHunter, which has two novelties, one is the SVM-based fast learning algorithm; another is the easy-to-use graphical user interface, especially the relevance-measuring instrument."
            },
            "venue": {
                "fragments": [],
                "text": "ICPR 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143884808"
                        ],
                        "name": "M. Pi",
                        "slug": "M.-Pi",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Pi",
                            "middleNames": [
                                "Hong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34767796"
                        ],
                        "name": "M. Mandal",
                        "slug": "M.-Mandal",
                        "structuredName": {
                            "firstName": "Mrinal",
                            "lastName": "Mandal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mandal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684311"
                        ],
                        "name": "A. Basu",
                        "slug": "A.-Basu",
                        "structuredName": {
                            "firstName": "Anup",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Basu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11340124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2c8f5385ee8b067c71a5c3503b8d85cc6bd669f",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image indexing and retrieval techniques are important for efficient management of visual databases. These techniques are generally developed based on the associated compression techniques. In the fractal domain, luminance offset and contrast scaling parameter are typically used as the fractal indices. However, luminance offset and contrast scaling parameter are strongly correlated. In this paper, we prove that range block mean and contrast scaling parameters are independent. Based on this independence, we propose four statistical indices for efficient image retrieval. In addition, we propose an efficient hierarchical indexing strategy based on the de and ac component analysis. Experimental results on a database of 416 texture images, created by decomposing 26 images, indicate that the proposed indices significantly improve the retrieval rate, compared to other retrieval methods."
            },
            "slug": "Image-retrieval-based-on-histogram-of-fractal-Pi-Mandal",
            "title": {
                "fragments": [],
                "text": "Image retrieval based on histogram of fractal parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that range block mean and contrast scaling parameters are independent, and four statistical indices for efficient image retrieval are proposed, including an efficient hierarchical indexing strategy based on the de and ac component analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Multimedia"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48212474"
                        ],
                        "name": "Hui Zhang",
                        "slug": "Hui-Zhang",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2521078"
                        ],
                        "name": "R. Rahmani",
                        "slug": "R.-Rahmani",
                        "structuredName": {
                            "firstName": "Rouhollah",
                            "lastName": "Rahmani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rahmani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056184"
                        ],
                        "name": "Sharath R. Cholleti",
                        "slug": "Sharath-R.-Cholleti",
                        "structuredName": {
                            "firstName": "Sharath",
                            "lastName": "Cholleti",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sharath R. Cholleti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32150954"
                        ],
                        "name": "S. Goldman",
                        "slug": "S.-Goldman",
                        "structuredName": {
                            "firstName": "Sally",
                            "lastName": "Goldman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1576738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a265aa6d04c1e5e25f735010e0af6bf35eea06f",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Salient points are locations in an image where there is a significant variation with respect to a chosen image feature. Since the set of salient points in an image capture important local characteristics of that image, they can form the basis of a good image representation for content-based image retrieval (CBIR). The features for a salient point should represent the local characteristic of that point so that the similarity between features indicates the similarity between the salient points. Traditional uses of salient points for CBIR assign features to a salient point based on the image features of all pixels in a window around that point. However, since salient points are often on the boundary of objects, the features assigned to a salient point often involve pixels from different objects. In this paper, we propose a CBIR system that uses a novel salient point method that both reduces the number of salient points using a segmentation as a filter, and also improves the representation so that it is a more faithful representation of a single object (or portion of an object) that includes information about its surroundings. We also introduce an improved Expectation Maximization-Diverse Density (EM-DD) based multiple-instance learning algorithm. Experimental results show that our CBIR techniques improve retrieval performance by 5%-11% as compared with current methods."
            },
            "slug": "Local-image-representations-using-pruned-salient-to-Zhang-Rahmani",
            "title": {
                "fragments": [],
                "text": "Local image representations using pruned salient points with applications to CBIR"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A CBIR system that uses a novel salient point method that both reduces the number of salient points using a segmentation as a filter, and also improves the representation so that it is a more faithful representation of a single object (or portion of an object) that includes information about its surroundings."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36206854"
                        ],
                        "name": "Navneet Panda",
                        "slug": "Navneet-Panda",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Panda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navneet Panda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 6
                            }
                        ],
                        "text": "2001] [Panda and Chang 2006] Training introduces bias, many classes unseen"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 129
                            }
                        ],
                        "text": "A more recent work describes an efficient method for processing multimedia queries in an SVM based supervised learning framework [Panda and Chang 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 129
                            }
                        ],
                        "text": "A more recent work describes an ef.cient method for processing multimedia queries \nin an SVM-based supervised learning framework [Panda and Chang 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 143
                            }
                        ],
                        "text": "\u2026\nbias, many classes training data, not automatic classi.ers, k-NN, trees unseen interactive) organization \n[Zhang et al. 2002] [Hastie et al. 2001] [Panda and Chang 2006] Relevance Feedback (signi.cant, interactive) \nCapture user and query speci.c semantics, re.ne rank accordingly Feature\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7236137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c834b9a139c959bc5fd0612d3f0fc5c57d704a0",
            "isKey": true,
            "numCitedBy": 22,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A query can be answered by a binary classifier, which separates the instances that are relevant to the query from the ones that are not. When kernel methods are employed to train such a classifier, the class boundary is represented as a hyperplane in a projected space. Data instances that are farthest from the hyperplane are deemed to be most relevant to the query, and that are nearest to the hyperplane to be most uncertain to the query. In this paper, we address the twin problems of efficient retrieval of the approximate set of instances (a) farthest from and (b) nearest to a query hyperplane. Retrieval of instances for this hyperplane-based query scenario is mapped to the range-query problem allowing for the reuse of existing index structures. Empirical evaluation on large image datasets confirms the effectiveness of our approach."
            },
            "slug": "Efficient-top-k-hyperplane-query-processing-for-Panda-Chang",
            "title": {
                "fragments": [],
                "text": "Efficient top-k hyperplane query processing for multimedia information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper addresses the twin problems of efficient retrieval of the approximate set of instances of data instances that are farthest from and nearest to a query hyperplane by mapped to the range- query problem allowing for the reuse of existing index structures."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731570"
                        ],
                        "name": "M. Lew",
                        "slug": "M.-Lew",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lew",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901762"
                        ],
                        "name": "D. P. Huijsmans",
                        "slug": "D.-P.-Huijsmans",
                        "structuredName": {
                            "firstName": "Dionysius",
                            "lastName": "Huijsmans",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. P. Huijsmans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8247580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b7fc88eea5ceaa762c0b9a5ff1f75645425a61c",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "In many computer vision algorithms, a metric or similarity measure is used to determine the distance between two features. The Euclidean or SSD (sum of the squared differences) metric is prevalent and justified from a maximum likelihood perspective when the additive noise distribution is Gaussian. Based on real noise distributions measured from international test sets, we have found that the Gaussian noise distribution assumption is often invalid. This implies that other metrics, which have distributions closer to the real noise distribution, should be used. In this paper, we consider three different applications: content-based retrieval in image databases, stereo matching, and motion tracking. In each of them, we experiment with different modeling functions for the noise distribution and compute the accuracy of the methods using the corresponding distance measures. In our experiments, we compared the SSD metric, the SAD (sum of the absolute differences) metric, the Cauchy metric, and the Kullback relative information. For several algorithms from the research literature which used the SSD or SAD, we showed that greater accuracy could be obtained by using the Cauchy metric instead."
            },
            "slug": "Toward-Improved-Ranking-Metrics-Sebe-Lew",
            "title": {
                "fragments": [],
                "text": "Toward Improved Ranking Metrics"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper considers three different applications: content-based retrieval in image databases, stereo matching, and motion tracking, and shows that greater accuracy could be obtained by using the Cauchy metric instead."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723700"
                        ],
                        "name": "Changbo Yang",
                        "slug": "Changbo-Yang",
                        "structuredName": {
                            "firstName": "Changbo",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changbo Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964053"
                        ],
                        "name": "Ming Dong",
                        "slug": "Ming-Dong",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9517808"
                        ],
                        "name": "F. Fotouhi",
                        "slug": "F.-Fotouhi",
                        "structuredName": {
                            "firstName": "Farshad",
                            "lastName": "Fotouhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fotouhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 787381,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics",
                "Education"
            ],
            "id": "5406e3c74cf387c63d85145d6642abeba0c475cd",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In an annotated image database, keywords are usually associated with images instead of individual regions, which poses a major challenge for any region based image annotation algorithm. In this paper, we propose to learn the correspondence between image regions and keywords through Multiple-Instance Learning (MIL). After a representative image region has been learned for a given keyword, we consider image annotation as a problem of image classification, in which each keyword is treated as a distinct class label. The classification problem is then addressed using the Bayesian framework. The proposed image annotation method is evaluated on an image database with 5,000 images."
            },
            "slug": "Region-based-image-annotation-through-learning-Yang-Dong",
            "title": {
                "fragments": [],
                "text": "Region based image annotation through multiple-instance learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to learn the correspondence between image regions and keywords through Multiple-Instance Learning (MIL), and considers image annotation as a problem of image classification, in which each keyword is treated as a distinct class label."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664201"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1791876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2a0a5fc0a33a8df662b840ecc80ad5530ae4bf5",
            "isKey": false,
            "numCitedBy": 490,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a fuzzy logic approach, UFM (unified feature matching), for region-based image retrieval. In our retrieval system, an image is represented by a set of segmented regions, each of which is characterized by a fuzzy feature (fuzzy set) reflecting color, texture, and shape properties. As a result, an image is associated with a family of fuzzy features corresponding to regions. Fuzzy features naturally characterize the gradual transition between regions (blurry boundaries) within an image and incorporate the segmentation-related uncertainties into the retrieval algorithm. The resemblance of two images is then defined as the overall similarity between two families of fuzzy features and quantified by a similarity measure, UFM measure, which integrates properties of all the regions in the images. Compared with similarity measures based on individual regions and on all regions with crisp-valued feature representations, the UFM measure greatly reduces the influence of inaccurate segmentation and provides a very intuitive quantification. The UFM has been implemented as a part of our experimental SIMPLIcity image retrieval system. The performance of the system is illustrated using examples from an image database of about 60,000 general-purpose images."
            },
            "slug": "A-Region-Based-Fuzzy-Feature-Matching-Approach-to-Chen-Wang",
            "title": {
                "fragments": [],
                "text": "A Region-Based Fuzzy Feature Matching Approach to Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A fuzzy logic approach, UFM (unified feature matching), for region-based image retrieval, which greatly reduces the influence of inaccurate segmentation and provides a very intuitive quantification."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18967272,
            "fieldsOfStudy": [
                "Economics",
                "Computer Science",
                "Education"
            ],
            "id": "e9bf035a93b4a873a4ee902af7db79f986937361",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We're interested in using keywords and visual content together in image retrieval. We used a seamless joint querying and relevance feedback scheme based on keywords and lowlevel visual content, incorporating keyword similarities. We developed an algorithm for a learned word similarity matrix and conducted experiments that validated our approach."
            },
            "slug": "Unifying-Keywords-and-Visual-Contents-in-Image-Zhou-Huang",
            "title": {
                "fragments": [],
                "text": "Unifying Keywords and Visual Contents in Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A seamless joint querying and relevance feedback scheme based on keywords and lowlevel visual content, incorporating keyword similarities, is used based on a developed algorithm for a learned word similarity matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Multim."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716642"
                        ],
                        "name": "Ilaria Bartolini",
                        "slug": "Ilaria-Bartolini",
                        "structuredName": {
                            "firstName": "Ilaria",
                            "lastName": "Bartolini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilaria Bartolini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689798"
                        ],
                        "name": "P. Ciaccia",
                        "slug": "P.-Ciaccia",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Ciaccia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ciaccia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742653"
                        ],
                        "name": "M. Patella",
                        "slug": "M.-Patella",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Patella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Patella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8998729,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d77afe8adedb62732f453460b68ae4be7cf4946",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Effective and efficient retrieval of similar shapes from large image databases is still a challenging problem in spite of the high relevance that shape information can have in describing image contents. We propose a novel Fourier-based approach, called WARP, for matching and retrieving similar shapes. The unique characteristics of WARP are the exploitation of the phase of Fourier coefficients and the use of the dynamic time warping (DTW) distance to compare shape descriptors. While phase information provides a more accurate description of object boundaries than using only the amplitude of Fourier coefficients, the DTW distance permits us to accurately match images even in the presence of (limited) phase shillings. In terms of classical precision/recall measures, we experimentally demonstrate that WARP can gain, say, up to 35 percent in precision at a 20 percent recall level with respect to Fourier-based techniques that use neither phase nor DTW distance."
            },
            "slug": "WARP:-accurate-retrieval-of-shapes-using-phase-of-Bartolini-Ciaccia",
            "title": {
                "fragments": [],
                "text": "WARP: accurate retrieval of shapes using phase of Fourier descriptors and time warping distance"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a novel Fourier-based approach, called WARP, for matching and retrieving similar shapes, which exploits the phase of Fourier coefficients and the use of the dynamic time warping distance to compare shape descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34792252"
                        ],
                        "name": "J. Amores",
                        "slug": "J.-Amores",
                        "structuredName": {
                            "firstName": "Jaume",
                            "lastName": "Amores",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Amores"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143601910"
                        ],
                        "name": "P. Radeva",
                        "slug": "P.-Radeva",
                        "structuredName": {
                            "firstName": "Petia",
                            "lastName": "Radeva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Radeva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12483050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fadbab92cce2274a9b62f2dfa0b59741dacef0fb",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for fast object class recognition incorporating contextual information into boosting. The object is represented as a constellation of generalized correlograms that integrate both information of local parts and their spatial relations. Incorporating the spatial relations into our constellation of descriptors, we show that an exhaustive search for the best matching can be avoided. Combining the contextual descriptors with boosting, the system simultaneously learns the information that characterize each part of the object along with their characteristic mutual spatial relations. The proposed framework includes a matching step between homologous parts in the training set, and learning the spatial pattern after matching. In the matching part two approaches are provided: a supervised algorithm and an unsupervised one. Our results are favorably compared against state-of-the-art results."
            },
            "slug": "Fast-spatial-pattern-discovery-integrating-boosting-Amores-Sebe",
            "title": {
                "fragments": [],
                "text": "Fast spatial pattern discovery integrating boosting with constellations of contextual descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A novel approach for fast object class recognition incorporating contextual information into boosting, which shows that an exhaustive search for the best matching can be avoided."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2475944"
                        ],
                        "name": "T. Ng",
                        "slug": "T.-Ng",
                        "structuredName": {
                            "firstName": "Tian-Tsong",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5648211"
                        ],
                        "name": "J. Hsu",
                        "slug": "J.-Hsu",
                        "structuredName": {
                            "firstName": "Jessie",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33650938"
                        ],
                        "name": "Lexing Xie",
                        "slug": "Lexing-Xie",
                        "structuredName": {
                            "firstName": "Lexing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lexing Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145120676"
                        ],
                        "name": "Mao-Pei Tsui",
                        "slug": "Mao-Pei-Tsui",
                        "structuredName": {
                            "firstName": "Mao-Pei",
                            "lastName": "Tsui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mao-Pei Tsui"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 100
                            }
                        ],
                        "text": "More recently, semantic-sensitive features have also been employed in a \nphysics-motivated approach [Ng et al. 2005], where images are distinguished as either photo-realistic \nrendering or photograph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 93
                            }
                        ],
                        "text": "More recently, semantic-sensitive features are also employed in a physics-motivated approach [Ng et al. 2005], where images are distinguished as either photo-realistic rendering or photograph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2989164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "004a894ca551b2454a0a2215920ac467e85418c8",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The increasing photorealism for computer graphics has made computer graphics a convincing form of image forgery. Therefore, classifying photographic images and photorealistic computer graphics has become an important problem for image forgery detection. In this paper, we propose a new geometry-based image model, motivated by the physical image generation process, to tackle the above-mentioned problem. The proposed model reveals certain physical differences between the two image categories, such as the gamma correction in photographic images and the sharp structures in computer graphics. For the problem of image forgery detection, we propose two levels of image authenticity definition, i.e., imaging-process authenticity and scene authenticity, and analyze our technique against these definitions. Such definition is important for making the concept of image authenticity computable. Apart from offering physical insights, our technique with a classification accuracy of 83.5% outperforms those in the prior work, i.e., wavelet features at 80.3% and cartoon features at 71.0%. We also consider a recapturing attack scenario and propose a counter-attack measure. In addition, we constructed a publicly available benchmark dataset with images of diverse content and computer graphics of high photorealism."
            },
            "slug": "Physics-motivated-features-for-distinguishing-and-Ng-Chang",
            "title": {
                "fragments": [],
                "text": "Physics-motivated features for distinguishing photographic images and computer graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new geometry-based image model is proposed, motivated by the physical image generation process, to tackle the problem of image forgery detection and constructed a publicly available benchmark dataset with images of diverse content and computer graphics of high photorealism."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708642"
                        ],
                        "name": "Jorma T. Laaksonen",
                        "slug": "Jorma-T.-Laaksonen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Laaksonen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorma T. Laaksonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758971"
                        ],
                        "name": "M. Koskela",
                        "slug": "M.-Koskela",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Koskela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Koskela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38965885"
                        ],
                        "name": "Sami Laakso",
                        "slug": "Sami-Laakso",
                        "structuredName": {
                            "firstName": "Sami",
                            "lastName": "Laakso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sami Laakso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "A tree-structured SOM has been used as an underlying technique \nfor RF [Laaksonen et al. 2001] in a CBIR system [Laaksonen et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18100206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f53c80124df4d6cf0427f09bbfebb2266d71163d",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract:Self-Organising Maps (SOMs) can be used in implementing a powerful relevance feedback mechanism for Content-Based Image Retrieval (CBIR). This paper introduces the PicSOM CBIR system, and describes the use of SOMs as a relevance feedback technique in it. The technique is based on the SOM\u2019s inherent property of topology-preserving mapping from a high-dimensional feature space to a two-dimensional grid of artificial neurons. On this grid similar images are mapped in nearby locations. As image similarity must, in unannotated databases, be based on low-level visual features, the similarity of images is dependent on the feature extraction scheme used. Therefore, in PicSOM there exists a separate tree-structured SOM for each different feature type. The incorporation of the relevance feedback and the combination of the outputs from the SOMs are performed as two successive processing steps. The proposed relevance feedback technique is described, analysed qualitatively, and visualised in the paper. Also, its performance is compared with a reference method."
            },
            "slug": "Self-Organising-Maps-as-a-Relevance-Feedback-in-Laaksonen-Koskela",
            "title": {
                "fragments": [],
                "text": "Self-Organising Maps as a Relevance Feedback Technique in Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The PicSOM CBIR system is introduced, and the use of self-Organising Maps as a relevance feedback technique in it is described, analysed qualitatively, and visualised."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis & Applications"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34659351"
                        ],
                        "name": "M\u00e1rio A. T. Figueiredo",
                        "slug": "M\u00e1rio-A.-T.-Figueiredo",
                        "structuredName": {
                            "firstName": "M\u00e1rio",
                            "lastName": "Figueiredo",
                            "middleNames": [
                                "A.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e1rio A. T. Figueiredo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9140319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "142f056a365dccd029c0897fcfa7833aecf2212f",
            "isKey": false,
            "numCitedBy": 868,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Grouping images into (semantically) meaningful categories using low-level visual features is a challenging and important problem in content-based image retrieval. Using binary Bayesian classifiers, we attempt to capture high-level concepts from low-level image features under the constraint that the test image does belong to one of the classes. Specifically, we consider the hierarchical classification of vacation images; at the highest level, images are classified as indoor or outdoor; outdoor images are further classified as city or landscape; finally, a subset of landscape images is classified into sunset, forest, and mountain classes. We demonstrate that a small vector quantizer (whose optimal size is selected using a modified MDL criterion) can be used to model the class-conditional densities of the features, required by the Bayesian methodology. The classifiers have been designed and evaluated on a database of 6931 vacation photographs. Our system achieved a classification accuracy of 90.5% for indoor/outdoor, 95.3% for city/landscape, 96.6% for sunset/forest and mountain, and 96% for forest/mountain classification problems. We further develop a learning method to incrementally train the classifiers as additional data become available. We also show preliminary results for feature reduction using clustering techniques. Our goal is to combine multiple two-class classifiers into a single hierarchical classifier."
            },
            "slug": "Image-classification-for-content-based-indexing-Vailaya-Figueiredo",
            "title": {
                "fragments": [],
                "text": "Image classification for content-based indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The goal is to combine multiple two-class classifiers into a single hierarchical classifier, and it is demonstrated that a small vector quantizer can be used to model the class-conditional densities of the features, required by the Bayesian methodology."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144625576"
                        ],
                        "name": "M. Barni",
                        "slug": "M.-Barni",
                        "structuredName": {
                            "firstName": "Mauro",
                            "lastName": "Barni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Barni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46322834"
                        ],
                        "name": "A. Pelagotti",
                        "slug": "A.-Pelagotti",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Pelagotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pelagotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778090"
                        ],
                        "name": "A. Piva",
                        "slug": "A.-Piva",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Piva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Piva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 81
                            }
                        ],
                        "text": "Comprehensive surveys on latest advances in art imaging research can be found in [Martinez et al. 2002; Maitre et al. 2001; Barni et al. 2005; Chen et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62360750,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "1b3c0efa542c6c2de14d64528be5cfd45caa8e42",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of science and engineering to the analysis of priceless paintings and statues dates back several centuries. However, only over the past few decades have analytical methods developed in the physical sciences been able to glean information, from the past and contribute to the analysis, conservation, and dissemination of works of art. By specifically focusing on the visual arts (e.g., on the binomial image processing and paintings), it is the purpose of this column to: 1) sketch the main applications that could benefit from the introduction of ad hoc image processing tools, 2) outline the state-of-the-art, 3) describe the main peculiarities of this field, and 4) discuss the main obstacles impeding a more fruitful cooperation between the image processing community and art historians, restorers, and artists in general."
            },
            "slug": "Image-processing-for-the-analysis-and-conservation-Barni-Pelagotti",
            "title": {
                "fragments": [],
                "text": "Image processing for the analysis and conservation of paintings: opportunities and challenges"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This column sketches the main applications that could benefit from the introduction of ad hoc image processing tools, outlines the state-of-the-art, and discusses the main obstacles impeding a more fruitful cooperation between the image processing community and art historians, restorers, and artists in general."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Process. Mag."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724421"
                        ],
                        "name": "Deng Cai",
                        "slug": "Deng-Cai",
                        "structuredName": {
                            "firstName": "Deng",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deng Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3945955"
                        ],
                        "name": "Xiaofei He",
                        "slug": "Xiaofei-He",
                        "structuredName": {
                            "firstName": "Xiaofei",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofei He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109689495"
                        ],
                        "name": "Zhiwei Li",
                        "slug": "Zhiwei-Li",
                        "structuredName": {
                            "firstName": "Zhiwei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiwei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259699"
                        ],
                        "name": "Ji-Rong Wen",
                        "slug": "Ji-Rong-Wen",
                        "structuredName": {
                            "firstName": "Ji-Rong",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji-Rong Wen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 32
                            }
                        ],
                        "text": ", geometric hashing Wolfson and Rigoutsos [1997]), matching at the semantic level (e.g., Fagin [1997]), and learning-based approaches for similarity matching (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 758,
                                "start": 32
                            }
                        ],
                        "text": ", geometric hashing Wolfson and Rigoutsos [1997]), matching at the semantic level (e.g., Fagin [1997]), and learning-based approaches for similarity matching (e.g., Wu et al. [2000] and Webe et al. [2000]). Closely tied to the similarity measures are how they emulate the user needs, and, more practically, how they can be modified step-wise with feedback from the user. In this respect, a major advance made in the user interaction technology for image retrieval was relevance feedback (RF). Important early work that introduced RF into the image retrieval domain included Rui et al. [1998], which was implemented in their MARS system [Rui et al. 1997]. Methods for visualization of image query results were explored, for example, in Flickner et al. [1995] and Chang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 0
                            }
                        ],
                        "text": "Research on efficient ways to index images by content has been largely overshadowed by research on efficient visual representation and similarity measures. Most of the methods used for visual indexing are adopted from text-indexing research. In Petrakis et al. [2002], R-trees are used for indexing images represented as attributed relational graphs (ARGs)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 32
                            }
                        ],
                        "text": ", geometric hashing Wolfson and Rigoutsos [1997]), matching at the semantic level (e.g., Fagin [1997]), and learning-based approaches for similarity matching (e.g., Wu et al. [2000] and Webe et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 592,
                                "start": 32
                            }
                        ],
                        "text": ", geometric hashing Wolfson and Rigoutsos [1997]), matching at the semantic level (e.g., Fagin [1997]), and learning-based approaches for similarity matching (e.g., Wu et al. [2000] and Webe et al. [2000]). Closely tied to the similarity measures are how they emulate the user needs, and, more practically, how they can be modified step-wise with feedback from the user. In this respect, a major advance made in the user interaction technology for image retrieval was relevance feedback (RF). Important early work that introduced RF into the image retrieval domain included Rui et al. [1998], which was implemented in their MARS system [Rui et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2428,
                                "start": 34
                            }
                        ],
                        "text": "Content-based image retrieval (CBIR), as we see it today, is any technology that in principle helps to organize digital picture archives by their visual content. By this definition, anything ranging from an image similarity function to a robust image annotation engine falls under the purview of CBIR. This characterization of CBIR as a field of study places it at a unique juncture within the scientific community. While we witness continued effort in solving the fundamental open problem of robust image understanding, we also see people from different fields, such as, computer vision, machine learning, information retrieval, human-computer interaction, database systems, Web and data mining, information theory, statistics, and psychology contributing and becoming part of the CBIR community [Wang et al. 2006]. Moreover, a lateral bridging of gaps between some of these research communities is being gradually brought about as a by-product of such contributions, the impact of which can potentially go beyond CBIR. Again, what we see today as a few cross-field publications may very well spring into new fields of study in the foreseeable future. Amidst such marriages of fields, it is important to recognize the shortcomings of CBIR as a real-world technology. One problem with all current approaches is the reliance on visual similarity for judging semantic similarity, which may be problematic due to the semantic gap [Smeulders et al. 2000] between low-level content and higher-level concepts. While this intrinsic difficulty in solving the core problem cannot be denied, we believe that the current state-of-the-art in CBIR holds enough promise and maturity to be useful for real-world applications if aggressive attempts are made. For example, GoogleTM and Yahoo!\u00ae are household names today primarily due to the benefits reaped through their use, despite the fact that robust text understanding is still an open problem. Online photo-sharing has become extremely popular with Flickr [Flickr 2002], which hosts hundreds of millions of pictures with diverse content. The video-sharing and distribution forum YouTube has also brought in a new revolution in multimedia usage. Of late, there is renewed interest in the media about potential real-world applications of CBIR and image analysis technologies, as evidenced by publications in Scintific American [Mirsky 2006], Discovery News [Staedter 2006] and on CNN [2005]. We envision that image retrieval will enjoy a success story in the coming years."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 782,
                                "start": 32
                            }
                        ],
                        "text": ", geometric hashing Wolfson and Rigoutsos [1997]), matching at the semantic level (e.g., Fagin [1997]), and learning-based approaches for similarity matching (e.g., Wu et al. [2000] and Webe et al. [2000]). Closely tied to the similarity measures are how they emulate the user needs, and, more practically, how they can be modified step-wise with feedback from the user. In this respect, a major advance made in the user interaction technology for image retrieval was relevance feedback (RF). Important early work that introduced RF into the image retrieval domain included Rui et al. [1998], which was implemented in their MARS system [Rui et al. 1997]. Methods for visualization of image query results were explored, for example, in Flickner et al. [1995] and Chang et al. [1997]. Content-based image retrieval systems that gained prominence in this era were, for example, IBM QBIC [Flickner et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 32
                            }
                        ],
                        "text": ", geometric hashing Wolfson and Rigoutsos [1997]), matching at the semantic level (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1226,
                                "start": 32
                            }
                        ],
                        "text": ", geometric hashing Wolfson and Rigoutsos [1997]), matching at the semantic level (e.g., Fagin [1997]), and learning-based approaches for similarity matching (e.g., Wu et al. [2000] and Webe et al. [2000]). Closely tied to the similarity measures are how they emulate the user needs, and, more practically, how they can be modified step-wise with feedback from the user. In this respect, a major advance made in the user interaction technology for image retrieval was relevance feedback (RF). Important early work that introduced RF into the image retrieval domain included Rui et al. [1998], which was implemented in their MARS system [Rui et al. 1997]. Methods for visualization of image query results were explored, for example, in Flickner et al. [1995] and Chang et al. [1997]. Content-based image retrieval systems that gained prominence in this era were, for example, IBM QBIC [Flickner et al. 1995], VIRAGE [Gupta and Jain 1997], and NEC AMORE [Mukherjea et al. 1999] in the commercial domain, and MIT Photobook [Pentland et al. 1994], Columbia VisualSEEK and WebSEEK [Smith and Chang 1997b], UCSB NeTra [Ma and Manjunath 1997], and Stanford WBIIS [Wang et al. 1998] in the academic domain. In Smeulders et al. [2000], practical issues such as system implementation and architecture, as well as their limitations and how to overcome them, the user in the loop, intuitive result visualization, and system evaluation were discussed, and suggestions made."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 497,
                                "start": 0
                            }
                        ],
                        "text": "Research on efficient ways to index images by content has been largely overshadowed by research on efficient visual representation and similarity measures. Most of the methods used for visual indexing are adopted from text-indexing research. In Petrakis et al. [2002], R-trees are used for indexing images represented as attributed relational graphs (ARGs). Retrieval of images using wavelet coefficients as image representations and R\u2217-trees for indexing has been studied in Natsev et al. [2004]. Visual content matching using graph-based image representation and an efficient metric indexing algorithm has been proposed in Berretti et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 866392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68332b6a7f4a792eaeda56d84d0e4de32395411b",
            "isKey": true,
            "numCitedBy": 386,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of clustering Web image search results. Generally, the image search results returned by an image search engine contain multiple topics. Organizing the results into different semantic clusters facilitates users' browsing. In this paper, we propose a hierarchical clustering method using visual, textual and link analysis. By using a vision-based page segmentation algorithm, a web page is partitioned into blocks, and the textual and link information of an image can be accurately extracted from the block containing that image. By using block-level link analysis techniques, an image graph can be constructed. We then apply spectral techniques to find a Euclidean embedding of the images which respects the graph structure. Thus for each image, we have three kinds of representations, i.e. visual feature based representation, textual feature based representation and graph based representation. Using spectral clustering techniques, we can cluster the search results into different semantic clusters. An image search example illustrates the potential of these techniques."
            },
            "slug": "Hierarchical-clustering-of-WWW-image-search-results-Cai-He",
            "title": {
                "fragments": [],
                "text": "Hierarchical clustering of WWW image search results using visual, textual and link information"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A hierarchical clustering method using visual, textual and link analysis to cluster the search results into different semantic clusters of image search results is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39089563"
                        ],
                        "name": "Lei Zhang",
                        "slug": "Lei-Zhang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146071097"
                        ],
                        "name": "Le Chen",
                        "slug": "Le-Chen",
                        "structuredName": {
                            "firstName": "Le",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Le Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745185"
                        ],
                        "name": "Feng Jing",
                        "slug": "Feng-Jing",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796862"
                        ],
                        "name": "Kefeng Deng",
                        "slug": "Kefeng-Deng",
                        "structuredName": {
                            "firstName": "Kefeng",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kefeng Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18118919,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d376aaa239b67d4a27646f65e428f27cbca1006",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose building a vertical image search engine called EnjoyPhoto that leverages rich metadata from various photo forum web sites to meet users' requirements for enjoying high-quality photos, which is virtually impossible in traditional image search engines. To solve the ranking problem when aggregating multiple photo forums, we propose a novel rank fusion algorithm that uses duplicate photos to normalize rating scores. To further improve user experiences in enjoying photos, we design an in-place image browsing interface, and compare it with several other interfaces in a user study. With rich metadata and rating information, more attractive user interfaces are enabled, including slideshow authoring and photo recommendations. We conducted experiments and user studies on a 2.5-million image database to evaluate the proposed rank fusion algorithm, investigate the rationale behind building a vertical image search engine, and study user interfaces and preferences for the purpose of enjoying high-quality photos. The experimental results demonstrate the effectiveness of the proposed ranking algorithm. The results also show that the 2.5-million high-quality image database in EnjoyPhoto performs comparably with Google's 1- billion image database for queries related to location, nature, and daily life categories. Finally, our results show that the in-place browsing interface-called Force-Transfer view-is much more convenient for users than traditional interfaces."
            },
            "slug": "EnjoyPhoto:-a-vertical-image-search-engine-for-Zhang-Chen",
            "title": {
                "fragments": [],
                "text": "EnjoyPhoto: a vertical image search engine for enjoying high-quality photos"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A vertical image search engine called EnjoyPhoto is proposed that leverages rich metadata from various photo forum web sites to meet users' requirements for enjoying high-quality photos, which is virtually impossible in traditional image search engines."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145394457"
                        ],
                        "name": "Gang Wu",
                        "slug": "Gang-Wu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36206854"
                        ],
                        "name": "Navneet Panda",
                        "slug": "Navneet-Panda",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Panda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navneet Panda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 858614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a176b2e989e1dbb58fe726c72f486ca04a094cc3",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Tasks of information retrieval depend on a good distance function for measuring similarity between data instances. The most effective distance function must be formulated in a context-dependent (also application-, data-, and user-dependent) way. In this paper, we present a novel method, which learns a distance function by capturing the nonlinear relationships among contextual information provided by the application, data, or user. We show that through a process called the \"kernel trick,\" such nonlinear relationships can be learned efficiently in a projected space. In addition to using the kernel trick, we propose two algorithms to further enhance efficiency and effectiveness of function learning. For efficiency, we propose a SMO-like solver to achieve O(N2) learning performance. For effectiveness, we propose using unsupervised learning in an innovative way to address the challenge of lack of labeled data (contextual information). Theoretically, we substantiate that our method is both sound and optimal. Empirically, we demonstrate that our method is effective and useful."
            },
            "slug": "Formulating-context-dependent-similarity-functions-Wu-Chang",
            "title": {
                "fragments": [],
                "text": "Formulating context-dependent similarity functions"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel method is presented, which learns a distance function by capturing the nonlinear relationships among contextual information provided by the application, data, or user through a process called the \"kernel trick,\" which can be learned efficiently in a projected space."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741155"
                        ],
                        "name": "N. Boujemaa",
                        "slug": "N.-Boujemaa",
                        "structuredName": {
                            "firstName": "Nozha",
                            "lastName": "Boujemaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Boujemaa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7661726"
                        ],
                        "name": "Alexander Hauptmann",
                        "slug": "Alexander-Hauptmann",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hauptmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hauptmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789352"
                        ],
                        "name": "Jelena Tesic",
                        "slug": "Jelena-Tesic",
                        "structuredName": {
                            "firstName": "Jelena",
                            "lastName": "Tesic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jelena Tesic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13962172,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5623db871f13f3966a5c2d3d54d74b669d0e83f0",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Multimedia information retrieval is a highly diverse field. A variety of data types, research problems,methodologies are involved.Researchers in the field come from very different disciplines, ranging from mathematical and physical sciences, computational sciences and engineering, to application domains. The panel, consisting of highly visible active researchers from both academia and the industry,opens a discussion on the importance of diversity to the healthy growth of the field. This paper records their opinions expressed at the panel."
            },
            "slug": "Diversity-in-multimedia-information-retrieval-Wang-Boujemaa",
            "title": {
                "fragments": [],
                "text": "Diversity in multimedia information retrieval research"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The panel, consisting of highly visible active researchers from both academia and the industry, opens a discussion on the importance of diversity to the healthy growth of the field."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160780"
                        ],
                        "name": "K. Nakano",
                        "slug": "K.-Nakano",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nakano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285368"
                        ],
                        "name": "E. Takamichi",
                        "slug": "E.-Takamichi",
                        "structuredName": {
                            "firstName": "Etsuko",
                            "lastName": "Takamichi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Takamichi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 169
                            }
                        ],
                        "text": "\u2026implementa\u00adtion of a color-histogram-based image \nretrieval system [Kotoulas and Andreadis 2003], an FPGA implementation for subimage retrieval within \nan image database [Nakano and Takamichi 2003], and a method for ef.cient retrieval in a network of imaging \ndevices [Woodrow and Heinzelman 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 200
                            }
                        ],
                        "text": "The notable few include an FPGA implementation of a color histogram based image retrieval system [Kotoulas and Andreadis 2003], an FPGA implementation for sub-image retrieval within an image database [Nakano and Takamichi 2003], and a method for efficient retrieval in a network of imaging devices [Woodrow and Heinzelman 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7042153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ec8e09b856af850c53f16cd4643f638c92bb5ae",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The main contribution of this paper is to present an image retrieval system using FPGAs. Given a template image T and a database of a number of images I/sub 1/, I/sub 2/,..., our system lists all images that contain a subimage similar to T. More specifically, a hardware generator in our system creates the Verilog HDL source of a hardware that determines whether I/sub i/ has a similar subimage to T for any image Ii and a particular template T. The created Verilog HDL source is embed in an FPGA using the design tool provided by the FPGA vendor. Since the hardware embedded in the FPGA is designed for a particular template T, it is an instance-specific hardware that allows us to achieve extreme acceleration. We evaluate the performance of our image matching hardware using a PCI-connected Xilinx FPGA and a tinting analyzer. Since the generated hardware attains up to 3000 speedup factor over the software solution, our approach is promising."
            },
            "slug": "An-image-retrieval-system-using-FPGAs-Nakano-Takamichi",
            "title": {
                "fragments": [],
                "text": "An image retrieval system using FPGAs"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An image retrieval system using FPGAs that attains up to 3000 speedup factor over the software solution, and an instance-specific hardware that allows the system to achieve extreme acceleration."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ASP-DAC Asia and South Pacific Design Automation Conference, 2003."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17582380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34d4eb4666a20f7e3fad689d7862959bd128130b",
            "isKey": false,
            "numCitedBy": 1296,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Contour-and-Texture-Analysis-for-Image-Segmentation-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Contour and Texture Analysis for Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture, and introduces a gating operator based on the texturedness of the neighborhood at a pixel to facilitate cue combination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741922"
                        ],
                        "name": "R. Cucchiara",
                        "slug": "R.-Cucchiara",
                        "structuredName": {
                            "firstName": "Rita",
                            "lastName": "Cucchiara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cucchiara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705203"
                        ],
                        "name": "C. Grana",
                        "slug": "C.-Grana",
                        "structuredName": {
                            "firstName": "Costantino",
                            "lastName": "Grana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Grana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51382163"
                        ],
                        "name": "A. Prati",
                        "slug": "A.-Prati",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Prati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Prati"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1733119,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f16aa28e7fa50b55dc6affe41facee2da3cc9fa",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present a framework for on-the-fly video transcoding that exploits computer vision-based techniques to adapt the Web access to the user requirements. The proposed transcoding approach aims at coping with both user bandwidth and resources capabilities, and with user interests in the video's content. We propose an object-based semantic transcoding that, according to the user-defined classes of relevance, applies different transcoding techniques to the objects segmented in a scene. Object extraction is provided by on-the-fly video processing, without manual annotation. Multiple transcoding policies are reviewed and a performance evaluation metric based on the Weighted Mean Square Error (and corresponding PSNR), that takes into account the perceptual user requirements by means of classes of relevance, is defined. Results are analyzed by varying transcoding techniques, bandwidth requirements and video types (with indoor and outdoor scenes), showing that the use of semantics can dramatically improve the bandwidth to distortion ratio."
            },
            "slug": "Semantic-Video-Transcoding-Using-Classes-of-Cucchiara-Grana",
            "title": {
                "fragments": [],
                "text": "Semantic Video Transcoding Using Classes of Relevance"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work proposes an object-based semantic transcoding that, according to the user-defined classes of relevance, applies different transcoding techniques to the objects segmented in a scene."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Image Graph."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059257793"
                        ],
                        "name": "Jo\u00e3o Freitas",
                        "slug": "Jo\u00e3o-Freitas",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Freitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12561212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d9f55b445f36578802e7eef4393cfa914b11620",
            "isKey": false,
            "numCitedBy": 1765,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model of object recognition as machine translation. In this model, recognition is a process of annotating image regions with words. Firstly, images are segmented into regions, which are classified into region types using a variety of features. A mapping between region types and keywords supplied with the images, is then learned, using a method based around EM. This process is analogous with learning a lexicon from an aligned bitext. For the implementation we describe, these words are nouns taken from a large vocabulary. On a large test set, the method can predict numerous words with high accuracy. Simple methods identify words that cannot be predicted well. We show how to cluster words that individually are difficult to predict into clusters that can be predicted well -- for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. The method is trained on a substantial collection of images. Extensive experimental results illustrate the strengths and weaknesses of the approach."
            },
            "slug": "Object-Recognition-as-Machine-Translation:-Learning-Sahin-Barnard",
            "title": {
                "fragments": [],
                "text": "Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows how to cluster words that individually are difficult to predict into clusters that can be predicted well, and cannot predict the distinction between train and locomotive using the current set of features, but can predict the underlying concept."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15171942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2989b07819dfd279222a3755d3b7862f1a1a7f53",
            "isKey": false,
            "numCitedBy": 4175,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated."
            },
            "slug": "Texture-Features-for-Browsing-and-Retrieval-of-Data-Manjunath-Ma",
            "title": {
                "fragments": [],
                "text": "Texture Features for Browsing and Retrieval of Image Data"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5113463"
                        ],
                        "name": "D. Joshi",
                        "slug": "D.-Joshi",
                        "structuredName": {
                            "firstName": "Dhiraj",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 174
                            }
                        ],
                        "text": "What, in CBIR, is analogous to such ranking, given that a large subset of the images are determined to be semantically relevant? This question has been recently addressed in [Datta et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "Net 1993], an approach that has been followed in [Datta et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14631088,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "8772877ceb40d6d8685655145034740f3df7baad",
            "isKey": false,
            "numCitedBy": 712,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Aesthetics, in the world of art and photography, refers to the principles of the nature and appreciation of beauty. Judging beauty and other aesthetic qualities of photographs is a highly subjective task. Hence, there is no unanimously agreed standard for measuring aesthetic value. In spite of the lack of firm rules, certain features in photographic images are believed, by many, to please humans more than certain others. In this paper, we treat the challenge of automatically inferring aesthetic quality of pictures using their visual content as a machine learning problem, with a peer-rated online photo sharing Website as data source. We extract certain visual features based on the intuition that they can discriminate between aesthetically pleasing and displeasing images. Automated classifiers are built using support vector machines and classification trees. Linear regression on polynomial terms of the features is also applied to infer numerical aesthetics ratings. The work attempts to explore the relationship between emotions which pictures arouse in people, and their low-level content. Potential applications include content-based image retrieval and digital photography."
            },
            "slug": "Studying-Aesthetics-in-Photographic-Images-Using-a-Datta-Joshi",
            "title": {
                "fragments": [],
                "text": "Studying Aesthetics in Photographic Images Using a Computational Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper treats the challenge of automatically inferring aesthetic quality of pictures using their visual content as a machine learning problem, with a peer-rated online photo sharing Website as data source and extracts certain visual features based on the intuition that they can discriminate between aesthetically pleasing and displeasing images."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109689495"
                        ],
                        "name": "Zhiwei Li",
                        "slug": "Zhiwei-Li",
                        "structuredName": {
                            "firstName": "Zhiwei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiwei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144076239"
                        ],
                        "name": "Xing Xie",
                        "slug": "Xing-Xie",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143856677"
                        ],
                        "name": "Hao Liu",
                        "slug": "Hao-Liu",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26989132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cbb8ec4c45f81c0aacd44ff1241fb0316fa400f",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Web image search engine has become an important tool to organize digital images on the Web. However, most commercial search engines still use a list presentation while little effort has been placed on improving their usability. How to present the image search results in a more intuitive and effective way is still an open question to be carefully studied. In this demo, we present iFind, a scalable Web image search engine, in which we integrated two kinds of search result browsing interfaces. User study results have proved that our interfaces are superior to traditional interfaces."
            },
            "slug": "Intuitive-and-effective-interfaces-for-WWW-image-Li-Xie",
            "title": {
                "fragments": [],
                "text": "Intuitive and effective interfaces for WWW image search engines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "iFind is presented, a scalable Web image search engine, in which it integrated two kinds of search result browsing interfaces, and user study results have proved that the interfaces are superior to traditional interfaces."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634361"
                        ],
                        "name": "Yining Deng",
                        "slug": "Yining-Deng",
                        "structuredName": {
                            "firstName": "Yining",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yining Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319358"
                        ],
                        "name": "C. Kenney",
                        "slug": "C.-Kenney",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Kenney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kenney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117172289"
                        ],
                        "name": "M. Moore",
                        "slug": "M.-Moore",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Moore",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145822222"
                        ],
                        "name": "H. Shin",
                        "slug": "H.-Shin",
                        "structuredName": {
                            "firstName": "Hyun",
                            "lastName": "Shin",
                            "middleNames": [
                                "Doo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 3
                            }
                        ],
                        "text": "In [Deng et al. 2001; Wang et al. 2001], it is argued that region-based signature is more efficient computationally for retrieval, and it also gets around drawbacks associated with earlier propositions such as dimension reduction and color moment descriptors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 71
                            }
                        ],
                        "text": "This is essentially the widely used region-based signature, as used in [Deng et al. 2001; Wang et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6979297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e27a4e623e5b14f4b88907d79df153daf3716ab",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A compact color descriptor and an efficient indexing method for this descriptor are presented. The target application is similarity retrieval in large image databases using color. Colors in a given region are clustered into a small number of representative colors. The feature descriptor consists of the representative colors and their percentages in the region. A similarity measure similar to the quadratic color histogram distance measure is defined for this descriptor. The representative colors can be indexed in the three-dimensional (3-D) color space thus avoiding the high-dimensional indexing problems associated with the traditional color histogram. For similarity retrieval, each representative color in the query image or region is used independently to find regions containing that color. The matches from all of the query colors are then combined to obtain the final retrievals. An efficient indexing scheme for fast retrieval is presented. Experimental results show that this compact descriptor is effective and compares favorably with the traditional color histogram in terms of overall computational complexity."
            },
            "slug": "An-efficient-color-representation-for-image-Deng-Manjunath",
            "title": {
                "fragments": [],
                "text": "An efficient color representation for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results show that this compact color descriptor is effective and compares favorably with the traditional color histogram in terms of overall computational complexity."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467521"
                        ],
                        "name": "Takeshi Nagamine",
                        "slug": "Takeshi-Nagamine",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Nagamine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Nagamine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144633617"
                        ],
                        "name": "A. Jaimes",
                        "slug": "A.-Jaimes",
                        "structuredName": {
                            "firstName": "Alejandro",
                            "lastName": "Jaimes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jaimes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2869396"
                        ],
                        "name": "Kengo Omura",
                        "slug": "Kengo-Omura",
                        "structuredName": {
                            "firstName": "Kengo",
                            "lastName": "Omura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kengo Omura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263781"
                        ],
                        "name": "K. Hirata",
                        "slug": "K.-Hirata",
                        "structuredName": {
                            "firstName": "Kazutaka",
                            "lastName": "Hirata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hirata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22810945,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "bca196a52c967aa9cdef1b1d353b9f8278d3f192",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system based on a new, memory-cue paradigm for retrieving meeting video scenes. The system graically represents important memory retrieval cues such as room layout, participant's faces and sitting positions, etc.. Queries are formulated dynamically: as the user graically manipulates the cues, the query results are shown. Our system (1) helps users easily express the <i>cues</i> they recall about a particular meeting; (2) helps users <i>remember</i> new cues for meeting video retrieval. We discuss the experiments that motivate this new approach, implementation, and future work."
            },
            "slug": "A-visuospatial-memory-cue-system-for-meeting-video-Nagamine-Jaimes",
            "title": {
                "fragments": [],
                "text": "A visuospatial memory cue system for meeting video retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A system based on a new, memory-cue paradigm for retrieving meeting video scenes that helps users easily express the cues they recall about a particular meeting and helps users remember new cues for meeting video retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507859"
                        ],
                        "name": "S. Berretti",
                        "slug": "S.-Berretti",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Berretti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Berretti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 5
                            }
                        ],
                        "text": ", in [Mehrotra and Gary 1995; Berretti et al. 2000; Petrakis et al. 2002], due to the typical modeling limitations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2992449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc866302cead61086ec59c2982f6af3ae945f7d6",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "An important problem in accessing and retrieving visual information is to provide efficient similarity matching in large databases. Though much work is being done on the investigation of suitable perceptual models and the automatic extraction of features, little attention is given to the combination of useful representations and similarity models with efficient index structures. In this paper we propose retrieval by shape similarity using local descriptors and effective indexing. Shapes are partitioned into tokens in correspondence with their protrusions, and each token is modeled according to a set of perceptually salient attributes. Shape indexing is obtained by arranging shape tokens into a suitably modified M-tree index structure. Two distinct distance functions model respectively, token and shape perceptual similarity. Examples from a prototype system and computational experiences are reported for both retrieval accuracy and indexing efficiency. Shape retrieval has been tested under shape scaling, orientation changes, and partial shape occlusions. A comparative analysis of different indexing structures, for shape retrieval is presented."
            },
            "slug": "Retrieval-by-Shape-Similarity-with-Perceptual-and-Berretti-Bimbo",
            "title": {
                "fragments": [],
                "text": "Retrieval by Shape Similarity with Perceptual Distance and Effective Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes retrieval by shape similarity using local descriptors and effective indexing, and presents a comparative analysis of different indexing structures, for shape retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multim."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145575177"
                        ],
                        "name": "G. Carneiro",
                        "slug": "G.-Carneiro",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Carneiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Carneiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 462448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04522dc16114c88dfb0ebd3b95050fdbd4193b90",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The extraction of optimal features, in a classification sense, is still quite challenging in the context of large-scale classification problems (such as visual recognition), involving a large number of classes and significant amounts of training data per class. We present an optimal, in the minimum Bayes error sense, algorithm for feature design that combines the most appealing properties of the two strategies that are currently dominant: feature extraction (FE) and feature selection (FS). The new algorithm proceeds by interleaving pairs of FS and FE steps, which amount to a sequential search for the most discriminant directions in a collection of two dimensional subspaces. It combines the fast convergence rate of FS with the ability of FE to uncover optimal features that are not part of the original basis functions, leading to solutions that are better than those achievable by either FE or FS alone, in a small number of iterations. Because the basic iteration has very low complexity, the new algorithm is scalable in the number of classes of the recognition problem, a property that is currently only available for feature extraction methods that are either sub-optimal or optimal under restrictive assumptions that do not hold for generic recognition. Experimental results show significant improvements over these methods, either through much greater robustness to local minima or by achieving significantly faster convergence."
            },
            "slug": "Minimum-Bayes-error-features-for-visual-recognition-Carneiro-Vasconcelos",
            "title": {
                "fragments": [],
                "text": "Minimum Bayes error features for visual recognition by sequential feature selection and extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents an optimal, in the minimum Bayes error sense, algorithm for feature design that combines the most appealing properties of the two strategies that are currently dominant: feature extraction and feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "The 2nd Canadian Conference on Computer and Robot Vision (CRV'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881728"
                        ],
                        "name": "Thomas K\u00e4ster",
                        "slug": "Thomas-K\u00e4ster",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "K\u00e4ster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas K\u00e4ster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070193669"
                        ],
                        "name": "M. Pfeiffer",
                        "slug": "M.-Pfeiffer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Pfeiffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pfeiffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692283"
                        ],
                        "name": "C. Bauckhage",
                        "slug": "C.-Bauckhage",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauckhage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bauckhage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13892708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aff3b33ab3047c6721fb37513652db3aae7b33d3",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Given the size of todays professional image databases, the stan-dard approach to object- or theme-related image retrieval is to in-teractively navigate through the content. But as most users of such databases are designers or artists who do not have a technical back-ground, navigation interfaces must be intuitive to use and easy to learn. This paper reports on efforts towards this goal. We present a system for intuitive image retrieval that features different moda-lities for interaction. Apart from conventional input devices like mouse or keyboard it is also possible to use speech or haptic gesture to indicate what kind of images one is looking for. Seeing a selection of images on the screen, the user provides relevance feedback to narrow the choice of motifs presented next. This is done either by scoring whole images or by choosing cer-tain image regions. In order to derive consistent reactions from multimodal user input, asynchronous integration of modalities and probabilistic reasoning based on Bayesian networks are applied. After addressing technical details, we will discuss a series of usability experiments, which we conducted to examine the impact of multimodal input facilities on interactive image retrieval. The results indicate that users appreciate multimodality. While we ob-served little decrease in task performance, measures of contentment exceeded those for conventional input devices."
            },
            "slug": "Combining-speech-and-haptics-for-intuitive-and-K\u00e4ster-Pfeiffer",
            "title": {
                "fragments": [],
                "text": "Combining speech and haptics for intuitive and efficient navigation through image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system for intuitive image retrieval that features different modalities and probabilistic reasoning based on Bayesian networks are applied in order to derive consistent reactions from multimodal user input."
            },
            "venue": {
                "fragments": [],
                "text": "ICMI '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 134
                            }
                        ],
                        "text": "To alleviate this problem, a CBIR system is used as a validation technique in order to distort images before being presented to users [Datta et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "To alleviate this problem, a CBIR system is used as a \nvalidation technique in order to distort images before being presented to users [Datta et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3175921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc4bc803efa73958608ff4cec9d094672ed39965",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose IMAGINATION (IMAge Generation for INternet AuthenticaTION), a system for the generation of attack-resistant, user-friendly, image-based CAPTCHAs. In our system, we produce controlled distortions on randomly chosen images and present them to the user for annotation from a given list of words. The distortions are performed in a way that satisfies the incongruous requirements of low perceptual degradation and high resistance to attack by content-based image retrieval systems. Word choices are carefully generated to avoid ambiguity as well as to avoid attacks based on the choices themselves. Preliminary results demonstrate the attack-resistance and user-friendliness of our system compared to text-based CAPTCHAs."
            },
            "slug": "IMAGINATION:-a-robust-image-based-CAPTCHA-system-Datta-Li",
            "title": {
                "fragments": [],
                "text": "IMAGINATION: a robust image-based CAPTCHA generation system"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The proposed IMAGINATION (IMAge Generation for INternet AuthenticaTION), a system for the generation of attack-resistant, user-friendly, image-based CAPTCHAs, produces controlled distortions on randomly chosen images and presents them to the user for annotation from a given list of words."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 92
                            }
                        ],
                        "text": "Recently, a number of \nOCR-based techniques have been proposed to break text-based CAPTCHAs [Mori and Malik 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 16
                            }
                        ],
                        "text": "The most common CAPTCHAs \nuse distorted text, as seen in public Web sites such as Yahoo!, MSN, and PayPal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 177
                            }
                        ],
                        "text": "A problem \nwith this approach is the possibility that CBIR and concept learning techniques such as Barnard et al. \n[2003] and Li and Wang [2003] can be used to attack image-based CAPTCHAs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 66
                            }
                        ],
                        "text": "This will eventually lead to \nthe same problem faced by text-based CAPTCHAs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 38
                            }
                        ],
                        "text": "The .rst formalization of image-based CAPTCHAs is found in Chew \nand Tygar [2004], where pictures chosen at random are displayed and questions asked, such as what does \nthe picture contain, which picture is the odd 5:44 R. Datta et al. one out conceptually, etc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 46
                            }
                        ],
                        "text": "This has \npaved the way for natural\u00adimage-based CAPTCHAs, owing to the fact that CBIR is generally considered a \nmuch more dif.cult problem than OCR."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 20
                            }
                        ],
                        "text": "HIPs, also known as CAPTCHAs, are a savior in these situations."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1053619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "310dda18ecb3817aef260239f43a7821faf4cf55",
            "isKey": true,
            "numCitedBy": 674,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we explore object recognition in clutter. We test our object recognition techniques on Gimpy and EZ-Gimpy, examples of visual CAPTCHAs. A CAPTCHA (\"Completely Automated Public Turing test to Tell Computers and Humans Apart\") is a program that can generate and grade tests that most humans can pass, yet current computer programs can't pass. EZ-Gimpy, currently used by Yahoo, and Gimpy are CAPTCHAs based on word recognition in the presence of clutter. These CAPTCHAs provide excellent test sets since the clutter they contain is adversarial; it is designed to confuse computer programs. We have developed efficient methods based on shape context matching that can identify the word in an EZ-Gimpy image with a success rate of 92%, and the requisite 3 words in a Gimpy image 33% of the time. The problem of identifying words in such severe clutter provides valuable insight into the more general problem of object recognition in scenes. The methods that we present are instances of a framework designed to tackle this general problem."
            },
            "slug": "Recognizing-objects-in-adversarial-clutter:-a-Mori-Malik",
            "title": {
                "fragments": [],
                "text": "Recognizing objects in adversarial clutter: breaking a visual CAPTCHA"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Efficient methods based on shape context matching are developed that can identify the word in an EZ-Gimpy image with a success rate of 92%, and the requisite 3 words in a Gimpy image 33% of the time."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108503703"
                        ],
                        "name": "Zhiyong Wang",
                        "slug": "Zhiyong-Wang",
                        "structuredName": {
                            "firstName": "Zhiyong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8590720"
                        ],
                        "name": "Z. Chi",
                        "slug": "Z.-Chi",
                        "structuredName": {
                            "firstName": "Zheru",
                            "lastName": "Chi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144820759"
                        ],
                        "name": "D. Feng",
                        "slug": "D.-Feng",
                        "structuredName": {
                            "firstName": "Dagan",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Feng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123088984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38639a04fc5aa51faa0c1974baa072f9adeb903a",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Generally, the more features utilized, the better the retrieval performance. However, it is a very challenging task to combine different feature sets in a way reflecting human perception. This paper presents the combination of different shape based feature sets using fuzzy integral for leaf image retrieval. The feature sets used in our system include centroid-contour distance curve, eccentricity, and angle code histogram. The fuzzy integral approach can release the user's burden from tuning the combination parameters. In order to reduce the matching time in the retrieval process, a thinning based method is proposed to locate the start point of a leaf contour. Experimental results on 440 leaf images from 44 plant species (10 samples from each plant species) show that the fuzzy integral approach can achieve a comparable retrieval performance with the best case of the weighted summation combination. The results also indicate that our approach, which are more efficient, can achieve a better retrieval performance than both the curvature scale space (CSS) method and the modified Fourier descriptor (MFD) method."
            },
            "slug": "Fuzzy-integral-for-leaf-image-retrieval-Wang-Chi",
            "title": {
                "fragments": [],
                "text": "Fuzzy integral for leaf image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that the fuzzy integral approach can achieve a comparable retrieval performance with the best case of the weighted summation combination, and results indicate that the approach can achieved a better retrieval performance than both the curvature scale space (CSS) method and the modified Fourier descriptor (MFD) method."
            },
            "venue": {
                "fragments": [],
                "text": "2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291)"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108052514"
                        ],
                        "name": "Yi Wu",
                        "slug": "Yi-Wu",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143922493"
                        ],
                        "name": "K. Chang",
                        "slug": "K.-Chang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Chang",
                            "middleNames": [
                                "Chen-Chuan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 125
                            }
                        ],
                        "text": "Another novelty in feedback speci.cation is the use of multilevel relevance scores \nto indicate varying degrees of relevance [Wu et al. 2004]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10906069,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ea50116e00fbc02cc8da5e0291f7c1264f3fda6",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Considerable research has been devoted to utilizing multimodal features for better understanding multimedia data. However, two core research issues have not yet been adequately addressed. First, given a set of features extracted from multiple media sources (e.g., extracted from the visual, audio, and caption track of videos), how do we determine the best modalities? Second, once a set of modalities has been identified, how do we best fuse them to map to semantics? In this paper, we propose a two-step approach. The first step finds <i>statistically independent modalities</i> from raw features. In the second step, we use <i>super-kernel fusion</i> to determine the optimal combination of individual modalities. We carefully analyze the tradeoffs between three design factors that affect fusion performance: <i>modality independence</i>, <i>curse of dimensionality</i>, and <i>fusion-model complexity</i>. Through analytical and empirical studies, we demonstrate that our two-step approach, which achieves a careful balance of the three design factors, can improve class-prediction accuracy over traditional techniques."
            },
            "slug": "Optimal-multimodal-fusion-for-multimedia-data-Wu-Chang",
            "title": {
                "fragments": [],
                "text": "Optimal multimodal fusion for multimedia data analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Through analytical and empirical studies, it is demonstrated that the two-step approach, which achieves a careful balance of the three design factors, can improve class-prediction accuracy over traditional techniques."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634361"
                        ],
                        "name": "Yining Deng",
                        "slug": "Yining-Deng",
                        "structuredName": {
                            "firstName": "Yining",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yining Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 118
                            }
                        ],
                        "text": "An unsupervised approach for segmentation of images containing homogeneous color/texture regions has been proposed in [Deng and Manjunath 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17064842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ff4bc32bbdeb84c403a0535b244d468b352ce06",
            "isKey": false,
            "numCitedBy": 1516,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for unsupervised segmentation of color-texture regions in images and video is presented. This method, which we refer to as JSEG, consists of two independent steps: color quantization and spatial segmentation. In the first step, colors in the image are quantized to several representative classes that can be used to differentiate regions in the image. The image pixels are then replaced by their corresponding color class labels, thus forming a class-map of the image. The focus of this work is on spatial segmentation, where a criterion for \"good\" segmentation using the class-map is proposed. Applying the criterion to local windows in the class-map results in the \"J-image,\" in which high and low values correspond to possible boundaries and interiors of color-texture regions. A region growing method is then used to segment the image based on the multiscale J-images. A similar approach is applied to video sequences. An additional region tracking scheme is embedded into the region growing process to achieve consistent segmentation and tracking results, even for scenes with nonrigid object motion. Experiments show the robustness of the JSEG algorithm on real images and video."
            },
            "slug": "Unsupervised-Segmentation-of-Color-Texture-Regions-Deng-Manjunath",
            "title": {
                "fragments": [],
                "text": "Unsupervised Segmentation of Color-Texture Regions in Images and Video"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The focus of this work is on spatial segmentation, where a criterion for \"good\" segmentation using the class-map is proposed and applying the criterion to local windows in theclass-map results in the \"J-image,\" in which high and low values correspond to possible boundaries and interiors of color-texture regions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2377815"
                        ],
                        "name": "A. Velivelli",
                        "slug": "A.-Velivelli",
                        "structuredName": {
                            "firstName": "Atulya",
                            "lastName": "Velivelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Velivelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977389"
                        ],
                        "name": "C. Ngo",
                        "slug": "C.-Ngo",
                        "structuredName": {
                            "firstName": "Chong-Wah",
                            "lastName": "Ngo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ngo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5774863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e3f74123d81fd4930008bc21619f39ed7533b26",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The concept of a documentary scene was inferred from the audio-visual characteristics of certain documentary videos. It was observed that the amount of information from the visual component alone was not enough to convey a semantic context to most portions of these videos, but a joint observation of the visual component and the audio component conveyed a better semantic context. From the observations that we made on the video data, we generated an audio score and a visual score. We later generated a weighted audio-visual score within an interval and adaptively expanded or shrunk this interval until we found a local maximum score value. The video ultimately will be divided into a set of intervals that correspond to the documentary scenes in the video. After we obtained a set of documentary scenes, we made a check for any redundant detections."
            },
            "slug": "Detection-of-Documentary-Scene-Changes-by-Fusion-Velivelli-Ngo",
            "title": {
                "fragments": [],
                "text": "Detection of Documentary Scene Changes by Audio-Visual Fusion"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "It was observed that the amount of information from the visual component alone was not enough to convey a semantic context to most portions of these videos, but a joint observation of the visual components and the audio component conveyed a better semantic context."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115950542"
                        ],
                        "name": "C.R. Johnson",
                        "slug": "C.R.-Johnson",
                        "structuredName": {
                            "firstName": "C.R.",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C.R. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36507939"
                        ],
                        "name": "E. Hendriks",
                        "slug": "E.-Hendriks",
                        "structuredName": {
                            "firstName": "Ella",
                            "lastName": "Hendriks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hendriks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145931642"
                        ],
                        "name": "I. Berezhnoy",
                        "slug": "I.-Berezhnoy",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Berezhnoy",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Berezhnoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445241"
                        ],
                        "name": "E. Brevdo",
                        "slug": "E.-Brevdo",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Brevdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brevdo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751302"
                        ],
                        "name": "S. Hughes",
                        "slug": "S.-Hughes",
                        "structuredName": {
                            "firstName": "Shannon",
                            "lastName": "Hughes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hughes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71016211"
                        ],
                        "name": "E. Postma",
                        "slug": "E.-Postma",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Postma",
                            "middleNames": [
                                "Marie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Postma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120465785"
                        ],
                        "name": "J.Z. Wang",
                        "slug": "J.Z.-Wang",
                        "structuredName": {
                            "firstName": "J.Z.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J.Z. Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 274
                            }
                        ],
                        "text": "\u2026search and retrieval in large art/cultural \nimage databases, statistical learning techniques have also been proposed to capture properties of the \nbrush strokes of painters [Melzer et al. 1998; Sablatnig et al. 1998; Li and Wang 2004; Lyu et al. 2004; \nBerezhnoy et al. 2005; Johnson et al. 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18545749,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "160882b239795f6ed919d2a74cec58dd0aadd74e",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "A survey of the literature reveals that image processing tools aimed at supplementing the art historian's toolbox are currently in the earliest stages of development. To jump-start the development of such methods, the Van Gogh and Kroller-Muller museums in The Netherlands agreed to make a data set of 101 high-resolution gray-scale scans of paintings within their collections available to groups of image processing researchers from several different universities. This article describes the approaches to brushwork analysis and artist identification developed by three research groups, within the framework of this data set."
            },
            "slug": "Image-processing-for-artist-identification-Johnson-Hendriks",
            "title": {
                "fragments": [],
                "text": "Image processing for artist identification"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The approaches to brushwork analysis and artist identification developed by three research groups are described within the framework of this data set of 101 high-resolution gray-scale scans of paintings within the Van Gogh and Kroller-Muller museums."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1834451"
                        ],
                        "name": "M. Do",
                        "slug": "M.-Do",
                        "structuredName": {
                            "firstName": "Minh",
                            "lastName": "Do",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Do"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145876744"
                        ],
                        "name": "M. Vetterli",
                        "slug": "M.-Vetterli",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Vetterli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vetterli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 169
                            }
                        ],
                        "text": "We note, however, that the \ndistributions extracted from a collection of local feature vec\u00adtors can be of other forms, for instance, \na continuous density function [Do and Vetterli 2002], or even a spatial stochastic model [Li and Wang \n2004]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 260
                            }
                        ],
                        "text": "When images are represented as ensembles of feature \nvectors, or underlying distributions of the low\u00adlevel features, visual similarity can be ascertained \nby means of nonparametric tests such as Wald-Wolfowitz [Theoharatos et al. 2005] and K-L divergence [Do \nand Vetterli 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 177
                            }
                        ],
                        "text": "One advantage of the mixture modeling \napproach is that it not only provides a partition of data, but also yields an estimated density, which \nsometimes is itself desired [Do and Vetterli 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9490140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "147e93184cd4b13a1423dbe5bca0c706cbc5b978",
            "isKey": true,
            "numCitedBy": 1210,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a statistical view of the texture retrieval problem by combining the two related tasks, namely feature extraction (FE) and similarity measurement (SM), into a joint modeling and classification scheme. We show that using a consistent estimator of texture model parameters for the FE step followed by computing the Kullback-Leibler distance (KLD) between estimated models for the SM step is asymptotically optimal in term of retrieval error probability. The statistical scheme leads to a new wavelet-based texture retrieval method that is based on the accurate modeling of the marginal distribution of wavelet coefficients using generalized Gaussian density (GGD) and on the existence a closed form for the KLD between GGDs. The proposed method provides greater accuracy and flexibility in capturing texture information, while its simplified form has a close resemblance with the existing methods which uses energy distribution in the frequency domain to identify textures. Experimental results on a database of 640 texture images indicate that the new method significantly improves retrieval rates, e.g., from 65% to 77%, compared with traditional approaches, while it retains comparable levels of computational complexity."
            },
            "slug": "Wavelet-based-texture-retrieval-using-generalized-Do-Vetterli",
            "title": {
                "fragments": [],
                "text": "Wavelet-based texture retrieval using generalized Gaussian density and Kullback-Leibler distance"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A statistical view of the texture retrieval problem is presented by combining the two related tasks, namely feature extraction (FE) and similarity measurement (SM), into a joint modeling and classification scheme that leads to a new wavelet-based texture retrieval method that is based on the accurate modeling of the marginal distribution of wavelet coefficients using generalized Gaussian density (GGD)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729390"
                        ],
                        "name": "Euripides G. M. Petrakis",
                        "slug": "Euripides-G.-M.-Petrakis",
                        "structuredName": {
                            "firstName": "Euripides",
                            "lastName": "Petrakis",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Euripides G. M. Petrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6565978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c162829cd2c6c7bdb55bbd2b67b83dc643ad7602",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method to handle approximate searching by image content in medical image databases. Image content is represented by attributed relational graphs holding features of objects and relationships between objects. The method relies on the assumption that a fixed number of \"labeled\" or \"expected\" objects (e.g., \"heart\", \"lungs\", etc.) are common in all images of a given application domain in addition to a variable number of \"unexpected\" or \"unlabeled\" objects (e.g., \"tumor\", \"hematoma\", etc.). The method can answer queries by example, such as \"find all X-rays that are similar to Smith's X-ray\". The stored images are mapped to points in a multidimensional space and are indexed using state-of-the-art database methods (R-trees). The proposed method has several desirable properties: (a) Database search is approximate, so that all images up to a prespecified degree of similarity (tolerance) are retrieved. (b) It has no \"false dismissals\" (i.e., all images qualifying query selection criteria are retrieved). (c) It is much faster than sequential scanning for searching in the main memory and on the disk (i.e., by up to an order of magnitude), thus scaling-up well for large databases."
            },
            "slug": "Similarity-Searching-in-Medical-Image-Databases-Petrakis-Faloutsos",
            "title": {
                "fragments": [],
                "text": "Similarity Searching in Medical Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The proposed method to handle approximate searching by image content in medical image databases has several desirable properties: it is much faster than sequential scanning for searching in the main memory and on the disk, thus scaling-up well for large databases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11480,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801509"
                        ],
                        "name": "M. Bertini",
                        "slug": "M.-Bertini",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Bertini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bertini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741922"
                        ],
                        "name": "R. Cucchiara",
                        "slug": "R.-Cucchiara",
                        "structuredName": {
                            "firstName": "Rita",
                            "lastName": "Cucchiara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cucchiara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51382163"
                        ],
                        "name": "A. Prati",
                        "slug": "A.-Prati",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Prati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Prati"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 150
                            }
                        ],
                        "text": "A class of methods known as semantic transcoding aim at designing intelligent transcoding systems which can adapt \u201csemantically\u201d to user requirements [Bertini et al. 2003; Cucchiara et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 236
                            }
                        ],
                        "text": "Image transcoding techniques, which aim at adapting \nmultimedia (image and video) content to the capabilities of the client device, have been studied extensively \nin the last several years [Shanableh and Ghanbari 2000; Vetro et al. 2003; Bertini et al. 2003; Cucchiara \net al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "A class of methods known as semantic transcoding aims at designing intelligent transcoding \nsystems which can adapt semantically to user requirements [Bertini et al. 2003; Cucchiara et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 187
                            }
                        ],
                        "text": "Image transcoding techniques, which aim at adapting multimedia (image and video) content to the capabilities of the client device, have been studied extensively in the last several years [Shanableh and Ghanbari 2000; Vetro et al. 2003; Bertini et al. 2003; Cucchiara et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14369687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "208d93986a60569569ba833f5f14ad0dcdad02e8",
            "isKey": true,
            "numCitedBy": 8,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Video annotation provides a suitable way to describe, organize, and index stored videos. On the other hand, transcoding aims at adapting content to the user/client capabilities and requirements. Both cues are now mandatory, given the tremendous demand of multimedia access from remote clients, in particular nowadays that new terminals with limited resources (PDAs, HCCs, Smart phones) have access to the network. In this paper we propose a unified framework to define event-based and object-based semantic extraction from video to provide both semantic video annotation for video stored and semantic on-line transcoding from live cameras. Two case studies (highlights' extraction from soccer videos for the annotation and people behavior detection in domotic application for transcoding) and corresponding experimental results are reported."
            },
            "slug": "Object-and-event-detection-for-semantic-annotation-Bertini-Cucchiara",
            "title": {
                "fragments": [],
                "text": "Object and event detection for semantic annotation and transcoding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A unified framework to define event-based and object-based semantic extraction from video to provide both semantic video annotation for video stored and semantic on-line transcoding from live cameras is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145758269"
                        ],
                        "name": "J. Ohm",
                        "slug": "J.-Ohm",
                        "structuredName": {
                            "firstName": "Jens-Rainer",
                            "lastName": "Ohm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120123566"
                        ],
                        "name": "V. Vasudevan",
                        "slug": "V.-Vasudevan",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Vasudevan",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29462550"
                        ],
                        "name": "A. Yamada",
                        "slug": "A.-Yamada",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yamada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14372485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "685b1fb262a2be4749f8ed23f36230699d85c997",
            "isKey": false,
            "numCitedBy": 1818,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an overview of color and texture descriptors that have been approved for the Final Committee Draft of the MPEG-7 standard. The color and texture descriptors that are described in this paper have undergone extensive evaluation and development during the past two years. Evaluation criteria include effectiveness of the descriptors in similarity retrieval, as well as extraction, storage, and representation complexities. The color descriptors in the standard include a histogram descriptor that is coded using the Haar transform, a color structure histogram, a dominant color descriptor, and a color layout descriptor. The three texture descriptors include one that characterizes homogeneous texture regions and another that represents the local edge distribution. A compact descriptor that facilitates texture browsing is also defined. Each of the descriptors is explained in detail by their semantics, extraction and usage. The effectiveness is documented by experimental results."
            },
            "slug": "Color-and-texture-descriptors-Manjunath-Ohm",
            "title": {
                "fragments": [],
                "text": "Color and texture descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An overview of color and texture descriptors that have been approved for the Final Committee Draft of the MPEG-7 standard is presented, explained in detail by their semantics, extraction and usage."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5113463"
                        ],
                        "name": "D. Joshi",
                        "slug": "D.-Joshi",
                        "structuredName": {
                            "firstName": "Dhiraj",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 404001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7d6366c90fe8f1fe87c3ad3abbed5945bf9a979",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised approach to automated story picturing. Semantic keywords are extracted from the story, an annotated image database is searched. Thereafter, a novel image ranking scheme automatically determines the importance of each image. Both lexical annotations and visual content play a role in determining the ranks. Annotations are processed using the Wordnet. A mutual reinforcement-based rank is calculated for each image. We have implemented the methods in our Story Picturing Engine (SPE) system. Experiments on large-scale image databases are reported. A user study has been performed and statistical analysis of the results has been presented."
            },
            "slug": "The-Story-Picturing-Engine---a-system-for-automatic-Joshi-Wang",
            "title": {
                "fragments": [],
                "text": "The Story Picturing Engine---a system for automatic text illustration"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An unsupervised approach to automated story picturing by extracting semantic keywords from the story, an annotated image database is searched and a novel image ranking scheme automatically determines the importance of each image."
            },
            "venue": {
                "fragments": [],
                "text": "TOMCCAP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2964260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aac66ac5e90cc4c187a5aa063b522e5193ef8834",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and demonstrate a texture region descriptor which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region. It is applicable to texture patches which are locally planar and have stationary statistics. The novelty of the descriptor is that it is based on statistics aggregated over the region, resulting in richer and more stable descriptors than those computed at a point. Two texture matching applications of this descriptor are demonstrated: (1) it is used to automatically identify, regions of the same type of texture, but with varying surface pose, within a single image; (2) it is used to support wide baseline stereo, i.e. to enable the automatic computation of the epipolar geometry between two images acquired from quite separated viewpoints. Results are presented on several sets of real images."
            },
            "slug": "Viewpoint-invariant-texture-matching-and-wide-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Viewpoint invariant texture matching and wide baseline stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A texture region descriptor is described and demonstrated which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region, resulting in richer and more stable descriptors than those computed at a point."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689798"
                        ],
                        "name": "P. Ciaccia",
                        "slug": "P.-Ciaccia",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Ciaccia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ciaccia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742653"
                        ],
                        "name": "M. Patella",
                        "slug": "M.-Patella",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Patella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Patella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701332"
                        ],
                        "name": "P. Zezula",
                        "slug": "P.-Zezula",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Zezula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Zezula"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15393774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7576f59f5b78b9b34f8df872243400df18949b25",
            "isKey": false,
            "numCitedBy": 1852,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A new access method, called M-tree, is proposed to organize and search large data sets from a generic \u201cmetric space\u201d, i.e. where object proximity is only defined by a distance function satisfying the positivity, symmetry, and triangle inequality postulates. We detail algorithms for insertion of objects and split management, which keep the M-tree always balanced - several heuristic split alternatives are considered and experimentally evaluated. Algorithms for similarity (range and k-nearest neighbors) queries are also described. Results from extensive experimentation with a prototype system are reported, considering as the performance criteria the number of page I/O\u2019s and the number of distance computations. The results demonstrate that the Mtree indeed extends the domain of applicability beyond the traditional vector spaces, performs reasonably well in high-dimensional data spaces, and scales well in case of growing files."
            },
            "slug": "M-tree:-An-Efficient-Access-Method-for-Similarity-Ciaccia-Patella",
            "title": {
                "fragments": [],
                "text": "M-tree: An Efficient Access Method for Similarity Search in Metric Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results demonstrate that the Mtree indeed extends the domain of applicability beyond the traditional vector spaces, performs reasonably well in high-dimensional data spaces, and scales well in case of growing files."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2396296"
                        ],
                        "name": "S. Gordon",
                        "slug": "S.-Gordon",
                        "structuredName": {
                            "firstName": "Shiri",
                            "lastName": "Gordon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34508613"
                        ],
                        "name": "J. Goldberger",
                        "slug": "J.-Goldberger",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Goldberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goldberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1044685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c82fcf6e64532a358e79237bd5e7282252259570",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for unsupervised clustering of image databases. The method is based on a recently introduced information-theoretic principle, the information bottleneck (IB) principle. Image archives are clustered such that the mutual information between the clusters and the image content is maximally preserved. The IB principle is applied to both discrete and continuous image representations, using discrete image histograms and probabilistic continuous image modeling based on mixture of Gaussian densities, respectively. Experimental results demonstrate the performance of the proposed method for image clustering on a large image database. Several clustering algorithms derived from the IB principle are explored and compared."
            },
            "slug": "Applying-the-information-bottleneck-principle-to-of-Gordon-Greenspan",
            "title": {
                "fragments": [],
                "text": "Applying the information bottleneck principle to unsupervised clustering of discrete and continuous image representations"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The proposed method is based on a recently introduced information-theoretic principle, the information bottleneck (IB) principle, which is applied to both discrete and continuous image representations, using discrete image histograms and probabilistic continuous image modeling based on mixture of Gaussian densities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40603954"
                        ],
                        "name": "Kingshy Goh",
                        "slug": "Kingshy-Goh",
                        "structuredName": {
                            "firstName": "Kingshy",
                            "lastName": "Goh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kingshy Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2314761"
                        ],
                        "name": "Gerard Sychay",
                        "slug": "Gerard-Sychay",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Sychay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerard Sychay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145394457"
                        ],
                        "name": "Gang Wu",
                        "slug": "Gang-Wu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12014229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62f5bf45b2e702775fa2a36de45a7522bb9ff23f",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a content-based soft annotation (CBSA) procedure for providing images with semantical labels. The annotation procedure starts with labeling a small set of training images, each with one single semantical label (e.g., forest, animal, or sky). An ensemble of binary classifiers is then trained for predicting label membership for images. The trained ensemble is applied to each individual image to give the image multiple soft labels, and each label is associated with a label membership factor. To select a base binary-classifier for CBSA, we experiment with two learning methods, support vector machines (SVMs) and Bayes point machines (BPMs), and compare their class-prediction accuracy. Our empirical study on a 116-category 25K-image set shows that the BPM-based ensemble provides better annotation quality than the SVM-based ensemble for supporting multimodal image retrievals."
            },
            "slug": "CBSA:-content-based-soft-annotation-for-multimodal-Chang-Goh",
            "title": {
                "fragments": [],
                "text": "CBSA: content-based soft annotation for multimodal image retrieval using Bayes point machines"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work proposes a content-based soft annotation procedure for providing images with semantical labels, and experiments with two learning methods, support vector machines (SVMs) and Bayes point machines (BPMs), to select a base binary-classifier for CBSA."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764131"
                        ],
                        "name": "R. Mehrotra",
                        "slug": "R.-Mehrotra",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mehrotra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50476996"
                        ],
                        "name": "James E. Gary",
                        "slug": "James-E.-Gary",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Gary",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James E. Gary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42769186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ef7073a8db6dd706e432785564393871f38353e",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Addresses the problem of similar-shape retrieval, where shapes or images in a shape database that satisfy specified shape-similarity constraints with respect to the query shape or image must be retrieved from the database. In its simplest form, the similar-shape retrieval problem can be stated as, \"retrieve or select all shapes or images that are visually similar to the query shape or the query image's shape\". We focus on databases of 2D shapes-or equivalently, databases of images of flat or almost flat objects. (We use the terms \"object\" and \"shape\" interchangeably). Two common types of 2D objects are rigid objects, which have a single rigid component called a link, and articulated objects, which have two or more rigid components joined by movable (rotating or sliding) joints. An ideal similar-shape retrieval technique must be general enough to handle images of articulated as well as rigid objects. It must be flexible enough to handle simple query images, which have isolated shapes, and complex query images, which have partially visible, overlapping or touching objects. We discuss the central issues in similar-shape retrieval and explain how these issues are resolved in a shape retrieval scheme called FIBSSR (Feature Index-Based Similar-Shape Retrieval). This new similar-shape retrieval system effectively models real-world applications. >"
            },
            "slug": "Similar-Shape-Retrieval-in-Shape-Data-Management-Mehrotra-Gary",
            "title": {
                "fragments": [],
                "text": "Similar-Shape Retrieval in Shape Data Management"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work discusses the central issues in similar-shape retrieval and explains how these issues are resolved in a shape retrieval scheme called FIBSSR (Feature Index-Based Similar-Shape Retrieval)."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26959611"
                        ],
                        "name": "Jie Yu",
                        "slug": "Jie-Yu",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876831"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34792252"
                        ],
                        "name": "J. Amores",
                        "slug": "J.-Amores",
                        "structuredName": {
                            "firstName": "Jaume",
                            "lastName": "Amores",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Amores"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2279134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7441dafa629e154f03061f29f18010ed56b3c0f3",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a general guideline to establish the relation between a distribution model and its corresponding similarity estimation. A rich set of distance metrics, such as harmonic distance and geometric distance, is derived according to Maximum Likelihood theory. These metrics can provide a more accurate feature model than the conventional Euclidean distance (SSD) and Manhattan distance (SAD). Because the feature elements are from heterogeneous sources and may have different influence on similarity estimation, the assumption of single isotropic distribution model is often inappropriate. We propose a novel boosted distance metric that not only finds the best distance metric that fits the distribution of the underlying elements but also selects the most important feature elements with respect to similarity. We experiment with different distance metrics for similarity estimation and compute the accuracy of different methods in two applications: stereo matching and motion tracking in video sequences. The boosted distance metric is tested on fifteen benchmark data sets from the UCI repository and two image retrieval applications. In all the experiments, robust results are obtained based on the proposed methods."
            },
            "slug": "Toward-Robust-Distance-Metric-Analysis-for-Yu-Tian",
            "title": {
                "fragments": [],
                "text": "Toward Robust Distance Metric Analysis for Similarity Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel boosted distance metric is proposed that not only finds the best distance metric that fits the distribution of the underlying elements but also selects the most important feature elements with respect to similarity."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2208644"
                        ],
                        "name": "Sangoh Jeong",
                        "slug": "Sangoh-Jeong",
                        "structuredName": {
                            "firstName": "Sangoh",
                            "lastName": "Jeong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangoh Jeong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706549"
                        ],
                        "name": "C. Won",
                        "slug": "C.-Won",
                        "structuredName": {
                            "firstName": "Chee",
                            "lastName": "Won",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Won"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In [Jeong et al. 2004], Gaussian mixture vector quantization (GMVQ) is used to extract color histograms and shown to yield better retrieval than uniform quantization and vector quantization with squared error."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15588452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a46414ab9a4cac09eec36e25b220c44faf666130",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-retrieval-using-color-histograms-generated-by-Jeong-Won",
            "title": {
                "fragments": [],
                "text": "Image retrieval using color histograms generated by Gauss mixture vector quantization"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35561340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73bd5c30eb274671c30b8f7222b5e4b03a915a62",
            "isKey": false,
            "numCitedBy": 2286,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel statistical and variational approach to image segmentation based on a new algorithm, named region competition. This algorithm is derived by minimizing a generalized Bayes/minimum description length (MDL) criterion using the variational principle. The algorithm is guaranteed to converge to a local minimum and combines aspects of snakes/balloons and region growing. The classic snakes/balloons and region growing algorithms can be directly derived from our approach. We provide theoretical analysis of region competition including accuracy of boundary location, criteria for initial conditions, and the relationship to edge detection using filters. It is straightforward to generalize the algorithm to multiband segmentation and we demonstrate it on gray level images, color images and texture images. The novel color model allows us to eliminate intensity gradients and shadows, thereby obtaining segmentation based on the albedos of objects. It also helps detect highlight regions."
            },
            "slug": "Region-Competition:-Unifying-Snakes,-Region-and-for-Zhu-Yuille",
            "title": {
                "fragments": [],
                "text": "Region Competition: Unifying Snakes, Region Growing, and Bayes/MDL for Multiband Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel statistical and variational approach to image segmentation based on a new algorithm, named region competition, derived by minimizing a generalized Bayes/minimum description length (MDL) criterion using the variational principle is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10952196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e28e81e757009d2f76b8674e0da431f5845884a",
            "isKey": false,
            "numCitedBy": 1773,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the automatic selection of features from an image training set using the theories of multidimensional discriminant analysis and the associated optimal linear projection. We demonstrate the effectiveness of these most discriminating features for view-based class retrieval from a large database of widely varying real-world objects presented as \"well-framed\" views, and compare it with that of the principal component analysis."
            },
            "slug": "Using-Discriminant-Eigenfeatures-for-Image-Swets-Weng",
            "title": {
                "fragments": [],
                "text": "Using Discriminant Eigenfeatures for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper describes the automatic selection of features from an image training set using the theories of multidimensional discriminant analysis and the associated optimal linear projection, and demonstrates the effectiveness of these most discriminating features for view-based class retrieval from a large database of widely varying real-world objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683556"
                        ],
                        "name": "G. Wiederhold",
                        "slug": "G.-Wiederhold",
                        "structuredName": {
                            "firstName": "Gio",
                            "lastName": "Wiederhold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wiederhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1149168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d607b773d2719a5948bab0c16500e4f00fd61df8",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised segmentation of images with low depth of field (DOF) is highly useful in various applications. This paper describes a novel multiresolution image segmentation algorithm for low DOF images. The algorithm is designed to separate a sharply focused object-of-interest from other foreground or background objects. The algorithm is fully automatic in that all parameters are image independent. A multi-scale approach based on high frequency wavelet coefficients and their statistics is used to perform context-dependent classification of individual blocks of the image. Unlike other edge-based approaches, our algorithm does not rely on the process of connecting object boundaries. The algorithm has achieved high accuracy when tested on more than 100 low DOF images, many with inhomogeneous foreground or background distractions. Compared with he state of the art algorithms, this new algorithm provides better accuracy at higher speed."
            },
            "slug": "Unsupervised-Multiresolution-Segmentation-for-with-Wang-Li",
            "title": {
                "fragments": [],
                "text": "Unsupervised Multiresolution Segmentation for Images with Low Depth of Field"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel multiresolution image segmentation algorithm designed to separate a sharply focused object-of-interest from other foreground or background objects and provides better accuracy at higher speed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145420180"
                        ],
                        "name": "Y. Zhai",
                        "slug": "Y.-Zhai",
                        "structuredName": {
                            "firstName": "Yun",
                            "lastName": "Zhai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zhai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1858702"
                        ],
                        "name": "A. Yilmaz",
                        "slug": "A.-Yilmaz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Yilmaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yilmaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1929459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd16f1b55a447f609d7a5575801b54cb0807ba92",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a framework for segmenting the news programs into different story topics. The proposed method utilizes both visual and text information of the video. We represent the news video by a Shot Connectivity Graph (SCG), where the nodes in the graph represent the shots in the video, and the edges between nodes represent the transitions between shots. The cycles in the graph correspond to the story segments in the news program. We first detect the cycles in the graph by finding the anchor persons in the video. This provides us with the coarse segmentation of the news video. The initial segmentation is later refined by the detections of the weather and sporting news, and the merging of similar stories. For the weather detection, the global color information of the images and the motion of the shots are considered. We have used the text obtained from automatic speech recognition (ASR) for detecting the potential sporting shots to form the sport stories. Adjacent stories with similar semantic meanings are further merged based on the visual and text similarities. The proposed framework has been tested on a widely used data set provided by NIST, which contains the ground truth of the story boundaries, and competitive evaluation results have been obtained."
            },
            "slug": "Story-Segmentation-in-News-Videos-Using-Visual-and-Zhai-Yilmaz",
            "title": {
                "fragments": [],
                "text": "Story Segmentation in News Videos Using Visual and Text Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The proposed framework for segmenting the news programs into different story topics has been tested on a widely used data set provided by NIST, which contains the ground truth of the story boundaries, and competitive evaluation results have been obtained."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144685852"
                        ],
                        "name": "K. Martinez",
                        "slug": "K.-Martinez",
                        "structuredName": {
                            "firstName": "Kirk",
                            "lastName": "Martinez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Martinez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48189329"
                        ],
                        "name": "J. Cupitt",
                        "slug": "J.-Cupitt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cupitt",
                            "middleNames": [
                                "R.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cupitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024578"
                        ],
                        "name": "D. Saunders",
                        "slug": "D.-Saunders",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145329919"
                        ],
                        "name": "R. Pillay",
                        "slug": "R.-Pillay",
                        "structuredName": {
                            "firstName": "Ruven",
                            "lastName": "Pillay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pillay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 81
                            }
                        ],
                        "text": "Comprehensive surveys on latest advances in art imaging research can be found in [Martinez et al. 2002; Maitre et al. 2001; Barni et al. 2005; Chen et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14951492,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "8da9a014d416492ed7a87a7dff1541ff9d398623",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a decade of work on digital imaging for museums. From 1989 to 1992, the visual arts system for archiving and retrieval of images (VASARI) project produced a digital-imaging system that made color-calibrated images of up to 20000/spl times/20000 pixels directly from paintings. It used seven color-separation bands in the visible region, resulting in an average color error of around 1 /spl Delta/E*/sub ab/ unit. These images have since been used to monitor the condition of paintings, document paintings during conservation treatment, including predicting appearance after cleaning, reconstruct the original appearance of paintings in which pigments have faded, and assess whether paintings have been damaged during transportation, in estimations of the surface reflectance spectra and in the printing of high-quality reproductions. We have applied similar techniques to museum infrared and X-ray imaging. To manage the images produced by the VASARI system, an image-processing package has been developed that is tailored for very large colorimetric images. This package has since been used in several other projects, including a remote image viewer designed to provide internet access to high-resolution images. The paper explores these developments and gives details of the current generation of VASARI-derived systems, set in the context of the state of the art for museum imaging."
            },
            "slug": "Ten-years-of-art-imaging-research-Martinez-Cupitt",
            "title": {
                "fragments": [],
                "text": "Ten years of art imaging research"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A decade of work on digital imaging for museums, set in the context of the state of the art for museum imaging, is described, including a remote image viewer designed to provide internet access to high-resolution images."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144076239"
                        ],
                        "name": "Xing Xie",
                        "slug": "Xing-Xie",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143856677"
                        ],
                        "name": "Hao Liu",
                        "slug": "Hao-Liu",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2003931"
                        ],
                        "name": "Simon Goumaz",
                        "slug": "Simon-Goumaz",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Goumaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Goumaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11709445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b13afc392d318b1ff1199a7df19d68c188af92fa",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Mobile devices which can capture and view pictures are becoming increasingly common in our life. The limitation of these small-form-factor devices makes the user experience of image browsing quite different from that on desktop PCs. In this paper, we first present a user study on how users interact with a mobile image browser with basic functions. We found that on small displays, users tend to use more zooming and scrolling actions in order to view interesting regions in detail. From this fact, we designed a new method to detect user interest maps and extract user attention objects from the image browsing log. This approach is more efficient than image-analysis based methods and can better represent users' actual interest. A smart image viewer was then developed based on user interest analysis. A second experiment was carried out to study how users behave with such a viewer. Experimental results demonstrate that the new smart features can improve the browsing efficiency and are a good compliment to traditional image browsers."
            },
            "slug": "Learning-user-interest-for-image-browsing-on-Xie-Liu",
            "title": {
                "fragments": [],
                "text": "Learning user interest for image browsing on small-form-factor devices"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new method to detect user interest maps and extract user attention objects from the image browsing log is designed, which is more efficient than image-analysis based methods and can better represent users' actual interest."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068322935"
                        ],
                        "name": "Yan Ke",
                        "slug": "Yan-Ke",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Ke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Ke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745185"
                        ],
                        "name": "Feng Jing",
                        "slug": "Feng-Jing",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Jing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 16
                            }
                        ],
                        "text": "Another attempt [Ke et al. 2006] at distinguishing high-quality images from low-quality ones has found similar levels of success with data obtained from yet another peer-rated photo contest oriented Website [DPChallenge."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 139225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6989f866a445bb880ed8663a05dc4cd71c87b1b7",
            "isKey": false,
            "numCitedBy": 641,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a principled method for designing high level features forphoto quality assessment. Our resulting system can classify between high quality professional photos and low quality snapshots. Instead of using the bag of low-level features approach, we first determine the perceptual factors that distinguish between professional photos and snapshots. Then, we design high level semantic features to measure the perceptual differences. We test our features on a large and diverse dataset and our system is able to achieve a classification rate of 72% on this difficult task. Since our system is able to achieve a precision of over 90% in low recall scenarios, we show excellent results in a web image search application."
            },
            "slug": "The-Design-of-High-Level-Features-for-Photo-Quality-Ke-Tang",
            "title": {
                "fragments": [],
                "text": "The Design of High-Level Features for Photo Quality Assessment"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A principled method for designing high level features for photo quality assessment is proposed and the resulting system can classify between high quality professional photos and low quality snapshots."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741126"
                        ],
                        "name": "S. Hoi",
                        "slug": "S.-Hoi",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Hoi",
                            "middleNames": [
                                "C.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785083"
                        ],
                        "name": "Michael R. Lyu",
                        "slug": "Michael-R.-Lyu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lyu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15959377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23cf330816f8281cf458f341d28ee32653b879a5",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines (SVMs) have become one of the most promising techniques for relevance feedback in content-based image retrieval (CBIR). Typical SVM-based relevance feedback techniques simply apply the strict binary classifications: positive (relevant) class and negative (irrelevant) class. However, in a real-world relevance feedback task, it is more reasonable and practical to assume the data come from multiple positive classes and one negative class. In order to formulate an effective relevance feedback algorithm, we propose a novel group-based relevance feedback scheme constructed with the SVM ensembles technique. Experiments are conducted to evaluate the performance of our proposed scheme and the traditional SVM-based relevance feedback technique in CBIR. The experimental results show that our proposed scheme is more effective than the regular method."
            },
            "slug": "Group-based-relevance-feedback-with-support-vector-Hoi-Lyu",
            "title": {
                "fragments": [],
                "text": "Group-based relevance feedback with support vector machine ensembles"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a novel group-based relevance feedback scheme constructed with the SVM ensembles technique, and results show that the proposed scheme is more effective than the regular method."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15208439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "400736e84b3b04ffa41542cf62b6546e57f590f7",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a framework for texture recognition based on local affine-invariant descriptors and their spatial layout. At modelling time, a generative model of local descriptors is learned from sample images using the EM algorithm. The EM framework allows the incorporation of unsegmented multitexture images into the training set. The second modelling step consists of gathering co-occurrence statistics of neighboring descriptors. At recognition time, initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics. Performance is evaluated on images of an indoor scene and pictures of wild animals."
            },
            "slug": "Affine-invariant-local-descriptors-and-neighborhood-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Affine-invariant local descriptors and neighborhood statistics for texture recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A framework for texture recognition based on local affine-invariant descriptors and their spatial layout is presented and initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24982365"
                        ],
                        "name": "Dengyong Zhou",
                        "slug": "Dengyong-Zhou",
                        "structuredName": {
                            "firstName": "Dengyong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dengyong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708497"
                        ],
                        "name": "A. Gretton",
                        "slug": "A.-Gretton",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Gretton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gretton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698617"
                        ],
                        "name": "O. Bousquet",
                        "slug": "O.-Bousquet",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bousquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bousquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 69
                            }
                        ],
                        "text": "This idea is explored and applied to image similarity and ranking in [He 2004; Vasconcelos and Lippman 2005; He et al. 2004; He et al. 2004a; Zhou et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7724688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "429eb35f06a90892a9595545d18e46ddfe981152",
            "isKey": false,
            "numCitedBy": 737,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Google search engine has enjoyed huge success with its web page ranking algorithm, which exploits global, rather than local, hyperlink structure of the web using random walks. Here we propose a simple universal ranking algorithm for data lying in the Euclidean space, such as text or image data. The core idea of our method is to rank the data with respect to the intrinsic manifold structure collectively revealed by a great amount of data. Encouraging experimental results from synthetic, image, and text data illustrate the validity of our method."
            },
            "slug": "Ranking-on-Data-Manifolds-Zhou-Weston",
            "title": {
                "fragments": [],
                "text": "Ranking on Data Manifolds"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple universal ranking algorithm for data lying in the Euclidean space, such as text or image data, to rank the data with respect to the intrinsic manifold structure collectively revealed by a great amount of data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2643381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1a2d203733208deda7427c8e20318334193d9d7",
            "isKey": false,
            "numCitedBy": 3025,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many \"plausible\" ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider \"similar.\" For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \u211dn, learns a distance metric over \u211dn that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance."
            },
            "slug": "Distance-Metric-Learning-with-Application-to-with-Xing-Ng",
            "title": {
                "fragments": [],
                "text": "Distance Metric Learning with Application to Clustering with Side-Information"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \ufffd\u201dn, learns a distance metric over \u211dn that respects these relationships."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108149564"
                        ],
                        "name": "Junqing Chen",
                        "slug": "Junqing-Chen",
                        "structuredName": {
                            "firstName": "Junqing",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junqing Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714983"
                        ],
                        "name": "T. Pappas",
                        "slug": "T.-Pappas",
                        "structuredName": {
                            "firstName": "Thrasyvoulos",
                            "lastName": "Pappas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pappas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144053687"
                        ],
                        "name": "A. Mojsilovic",
                        "slug": "A.-Mojsilovic",
                        "structuredName": {
                            "firstName": "Aleksandra",
                            "lastName": "Mojsilovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mojsilovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3112585"
                        ],
                        "name": "B. Rogowitz",
                        "slug": "B.-Rogowitz",
                        "structuredName": {
                            "firstName": "Bernice",
                            "lastName": "Rogowitz",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rogowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 971415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6d05c0977754d4829541a7ecb33b660da8a922",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an image segmentation algorithm that is based on spatially adaptive color and texture features. The features are first developed independently, and then combined to obtain an overall segmentation. Texture feature estimation requires a finite neighborhood which limits the spatial resolution of texture segmentation, while color segmentation provides accurate and precise edge localization. We combine a previously proposed adaptive clustering algorithm for color segmentation with a simple but effective texture segmentation approach to obtain an overall image segmentation. Our focus is in the domain of photographic images with an essentially unlimited range of topics. The images are assumed to be of relatively low resolution and may be degraded or compressed."
            },
            "slug": "Adaptive-image-segmentation-based-on-color-and-Chen-Pappas",
            "title": {
                "fragments": [],
                "text": "Adaptive image segmentation based on color and texture"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work combines a previously proposed adaptive clustering algorithm for color segmentation with a simple but effective texture segmentation approach to obtain an overall image segmentation algorithm in the domain of photographic images with an essentially unlimited range of topics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144112511"
                        ],
                        "name": "Ronald Fagin",
                        "slug": "Ronald-Fagin",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Fagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Fagin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 2
                            }
                        ],
                        "text": ", [Fagin 1997]), and learning based approaches for similarity matching (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28200118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b290ed077e7ff0cc1d93de359344e1cced34ebd",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In a traditional database system, the result of a query is a set of values (those values that satisfy the query). In other data servers, such as a system with queries based on image content, or many text retrieval systems, the result of a query is a sorted list. For example, in the case of a system with queries based on image content, the query might ask for objects that are a particular shade of red, and the result of the query would be a sorted list of objects in the database, sorted by how well the color of the object matches that given in the query. A multimedia system must somehow synthesize both types of queries (those whose result is a set and those whose result is a sorted list) in a consistent manner. In this paper we discuss the solution adopted by Garlic, a multimedia information system being developed at the IBM Almaden Research Center. This solution is based on \u201cgraded\u201d (or \u201cfuzzy\u201d) sets. Issues of efficient query evaluation in a multimedia system are very different from those in a traditional database system. This is because the multimedia system receives answers to subqueries from various subsystems, which can be accessed only in limited ways. For the important class of queries that are conjunctions of atomic queries (where each atomic query might be evaluated by a different subsystem), the naive algorithm must retrieve a number of elements that is linear in the database size. In contrast, in this paper an algorithm is given, which has been implemented in Garlic, such that if the conjuncts are independent, then with arbitrarily high probability, the total number of elements retrieved in evaluating the query is sublinear in the database size (in the case of two conjuncts, it is of the order of the square root of the database size). It is also shown that for such queries, the algorithm is optimal. The matching upper and lower bounds are robust, in the sense that they hold under almost any reasonable rule (including the standard min rule of fuzzy logic) for evaluating the conjunction. Finally, we find a query that is provably hard, in the sense that the naive linear algorithm is essentially optimal."
            },
            "slug": "Combining-Fuzzy-Information-from-Multiple-Systems-Fagin",
            "title": {
                "fragments": [],
                "text": "Combining Fuzzy Information from Multiple Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm is given, which has been implemented in Garlic, such that if the conjuncts are independent, then with arbitrarily high probability, the total number of elements retrieved in evaluating the query is sublinear in the database size."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718927"
                        ],
                        "name": "S. Cunningham",
                        "slug": "S.-Cunningham",
                        "structuredName": {
                            "firstName": "Sally",
                            "lastName": "Cunningham",
                            "middleNames": [
                                "Jo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cunningham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143748132"
                        ],
                        "name": "D. Bainbridge",
                        "slug": "D.-Bainbridge",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bainbridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bainbridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740975"
                        ],
                        "name": "M. Masoodian",
                        "slug": "M.-Masoodian",
                        "structuredName": {
                            "firstName": "Masood",
                            "lastName": "Masoodian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Masoodian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12426015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d7d43c4fe745d821574494959eeff6cbc648688",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "When people are looking for visual arts information - information related to images - how do they characterize their needs? We analyze a set of 404 queries to identify the attributes that people provide to the Google Answers /spl trade/ 'ask an expert' online reference system. The results suggest directions to take in developing an effective organization and features for an image digital library."
            },
            "slug": "How-people-describe-their-image-information-needs:-Cunningham-Bainbridge",
            "title": {
                "fragments": [],
                "text": "How people describe their image information needs: a grounded theory analysis of visual arts queries"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A set of 404 queries is analyzed to identify the attributes that people provide to the Google Answers /spl trade/ 'ask an expert' online reference system and the results suggest directions to take in developing an effective organization and features for an image digital library."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries, 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33523605"
                        ],
                        "name": "J. Portilla",
                        "slug": "J.-Portilla",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "Portilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Portilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2475577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37afeac49518877dc96a3ca2ec3ebdfc5305e0a9",
            "isKey": false,
            "numCitedBy": 1811,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a universal statistical model for texture images in the context of an overcomplete complex wavelet transform. The model is parameterized by a set of statistics computed on pairs of coefficients corresponding to basis functions at adjacent spatial locations, orientations, and scales. We develop an efficient algorithm for synthesizing random images subject to these constraints, by iteratively projecting onto the set of images satisfying each constraint, and we use this to test the perceptual validity of the model. In particular, we demonstrate the necessity of subgroups of the parameter set by showing examples of texture synthesis that fail when those parameters are removed from the set. We also demonstrate the power of our model by successfully synthesizing examples drawn from a diverse collection of artificial and natural textures."
            },
            "slug": "A-Parametric-Texture-Model-Based-on-Joint-of-Portilla-Simoncelli",
            "title": {
                "fragments": [],
                "text": "A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A universal statistical model for texture images in the context of an overcomplete complex wavelet transform is presented, demonstrating the necessity of subgroups of the parameter set by showing examples of texture synthesis that fail when those parameters are removed from the set."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39089563"
                        ],
                        "name": "Lei Zhang",
                        "slug": "Lei-Zhang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65772260"
                        ],
                        "name": "Longbin Chen",
                        "slug": "Longbin-Chen",
                        "structuredName": {
                            "firstName": "Longbin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Longbin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8392859"
                        ],
                        "name": "Mingjing Li",
                        "slug": "Mingjing-Li",
                        "structuredName": {
                            "firstName": "Mingjing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingjing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1573162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86ff576c2fa8d4acbce75093459f0bf6c915c7db",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic annotation of photographs is one of the most desirable needs in family photograph management systems. In this paper, we present a learning framework to automate the face annotation in family photograph albums. Firstly, methodologies of content-based image retrieval and face recognition are seamlessly integrated to achieve automated annotation. Secondly, face annotation is formulated in a Bayesian framework, in which the face similarity measure is defined as maximum a posteriori (MAP) estimation. Thirdly, to deal with the missing features, marginal probability is used so that samples which have missing features are compared with those having the full feature set to ensure a non-biased decision. The experimental evaluation has been conducted within a family album of few thousands of photographs and the results show that the proposed approach is effective and efficient in automated face annotation in family albums."
            },
            "slug": "Automated-annotation-of-human-faces-in-family-Zhang-Chen",
            "title": {
                "fragments": [],
                "text": "Automated annotation of human faces in family albums"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The experimental evaluation has been conducted within a family album of few thousands of photographs and the results show that the proposed approach is effective and efficient in automated face annotation in family albums."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107881808"
                        ],
                        "name": "Stella X. Yu",
                        "slug": "Stella-X.-Yu",
                        "structuredName": {
                            "firstName": "Stella",
                            "lastName": "Yu",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stella X. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14179884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14b70aafe93f52f68e51a35aaf30f36c1741604c",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider data clustering problems where partial grouping is known a priori. We formulate such biased grouping problems as a constrained optimization problem, where structural properties of the data define the goodness of a grouping and partial grouping cues define the feasibility of a grouping. We enforce grouping smoothness and fairness on labeled data points so that sparse partial grouping information can be effectively propagated to the unlabeled data. Considering the normalized cuts criterion in particular, our formulation leads to a constrained eigenvalue problem. By generalizing the Rayleigh-Ritz theorem to projected matrices, we find the global optimum in the relaxed continuous domain by eigendecomposition, from which a near-global optimum to the discrete labeling problem can be obtained effectively. We apply our method to real image segmentation problems, where partial grouping priors can often be derived based on a crude spatial attentional map that binds places with common salient features or focuses on expected object locations. We demonstrate not only that it is possible to integrate both image structures and priors in a single grouping process, but also that objects can be segregated from the background without specific object knowledge."
            },
            "slug": "Segmentation-given-partial-grouping-constraints-Yu-Shi",
            "title": {
                "fragments": [],
                "text": "Segmentation given partial grouping constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated not only that it is possible to integrate both image structures and priors in a single grouping process, but also that objects can be segregated from the background without specific object knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 773679,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "9724f7686913adf13b88951b3a2bee6579e51739",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper addresses learning-based characterization of fine art painting styles. The research has the potential to provide a powerful tool to art historians for studying connections among artists or periods in the history of art. Depending on specific applications, paintings can be categorized in different ways. We focus on comparing the painting styles of artists. To profile the style of an artist, a mixture of stochastic models is estimated using training images. The two-dimensional (2D) multiresolution hidden Markov model (MHMM) is used in the experiment. These models form an artist's distinct digital signature. For certain types of paintings, only strokes provide reliable information to distinguish artists. Chinese ink paintings are a prime example of the above phenomenon; they do not have colors or even tones. The 2D MHMM analyzes relatively large regions in an image, which in turn makes it more likely to capture properties of the painting strokes. The mixtures of 2D MHMMs established for artists can be further used to classify paintings and compare paintings or artists. We implemented and tested the system using high-resolution digital photographs of some of China's most renowned artists. Experiments have demonstrated good potential of our approach in automatic analysis of paintings. Our work can be applied to other domains."
            },
            "slug": "Studying-digital-imagery-of-ancient-paintings-by-of-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Studying digital imagery of ancient paintings by mixtures of stochastic models"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work implemented and tested a learning-based characterization of fine art painting styles using high-resolution digital photographs of some of China's most renowned artists, and demonstrated good potential in automatic analysis of paintings."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5113463"
                        ],
                        "name": "D. Joshi",
                        "slug": "D.-Joshi",
                        "structuredName": {
                            "firstName": "Dhiraj",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780080"
                        ],
                        "name": "M. Naphade",
                        "slug": "M.-Naphade",
                        "structuredName": {
                            "firstName": "Milind",
                            "lastName": "Naphade",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Naphade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820908"
                        ],
                        "name": "A. Natsev",
                        "slug": "A.-Natsev",
                        "structuredName": {
                            "firstName": "Apostol",
                            "lastName": "Natsev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Natsev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17318234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f58db85b5745828361331430b4bb7f2ff60b466",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a greedy performance driven algorithm for learning how to fuse across multiple classification and search systems. We assume a scenario when many such systems need to be fused to generate the final ranking. The algorithm is inspired from Ensemble Learning but takes that idea further for improving generalization capability. Fusion learning is applied to leverage text, visual and model based modalities for 2005 TRECVID query retrieval task. Experiments using the well established retrieval effectiveness measure of mean average precision reveal that our proposed algorithm improves over naive baseline (fusion with equal weights) as well as over Caruana's original algorithm (NACHOS) by 36% and 46% respectively."
            },
            "slug": "A-Greedy-Performance-Driven-Algorithm-for-Decision-Joshi-Naphade",
            "title": {
                "fragments": [],
                "text": "A Greedy Performance Driven Algorithm for Decision Fusion Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A greedy performance driven algorithm for learning how to fuse across multiple classification and search systems and improves over naive baseline (fusion with equal weights) as well as over Caruana's original algorithm (NACHOS) by 36% and 46% respectively."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE International Conference on Image Processing"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701516"
                        ],
                        "name": "J. R. Mathiassen",
                        "slug": "J.-R.-Mathiassen",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Mathiassen",
                            "middleNames": [
                                "Reidar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Mathiassen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3283627"
                        ],
                        "name": "A. Skavhaug",
                        "slug": "A.-Skavhaug",
                        "structuredName": {
                            "firstName": "Amund",
                            "lastName": "Skavhaug",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Skavhaug"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2337957"
                        ],
                        "name": "Ketil B\u00f8",
                        "slug": "Ketil-B\u00f8",
                        "structuredName": {
                            "firstName": "Ketil",
                            "lastName": "B\u00f8",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ketil B\u00f8"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8969346,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b6a42c12d0eab3bafe20e3ebe3ff0247502794c",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a texture similarity measure based on the Kullback-Leibler divergence between gamma distributions (KLGamma). We conjecture that the spatially smoothed Gabor filter magnitude responses of some classes of visually homogeneous stochastic textures are gamma distributed. Classification experiments with disjoint test and training images, show that the KLGamma measure performs better than other parametric measures. It approaches, and under some conditions exceeds, the classification performance of the best non-parametric measures based on binned marginal histograms, although it has a computational cost at least an order of magnitude less. Thus, the KLGamma measure is well suited for use in real-time image segmentation algorithms and time-critical texture classification and retrieval from large databases."
            },
            "slug": "Texture-Similarity-Measure-Using-Kullback-Leibler-Mathiassen-Skavhaug",
            "title": {
                "fragments": [],
                "text": "Texture Similarity Measure Using Kullback-Leibler Divergence between Gamma Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is conjecture that the spatially smoothed Gabor filter magnitude responses of some classes of visually homogeneous stochastic textures are gamma distributed, and the KLGamma measure is well suited for use in real-time image segmentation algorithms and time-critical texture classification and retrieval from large databases."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679040"
                        ],
                        "name": "Shi-Kuo Chang",
                        "slug": "Shi-Kuo-Chang",
                        "structuredName": {
                            "firstName": "Shi-Kuo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Kuo Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107472893"
                        ],
                        "name": "C. Yan",
                        "slug": "C.-Yan",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Yan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117961287"
                        ],
                        "name": "D. Dimitroff",
                        "slug": "D.-Dimitroff",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Dimitroff",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dimitroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145149326"
                        ],
                        "name": "Timothy Arndt",
                        "slug": "Timothy-Arndt",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Arndt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Arndt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206416394,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f52bfd1d98b3b2019c3cde61bcb185336d0ff351",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A prototype intelligent image database system (IIDS) that is based on a novel pictorial data structure is presented. This prototype system supports spatial reasoning, flexible image information retrieval, visualization, and traditional image database operations. A pictorial data structure, based on 2-D strings, provides an efficient means for iconic indexing in image database systems and spatial reasoning. The modular design of IIDS facilitates its implementation. Further extensions of the prototype system are discussed. >"
            },
            "slug": "An-Intelligent-Image-Database-System-Chang-Yan",
            "title": {
                "fragments": [],
                "text": "An Intelligent Image Database System"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A prototype intelligent image database system (IIDS) that is based on a novel pictorial data structure that supports spatial reasoning, flexible image information retrieval, visualization, and traditional image database operations is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Software Eng."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111010157"
                        ],
                        "name": "Richard C. Wilson",
                        "slug": "Richard-C.-Wilson",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Wilson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard C. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679753"
                        ],
                        "name": "E. Hancock",
                        "slug": "E.-Hancock",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Hancock",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hancock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5698143,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6382ab4fffd4322afb8cc5667fd54e8df3cf4c65",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a Bayesian framework for performing relational graph matching by discrete relaxation. Our basic aim is to draw on this framework to provide a comparative evaluation of a number of contrasting approaches to relational matching. Broadly speaking there are two main aspects to this study. Firstly we focus on the issue of how relational inexactness may be quantified. We illustrate that several popular relational distance measures can be recovered as specific limiting cases of the Bayesian consistency measure. The second aspect of our comparison concerns the way in which structural inexactness is controlled. We investigate three different realizations of the matching process which draw on contrasting control models. The main conclusion of our study is that the active process of graph-editing outperforms the alternatives in terms of its ability to effectively control a large population of contaminating clutter."
            },
            "slug": "Structural-Matching-by-Discrete-Relaxation-Wilson-Hancock",
            "title": {
                "fragments": [],
                "text": "Structural Matching by Discrete Relaxation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The main conclusion of the study is that the active process of graph-editing outperforms the alternatives in terms of its ability to effectively control a large population of contaminating clutter."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723669"
                        ],
                        "name": "David Huynh",
                        "slug": "David-Huynh",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Huynh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Huynh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2311676"
                        ],
                        "name": "S. Drucker",
                        "slug": "S.-Drucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Drucker",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729393"
                        ],
                        "name": "Patrick Baudisch",
                        "slug": "Patrick-Baudisch",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Baudisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Baudisch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144058864"
                        ],
                        "name": "C. Wong",
                        "slug": "C.-Wong",
                        "structuredName": {
                            "firstName": "Curtis",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14240539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "938eebbc23922f57ae6d8f96418cf1e751d05cfb",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In the absence of manual organization of large digital photo collections, the photos ' visual content and creation dates can help support time-based visual search tasks. Current zoomable photo browsers are designed to support visual searches by maximizing screenspace usage. However, their space-filling layouts fail to convey temporal order effectively. We propose a novel layout called time quilt that trades off screenss-pace usage for better presentation of temporal order. In an experimental comparison of space-filling, linear timeline, and time quilt layouts, participants carried out the task of finding photos in their personal photo collections averaging 4,000 items. They performed 45% faster on time quilt.Furthermore, while current zoomable photo browsers are designed for visual searches,this support does not scale to thousands of photos: individual thumbnails become less informative as they grow smaller. We found a subjective preference for the use of representative photos to provide an overview for visual searches in place of the diminishing thumbnails."
            },
            "slug": "Time-quilt:-scaling-up-zoomable-photo-browsers-for-Huynh-Drucker",
            "title": {
                "fragments": [],
                "text": "Time quilt: scaling up zoomable photo browsers for large, unstructured photo collections"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel layout called time quilt is proposed that trades off screenspace usage for better presentation of temporal order and is found to have a subjective preference for the use of representative photos to provide an overview for visual searches in place of the diminishing thumbnails."
            },
            "venue": {
                "fragments": [],
                "text": "CHI Extended Abstracts"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144240262"
                        ],
                        "name": "Pabitra Mitra",
                        "slug": "Pabitra-Mitra",
                        "structuredName": {
                            "firstName": "Pabitra",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pabitra Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700628"
                        ],
                        "name": "C. A. Murthy",
                        "slug": "C.-A.-Murthy",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Murthy",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. A. Murthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736103"
                        ],
                        "name": "S. Pal",
                        "slug": "S.-Pal",
                        "structuredName": {
                            "firstName": "Sankar",
                            "lastName": "Pal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 536023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0764b853fcfca05b94b95a4b625935af8544dd6e",
            "isKey": false,
            "numCitedBy": 1379,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe an unsupervised feature selection algorithm suitable for data sets, large in both dimension and size. The method is based on measuring similarity between features whereby redundancy therein is removed. This does not need any search and, therefore, is fast. A new feature similarity measure, called maximum information compression index, is introduced. The algorithm is generic in nature and has the capability of multiscale representation of data sets. The superiority of the algorithm, in terms of speed and performance, is established extensively over various real-life data sets of different sizes and dimensions. It is also demonstrated how redundancy and information loss in feature selection can be quantified with an entropy measure."
            },
            "slug": "Unsupervised-Feature-Selection-Using-Feature-Mitra-Murthy",
            "title": {
                "fragments": [],
                "text": "Unsupervised Feature Selection Using Feature Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "An unsupervised feature selection algorithm suitable for data sets, large in both dimension and size, based on measuring similarity between features whereby redundancy therein is removed, which does not need any search and is fast."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065554001"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5601682,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "29cb9c230d999a2175c31969f0d90fcae3fb4efe",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of human preattentive texture perception. This model consists of three stages: (1) convolution of the image with a bank of even-symmetric linear filters followed by half-wave rectification to give a set of responses modeling outputs of V1 simple cells, (2) inhibition, localized in space, within and among the neural-response profiles that results in the suppression of weak responses when there are strong responses at the same or nearby locations, and (3) texture-boundary detection by using wide odd-symmetric mechanisms. Our model can predict the salience of texture boundaries in any arbitrary gray-scale image. A computer implementation of this model has been tested on many of the classic stimuli from psychophysical literature. Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminability in human observers."
            },
            "slug": "Preattentive-texture-discrimination-with-early-Malik-Perona",
            "title": {
                "fragments": [],
                "text": "Preattentive texture discrimination with early vision mechanisms."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A model of human preattentive texture perception that can predict the salience of texture boundaries in any arbitrary gray-scale image and Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminateability in human observers."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3121908"
                        ],
                        "name": "Vishwa Vinay",
                        "slug": "Vishwa-Vinay",
                        "structuredName": {
                            "firstName": "Vishwa",
                            "lastName": "Vinay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishwa Vinay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398136050"
                        ],
                        "name": "Natasa Milic-Frayling",
                        "slug": "Natasa-Milic-Frayling",
                        "structuredName": {
                            "firstName": "Natasa",
                            "lastName": "Milic-Frayling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Natasa Milic-Frayling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053320673"
                        ],
                        "name": "Kenneth R. Wood",
                        "slug": "Kenneth-R.-Wood",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Wood",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth R. Wood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 723678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb41527303621818411c558c7c9be61e6ae83fa9",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Searching information resources using mobile devices is affected by displays on which only a small fraction of the set of ranked documents can be displayed. In this study we explore the effectiveness of relevance feedback methods in assisting the user to access a predefined target document through searching on a small display device. We propose an innovative approach to study this problem. For small display size and, thus, limited decision choices for relevance feedback, we generate and study the complete space of user interactions and system responses. This is done by building a tree \u2013 the documents displayed at any level depend on the choice of relevant document made at the earlier level. Construction of the tree of all possible user interactions permits an evaluation of relevance feedback algorithms with reduced reliance on user studies. From the point of view of real applications, the first few iterations are most important \u2013 we therefore limit ourselves to a maximum depth of six in the tree."
            },
            "slug": "Evaluating-Relevance-Feedback-and-Display-for-on-Vinay-Cox",
            "title": {
                "fragments": [],
                "text": "Evaluating Relevance Feedback and Display Strategies for Searching on Small Displays"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study explores the effectiveness of relevance feedback methods in assisting the user to access a predefined target document through searching through searching on a small display device using an innovative approach to study this problem."
            },
            "venue": {
                "fragments": [],
                "text": "SPIRE"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 33
                            }
                        ],
                        "text": "The correspondence-LDA [Blei and Jordan \n2003] model, proposed for joint word-image modeling, has since been applied to problems in bioinformatics \n[Zheng et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207561477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473f4b7f8ae2b03dda2593f54b316ff7d55db26b",
            "isKey": false,
            "numCitedBy": 1214,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval."
            },
            "slug": "Modeling-annotated-data-Blei-Jordan",
            "title": {
                "fragments": [],
                "text": "Modeling annotated data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Three hierarchical probabilistic mixture models which aim to describe annotated data with multiple types, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890284"
                        ],
                        "name": "F. Mokhtarian",
                        "slug": "F.-Mokhtarian",
                        "structuredName": {
                            "firstName": "Farzin",
                            "lastName": "Mokhtarian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mokhtarian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16379758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abdbc51d06170b26002c694c5a1dd67621ce5986",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A complete, fast and practical isolated object recognition system has been developed which is very robust with respect to scale, position and orientation changes of the objects as well as noise and local deformations of shape (due to perspective projection, segmentation errors and non-rigid material used in some objects). The system has been tested on a wide variety of three-dimensional objects with different shapes and material and surface properties. A light-box setup is used to obtain silhouette images which are segmented to obtain the physical boundaries of the objects which are classified as either convex or concave. Convex curves are recognized using their four high-scale curvature extrema points. Curvature scale space (CSS) representations are computed for concave curves. The CSS representation is a multi-scale organization of the natural, invariant features of a curve (curvature zero-crossings or extrema) and useful for very reliable recognition of the correct model since it places no constraints on the shape of objects. A three-stage, coarse-to-fine matching algorithm prunes the search space in stage one by applying the CSS aspect ratio test. The maxima of contours in CSS representations of the surviving models are used for fast CSS matching in stage two. Finally, stage three verifies the best match and resolves any ambiguities by determining the distance between the image and model curves. Transformation parameter optimization is then used to find the best fit of the input object to the correct model. >"
            },
            "slug": "Silhouette-Based-Isolated-Object-Recognition-Scale-Mokhtarian",
            "title": {
                "fragments": [],
                "text": "Silhouette-Based Isolated Object Recognition through Curvature Scale Space"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A complete, fast and practical isolated object recognition system has been developed which is very robust with respect to scale, position and orientation changes of the objects as well as noise and local deformations of shape (due to perspective projection, segmentation errors and non-rigid material used in some objects)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326060"
                        ],
                        "name": "F. Farrokhnia",
                        "slug": "F.-Farrokhnia",
                        "structuredName": {
                            "firstName": "Farshid",
                            "lastName": "Farrokhnia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Farrokhnia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 115
                            }
                        ],
                        "text": "The texture extraction part of this thesaurus building process involves the application of a bank of Gabor filters [Jain and Farrokhnia 1990] to the images, to encode statistics of the filtered outputs as texture features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 115
                            }
                        ],
                        "text": "The texture extraction \npart of this thesaurus building process involves the application of a bank of Gabor .lters [Jain and \nFarrokhnia 1990] to the images, to encode statistics of the .ltered outputs as texture features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21804891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e468e08612b1448c7e814e3d32c4384a06cfbe3c",
            "isKey": false,
            "numCitedBy": 2456,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A texture segmentation algorithm inspired by the multichannel filtering theory for visual information processing in the early stages of the human visual system is presented. The channels are characterized by a bank of Gabor filters that nearly uniformly covers the spatial-frequency domain. A systematic filter selection scheme based on reconstruction of the input image from the filtered images is proposed. Texture features are obtained by subjecting each (selected) filtered image to a nonlinear transformation and computing a measure of energy in a window around each pixel. An unsupervised square-error clustering algorithm is then used to integrate the feature images and produce a segmentation. A simple procedure to incorporate spatial adjacency information in the clustering process is proposed. Experiments on images with natural textures as well as artificial textures with identical second and third-order statistics are reported. The algorithm appears to perform as predicted by preattentive texture discrimination by a human.<<ETX>>"
            },
            "slug": "Unsupervised-texture-segmentation-using-Gabor-Jain-Farrokhnia",
            "title": {
                "fragments": [],
                "text": "Unsupervised texture segmentation using Gabor filters"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A texture segmentation algorithm inspired by the multichannel filtering theory for visual information processing in the early stages of the human visual system is presented and appears to perform as predicted by preattentive texture discrimination by a human."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IEEE International Conference on Systems, Man, and Cybernetics Conference Proceedings"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2759584"
                        ],
                        "name": "P. Aigrain",
                        "slug": "P.-Aigrain",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Aigrain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Aigrain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38188346"
                        ],
                        "name": "Hong-jiang Zhang",
                        "slug": "Hong-jiang-Zhang",
                        "structuredName": {
                            "firstName": "Hong-jiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong-jiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 50
                            }
                        ],
                        "text": "Comprehensive surveys \nexist on the topic of CBIR [Aigrain et al. 1996; Rui et al. 1999; Smeulders et al. 2000; Snoek and Worring \n2005], all of which deal primarily with work prior to the year 2000."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62732276,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c199e5f1dceb3b62e0df3adecc378e4e0bbe7673",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews a number of recently available techniques in content analysis of visual media and their application to the indexing, retrieval, abstracting, relevance assessment, interactive perception, annotation and re-use of visual documents."
            },
            "slug": "Content-based-representation-and-retrieval-of-A-Aigrain-Zhang",
            "title": {
                "fragments": [],
                "text": "Content-Based Representation and Retrieval of Visual Media: A State-of-the-Art Review"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper reviews a number of recently available techniques in content analysis of visual media and their application to the indexing, retrieval, abstracting, relevance assessment, interactive perception, annotation and re-use of visual documents."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679040"
                        ],
                        "name": "Shi-Kuo Chang",
                        "slug": "Shi-Kuo-Chang",
                        "structuredName": {
                            "firstName": "Shi-Kuo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Kuo Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106531491"
                        ],
                        "name": "Q. Shi",
                        "slug": "Q.-Shi",
                        "structuredName": {
                            "firstName": "Qing-Yun",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107472893"
                        ],
                        "name": "C. Yan",
                        "slug": "C.-Yan",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Yan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12115567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fdfe67d4c053198be988c5fb24926bcfebebd26",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a new way of representing a symbolic picture by a two-dimensional string. A picture query can also be specified as a 2-D string. The problem of pictorial information retrieval then becomes a problem of 2-D subsequence matching. We present algorithms for encoding a symbolic picture into its 2-D string representation, reconstructing a picture from its 2-D string representation, and matching a 2-D string with another 2-D string. We also prove the necessary and sufficient conditions to characterize ambiguous pictures for reduced 2-D strings as well as normal 2-D strings. This approach thus allows an efficient and natural way to construct iconic indexes for pictures."
            },
            "slug": "Iconic-Indexing-by-2-D-Strings-Chang-Shi",
            "title": {
                "fragments": [],
                "text": "Iconic Indexing by 2-D Strings"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This approach allows an efficient and natural way to construct iconic indexes for pictures and proves the necessary and sufficient conditions to characterize ambiguous pictures for reduced 2D strings as well as normal 2-D strings."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110288622"
                        ],
                        "name": "Ching Chen",
                        "slug": "Ching-Chen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ching Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679880"
                        ],
                        "name": "H. Wactlar",
                        "slug": "H.-Wactlar",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wactlar",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wactlar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145986040"
                        ],
                        "name": "K. Kiernan",
                        "slug": "K.-Kiernan",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Kiernan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kiernan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8200860,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "c15cb4365ddd551502a62e5a9bbdea5f3f3258aa",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital imagery for significant cultural and historical materials is an emerging research field that bridges people, culture, and technologies. In this paper, we first discuss the great importance of this field. Then we focus on its four interrelated subareas: (1) creation and preservation, (2) retrieval, (3) presentation and usability, and (4) applications and use. We propose several mechanisms to encourage collaboration and argue that the field has high potential impact on our digital society. Finally, we make specific recommendations on what to pursue in this field."
            },
            "slug": "Digital-imagery-for-significant-cultural-and-Chen-Wactlar",
            "title": {
                "fragments": [],
                "text": "Digital imagery for significant cultural and historical materials"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper discusses the great importance of this field of digital imagery for significant cultural and historical materials, and focuses on its four interrelated subareas: creation and preservation, retrieval, presentation and usability, and applications and use."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Digital Libraries"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3064190"
                        ],
                        "name": "K. Rodden",
                        "slug": "K.-Rodden",
                        "structuredName": {
                            "firstName": "Kerry",
                            "lastName": "Rodden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rodden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053320673"
                        ],
                        "name": "Kenneth R. Wood",
                        "slug": "Kenneth-R.-Wood",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Wood",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth R. Wood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3202587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9e77e4cd53762ef4212807770a699aefd50e411",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present and discuss the findings of a study that investigated how people manage their collections of digital photographs. The six-month, 13-participant study included interviews, questionnaires, and analysis of usage statistics gathered from an instrumented digital photograph management tool called Shoebox. Alongside simple browsing features such as folders, thumbnails and timelines, Shoebox has some advanced multimedia features: content-based image retrieval and speech recognition applied to voice annotations. Our results suggest that participants found their digital photos much easier to manage than their non-digital ones, but that this advantage was almost entirely due to the simple browsing features. The advanced features were not used very often and their perceived utility was low. These results should help to inform the design of improved tools for managing personal digital photographs."
            },
            "slug": "How-do-people-manage-their-digital-photographs-Rodden-Wood",
            "title": {
                "fragments": [],
                "text": "How do people manage their digital photographs?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results suggest that participants found their digital photos much easier to manage than their non-digital ones, but that this advantage was almost entirely due to the simple browsing features of Shoebox."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145248524"
                        ],
                        "name": "A. Najmi",
                        "slug": "A.-Najmi",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Najmi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Najmi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1613124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79368bfbeab606c13c29f59492b88af4e031220d",
            "isKey": false,
            "numCitedBy": 229,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "For block-based classification, an image is divided into blocks, and a feature vector is formed for each block by grouping statistics extracted from the block. Conventional block-based classification algorithms decide the class of a block by examining only the feature vector of this block and ignoring context information. In order to improve classification by context, an algorithm is proposed that models images by two dimensional (2-D) hidden Markov models (HMMs). The HMM considers feature vectors statistically dependent through an underlying state process assumed to be a Markov mesh, which has transition probabilities conditioned on the states of neighboring blocks from both horizontal and vertical directions. Thus, the dependency in two dimensions is reflected simultaneously. The HMM parameters are estimated by the EM algorithm. To classify an image, the classes with maximum a posteriori probability are searched jointly for all the blocks. Applications of the HMM algorithm to document and aerial image segmentation show that the algorithm outperforms CART/sup TM/, LVQ, and Bayes VQ."
            },
            "slug": "Image-classification-by-a-two-dimensional-hidden-Li-Najmi",
            "title": {
                "fragments": [],
                "text": "Image classification by a two-dimensional hidden Markov model"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An algorithm is proposed that models images by two dimensional (2-D) hidden Markov models (HMMs) that outperforms CART/sup TM/, LVQ, and Bayes VQ in classification by context."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766703"
                        ],
                        "name": "A. Elisseeff",
                        "slug": "A.-Elisseeff",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Elisseeff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elisseeff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 379259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8384f7ef288d2d5cb267128471c5427fc98b54b",
            "isKey": false,
            "numCitedBy": 14054,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods."
            },
            "slug": "An-Introduction-to-Variable-and-Feature-Selection-Guyon-Elisseeff",
            "title": {
                "fragments": [],
                "text": "An Introduction to Variable and Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The contributions of this special issue cover a wide range of aspects of variable selection: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12345366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68da4b0057bf09c11ba157acaed006bf4931f034",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a computational paradigm called Data Driven Markov Chain Monte Carlo (DDMCMC) for image segmentation in the Bayesian, statistical framework. The paper contributes to image segmentation in three aspects. Firstly, it designs effective and well balanced Markov Chain dynamics to explore the solution space and makes the split and merge process reversible at a middle level vision formulation. Thus it achieves globally optimal solution independent of initial segmentations. Secondly, instead of computing a single maximum a posteriori solution, it proposes a mathematical principle for computing multiple distinct solutions to incorporates intrinsic ambiguities in image segmentation. A k-adventurers algorithm is proposed for extracting distinct multiple solutions from the Markov chain sequence. Thirdly, it utilizes data-driven (bottom-up) techniques, such as clustering and edge detection, to compute importance proposal probabilities, which effectively drive the Markov chain dynamics and achieve tremendous speedup in comparison to traditional jump-diffusion method. Thus DDM-CMC paradigm provides a unifying framework where the role of existing segmentation algorithms, such as; edge detection, clustering, region growing, split-merge, SNAKEs, region competition, are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities. We report some results on color and grey level image segmentation in this paper and refer to a detailed report and a web site for extensive discussion."
            },
            "slug": "Image-segmentation-by-data-driven-Markov-chain-Tu-Zhu",
            "title": {
                "fragments": [],
                "text": "Image segmentation by data driven Markov chain Monte Carlo"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The DDM-CMC paradigm provides a unifying framework where the role of existing segmentation algorithms, such as; edge detection, clustering, region growing, split-merge, SNAKEs, region competition, are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719780"
                        ],
                        "name": "Yan Ke",
                        "slug": "Yan-Ke",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Ke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Ke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694199"
                        ],
                        "name": "R. Sukthankar",
                        "slug": "R.-Sukthankar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sukthankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sukthankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144952241"
                        ],
                        "name": "Larry Huston",
                        "slug": "Larry-Huston",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Huston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Larry Huston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5927563,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f63635bb36a1e61d6bce0d96552e72f0eec62cd8",
            "isKey": false,
            "numCitedBy": 398,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "An image forming apparatus operable in a duplex print mode includes an image carrier and an image transferring device including a first and a second intermediate image transfer body whose surfaces are movable in contact with each other while forming a nip therebetween. Toner images are respectively transferred to opposite surfaces of a sheet using two pairs of conductive rollers that face each other via the first and second intermediate image transfer bodies at a nip. Two of the conductive rollers associated with the second intermediate image transfer body are transfer rollers respectively applied with one and the other of biases of opposite polarities."
            },
            "slug": "Efficient-Near-duplicate-Detection-and-Sub-image-Ke-Sukthankar",
            "title": {
                "fragments": [],
                "text": "Efficient Near-duplicate Detection and Sub-image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An image forming apparatus operable in a duplex print mode includes an image carrier and an image transferring device including a first and a second intermediate image transfer body whose surfaces are movable in contact with each other while forming a nip therebetween."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794837"
                        ],
                        "name": "Siwei Lyu",
                        "slug": "Siwei-Lyu",
                        "structuredName": {
                            "firstName": "Siwei",
                            "lastName": "Lyu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siwei Lyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923670"
                        ],
                        "name": "D. Rockmore",
                        "slug": "D.-Rockmore",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Rockmore",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rockmore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4153758"
                        ],
                        "name": "H. Farid",
                        "slug": "H.-Farid",
                        "structuredName": {
                            "firstName": "Hany",
                            "lastName": "Farid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Farid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 578477,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "947d2678eddf93f78d072e21b7a59dbbf105bcc5",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a computational technique for authenticating works of art, specifically paintings and drawings, from high-resolution digital scans of the original works. This approach builds a statistical model of an artist from the scans of a set of authenticated works against which new works then are compared. The statistical model consists of first- and higher-order wavelet statistics. We show preliminary results from our analysis of 13 drawings that at various times have been attributed to Pieter Bruegel the Elder; these results confirm expert authentications. We also apply these techniques to the problem of determining the number of artists that may have contributed to a painting attributed to Pietro Perugino and again achieve an analysis agreeing with expert opinion."
            },
            "slug": "A-digital-technique-for-art-authentication-Lyu-Rockmore",
            "title": {
                "fragments": [],
                "text": "A digital technique for art authentication"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A computational technique for authenticating works of art, specifically paintings and drawings, from high-resolution digital scans of the original works, is described, which confirms expert authentications of Pieter Bruegel the Elder."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Natl. Acad. Sci. USA"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7838848"
                        ],
                        "name": "Weina Ge",
                        "slug": "Weina-Ge",
                        "structuredName": {
                            "firstName": "Weina",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weina Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 158
                            }
                        ],
                        "text": ", Yahoo! Flickr), where images and publicly generated tags arrive into a system asynchronously over time, has been explored using a metalearning framework in [Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 85
                            }
                        ],
                        "text": "To this end, a recent attempt at bridging the retrieval-annotation gap has been made [Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": "As explored in [Datta et al. 2007], it is possible to effectively bridge the paradigms of keyword and contentbased search through a unified framework to provide the user the flexibility of both, without losing out on the search scope."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 77
                            }
                        ],
                        "text": "quality pictures and eliminating low-quality ones from image collections, in [Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 86
                            }
                        ],
                        "text": "To this end, a recent attempt at bridging the retrieval-annotation gap has been made \n[Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": "Image classification based on a generative model for the purpose of retrieval is explored in [Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In [Datta et al. 2007], probabilistic modeling of class-wise color segment interactions has been employed for the purpose of image categorization and retrieval, to reduce sensitivity to segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 138
                            }
                        ],
                        "text": "More recently, image annotation using a novel structure-composition model, and a WordNet-based word saliency measure has been proposed in [Datta et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3749776,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14195cbca9ef3cf36d95f48adbd37844d5580288",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "By combining novel statistical modeling techniques and the WordNet ontology, we offer a promising new approach to image search that uses automatic image tagging directly to perform retrieval."
            },
            "slug": "Toward-Bridging-the-Annotation-Retrieval-Gap-in-Datta-Ge",
            "title": {
                "fragments": [],
                "text": "Toward Bridging the Annotation-Retrieval Gap in Image Search"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "By combining novel statistical modeling techniques and the WordNet ontology, this work offers a promising new approach to image search that uses automatic image tagging directly to perform retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE MultiMedia"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027413"
                        ],
                        "name": "M. Unser",
                        "slug": "M.-Unser",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Unser",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Unser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 207
                            }
                        ],
                        "text": "Texture features have been studied for long in image processing, computer vision, and computer graphics [Haralick 1979], such as multi-orientation filter banks [Malik and Perona 1990] and wavelet transforms [Unser 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 202
                            }
                        ],
                        "text": "Texture features have long been studied in image processing, computer vision, \nand computer graph\u00adics [Haralick 1979], such as multiorientation .lter banks [Malik and Perona 1990] \nand wavelet transforms [Unser 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4650963,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4f7e47e5875f9c2b322bdef47b6e66013c08994f",
            "isKey": false,
            "numCitedBy": 1531,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new approach to the characterization of texture properties at multiple scales using the wavelet transform. The analysis uses an overcomplete wavelet decomposition, which yields a description that is translation invariant. It is shown that this representation constitutes a tight frame of l(2) and that it has a fast iterative algorithm. A texture is characterized by a set of channel variances estimated at the output of the corresponding filter bank. Classification experiments with l(2) Brodatz textures indicate that the discrete wavelet frame (DWF) approach is superior to a standard (critically sampled) wavelet transform feature extraction. These results also suggest that this approach should perform better than most traditional single resolution techniques (co-occurrences, local linear transform, and the like). A detailed comparison of the classification performance of various orthogonal and biorthogonal wavelet transforms is also provided. Finally, the DWF feature extraction technique is incorporated into a simple multicomponent texture segmentation algorithm, and some illustrative examples are presented."
            },
            "slug": "Texture-classification-and-segmentation-using-Unser",
            "title": {
                "fragments": [],
                "text": "Texture classification and segmentation using wavelet frames"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400556488"
                        ],
                        "name": "Aharon Bar-Hillel",
                        "slug": "Aharon-Bar-Hillel",
                        "structuredName": {
                            "firstName": "Aharon",
                            "lastName": "Bar-Hillel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aharon Bar-Hillel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774536"
                        ],
                        "name": "T. Hertz",
                        "slug": "T.-Hertz",
                        "structuredName": {
                            "firstName": "Tomer",
                            "lastName": "Hertz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hertz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787804"
                        ],
                        "name": "N. Shental",
                        "slug": "N.-Shental",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shental",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Shental"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 129
                            }
                        ],
                        "text": "One way to achieve this is to learn a generalized Mahalanobis distance metric, such as those general-purpose methods proposed in [Xing et al. 2003; Bar-hillel et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8600094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85ca6bf1968fe41603a0c08e097220652654c04e",
            "isKey": false,
            "numCitedBy": 562,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Many learning algorithms use a metric defined over the input space as a principal tool, and their performance critically depends on the quality of this metric. We address the problem of learning metrics using side-information in the form of equivalence constraints. Unlike labels, we demonstrate that this type of side-information can sometimes be automatically obtained without the need of human intervention. We show how such side-information can be used to modify the representation of the data, leading to improved clustering and classification.Specifically, we present the Relevant Component Analysis (RCA) algorithm, which is a simple and efficient algorithm for learning a Mahalanobis metric. We show that RCA is the solution of an interesting optimization problem, founded on an information theoretic basis. If dimensionality reduction is allowed within RCA, we show that it is optimally accomplished by a version of Fisher's linear discriminant that uses constraints. Moreover, under certain Gaussian assumptions, RCA can be viewed as a Maximum Likelihood estimation of the within class covariance matrix. We conclude with extensive empirical evaluations of RCA, showing its advantage over alternative methods."
            },
            "slug": "Learning-a-Mahalanobis-Metric-from-Equivalence-Bar-Hillel-Hertz",
            "title": {
                "fragments": [],
                "text": "Learning a Mahalanobis Metric from Equivalence Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents the Relevant Component Analysis algorithm, which is a simple and efficient algorithm for learning a Mahalanobis metric, and shows that RCA is the solution of an interesting optimization problem, founded on an information theoretic basis."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117912702"
                        ],
                        "name": "YongSeog Kim",
                        "slug": "YongSeog-Kim",
                        "structuredName": {
                            "firstName": "YongSeog",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "YongSeog Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2562282"
                        ],
                        "name": "W. N. Street",
                        "slug": "W.-N.-Street",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Street",
                            "middleNames": [
                                "Nick"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. N. Street"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653472"
                        ],
                        "name": "F. Menczer",
                        "slug": "F.-Menczer",
                        "structuredName": {
                            "firstName": "Filippo",
                            "lastName": "Menczer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Menczer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 411154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "031253e71c99fcc8229bbdb55272e91f8f673ef7",
            "isKey": false,
            "numCitedBy": 321,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Feature subset selection is an important problem in knowledge discovery, not only for the insight gained from determining relevant modeling variables but also for the improved understandability, scalabilit y, and possibly , accuracy of the resulting models. In this paper w e consider the problem of feature selection for unsupervised learning. A number of heuristic criteria can be used to estimate the quality of clusters built from a giv en featuresubset. Rather than combining such criteria, we use ELSA, an evolutionary local selection algorithm that maintains a diverse population of solutions that approximate the Pareto front in a multidimensional objectiv espace. Eac hevolved solution represents a feature subset and a number of clusters; a standard K-means algorithm is applied to form the given n umber of clusters based on the selected features. Preliminary results on both real and synthetic data show promise in nding P areto-optimal solutions through which we can identify the signi cant features and the correct number of clusters."
            },
            "slug": "Feature-selection-in-unsupervised-learning-via-Kim-Street",
            "title": {
                "fragments": [],
                "text": "Feature selection in unsupervised learning via evolutionary search"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "ELSA is used, an evolutionary local selection algorithm that maintains a diverse population of solutions that approximate the Pareto front in a multidimensional objectiv espace and shows promise in identifying the right features and the correct number of clusters."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706090"
                        ],
                        "name": "R. Sablatnig",
                        "slug": "R.-Sablatnig",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sablatnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sablatnig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1454573945"
                        ],
                        "name": "P. Kammerer",
                        "slug": "P.-Kammerer",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Kammerer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kammerer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150615"
                        ],
                        "name": "Ernestine Zolda",
                        "slug": "Ernestine-Zolda",
                        "structuredName": {
                            "firstName": "Ernestine",
                            "lastName": "Zolda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernestine Zolda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17823386,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "59e85634b45a6bb7d1536b53b36e1dabbeeb12c4",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "It is often difficult to attribute works of art to a certain artist. In the case of paintings, radiological methods like X-ray and infra-red diagnosis, digital radiography, computer-tomography, etc. and color analyzes are employed to authenticate works of art. But all these methods do not relate certain characteristics of an art work to a specific artist-the artist's personal style. In order to study this personal style, we examine the \"structural signature\" based on brush strokes in particular in portrait miniatures. A computer-aided classification and recognition system for portrait miniatures is developed, which enables a semi-automatic classification based on brush strokes. A hierarchically structured classification scheme is introduced which separates the classification into three different levels of information: color, shape of region, and structure of brush strokes."
            },
            "slug": "Hierarchical-classification-of-paintings-using-face-Sablatnig-Kammerer",
            "title": {
                "fragments": [],
                "text": "Hierarchical classification of paintings using face- and brush stroke models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A computer-aided classification and recognition system for portrait miniatures is developed, which enables a semi-automatic classification based on brush strokes, and a hierarchically structured classification scheme is introduced which separates the classification into three different levels of information: color, shape of region, and structure of brush strokes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841376"
                        ],
                        "name": "N. Rowe",
                        "slug": "N.-Rowe",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Rowe",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Rowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15632601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c36be537a85b2e70d740825338dad4bf74481c4c",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Marie-4, an intelligent software agent-based Web crawler and caption filter, searches the Web to find image captions and the associated image objects. It uses a broad set of criteria to yield higher recall than competing systems, which generally focus on high precision."
            },
            "slug": "Marie-4:-A-High-Recall,-Self-Improving-Web-Crawler-Rowe",
            "title": {
                "fragments": [],
                "text": "Marie-4: A High-Recall, Self-Improving Web Crawler That Finds Images Using Captions"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Marie-4, an intelligent software agent-based Web crawler and caption filter, searches the Web to find image captions and the associated image objects and uses a broad set of criteria to yield higher recall than competing systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intell. Syst."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3121908"
                        ],
                        "name": "Vishwa Vinay",
                        "slug": "Vishwa-Vinay",
                        "structuredName": {
                            "firstName": "Vishwa",
                            "lastName": "Vinay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishwa Vinay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398136050"
                        ],
                        "name": "Natasa Milic-Frayling",
                        "slug": "Natasa-Milic-Frayling",
                        "structuredName": {
                            "firstName": "Natasa",
                            "lastName": "Milic-Frayling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Natasa Milic-Frayling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053320673"
                        ],
                        "name": "Kenneth R. Wood",
                        "slug": "Kenneth-R.-Wood",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Wood",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth R. Wood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2505167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e882a3e2f81685a5154374b39ca04e4e8bcc1697",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Searching online information resources using mobile devices is affected by displays on which only a small fraction of the set of ranked documents can be displayed. In this paper, we ask whether the search effort can be reduced, on average, by user feedback indicating a single most relevant document in each display. For small display sizes and limited user actions, we are able to construct a tree representing all possible outcomes. Examination of the tree permits us to compute an upper limit on relevance feedback performance. Three standard feedback algorithms are considered \u2013 Rocchio, Robertson/Sparck-Jones and a Bayesian algorithm. Two display strategies are considered, one based on maximizing the immediate information gain and the other on most likely documents. Our results bring out the strengths and weaknesses of the algorithms, and the need for exploratory display strategies with conservative feedback algorithms."
            },
            "slug": "Evaluating-Relevance-Feedback-Algorithms-for-on-Vinay-Cox",
            "title": {
                "fragments": [],
                "text": "Evaluating Relevance Feedback Algorithms for Searching on Small Displays"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper asks whether the search effort can be reduced, on average, by user feedback indicating a single most relevant document in each display, and construction of a tree representing all possible outcomes permits an upper limit on relevance feedback performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECIR"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789486"
                        ],
                        "name": "G. Finlayson",
                        "slug": "G.-Finlayson",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Finlayson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Finlayson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 173
                            }
                        ],
                        "text": "Innovations in color constancy, the ability to perceive the same color amidst environmental changes, were made by including specular reflection and shape into consideration [Finlayson 1996]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 179
                            }
                        ],
                        "text": "Innovations in color constancy, that is, the ability to per\u00adceive the same \ncolor amidst environmental changes, were made by taking specular re.ection and shape into consideration \n[Finlayson 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38426803,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f231b40c40dbbc8b031125a4d81abd6d6d126116",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Simple constraints on the sets of possible surface reflectance and illuminants are exploited in a new color constancy algorithm that builds upon Forsyth's (1990) theory of color constancy. Forsyth's method invokes the constraint that the surface colors under a canonical illuminant all fall within an established maximal convex gamut of possible colors. However, the method works only when restrictive conditions are imposed on the world: the illumination must be uniform, the surfaces must be planar, and there can be no specularities. To overcome these restrictions, we modify Forsyth's algorithm so that it works with the colors under a perspective projection (in a chromaticity space). The new algorithm working in perspective is simpler than Forsyth's method and more importantly the restrictions on the illuminant, surface shape and specularities can be relaxed. The algorithm is then extended to include a maximal gamut constraint on a set of illuminants that is analogous to the gamut constraint on surface colors. Tests on real images show that the algorithm provides good color constancy."
            },
            "slug": "Color-in-Perspective-Finlayson",
            "title": {
                "fragments": [],
                "text": "Color in Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new color constancy algorithm is developed that works with the colors under a perspective projection (in a chromaticity space) and is extended to include a maximal gamut constraint on a set of illuminants that is analogous to the gamut constraints on surface colors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1704741,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8b440596b28dc6683caa2b5f6fbca70963e5909e",
            "isKey": false,
            "numCitedBy": 4161,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching results; the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points."
            },
            "slug": "Scale-&-Affine-Invariant-Interest-Point-Detectors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Scale & Affine Invariant Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A comparative evaluation of different detectors is presented and it is shown that the proposed approach for detecting interest points invariant to scale and affine transformations provides better results than existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 129468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "faf8444bad76e8aa727c8b2df42fefe7b8242957",
            "isKey": false,
            "numCitedBy": 5812,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents my work on computing shape models that are computationally fast and invariant basic transformations like translation, scaling and rotation. In this paper, I propose shape detection using a feature called shape context. Shape context describes all boundary points of a shape with respect to any single boundary point. Thus it is descriptive of the shape of the object. Object recognition can be achieved by matching this feature with a priori knowledge of the shape context of the boundary points of the object. Experimental results are promising on handwritten digits, trademark images."
            },
            "slug": "Shape-matching-and-object-recognition-using-shape-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using shape contexts"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper presents work on computing shape models that are computationally fast and invariant basic transformations like translation, scaling and rotation, and proposes shape detection using a feature called shape context, which is descriptive of the shape of the object."
            },
            "venue": {
                "fragments": [],
                "text": "2010 3rd International Conference on Computer Science and Information Technology"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143808488"
                        ],
                        "name": "E. Levina",
                        "slug": "E.-Levina",
                        "structuredName": {
                            "firstName": "Elizaveta",
                            "lastName": "Levina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9682419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "554ed92c2af92d5a1456bed2ddc85fe59d5dae00",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The Earth Mover's distanc1e was first introduced as a purely empirical ways to measure texture and color similarities. We show that it has a rigorous probabilistic interpretation and is conceptually equivalent to the Mallows distance on probability distributions. The two distances are exactly the same when applied to probability distributions, but behave differently when applied to unnormalized distributions with different masses, called signatures. We discuss the advantages and disadvantages of both distances, and statistical issues involved in computing them from data. We also report some texture classification results for the Mallows distance applied to texture features and compare several ways of estimating feature distributions. In addition, we list some known probabilistic properties of this distance."
            },
            "slug": "The-Earth-Mover's-distance-is-the-Mallows-distance:-Levina-Bickel",
            "title": {
                "fragments": [],
                "text": "The Earth Mover's distance is the Mallows distance: some insights from statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The Earth Mover's distanc1e has a rigorous probabilistic interpretation and is conceptually equivalent to the Mallows distance on probability distributions, but behave differently when applied to unnormalized distributions with different masses, called signatures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444394"
                        ],
                        "name": "E. Ziegel",
                        "slug": "E.-Ziegel",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Ziegel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ziegel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 87
                            }
                        ],
                        "text": "An effective way to obtain a density estimation is by fitting a Gaussian mixture model [Hastie et al. 2001], and the Kullback-Leibler distance is often used to measure the disparity between distributions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 183
                            }
                        ],
                        "text": "Clustering (minimal) Meaningful result visualization, faster retrieval, efficient storage Side-information, kernel mapping, kmeans, hierarchical, metric learning [Chen and Wang 2004] [Hastie et al. 2001] [Sebe et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 12
                            }
                        ],
                        "text": "We refer to [Hastie et al. 2001] for basic principles and a more comprehensive review."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 204
                            }
                        ],
                        "text": "Relevance Feedback (significant, interactive) Capture user and query specific semantics, refine rank accordingly Feature re-weighting, region weighting, active learning, memory/mental retrieval, boosting [Hastie et al. 2001] [Rui et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 144
                            }
                        ],
                        "text": "\u2026visualization, faster retrieval, ef.cient storage Side-information, \nkernel mapping, k-means, hierarchical, metric learning [Chen and Wang 2004] [Hastie et al. 2001] [Sebe \net al. 2000] [Wu et al. 2005] Same low-level features, poor user adaptability Classi.cation Pre-processing, \nfast/ SVM,\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 150
                            }
                        ],
                        "text": "\u2026retrieval, models, Bayesian \nbias, many classes training data, not automatic classi.ers, k-NN, trees unseen interactive) organization \n[Zhang et al. 2002] [Hastie et al. 2001] [Panda and Chang 2006] Relevance Feedback (signi.cant, interactive) \nCapture user and query speci.c semantics, re.ne rank\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 6
                            }
                        ],
                        "text": "2002] [Hastie et al. 2001] [Panda and Chang 2006] Training introduces bias, many classes unseen"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 233
                            }
                        ],
                        "text": "\u2026et al. 2001] [Panda and Chang 2006] Relevance Feedback (signi.cant, interactive) \nCapture user and query speci.c semantics, re.ne rank accordingly Feature re-weighting, region weighting, \nactive learning, memory/ mental retrieval, boosting [Hastie et al. 2001] [Rui et al. 1998] [Jaimes et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 87
                            }
                        ],
                        "text": "An effective way to obtain a density estimation \nis by .tting a Gaussian mixture model [Hastie et al. 2001], and the Kullback-Leibler distance is often \nused to measure the disparity between distributions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46701966,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "e41ba5dc12c79a64dfa905c0328f95976252ffe0",
            "isKey": true,
            "numCitedBy": 12391,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapter 11 includes more case studies in other areas, ranging from manufacturing to marketing research. Chapter 12 concludes the book with some commentary about the scienti\u008e c contributions of MTS. The Taguchi method for design of experiment has generated considerable controversy in the statistical community over the past few decades. The MTS/MTGS method seems to lead another source of discussions on the methodology it advocates (Montgomery 2003). As pointed out by Woodall et al. (2003), the MTS/MTGS methods are considered ad hoc in the sense that they have not been developed using any underlying statistical theory. Because the \u201cnormal\u201d and \u201cabnormal\u201d groups form the basis of the theory, some sampling restrictions are fundamental to the applications. First, it is essential that the \u201cnormal\u201d sample be uniform, unbiased, and/or complete so that a reliable measurement scale is obtained. Second, the selection of \u201cabnormal\u201d samples is crucial to the success of dimensionality reduction when OAs are used. For example, if each abnormal item is really unique in the medical example, then it is unclear how the statistical distance MD can be guaranteed to give a consistent diagnosis measure of severity on a continuous scale when the larger-the-better type S/N ratio is used. Multivariate diagnosis is not new to Technometrics readers and is now becoming increasingly more popular in statistical analysis and data mining for knowledge discovery. As a promising alternative that assumes no underlying data model, The Mahalanobis\u2013Taguchi Strategy does not provide suf\u008e cient evidence of gains achieved by using the proposed method over existing tools. Readers may be very interested in a detailed comparison with other diagnostic tools, such as logistic regression and tree-based methods. Overall, although the idea of MTS/MTGS is intriguing, this book would be more valuable had it been written in a rigorous fashion as a technical reference. There is some lack of precision even in several mathematical notations. Perhaps a follow-up with additional theoretical justi\u008e cation and careful case studies would answer some of the lingering questions."
            },
            "slug": "The-Elements-of-Statistical-Learning-Ziegel",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Chapter 11 includes more case studies in other areas, ranging from manufacturing to marketing research, and a detailed comparison with other diagnostic tools, such as logistic regression and tree-based methods."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5113463"
                        ],
                        "name": "D. Joshi",
                        "slug": "D.-Joshi",
                        "structuredName": {
                            "firstName": "Dhiraj",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40490812"
                        ],
                        "name": "R. Datta",
                        "slug": "R.-Datta",
                        "structuredName": {
                            "firstName": "Ritendra",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3017391"
                        ],
                        "name": "Ziming Zhuang",
                        "slug": "Ziming-Zhuang",
                        "structuredName": {
                            "firstName": "Ziming",
                            "lastName": "Zhuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziming Zhuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053358344"
                        ],
                        "name": "W. Weiss",
                        "slug": "W.-Weiss",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Weiss",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48485312"
                        ],
                        "name": "M. Friedenberg",
                        "slug": "M.-Friedenberg",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Friedenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Friedenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 735304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f823d78c36cea14391c931a94233455af4880a2a",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate PARAgrab - a scalable Web image archival, retrieval, and annotation system that supports multiple querying modalities. The underlying architecture of our large-scale Web image database is described. Querying and visualization techniques used in the system are explained."
            },
            "slug": "PARAgrab:-a-comprehensive-architecture-for-web-and-Joshi-Datta",
            "title": {
                "fragments": [],
                "text": "PARAgrab: a comprehensive architecture for web image management and multimodal querying"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "PARAgrab is demonstrated - a scalable Web image archival, retrieval, and annotation system that supports multiple querying modalities and the underlying architecture of the large-scale Web image database is described."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40603954"
                        ],
                        "name": "Kingshy Goh",
                        "slug": "Kingshy-Goh",
                        "structuredName": {
                            "firstName": "Kingshy",
                            "lastName": "Goh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kingshy Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766349"
                        ],
                        "name": "K. Cheng",
                        "slug": "K.-Cheng",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 70
                            }
                        ],
                        "text": "Supervised classification based on SVMs has been applied to images in [Goh et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8193876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48f88bd29bb83a7bc45c29638c4d1e887ab0dd1a",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We study how the SVM-based binary classifiers can be effectively combined to tackle the multi-class image classification problem. We study several ensemble schemes, including OPC (one per class), PWC (pairwise coupling), and ECOC (error-correction output coding), that aim to achieve good error correction capability through redundancy. To enhance these ensemble schemes' accuracy, we propose methods that on the one hand boost the margins (i.e., confidence) of the SVM-based binary classifiers, and, on the other hand, remove the noise of irrelevant classifiers from class prediction. From empirical study we show that our margin boosting and noise reduction methods lead to higher classification accuracy than ensemble schemes that are solely designed for maximum error correction capability."
            },
            "slug": "SVM-binary-classifier-ensembles-for-image-Goh-Chang",
            "title": {
                "fragments": [],
                "text": "SVM binary classifier ensembles for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "From empirical study, it is shown that margin boosting and noise reduction methods lead to higher classification accuracy than ensemble schemes that are solely designed for maximum error correction capability."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144715575"
                        ],
                        "name": "B. Jansen",
                        "slug": "B.-Jansen",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Jansen",
                            "middleNames": [
                                "Jim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144275474"
                        ],
                        "name": "A. Spink",
                        "slug": "A.-Spink",
                        "structuredName": {
                            "firstName": "Amanda",
                            "lastName": "Spink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Spink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 206
                            }
                        ],
                        "text": "This makes the creation of Web\u00adbased CBIR systems more challenging than the core questions of CBIR, aggravated \nfurther by the fact that multimedia searching is typically more complex than generic searching [Jansen \net al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 206
                            }
                        ],
                        "text": "This makes the creation of Web-based CBIR systems more challenging than the core questions of CBIR, aggravated further by the fact that multimedia searching is typically more complex than generic searching [Jansen et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6459462,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "8c760486f829b0e42a01ae16edaf062b09d61bdb",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Web searching is a significant activity for many people seeking multimedia information. Major Web search engines, such as Alta Vista, are essential tools in the quest to locate relevant online information. As such, it is important that we understand how searchers utilize these Web information systems. This paper presents research that examines characteristics of multimedia Web searching on Alta Vista. More specifically, the research questions driving this study are: (1) What are the characteristics of multimedia searching on Alta Vista? and (2) How does this multimedia searching compare to Web searching in general? The results of our research show that multimedia searching is complex relative to general Web searching and that searching specific multimedia collections does not necessarily reduce the searching complexity. We discuss the implications of the findings for the development of online multimedia retrieval systems."
            },
            "slug": "An-analysis-of-multimedia-searching-on-AltaVista-Jansen-Spink",
            "title": {
                "fragments": [],
                "text": "An analysis of multimedia searching on AltaVista"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results of the research show that multimedia searching is complex relative to general Web searching and that searching specific multimedia collections does not necessarily reduce the searching complexity."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14045640"
                        ],
                        "name": "E. Woodrow",
                        "slug": "E.-Woodrow",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Woodrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Woodrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683916"
                        ],
                        "name": "W. Heinzelman",
                        "slug": "W.-Heinzelman",
                        "structuredName": {
                            "firstName": "Wendi",
                            "lastName": "Heinzelman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Heinzelman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2202249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6b0995fd22d5af440c177ed8920e8c175355652",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose and analyze a routing protocol for mobile ad hoc networks that supports efficient image retrieval based on metadata queries. In digital photography, metadata describes captured information about an image and provides the key element needed for advanced techniques for sharing pictures. Our goal was to find an efficient way to utilize metadata to retrieve images in a wireless network of imaging devices. Building on the SPIN (sensor protocols for information via negotiation) protocol for metadata negotiation, we designed SPIN-IT (SPIN-image transfer), a protocol where wireless imaging devices use metadata queries to retrieve desired pictures. This protocol provides low bandwidth query-based communication prior to the transfer of image data to set up routes to desired data rather than routes to specific nodes. We compare SPIN-IT to a centralized approach and discuss the advantages of each design for different picture-sharing scenarios."
            },
            "slug": "SPIN-IT:-a-data-centric-routing-protocol-for-image-Woodrow-Heinzelman",
            "title": {
                "fragments": [],
                "text": "SPIN-IT: a data centric routing protocol for image retrieval in wireless networks"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A routing protocol for mobile ad hoc networks that supports efficient image retrieval based on metadata queries and compares SPIN-IT to a centralized approach and discusses the advantages of each design for different picture-sharing scenarios."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11357447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fc5f96b85654154a4d78944e9a2ee26e5aba789",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper treats a multiresolution hidden Markov model for classifying images. Each image is represented by feature vectors at several resolutions, which are statistically dependent as modeled by the underlying state process, a multiscale Markov mesh. Unknowns in the model are estimated by maximum likelihood, in particular by employing the expectation-maximization algorithm. An image is classified by finding the optimal set of states with maximum a posteriori probability. States are then mapped into classes. The multiresolution model enables multiscale information about context to be incorporated into classification. Suboptimal algorithms based on the model provide progressive classification that is much faster than the algorithm based on single-resolution hidden Markov models."
            },
            "slug": "Multiresolution-image-classification-by-modeling-Li-Gray",
            "title": {
                "fragments": [],
                "text": "Multiresolution image classification by hierarchical modeling with two-dimensional hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Suboptimal algorithms based on the model provide progressive classification that is much faster than the algorithm based on single-resolution hidden Markov models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112670560"
                        ],
                        "name": "Bin Zheng",
                        "slug": "Bin-Zheng",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39335197"
                        ],
                        "name": "David C. McLean",
                        "slug": "David-C.-McLean",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McLean",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. McLean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244761"
                        ],
                        "name": "Xinghua Lu",
                        "slug": "Xinghua-Lu",
                        "structuredName": {
                            "firstName": "Xinghua",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinghua Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 13261300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4b2704e516921c81975926845d8713004f8f756",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "BackgroundBiomedical literature, e.g., MEDLINE, contains a wealth of knowledge regarding functions of proteins. Major recurring biological concepts within such text corpora represent the domains of this body of knowledge. The goal of this research is to identify the major biological topics/concepts from a corpus of protein-related MEDLINE\u00a9 titles and abstracts by applying a probabilistic topic model.ResultsThe latent Dirichlet allocation (LDA) model was applied to the corpus. Based on the Bayesian model selection, 300 major topics were extracted from the corpus. The majority of identified topics/concepts was found to be semantically coherent and most represented biological objects or concepts. The identified topics/concepts were further mapped to the controlled vocabulary of the Gene Ontology (GO) terms based on mutual information.ConclusionThe major and recurring biological concepts within a collection of MEDLINE documents can be extracted by the LDA model. The identified topics/concepts provide parsimonious and semantically-enriched representation of the texts in a semantic space with reduced dimensionality and can be used to index text."
            },
            "slug": "Identifying-biological-concepts-from-a-corpus-with-Zheng-McLean",
            "title": {
                "fragments": [],
                "text": "Identifying biological concepts from a protein-related corpus with a probabilistic topic model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The major and recurring biological concepts within a collection of protein-related MEDLINE documents can be extracted by the LDA model and provide parsimonious and semantically-enriched representation of the texts in a semantic space with reduced dimensionality and can be used to index text."
            },
            "venue": {
                "fragments": [],
                "text": "BMC Bioinformatics"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34792252"
                        ],
                        "name": "J. Amores",
                        "slug": "J.-Amores",
                        "structuredName": {
                            "firstName": "Jaume",
                            "lastName": "Amores",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Amores"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143601910"
                        ],
                        "name": "P. Radeva",
                        "slug": "P.-Radeva",
                        "structuredName": {
                            "firstName": "Petia",
                            "lastName": "Radeva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Radeva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2692966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4fd4cf8d30ea20d44c5295d67a3cebfc45b3879",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Boosting-the-distance-estimation:-Application-to-Amores-Sebe",
            "title": {
                "fragments": [],
                "text": "Boosting the distance estimation: Application to the K-Nearest Neighbor Classifier"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32987416"
                        ],
                        "name": "Monica Chew",
                        "slug": "Monica-Chew",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Chew",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Monica Chew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787610"
                        ],
                        "name": "J. Tygar",
                        "slug": "J.-Tygar",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Tygar",
                            "middleNames": [
                                "Doug"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tygar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 60
                            }
                        ],
                        "text": "The first formalization of image based CAPTCHAs is found in [Chew and Tygar 2004], where pictures chosen at random are displayed and questions asked, e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16097875,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "7a2a256d406dd827df4e244c24beb0baf1938304",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "CAPTCHAs are tests that distinguish humans from software robots in an online environment [3,14,7]. We propose and implement three CAPTCHAs based on naming images, distinguishing images, and identifying an anomalous image out of a set. Novel contributions include proposals for two new CAPTCHAs, the first user study on image recognition CAPTCHAs, and a new metric for evaluating CAPTCHAs."
            },
            "slug": "Image-Recognition-CAPTCHAs-Chew-Tygar",
            "title": {
                "fragments": [],
                "text": "Image Recognition CAPTCHAs"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work proposes and implements three CAPTCHAs based on naming images, distinguishing images, and identifying an anomalous image out of a set that distinguish humans from software robots in an online environment."
            },
            "venue": {
                "fragments": [],
                "text": "ISC"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690163"
                        ],
                        "name": "G. McLachlan",
                        "slug": "G.-McLachlan",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "McLachlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McLachlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091184399"
                        ],
                        "name": "D. Peel",
                        "slug": "D.-Peel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Peel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Peel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 124985575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe4b07489942fc80654e9a87663aee3aa5119429",
            "isKey": false,
            "numCitedBy": 7960,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The important role of finite mixture models in the statistical analysis of data is underscored by the ever-increasing rate at which articles on mixture applications appear in the statistical and general scientific literature. The aim of this article is to provide an up-to-date account of the theory and methodological developments underlying the applications of finite mixture models. Because of their flexibility, mixture models are being increasingly exploited as a convenient, semiparametric way in which to model unknown distributional shapes. This is in addition to their obvious applications where there is group-structure in the data or where the aim is to explore the data for such structure, as in a cluster analysis. It has now been three decades since the publication of the monograph by McLachlan & Basford (1988) with an emphasis on the potential usefulness of mixture models for inference and clustering. Since then, mixture models have attracted the interest of many researchers and have found many new and interesting fields of application. Thus, the literature on mixture models has expanded enormously, and as a consequence, the bibliography here can only provide selected coverage."
            },
            "slug": "Finite-Mixture-Models-McLachlan-Peel",
            "title": {
                "fragments": [],
                "text": "Finite Mixture Models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The aim of this article is to provide an up-to-date account of the theory and methodological developments underlying the applications of finite mixture models."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley Series in Probability and Statistics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805004"
                        ],
                        "name": "T. Shanableh",
                        "slug": "T.-Shanableh",
                        "structuredName": {
                            "firstName": "Tamer",
                            "lastName": "Shanableh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shanableh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145073424"
                        ],
                        "name": "M. Ghanbari",
                        "slug": "M.-Ghanbari",
                        "structuredName": {
                            "firstName": "Mohammed",
                            "lastName": "Ghanbari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ghanbari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 715857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "292889c24c0fa339af5927bb4845b25b89a5e57a",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, transcoding of pre-encoded MPEG-1, 2 video into lower bit rates is realized through altering the coding algorithm into H.261/H.263 standards with lower spatio-temporal resolutions. For this heterogeneous transcoding, we extract and compose a set of candidate motion vectors, from the incoming bit stream, to comply with the encoding format of the output bit stream. For the spatial resolution reduction we generate one motion vector out of a set of input motion vectors operating on the higher spatial resolution image. Finally, for the temporal resolution reduction we compose new motion vectors from the dropped frames motion vectors. Throughout the paper, we discuss the impact of motion estimation refinement on the new motion vectors and show that for all cases a simple half-pixel refinement is sufficient for near-optimum results."
            },
            "slug": "Heterogeneous-Video-Transcoding-to-Lower-and-Shanableh-Ghanbari",
            "title": {
                "fragments": [],
                "text": "Heterogeneous Video Transcoding to Lower Spatio-Temporal Resolutions and Different Encoding Formats"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work transcoding of pre-encoded MPEG-1, 2 video into lower bit rates is realized through altering the coding algorithm into H.261/H.263 standards with lower spatio-temporal resolutions through heterogeneous transcoding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multim."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108002908"
                        ],
                        "name": "Yongyue Zhang",
                        "slug": "Yongyue-Zhang",
                        "structuredName": {
                            "firstName": "Yongyue",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongyue Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144431498"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2162210436"
                        ],
                        "name": "Stephen M. Smith",
                        "slug": "Stephen-M.-Smith",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smith",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 143
                            }
                        ],
                        "text": "\u2026\n3D brain magnetic res\u00adonance (MR) images have been segmented using hidden Markov random .elds and the \nexpectation-maximization (EM) algorithm [Zhang et al. 2001], and the spectral clus\u00adtering approach has \nfound some success in segmenting vertebral bodies from sagittal MR images\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 158
                            }
                        ],
                        "text": "In this domain, 3D brain magnetic resonance (MR) images have been segmented using Hidden Markov Random Fields and the Expectation-Maximization (EM) algorithm [Zhang et al. 2001], and the spectral clustering approach has found some success in segmenting vertebral bodies from sagittal MR images [Carballido-Gamio et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16281709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d5aedecdfc4e8f83638bac47eb7cf2f860ec51c",
            "isKey": false,
            "numCitedBy": 5752,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The finite mixture (FM) model is the most commonly used model for statistical segmentation of brain magnetic resonance (MR) images because of its simple mathematical form and the piecewise constant nature of ideal brain MR images. However, being a histogram-based model, the FM has an intrinsic limitation-no spatial information is taken into account. This causes the FM model to work only on well-defined images with low levels of noise; unfortunately, this is often not the the case due to artifacts such as partial volume effect and bias field distortion. Under these conditions, FM model-based methods produce unreliable results. Here, the authors propose a novel hidden Markov random field (HMRF) model, which is a stochastic process generated by a MRF whose state sequence cannot be observed directly but which can be indirectly estimated through observations. Mathematically, it can be shown that the FM model is a degenerate version of the HMRF model. The advantage of the HMRF model derives from the way in which the spatial information is encoded through the mutual influences of neighboring sites. Although MRF modeling has been employed in MR image segmentation by other researchers, most reported methods are limited to using MRF as a general prior in an FM model-based approach. To fit the HMRF model, an EM algorithm is used. The authors show that by incorporating both the HMRF model and the EM algorithm into a HMRF-EM framework, an accurate and robust segmentation can be achieved. More importantly, the HMRF-EM framework can easily be combined with other techniques. As an example, the authors show how the bias field correction algorithm of Guillemaud and Brady (1997) can be incorporated into this framework to achieve a three-dimensional fully automated approach for brain MR image segmentation."
            },
            "slug": "Segmentation-of-brain-MR-images-through-a-hidden-Zhang-Brady",
            "title": {
                "fragments": [],
                "text": "Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors propose a novel hidden Markov random field (HMRF) model, which is a stochastic process generated by a MRF whose state sequence cannot be observed directly but which can be indirectly estimated through observations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Medical Imaging"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2598854"
                        ],
                        "name": "I. Rigoutsos",
                        "slug": "I.-Rigoutsos",
                        "structuredName": {
                            "firstName": "Isidore",
                            "lastName": "Rigoutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Rigoutsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 20
                            }
                        ],
                        "text": ", geometric hashing [Wolfson and Rigoutsos 1997]), matching at the semantic level (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11915313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3efe88739c2604d7fede2cf1da977670dd7968e6",
            "isKey": false,
            "numCitedBy": 625,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric hashing, a technique originally developed in computer vision for matching geometric features against a database of such features, finds use in a number of other areas. Matching is possible even when the recognizable database objects have undergone transformations or when only partial information is present. The technique is highly efficient and of low polynomial complexity."
            },
            "slug": "Geometric-hashing:-an-overview-Wolfson-Rigoutsos",
            "title": {
                "fragments": [],
                "text": "Geometric hashing: an overview"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Geometric hashing, a technique originally developed in computer vision for matching geometric features against a database of such features, finds use in a number of other areas."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 105
                            }
                        ],
                        "text": "Given an annotated image database, pair-wise \nreinforcement is based on both visual similarity as well as Wordnet-based lexical similarity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 53
                            }
                        ],
                        "text": "Image annotations by combining multiple evidence and Wordnet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 95
                            }
                        ],
                        "text": "This assumption is coherent with the hierarchical model for nouns and verbs adopted by Wordnet [Miller 1995]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 131
                            }
                        ],
                        "text": "This translation model is extended [Jin et al. 2005] to eliminate uncorrelated \nwords from among those generated, making use of the Wordnet ontology."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 101
                            }
                        ],
                        "text": "If metadata associated with images \ncan be arranged in tree order (e.g., WordNet topical hierarchies [Miller 1995]), it can be a very useful \naid in visualization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Wordnet: A lexical database for English."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 92
                            }
                        ],
                        "text": "This assumption coheres with the hierarchical model for nouns and verbs \nadopted by Wordnet [Miller 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 30
                            }
                        ],
                        "text": ", WordNet topical hierarchies [Miller 1995]), it can be a very useful aid in visualization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1671874,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "68c03788224000794d5491ab459be0b2a2c38677",
            "isKey": true,
            "numCitedBy": 13888,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4]."
            },
            "slug": "WordNet:-A-Lexical-Database-for-English-Miller",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Database for English"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "WordNet1 provides a more effective combination of traditional lexicographic information and modern computing, and is an online lexical database designed for use under program control."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398855842"
                        ],
                        "name": "J. Carballido-Gamio",
                        "slug": "J.-Carballido-Gamio",
                        "structuredName": {
                            "firstName": "Julio",
                            "lastName": "Carballido-Gamio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carballido-Gamio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145346586"
                        ],
                        "name": "S. Majumdar",
                        "slug": "S.-Majumdar",
                        "structuredName": {
                            "firstName": "Sharmila",
                            "lastName": "Majumdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Majumdar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10413260,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "34274f65f20d26b8c2dee8c0c8885505ad31f80d",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of medical images has become an indispensable process to perform quantitative analysis of images of human organs and their functions. Normalized Cuts (NCut) is a spectral graph theoretic method that readily admits combinations of different features for image segmentation. The computational demand imposed by NCut has been successfully alleviated with the Nystro/spl uml/m approximation method for applications different than medical imaging. In this paper we discuss the application of NCut with the Nystro/spl uml/m approximation method to segment vertebral bodies from sagittal T1-weighted magnetic resonance images of the spine. The magnetic resonance images were preprocessed by the anisotropic diffusion algorithm, and three-dimensional local histograms of brightness was chosen as the segmentation feature. Results of the segmentation as well as limitations and challenges in this area are presented."
            },
            "slug": "Normalized-cuts-in-3-D-for-spinal-MRI-segmentation-Carballido-Gamio-Belongie",
            "title": {
                "fragments": [],
                "text": "Normalized cuts in 3-D for spinal MRI segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The application of NCut with the Nystro/spl uml/m approximation method to segment vertebral bodies from sagittal T1-weighted magnetic resonance images of the spine is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Medical Imaging"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5295725,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology",
                "Environmental Science"
            ],
            "id": "1af4aa8826fdee95a22fedbfc2f88b657af0ce08",
            "isKey": false,
            "numCitedBy": 1223,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Visual Information Retrieval 2. Image Retrieval by Color Similarity 3. Image Retrieval by Texture Similarity 4. Image Retrieval by Shape Similarity 5. Image Retrieval by Spatial Relationships 6. Content-Based Video Retrieval"
            },
            "slug": "Visual-information-retrieval-Bimbo",
            "title": {
                "fragments": [],
                "text": "Visual information retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323921"
                        ],
                        "name": "T. Painter",
                        "slug": "T.-Painter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Painter",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Painter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144957194"
                        ],
                        "name": "J. Dozier",
                        "slug": "J.-Dozier",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Dozier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dozier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "96235759"
                        ],
                        "name": "D. Roberts",
                        "slug": "D.-Roberts",
                        "structuredName": {
                            "firstName": "Dar",
                            "lastName": "Roberts",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roberts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88018493"
                        ],
                        "name": "R. Davis",
                        "slug": "R.-Davis",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Davis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803761"
                        ],
                        "name": "R. Green",
                        "slug": "R.-Green",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Green",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Green"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14833935,
            "fieldsOfStudy": [
                "Environmental Science",
                "Mathematics"
            ],
            "id": "35eb12400cacc74956f600974ab02b6461ed8436",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Retrieval-of-subpixel-snow-covered-area-and-grain-Painter-Dozier",
            "title": {
                "fragments": [],
                "text": "Retrieval of subpixel snow-covered area and grain size from imaging spectrometer data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39453972"
                        ],
                        "name": "Vin de Silva",
                        "slug": "Vin-de-Silva",
                        "structuredName": {
                            "firstName": "Vin",
                            "lastName": "Silva",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vin de Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 195
                            }
                        ],
                        "text": "Typical methods for learning underlying manifolds, which essentially \namounts to nonlinear dimension re\u00adduction, are locally-linear embedding (LLE), isomapping, and multidimensional \nscaling (MDS) [de Silva and Tenenbaum 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2049761,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "df83034e88557e1e2c7f9d268d90b19762312847",
            "isKey": false,
            "numCitedBy": 890,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently proposed algorithms for nonlinear dimensionality reduction fall broadly into two categories which have different advantages and disadvantages: global (Isomap [1]), and local (Locally Linear Embedding [2], Laplacian Eigenmaps [3]). We present two variants of Isomap which combine the advantages of the global approach with what have previously been exclusive advantages of local methods: computational sparsity and the ability to invert conformal maps."
            },
            "slug": "Global-Versus-Local-Methods-in-Nonlinear-Reduction-Silva-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Global Versus Local Methods in Nonlinear Dimensionality Reduction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents two variants of Isomap which combine the advantages of the global approach with what have previously been exclusive advantages of local methods: computational sparsity and the ability to invert conformal maps."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507859"
                        ],
                        "name": "S. Berretti",
                        "slug": "S.-Berretti",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Berretti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Berretti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17487230,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "eaa9e86781784fd6c176bb23152353646fdf067e",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose an original modeling technique which enables quantitative non-symbolic representation and comparison of the mutual spatial positioning of extended entities in a 3D space. The representation accounts for the overall distribution of relationships among the individual points of two objects. Properties of the model are expounded to develop an efficient computation technique and to motivate and assess a metric of similarity for quantitative comparison of spatial relationships between object pairs. Experiments compare the proposed approach against two different solutions"
            },
            "slug": "Modeling-Spatial-Relationships-between-3D-Objects-Berretti-Bimbo",
            "title": {
                "fragments": [],
                "text": "Modeling Spatial Relationships between 3D Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An original modeling technique is proposed which enables quantitative non-symbolic representation and comparison of the mutual spatial positioning of extended entities in a 3D space and to motivate and assess a metric of similarity for quantitative comparison of spatial relationships between object pairs."
            },
            "venue": {
                "fragments": [],
                "text": "18th International Conference on Pattern Recognition (ICPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153292035"
                        ],
                        "name": "Sayan Mukherjee",
                        "slug": "Sayan-Mukherjee",
                        "structuredName": {
                            "firstName": "Sayan",
                            "lastName": "Mukherjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sayan Mukherjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2860274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46ba0c8afc9339221076f2b2e497e2a6d9ce6248",
            "isKey": false,
            "numCitedBy": 1131,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method of feature selection for Support Vector Machines. The method is based upon finding those features which minimize bounds on the leave-one-out error. This search can be efficiently performed via gradient descent. The resulting algorithms are shown to be superior to some standard feature selection algorithms on both toy data and real-life problems of face recognition, pedestrian detection and analyzing DNA microarray data."
            },
            "slug": "Feature-Selection-for-SVMs-Weston-Mukherjee",
            "title": {
                "fragments": [],
                "text": "Feature Selection for SVMs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The resulting algorithms are shown to be superior to some standard feature selection algorithms on both toy data and real-life problems of face recognition, pedestrian detection and analyzing DNA microarray data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144633617"
                        ],
                        "name": "A. Jaimes",
                        "slug": "A.-Jaimes",
                        "structuredName": {
                            "firstName": "Alejandro",
                            "lastName": "Jaimes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jaimes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4412002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38c6b1319eabba8b519930559907aae9c1e6e37e",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Human-Centered Computing (HCC) is a set of methodologies that apply to any field that uses computers, in any form, in applications in which humans directly interact with devices or systems that use computer technologies. In this paper, we give an overview of HCC from a Multimedia perspective. We describe what we consider to be the three main areas of Human-Centered Multimedia (HCM): media production, analysis, and interaction. In addition, we identify the core characteristics of HCM, describe example applications, and propose a research agenda for HCM."
            },
            "slug": "Human-centered-computing:-a-multimedia-perspective-Jaimes-Sebe",
            "title": {
                "fragments": [],
                "text": "Human-centered computing: a multimedia perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes what it considers to be the three main areas of Human-Centered Multimedia (HCM): media production, analysis, and interaction."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409513867"
                        ],
                        "name": "M.",
                        "slug": "M.",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "M.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1990278,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f7625798c6e08daa9a603551c71bab68f9abe5dd",
            "isKey": false,
            "numCitedBy": 3670,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "A b m t-I n this survey we review the impge processing literature on the various approaches and models investigators have uaed for texture."
            },
            "slug": "Statistical-and-Structural-Approaches-to-Texture-M.",
            "title": {
                "fragments": [],
                "text": "Statistical and Structural Approaches to Texture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1519978914"
                        ],
                        "name": "E. Bertini",
                        "slug": "E.-Bertini",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bertini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bertini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35161586"
                        ],
                        "name": "A. Cal\u00ec",
                        "slug": "A.-Cal\u00ec",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Cal\u00ec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cal\u00ec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772402"
                        ],
                        "name": "T. Catarci",
                        "slug": "T.-Catarci",
                        "structuredName": {
                            "firstName": "Tiziana",
                            "lastName": "Catarci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Catarci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717514"
                        ],
                        "name": "S. Gabrielli",
                        "slug": "S.-Gabrielli",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Gabrielli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gabrielli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761260"
                        ],
                        "name": "S. Kimani",
                        "slug": "S.-Kimani",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Kimani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kimani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 119
                            }
                        ],
                        "text": "Personalization of search for small displays by modeling interaction from the gathered usage data has been proposed in [Bertini et al. 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37573525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a17cad83b43de6bec5c1dda9e0e92e930d8d8b5",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores an original approach to overcome current issues in the use of mobile devices, such as limited screen space and interaction modalities, based on exploiting interface adaptation and adaptive techniques. Specifically, the paper describes the application of this approach to a web searching prototype, which collects usage data to model interaction and provide a personalized version of the web facility visited by the user."
            },
            "slug": "Interaction-Based-Adaptation-for-Small-Screen-Bertini-Cal\u00ec",
            "title": {
                "fragments": [],
                "text": "Interaction-Based Adaptation for Small Screen Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An original approach to overcome current issues in the use of mobile devices, such as limited screen space and interaction modalities, based on exploiting interface adaptation and adaptive techniques is explored."
            },
            "venue": {
                "fragments": [],
                "text": "User Modeling"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143842629"
                        ],
                        "name": "T. Melzer",
                        "slug": "T.-Melzer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Melzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Melzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1454573945"
                        ],
                        "name": "P. Kammerer",
                        "slug": "P.-Kammerer",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Kammerer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kammerer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150615"
                        ],
                        "name": "Ernestine Zolda",
                        "slug": "Ernestine-Zolda",
                        "structuredName": {
                            "firstName": "Ernestine",
                            "lastName": "Zolda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernestine Zolda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38904148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e2b02c99fc236d4781f65f4c1302592f939f4a6",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The arrangement of brush strokes is an important criterion in classifying portrait miniatures. In order to detect single brush strokes we used both a model based and a semi-parametric, neural network approach. The performance of both operators is evaluated and compared experimentally."
            },
            "slug": "Stroke-detection-of-brush-strokes-in-portrait-using-Melzer-Kammerer",
            "title": {
                "fragments": [],
                "text": "Stroke detection of brush strokes in portrait miniatures using a semi-parametric and a model based approach"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work used both a model based and a semi-parametric, neural network approach in order to detect single brush strokes in portrait miniatures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144112511"
                        ],
                        "name": "Ronald Fagin",
                        "slug": "Ronald-Fagin",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Fagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Fagin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10857225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c931ab761b23df465f068c0b54e92b96a84177bb",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Fuzzy Information from Multiple Systems"
            },
            "slug": "Combining-fuzzy-information-from-multiple-systems-Fagin",
            "title": {
                "fragments": [],
                "text": "Combining fuzzy information from multiple systems (extended abstract)"
            },
            "venue": {
                "fragments": [],
                "text": "PODS"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 370,
                                "start": 367
                            }
                        ],
                        "text": "Content-based \nimage retrieval systems that gained prominence in this era were, for example, IBM QBIC [Flickner et al. \n1995], VIRAGE [Gupta and Jain 1997], and NEC AMORE [Mukherjea et al. 1999] in the commercial domain, \nand MIT Photobook [Pentland et al. 1994], Columbia VisualSEEK and WebSEEK [Smith and Chang 1997b], UCSB \nNeTra [Ma and Manjunath 1997], and Stanford WBIIS [Wang et al. 1998] in the academic domain."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "Daubechies \nwavelet transforms were used to improve color layout feature extraction in the WBIIS system [Wang et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 19
                            }
                        ],
                        "text": "and Stanford WBIIS [Wang et al. 1998] in the academic domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 248
                            }
                        ],
                        "text": "\u2026VIRAGE [Gupta and Jain 1997], and NEC AMORE [Mukherjea et al. 1999] in the commercial domain, \nand MIT Photobook [Pentland et al. 1994], Columbia VisualSEEK and WebSEEK [Smith and Chang 1997b], UCSB \nNeTra [Ma and Manjunath 1997], and Stanford WBIIS [Wang et al. 1998] in the academic domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 92
                            }
                        ],
                        "text": "Daubechies\u2019 wavelet transforms were used for texture feature extraction in the WBIIS system [Wang et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Content-based image indexing and searching using daubechies"
            },
            "venue": {
                "fragments": [],
                "text": "wavelets. Int. J. Digital Libraries"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "148954033"
                        ],
                        "name": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
                        "slug": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 199984869,
            "fieldsOfStudy": [],
            "id": "64cfe81049b1ba5828f81aa0d665cde80b1e6e9d",
            "isKey": false,
            "numCitedBy": 1221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fb\u30b5\u30a4\u30a8\u30f3\u30b9-:-ACM-computing-surveys-\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
            "title": {
                "fragments": [],
                "text": "\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fb\u30b5\u30a4\u30a8\u30f3\u30b9 : ACM computing surveys"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2655181"
                        ],
                        "name": "C. Mallows",
                        "slug": "C.-Mallows",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Mallows",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mallows"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122333431,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65c71ba7eabc196fbb5f91190208bbb7f3242335",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Note-on-Asymptotic-Joint-Normality-Mallows",
            "title": {
                "fragments": [],
                "text": "A Note on Asymptotic Joint Normality"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9056131"
                        ],
                        "name": "V. Cappellini",
                        "slug": "V.-Cappellini",
                        "structuredName": {
                            "firstName": "Vito",
                            "lastName": "Cappellini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cappellini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113657926"
                        ],
                        "name": "Ma\u00eetre",
                        "slug": "Ma\u00eetre",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Ma\u00eetre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ma\u00eetre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102803472"
                        ],
                        "name": "Pitas",
                        "slug": "Pitas",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Pitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102852177"
                        ],
                        "name": "Piva",
                        "slug": "Piva",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Piva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120462897,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "b891a777abc4cceadf5e7dc3d64df501e3ba6571",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Guest-Editorial-Special-Issue-on-Image-Processing-Cappellini-Ma\u00eetre",
            "title": {
                "fragments": [],
                "text": "Guest Editorial Special Issue on Image Processing for Cultural Heritage"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145931642"
                        ],
                        "name": "I. Berezhnoy",
                        "slug": "I.-Berezhnoy",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Berezhnoy",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Berezhnoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729457"
                        ],
                        "name": "E. Postma",
                        "slug": "E.-Postma",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Postma",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Postma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14163440"
                        ],
                        "name": "J. Herik",
                        "slug": "J.-Herik",
                        "structuredName": {
                            "firstName": "Jaap",
                            "lastName": "Herik",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Herik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59826692,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "634ea606769e92a640ba407951c6880325e4d468",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computerized-visual-analysis-of-paintings-Berezhnoy-Postma",
            "title": {
                "fragments": [],
                "text": "Computerized visual analysis of paintings"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2808999"
                        ],
                        "name": "Chen-Hsiu Huang",
                        "slug": "Chen-Hsiu-Huang",
                        "structuredName": {
                            "firstName": "Chen-Hsiu",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen-Hsiu Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 217
                            }
                        ],
                        "text": "Image transcoding techniques, which aim at adapting \nmultimedia (image and video) content to the capabilities of the client device, have been studied extensively \nin the last several years [Shanableh and Ghanbari 2000; Vetro et al. 2003; Bertini et al. 2003; Cucchiara \net al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 187
                            }
                        ],
                        "text": "Image transcoding techniques, which aim at adapting multimedia (image and video) content to the capabilities of the client device, have been studied extensively in the last several years [Shanableh and Ghanbari 2000; Vetro et al. 2003; Bertini et al. 2003; Cucchiara et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18598268,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "dbc8987f77aaecdb058aac10c175124b06b1dbaf",
            "isKey": false,
            "numCitedBy": 525,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Video-Transcoding-Architectures-and-Techniques-:-An-Huang",
            "title": {
                "fragments": [],
                "text": "Video Transcoding Architectures and Techniques : An Overview"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109552014"
                        ],
                        "name": "Dong-Qing Zhang",
                        "slug": "Dong-Qing-Zhang",
                        "structuredName": {
                            "firstName": "Dong-Qing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong-Qing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207155602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03cfc10c38bd1283760ee3e9408128f9c8fec3b6",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting Image Near-Duplicate (IND) is an important problem in a variety of applications, such as copyright infringement detection and multimedia linking. Traditional image similarity models are often difficult to identify IND due to their inability to capture scene composition and semantics. We present a part-based image similarity measure derived from stochastic matching of Attributed Relational Graphs that represent the compositional parts and part relations of image scenes. Such a similarity model is fundamentally different from traditional approaches using low-level features or image alignment. The advantage of this model is its ability to accommodate spatial attributed relations and support supervised and unsupervised learning from training data. The experiments compare the presented model with several prior similarity models, such as color histogram, local edge descriptor, etc. The presented model outperforms the prior approaches with large margin."
            },
            "slug": "Detecting-image-near-duplicate-by-stochastic-graph-Zhang-Chang",
            "title": {
                "fragments": [],
                "text": "Detecting image near-duplicate by stochastic attributed relational graph matching with learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A part-based image similarity measure derived from stochastic matching of Attributed Relational Graphs that represent the compositional parts and part relations of image scenes that outperforms the prior approaches with large margin."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '04"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Design and implementation factors in electronic image retrieval systems"
            },
            "venue": {
                "fragments": [],
                "text": "Library and Information Commission"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Benchathlon homepage"
            },
            "venue": {
                "fragments": [],
                "text": "Benchathlon homepage"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 65"
            },
            "venue": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 65"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Content-based representation and retrieval of visual media: A review of the state-of-the-art"
            },
            "venue": {
                "fragments": [],
                "text": "Multimed. Tools Appl"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DPChallenge.com"
            },
            "venue": {
                "fragments": [],
                "text": "DPChallenge.com"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 97
                            }
                        ],
                        "text": "We searched for publications containing the phrases Im\u00adage Retrieval using Google \nScholar [Google Scholar 2004] and the digital libraries of ACM, IEEE, and Springer, within each year \nfrom 1995 to 2005."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Google scholar homepage"
            },
            "venue": {
                "fragments": [],
                "text": "Google scholar homepage"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "Clustering based on the IB principle [Tishby et al. 1999] can \nbe sum\u00admarized as follows: Given two variables A (which we try to compress/cluster) and B (which contains \nrelevant information), and their joint distribution Pr(A, B), we seek to perform soft partitioning of \nA by a probabilistic\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 37
                            }
                        ],
                        "text": "Clustering based on the IB principle [Tishby et al. 1999] can be summarized as follows: given two variables A (which we try to compress/cluster) and B (which contains relevant information), and their joint distribution Pr(A, B), we seek to perform soft partitioning of A by a probabilistic mapping V , i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The information botflencek method"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. Allerton Conf. Communication and Computation"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image processing for artist identification\u2014computerized analysis of Vincent van Gogh's painting brush stokes"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Sign. Process"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alipr homepage"
            },
            "venue": {
                "fragments": [],
                "text": "Alipr homepage"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital pics 'read' by computer"
            },
            "venue": {
                "fragments": [],
                "text": "Digital pics 'read' by computer"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM Transactions on Computing Surveys"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Computing Surveys"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 77
                            }
                        ],
                        "text": "By fitting a mixture of Gaussians to a data set, usually by the EM algorithm [McLachlan and Peel 2000], we estimate the means and covariance matrices of the Gaussian components, which correspond to the center locations and shapes of clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "By .tting a mixture of Gaussians to a dataset, usually by the EM \nalgo\u00adrithm [McLachlan and Peel 2000], we estimate the means and covariance matrices of the Gaussian components, \nwhich correspond to the center locations and shapes of clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finite Mixture Models. Wiley-Interscience"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 110
                            }
                        ],
                        "text": "Image analysis and retrieval systems have \nreceived widespread public and media interest of late [Mirsky 2006; Staedter 2006; CNN 2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 210
                            }
                        ],
                        "text": "Of late, there is renewed interest \nin the media about potential real-world ap\u00adplications of CBIR and image analysis technologies, as evidenced \nby publications in Scinti.c American [Mirsky 2006], Discovery News [Staedter 2006] and on CNN [2005]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital pics \u2018read"
            },
            "venue": {
                "fragments": [],
                "text": "by computer. http://dsc.discovery.com/news/2006/11/09/images tec. html"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The CLEF cross language image retrieval track (ImageCLEF) homepage"
            },
            "venue": {
                "fragments": [],
                "text": "The CLEF cross language image retrieval track (ImageCLEF) homepage"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 190
                            }
                        ],
                        "text": "Multiple-instance-learning-based \napproaches have been proposed for se\u00admantic categorization of images [Chen and Wang 2004] and to learn \nthe correspondence between image regions and keywords [Yang et al. 2005a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Region based image annotation through multipleinstance learning"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. ACM Multimedia"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital pics 'read' by computer. Tracy Staedter -Discovery News"
            },
            "venue": {
                "fragments": [],
                "text": "Discovery"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Global Memory Net homepage"
            },
            "venue": {
                "fragments": [],
                "text": "Global Memory Net homepage"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 59"
            },
            "venue": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 59"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 70
                            }
                        ],
                        "text": "A tree-structured SOM has been used as an underlying technique for RF [Laaksonen et al. 2001] in a CBIR system [Laaksonen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "A tree-structured SOM has been used as an underlying technique \nfor RF [Laaksonen et al. 2001] in a CBIR system [Laaksonen et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self-organizing maps as a relevance feedback technique in content-based image retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Applications"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Terragalleria homepage"
            },
            "venue": {
                "fragments": [],
                "text": "Terragalleria homepage"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The flickr homepage"
            },
            "venue": {
                "fragments": [],
                "text": "The flickr homepage"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimal multimodal fusion for multimedia"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In [Tope and Enser 2000], case studies on design and implementation of many different electronic retrieval systems have been reported."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Design and implementation factors in electronic image retrieval systems"
            },
            "venue": {
                "fragments": [],
                "text": "In Library and Information Commission Research Report 105"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 63
                            }
                        ],
                        "text": "Work on local patch-based salient \nfeatures [Tuytelaars and van Gool 1999] found prominence in areas such as image retrieval and stereo \nmatching."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Content-Based image retrieval based on local affinely invariant"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Article 5, Publication date"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Computing Surveys"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 57"
            },
            "venue": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 57"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Received November ACM Computing Surveys"
            },
            "venue": {
                "fragments": [],
                "text": "Received November ACM Computing Surveys"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 63"
            },
            "venue": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 63"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 125
                            }
                        ],
                        "text": "The TRECVID \nbenchmark is very popular in the CBIR community to validate their search and retrieval algorithms [TRECVID \n2001; Smeaton and Over 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 110
                            }
                        ],
                        "text": "The TRECVID benchmark is very popular in the CBIR community to validate their search and retrieval algorithms [TRECVID 2001; Smeaton and Over 2003]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Benchmarking the effectiveness of information retrieval tasks on digital video"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. CIVR"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 140
                            }
                        ],
                        "text": "\u2026similarity search tool [Wang et al. 2001] is being used for an online database of over 800, \n000 airline-related images [Airliners.Net 2005; Slashdot 2005] (again see Figure 4), the integration \nof similarity search functionality to a large col\u00adlection of art and cultural images\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Searching by image instead of keywords"
            },
            "venue": {
                "fragments": [],
                "text": "Slashdot News"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 274
                            }
                        ],
                        "text": "\u2026search and retrieval in large art/cultural \nimage databases, statistical learning techniques have also been proposed to capture properties of the \nbrush strokes of painters [Melzer et al. 1998; Sablatnig et al. 1998; Li and Wang 2004; Lyu et al. 2004; \nBerezhnoy et al. 2005; Johnson et al. 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image processing for artist identification\u2014computerized analysis of Vincent van Gogh\u2019s painting brush stokes"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Sign. Process. 25 (Special Issue on Visual Cultural Heritage)"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 50
                            }
                        ],
                        "text": "Comprehensive surveys \nexist on the topic of CBIR [Aigrain et al. 1996; Rui et al. 1999; Smeulders et al. 2000; Snoek and Worring \n2005], all of which deal primarily with work prior to the year 2000."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 49
                            }
                        ],
                        "text": "Comprehensive surveys exist on the topic of CBIR [Aigrain et al. 1996; Rui et al. 1999; Smeulders et al. 2000; Snoek and Worring 2005], all of which deal primarily with work prior to the year 2000."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Content-based representation and retrieval of visual media: A review of the state-of-the-art"
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Tools and Applications"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Photonet homepage. http://www.photo.net. PHOTO.NET(RATINGSYSTEM) Photonet standards"
            },
            "venue": {
                "fragments": [],
                "text": "Photonet homepage. http://www.photo.net. PHOTO.NET(RATINGSYSTEM) Photonet standards"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computers get the picture. Steve Mirsky -Scientific American 60-second World of Science"
            },
            "venue": {
                "fragments": [],
                "text": "Computers get the picture. Steve Mirsky -Scientific American 60-second World of Science"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computers get the picture"
            },
            "venue": {
                "fragments": [],
                "text": "Sci. Amer"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Content-based image retrieval using multipleinstance learning"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference on Machine Learning (ICML)"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image retrieval using color histograms generated by Gauss mixture vector quantization. Comput. Vision Image Understand"
            },
            "venue": {
                "fragments": [],
                "text": "Image retrieval using color histograms generated by Gauss mixture vector quantization. Comput. Vision Image Understand"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer decodes mona lisa's smile. CNN -Technology"
            },
            "venue": {
                "fragments": [],
                "text": "Computer decodes mona lisa's smile. CNN -Technology"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picasa homepage"
            },
            "venue": {
                "fragments": [],
                "text": "Picasa homepage"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 61"
            },
            "venue": {
                "fragments": [],
                "text": "Image Retrieval: Ideas, Influences, and Trends of the New Age \u00b7 61"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The ImageEval homepage"
            },
            "venue": {
                "fragments": [],
                "text": "The ImageEval homepage"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Airliners.Net"
            },
            "venue": {
                "fragments": [],
                "text": "Airliners.Net"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer decodes Mona Lisa's smile"
            },
            "venue": {
                "fragments": [],
                "text": "Computer decodes Mona Lisa's smile"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The information botflencek method"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Allerton Conference on Communication and Computation"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 55,
            "methodology": 47,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 325,
        "totalPages": 33
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-retrieval:-Ideas,-influences,-and-trends-of-Datta-Joshi/0dfa5679a15d0125ecec8539b79e8ba0babb8f73?sort=total-citations"
}