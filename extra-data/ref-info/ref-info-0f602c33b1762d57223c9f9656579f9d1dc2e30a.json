{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37895334"
                        ],
                        "name": "S. Fidler",
                        "slug": "S.-Fidler",
                        "structuredName": {
                            "firstName": "Sanja",
                            "lastName": "Fidler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fidler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34419904"
                        ],
                        "name": "Gregor Berginc",
                        "slug": "Gregor-Berginc",
                        "structuredName": {
                            "firstName": "Gregor",
                            "lastName": "Berginc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregor Berginc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 292
                            }
                        ],
                        "text": "Parts and their higher level combinations should be learned in an unsupervised manner (at least in the first stages of the hierarchy) in order to avoid hand-labelling of massive image data as well as to capture the regularities within the visual data as effectively and compactly as possible [3, 17, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": ") will be omitted, since the procedure is the same as proposed in [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "For any given image, the process starts by describing the image in terms of local oriented edges similarly as proposed in [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "With respect to our previous work [7], this paper proposes a much simpler and efficient learning algorithm, and introduces additional steps that enable a higher level representation of object categories."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "In contrast to [7], we do not perform the global MDL, but rather local inhibition (see Subsec."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "As it can be evident from the computational perspective in (1), and even more so from the exponential complexity of unsupervised learning (with computational issues addressed in [7]), the number of parts that consequently define a novel composition should not be too large."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15062936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "568c2db94c3c4da7321f83e7713bd51daf9db7b2",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "With the growing interest in object categorization various methods have emerged that perform well in this challenging task, yet are inherently limited to only a moderate number of object classes. In pursuit of a more general categorization system this paper proposes a way to overcome the computational complexity encompassing the enormous number of different object categories by exploiting the statistical properties of the highly structured visual world. Our approach proposes a hierarchical acquisition of generic parts of object structure, varying from simple to more complex ones, which stem from the favorable statistics of natural images. The parts recovered in the individual layers of the hierarchy can be used in a top-down manner resulting in a robust statistical engine that could be efficiently used within many of the current categorization systems. The proposed approach has been applied to large image datasets yielding important statistical insights into the generic parts of object structure."
            },
            "slug": "Hierarchical-Statistical-Learning-of-Generic-Parts-Fidler-Berginc",
            "title": {
                "fragments": [],
                "text": "Hierarchical Statistical Learning of Generic Parts of Object Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a hierarchical acquisition of generic parts of object structure that can be used in a top-down manner resulting in a robust statistical engine that could be efficiently used within many of the current categorization systems."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126798"
                        ],
                        "name": "B. Epshtein",
                        "slug": "B.-Epshtein",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Epshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Epshtein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11631653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4bf169531bb0ecc0018e6c32822030550211c2e",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The chapter describes visual classification by a hierarchy of semantic fragments. In fragment-based classification, objects within a class are represented by common sub-structures selected during training. The chapter describes two extensions to the basic fragment-based scheme. The first extension is the extraction and use of feature hierarchies. We describe a method that automatically constructs complete feature hierarchies from image examples, and show that features constructed hierarchically are significantly more informative and better for classification compared with similar non-hierarchical features. The second extension is the use of so-called semantic fragments to represent object parts. The goal of a semantic fragment is to represent the different possible appearances of a given object part. The visual appearance of such object parts can differ substantially, and therefore traditional image similarity-based methods are inappropriate for the task. We show how the method can automatically learn the part structure of a new domain, identify the main parts, and how their appearance changes across objects in the class. We discuss the implications of these extensions to object classification and recognition."
            },
            "slug": "Visual-Classification-by-a-Hierarchy-of-Extended-Ullman-Epshtein",
            "title": {
                "fragments": [],
                "text": "Visual Classification by a Hierarchy of Extended Fragments"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A method that automatically constructs complete feature hierarchies from image examples is described, and it is shown that features constructed hierarchically are significantly more informative and better for classification compared with similar non-hierarchical features."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 126
                            }
                        ],
                        "text": "To overcome the curse of large-scale recognition, some authors emphasized the need for indexable hierarchical representations [4, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 215
                            }
                        ],
                        "text": "To achieve robustness against noise and clutter, the parts comprising the individual hierarchical layers should be manifested as models to enable a robust verification of the presence of their underlying components [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [2], the authors use hand-crafted local edge features and only learn their global arrangements pertaining to specific object categories."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7784637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61b2d0383b186c4d634c5f51421cab67c16d90a1",
            "isKey": true,
            "numCitedBy": 197,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a computational model for detecting and localizing instances from an object class in static gray-level images. We divide detection into visual selection and final classification, concentrating on the former: drastically reducing the number of candidate regions that require further, usually more intensive, processing, but with a minimum of computation and missed detections. Bottom-up processing is based on local groupings of edge fragments constrained by loose geometrical relationships. They have no a priori semantic or geometric interpretation. The role of training is to select special groupings that are moderately likely at certain places on the object but rare in the background. We show that the statistics in both populations are stable. The candidate regions are those that contain global arrangements of several local groupings. Whereas our model was not conceived to explain brain functions, it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse or incomplete patterns (e.g., illusory contours) and to scale and translation invariance in IT. Finally, the algorithm is applied to face and symbol detection."
            },
            "slug": "A-Computational-Model-for-Visual-Selection-Amit-Geman",
            "title": {
                "fragments": [],
                "text": "A Computational Model for Visual Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The model was not conceived to explain brain functions, but it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse or incomplete patterns and to scale and translation invariance in IT."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52118596"
                        ],
                        "name": "S. Krempp",
                        "slug": "S.-Krempp",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Krempp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Krempp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 268
                            }
                        ],
                        "text": "Hierarchical systems build on simple features that fire densely on all objects and combine them into more complex entities that become sparser, thus achieving compact object representation, enabling fast and robust categorization with better generalization properties [4, 20, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6386555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61b933b8ef5b10ae4f6491a89f89972322534cf0",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Our long-range goal is detecting instances from a large number of object classes in a computationally efficient manner. Detectors involving a hierarchy of tests based on edges have been used elsewhere and shown to be quite fast online. However, significant further gains in efficiency in representation, error rates and computation can be realized if the family of detectors is constructed from common parts. Our parts are flexible, extended edge configurations; they are learned, not pre-designed. In training, object classes are presented sequentially; the objective is then to accommodate new classes by maximally reusing parts. Ideally, the number of distinct parts in the system would grow much more slowly than linearly with the number of classes. Initial experiments on learning to detect several hundred LTEXsymbols are encouraging."
            },
            "slug": "Sequential-Learning-of-Reusable-Parts-for-Object-Krempp-Geman",
            "title": {
                "fragments": [],
                "text": "Sequential Learning of Reusable Parts for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Initial experiments on learning to detect several hundred LTEXsymbols are encouraging, and significant further gains in efficiency in representation, error rates and computation can be realized if the family of detectors is constructed from common parts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799035"
                        ],
                        "name": "Erik B. Sudderth",
                        "slug": "Erik-B.-Sudderth",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sudderth",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik B. Sudderth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "The current state-of-the-art categorization methods predominantly build their representations on image patches [14, 22] or other highly discriminative features such as the SIFT [20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 259
                            }
                        ],
                        "text": "This drawback has been alleviated within the most recent methods that employ hierarchical clustering in a high dimensional feature space, yet the resulting representations still demand at least a linear search through the library of stored objects/categories [14, 20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 268
                            }
                        ],
                        "text": "Hierarchical systems build on simple features that fire densely on all objects and combine them into more complex entities that become sparser, thus achieving compact object representation, enabling fast and robust categorization with better generalization properties [4, 20, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6153430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5331349557fababfac48d47e49b44583e3bd5f6",
            "isKey": true,
            "numCitedBy": 365,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a hierarchical probabilistic model for the detection and recognition of objects in cluttered, natural scenes. The model is based on a set of parts which describe the expected appearance and position, in an object centered coordinate frame, of features detected by a low-level interest operator. Each object category then has its own distribution over these parts, which are shared between objects. We learn the parameters of this model via a Gibbs sampler which uses the graphical model's structure to analytically average over many parameters. Applied to a database of images of isolated objects, the sharing of parts among objects improves detection accuracy when few training examples are available. We also extend this hierarchical framework to scenes containing multiple objects"
            },
            "slug": "Learning-hierarchical-models-of-scenes,-objects,-Sudderth-Torralba",
            "title": {
                "fragments": [],
                "text": "Learning hierarchical models of scenes, objects, and parts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Applied to a database of images of isolated objects, the sharing of parts among objects improves detection accuracy when few training examples are available and this hierarchical probabilistic model is extended to scenes containing multiple objects."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2337630"
                        ],
                        "name": "G. Ettinger",
                        "slug": "G.-Ettinger",
                        "structuredName": {
                            "firstName": "Gil",
                            "lastName": "Ettinger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ettinger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 168
                            }
                        ],
                        "text": "In pursuit of a general categorization system capable of recognizing a vast number of object categories, a need for hierarchical structuring of information has emerged [21, 13, 4, 6, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12794673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5096659cde865ae8f949dd4c02e48f77cbf17816",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A description is given of the development of a model-based vision system that utilizes hierarchies of both object structure and object scale. The focus of the research is to use these hierarchies to achieve robust recognition based on effective organization and indexing schemes for model libraries. The goal of the system is to recognize parameterized instances of nonrigid model objects contained in a large knowledge base, despite the presence of noise and occlusion. The approach presented is to develop an object shape representation that incorporates a component subpart hierarchy, to allow for efficient and correct indexing into an automatically generated model library as well as for relative parametrization among subparts, and a scale hierarchy, to allow for a general to specific recognition procedure. The implemented system uses a representation based on significant contour curvature changes and recognition engine based on geometric constraints of feature properties. Examples of the system's performance are given, followed by an analysis of the results.<<ETX>>"
            },
            "slug": "Large-hierarchical-object-recognition-using-of-Ettinger",
            "title": {
                "fragments": [],
                "text": "Large hierarchical object recognition using libraries of parameterized model sub-parts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach presented is to develop an object shape representation that incorporates a component subpart hierarchy to allow for efficient and correct indexing into an automatically generated model library as well as for relative parametrization among subparts, and a scale hierarchy, to allowed for a general to specific recognition procedure."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2721983"
                        ],
                        "name": "F. Fleuret",
                        "slug": "F.-Fleuret",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fleuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fleuret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "The learning algorithm proposed in [8], which acquires a hierarchy of local edge arrangements by correlation, is in concept similar to our learning method."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6754141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b535f4edc4cbf8d4fb6182ec6b5c54db3c1cccb",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We study visual selection: Detect and roughly localize all instances of a generic object class, such as a face, in a greyscale scene, measuring performance in terms of computation and false alarms. Our approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects. All the tests are binary and indicate the presence or absence of loose spatial arrangements of oriented edge fragments. Starting from training examples, we recursively find larger and larger arrangements which are \u201cdecomposable,\u201d which implies the probability of an arrangement appearing on an object decays slowly with its size. Detection means finding a sufficient number of arrangements of each size along a decreasing sequence of pose cells. At the beginning, the tests are simple and universal, accommodating many poses simultaneously, but the false alarm rate is relatively high. Eventually, the tests are more discriminating, but also more complex and dedicated to specific poses. As a result, the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which, presumably, could be eliminated with localized, more intensive, processing."
            },
            "slug": "Coarse-to-Fine-Face-Detection-Fleuret-Geman",
            "title": {
                "fragments": [],
                "text": "Coarse-to-Fine Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects, and the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which could be eliminated with localized, more intensive, processing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773022"
                        ],
                        "name": "F. Scalzo",
                        "slug": "F.-Scalzo",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Scalzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scalzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772389"
                        ],
                        "name": "J. Piater",
                        "slug": "J.-Piater",
                        "structuredName": {
                            "firstName": "Justus",
                            "lastName": "Piater",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Piater"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1489113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb35ae8a50de54c9ca29fbdf1ea2fbbb4e8c4662",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an unsupervised, probabilistic method for learning visual feature hierarchies. Starting from local, low-level features computed at interest point locations, the method combines these primitives into high-level abstractions. Our appearance-based learning method uses local statistical analysis between features and Expectation- Maximization (EM) to identify and code spatial correlations. Spatial correlation is asserted when two features tend to occur at the same relative position of each other. This learning scheme results in a graphical model that allows a probabilistic representation of a flexible visual feature hierarchy. For feature detection, evidence is propagated using Nonparametric Belief Propagation (NBP), a recent generalization of particle filtering. In experiments, the proposed approach demonstrates efficient learning and robust detection of object models in the presence of clutter and occlusion and under view point changes."
            },
            "slug": "Statistical-Learning-of-Visual-Feature-Hierarchies-Scalzo-Piater",
            "title": {
                "fragments": [],
                "text": "Statistical Learning of Visual Feature Hierarchies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An appearance-based learning method that uses local statistical analysis between features and Expectation- Maximization to identify and code spatial correlations and results in a graphical model that allows a probabilistic representation of a flexible visual feature hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7105458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6a40655c3f8aad3c70ce54f68d1b017a1e9bc2f",
            "isKey": false,
            "numCitedBy": 285,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose an approach capable of simultaneous recognition and localization of multiple object classes using a generative model. A novel hierarchical representation allows to represent individual images as well as various objects classes in a single, scale and rotation invariant model. The recognition method is based on a codebook representation where appearance clusters built from edge based features are shared among several object classes. A probabilistic model allows for reliable detection of various objects in the same image. The approach is highly efficient due to fast clustering and matching methods capable of dealing with millions of high dimensional features. The system shows excellent performance on several object categories over a wide range of scales, in-plane rotations, background clutter, and partial occlusions. The performance of the proposed multi-object class detection approach is competitive to state of the art approaches dedicated to a single object class recognition problem."
            },
            "slug": "Multiple-Object-Class-Detection-with-a-Generative-Mikolajczyk-Leibe",
            "title": {
                "fragments": [],
                "text": "Multiple Object Class Detection with a Generative Model"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The performance of the proposed multi-object class detection approach is competitive to state of the art approaches dedicated to a single object class recognition problem."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 316,
                                "start": 309
                            }
                        ],
                        "text": "Approaches that do build the layers by learning and are able to make a sufficient number of them (by starting with simple features) mostly design the parts by histogramming the local neighborhoods of parts of the previous layers [1] or by learning the neural weights based on the responses on previous layers [11, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "This is also a drawback in layers of clustered histograms used in [1] and hierarchical classifiers in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9123239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf03fdf52dd6e4249cbbdbd0bffbbbe5ca389feb",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "The detection and recognition of generic object categories with invariance to viewpoint, illumination, and clutter requires the combination of a feature extractor and a classifier. We show that architectures such as convolutional networks are good at learning invariant features, but not always optimal for classification, while Support Vector Machines are good at producing decision surfaces from wellbehaved feature vectors, but cannot learn complicated invariances. We present a hybrid system where a convolutional network is trained to detect and recognize generic objects, and a Gaussian-kernel SVM is trained from the features learned by the convolutional network. Results are given on a large generic object recognition task with six categories (human figures, four-legged animals, airplanes, trucks, cars, and \"none of the above\"), with multiple instances of each object category under various poses, illuminations, and backgrounds. On the test set, which contains different object instances than the training set, an SVM alone yields a 43.3% error rate, a convolutional net alone yields 7.2% and an SVM on top of features produced by the convolutional net yields 5.9%."
            },
            "slug": "Large-scale-Learning-with-SVM-and-Convolutional-for-Huang-LeCun",
            "title": {
                "fragments": [],
                "text": "Large-scale Learning with SVM and Convolutional for Generic Object Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that architectures such as convolutional networks are good at learning invariant features, but not always optimal for classification, while Support Vector Machines are good for producing decision surfaces from wellbehaved feature vectors, but cannot learn complicated invariances."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984136"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 229
                            }
                        ],
                        "text": "Approaches that do build the layers by learning and are able to make a sufficient number of them (by starting with simple features) mostly design the parts by histogramming the local neighborhoods of parts of the previous layers [1] or by learning the neural weights based on the responses on previous layers [11, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "This is also a drawback in layers of clustered histograms used in [1] and hierarchical classifiers in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15284075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bd170564ea5e58faffd557826d442ab0baf8dc6",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Histograms of local appearance descriptors are a popular representation for visual recognition. They are highly discriminant and have good resistance to local occlusions and to geometric and photometric variations, but they are not able to exploit spatial co-occurrence statistics at scales larger than their local input patches. We present a new multilevel visual representation, \u2018hyperfeatures', that is designed to remedy this. The starting point is the familiar notion that to detect object parts, in practice it often suffices to detect co-occurrences of more local object fragments \u2013 a process that can be formalized as comparison (e.g. vector quantization) of image patches against a codebook of known fragments, followed by local aggregation of the resulting codebook membership vectors to detect co-occurrences. This process converts local collections of image descriptor vectors into somewhat less local histogram vectors \u2013 higher-level but spatially coarser descriptors. We observe that as the output is again a local descriptor vector, the process can be iterated, and that doing so captures and codes ever larger assemblies of object parts and increasingly abstract or \u2018semantic' image properties. We formulate the hyperfeatures model and study its performance under several different image coding methods including clustering based Vector Quantization, Gaussian Mixtures, and combinations of these with Latent Dirichlet Allocation. We find that the resulting high-level features provide improved performance in several object image and texture image classification tasks."
            },
            "slug": "Hyperfeatures-Multilevel-Local-Coding-for-Visual-Agarwal-Triggs",
            "title": {
                "fragments": [],
                "text": "Hyperfeatures - Multilevel Local Coding for Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The hyperfeatures model is formulated and its performance under several different image coding methods including clustering based Vector Quantization, Gaussian Mixtures, and combinations of these with Latent Dirichlet Allocation is studied."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243801"
                        ],
                        "name": "Jim Mutch",
                        "slug": "Jim-Mutch",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Mutch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Mutch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Mutch et al [15] (and their predecessor [19]) employ matching of all 4000 higher-layer templates against features extracted in each pixel and scale of the resampled pyramid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1427294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e65fcb0e04174577f211d702d3f837e3624c5b",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply a biologically inspired model of visual object recognition to the multiclass object categorization problem. Our model modifies that of Serre, Wolf, and Poggio. As in that work, we first apply Gabor filters at all positions and scales; feature complexity and position/scale invariance are then built up by alternating template matching and max pooling operations. We refine the approach in several biologically plausible ways, using simple versions of sparsification and lateral inhibition. We demonstrate the value of retaining some position and scale information above the intermediate feature level. Using feature selection we arrive at a model that performs better with fewer features. Our final model is tested on the Caltech 101 object categories and the UIUC car localization task, in both cases achieving state-of-the-art performance. The results strengthen the case for using this class of model in computer vision."
            },
            "slug": "Multiclass-Object-Recognition-with-Sparse,-Features-Mutch-Lowe",
            "title": {
                "fragments": [],
                "text": "Multiclass Object Recognition with Sparse, Localized Features"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A biologically inspired model of visual object recognition to the multiclass object categorization problem, modifies that of Serre, Wolf, and Poggio, and demonstrates the value of retaining some position and scale information above the intermediate feature level."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093644"
                        ],
                        "name": "Bartlett W. Mel",
                        "slug": "Bartlett-W.-Mel",
                        "structuredName": {
                            "firstName": "Bartlett",
                            "lastName": "Mel",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bartlett W. Mel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1936517"
                        ],
                        "name": "J. Fiser",
                        "slug": "J.-Fiser",
                        "structuredName": {
                            "firstName": "J\u00f3zsef",
                            "lastName": "Fiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 95
                            }
                        ],
                        "text": "Models should incorporate loose geometric relations to achieve the spatial binding of features [5, 13], yet encode enough flexibility to gain discrimination gradually through composition within the hierarchy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 168
                            }
                        ],
                        "text": "In pursuit of a general categorization system capable of recognizing a vast number of object categories, a need for hierarchical structuring of information has emerged [21, 13, 4, 6, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "The importance of good representations in vision tasks has often been emphasized in literature [5, 17, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 480601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e71cb72759ae40166a30ed8033ea44a65e7fef26",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We have studied some of the design trade-offs governing visual representations based on spatially invariant conjunctive feature detectors, with an emphasis on the susceptibility of such systems to false-positive recognition errorsMalsburg's classical binding problem. We begin by deriving an analytical model that makes explicit how recognition performance is affected by the number of objects that must be distinguished, the number of features included in the representation, the complexity of individual objects, and the clutter load, that is, the amount of visual material in the field of view in which multiple objects must be simultaneously recognized, independent of pose, and without explicit segmentation. Using the domain of text to model object recognition in cluttered scenes, we show that with corrections for the nonuniform probability and nonindependence of text features, the analytical model achieves good fits to measured recognition rates in simulations involving a wide range of clutter loads, word sizes, and feature counts. We then introduce a greedy algorithm for feature learning, derived from the analytical model, which grows a representation by choosing those conjunctive features that are most likely to distinguish objects from the cluttered backgrounds in which they are embedded. We show that the representations produced by this algorithm are compact, decorrelated, and heavily weighted toward features of low conjunctive order. Our results provide a more quantitative basis for understanding when spatially invariant conjunctive features can support unambiguous perception in multiobject scenes, and lead to several insights regarding the properties of visual representations optimized for specific recognition tasks."
            },
            "slug": "Minimizing-Binding-Errors-Using-Learned-Conjunctive-Mel-Fiser",
            "title": {
                "fragments": [],
                "text": "Minimizing Binding Errors Using Learned Conjunctive Features"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results provide a more quantitative basis for understanding when spatially invariant conjunctive features can support unambiguous perception in multiobject scenes, and lead to several insights regarding the properties of visual representations optimized for specific recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "The authors of [16] use predesigned filters and process the visual information in the feed-forward manner, while their recent version [19] exchanged the intermediate layer with random combinations of local edge arrangements rather than choosing the features in accordance with the natural statistics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Mutch et al [15] (and their predecessor [19]) employ matching of all 4000 higher-layer templates against features extracted in each pixel and scale of the resampled pyramid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 168
                            }
                        ],
                        "text": "In pursuit of a general categorization system capable of recognizing a vast number of object categories, a need for hierarchical structuring of information has emerged [21, 13, 4, 6, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": true,
            "numCitedBy": 969,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 292
                            }
                        ],
                        "text": "Parts and their higher level combinations should be learned in an unsupervised manner (at least in the first stages of the hierarchy) in order to avoid hand-labelling of massive image data as well as to capture the regularities within the visual data as effectively and compactly as possible [3, 17, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 95
                            }
                        ],
                        "text": "Models should incorporate loose geometric relations to achieve the spatial binding of features [5, 13], yet encode enough flexibility to gain discrimination gradually through composition within the hierarchy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "The importance of good representations in vision tasks has often been emphasized in literature [5, 17, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7160552,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "39fa389d5049bb10a5f25e0f893fe42d298d0a36",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 175,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Towards-structural-systematicity-in-distributed,-Edelman-Intrator",
            "title": {
                "fragments": [],
                "text": "Towards structural systematicity in distributed, statically bound visual representations"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43289321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "716d218b0831157b6ff431f5418094bf776ee3f2",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This book is the outcome of two workshops that brought together about 40 prominent vision and machine learning researchers interested in the fundamental and applicative aspects of object recognition, as well as representatives of industry. The main goals of these two workshops were (1) to promote the creation of an international object recognition community, with common datasets and evaluation procedures, (2) to map the state of the art and identify the main open problems and opportunities for synergistic research, and (3) to articulate the industrial and societal needs and opportunities for object recognition research worldwide. These goals are reflected in a relatively small number of papers that illustrate the breadth of today's object recognition research and the arsenal of techniques at its disposal, and discuss current achievements and outstanding challenges. Most of the chapters are descriptions of technical approaches, intended to capture the current state of the art. Some of the chapters are of a tutorial nature. They cover fundamental building blocks for object recognition techniques."
            },
            "slug": "Toward-Category-Level-Object-Recognition-Ponce-Hebert",
            "title": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This book is the outcome of two workshops that brought together about 40 prominent vision and machine learning researchers interested in the fundamental and applicative aspects of object recognition, as well as representatives of industry to promote the creation of an international object recognition community."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "The authors of [16] use predesigned filters and process the visual information in the feed-forward manner, while their recent version [19] exchanged the intermediate layer with random combinations of local edge arrangements rather than choosing the features in accordance with the natural statistics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8920227,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "85abadb689897997f1e37baa7b5fc6f7d497518b",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function."
            },
            "slug": "Hierarchical-models-of-object-recognition-in-cortex-Riesenhuber-Poggio",
            "title": {
                "fragments": [],
                "text": "Hierarchical models of object recognition in cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions is described."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727853"
                        ],
                        "name": "John K. Tsotsos",
                        "slug": "John-K.-Tsotsos",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsotsos",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John K. Tsotsos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 168
                            }
                        ],
                        "text": "In pursuit of a general categorization system capable of recognizing a vast number of object categories, a need for hierarchical structuring of information has emerged [21, 13, 4, 6, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144964393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b1b12e4510e5dab24c270502b7dad25295ce61e",
            "isKey": false,
            "numCitedBy": 685,
            "numCiting": 132,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The general problem of visual search can be shown to be computationally intractable in a formal, complexity-theoretic sense, yet visual search is extensively involved in everyday perception, and biological systems manage to perform it remarkably well. Complexity level analysis may resolve this contradiction. Visual search can be reshaped into tractability through approximations and by optimizing the resources devoted to visual processing. Architectural constraints can be derived using the minimum cost principle to rule out a large class of potential solutions. The evidence speaks strongly against bottom-up approaches to vision. In particular, the constraints suggest an attentional mechanism that exploits knowledge of the specific problem being solved. This analysis of visual search performance in terms of attentional influences on visual information processing and complexity satisfaction allows a large body of neurophysiological and psychological evidence to be tied together."
            },
            "slug": "Analyzing-vision-at-the-complexity-level-Tsotsos",
            "title": {
                "fragments": [],
                "text": "Analyzing vision at the complexity level"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This analysis of visual search performance in terms of attentional influences on visual information processing and complexity satisfaction allows a large body of neurophysiological and psychological evidence to be tied together."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070677950"
                        ],
                        "name": "A. Califano",
                        "slug": "A.-Califano",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Califano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Califano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057667806"
                        ],
                        "name": "R. Mohan",
                        "slug": "R.-Mohan",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10403106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62f6a99f6749262f6dc6cc8b3d6f2f2c16a1aefb",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "A homogeneous approach for acquisition, storage, and recognition of nonparametric shapes from images, using a novel shape representation based on shape autocorrelation operators is presented. A theoretical and experimental analysis of the computational complexity, recognition performance with increasing database size, and fault tolerance of the approach is presented. The system has been tested extensively with more than 300 arbitrary shapes in the database. Using a set of complex shapes, the recognition behavior with respect to occlusion, geometric transformation, and cluttered environments is studied. Unsupervised shape and subpart acquisition is demonstrated.<<ETX>>"
            },
            "slug": "Multidimensional-indexing-for-recognizing-visual-Califano-Mohan",
            "title": {
                "fragments": [],
                "text": "Multidimensional Indexing for Recognizing Visual Shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A homogeneous approach for acquisition, storage, and recognition of nonparametric shapes from images, using a novel shape representation based on shape autocorrelation operators is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145399800"
                        ],
                        "name": "K. Clark",
                        "slug": "K.-Clark",
                        "structuredName": {
                            "firstName": "Kettner",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Clark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 292
                            }
                        ],
                        "text": "Parts and their higher level combinations should be learned in an unsupervised manner (at least in the first stages of the hierarchy) in order to avoid hand-labelling of massive image data as well as to capture the regularities within the visual data as effectively and compactly as possible [3, 17, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10038446,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bc03c5f67e76131f36c91d127df445d494f27f6a",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "It is a mistake to consider perception and learning separately because what one learns is strongly constrained by what one perceives, and what one perceives depends on what one bas experienced. I shall propose the hypothesis that perception is the computation of a representation that enables us to make reliable and versatile inferences about associations occurring in the world around us-that is, perception pmpares the ground for learning. The statistical problem in learning is to determine whether a compound event such as \u201cC followed by u\u201d is a random co-occurrence or a significant association, for if it is the former it would bea mistake to pay any particular attention to C. whereas ifit is the latter C is a conditional stimulus for U and a useful predictor for it. Now you cannot decide whether the association is random or not without knowledge of the prior probabilities of C and U: hence on my hypotbeais when you perceive an object or event the representation must not only signal \u201cit\u2019s there\u201d or \u201cit\u2019s happened\u201d, but must also make evident (or rapidly accessible) the prior probability of what has been signalled. Furthermore it must do this for all the objects or events that can act as conditional stimuli, and this implies that the representative elements should be statistically independent (or approximately so) in the normal enviromnent. Forms of coding that would do this, and the relationship with Helmholtx\u2019s unconsicous inference, will be discussed. These considerations imply that the task performed in perception has been overlooked both by learning theorists and by connectionists working on associative and adaptive networks. Coding for independence may be particularly important in understanding the developmental process during the sensitive period: it may be the operation that leads ontogenetically-timed, activity-dependent, connections to imprint appropriate codes if the animal has experience, but inappropriate codes without experience. Coding Conditioning Cortex Representation Sensitive period Inference Hehnholtx Prior probability Perception THE RELATION OF PERCEPTION TO LEARNING I decided to talk on this topic with some trepidation because Gerald know8 his Helmholtz so much better than I do and does not, I suspect, trust a non-German speaker to get him right. However Helmholtz expressed himself with unrivalled clarity and the ideas I shall propose are directly descended from his well-argued proposal that percepts represent unconscious inferences, so I cannot avoid bringing him in and must risk Gerald\u2019s criticisms. My argument is, briefly, that to understand perception one must view it as a prologue to learning. Acquiring new knowledge of the world is among the most important things our brains do for us, and for most people at this meeting it is probably the most interesting thing it does. So I shall try out on you the idea that perception is the process of preparing a representation of the current sensory scene in a form that enables subsequent learning mechanisms to be versatile and reliable. I shall assume that learning is based on what we perceive, and that cerebral cortex is where the representation we perceive is computed, even though neither assumption is 100% certain McCormick, Lavond, Clark, Kettner, Rising and Thompson (198 1) and Yeo, Hardiman and Glickstein (1985) have shown that conditioning of the nictitating membrane response in the rabbit occurs in the cerebellum, and I am sure that many other forms of learning can occur without the learner consciously perceiving the sensory stimulus that is learnt. Nevertheless our perceptions certainly provide much of the information from which we learn and the cerebral cortex must create the representations used for this purpose. This is a sufficient basis for my argument, though one should be aware that other types of representation and learning do occur."
            },
            "slug": "CONDITIONS-FOR-VERSATILE-LEARNING-,-HELMHOLTZ-\u2019-S-,-Clark",
            "title": {
                "fragments": [],
                "text": "CONDITIONS FOR VERSATILE LEARNING , HELMHOLTZ \u2019 S UNCONSCIOUS INFERENCE , AND THE TASK OF PERCEPTION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126340"
                        ],
                        "name": "S. Miyake",
                        "slug": "S.-Miyake",
                        "structuredName": {
                            "firstName": "Sei",
                            "lastName": "Miyake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miyake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145214184"
                        ],
                        "name": "Takayuki Ito",
                        "slug": "Takayuki-Ito",
                        "structuredName": {
                            "firstName": "Takayuki",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takayuki Ito"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 316,
                                "start": 309
                            }
                        ],
                        "text": "Approaches that do build the layers by learning and are able to make a sufficient number of them (by starting with simple features) mostly design the parts by histogramming the local neighborhoods of parts of the previous layers [1] or by learning the neural weights based on the responses on previous layers [11, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8235461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71ea46c9266f5104f79ea27fdfb4c5686677695a",
            "isKey": false,
            "numCitedBy": 755,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A recognition with a large-scale network is simulated on a PDP-11/34 minicomputer and is shown to have a great capability for visual pattern recognition. The model consists of nine layers of cells. The authors demonstrate that the model can be trained to recognize handwritten Arabic numerals even with considerable deformations in shape. A learning-with-a-teacher process is used for the reinforcement of the modifiable synapses in the new large-scale model, instead of the learning-without-a-teacher process applied to a previous model. The authors focus on the mechanism for pattern recognition rather than that for self-organization."
            },
            "slug": "Neocognitron:-A-neural-network-model-for-a-of-Fukushima-Miyake",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A neural network model for a mechanism of visual pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A recognition with a large-scale network is simulated on a PDP-11/34 minicomputer and is shown to have a great capability for visual pattern recognition and can be trained to recognize handwritten Arabic numerals even with considerable deformations in shape."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144663088"
                        ],
                        "name": "E. Rolls",
                        "slug": "E.-Rolls",
                        "structuredName": {
                            "firstName": "Edmund",
                            "lastName": "Rolls",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rolls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145333301"
                        ],
                        "name": "G. Deco",
                        "slug": "G.-Deco",
                        "structuredName": {
                            "firstName": "Gustavo",
                            "lastName": "Deco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Deco"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 292
                            }
                        ],
                        "text": "Parts and their higher level combinations should be learned in an unsupervised manner (at least in the first stages of the hierarchy) in order to avoid hand-labelling of massive image data as well as to capture the regularities within the visual data as effectively and compactly as possible [3, 17, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "This is also consistent with the findings on biological systems [17]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "The importance of good representations in vision tasks has often been emphasized in literature [5, 17, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47074,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "3a2b6d523914aba26a46f6f5d5a1f976304793c9",
            "isKey": false,
            "numCitedBy": 538,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "PREFACE 1. Introduction 2. The primary visual cortex 3. Extrastriate visual areas 4. The parietal cortex 5. Inferior temporal cortical visual areas 6. Visual attentional mechanisms 7. Neural network models 8. Models of invariant object recognition 9. The cortical neurodynamics of visual attention - a model 10. Visual search: Attentional neurodynamics at work 11. A computational approach to the neuropsychology of visual attention 12. Outputs of visual processing 13. Principles and conclusions INTRODUCTION TO LINEAR ALGEBRA FOR NEURAL NETWORKS INFORMATION THEORY References Index"
            },
            "slug": "Computational-neuroscience-of-vision-Rolls-Deco",
            "title": {
                "fragments": [],
                "text": "Computational neuroscience of vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A computational approach to the neuropsychology of visual attention using neural network models and models of invariant object recognition as a model for this purpose is suggested."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 126
                            }
                        ],
                        "text": "To overcome the curse of large-scale recognition, some authors emphasized the need for indexable hierarchical representations [4, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 279
                            }
                        ],
                        "text": "Our main motivation for building a hierarchical visual representation is to enable fast indexing and matching of image features against hierarchically organized stored prototypes in order to avoid the computationally prohibitive linear search in the number of objects/categories [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 268
                            }
                        ],
                        "text": "Hierarchical systems build on simple features that fire densely on all objects and combine them into more complex entities that become sparser, thus achieving compact object representation, enabling fast and robust categorization with better generalization properties [4, 20, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 168
                            }
                        ],
                        "text": "In pursuit of a general categorization system capable of recognizing a vast number of object categories, a need for hierarchical structuring of information has emerged [21, 13, 4, 6, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multidimensional indexing for recognizing visual"
            },
            "venue": {
                "fragments": [],
                "text": "shapes. PAMI,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "This can be attained by the principles of composition [10], i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Composition systems"
            },
            "venue": {
                "fragments": [],
                "text": "Quarterly of App. Math., Vol. 60(Nb"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 115
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "The current state-of-the-art categorization methods predominantly build their representations on image patches [14, 22] or other highly discriminative features such as the SIFT [20]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual Classification by a Hierarchy of Extended Features"
            },
            "venue": {
                "fragments": [],
                "text": "Towards Category-Level Object Recognition. Springer-Verlag,"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "A number of hierarchical methods have confirmed the success of such representations in object categorization tasks [9, 19, 8, 2, 20, 11, 22, 18, 1, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Thus, positions of all parts in a certain image are downsampled by a factor f   1 and parts that are within a small radius of distance (relative to the size of the neighborhoods they cover) will not be considered to form a novel composition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual Classification by a Hierarchy of Extended Features. Towards Category-Level Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Visual Classification by a Hierarchy of Extended Features. Towards Category-Level Object Recognition"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 7,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Towards-Scalable-Representations-of-Object-Learning-Fidler-Leonardis/0f602c33b1762d57223c9f9656579f9d1dc2e30a?sort=total-citations"
}