{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7164862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3ac6aee145606abe44d1374d9550a378adf768c",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years many researchers have investigated the use of Markov random fields (MRFs) for computer vision. The computational complexity of the implementation has been a drawback of MRFs. In this paper we derive deterministic approximations to MRFs models. All the theoretical results are obtained in the framework of the mean field theory from statistical mechanics. Because we use MRFs models the mean field equations lead to parallel and iterative algorithms. One of the considered models for image reconstruction is shown to give in a natural way the graduate non-convexity algorithm proposed by Blake and Zisserman."
            },
            "slug": "Parallel-and-deterministic-algorithms-from-MRFs:-Geiger-Girosi",
            "title": {
                "fragments": [],
                "text": "Parallel and deterministic algorithms from MRFs: surface reconstruction and integration"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Deterministic approximations to MRFs models are derived and one of the considered models for image reconstruction is shown to give in a natural way the graduate non-convexity algorithm proposed by Blake and Zisserman."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143962909"
                        ],
                        "name": "A. Lumsdaine",
                        "slug": "A.-Lumsdaine",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lumsdaine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lumsdaine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47064862"
                        ],
                        "name": "J. Wyatt",
                        "slug": "J.-Wyatt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wyatt",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wyatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144961113"
                        ],
                        "name": "I. Elfadel",
                        "slug": "I.-Elfadel",
                        "structuredName": {
                            "firstName": "Ibrahim",
                            "lastName": "Elfadel",
                            "middleNames": [
                                "Abe",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Elfadel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 39388047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fe47dc9fe110641b701a93de0498603eec26d49",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Image smoothing and segmentation algorithms are frequently formulated as optimization problems. Linear and nonlinear (reciprocal)resistive networks have solutions characterized by an extremum principle. Thus, appropriately designed networks canautomatically solve certain smoothing and segmentation problems in robot vision. This paper considers switched linear resistive networks and nonlinear resistive networks for such tasks. Following [1] the latter network type is derived from the former via an intermediate stochastic formulation, and a new result relating the solution sets of the two is given for the \u201czero temperature\u201d limit. We then present simulation studies of several continuation methods that can be gracefully implemented in analog VLSI and that seem to give \u201cgood\u201d results for these nonconvex optimization problems."
            },
            "slug": "Nonlinear-analog-networks-for-image-smoothing-and-Lumsdaine-Wyatt",
            "title": {
                "fragments": [],
                "text": "Nonlinear analog networks for image smoothing and segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper considers switched linear resistsive networks and nonlinear resistive networks for such tasks and presents simulation studies of several continuation methods that can be gracefully implemented in analog VLSI and that seem to give \u201cgood\u201d results for these nonconvex optimization problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. VLSI Signal Process."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2630782"
                        ],
                        "name": "J. Marroqu\u00edn",
                        "slug": "J.-Marroqu\u00edn",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Marroqu\u00edn",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Marroqu\u00edn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689724"
                        ],
                        "name": "S. Mitter",
                        "slug": "S.-Mitter",
                        "structuredName": {
                            "firstName": "Sanjoy",
                            "lastName": "Mitter",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mitter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14692859,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "97c12f5ddfdf036eb6cf935a679d1e4ba2fe535f",
            "isKey": false,
            "numCitedBy": 865,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We formulate several problems in early vision as inverse problems. Among the solution methods we review standard regularization theory, discuss its limitations, and present new stochastic (in particular, Bayesian) techniques based on Markov Random Field models for their solution. We derive efficient algorithms and describe parallel implementations on digital parallel SIMD architectures, as well as a new class of parallel hybrid computers that mix digital with analog components."
            },
            "slug": "Probabilistic-Solution-of-Ill-Posed-Problems-in-Marroqu\u00edn-Mitter",
            "title": {
                "fragments": [],
                "text": "Probabilistic Solution of Ill-Posed Problems in Computational Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work derives efficient algorithms and describes parallel implementations on digital parallel SIMD architectures, as well as a new class of parallel hybrid computers that mix digital with analog components."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32015263"
                        ],
                        "name": "E. Gamble",
                        "slug": "E.-Gamble",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Gamble",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gamble"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42814147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef58fc904a36dccf7e6b7f663126c0690d7c9edb",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "It is assumed that a major goal of the early vision modules and their integration is to deliver a cartoon of the discontinuities in the scene and to label them in terms of their physical origin. The output of each of the vision modules is noisy, possibly sparse, and sometimes not unique. The authors suggest the use of a coupled Markov random field (MRF) at the output of each module (image cues)-stereo, motion, color, and texture-to achieve two goals: first, to counteract the noise and fill in sparse data, and secondly, to integrate the image within each MRF to find the module discontinuities and align them with the intensity edges. The authors outline a theory of how to label the discontinuities in terms of depth, orientation, albedo, illumination, and specular discontinuities. They present labeling results using a simple linear classifier operating on the output of the MRF associated with each vision module and coupled to the image data. The classifier has been trained on a small set of a mixture of synthetic and real data. >"
            },
            "slug": "Integration-of-vision-modules-and-labeling-of-Gamble-Geiger",
            "title": {
                "fragments": [],
                "text": "Integration of vision modules and labeling of surface discontinuities"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors suggest the use of a coupled Markov random field at the output of each module (image cues) to achieve two goals: first, to counteract the noise and fill in sparse data, and secondly, to integrate the image within each MRF to find the module discontinuities and align them with the intensity edges."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107819038"
                        ],
                        "name": "J. G. Harris",
                        "slug": "J.-G.-Harris",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107197750"
                        ],
                        "name": "J. Luo",
                        "slug": "J.-Luo",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Luo",
                            "middleNames": [
                                "X"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Luo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35782922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7c8b66f580ff84f64a5828bd9d6c058c3588775",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A large number of computer vision algorithms for finding intensity edges, computing motion, depth, and color, and recovering the three-dimensional shape of objects have been developed within the framework of minimizing an associated \"energy\" or \"cost\" functional. Particularly successful has been the introduction of binary variables coding for discontinuities in intensity, optical flow field, depth, and other variables, allowing image segmentation to occur in these modalities. The associated nonconvex variational functionals can be mapped onto analog, resistive networks, such that the stationary voltage distribution in the network corresponds to a minimum of the functional. The performance of an experimental analog very-large-scale integration (VLSI) circuit implementing the nonlinear resistive network for the problem of two-dimensional surface interpolation in the presence of discontinuities is demonstrated; this circuit is implemented in complementary metal oxide semiconductor technology."
            },
            "slug": "A-two-dimensional-analog-VLSI-circuit-for-detecting-Harris-Koch",
            "title": {
                "fragments": [],
                "text": "A two-dimensional analog VLSI circuit for detecting discontinuities in early vision."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The performance of an experimental analog very-large-scale integration (VLSI) circuit implementing the nonlinear resistive network for the problem of two-dimensional surface interpolation in the presence of discontinuities is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18709,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46933679"
                        ],
                        "name": "M. Bertero",
                        "slug": "M.-Bertero",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Bertero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bertero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145730991"
                        ],
                        "name": "V. Torre",
                        "slug": "V.-Torre",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Torre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Torre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14285485,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "31b5a06273e75f159d5d9e42bc5bdfd7fd4b625e",
            "isKey": false,
            "numCitedBy": 855,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Mathematical results on ill-posed and ill-conditioned problems are reviewed and the formal aspects of regularization theory in the linear case are introduced. Specific topics in early vision and their regularization are then analyzed rigorously, characterizing existence, uniqueness, and stability of solutions. A fundamental difficulty that arises in almost every vision problem is scale, that is, the resolution at which to operate. Methods that have been proposed to deal with the problem include scale-space techniques that consider the behavior of the result across a continuum of scales. From the point of view of regulation theory, the concept of scale is related quite directly to the regularization parameter lambda . It suggested that methods used to obtained the optimal value of lambda may provide, either directly or after suitable modification, the optimal scale associated with the specific instance of certain problems. >"
            },
            "slug": "Ill-posed-problems-in-early-vision-Bertero-Poggio",
            "title": {
                "fragments": [],
                "text": "Ill-posed problems in early vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119706616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cbd5a66c1198d5a14f13e03483b69321024444b",
            "isKey": false,
            "numCitedBy": 1030,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The problem of detecting intensity changes in images is canonical in vision. Edge detection operators are typically designed to optimally estimate first or second derivative over some (usually small) support. Other criteria such as output signal to noise ratio or bandwidth have also been been argued for. This thesis is an attempt to formulate a set of edge detection criteria that capture as directly as possible the desirable properties of an edge operator. Variational techniques are used to find a solution over the space of all linear shift invariant operators. The first criterion is that the detector have low probability of error i.e. failing to mark edges or falsely marking non-edges. The second is that the marked points should b The third criterion is that there should be low probability of more than one response to a single edge. The technique is used to find optimal operators for step edges and for extended impulse profiles (ridges or valleys in two dimensions). The extension of the one dimensional operators to two dimensions is then discussed. The result is a set of operators of varying width, length and orientation. The problem of combining these outputs into a single description is discussed, and a set of heuristics for the integration are given. (Author)"
            },
            "slug": "Finding-Edges-and-Lines-in-Images-Canny",
            "title": {
                "fragments": [],
                "text": "Finding Edges and Lines in Images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This thesis is an attempt to formulate a set of edge detection criteria that capture as directly as possible the desirable properties of an edge operator."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5997639,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "891788374b453d082d96a4d17aa5a4f015c4f42f",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Many problems in early vision are ill posed. Edge detection is a typical example. This paper applies regularization techniques to the problem of edge detection. We derive an optimal filter for edge detection with a size controlled by the regularization parameter $\\lambda $ and compare it to the Gaussian filter. A formula relating the signal-to-noise ratio to the parameter $\\lambda $ is derived from regularization analysis for the case of small values of $\\lambda$. We also discuss the method of Generalized Cross Validation for obtaining the optimal filter scale. Finally, we use our framework to explain two perceptual phenomena: coarsely quantized images becoming recognizable by either blurring or adding noise."
            },
            "slug": "An-Optimal-Scale-for-Edge-Detection-Geiger-Poggio",
            "title": {
                "fragments": [],
                "text": "An Optimal Scale for Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "An optimal filter for edge detection with a size controlled by the regularization parameter $\\lambda $ is derived and compared to the Gaussian filter and a formula relating the signal-to-noise ratio to the parameters is derived from regularization analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2630782"
                        ],
                        "name": "J. Marroqu\u00edn",
                        "slug": "J.-Marroqu\u00edn",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Marroqu\u00edn",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Marroqu\u00edn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18701248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c0f7d514a38f64a9022b392b9f460dff3aeaa00",
            "isKey": false,
            "numCitedBy": 321,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Many problems in early vision can be formulated in terms of minimizing a cost function. Examples are shape from shading, edge detection, motion analysis, structure from motion, and surface interpolation. As shown by Poggio and Koch [Poggio, T. & Koch, C. (1985) Proc. R. Soc. London, Ser. B 226, 303-323], quadratic variational problems, an important subset of early vision tasks, can be \"solved\" by linear, analog electrical, or chemical networks. However, in the presence of discontinuities, the cost function is nonquadratic, raising the question of designing efficient algorithms for computing the optimal solution. Recently, Hopfield and Tank [Hopfield, J. J. & Tank, D. W. (1985) Biol. Cybern. 52, 141-152] have shown that networks of nonlinear analog \"neurons\" can be effective in computing the solution of optimization problems. We show how these networks can be generalized to solve the nonconvex energy functionals of early vision. We illustrate this approach by implementing a specific analog network, solving the problem of reconstructing a smooth surface from sparse data while preserving its discontinuities. These results suggest a novel computational strategy for solving early vision problems in both biological and real-time artificial vision systems."
            },
            "slug": "Analog-\"neuronal\"-networks-in-early-vision.-Koch-Marroqu\u00edn",
            "title": {
                "fragments": [],
                "text": "Analog \"neuronal\" networks in early vision."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work illustrates this approach by implementing a specific analog network, solving the problem of reconstructing a smooth surface from sparse data while preserving its discontinuities, and suggests a novel computational strategy for solving early vision problems in both biological and real-time artificial vision systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32015263"
                        ],
                        "name": "E. Gamble",
                        "slug": "E.-Gamble",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Gamble",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gamble"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119850114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e961c869a382e61b5500d3fce7cae9f72a3ad237",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Integration of several vision modules is likely to be one of the keys to the power and robustness of the human visual system. We suggest that integration is best performed at the location of discontinuities in early processes, such as discontinuities in image brightness, depth, motion, texture, and color. Coupled Markov Random Field models can be used to combine vision modalities with their discontinuities. We derive a scheme to integrate intensity edges with stereo depth and motion field information and show results from a Connection Machine algorithm on synthetic and natural images. The use of intensity edges to integrate other visual cues and to help discover discontinuities emerges as a general and powerful principle."
            },
            "slug": "Visual-Integration-and-Detection-of-The-Key-Role-of-Gamble-Poggio",
            "title": {
                "fragments": [],
                "text": "Visual Integration and Detection of Discontinuities: The Key Role of Intensity Edges"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A scheme to integrate intensity edges with stereo depth and motion field information and results from a Connection Machine algorithm are shown, showing the use of intensity edges to integrate other visual cues and to help discover discontinuities emerges as a general and powerful principle."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076400"
                        ],
                        "name": "B. Caprile",
                        "slug": "B.-Caprile",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Caprile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caprile"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116974959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6759d5352ae6039a3117b49ec95cb7adf183855",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning an input-output mapping from a set of examples can be regarded as synthesizing an approximation of a multi-dimensional function. From this point of view, this form of learning is closely related to regularization theory. In this note, we extend the theory by introducing ways of dealing with two aspects of learning: learning in the presence of unreliable examples and learning from positive {\\it and} negative examples. The first extension corresponds to dealing with outliers among the sparse data. The second one corresponds to exploiting information about points or regions in the range of the function that are forbidden."
            },
            "slug": "Extensions-of-a-Theory-of-Networks-and-Learning:-Poggio-Girosi",
            "title": {
                "fragments": [],
                "text": "Extensions of a Theory of Networks and Learning: Outliers and Negative Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The theory of input-output mapping from a set of examples is extended by introducing ways of dealing with two aspects of learning: learning in the presence of unreliable examples and learning from positive {\\it and} negative examples."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145847131"
                        ],
                        "name": "S. Kirkpatrick",
                        "slug": "S.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5882723"
                        ],
                        "name": "C. D. Gelatt",
                        "slug": "C.-D.-Gelatt",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gelatt",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Gelatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88645967"
                        ],
                        "name": "M. Vecchi",
                        "slug": "M.-Vecchi",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Vecchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vecchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205939,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dd5061631a4d11fa394f4421700ebf7e78dcbc59",
            "isKey": false,
            "numCitedBy": 39637,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods."
            },
            "slug": "Optimization-by-Simulated-Annealing-Kirkpatrick-Gelatt",
            "title": {
                "fragments": [],
                "text": "Optimization by Simulated Annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32922277"
                        ],
                        "name": "N. Metropolis",
                        "slug": "N.-Metropolis",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Metropolis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Metropolis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91743329"
                        ],
                        "name": "A. W. Rosenbluth",
                        "slug": "A.-W.-Rosenbluth",
                        "structuredName": {
                            "firstName": "Arianna",
                            "lastName": "Rosenbluth",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. W. Rosenbluth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2991661"
                        ],
                        "name": "M. Rosenbluth",
                        "slug": "M.-Rosenbluth",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Rosenbluth",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosenbluth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46516796"
                        ],
                        "name": "A. H. Teller",
                        "slug": "A.-H.-Teller",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Teller",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. H. Teller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3840350"
                        ],
                        "name": "E. Teller",
                        "slug": "E.-Teller",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Teller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Teller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1046577,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f6a13f116e270dde9d67848495f801cdb8efa25d",
            "isKey": false,
            "numCitedBy": 32413,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. The method consists of a modified Monte Carlo integration over configuration space. Results for the two\u2010dimensional rigid\u2010sphere system have been obtained on the Los Alamos MANIAC and are presented here. These results are compared to the free volume equation of state and to a four\u2010term virial coefficient expansion."
            },
            "slug": "Equation-of-state-calculations-by-fast-computing-Metropolis-Rosenbluth",
            "title": {
                "fragments": [],
                "text": "Equation of state calculations by fast computing machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145733439"
                        ],
                        "name": "G. Wahba",
                        "slug": "G.-Wahba",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Wahba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wahba"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122703854,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "ae62ecdc61198743267f3756ad54001e150df453",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider approximate solutions $f_{n,\\lambda } $ to linear operator equations $\\mathcal{K}f = g$, of the form: $f_{n,\\lambda } $ is the minimizer in $\\mathcal{H}$ of $({1 / n})\\sum _{j = 1}^n {[(\\mathcal{K}h)(t_j ) - y(t_j )]} ^2 + \\lambda \\| h \\|^2 $, where $\\mathcal{H}$ is a Hilbert space, and the data $\\{ {y(t_j )} \\}$ satisfy $y(t_j ) = g(t_j ) + \\varepsilon (t_j )$, the $\\{ {\\varepsilon (t_j )} \\}$ being measurement errors. $f_{n,\\lambda } $ is the so-called regularized solution, and $\\lambda > 0$ is the regularization parameter, to be chosen. It is important to choose $\\lambda $ correctly. The purpose of this paper is to propose the method of weighted cross-validation for choosing $\\lambda $from the data. We suppose that g is very smooth and the errors are white noise. It is shown that the weighted cross-validation estimate $\\hat \\lambda $ estimates the value of $\\lambda $ which minimizes $({1 / n})E\\sum\\nolimits_{j = 1}^n {[(\\mathcal{K}f_{n,\\lambda } )(t_j ) - (\\mathcal{K}f)(t_j )]} ^2 $ . Resul..."
            },
            "slug": "Practical-Approximate-Solutions-to-Linear-Operator-Wahba",
            "title": {
                "fragments": [],
                "text": "Practical Approximate Solutions to Linear Operator Equations When the Data are Noisy"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that the weighted cross-validation estimate of $\\hat \\lambda $ estimates the value of $\\lambda $ which minimizes $({1 / n) E\\sum\\nolimits_{j = 1}^n {[(\\mathcal{K}f_{n,\\lambda } )(t_j ) - (\\mathcal(K)f)(t-j )]} ^2 $ ."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143639508"
                        ],
                        "name": "A. Tikhonov",
                        "slug": "A.-Tikhonov",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Tikhonov",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tikhonov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102992139"
                        ],
                        "name": "Vasiliy Yakovlevich Arsenin",
                        "slug": "Vasiliy-Yakovlevich-Arsenin",
                        "structuredName": {
                            "firstName": "Vasiliy",
                            "lastName": "Arsenin",
                            "middleNames": [
                                "Yakovlevich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasiliy Yakovlevich Arsenin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122072756,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bc14819e745cd7af37efd09ea29773dc0065119e",
            "isKey": false,
            "numCitedBy": 7884,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Solutions-of-ill-posed-problems-Tikhonov-Arsenin",
            "title": {
                "fragments": [],
                "text": "Solutions of ill-posed problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26705393,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "efadad5b0d52daa3b31b26f0b988bda73ec0e923",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiresolution-computation-of-visible-surface-Terzopoulos",
            "title": {
                "fragments": [],
                "text": "Multiresolution computation of visible-surface representations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13115760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "048e3a0904f7d964a0ade5da031a585dadc5a92f",
            "isKey": false,
            "numCitedBy": 1908,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Visual-Reconstruction-Blake-Zisserman",
            "title": {
                "fragments": [],
                "text": "Visual Reconstruction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Parallel-and-Deterministic-Algorithms-from-MRFs:-Geiger-Girosi/8d5a193fdbf9d34118f136935cfd07a81b3e0d77?sort=total-citations"
}