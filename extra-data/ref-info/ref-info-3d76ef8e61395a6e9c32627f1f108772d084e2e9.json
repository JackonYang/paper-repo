{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Face detection, Pattern recognition, Computer vision, Artificial neural networks, Machine learning"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16932868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e2f29d26f31846d6e0294cfa3733adfc618bbb",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-based-human-face-detection-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Feature-based human face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783224"
                        ],
                        "name": "A. Colmenarez",
                        "slug": "A.-Colmenarez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Colmenarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Colmenarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "In recent work, Colmenarez and Huang presented a statistically based method for face detection [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 84
                            }
                        ],
                        "text": "These images can be characterized by probabilistic models of the set of face images [4,13,15], or implicitly by neural networks or other mechanisms [3,12,14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9192390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e744c3eef4fbc4ac52b2458eb2d545a4432bcb86",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a visual learning technique that maximizes the discrimination between positive and negative examples in a training set. We demonstrate our technique in the context of face detection with complex background without color or motion information, which has proven to be a challenging problem. We use a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics. Then, we convert the learning process into an optimization, selecting the Markov process that optimizes the information-based discrimination between the two classes. The detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure. We show that because of the discrete nature of these models, the detection process is at least two orders of magnitude less computationally expensive than neural network approaches. However, no improvement in terms of correct-answer/false-alarm tradeoff is achieved."
            },
            "slug": "Face-detection-with-information-based-maximum-Colmenarez-Huang",
            "title": {
                "fragments": [],
                "text": "Face detection with information-based maximum discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A visual learning technique that maximizes the discrimination between positive and negative examples in a training set by using a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17594951,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "ca5a2525715ee55f9f99f2144fb5a3d2772460b1",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extending upright, frontal, template-based face detection systems to e ciently handle all in-plane rotations. Detecting rotated faces is a two step procedure. First a \\DeRotation\" network is used to process each input window. If there is a face in the window, this network determines its angle of rotation. Based upon this estimated angle of rotation, the window is then rotated to an upright position. Second, a \\Detection\" network, or multiple detection networks, are used to determine whether the rotated window contained an upright face. The training methods for both networks are presented. Preliminary empirical results are also provided."
            },
            "slug": "Face-Detection-with-In-Plane-Rotation:-Early-and-Baluja",
            "title": {
                "fragments": [],
                "text": "Face Detection with In-Plane Rotation: Early Concepts and Preliminary Results"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A method for extending upright, frontal, template-based face detection systems to e ciently handle all in-plane rotations and training methods for both networks are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6344581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da129d0b34eb13d8ba386e36bb82df77da7ea8f",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Human face detection has always been an important problem for face, expression and gesture recognition. Though numerous attempts have been made to detect and localize faces, these approaches have made assumptions that restrict their extension to more general cases. In this research, we propose a feature-based face detection algorithm that can be easily extended to detect faces under diierent scale and orientation. Feature points are detected from the image using spatial lters and grouped into face candidates using geometric and gray level constraints. A probabilistic framework is then used to evaluate the likelihood of the candidate as a face. We provide results to support the validity of the approach, and show that the algorithm can indeed cope eeciently with faces at diierent scale and orientation."
            },
            "slug": "Scale-and-Orientation-Invariance-in-Human-Face-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Scale and Orientation Invariance in Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This research proposes a feature-based face detection algorithm that can be easily extended to detect faces under diierent scale and orientation, and provides results to support the validity of the approach, and shows that the algorithm can indeed cope eeciently with faces at diiesrent Scale and orientation."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47128406"
                        ],
                        "name": "Shang-Hung Lin",
                        "slug": "Shang-Hung-Lin",
                        "structuredName": {
                            "firstName": "Shang-Hung",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shang-Hung Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144410963"
                        ],
                        "name": "S. Kung",
                        "slug": "S.-Kung",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kung",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111062938"
                        ],
                        "name": "Long-Ji Lin",
                        "slug": "Long-Ji-Lin",
                        "structuredName": {
                            "firstName": "Long-Ji",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long-Ji Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Face detection, Pattern recognition, Computer vision, Artificial neural networks, Machine learning"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24636915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa2603efaf717974c77162c93d800defae61a129",
            "isKey": false,
            "numCitedBy": 669,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a face recognition system, based on probabilistic decision-based neural networks (PDBNN). With technological advance on microelectronic and vision system, high performance automatic techniques on biometric recognition are now becoming economically feasible. Among all the biometric identification methods, face recognition has attracted much attention in recent years because it has potential to be most nonintrusive and user-friendly. The PDBNN face recognition system consists of three modules: First, a face detector finds the location of a human face in an image. Then an eye localizer determines the positions of both eyes in order to generate meaningful feature vectors. The facial region proposed contains eyebrows, eyes, and nose, but excluding mouth (eye-glasses will be allowed). Lastly, the third module is a face recognizer. The PDBNN can be effectively applied to all the three modules. It adopts a hierarchical network structures with nonlinear basis functions and a competitive credit-assignment scheme. The paper demonstrates a successful application of PDBNN to face recognition applications on two public (FERET and ORL) and one in-house (SCR) databases. Regarding the performance, experimental results on three different databases such as recognition accuracies as well as false rejection and false acceptance rates are elaborated. As to the processing speed, the whole recognition process (including PDBNN processing for eye localization, feature extraction, and classification) consumes approximately one second on Sparc10, without using hardware accelerator or co-processor."
            },
            "slug": "Face-recognition/detection-by-probabilistic-neural-Lin-Kung",
            "title": {
                "fragments": [],
                "text": "Face recognition/detection by probabilistic decision-based neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The paper demonstrates a successful application of PDBNN to face recognition applications on two public (FERET and ORL) and one in-house (SCR) databases and experimental results on three different databases such as recognition accuracies as well as false rejection and false acceptance rates are elaborated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48636477"
                        ],
                        "name": "G. Yang",
                        "slug": "G.-Yang",
                        "structuredName": {
                            "firstName": "Guangzheng",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38060615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bb1ba70d48561ce8c3fbf59739fabc95e7b3d50",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-face-detection-in-a-complex-background-Yang-Huang",
            "title": {
                "fragments": [],
                "text": "Human face detection in a complex background"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121032587"
                        ],
                        "name": "H. M. Hunke",
                        "slug": "H.-M.-Hunke",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Hunke",
                            "middleNames": [
                                "Martin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M. Hunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58720836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09d1977832e0181ce3b3f28d46016cbf8887cc38",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "E ective Human{to{Human communication involves both auditory and visual modalities, providing robustness and naturalness in realistic communication situations. Recent e orts at our lab are aimed at providing such multimodal capabilities for human-machine communication as well by introducing gesture, character and speech recognition, eye-tracking and lipreading. Most of the visual modalities require a stable image of a speaker's face. In this technical report a connectionist face tracker is proposed that manipulates camera orientation and zoom, to keep a person's face located at all times in an image sequence. The system operates in real time and can adapt rapidly to di erent lighting conditions, di erent cameras and faces, making it robust against environmental variability. Extensions and integration of the system with a multimodal interface will be presented."
            },
            "slug": "Locating-and-Tracking-of-Human-Faces-with-Neural-Hunke",
            "title": {
                "fragments": [],
                "text": "Locating and Tracking of Human Faces with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A connectionist face tracker is proposed that manipulates camera orientation and zoom, to keep a person's face located at all times in an image sequence, making it robust against environmental variability."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118541653"
                        ],
                        "name": "Ming Zhang",
                        "slug": "Ming-Zhang",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144729846"
                        ],
                        "name": "J. Fulcher",
                        "slug": "J.-Fulcher",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Fulcher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fulcher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 137
                            }
                        ],
                        "text": "A pose estimator is responsible for directing the input window to one of these view-specific detectors, similar to the idea presented in [Zhang and Fulcher, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26219891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63d17193cd70ada36c9ee192607d5b4f227d7212",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent artificial neural network research has focused on simple models, but such models have not been very successful in describing complex systems (such as face recognition). This paper introduces the artificial neural network group-based adaptive tolerance (GAT) tree model for translation-invariant face recognition, suitable for use in an airport security system. GAT trees use a two-stage divide-and-conquer tree-type approach. The first stage determines general properties of the input, such as whether the facial image contains glasses or a beard. The second stage identifies the individual. Face perception classification, detection of front faces with glasses and/or beards, and face recognition results using GAT trees under laboratory conditions are presented. We conclude that the neural network group-based model offers significant improvement over conventional neural network trees for this task."
            },
            "slug": "Face-recognition-using-artificial-neural-network-Zhang-Fulcher",
            "title": {
                "fragments": [],
                "text": "Face recognition using artificial neural network group-based adaptive tolerance (GAT) trees"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The artificial neural network group-based adaptive tolerance (GAT) tree model for translation-invariant face recognition, suitable for use in an airport security system, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147984118"
                        ],
                        "name": "R. Vaillant",
                        "slug": "R.-Vaillant",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "These images can be characterized by probabilistic models of the set of face images [4], [13], [15] or implicitly by neural networks or other mechanisms [3], [12], [14], [19], [21], [23], [25], [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "The candidate verification process used to speed up our system, described in Section 4, is similar to the detection technique presented in [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16690291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc7fa2cf9d7d2b3aca4fa22271412831e9a61e22",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents an algorithm for the detection of faces in images using shared-weight replicated neural networks. A neural net forms rough hypotheses about the position of faces. These hypotheses are then verified using a second neural network. The algorithm applies to images where the size of the faces is unknown a priori. The computational time which is necessary for the complete processing of an image is reasonable. With a classical workstation an image of size 512*512 is treated in 50 seconds including smoothing and normalization of the image. This algorithm can be easily installed on a more specialized machine as the major part of the operation is based on convolutions with kernels of size 5*5 or 8*8. In this paper, the authors assume that the face are well oriented in the image. It is possible to eliminate this assumption by following an approach similar to the one used for the scale problem. A net is trained to be insensitive to the precise orientation of the face. This kind of segmentation algorithm can be applied to other problems where the objects to be detected cannot be characterized easily by its outline or by classical primitives in image processing."
            },
            "slug": "An-original-approach-for-the-localization-of-in-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "An original approach for the localization of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for the detection of faces in images using shared-weight replicated neural networks, trained to be insensitive to the precise orientation of the face by following an approach similar to the one used for the scale problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 155
                            }
                        ],
                        "text": "A few authors have taken the approach of extracting fe a ures and applying either manually or automatically generated rules for evaluating t hese features [7,11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2904067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d50d0e2af0b45cc7ed25fe4aa97af900c9bd32a",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally.<<ETX>>"
            },
            "slug": "Finding-faces-in-cluttered-scenes-using-random-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding faces in cluttered scenes using random labeled graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented and it is found that it is invariant with respect to translation, rotation, and scale and can handle partial occlusions of the face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10223132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c27487c3e0894b65e976a287e6f8c9aa40f089c",
            "isKey": false,
            "numCitedBy": 2132,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from Lades et al. (1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs."
            },
            "slug": "Face-recognition-by-elastic-bunch-graph-matching-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face recognition by elastic bunch graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, based on a Gabor wavelet transform, which differs from Lades et al. (1993) in three respects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 497801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "791e530f6a4098bb39696d1476032821a7a1c569",
            "isKey": false,
            "numCitedBy": 2330,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1199 individuals are included in the FERET database, which is divided into development and sequestered portions. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to (1) assess the state of the art, (2) identify future areas of research, and (3) measure algorithm performance on large databases."
            },
            "slug": "The-FERET-evaluation-methodology-for-algorithms-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET evaluation methodology for face-recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40302807"
                        ],
                        "name": "G. Gordon",
                        "slug": "G.-Gordon",
                        "structuredName": {
                            "firstName": "Gaile",
                            "lastName": "Gordon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143833523"
                        ],
                        "name": "M. Harville",
                        "slug": "M.-Harville",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Harville",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Harville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803592"
                        ],
                        "name": "J. Woodfill",
                        "slug": "J.-Woodfill",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Woodfill",
                            "middleNames": [
                                "Iselin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Woodfill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10236323,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43000bd6b1cc93c47fb6860cab71fe0dfafd73ad",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to real-time person tracking in crowded and/or unknown environments using integration of multiple visual modalities. We combine stereo, color, and face detection modules into a single robust system, and show an initial application in an interactive, face-responsive display. Dense, real-time stereo processing is used to isolate users from other objects and people in the background. Skin-hue classification identifies and tracks likely body parts within the silhouette of a user. Face pattern detection discriminates and localizes the face within the identified body parts. Faces and bodies of users are tracked over several temporal scales: short-term (user stays within the field of view), medium-term (user exits/reenters within minutes), and long term (user returns after hours or days). Short-term tracking is performed using simple region position and size correspondences, while medium and long-term tracking are based on statistics of user appearance. We discuss the failure modes of each individual module, describe our integration method, and report results with the complete system in trials with thousands of users."
            },
            "slug": "Integrated-Person-Tracking-Using-Stereo,-Color,-and-Darrell-Gordon",
            "title": {
                "fragments": [],
                "text": "Integrated Person Tracking Using Stereo, Color, and Pattern Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work combines stereo, color, and face detection modules into a single robust system, shows an initial application in an interactive, face-responsive display, and discusses the failure modes of each individual module."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17779599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc8b25e35a3acb812beb499844734081722319b4",
            "isKey": false,
            "numCitedBy": 2398,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-FERET-database-and-evaluation-procedure-for-Phillips-Wechsler",
            "title": {
                "fragments": [],
                "text": "The FERET database and evaluation procedure for face-recognition algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050470845"
                        ],
                        "name": "H. Drucker",
                        "slug": "H.-Drucker",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Drucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33515643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "843ffb9898cedf899ddcdb9c4bdd10881c122429",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A boosting algorithm, based on the probably approximately correct (PAC) learning model is used to construct an ensemble of neural networks that significantly improves performance (compared to a single network) in optical character recognition (OCR) problems. The effect of boosting is reported on four handwritten image databases consisting of 12000 digits from segmented ZIP Codes from the United States Postal Service and the following from the National Institute of Standards and Technology: 220000 digits, 45000 upper case letters, and 45000 lower case letters. We use two performance measures: the raw error rate (no rejects) and the reject rate required to achieve a 1% error rate on the patterns not rejected. Boosting improved performance significantly, and, in some cases, dramatically."
            },
            "slug": "Boosting-Performance-in-Neural-Networks-Drucker-Schapire",
            "title": {
                "fragments": [],
                "text": "Boosting Performance in Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The boosting algorithm is used to construct an ensemble of neural networks that significantly improves performance (compared to a single network) in optical character recognition (OCR) problems and improved performance significantly, and, in some cases, dramatically."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144075899"
                        ],
                        "name": "Tanzeem Choudhury",
                        "slug": "Tanzeem-Choudhury",
                        "structuredName": {
                            "firstName": "Tanzeem",
                            "lastName": "Choudhury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanzeem Choudhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46978775"
                        ],
                        "name": "B. Clarkson",
                        "slug": "B.-Clarkson",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Clarkson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Clarkson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116449956"
                        ],
                        "name": "Alex Pentland Perceptual",
                        "slug": "Alex-Pentland-Perceptual",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Perceptual",
                            "middleNames": [
                                "Pentland"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Pentland Perceptual"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 967395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "670b164d4587ab0cacd6b5aed62acf5473559a83",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a person identi cation technique that can recognize and verify people from unconstrained video and audio. We do not expect fully frontal face image or clean speech as our input. Our recognition algorithm can detect and compensate for pose variation and changes in the auditory background and also select the most reliable video frame and audio clip to use for recognition. We also use 3D depth information of a human head to detect the presence of an actual person as opposed to an image of that person. Our system achieves 100% recognition and veri cation rates on natural real-time input with 26 registered clients."
            },
            "slug": "Multimodal-person-recognition-using-unconstrained-Choudhury-Clarkson",
            "title": {
                "fragments": [],
                "text": "Multimodal person recognition using unconstrained audio and video"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work proposes a person identification technique that can recognize and verify people from unconstrained video and audio and achieves 100% recognition and veri cation rates on natural real-time input with 26 registered clients."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772332"
                        ],
                        "name": "L. Neiberg",
                        "slug": "L.-Neiberg",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Neiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Neiberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34925745"
                        ],
                        "name": "D. Casasent",
                        "slug": "D.-Casasent",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Casasent",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casasent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48235382"
                        ],
                        "name": "R. Fontana",
                        "slug": "R.-Fontana",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fontana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fontana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117715815"
                        ],
                        "name": "J. E. Cade",
                        "slug": "J.-E.-Cade",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Cade",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. E. Cade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62165996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7bf7663100a2a656f66f9c51d81e7f774402c1d",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel neural network for distortion-invariant pattern recognition is described. Image regions of interest are determined using a detection stage, each region is then enhanced (the steps used are detailed), features are extracted (new Gabor wavelet features are used), and these features are used to classify the contents of each input region. A new feature space trajectory neural network (FST NN) classifier is used. A new 8 class database is used, a new multilayer NN to calculate the distance measures necessary is detailed, its low storage and on-line computational load requirements are noted. The ability of the adaptive FST algorithm to reduce network complexity while achieving excellent performance is demonstrated. The clutter rejection ability of this neural network to reject false alarm inputs is demonstrated, and time-history processing to further reduce false alarms is discussed. Hardware and commercial realizations are noted."
            },
            "slug": "Feature-space-trajectory-neural-net-classifier:-Neiberg-Casasent",
            "title": {
                "fragments": [],
                "text": "Feature space trajectory neural net classifier: 8-class distortion-invariant tests"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The ability of the adaptive FST algorithm to reduce network complexity while achieving excellent performance is demonstrated and the clutter rejection ability of this neural network to reject false alarm inputs is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 219
                            }
                        ],
                        "text": "As with Sung and Poggio\u2019s work, Moghoddam and Pentland\u2019s approach uses a two component distance measure, but combines the two distances in a principled way based on the assumption that the distribution of each cluster is Gaussian [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 85
                            }
                        ],
                        "text": "These images can be characteri zed by probabilistic models of the set of face images [4,13,15], or implicitly by neural networks or other mechanism s [3,12,14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] Baback Moghaddam and Alex Pentland."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "As with Sung and Poggio\u2019s work, Moghoddam and Pentland\u2019s approach uses a two component distance measure, but combines the two distances in a principled way based on t h assumption that the distribution of each cluster is Gaussian [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "The clusters are used together as a multi-modal Gaussian distribution, giving a probability distribution for all face images."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9242811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6",
            "isKey": true,
            "numCitedBy": 461,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands.<<ETX>>"
            },
            "slug": "Probabilistic-visual-learning-for-object-detection-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and a multivariate Mixture-of-Gaussians model is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1154755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "002aaf4412f91d0828b79511f35c0863a1a32c47",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a real-time face tracker. The system has achieved a rate of 30+ frames/second using an HP-9000 workstation with a frame grabber and a Canon VC-Cl camera. It can track a person's face while the person moves freely (e.g., walks, jumps, sits down and stands up) in a room. Three types of models have been employed in developing the system. First, they present a stochastic model to characterize skin color distributions of human faces. The information provided by the model is sufficient for tracking a human face in various poses and views. This model is adaptable to different people and different lighting conditions in real-time. Second, a motion model is used to estimate image motion and to predict the search window. Third, a camera model is used to predict and compensate for camera motion. The system can be applied to teleconferencing and many HCI applications including lip reading and gaze tracking. The principle in developing this system can be extended to other tracking problems such as tracking the human hand."
            },
            "slug": "A-real-time-face-tracker-Yang-Waibel",
            "title": {
                "fragments": [],
                "text": "A real-time face tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The authors present a real-time face tracker that can track a person's face while the person moves freely in a room and can be applied to teleconferencing and many HCI applications including lip reading and gaze tracking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE Workshop on Applications of Computer Vision. WACV'96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6150049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cef9b899297bee5b50cb7a15442b18ac01f58784",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Flexible models of object classes, based on linear combinations of prototypical images, are capable of matching novel images of the same class and have been shown to be a powerful tool to solve several fundamental vision tasks such as recognition, synthesis and correspondence. The key problem in creating a specific flexible model is the computation of pixelwise correspondence between the prototypes, a task done until now in a semiautomatic way. In this paper we describe an algorithm that automatically bootstraps the correspondence between the prototypes. The algorithm -which can be used for 2D images as well as for 3D models-is shown to synthesize successfully a flexible model of frontal face images and a flexible model of handwritten digits."
            },
            "slug": "A-bootstrapping-algorithm-for-learning-linear-of-Vetter-Jones",
            "title": {
                "fragments": [],
                "text": "A bootstrapping algorithm for learning linear models of object classes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm that automatically bootstraps the correspondence between the prototypes is described, which can be used for 2D images as well as for 3D models and is shown to synthesize successfully a flexible model of frontal face images and a flexible models of handwritten digits."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1851364"
                        ],
                        "name": "S. Nene",
                        "slug": "S.-Nene",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Nene",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 328096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd136608c086e07d406aef8e096e32327d9b92b7",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "A real-time vision system is described that can recognize 100 complex three-dimensional objects. In contrast to traditional strategies that rely on object geometry and local image features, the present system is founded on the concept of appearance matching. Appearance manifolds of the 100 objects were automatically learned using a computer-controlled turntable. The entire learning process was completed in 1 day. A recognition loop has been implemented that performs scene change detection, image segmentation, region normalizations, and appearance matching, in less than 1 second. The hardware used by the recognition system includes no more than a CCD color camera and a workstation. The real-time capability and interactive nature of the system have allowed numerous observers to test its performance. To quantify performance, we have conducted controlled experiments on recognition and pose estimation. The recognition rate was found to be 100% and object pose was estimated with a mean absolute error of 2.02 degrees and standard deviation of 1.67 degrees."
            },
            "slug": "Real-time-100-object-recognition-system-Nayar-Nene",
            "title": {
                "fragments": [],
                "text": "Real-time 100 object recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A real-time vision system is described that can recognize 100 complex three-dimensional objects and its recognition rate was found to be 100% and object pose was estimated with a mean absolute error of 2.02 degrees and standard deviation of 1.67 degrees."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Robotics and Automation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "It also includes 23 images used in [21] to measure the accuracy of their system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "training set as training progresses [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "It may be possible to make the detectors more robust using the bootstrap training technique described here and in [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "Sung and Poggio developed a face detection system based on clustering techniques [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 150
                            }
                        ],
                        "text": "These images can be characterized by probabilistic models of the set of face images [4, 13, 15], or implicitly by neural networks or other mechanisms [3, 12, 14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "First, a preprocessing step, adapted from [21], is applied to a window of the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "The result of their system on the same 23 images used in [21] is given in Table 3; the accuracy is currently slightly poorer than the other two systems for this small test set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "Osuna, Freund, and Girosi [14] have recently investigated face detection using a framework similar to that used in [21] and in our own work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "Instead of collecting the images before training is started, the images are collected during training, in the following manner, adapted from [21]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [21], 149 faces were labelled in this test set, while we labelled 155."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17583351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3317b98195fe0be4acf7b450f015c1abca13ab9",
            "isKey": true,
            "numCitedBy": 248,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Object and pattern detection is a classical computer vision problem with many potential applications, ranging from automatic target recognition to image-based industrial inspection tasks in assembly lines. While there have been some successful object and pattern detection systems in the past, most such systems handle only specific rigid objects or patterns that can be accurately described by fixed geometric models or pictorial templates. \nThis thesis presents a learning based approach for detecting classes of objects and patterns with variable image appearance but highly predictable image boundaries. Some examples of such object and pattern classes include human faces, aerial views of structured terrain features like volcanoes, localized material defect signatures in industrial parts, certain tissue anomalies in medical images, and instances of a given digit or character, which may be written or printed in many different styles. \nThe thesis consists of two parts. In part one, we introduce our object and pattern detection approach using a concrete human face detection example. The approach first builds a distribution-based model of the target pattern class in an appropriate feature space to describe the target's variable image appearance. It then learns from examples a similarity measure for matching new patterns against the distribution-based target model. We also discuss some pertinent learning issues, including ideas on virtual example generation and example selection. The approach makes few assumptions about the target pattern class and should therefore be fairly general, as long as the target class has predictable image boundaries. We show that this is indeed the case by demonstrating the technique on two other pattern detection/recognition problems. \nBecause our object and pattern detection approach is very much learning-based, how well a system eventually performs depends heavily on the quality of training examples it receives. The second part of this thesis looks at how one can select high quality examples for function approximation learning tasks. Active learning is an area of research that investigates how a learner can intelligently select future training examples to get better approximation results with less data. We propose an active learning formulation for function approximation, and show for three specific approximation function classes, that the active example selection strategy learns its target with fewer data samples than random sampling. Finally, we simplify the original active learning formulation, and show how it leads to a tractable example selection paradigm, suitable for use in many object and pattern detection problems. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
            },
            "slug": "Learning-and-example-selection-for-object-and-Sung",
            "title": {
                "fragments": [],
                "text": "Learning and example selection for object and pattern detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This thesis presents a learning based approach for detecting classes of objects and patterns with variable image appearance but highly predictable image boundaries, and proposes an active learning formulation for function approximation, and shows that the active example selection strategy learns its target with fewer data samples than random sampling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700567"
                        ],
                        "name": "S. Satoh",
                        "slug": "S.-Satoh",
                        "structuredName": {
                            "firstName": "Shin\u2019ichi",
                            "lastName": "Satoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Satoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2304541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58942abb806c435d880cc6717eccd4963528dc53",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel approach to extract meaningful content information from video by collaborative integration of image understanding and natural language processing. As an actual example, we developed a system that associates faces and names in videos, called Name-It, which is given news videos as a knowledge source, then automatically extracts face and name association as content information. The system can infer the name of a given unknown face image, or guess faces which are likely to have the name given to the system. This paper explains the method with several successful matching results which reveal effectiveness in integrating heterogeneous techniques as well as the importance of real content information extraction from video, especially face-name association."
            },
            "slug": "Name-It:-association-of-face-and-name-in-video-Satoh-Kanade",
            "title": {
                "fragments": [],
                "text": "Name-It: association of face and name in video"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A system that associates faces and names in videos, called Name-It, is developed, which is given news videos as a knowledge source, then automatically extracts face and name association as content information."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704975"
                        ],
                        "name": "G. Burel",
                        "slug": "G.-Burel",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Burel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Burel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081671334"
                        ],
                        "name": "Dominique Carel",
                        "slug": "Dominique-Carel",
                        "structuredName": {
                            "firstName": "Dominique",
                            "lastName": "Carel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominique Carel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14746961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cdb510aed4f8b04b73240287da954f9eff39318",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Detection-and-localization-of-faces-on-digital-Burel-Carel",
            "title": {
                "fragments": [],
                "text": "Detection and localization of faces on digital images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9563026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd62c9976534a6a2096a38244f6cbb03635a127e",
            "isKey": false,
            "numCitedBy": 2786,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >"
            },
            "slug": "Phoneme-recognition-using-time-delay-neural-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition using time-delay neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Their system, like ours, passes a small window over all portions of the image, and determines whether a face exists in each window."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64074620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f96cbb6c373c0e68c75ef23e5cdca7ed56af05a6",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 105,
            "paperAbstract": {
                "fragments": [],
                "text": "In many real-world tasks, the ability to focus attention on the relevant portions of the input is crucial for good performance. This work has shown that, for temporally coherent inputs, a computed expectation of the next time step\u2019s inputs provides a basis upon which to focus attention. Expectations are useful in tasks which arise in visual and non-visual domains, ranging from scene analysis to anomaly detection. When temporally related inputs are available, an expectation of the next input\u2019s contents can be computed based upon the current inputs. A saliency map, which is based upon the computed expectation and the actual inputs, indicates which inputs will be important for performing the task in the next time step. For example, in many visual object tracking problems, the relevant features are predictable, while the distractions in the scene are either unpredictable or unrelated to the task. The task-specific selective attention methods can be used to create a saliency map which accentuates only the predictable inputs that are useful in solving the task. In a second use of expectation, anomaly detection, the unexpected features are important. Here, the role of expectation is reversed; it is used to emphasize the unpredicted features. The performance of these methods is demonstrated in artificial neural network based systems on two real-world vision tasks: lane-marker tracking for autonomous vehicle control and driver monitoring, and hand tracking in cluttered scenes. For the hand-tracking task, techniques for incorporating a priori available domain knowledge are presented. These methods are also demonstrated in a nonvision based task: anomaly detection in the plasma etch step of semiconductor wafer fabrication. In addition to explicitly creating a saliency map to indicate where a network should pay attention, techniques are developed to reveal a network\u2019s implicit saliency map. The implicit saliency map represents the portions of the input to which a network will pay attention in the absence of the explicit focusing mechanisms developed in this thesis. Methods to examine the features a network has encoded in its hidden layers are also presented. These techniques are applied to networks trained to perform face-detection in arbitrary visual scenes. The results clearly display the facial features the network determines to be the most important for face detection. These techniques address one of the largest criticisms of artificial neural networks \u2212 that it is difficult to understand what they encode."
            },
            "slug": "Expectation-based-selective-attention-Baluja",
            "title": {
                "fragments": [],
                "text": "Expectation-based selective attention"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Techniques are developed to reveal a network\u2019s implicit saliency map, which represents the portions of the input to which a network will pay attention in the absence of the explicit focusing mechanisms developed in this thesis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9204636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "044779db85dc83e2633951791b29bc311cfbae53",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new framework for recognizing planar object classes, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features. The allowed object deformations are represented through shape statistics, which are learned from examples. Instances of an object in an image are detected by finding the appropriate features in the correct spatial configuration. The algorithm is robust with respect to partial occlusion, detector false alarms, and missed features. A 94% success rate was achieved for the problem of locating quasi-frontal views of faces in cluttered scenes."
            },
            "slug": "Recognition-of-planar-object-classes-Burl-Perona",
            "title": {
                "fragments": [],
                "text": "Recognition of planar object classes"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new framework for recognizing planar object classes is presented, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features, and the allowed object deformations are represented through shape statistics, which are learned from examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231915"
                        ],
                        "name": "S. Der",
                        "slug": "S.-Der",
                        "structuredName": {
                            "firstName": "Sandor",
                            "lastName": "Der",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Der"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14238832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39577ba5d7020bc1750b3a417b7d6432ebb7f00c",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As part of the Face Recognition Technology (FERET) program, the U.S. Army Research Laboratory (ARL) conducted supervised government tests and evaluations of automatic face recognition algorithms. The goal of the tests was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition. This report describes the design and presents the results of the August 1994 and March 1995 FERET tests. Results for FERET tests administered by ARL between August 1994 and August 1996 are reported."
            },
            "slug": "FERET-(Face-Recognition-Technology)-Recognition-and-Phillips-Rauss",
            "title": {
                "fragments": [],
                "text": "FERET (Face Recognition Technology) Recognition Algorithm Development and Test Results."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The design and results of the August 1994 and March 1995 FERET tests are described and the goal was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2238841"
                        ],
                        "name": "Stan Birchfield",
                        "slug": "Stan-Birchfield",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Birchfield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stan Birchfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9845332,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5df7c31418d6963fd86c9d74bdcd129d5aa61b7d",
            "isKey": false,
            "numCitedBy": 898,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for tracking a person's head is presented. The head's projection onto the image plane is modeled as an ellipse whose position and size are continually updated by a local search combining the output of a module concentrating on the intensity gradient around the ellipse's perimeter with that of another module focusing on the color histogram of the ellipse's interior. Since these two modules have roughly orthogonal failure modes, they serve to complement one another. The result is a robust, real-time system that is able to track a person's head with enough accuracy to automatically control the camera's pan, tilt, and zoom in order to keep the person centered in the field of view at a desired size. Extensive experimentation shows the algorithm's robustness with respect to full 360-degree out-of-plane rotation, up to 90-degree tilting, severe but brief occlusion, arbitrary camera movement, and multiple moving people in the background."
            },
            "slug": "Elliptical-head-tracking-using-intensity-gradients-Birchfield",
            "title": {
                "fragments": [],
                "text": "Elliptical head tracking using intensity gradients and color histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "An algorithm that is able to track a person's head with enough accuracy to automatically control the camera's pan, tilt, and zoom in order to keep the person centered in the field of view at a desired size is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18200026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6d4bdf0bbf93e014e89b65a805d099a93f98b99",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual target modeling which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. A computationally efficient and optimal estimator for a multivariate Gaussian distribution is derived. This density estimate is then used to formulate a maximum likelihood estimation framework for visual search and target detection. Our learning technique is applied to the probabilistic visual modeling and subsequent detection of facial features and is shown to be superior to matched filtering."
            },
            "slug": "A-subspace-method-for-maximum-likelihood-target-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "A subspace method for maximum likelihood target detection"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "An unsupervised technique for visual target modeling which is based on density estimation in high-dimensional spaces using an eigenspace decomposition is presented and is shown to be superior to matched filtering."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694199"
                        ],
                        "name": "R. Sukthankar",
                        "slug": "R.-Sukthankar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sukthankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sukthankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144529834"
                        ],
                        "name": "R. Stockton",
                        "slug": "R.-Stockton",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Stockton",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stockton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6346153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a66b92198b874ab007fb25da8a5a48b7c1c08d8",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "ARGUS is a multi-agent visitor identification system distributed over several workstations. Human faces are extracted from security camera images by a neural-network-based face detector, and identified as frequent visitors by ARENA, a memory-based face recognition system. ARGUS then uses a messaging system to notify hosts that their guests have arrived. An interface agent enables users to submit feedback, which is immediately incorporated by ARENA to improve its face recognition performance. The ARGUS components were rapidly developed using JGram, an agent framework that is also detailed in this paper. JGram automatically converts high-level agent specifications into Java source code, and assembles complex tasks by composing individual agent services into a JGram pipeline. ARGUS has been operating successfully in an outdoor environment for several months."
            },
            "slug": "ARGUS:-An-Automated-Multi-Agent-Visitor-System-Sukthankar-Stockton",
            "title": {
                "fragments": [],
                "text": "ARGUS: An Automated Multi-Agent Visitor Identification System"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The ARGUS components were rapidly developed using JGram, an agent framework that is also detailed in this paper that automatically converts high-level agent specifications into Java source code, and assembles complex tasks by composing individual agent services into a JG Gram pipeline."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47953439"
                        ],
                        "name": "R\u00e9gis Vaillant",
                        "slug": "R\u00e9gis-Vaillant",
                        "structuredName": {
                            "firstName": "R\u00e9gis",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9gis Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62763570,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "09ebd9ad4fa21c0d56433ac57a4cd69e94c72281",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps. In the first step, a rough localisation is performed by presenting each pixel with its neighbourhood to a neural net which is able to indicate whether this pixel and its neighbourhood are the image of the search object. This first filter does not discriminate for position. From its result, areas which might contain an image of the object can be selected. In the second step, these areas are presented to another neural net which can determine the exact position of the object in each area. This algorithm is applied to the problem of localising faces in images."
            },
            "slug": "Original-approach-for-the-localisation-of-objects-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "Original approach for the localisation of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps and is applied to the problem of localising faces in images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398079691"
                        ],
                        "name": "Tammy Riklin-Raviv",
                        "slug": "Tammy-Riklin-Raviv",
                        "structuredName": {
                            "firstName": "Tammy",
                            "lastName": "Riklin-Raviv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tammy Riklin-Raviv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 121
                            }
                        ],
                        "text": "3 Quotient Images for Compensation Another approach to intelligently correcting the lighting in an image is presented in [Riklin-Raviv and Shashua, 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 174
                            }
                        ],
                        "text": "The original work on this technique used the quotient image for face recognition, because it removes the effects of lighting and allows recognition with fewer example images [Riklin-Raviv and Shashua, 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1756283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f18c9a9859b0b7f78a1a5ffc158b4f717565fff",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper addresses the problem of \"class-based\" recognition and image-synthesis with varying illumination. The class-based synthesis and recognition tasks are defined as follows: given a single input image of an object, and a sample of images with varying illumination conditions of other objects of the same general class, capture the equivalence relationship (by generation of new images or by invariants) among all images of the object corresponding to new illumination conditions. The key result in our approach is based on a definition of an illumination invariant signature image, we call the \"quotient\" image, which enables an analytic generation of the image space with varying illumination from a single input image and a very small sample of other objects of the class-in our experiments as few as two objects. In many cases the recognition results outperform by far conventional methods and the image-synthesis is of remarkable quality considering the size of the database of example images and the mild pre-process required for making the algorithm work."
            },
            "slug": "The-quotient-image:-Class-based-recognition-and-Riklin-Raviv-Shashua",
            "title": {
                "fragments": [],
                "text": "The quotient image: Class based recognition and synthesis under varying illumination conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The key result in this approach is based on a definition of an illumination invariant signature image, which enables an analytic generation of the image space with varying illumination from a single input image and a very small sample of other objects of the class-in the authors' experiments as few as two objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143672874"
                        ],
                        "name": "Ian Burns",
                        "slug": "Ian-Burns",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Burns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Burns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 12263191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37e12ff3d721c9d3e3308a8cd74a56c4362530b9",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A commonly encountered problem in MLP (multi-layer perceptron) classification problems is related to the prior probabilities of the individual classes - if the number of training examples that correspond to each class varies significantly between the classes, then it may be harder for the network to learn the rarer classes in some cases. Such practical experience does not match theoretical results which show that MLPs approximate Bayesian a posteriori probabilities (independent of the prior class probabilities). Our investigation of the problem shows that the difference between the theoretical and practical results lies with the assumptions made in the theory (accurate estimation of Bayesian a posteriori probabilities requires the network to be large enough, training to converge to a global minimum, infinite training data, and the a priori class probabilities of the test set to be correctly represented in the training set). Specifically, the problem can often be traced to the fact that efficient MLP training mechanisms lead to sub-optimal solutions for most practical problems. In this chapter, we demonstrate the problem, discuss possible methods for alleviating it, and introduce new heuristics which are shown to perform well on a sample ECG classification problem. The heuristics may also be used as a simple means of adjusting for unequal misclassification costs."
            },
            "slug": "Neural-Network-Classification-and-Prior-Class-Lawrence-Burns",
            "title": {
                "fragments": [],
                "text": "Neural Network Classification and Prior Class Probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The investigation of the problem shows that the difference between the theoretical and practical results lies with the assumptions made in the theory, and introduces new heuristics which are shown to perform well on a sample ECG classification problem."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718007"
                        ],
                        "name": "P. Suetens",
                        "slug": "P.-Suetens",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Suetens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Suetens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730461"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hanson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14151360,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "87b54761e5fbf8a2197091aa966a152c74883734",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "This article reviews the available methods for automated identification of objects in digital images. The techniques are classified into groups according to the nature of the computational strategy used. Four classes are proposed: (1) the simplest strategies, which work on data appropriate for feature vector classification, (2) methods that match models to symbolic data structures for situations involving reliable data and complex models, (3) approaches that fit models to the photometry and are appropriate for noisy data and simple models, and (4) combinations of these strategies, which must be adopted in complex situations. Representative examples of various methods are summarized, and the classes of strategies with respect to their appropriateness for particular applications."
            },
            "slug": "Computational-strategies-for-object-recognition-Suetens-Fua",
            "title": {
                "fragments": [],
                "text": "Computational strategies for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This article reviews the available methods for automated identification of objects in digital images and proposes the simplest strategies, which work on data appropriate for feature vector classification, and methods that match models to symbolic data structures for situations involving reliable data and complex models."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "Similar input connection patterns are commonly used in speech and character recognition tasks [10], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7828,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21754467"
                        ],
                        "name": "R. Chin",
                        "slug": "R.-Chin",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Chin",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724754"
                        ],
                        "name": "C. Dyer",
                        "slug": "C.-Dyer",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Dyer",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10037306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e0ce7719dcb315145284fea50fd7c96df3599ab",
            "isKey": false,
            "numCitedBy": 672,
            "numCiting": 203,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a comparative study and survey of model-based object-recognition algorithms for robot vision. The goal of these algorithms is to recognize the identity, position, and orientation of randomly oriented industrial parts. In one form this is commonly referred to as the \"bin-picking\" problem, in which the parts to be recognized are presented in a jumbled bin. The paper is organized according to 2-D, 2\u00bd-D, and 3-D object representations, which are used as the basis for the recognition algorithms. Three central issues common to each category, namely, feature extraction, modeling, and matching, are examined in detail. An evaluation and comparison of existing industrial part-recognition systems and algorithms is given, providing insights for progress toward future robot vision systems."
            },
            "slug": "Model-based-recognition-in-robot-vision-Chin-Dyer",
            "title": {
                "fragments": [],
                "text": "Model-based recognition in robot vision"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper presents a comparative study and survey of model-based object-recognition algorithms for robot vision, and an evaluation and comparison of existing industrial part- recognition systems and algorithms is given, providing insights for progress toward future robot vision systems."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116707114"
                        ],
                        "name": "Alvy Ray Smith",
                        "slug": "Alvy-Ray-Smith",
                        "structuredName": {
                            "firstName": "Alvy",
                            "lastName": "Smith",
                            "middleNames": [
                                "Ray"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alvy Ray Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685272"
                        ],
                        "name": "J. Blinn",
                        "slug": "J.-Blinn",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Blinn",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Blinn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3332151,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "61a1c4ae4dbc182e2923c495339466bb0812f53d",
            "isKey": false,
            "numCitedBy": 458,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "A classical problem of imaging\u2014the matting problem\u2014is separation of a non-rectangular foreground image from a (usually) rectangular background image\u2014for example, in a film frame, extraction of an actor from a background scene to allow substitution of a different background. Of the several attacks on this difficult and persistent problem, we discuss here only the special case of separating a desired foreground image from a background of a constant, or almost constant, backing color. This backing color has often been blue, so the problem, and its solution, have been called blue screen matting. However, other backing colors, such as yellow or (increasingly) green, have also been used, so we often generalize to constant color matting. The mathematics of constant color matting is presented and proven to be unsolvable as generally practiced. This, of course, flies in the face of the fact that the technique is commonly used in film and video, so we demonstrate constraints on the general problem that lead to solutions, or at least significantly prune the search space of solutions. We shall also demonstrate that an algorithmic solution is possible by allowing the foreground object to be shot against two constant backing colors\u2014in fact, against two completely arbitrary backings so long as they differ everywhere."
            },
            "slug": "Blue-screen-matting-Smith-Blinn",
            "title": {
                "fragments": [],
                "text": "Blue screen matting"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The mathematics of constant color matting is presented and proven to be unsolvable as generally practiced, and constraints on the general problem that lead to solutions are demonstrated, or at least significantly prune the search space of solutions."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129047"
                        ],
                        "name": "Thanarat Horprasert",
                        "slug": "Thanarat-Horprasert",
                        "structuredName": {
                            "firstName": "Thanarat",
                            "lastName": "Horprasert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thanarat Horprasert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16081964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecdce210d5aa0f492ea73b4f7e2ab4200ea92e69",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach for estimating 3D head orientation in a monocular image sequence is presented. The approach employs recently developed image-based parameterized tracking for face and face features to locate the area in which an estimation of point feature locations is performed. This involves tracking of ve points (four at the eye corners and the fth is the tip of the nose). We describe an approach that relies on the coarse structure of the face to compute orientation relative to the camera plane. Our approach employs symmetry of the eyes and anthropometric statistics to estimate the head yaw, roll and pitch."
            },
            "slug": "An-anthropometric-shape-model-for-estimating-head-Horprasert-Yacoob",
            "title": {
                "fragments": [],
                "text": "An anthropometric shape model for estimating head orientation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work describes an approach that relies on the coarse structure of the face to compute orientation relative to the camera plane and employs symmetry of the eyes and anthropometric statistics to estimate the head yaw, roll and pitch."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880906"
                        ],
                        "name": "V. Blanz",
                        "slug": "V.-Blanz",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Blanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Blanz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14316400,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58d96fe13a791c9f62736b69aa9bac49095fdf44",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a method to derive 3D shape and surface texture of a human face from a single image. The method draws on a general flexible 3D face model which is \u201clearned\u201d from examples of individual 3D-face data (Cyberware-scans). In an analysis-by-synthesis loop, the flexible model is matched to the novel face image."
            },
            "slug": "Estimating-Coloured-3D-Face-Models-from-Single-An-Vetter-Blanz",
            "title": {
                "fragments": [],
                "text": "Estimating Coloured 3D Face Models from Single Images: An Example Based Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A method to derive 3D shape and surface texture of a human face from a single image using a general flexible 3D face model which is \u201clearned\u201d from examples of individual 3D-face data (Cyberware-scans)."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8119728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f1d20f0770b60675466bc413402871fcaea1805",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The efficiency of pattern recognition is critical when there are a large number of classes to be discriminated, or when the recognition algorithm must be applied a large number of times. We propose and analyze a general technique, namely pattern recognition, that leads to great efficiency improvements in both cases. Rejectors are introduced as algorithms that very quickly eliminate from further consideration, most of the classes or inputs (depending on the setting). Importantly, a number of rejectors may be combined to form a composite rejector, which performs far more effectively than any of its component rejectors. Composite rejectors are analyzed, and conditions derived which guarantee both efficiency and practicality. A general technique is proposed for the construction of rejectors, based on a single assumption about the pattern classes. The generality is shown through a close relationship with the Karhunen-Loeve expansion. Further, a comparison with Fisher's discriminant analysis is included to illustrate the benefits of pattern recognition. Composite rejectors were constructed for two applications, namely, object recognition and local feature detection. In both cases, a substantial improvement in efficiency over existing techniques is demonstrated."
            },
            "slug": "A-Theory-of-Pattern-Rejection-Baker-Nayar",
            "title": {
                "fragments": [],
                "text": "A Theory of Pattern Rejection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A general technique is proposed for the construction of rejectors, based on a single assumption about the pattern classes, which leads to great efficiency improvements in both pattern recognition and local feature detection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48855558"
                        ],
                        "name": "D. Pomerleau",
                        "slug": "D.-Pomerleau",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Pomerleau",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pomerleau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 110954972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c67f0f00eaab360db1b9bd377e783c27c922dc86",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nVision based mobile robot guidance has proven difficult for classical machine vision methods because of the diversity and real time constraints inherent in the task. This book describes a connectionist system called ALVINN (Autonomous Land Vehicle In a Neural Network) that overcomes these difficulties. ALVINN learns to guide mobile robots using the back-propagation training algorithm. Because of its ability to learn from example, ALVINN can adapt to new situations and therefore cope with the diversity of the autonomous navigation task. But real world problems like vision based mobile robot guidance present a different set of challenges for the connectionist paradigm. Among them are: how to develop a general representation from a limited amount of real training data, how to understand the internal representations developed by artificial neural networks, how to estimate the reliability of individual networks, how to combine multiple networks trained for different situations into a single system, and how to combine connectionist perception with symbolic reasoning. Neural Network Perception for Mobile Robot Guidance presents novel solutions to each of these problems. Using these techniques, the ALVINN system can learn to control an autonomous van in under 5 minutes by watching a person drive. Once trained, individual ALVINN networks can drive in a variety of circumstances, including single-lane paved and unpaved roads, and multi-lane lined and unlined roads, at speeds of up to 55 miles per hour. The techniques also are shown to generalize to the task of controlling the precise foot placement of a walking robot."
            },
            "slug": "Neural-Network-Perception-for-Mobile-Robot-Guidance-Pomerleau",
            "title": {
                "fragments": [],
                "text": "Neural Network Perception for Mobile Robot Guidance"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book describes a connectionist system called ALVINN (Autonomous Land Vehicle In a Neural Network) that overcomes difficulties and can learn to control an autonomous van in under 5 minutes by watching a person drive."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050737"
                        ],
                        "name": "P. Besl",
                        "slug": "P.-Besl",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Besl",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Besl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938732"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14648882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8560e9c39c50ea928eef7c115d99fdae5acfdfa3",
            "isKey": false,
            "numCitedBy": 1129,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "A general-purpose computer vision system must be capable of recognizing three-dimensional (3-D) objects. This paper proposes a precise definition of the 3-D object recognition problem, discusses basic concepts associated with this problem, and reviews the relevant literature. Because range images (or depth maps) are often used as sensor input instead of intensity images, techniques for obtaining, processing, and characterizing range data are also surveyed."
            },
            "slug": "Three-dimensional-object-recognition-Besl-Jain",
            "title": {
                "fragments": [],
                "text": "Three-dimensional object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A precise definition of the 3-D object recognition problem is proposed, basic concepts associated with this problem are discussed, and techniques for obtaining, processing, and characterizing range data are surveyed."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 103
                            }
                        ],
                        "text": "1 Linear Lighting Models The ideas in this section are based on the illumination models in the work of [Belhumeur and Kriegman, 1996], in which they explored the range of appearances an object can take on under differently lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2580433,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "acd0e8aedd2bb81a0cd8714ac350f9aac67c33ed",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of a particular object depends on both the viewpoint from which it is observed and the light sources by which it is illuminated. If the appearance of two objects is never identical for any pose or lighting conditions, then-in theory - the objects can always be distinguished or recognized. The question arises: What is the set of images of an object under all lighting conditions and pose? In this paper, we consider only the set of images of an object under variable illumination (including multiple, extended light sources and attached shadows). We prove that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a convex polyhedral cone in IR/sup n/ and that the dimension of this illumination cone equals the number of distinct surface normals. Furthermore, we show that the cone for a particular object can be constructed from three properly chosen images. Finally, we prove that the set of n-pixel images of an object of any shape and with an arbitrary reflectance function, seen under all possible illumination conditions, still forms a convex cone in IR/sup n/. These results immediately suggest certain approaches to object recognition. Throughout this paper, we offer results demonstrating the empirical validity of the illumination cone representation."
            },
            "slug": "What-is-the-set-of-images-of-an-object-under-all-Belhumeur-Kriegman",
            "title": {
                "fragments": [],
                "text": "What is the set of images of an object under all possible lighting conditions?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a conveX polyhedral cone in IR/sup n/ and that the dimension of this illumination cone equals the number of distinct surface normals."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679880"
                        ],
                        "name": "H. Wactlar",
                        "slug": "H.-Wactlar",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wactlar",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wactlar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116645471"
                        ],
                        "name": "Michael A. Smith",
                        "slug": "Michael-A.-Smith",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48817314"
                        ],
                        "name": "S. Stevens",
                        "slug": "S.-Stevens",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Stevens",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Stevens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8345108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b4d170b81ffc895e5b7960040a3f44a044d6bb8",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Carnegie Mellon's Informedia Digital Video Library project will establish a large, on-line digital video library featuring full-content and knowledge-based search and retrieval. Intelligent, automatic mechanisms will be developed to populate the library. Search and retrieval from digital video, audio, and text libraries will take place via desktop computer over local, metropolitan, and wide-area networks. The project's approach applies several techniques for content-based searching and video-sequence retrieval. Content is conveyed in both the narrative (speech and language) and the image. Only by the collaborative interaction of image, speech, and natural language understanding technology is it possible to successfully populate, segment, index, and search diverse video collections with satisfactory recall and precision. This collaborative interaction approach uniquely compensates for problems of interpretation and search in error-ridden and ambiguous data sets. The authors have focused the work on two corpuses. One is science documentaries and lectures, the other is broadcast news content with partial closed-captions. Further work will continue to improve the accuracy and performance of the underlying processing as well as explore performance issues related to Web-based access and interoperability with other digital video resources."
            },
            "slug": "Intelligent-Access-to-Digital-Video:-Informedia-Wactlar-Kanade",
            "title": {
                "fragments": [],
                "text": "Intelligent Access to Digital Video: Informedia Project"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Carnegie Mellon's Informedia Digital Video Library project will establish a large, on-line digital video library featuring full-content and knowledge-based search and retrieval, and focused the work on two corpuses."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722325"
                        ],
                        "name": "J. Bonet",
                        "slug": "J.-Bonet",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Bonet",
                            "middleNames": [
                                "S.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bonet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1908692,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18bc39207b4d24eabf9d98649db53563d9c2e3fd",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines a technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled. In a two-phase process, the input texture is first analyzed by measuring the joint occurrence of texture discrimination features at multiple resolutions. In the second phase, a new texture is synthesized by sampling successive spatial frequency bands from the input texture, conditioned on the similar joint occurrence of features at lower spatial frequencies. Textures synthesized with this method more successfully capture the characteristics of input textures than do previous techniques."
            },
            "slug": "Multiresolution-sampling-procedure-for-analysis-and-Bonet",
            "title": {
                "fragments": [],
                "text": "Multiresolution sampling procedure for analysis and synthesis of texture images"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled, which more successfully capture the characteristics of input textures than do previous techniques."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "2 Synthesizing Face Images The work of[Vetteret al., 1992] suggests that for bilaterally symmetric objects (such as faces and cars), a large number of views of the object can be generated from a single view, giv n information about which points in the image are symmetric points on the object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11205457,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f9d51f8eb56a89b6996c83127fa8e6b1fbe0e7c0",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Many 3D objects in the world around us are strongly constrained. For instance, not only cultural artifacts but also many natural objects are bilaterally symmetric. Thoretical arguments suggest and psychophysical experiments confirm that humans may be better in the recognition of symmetric objects. The hypothesis of symmetry-induced virtual views together with a network model that successfully accounts for human recognition of generic 3D objects leads to predictions that we have verified with psychophysical experiments."
            },
            "slug": "3D-Object-Recognition:-Symmetry-and-Virtual-Views-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "3D Object Recognition: Symmetry and Virtual Views"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776507"
                        ],
                        "name": "Michael Gleicher",
                        "slug": "Michael-Gleicher",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Gleicher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Gleicher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809905"
                        ],
                        "name": "A. Witkin",
                        "slug": "A.-Witkin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Witkin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Witkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1738577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "782dfc9f04f94d83a0ff499488f0849d3f7cd4b9",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce through-the-lens camera control, a body of techniques that permit a user to manipulate a virtual camera by controlling and constraining features in the image seen through its lens. Rather than solving for camera parameters directly, constrained optimization is used to compute their time derivatives based on desired changes in user-defined controls. This effectively permits new controls to be defined independent of the underlying parameterization. The controls can also serve as constraints, maintaining their values as others are changed. We describe the techniques in general and work through a detailed example of a specific camera model. Our implementation demonstrates a gallery of useful controls and constraints and provides some examples of how these may be used in composing images and animations."
            },
            "slug": "Through-the-lens-camera-control-Gleicher-Witkin",
            "title": {
                "fragments": [],
                "text": "Through-the-lens camera control"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Through-the-lens camera control, a body of techniques that permit a user to manipulate a virtual camera by controlling and constraining features in the image seen through its lens, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152736800"
                        ],
                        "name": "M. Smith",
                        "slug": "M.-Smith",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15525071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94c4141cdd7615e8e6fccbfa864abd518a62efd8",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video is rapidly becoming an important source for information, entertainment and a host of multimedia applications. With the size of these collections growing to thousands of hours, technology is needed to effectively browse segments in a short time without losing the content of the video. We propose a method to extract the significant audio and video information and create a \u201cskim\u201d video which represents a short synopsis of the original. The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding. The resulting skim is much smaller, and retains the essential content of the original segment. This research is sponsored by the National Science Foundation under grant no. IRI9411299, the National Space and Aeronautics Administration, and the Advanced Research Projects Agency. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of the United States Government."
            },
            "slug": "Video-Skimming-for-Quick-Browsing-based-on-Audio-Smith",
            "title": {
                "fragments": [],
                "text": "Video Skimming for Quick Browsing based on Audio and Image Characterization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding and a \u201cskim\u201d video is proposed which represents a short synopsis of the original."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121941586"
                        ],
                        "name": "C. Frankel",
                        "slug": "C.-Frankel",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Frankel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Frankel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720747"
                        ],
                        "name": "V. Athitsos",
                        "slug": "V.-Athitsos",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Athitsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Athitsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7811959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "105b158b73511030ff10ac0f0f1cbee65236e4a6",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of the size of the World Wide Web and its inherent lack of structure, finding what one is looking for can be a challenge. PC-Meters March, 1996, survey found that three of the five most visited Web sites were search engines. However, while Web pages typically contain both text and images, all the currently available search engines only index text. This paper describes WebSeer, a system for locating images on the Web. WebSeer uses image content in addition to associated text to index images, presenting the user with a selection that potentially fits her needs."
            },
            "slug": "WebSeer:-An-Image-Search-Engine-for-the-World-Wide-Frankel-Swain",
            "title": {
                "fragments": [],
                "text": "WebSeer: An Image Search Engine for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "WebSeer uses image content in addition to associated text to index images, presenting the user with a selection that potentially fits her needs on the Web."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116645471"
                        ],
                        "name": "Michael A. Smith",
                        "slug": "Michael-A.-Smith",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 135
                            }
                        ],
                        "text": "Syste ms utilizing the detector described above allow a user to make requests of the form \u201cShow me the p opl who appear in this video\u201d [18, 20] or \u201cWhich images on the World Wide Web contain faces?\u201d [6] and to have their queries answered automatically."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14666057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d98302953046ebf4d574d05db26a90db95789cc",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video is rapidly becoming important for education, entertainment, and a host of multimedia applications. With the size of the video collections growing to thousands of hours, technology is needed to effectively browse segments in a short time without losing the content of the video. We propose a method to extract the significant audio and video information and create a \"skim\" video which represents a very short synopsis of the original. The goal of this work is to show the utility of integrating language and image understanding techniques for video skimming by extraction of significant information, such as specific objects, audio keywords and relevant video structure. The resulting skim video is much shorter, where compaction is as high as 20:1, and yet retains the essential content of the original segment."
            },
            "slug": "Video-skimming-and-characterization-through-the-of-Smith",
            "title": {
                "fragments": [],
                "text": "Video skimming and characterization through the combination of image and language understanding techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The goal of this work is to show the utility of integrating language and image understanding techniques for video skimming by extraction of significant information, such as specific objects, audio keywords and relevant video structure."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "These images were laid out automatically by the PBIL optimization algorithm [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14799233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c133d9a18e88a4111c160d30d62903a5d614bf0",
            "isKey": false,
            "numCitedBy": 1371,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Genetic algorithms (GAs) are biologically motivated adaptive systems which have been used, with varying degrees of success, for function optimization. In this study, an abstraction of the basic genetic algorithm, the Equilibrium Genetic Algorithm (EGA), and the GA in turn, are reconsidered within the framework of competitive learning. This new perspective reveals a number of different possibilities for performance improvements. This paper explores population-based incremental learning (PBIL), a method of combining the mechanisms of a generational genetic algorithm with simple competitive learning. The combination of these two methods reveals a tool which is far simpler than a GA, and which out-performs a GA on large set of optimization problems in terms of both speed and accuracy. This paper presents an empirical analysis of where the proposed technique will outperform genetic algorithms, and describes a class of problems in which a genetic algorithm may be able to perform better. Extensions to this algorithm are discussed and analyzed. PBIL and extensions are compared with a standard GA on twelve problems, including standard numerical optimization functions, traditional GA test suite problems, and NP-Complete problems."
            },
            "slug": "A-Method-for-Integrating-Genetic-Search-Based-and-Baluja",
            "title": {
                "fragments": [],
                "text": "A Method for Integrating Genetic Search Based Function Optimization and Competitive Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper presents an empirical analysis of where the proposed technique will outperform genetic algorithms, and describes a class of problems in which a genetic algorithm may be able to perform better."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 57420724,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0071c960f49d8279e7a5503214a3567cb2237505",
            "isKey": false,
            "numCitedBy": 586,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Readings-in-speech-recognition-Waibel-Lee",
            "title": {
                "fragments": [],
                "text": "Readings in speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15208137,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "baf4491be1f4c1de7ecb03bf81325f6f09bda9c6",
            "isKey": false,
            "numCitedBy": 9488,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "IS B N 0-523108-5) C opright (C ) 19-1992 by C am bidge U nirsity P rss. P rogram s C opright (C ) 19-1992 by N um eical R eipes S ftw are. P rm ission is grnted or inrnet uers to m ke ne pper cpy or teir ow n peonal use. F uther repruction, or ny coying of m acineredable fles (inluding his one) to ny srver om pter, is sictly proibited. T o oder N um eical R eipes boks, disettes, or C D R O M s visit w esite hp://w w w .n.com or call 1-8072-7423 (N orth A m erica oly), or snd em il to trde@ cu.cam .ac.uk (otside N orth A m eca). Numerical Recipes in C"
            },
            "slug": "Numerical-recipes-in-C++:-the-art-of-scientific-2nd-Press",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C++: the art of scientific computing, 2nd Edition (C++ ed., print. is corrected to software version 2.10)"
            },
            "tldr": {
                "abstractSimilarityScore": 32,
                "text": "F uther repruction, or ny coying of m acineredable fles (inluding his one) to ny srver om pter, is sictly proibited."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402706679"
                        ],
                        "name": "Luis Alonso-Ovalle",
                        "slug": "Luis-Alonso-Ovalle",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Alonso-Ovalle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Alonso-Ovalle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141907"
                        ],
                        "name": "E. McCready",
                        "slug": "E.-McCready",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "McCready",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. McCready"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 83
                            }
                        ],
                        "text": "1 Linear Features One of the earliest projects on face recognition is described in [Kanade, 1973]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7775828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7784500bbed1fe34903d18f5ba933ee7a65cb37",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Kyoto-University-Potts-Alonso-Ovalle",
            "title": {
                "fragments": [],
                "text": "Kyoto University"
            },
            "venue": {
                "fragments": [],
                "text": "Current Biology"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144014876"
                        ],
                        "name": "S. Rose",
                        "slug": "S.-Rose",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Rose",
                            "middleNames": [
                                "Peter",
                                "Russell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rose"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 187
                            }
                        ],
                        "text": "1 Sensitivity Analysis In order to determine which part of its input image the network uses to decide whether the input is a face, we performed a sensitivity analysis using the method of [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "Standard tracking methods, as well as expectation-based methods [2], can be applied to focus the detector\u2019s attention."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29972954,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4f156bdf1e40b1ad87cc44cfc2186248cabed18a",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Bright Air, Brilliant Fire: On the Matter of the Mind.By Gerald Edelman. Basic Books/Alien Lane: 1992. Pp.280. $25. \u00a320."
            },
            "slug": "Selective-attention-Rose",
            "title": {
                "fragments": [],
                "text": "Selective attention"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "It is possible to compensate for this using Bayes\u2019 Theorem, though (see also the discussion in [Lawrence et al., 1998])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 46
                            }
                        ],
                        "text": "Although theoretically the wrong thing to do, [Lawrence et al., 1998] observes such techniques often work well in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208784962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff65ac698013cdd9d61326cab49a1d75404e001",
            "isKey": false,
            "numCitedBy": 18723,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editors",
            "title": {
                "fragments": [],
                "text": "Editors"
            },
            "venue": {
                "fragments": [],
                "text": "Brain Research Bulletin"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50387327"
                        ],
                        "name": "A. Favero",
                        "slug": "A.-Favero",
                        "structuredName": {
                            "firstName": "Albano",
                            "lastName": "Favero",
                            "middleNames": [
                                "Del"
                            ],
                            "suffix": "M.D."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Favero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118042230"
                        ],
                        "name": "G. Barro",
                        "slug": "G.-Barro",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "Barro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 72
                            }
                        ],
                        "text": ", 1994], and those using three dimensional geometric models of the face [Horprasert et al., 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 208790151,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "59fc75141b2eab4fc394532d75f3da28bb86cb16",
            "isKey": false,
            "numCitedBy": 752,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Italy-Favero-Barro",
            "title": {
                "fragments": [],
                "text": "Italy"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Sung and Poggio developed a face detection system based on clustering techniques [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 38
                            }
                        ],
                        "text": "2 Arbitration among Multiple Networks [Sung, 1996] provided some formalization of how a set of identically trained detectors can be used together to improve accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "As with Sung and Poggio\u2019s work, Moghoddam and Pentland\u2019s approach uses a two component distance measure, but combines the two distances in a principled way based on the assumption that the distribution of each cluster is Gaussian [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 70
                            }
                        ],
                        "text": "Parts of this database were used as the \u201chigh-quality\u201d test images in [Sung, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 63
                            }
                        ],
                        "text": "Since then, however, partly due to the well known work by Sung [Sung, 1996], the field has become more developed."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 148
                            }
                        ],
                        "text": "One of the first face detection systems with high accuracy in cluttered images was developed at the MIT Media Lab by Kah-Kay Sung and Tomaso Poggio [Sung, 1996]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Assuming that Sung and Poggio were unable to detect any of the six additional faces we labelled, the number of faces missed by their system is six more than listed in their paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 135
                            }
                        ],
                        "text": "We avoid the problem of using a huge training set for nonfaces by selectively adding images to the training set as training progresses [Sung, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 225
                            }
                        ],
                        "text": "Background Variation: In his thesis, Sung suggested that with current pattern recognition techniques, the view-based approach to object detection is only applicable for objects that have \u201chighly predictable image boundaries\u201d [Sung, 1996]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 131
                            }
                        ],
                        "text": "3 Active Learning Because of the difficult of training with every possible negative example, we utilized an algorithm described in [Sung, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 117
                            }
                        ],
                        "text": "3 Clustering of Faces and Non-Faces Sung and Poggio developed a face detection system based on clustering techniques [Sung, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "The authors would like to thank Kah-Kay Sung and Dr. Tomaso Poggio (at MIT) and Dr. Woodward Yang (at Harvard) for providing a series of test images and a mug-shot database for training, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 100
                            }
                        ],
                        "text": "We first address these problems by using a simple image processing approach, which was also used in [Sung, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 98
                            }
                        ],
                        "text": "These distance measures have close ties with Principal Components Analysis (PCA), as described in [Sung, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "January 1996"
            },
            "venue": {
                "fragments": [],
                "text": "Available as AI Technical Report"
            },
            "year": 1572
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 69
                            }
                        ],
                        "text": "In this work, the similarity was measured using the eigenface method [Pentland et al., 1994], although any face recognition method could be used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 39
                            }
                        ],
                        "text": "Another related system is described in [Pentland et al., 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Anecdotally, this system has good recognition performance (much more robust than the basis eigenface system described in [Pentland et al., 1994])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 72
                            }
                        ],
                        "text": "Some work on eigenfaces has also included a simple pose estimation step [Pentland et al., 1994]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 84\u201391"
            },
            "venue": {
                "fragments": [],
                "text": "June"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "[Sung and Poggio, 1994] reports a face detection system based on clustering techniques."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 90
                            }
                        ],
                        "text": "Test Set B consists of 23 images containing 155 faces (9,678,084 windows); it was used in [Sung and Poggio, 1994] to measure the accuracy of their system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 98
                            }
                        ],
                        "text": "These distance measures have close ties with Principal Components Analysis (PCA), as described in [Sung and Poggio, 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 42
                            }
                        ],
                        "text": "First, a preprocessing step, adapted from [Sung and Poggio, 1994], is applied to a window of the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 31
                            }
                        ],
                        "text": "The main computational cost in [Sung and Poggio, 1994] is in computing the two distance measures from each new window to 12 clusters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 136
                            }
                        ],
                        "text": "We avoid the problem of using a huge training set for non-faces by selectively adding images to the training set as training progresses [Sung and Poggio, 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 15
                            }
                        ],
                        "text": "8% 5 1/1929655 [Sung and Poggio, 1994] (Perceptron) 28 81."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 140
                            }
                        ],
                        "text": "Instead of collecting the images before training is started, the images are collected during training in the following manner, adapted from [Sung and Poggio, 1994]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 59
                            }
                        ],
                        "text": "Although our system is less computationally expensive than [Sung and Poggio, 1994], the system described so far is not real-time because of the number of windows which must be classified."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Memo 1521"
            },
            "venue": {
                "fragments": [],
                "text": "CBCL Paper 112, MIT, December"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 131
                            }
                        ],
                        "text": "Table 2 shows the result of applying each of the systems to images in Test Set 2 (a subset of public portion of the FERET database [16,17])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 123
                            }
                        ],
                        "text": "Moghaddam and Pentland\u2019s system, along with several others, was tested in the FERET evaluation of face recognition methods [16,17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Test Set 2 consists of facial images from the FERET database, coll ected under the ARPA/ARL FERET program [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 45
                            }
                        ],
                        "text": "Test Set 2 is a subset of the FERET database [16, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "FERET (face r  ecognition technology) recogition algorithm development and test results"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report ARL-T  R-995,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 100
                            }
                        ],
                        "text": "Below we mention some techniques to reduce these errors; for more details the reader is referred to [Rowley et al., 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "[Rowley et al., 1995] gives a breakdown of the performance of each of these system for each of the three test"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In [Rowley et al., 1995], we show that a face detection network can also be made translation invariant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CMUCS-95-158R"
            },
            "venue": {
                "fragments": [],
                "text": "Carnegie Mellon University, November"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The arbitrator then merges detections from individual filters and eliminates overlapping detections."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121903704,
            "fieldsOfStudy": [],
            "id": "57dc98cfb48247b400cc8decb93380e022864905",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to the Theory of Neural Computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71225891"
                        ],
                        "name": "D. Marquardt",
                        "slug": "D.-Marquardt",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Marquardt",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marquardt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122360030,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "288f41a655a178bf28d5883f68aa95807edbc950",
            "isKey": false,
            "numCitedBy": 27195,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Algorithm-for-Least-Squares-Estimation-of-Marquardt",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Least-Squares Estimation of Nonlinear Parameters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62020702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52f869ade6ac2de7b86648f4cb72b5b3bb9862ac",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Picture-Processing-System-by-Computer-Complex-and-Kanade",
            "title": {
                "fragments": [],
                "text": "Picture Processing System by Computer Complex and Recognition of Human Faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123962567"
                        ],
                        "name": "M. C. Seiler",
                        "slug": "M.-C.-Seiler",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Seiler",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Seiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50678756"
                        ],
                        "name": "F. A. Seiler",
                        "slug": "F.-A.-Seiler",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Seiler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. A. Seiler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62717952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e980fbf251ecb28ba85eb092fc66ce284bb63be",
            "isKey": false,
            "numCitedBy": 13115,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Recipes-in-C:-The-Art-of-Scientific-Seiler-Seiler",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes in C: The Art of Scientific Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 46
                            }
                        ],
                        "text": "A similar training algorithm was described in [Drucker et al., 1993], where at each iteration an entirely new network was trained with the examples on which the previous networks had made mistakes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115843015,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "International Journal of Pattern Recognition and Artificial Intelligence Signature Segmentation from Machine Printed Documents Using Contextual Information --manuscript Draft-- Full Title: Signature Segmentation from Machine Printed Documents Using Contextual Information Signature Segmentation from "
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107314775"
                        ],
                        "name": "C. C. Taylor",
                        "slug": "C.-C.-Taylor",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Taylor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. C. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": "The detector described in [Yang and Huang, 1994] uses an approach quite different from the ones presented above."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1625830,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "ca23e7a71ace53d6a5b2a553ff37c63365d22b8a",
            "isKey": false,
            "numCitedBy": 5720,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-Recognition-Ripley-Taylor",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686726016"
                        ],
                        "name": "WiskottLaurenz",
                        "slug": "WiskottLaurenz",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "WiskottLaurenz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "WiskottLaurenz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644047601"
                        ],
                        "name": "FellousJean-Marc",
                        "slug": "FellousJean-Marc",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "FellousJean-Marc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "FellousJean-Marc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644039936"
                        ],
                        "name": "Kr\u00fcgerNorbert",
                        "slug": "Kr\u00fcgerNorbert",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Kr\u00fcgerNorbert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kr\u00fcgerNorbert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644047205"
                        ],
                        "name": "von der MalsburgChristopher",
                        "slug": "von-der-MalsburgChristopher",
                        "structuredName": {
                            "firstName": "von",
                            "lastName": "MalsburgChristopher",
                            "middleNames": [
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "von der MalsburgChristopher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215900517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14a0c0e79183e4aa343b2aefc5d88f3b17436c23",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transfo..."
            },
            "slug": "Face-Recognition-by-Elastic-Bunch-Graph-Matching-WiskottLaurenz-FellousJean-Marc",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Elastic Bunch Graph Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, represented by labeled graphs, based on a Gabor wavelet transfo..."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "17(1):76\u2013145"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] Harris Drucker, Robert Schapire, and Patrice Simard."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "A similar training algorithm was describe d in [5], where at each iteration an entirely new network was trained with the examples on which t e previous networks had made mistakes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boosting performa  nce in neural networks. International Journal of Pattern Recognition and Artificial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tammy Riklin-Raviv and Amnon Shashua. The quotient image: Class bases recognition and synthesis under varying illumination conditions"
            },
            "venue": {
                "fragments": [],
                "text": "Tammy Riklin-Raviv and Amnon Shashua. The quotient image: Class bases recognition and synthesis under varying illumination conditions"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Although the system was trained only on real faces, hand drawn faces are"
            },
            "venue": {
                "fragments": [],
                "text": "were scanned from photographs, B, H, and L were obtained from the World Wide Web"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] Harris Drucker, Robert Schapire, and Patrice Simard."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "A similar training algorithm was described in [5], where at each iteration an entirely new network was trained with the examples on which the previous networks had made mistakes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boosting performance in neural networks. International Journal of Pattern Recognition and Artificial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "D: 1/1/0 B: 1/1"
            },
            "venue": {
                "fragments": [],
                "text": "D: 1/1/0 B: 1/1"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] Alex Pentland, Baback Moghaddam, and Thad Starner."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 85
                            }
                        ],
                        "text": "These images can be characteri zed by probabilistic models of the set of face images [4,13,15], or implicitly by neural networks or other mechanism s [3,12,14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "View-based and modular ei  genspaces for face recognition. InComputer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] Alex Pentland, Baback Moghaddam, and Thad Starner."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 85
                            }
                        ],
                        "text": "These images can be characteri zed by probabilistic models of the set of face images [4,13,15], or implicitly by neural networks or other mechanism s [3,12,14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "View-based and modular ei  genspaces for face recognition. InComputer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "D: 1/1/0 B: 1/1"
            },
            "venue": {
                "fragments": [],
                "text": "D: 1/1/0 B: 1/1"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "In recent work, Colmenarez and Huang presented a statistically based met hod for face detection [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 85
                            }
                        ],
                        "text": "These images can be characteri zed by probabilistic models of the set of face images [4,13,15], or implicitly by neural networks or other mechanism s [3,12,14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face detection with information-ba  sed maximum discrimination. InComputer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 30
                            }
                        ],
                        "text": "This relationship is shown in [Gleicher and Witkin, 1992], which also describes how to compute the J matrix efficiently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 331\u2013340"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGGRAPH, July"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 145
                            }
                        ],
                        "text": "Recent work has also examined the problem of synthesizing realistic textures, which might provide a systematic way to generate background images [Bonet, 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 361\u2013368"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGGRAPH, August"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Teaching the comptuer ot recognize a friendly face"
            },
            "venue": {
                "fragments": [],
                "text": "Teaching the comptuer ot recognize a friendly face"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Authorized licensed use limited to: West Virginia University Downloaded on April 8, 2009 at 22:00 from IEEE Xplore. Restrictions apply"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MINERVA: A second"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 150
                            }
                        ],
                        "text": "These images can be characteri zed by probabilistic models of the set of face images [4,13,15], or implicitly by neural networks or other mechanism s [3,12,14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human face detection in a complex background. Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ARENA: A simple, high-performance baseline for frontal face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Submitted to Computer Vision and Pattern Recognition"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 150
                            }
                        ],
                        "text": "These images can be characteri zed by probabilistic models of the set of face images [4,13,15], or implicitly by neural networks or other mechanism s [3,12,14, 19,21,23,25,26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human face detection in a complex background. Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CMU-CS-96-186R"
            },
            "venue": {
                "fragments": [],
                "text": "Carnegie Mellon University, May"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "were provided by Sung and Poggio at MIT, and R is a dithered CCD image"
            },
            "venue": {
                "fragments": [],
                "text": "PA 15213 Phone: (412) 268-8734 Fax"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ARENA: A simple"
            },
            "venue": {
                "fragments": [],
                "text": "high-performance baseline for frontal face recognition. Submitted to Computer Vision and Pattern Recognition"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 9
                            }
                        ],
                        "text": "accurate [Colmenarez and Huang, 1997], and the accurate methods are (at the moment) quite slow [Schneiderman and Kanade, 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 125
                            }
                        ],
                        "text": "4 Statistical Representations In recent work, Colmenarez and Huang presented a statistically based method for face detection [Colmenarez and Huang, 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 782\u2013787"
            },
            "venue": {
                "fragments": [],
                "text": "San Juan, Puerto Rico, June"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Henry Schneiderman and Takeo Kanade Probabilistic modelling of local appearance and spatial relationships for object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "11(2)"
            },
            "venue": {
                "fragments": [],
                "text": "June"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 637\u2013644"
            },
            "venue": {
                "fragments": [],
                "text": "Cambridge, Massachusetts, June"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "page 36"
            },
            "venue": {
                "fragments": [],
                "text": "July"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition provides security alternative"
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Engineering Times"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D object recognition: Symmetry and virtual views. A.I. Memo 1409, MIT"
            },
            "venue": {
                "fragments": [],
                "text": "3D object recognition: Symmetry and virtual views. A.I. Memo 1409, MIT"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E-mail: har@cs.cmu.edu Shumeet Baluja Justsystem Pittsburgh Research Center 4616 Henry Street Pittsburgh, PA 15213 Phone: (412) 683-8592 Fax"
            },
            "venue": {
                "fragments": [],
                "text": "E-mail: har@cs.cmu.edu Shumeet Baluja Justsystem Pittsburgh Research Center 4616 Henry Street Pittsburgh, PA 15213 Phone: (412) 683-8592 Fax"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 36\u201339"
            },
            "venue": {
                "fragments": [],
                "text": "October"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 101
                            }
                        ],
                        "text": "Some researchers have tried to use simple templates to complement the results of skin color matching [Birchfield, 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 232\u2013237"
            },
            "venue": {
                "fragments": [],
                "text": "Santa Barbara, CA, June"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hyeonjoon Moon"
            },
            "venue": {
                "fragments": [],
                "text": "Patrick Rauss, and Syed A. Rizvi. The FERET evaluation methodology for face-recognition algorithms. In Computer Vision and Pattern Recognition, pages 137\u2013143"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networkbased face detection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational strategies for object recognition.ACM Computing Surveys"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E-mail: tk@cs.cmu"
            },
            "venue": {
                "fragments": [],
                "text": "E-mail: tk@cs.cmu"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Memo 1431"
            },
            "venue": {
                "fragments": [],
                "text": "MIT, November"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM SIGGRAPH"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGGRAPH"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Authorized licensed use limited to: West Virginia University Downloaded on February 26, 2009 at 11:49 from IEEE Xplore. Restrictions apply"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 157
                            }
                        ],
                        "text": "5 Neural Networks The candidate verification process used to speed up our system, described in Chapter 6, is similar to the detection technique presented in [Vaillant et al., 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "141(4)"
            },
            "venue": {
                "fragments": [],
                "text": "August"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MINERVA: A second generation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Amnon Shashua, and Tomaso Poggio. Example based image analysis and synthesis. A.I. Memo 1431"
            },
            "venue": {
                "fragments": [],
                "text": "Amnon Shashua, and Tomaso Poggio. Example based image analysis and synthesis. A.I. Memo 1431"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stastical color models with apoplications to skin detection"
            },
            "venue": {
                "fragments": [],
                "text": "Stastical color models with apoplications to skin detection"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shumeet Baluja and Dean Pomerleau. Encouraging distributed input reliance in spatially constrained artificial neural networks: Applications to visual scene analysis and control"
            },
            "venue": {
                "fragments": [],
                "text": "Shumeet Baluja and Dean Pomerleau. Encouraging distributed input reliance in spatially constrained artificial neural networks: Applications to visual scene analysis and control"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network classification and prior class probabilities Lecture Notes in Computer Science State-of-the-Art Surveys"
            },
            "venue": {
                "fragments": [],
                "text": "Tricks of the Trade"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Output obtained in the same manner as the examples in Fig. 11. Some notes on specific images: Faces are missed in C (due to blurriness) and L (due to partial occlusion of the chin)"
            },
            "venue": {
                "fragments": [],
                "text": "Figure"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 25
                            }
                        ],
                        "text": "Recent work described in [Jones and Rehg, 1998] using a very large number of images collected from the world wide web showed there are slightly differences between the races, but that a simple histogram-based model of skin color can accurately model the distribution of skin color."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Technical Report 98-11"
            },
            "venue": {
                "fragments": [],
                "text": "Compaq Cambridge Research Laboratory, December"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural nets help security systems face the facts"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Systems Design"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 150
                            }
                        ],
                        "text": "When color information is available, standard \u201cblue screening\u201d techniques can separate the foreground and background in a more straightforward manner [Smith, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 259\u2013268"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGGRAPH, August"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection (PAMI"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection (PAMI"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 786\u2013793"
            },
            "venue": {
                "fragments": [],
                "text": "Cambridge, Massachusetts, June"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "24(1):5\u201361"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 187
                            }
                        ],
                        "text": "1 Sensitivity Analysis In order to determine which part of its input image the network uses to decide whether the input is a face, we performed a sensitivity analysis using the method of [Baluja, 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 64
                            }
                        ],
                        "text": "Standard tracking methods, as well as expectation-based methods [Baluja, 1996], can be applied to focus the detector\u2019s attention."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Carnegie Mellon University Computer Science Department"
            },
            "venue": {
                "fragments": [],
                "text": "October"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 40\u201346"
            },
            "venue": {
                "fragments": [],
                "text": "San Juan, Puerto Rico, June"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 40
                            }
                        ],
                        "text": "In the face detection work described in [Burel and Carel, 1994], similar observations about the nature of the outputs were made, resulting in the development of heuristics similar to those described above."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "15:963\u2013967"
            },
            "venue": {
                "fragments": [],
                "text": "October"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alvy Ray Smith. Blue screen matting"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Graphics"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 128
                            }
                        ],
                        "text": "These arbitration heuristics are very similar to, but computationally less expensive than, those presented in my previous paper [Rowley et al., 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "20(1):23\u201338"
            },
            "venue": {
                "fragments": [],
                "text": "January"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 775\u2013781"
            },
            "venue": {
                "fragments": [],
                "text": "San Juan, Puerto Rico,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "These images were laid out automatically by the PB IL optimization algorithm [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Population-based incremental learning: A method for integrat ing genetic search based function optimization and competitive learning"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Repor t CMU-CS-94- 163,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Umezaki, 1995] Tazio Umezaki"
            },
            "venue": {
                "fragments": [],
                "text": "Umezaki, 1995] Tazio Umezaki"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Face detection, Pattern recognition, Computer vision, Artificial neural networks, Machine learning"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition via image invariants: A case study"
            },
            "venue": {
                "fragments": [],
                "text": "Investigative Opthalmology and Visual Science"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 159
                            }
                        ],
                        "text": "The support vector machine has a number of interesting properties, including the fact that it makes the boundary between face and nonface images more explicit [Burges, 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Available at http://svm"
            },
            "venue": {
                "fragments": [],
                "text": "research.bell-labs.com/SVMdoc.html,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "18(1):67\u2013108"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1986
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 27,
            "methodology": 31,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 135,
        "totalPages": 14
    },
    "page_url": "https://www.semanticscholar.org/paper/Neural-network-based-face-detection-Rowley-Baluja/3d76ef8e61395a6e9c32627f1f108772d084e2e9?sort=total-citations"
}