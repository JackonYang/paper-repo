{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent examples of this approach include aligning pictorial cues [4], shape correspondence [1], and modeling the constellation of parts [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799035"
                        ],
                        "name": "Erik B. Sudderth",
                        "slug": "Erik-B.-Sudderth",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sudderth",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik B. Sudderth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other models, exploiting knowledge of the scene context in which the objects reside, have proven successful in boosting object recognition performance [18, 20, 15, 7, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6153430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5331349557fababfac48d47e49b44583e3bd5f6",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a hierarchical probabilistic model for the detection and recognition of objects in cluttered, natural scenes. The model is based on a set of parts which describe the expected appearance and position, in an object centered coordinate frame, of features detected by a low-level interest operator. Each object category then has its own distribution over these parts, which are shared between objects. We learn the parameters of this model via a Gibbs sampler which uses the graphical model's structure to analytically average over many parameters. Applied to a database of images of isolated objects, the sharing of parts among objects improves detection accuracy when few training examples are available. We also extend this hierarchical framework to scenes containing multiple objects"
            },
            "slug": "Learning-hierarchical-models-of-scenes,-objects,-Sudderth-Torralba",
            "title": {
                "fragments": [],
                "text": "Learning hierarchical models of scenes, objects, and parts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Applied to a database of images of isolated objects, the sharing of parts among objects improves detection accuracy when few training examples are available and this hierarchical probabilistic model is extended to scenes containing multiple objects."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054953874"
                        ],
                        "name": "M. Rubin",
                        "slug": "M.-Rubin",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Rubin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other models, exploiting knowledge of the scene context in which the objects reside, have proven successful in boosting object recognition performance [18, 20, 15, 7, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 657043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37684bb33f21dc70619597498f1b95fb44fbb139",
            "isKey": false,
            "numCitedBy": 977,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "While navigating in an environment, a vision system has to be able to recognize where it is and what the main objects in the scene are. We present a context-based vision system for place and object recognition. The goal is to identify familiar locations (e.g., office 610, conference room 941, main street), to categorize new environments (office, corridor, street) and to use that information to provide contextual priors for object recognition (e.g., tables are more likely in an office than a street). We present a low-dimensional global image representation that provides relevant information for place recognition and categorization, and show how such contextual information introduces strong priors that simplify object recognition. We have trained the system to recognize over 60 locations (indoors and outdoors) and to suggest the presence and locations of more than 20 different object types. The algorithm has been integrated into a mobile system that provides realtime feedback to the user."
            },
            "slug": "Context-based-vision-system-for-place-and-object-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Context-based vision system for place and object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A low-dimensional global image representation is presented that provides relevant information for place recognition and categorization, and it is shown how such contextual information introduces strong priors that simplify object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that the gist feature preserves spatial structure information and is similar to applying the SIFT descriptor [9] to the image region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221242327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c04f169203f9e55056a6f7f956695babe622a38",
            "isKey": false,
            "numCitedBy": 12997,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene and can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 258
                            }
                        ],
                        "text": "Our approach relies on the observation that when we have a large e nough database of labeled images, we can find with high probability some images in the database tha t are very close to the query image in appearance, scene contents, and spatial arrangement [6, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "Recent studies usi ng non-parametric methods for computer vision and graphics [19, 6] show that when a large number of im ages are available, simple indexing techniques can be used to retrieve images with object arrang ements similar to those of a query image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9789787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f97938382963c828fe0b3882528d373afa8bfd8",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system is remarkably tolerant to degradations in image resolution: in a scene recognition task, human performance is similar whether 32 \u00d7 32 color images or multi-mega pixel images are used. With small images, even object recognition and segmentation is performed robustly by the visual system, despite the object being unrecognizable in isolation. Motivated by these observations, we explore the space of 32 \u00d7 32 images using a database of 10 32\u00d7 32 color images gathered from the Internet using image search engines. Each image is loosely labeled with one of the 70, 399 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database represents a dense sampling of all object categories and scenes. With this dataset, we use nearest neighbor methods to perform object recognition across the 10 images."
            },
            "slug": "Tiny-images-Fergus-Freeman",
            "title": {
                "fragments": [],
                "text": "Tiny images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work explores the space of 32 \u00d7 32 images using a database of 10 32\u00d7 32 color images gathered from the Internet using image search engines and uses nearest neighbor methods to perform object recognition across the 10 images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Each of the two rows depicts an input image (on the left) and 30 images from the LabelMe dataset [14] that best match the input image using the gist feature [12] and L1 distance (the images are sorted by their distances in raster order)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The main issues are: (1) Can we find a big enough dataset to span the required large number of scene configurations? (2) Given an input image, how do we find a set of images that aligns well with the query image? (3) How do we transfer the knowledge about objects contained in the labels? The LabelMe dataset [14] is well-suited for this task, having a large number of images and labels spanning hundreds of object categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1900911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092c275005ae49dc1303214f6d02d134457c7053",
            "isKey": false,
            "numCitedBy": 3076,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\n"
            },
            "slug": "LabelMe:-A-Database-and-Web-Based-Tool-for-Image-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "LabelMe: A Database and Web-Based Tool for Image Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A web-based tool that allows easy image annotation and instant sharing of such annotations is developed and a large dataset that spans many object categories, often containing multiple instances over a wide variety of images is collected."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent examples of this approach include aligning pictorial cues [4], shape correspondence [1], and modeling the constellation of parts [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2277383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd9ab441df8b24f473a3635370c69620b00c1e60",
            "isKey": false,
            "numCitedBy": 2423,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images."
            },
            "slug": "Pictorial-Structures-for-Object-Recognition-Felzenszwalb-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Pictorial Structures for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A computationally efficient framework for part-based modeling and recognition of objects, motivated by the pictorial structure models introduced by Fischler and Elschlager, that allows for qualitative descriptions of visual appearance and is suitable for generic recognition problems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "We seek to build a system to recognize and localize many different object categories in complex scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863668"
                        ],
                        "name": "Andrew Rabinovich",
                        "slug": "Andrew-Rabinovich",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Rabinovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1954793"
                        ],
                        "name": "C. Galleguillos",
                        "slug": "C.-Galleguillos",
                        "structuredName": {
                            "firstName": "Carolina",
                            "lastName": "Galleguillos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Galleguillos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766844"
                        ],
                        "name": "Eric Wiewiora",
                        "slug": "Eric-Wiewiora",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Wiewiora",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Wiewiora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other models, exploiting knowledge of the scene context in which the objects reside, have proven successful in boosting object recognition performance [18, 20, 15, 7, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 749550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4d13788112f0fec457d31e1f7de9a53bbcec8e6",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In the task of visual object categorization, semantic context can play the very important role of reducing ambiguity in objects' visual appearance. In this work we propose to incorporate semantic object context as a post-processing step into any off-the-shelf object categorization model. Using a conditional random field (CRF) framework, our approach maximizes object label agreement according to contextual relevance. We compare two sources of context: one learned from training data and another queried from Google Sets. The overall performance of the proposed framework is evaluated on the PASCAL and MSRC datasets. Our findings conclude that incorporating context into object categorization greatly improves categorization accuracy."
            },
            "slug": "Objects-in-Context-Rabinovich-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Objects in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes to incorporate semantic object context as a post-processing step into any off-the-shelf object categorization model using a conditional random field (CRF) framework, which maximizes object label agreement according to contextual relevance."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48966748"
                        ],
                        "name": "James Hays",
                        "slug": "James-Hays",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hays",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hays"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our approach relies on the observation that when we have a large enough database of labeled images, we can find with high probability some images in the database that are very close to the query image in appearance, scene contents, and spatial arrangement [6, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent studies using non-parametric methods for computer vision and graphics [19, 6] show that when a large number of images are available, simple indexing techniques can be used to retrieve images with object arrangements similar to those of a query image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 940100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "714d48570351de99eb755735b543c7b84bd9fb46",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "What can you do with a million images? In this paper, we present a new image completion algorithm powered by a huge database of photographs gathered from the Web. The algorithm patches up holes in images by finding similar image regions in the database that are not only seamless, but also semantically valid. Our chief insight is that while the space of images is effectively infinite, the space of semantically differentiable scenes is actually not that large. For many image completion tasks, we are able to find similar scenes which contain image fragments that will convincingly complete the image. Our algorithm is entirely data driven, requiring no annotations or labeling by the user. Unlike existing image completion methods, our algorithm can generate a diverse set of image completions and we allow users to select among them. We demonstrate the superiority of our algorithm over existing image completion approaches."
            },
            "slug": "Scene-completion-using-millions-of-photographs-Hays-Efros",
            "title": {
                "fragments": [],
                "text": "Scene completion using millions of photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new image completion algorithm powered by a huge database of photographs gathered from the Web that can generate a diverse set of image completions and allow users to select among them."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 2007"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 152
                            }
                        ],
                        "text": "Other models, exploiting knowledge of the scene context in w hich the objects reside, have proven successful in boosting object recognition performance [18 , 20, 15, 7, 13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6152006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4081e007d7eced95cc618164e976a80d44ff5f4e",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Image understanding requires not only individually estimating elements of the visual world but also capturing the interplay among them. In this paper, we provide a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint. Most object detection methods consider all scales and locations in the image as equally likely. We show that with probabilistic estimates of 3D geometry, both in terms of surfaces and world coordinates, we can put objects into perspective and model the scale and location variance in the image. Our approach reflects the cyclical nature of the problem by allowing probabilistic object hypotheses to refine geometry and vice-versa. Our framework allows painless substitution of almost any object detector and is easily extended to include other aspects of image understanding. Our results confirm the benefits of our integrated approach."
            },
            "slug": "Putting-Objects-in-Perspective-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Putting Objects in Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper provides a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint by allowing probabilistic object hypotheses to refine geometry and vice-versa."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Each of the two rows depicts an input image (on the left) and 30 images from the LabelMe dataset [14] that best match the input image using the gist feature [12] and L1 distance (the images are sorted by their distances in raster order)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We describe the gist feature [12], which is a low dimensional representation of an image region and has been shown to achieve good performance for the scene recognition task when applied to an entire image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11664336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "869171b2f56cfeaa9b81b2626cb4956fea590a57",
            "isKey": false,
            "numCitedBy": 6522,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "slug": "Modeling-the-Shape-of-the-Scene:-A-Holistic-of-the-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 152
                            }
                        ],
                        "text": "Other models, exploiting knowledge of the scene context in w hich the objects reside, have proven successful in boosting object recognition performance [18 , 20, 15, 7, 13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1073705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c99f2391b956dc189855541e49e53c21ae5ec603",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "slug": "Contextual-Priming-for-Object-Detection-Torralba",
            "title": {
                "fragments": [],
                "text": "Contextual Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "We scored detections using the PASCAL VOC 2006 criteria [2], where the outputs are sorted from most confident to least and the ratio of intersection area to union area is computed between an output bounding box and groundtruth bounding box."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": false,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To overcome the diverse object labels provided by users of LabelMe, we used WordNet [3] to resolve synonyms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13573,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773821"
                        ],
                        "name": "Matthew J. Beal",
                        "slug": "Matthew-J.-Beal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Beal",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew J. Beal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "fiths, Engen, and McCloskey [8, 11, 16] with concentration parameter \u03b1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7934949,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b90d922ff07d0eb8d77b8687aba7f55bd3926436",
            "isKey": false,
            "numCitedBy": 3577,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes in terms of a stick-breaking process, and a generalization of the Chinese restaurant process that we refer to as the \u201cChinese restaurant franchise.\u201d We present Markov chain Monte Carlo algorithms for posterior inference in hierarchical Dirichlet process mixtures and describe applications to problems in information retrieval and text modeling."
            },
            "slug": "Hierarchical-Dirichlet-Processes-Teh-Jordan",
            "title": {
                "fragments": [],
                "text": "Hierarchical Dirichlet Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work considers problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups, and considers a hierarchical model, specifically one in which the base measure for the childDirichlet processes is itself distributed according to a Dirichlet process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411909"
                        ],
                        "name": "Jon D. McAuliffe",
                        "slug": "Jon-D.-McAuliffe",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "McAuliffe",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jon D. McAuliffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 98
                            }
                        ],
                        "text": "Note that improved performance may be achieved with variational inference for Dirichlet Processes [10, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7998884,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "31cbc51a4a441d2ca6668e0e0614f5abfcb88194",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The Dirichlet process prior allows flexible nonparametric mixture modeling. The number of mixture components is not specified in advance and can grow as new data arrive. However, analyses based on the Dirichlet process prior are sensitive to the choice of the parameters, including an infinite-dimensional distributional parameter G0. Most previous applications have either fixed G0 as a member of a parametric family or treated G0 in a Bayesian fashion, using parametric prior specifications. In contrast, we have developed an adaptive nonparametric method for constructing smooth estimates of G0. We combine this method with a technique for estimating \u03b1, the other Dirichlet process parameter, that is inspired by an existing characterization of its maximum-likelihood estimator. Together, these estimation procedures yield a flexible empirical Bayes treatment of Dirichlet process mixtures. Such a treatment is useful in situations where smooth point estimates of G0 are of intrinsic interest, or where the structure of G0 cannot be conveniently modeled with the usual parametric prior families. Analysis of simulated and real-world datasets illustrates the robustness of this approach."
            },
            "slug": "Nonparametric-empirical-Bayes-for-the-Dirichlet-McAuliffe-Blei",
            "title": {
                "fragments": [],
                "text": "Nonparametric empirical Bayes for the Dirichlet process mixture model"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work has developed an adaptive nonparametric method for constructing smooth estimates of G0 that is inspired by an existing characterization of its maximum-likelihood estimator and yields a flexible empirical Bayes treatment of Dirichlet process mixtures."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39201543"
                        ],
                        "name": "J. Berger",
                        "slug": "J.-Berger",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Berger",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Berger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845488"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 28
                            }
                        ],
                        "text": "fiths, Engen, and McCloskey [8, 11, 16] with concentration parameter \u03b1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 168
                            }
                        ],
                        "text": "To automatically infer the number of clusters, we use a Dirichlet Process prior on the mixing weights\u03c0 \u223c Stick(\u03b1), whereStick(\u03b1) is the stick-breaking process of Grif-\nfiths, Engen, and McCloskey [8, 11, 16] with concentration parameter\u03b1."
                    },
                    "intents": []
                }
            ],
            "corpusId": 720458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b30b5e6a342f1b34fcb278137251e302cb10fc12",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "I introduce a family of prior distributions over multivariate distributions, based on the use of a \u201cDirichlet diffusion tree\u201d to generate exchangeable data sets. These priors can be viewed as generalizations of Dirichlet processes and of Dirichlet process mixtures, but unlike simple mixtures, they can capture the hierarchical structure present in many distributions, by means of the latent diffusion tree underlying the data. This latent tree also provides a hierarchical clustering of the data, which, unlike ad hoc clustering methods, comes with probabilistic indications of uncertainty. The relevance of each variable to the clustering can also be determined. Although Dirichlet diffusion trees are defined in terms of a continuoustime process, posterior inference involves only finite-dimensional quantities, allowing computation to be performed by reasonably efficient Markov chain Monte Carlo methods. The methods are demonstrated on problems of modeling a two-dimensional density and of clustering gene expression data."
            },
            "slug": "Density-Modeling-and-Clustering-Using-Dirichlet-Berger-Dawid",
            "title": {
                "fragments": [],
                "text": "Density Modeling and Clustering Using Dirichlet Diffusion Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A family of prior distributions over multivariate distributions, based on the use of a \u201cDirichlet diffusion tree\u201d to generate exchangeable data sets, are introduced, allowing computation to be performed by reasonably efficient Markov chain Monte Carlo methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741460"
                        ],
                        "name": "H. Ishwaran",
                        "slug": "H.-Ishwaran",
                        "structuredName": {
                            "firstName": "Hemant",
                            "lastName": "Ishwaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ishwaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143705769"
                        ],
                        "name": "M. Zarepour",
                        "slug": "M.-Zarepour",
                        "structuredName": {
                            "firstName": "Mahmoud",
                            "lastName": "Zarepour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zarepour"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 28
                            }
                        ],
                        "text": "fiths, Engen, and McCloskey [8, 11, 16] with concentration parameter \u03b1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 168
                            }
                        ],
                        "text": "To automatically infer the number of clusters, we use a Dirichlet Process prior on the mixing weights\u03c0 \u223c Stick(\u03b1), whereStick(\u03b1) is the stick-breaking process of Grif-\nfiths, Engen, and McCloskey [8, 11, 16] with concentration parameter\u03b1."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10835111,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "315a9d88925d703104109aac6db82bc31a0fa6b8",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The Dirichlet process can be regarded as a random probability measure for which the authors examine various sum representations. They consider in particular the gamma process construction of Ferguson (1973) and the \u201cstick\u2010breaking\u201d construction of Sethuraman (1994). They propose a Dirichlet finite sum representation that strongly approximates the Dirichlet process. They assess the accuracy of this approximation and characterize the posterior that this new prior leads to in the context of Bayesian nonpara\u2010metric hierarchical models."
            },
            "slug": "Exact-and-approximate-sum-representations-for-the-Ishwaran-Zarepour",
            "title": {
                "fragments": [],
                "text": "Exact and approximate sum representations for the Dirichlet process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67057961"
                        ],
                        "name": "D. Newman",
                        "slug": "D.-Newman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Newman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Newman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that improved performance may be achieved with variational inference for Dirichlet Processes [10, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 851882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6030ee7a0ca960911fe8579b258b89bcecdae466",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent Dirichlet allocation (LDA) is a Bayesian network that has recently gained much popularity in applications ranging from document modeling to computer vision. Due to the large scale nature of these applications, current inference procedures like variational Bayes and Gibbs sampling have been found lacking. In this paper we propose the collapsed variational Bayesian inference algorithm for LDA, and show that it is computationally efficient, easy to implement and significantly more accurate than standard variational Bayesian inference for LDA."
            },
            "slug": "A-Collapsed-Variational-Bayesian-Inference-for-Teh-Newman",
            "title": {
                "fragments": [],
                "text": "A Collapsed Variational Bayesian Inference Algorithm for Latent Dirichlet Allocation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes the collapsed variational Bayesian inference algorithm for LDA, and shows that it is computationally efficient, easy to implement and significantly more accurate than standard variationalBayesian inference for L DA."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 76
                            }
                        ],
                        "text": "To overcome the diverse object labels provided by users of LabelMe, we used WordNet [3] to resolve synonyms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "To overc ome the diverse object labels provided by users of LabelMe, we used WordNet [3] to resolve synonyms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 166388486,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "67f8831944ecc502ce74c761bd7ae0d929b5e2f8",
            "isKey": false,
            "numCitedBy": 830,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Electronic-Lexical-Database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "An Electronic Lexical Database"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 168
                            }
                        ],
                        "text": "To automatically infer the number of clusters, we use a Dirichlet Process prior on the mixing weights\u03c0 \u223c Stick(\u03b1), whereStick(\u03b1) is the stick-breaking process of Grif-\nfiths, Engen, and McCloskey [8, 11, 16] with concentration parameter\u03b1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 28
                            }
                        ],
                        "text": "fiths, Engen, and McCloskey [8, 11, 16] with concentration pa rameter\u03b1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical  Dirichlet processes.Journal of the American Statistical Association"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 168
                            }
                        ],
                        "text": "To automatically infer the number of clusters, we use a Dirichlet Process prior on the mixing weights\u03c0 \u223c Stick(\u03b1), whereStick(\u03b1) is the stick-breaking process of Grif-\nfiths, Engen, and McCloskey [8, 11, 16] with concentration parameter\u03b1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 28
                            }
                        ],
                        "text": "fiths, Engen, and McCloskey [8, 11, 16] with concentration pa rameter\u03b1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exact and approximate sum-rep  res ntations for the dirichlet process"
            },
            "venue": {
                "fragments": [],
                "text": "Canadian Journal of Statistics  , 30:269\u2013283,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "Rece nt examples of this approach include aligning pictorial cues [4], shape correspondence [1], and mo eling the constellation of parts [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pictorial structures for objec  t recognition.Intl"
            },
            "venue": {
                "fragments": [],
                "text": "J. Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 99
                            }
                        ],
                        "text": "Note that improved performance may be achieved wi th variational inference for Dirichlet Processes [10, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 78
                            }
                        ],
                        "text": "Note that improved performance may be achieved with variational inference for Dirichlet Processes [10, 17]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric empirical ba yes for the Dirichlet process mixture model.Statistics and Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 99
                            }
                        ],
                        "text": "Note that improved performance may be achieved wi th variational inference for Dirichlet Processes [10, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 78
                            }
                        ],
                        "text": "Note that improved performance may be achieved with variational inference for Dirichlet Processes [10, 17]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A collapsed variational bayes ian inference algorithm for latent dirichlet allocation"
            },
            "venue": {
                "fragments": [],
                "text": "InAdvances in Neural Info. Proc. Systems"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 152
                            }
                        ],
                        "text": "Other models, exploiting knowledge of the scene context in w hich the objects reside, have proven successful in boosting object recognition performance [18 , 20, 15, 7, 13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Context-ba sed vision system for place and object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "InIntl. Conf. Computer Vision ,"
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 28,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Object-Recognition-by-Scene-Alignment-Russell-Torralba/2809f3a7f192f617a5cdf4c4e6b0fa84fb95aa50?sort=total-citations"
}