{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 147
                            }
                        ],
                        "text": "We propose a new incremental stochastic minimization (ISM) algorithm which has the bene ts of simulated annealing without many of the shortcomings [2, 3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 61
                            }
                        ],
                        "text": "For the remainder of the paper we focus on three constraints [2, 3]: data conservation, spatial coherence, and temporal coherence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206768565,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "e7c49a201daf302b8a7fd70729f1b08fcf4c1b90",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A model is proposed for the incremental estimation of visual motion fields from image sequences. The authors' model exploits three standard constraints on image motion within an optimization framework: (1) data conservation-the intensity structure of a surface patch changes gradually over time; (2) spatial coherence-neighboring points have similar motions; and (3) temporal coherence-the image velocity of a surface patch changes gradually. The authors' formulation takes into account the possibility of multiple motions at a particular location. They present an incremental scheme for the minimization of the objective function, based on simulated annealing. All computations are parallel, local, and incremental, and occlusion and disocclusion boundaries are estimated.<<ETX>>"
            },
            "slug": "A-model-for-the-detection-of-motion-over-time-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "A model for the detection of motion over time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An incremental scheme for the minimization of the objective function is presented, based on simulated annealing, and all computations are parallel, local, and incremental, and occlusion and disocclusion boundaries are estimated."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "The assumption however, ignores the case of motion discontinuities [4] and results in either errors in the motion estimate or over smoothing across discontinuities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29231806,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "2d604881bf3cb7232f0d6cbe19198ad77112b599",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Surface discontinuities are detected in a sequence of images by exploiting physical constraints at early stages in the processing of visual motion. To achieve accurate early discontinuity detection we exploit five physical constraints on the presence of discontinuities: i) the shape of the sum of squared differences (SSD) error surface in the presence of surface discontinuities; ii) the change in the shape of the SSD surface due to relative surface motion; iii) distribution of optic flow in a neighborhood of a discontinuity; iv) spatial consistency of discontinuities; V) temporal consistency of discontinuities. The constraints are described, and experimental results on sequences of real and synthetic images are presented. The work has applications in the recovery of environmental structure from motion and in the generation of dense optic flow fields."
            },
            "slug": "Constraints-for-the-Early-Detection-of-from-Motion-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "Constraints for the Early Detection of Discontinuity from Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This work exploits five physical constraints on the presence of discontinuities to achieve accurate early discontinuity detection and has applications in the recovery of environmental structure from motion and in the generation of dense optic flow fields."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143816432"
                        ],
                        "name": "G. Reynolds",
                        "slug": "G.-Reynolds",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Reynolds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Reynolds"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41223961,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9c99944a1a8f03e1081cf574d6f37fc372a84a56",
            "isKey": false,
            "numCitedBy": 1197,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The linear image restoration problem is to recover an original brightness distribution X/sup 0/ given the blurred and noisy observations Y=KX/sup 0/+B, where K and B represent the point spread function and measurement error, respectively. This problem is typical of ill-conditioned inverse problems that frequently arise in low-level computer vision. A conventional method to stabilize the problem is to introduce a priori constraints on X/sup 0/ and design a cost functional H(X) over images X, which is a weighted average of the prior constraints (regularization term) and posterior constraints (data term); the reconstruction is then the image X, which minimizes H. A prominent weakness in this approach, especially with quadratic-type stabilizers, is the difficulty in recovering discontinuities. The authors therefore examine prior smoothness constraints of a different form, which permit the recovery of discontinuities without introducing auxiliary variables for marking the location of jumps and suspending the constraints in their vicinity. In this sense, discontinuities are addressed implicitly rather than explicitly. >"
            },
            "slug": "Constrained-Restoration-and-the-Recovery-of-Geman-Reynolds",
            "title": {
                "fragments": [],
                "text": "Constrained Restoration and the Recovery of Discontinuities"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors examine prior smoothness constraints of a different form, which permit the recovery of discontinuities without introducing auxiliary variables for marking the location of jumps and suspending the constraints in their vicinity."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121534"
                        ],
                        "name": "J. Heel",
                        "slug": "J.-Heel",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Heel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Heel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 84
                            }
                        ],
                        "text": "This propagation can be viewed as warping the sites according to the motion estimate[2, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 116
                            }
                        ],
                        "text": "First we are exploring new formulations of the temporal minimization problem and its relationship to Kalman ltering [9, 11]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 32383187,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fd2ed11670c2a48afd529014f0f9a98d6ec2530a",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A solution is presented to the problem of obtaining and improving an estimate of the 3-D structure of a scene from a sequence of images. The algorithm, which combines single-frame reconstruction techniques and multiple-frame Kalman filtering, is tested on a variety of real motion image sequences.<<ETX>>"
            },
            "slug": "Temporally-integrated-surface-reconstruction-Heel",
            "title": {
                "fragments": [],
                "text": "Temporally integrated surface reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A solution is presented to the problem of obtaining and improving an estimate of the 3-D structure of a scene from a sequence of images, which combines single-frame reconstruction techniques and multiple-frame Kalman filtering."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Each level of the pyramid can be thought of as a MRF which is responsible for estimating motions of one pixel or less."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 205
                            }
                        ],
                        "text": "Various approaches have been presented for formulating the the spatial coherence assumption to account for motion discontinuities; in particular, the notion of weak continuity constraints has been popular [5, 7] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "For each site, we construct a probability density function de ned over the range of possible displacements using a Gibbs distribution [7] as follows:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 45
                            }
                        ],
                        "text": "Stochastic methods, like simulated annealing [7, 12], are one approach for minimizing such complex functions with many local minima."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 142
                            }
                        ],
                        "text": "The de nition of the constraints in terms of local neighborhoods on a grid allows the problem to be formalized as a Markov Random Field (MRF) [7, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 161
                            }
                        ],
                        "text": "This paper formulates more realistic constraints which account for multiple motions occurring at surface boundaries by exploiting the notions of weak continuity [5, 7] and robust statistics [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Each site in the MRF can be thought of as representing a small environmental surface patch."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "Standard simulated annealing techniques can be used to nd the minimum (u; v) by sampling from according to the distribution with logarithmicly decreasing temperatures[7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": true,
            "numCitedBy": 18711,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46283183"
                        ],
                        "name": "D. Vanderbilt",
                        "slug": "D.-Vanderbilt",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Vanderbilt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Vanderbilt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295048"
                        ],
                        "name": "S. Louie",
                        "slug": "S.-Louie",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Louie",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Louie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 106
                            }
                        ],
                        "text": "Since the mean of is u, the covariance matrix s, of\nthe state space is simply:\nsij = X\nu2\nui ujg(l): (13)\nVanderbilt and Louie [12] note that this can be expressed as:\ns = Q QT : (14)\nHence we can generate a state space with any desired covariance matrix s by solving for Q using Cholesky decomposition and then using Q to generate the state space in equation 12."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 45
                            }
                        ],
                        "text": "Stochastic methods, like simulated annealing [7, 12], are one approach for minimizing such complex functions with many local minima."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "The rst problem can be solved by using a continuous variant of simulated annealing [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Vanderbilt and Louie [12] note that this can be expressed as:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Vanderbilt and Louie[12] de ne a method which is adaptive in that the state space (dened by the step size, ut) adjusts to the local shape of the function being minimized."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120163318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e78fec456ae2973695a0f124f975de28c93bfb9",
            "isKey": true,
            "numCitedBy": 433,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Monte-carlo-simulated-annealing-approach-to-over-Vanderbilt-Louie",
            "title": {
                "fragments": [],
                "text": "A Monte carlo simulated annealing approach to optimization over continuous variables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 159
                            }
                        ],
                        "text": "In fact, we observe that the two problems are both special cases of the more general statistical problem of outlier rejection encountered in robust statistics [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "This function D is related to the redescending estimators used in robust statistics [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 190
                            }
                        ],
                        "text": "This paper formulates more realistic constraints which account for multiple motions occurring at surface boundaries by exploiting the notions of weak continuity [5, 7] and robust statistics [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "One way of characterizing the behavior of an error measure, (x), is by its in uence function, (x) = d dx (x) [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "W.,A, Robust Statistics: The Approach Based on  In uence Functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 101
                            }
                        ],
                        "text": "The line process variables can be removed from the smoothness constraint by rst minimizing over them [5, 6] resulting in an equivalent minimization problem:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 161
                            }
                        ],
                        "text": "This paper formulates more realistic constraints which account for multiple motions occurring at surface boundaries by exploiting the notions of weak continuity [5, 7] and robust statistics [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "This is a generalization of the Blake and Zisserman formulation [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 205
                            }
                        ],
                        "text": "Various approaches have been presented for formulating the the spatial coherence assumption to account for motion discontinuities; in particular, the notion of weak continuity constraints has been popular [5, 7] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13115760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "048e3a0904f7d964a0ade5da031a585dadc5a92f",
            "isKey": true,
            "numCitedBy": 1908,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Visual-Reconstruction-Blake-Zisserman",
            "title": {
                "fragments": [],
                "text": "Visual Reconstruction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 147
                            }
                        ],
                        "text": "We propose a new incremental stochastic minimization (ISM) algorithm which has the bene ts of simulated annealing without many of the shortcomings [2, 3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 61
                            }
                        ],
                        "text": "For the remainder of the paper we focus on three constraints [2, 3]: data conservation, spatial coherence, and temporal coherence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 84
                            }
                        ],
                        "text": "This propagation can be viewed as warping the sites according to the motion estimate[2, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "The new error surface can be interpolated by using bi{cubic splines[2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust dyanamic motion estimation over time,"
            },
            "venue": {
                "fragments": [],
                "text": "Yale University, Research Report YALEU/DCS/RR-835,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 106
                            }
                        ],
                        "text": "Since the mean of is u, the covariance matrix s, of\nthe state space is simply:\nsij = X\nu2\nui ujg(l): (13)\nVanderbilt and Louie [12] note that this can be expressed as:\ns = Q QT : (14)\nHence we can generate a state space with any desired covariance matrix s by solving for Q using Cholesky decomposition and then using Q to generate the state space in equation 12."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 45
                            }
                        ],
                        "text": "Stochastic methods, like simulated annealing [7, 12], are one approach for minimizing such complex functions with many local minima."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "The rst problem can be solved by using a continuous variant of simulated annealing [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Since the mean of is u, the covariance matrix s, of the state space is simply: sij = X u2 ui ujg(l): (13) Vanderbilt and Louie [12] note that this can be expressed as: s = Q QT : (14) Hence we can generate a state space with any desired covariance matrix s by solving for Q using Cholesky decomposition and then using Q to generate the state space in equation 12."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Vanderbilt and Louie[12] de ne a method which is adaptive in that the state space (dened by the step size, ut) adjusts to the local shape of the function being minimized."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A monte carlo sim-  ulated annealing approach to optimization over contin-  uous variables,"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Comp. Physics,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "For each site, we construct a probability density function de ned over the range of possible displacements using a Gibbs distribution [7] as follows: (u; v; t) = Z 1e H(u;v;t)=T (t); (11) where: Z = X (u;v)2 (t) e H(u;v;t)=T (t) and where t is the current time instance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Each level of the pyramid can be thought of as a MRF which is responsible for estimating motions of one pixel or less."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 205
                            }
                        ],
                        "text": "Various approaches have been presented for formulating the the spatial coherence assumption to account for motion discontinuities; in particular, the notion of weak continuity constraints has been popular [5, 7] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 45
                            }
                        ],
                        "text": "Stochastic methods, like simulated annealing [7, 12], are one approach for minimizing such complex functions with many local minima."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 142
                            }
                        ],
                        "text": "The de nition of the constraints in terms of local neighborhoods on a grid allows the problem to be formalized as a Markov Random Field (MRF) [7, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 161
                            }
                        ],
                        "text": "This paper formulates more realistic constraints which account for multiple motions occurring at surface boundaries by exploiting the notions of weak continuity [5, 7] and robust statistics [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Each site in the MRF can be thought of as representing a small environmental surface patch."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "Standard simulated annealing techniques can be used to nd the minimum (u; v) by sampling from according to the distribution with logarithmicly decreasing temperatures[7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic relaxation,  Gibbs distributions, and Bayesian restoration"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine In-  telligence, Vol. PAMI-6,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 147
                            }
                        ],
                        "text": "We propose a new incremental stochastic minimization (ISM) algorithm which has the bene ts of simulated annealing without many of the shortcomings [2, 3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 61
                            }
                        ],
                        "text": "For the remainder of the paper we focus on three constraints [2, 3]: data conservation, spatial coherence, and temporal coherence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 84
                            }
                        ],
                        "text": "This propagation can be viewed as warping the sites according to the motion estimate[2, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "The new error surface can be interpolated by using bi{cubic splines[2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust dyanamic mo-  tion estimation over time,\" Yale University, Research Re-  port YALEU/DCS/RR-835"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1962313"
                        ],
                        "name": "C. Jennison",
                        "slug": "C.-Jennison",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Jennison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jennison"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222264285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "855c9f9a51b0d0109560ea1abdb71a5497936415",
            "isKey": false,
            "numCitedBy": 521,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Robust-Statistics:-The-Approach-Based-on-Influence-Jennison",
            "title": {
                "fragments": [],
                "text": "Robust Statistics: The Approach Based on Influence Functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Figure 4: Pepsi can image sequence: a) Intensity image; b) Flow eld; c) Occlusion/Disocclusion Boundaries"
            },
            "venue": {
                "fragments": [],
                "text": "Figure 4: Pepsi can image sequence: a) Intensity image; b) Flow eld; c) Occlusion/Disocclusion Boundaries"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Each site in the MRF can be thought of as representing a small environmental surface patch."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 142
                            }
                        ],
                        "text": "The de nition of the constraints in terms of local neighborhoods on a grid allows the problem to be formalized as a Markov Random Field (MRF) [7, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Each level of the pyramid can be thought of as a MRF which is responsible for estimating motions of one pixel or less."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian estimation of motion elds from image sequences,"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Dissertation,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Figure 5: Nap-Of-the-Earth Helicopter Sequence. Snapshots of a 100 image sequence are shown with the current"
            },
            "venue": {
                "fragments": [],
                "text": "Figure 5: Nap-Of-the-Earth Helicopter Sequence. Snapshots of a 100 image sequence are shown with the current"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Figure 4: Pepsi can image sequence: a Intensity image; b Flow eld; c OcclusionnDisocclusion Boundaries"
            },
            "venue": {
                "fragments": [],
                "text": "Figure 4: Pepsi can image sequence: a Intensity image; b Flow eld; c OcclusionnDisocclusion Boundaries"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "Sub-pixel motion estimates can be obtained by interpolating the error surface [1, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kalman lter-  based algorithms for estimating depth from image se-  quences,"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. of Computer Vision,"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Robust-dynamic-motion-estimation-over-time-Black-Anandan/f5b4091691a32076c78a0f354994977230f95c23?sort=total-citations"
}