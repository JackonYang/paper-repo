{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 17
                            }
                        ],
                        "text": "It was shown in (Dagan et al., 1997) that a similarity-based smoothing method achieved much better results than backoff smoothing methods in word sense disambiguation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2480472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17126346c77db6436c0f0ec59c01b1e432ee4e7b",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We compare four similarity-based estimation methods against back-off and maximum-likelihood estimation methods on a pseudo-word sense disambiguation task in which we controlled for both unigram and bigram frequency. The similarity-based methods perform up to 40% better on this particular task. We also conclude that events that occur only once in the training set have major impact on similarity-based estimates."
            },
            "slug": "Similarity-Based-Methods-for-Word-Sense-Dagan-Lee",
            "title": {
                "fragments": [],
                "text": "Similarity-Based Methods for Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This work compares four similarity-based estimation methods against back-off and maximum-likelihood estimation methods on a pseudo-word sense disambiguation task in which both unigram and bigram frequency are controlled."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1394805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30a8f7577c1ccdbd14dcea85efdfae5420e1ccb6",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Most previous corpus-based algorithms disambiguate a word with a classifier trained from previous usages of the same word. Separate classifiers have to be trained for different words. We present an algorithm that uses the same knowledge sources to disambiguate different words. The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts."
            },
            "slug": "Using-Syntactic-Dependency-as-Local-Context-to-Word-Lin",
            "title": {
                "fragments": [],
                "text": "Using Syntactic Dependency as Local Context to Resolve Word Sense Ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An algorithm is presented that uses the same knowledge sources to disambiguate different words and does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 3
                            }
                        ],
                        "text": "In (Hindle, 1990), a small set of sample results are presented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 94
                            }
                        ],
                        "text": "It is worth noting that I ( w , r , w ' ) is equal to the mutual information between w and w' (Hindle, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15862538,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "f3f3dcfcaa960ec201e0381f4d026e57e64bea76",
            "isKey": false,
            "numCitedBy": 689,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject, verb and object in a large text corpus is described. The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "slug": "Noun-Classification-from-Predicate-Argument-Hindle",
            "title": {
                "fragments": [],
                "text": "Noun Classification from Predicate-Argument Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644031035"
                        ],
                        "name": "SmadjaFrank",
                        "slug": "SmadjaFrank",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "SmadjaFrank",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SmadjaFrank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215943452,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a1d430d43aef1e3c292128d197fb547e819428d4",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural languages are full of collocations, recurrent combinations of words that co-occur more often than expected by chance and that correspond to arbitrary word usages. Recent work in lexicograph..."
            },
            "slug": "Retrieving-collocations-from-text-SmadjaFrank",
            "title": {
                "fragments": [],
                "text": "Retrieving collocations from text"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Natural languages are full of collocations, recurrent combinations of words that co-occur more often than expected by chance and that correspond to arbitrary word usages."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6922975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cb09327e68400bf05e6f373e046a3a08e82510e",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In many applications of natural language processing it is necessary to determine the likelihood of a given word combination. For example, a speech recognizer may need to determine which of the two word combinations \"eat a peach\" and \"eat a beach\" is more likely. Statistical NLP methods determine the likelihood of a word combination according to its frequency in a training corpus. However, the nature of language is such that many word combinations are infrequent and do not occur in a given corpus. In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on \"most similar\" words.We describe a probabilistic word association model based on distributional word similarity, and apply it to improving probability estimates for unseen word bigrams in a variant of Katz's back-off model. The similarity-based method yields a 20% perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech-recognition error."
            },
            "slug": "Similarity-Based-Estimation-of-Word-Cooccurrence-Dagan-Pereira",
            "title": {
                "fragments": [],
                "text": "Similarity-Based Estimation of Word Cooccurrence Probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A probabilistic word association model based on distributional word similarity is described, and it is applied to improving probability estimates for unseen word bigrams in a variant of Katz's back-off model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 11
                            }
                        ],
                        "text": "similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59167516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4471e3117cdac2fae74d305d54b237bb3addd749",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Introduction. 2. Semantic Extraction. 3. Sextant. 4. Evaluation. 5. Applications. 6. Conclusion. 1: Preprocesors. 2. Webster Stopword List. 3: Similarity List. 4: Semantic Clustering. 5: Automatic Thesaurus Generation. 6. Corpora Treated. Index."
            },
            "slug": "Explorations-in-automatic-thesaurus-discovery-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Explorations in automatic thesaurus discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The aim of this monograph is to provide a catalog of words and phrases used in ThesaurusGeneration, as well as some examples of other writers' work, which have been used in similar contexts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119515866"
                        ],
                        "name": "G. Ruge",
                        "slug": "G.-Ruge",
                        "structuredName": {
                            "firstName": "Gerd",
                            "lastName": "Ruge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ruge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 19
                            }
                        ],
                        "text": "Ours is similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5517932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4966f2d75734b4abd4ad105b85eff675cb781b5d",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-on-Linguistically-Based-Term-Ruge",
            "title": {
                "fragments": [],
                "text": "Experiments on Linguistically-Based Term Associations"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 12
                            }
                        ],
                        "text": ", 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": "In (Dagan et\nal., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037240"
                        ],
                        "name": "U. Essen",
                        "slug": "U.-Essen",
                        "structuredName": {
                            "firstName": "Ute",
                            "lastName": "Essen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Essen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3214660"
                        ],
                        "name": "Volker Steinbiss",
                        "slug": "Volker-Steinbiss",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Steinbiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Steinbiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 173
                            }
                        ],
                        "text": "Another application of automatically extracted similar words is to help solve the problem of data sparseness in statistical natural language processing (Dagan et al., 1994; Essen and Steinbiss, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62555344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c80bcd31f077f9a632ce959278d1c2fc095131a8",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Training corpora for stochastic language models are virtually always too small for maximum-likelihood estimation, so smoothing the models is of great importance. The authors derive the cooccurrence smoothing technique for stochastic language modeling and give experimental evidence for its validity. Using word-bigram language models, cooccurrence smoothing improved the test-set perplexity by 14% on a German 100000-word text corpus and by 10% on an English 1-million word corpus.<<ETX>>"
            },
            "slug": "Cooccurrence-smoothing-for-stochastic-language-Essen-Steinbiss",
            "title": {
                "fragments": [],
                "text": "Cooccurrence smoothing for stochastic language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Using word-bigram language models, cooccurrence smoothing improved the test-set perplexity by 14% on a German 100000-word text corpus and by 10% on an English 1-million word corpus."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055976119"
                        ],
                        "name": "S. Marcus",
                        "slug": "S.-Marcus",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Marcus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2309269"
                        ],
                        "name": "Shaul Markovitch",
                        "slug": "Shaul-Markovitch",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Markovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaul Markovitch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1154960,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "8310a3f4ec3d6a37958c1c2aefe80b7b7badbca0",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In recent years there is much interest in word co-occurrence relations, such as n-grams, verb\u2013object combinations, or co-occurrence within a limited context. This paper discusses how to estimate the likelihood of co-occurrences that do not occur in the training data. We present a method that makes local analogies between each specific unobserved co-occurrence and other co-occurrences that contain similar words. These analogies are based on the assumption that similar word co-occurrences have similar values of mutual information. Accordingly, the word similarity metric captures similarities between vectors of mutual information values. Our evaluation suggests that this method performs better than existing, frequency-based, smoothing methods, and may provide an alternative to class-based models. A background survey is included, covering issues of lexical co-occurrence, data sparseness and smoothing, word similarity and clustering, and mutual information."
            },
            "slug": "Contextual-Word-Similarity-and-Estimation-From-Data-Dagan-Marcus",
            "title": {
                "fragments": [],
                "text": "Contextual Word Similarity and Estimation From Sparse Data"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The evaluation suggests that this method performs better than existing, frequency-based, smoothing methods, and may provide an alternative to class-based models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801071"
                        ],
                        "name": "Frank Smadja",
                        "slug": "Frank-Smadja",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Smadja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Smadja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 4
                            }
                        ],
                        "text": "In (Smadja, 1993), automatically extracted collocations are judged by a lexicographer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(Smadja, 1993), automatically extracted collocations are judged by a lexicographer."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16151922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3ff7801bcf72fea30117c88d397403a570c5c68",
            "isKey": false,
            "numCitedBy": 999,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural languages are full of collocations, recurrent combinations of words that co-occur more often than expected by chance and that correspond to arbitrary word usages. Recent work in lexicography indicates that collocations are pervasive in English; apparently, they are common in all types of writing, including both technical and nontechnical genres. Several approaches have been proposed to retrieve various types of collocations from the analysis of large samples of textual data. These techniques automatically produce large numbers of collocations along with statistical figures intended to reflect the relevance of the associations. However, none of these techniques provides functional information along with the collocation. Also, the results produced often contained improper word associations reflecting some spurious aspect of the training corpus that did not stand for true collocations.In this paper, we describe a set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora. These techniques produce a wide range of collocations and are based on some original filtering methods that allow the production of richer and higher-precision output. These techniques have been implemented and resulted in a lexicographic tool, Xtract. The techniques are described and some results are presented on a 10 million-word corpus of stock market news reports. A lexicographic evaluation of Xtract as a collocation retrieval tool has been made, and the estimated precision of Xtract is 80%."
            },
            "slug": "Retrieving-Collocations-from-Text:-Xtract-Smadja",
            "title": {
                "fragments": [],
                "text": "Retrieving Collocations from Text: Xtract"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora, based on some original filtering methods that allow the production of richer and higher-precision output are described."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 31
                            }
                        ],
                        "text": "We use a broad-coverage parser (Lin, 1993; Lin, 1994) to extract dependency triples from the text corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6106375,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b8e5d7da8441f0d44dac7ac3b87050d653bfa1a",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an efficient, broad-coverage, principle-based parser for English. The parser has been implemented in C++ and runs on SUN Sparcstations with X-windows. It contains a lexicon with over 90,000 entries, constructed automatically by applying a set of extraction and conversion rules to entries from machine readable dictionaries."
            },
            "slug": "PRINCIPAR-An-Efficient,-Broad-coverage,-Parser-Lin",
            "title": {
                "fragments": [],
                "text": "PRINCIPAR - An Efficient, Broad-coverage, Principle-based Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An efficient, broad-coverage, principle-based parser for English that contains a lexicon with over 90,000 entries, constructed automatically by applying a set of extraction and conversion rules to entries from machine readable dictionaries."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66511259"
                        ],
                        "name": "R. Beckwith",
                        "slug": "R.-Beckwith",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Beckwith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beckwith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145386345"
                        ],
                        "name": "Derek Gross",
                        "slug": "Derek-Gross",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113623689"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "5 (Miller et al., 1990) and Roget Thesaurus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 137
                            }
                        ],
                        "text": "Nouns\nRank Respective Nearest Neighbors Similarity 1 earnings profit 0.572525\n11 plan proposal 0.47475 21 employee worker 0.413936 31 battle fight 0.389776 41 airline carrier 0.370589 51 share stock 0.351294 61 rumor speculation 0.327266 71 outlay spending 0.320535 81 accident incident 0.310121 91\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2146137,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4bd970a37c59c97804ff93cbb2c108e081de3a37",
            "isKey": true,
            "numCitedBy": 5334,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought."
            },
            "slug": "Introduction-to-WordNet:-An-On-line-Lexical-Miller-Beckwith",
            "title": {
                "fragments": [],
                "text": "Introduction to WordNet: An On-line Lexical Database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163834"
                        ],
                        "name": "W. Frakes",
                        "slug": "W.-Frakes",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Frakes",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Frakes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389957009"
                        ],
                        "name": "R. Baeza-Yates",
                        "slug": "R.-Baeza-Yates",
                        "structuredName": {
                            "firstName": "Ricardo",
                            "lastName": "Baeza-Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baeza-Yates"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 125
                            }
                        ],
                        "text": "The measures sim ,.- / , sim , and sim 687 , 7 % are versions of similarity measures commonly used in information retrieval (Frakes and Baeza-Yates, 1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62157473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f133e39f3fb543f25a1a75400b81c0d42c6a91c",
            "isKey": false,
            "numCitedBy": 1720,
            "numCiting": 211,
            "paperAbstract": {
                "fragments": [],
                "text": "An edited volume containing data structures and algorithms for information retrieved including a disk with examples written in C. For programmers and students interested in parsing text, automated indexing, its the first collection in book form of the basic data structures and algorithms that are critical to the storage and retrieval of documents."
            },
            "slug": "Information-Retrieval:-Data-Structures-and-Frakes-Baeza-Yates",
            "title": {
                "fragments": [],
                "text": "Information Retrieval: Data Structures and Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "For programmers and students interested in parsing text, automated indexing, its the first collection in book form of the basic data structures and algorithms that are critical to the storage and retrieval of documents."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767307"
                        ],
                        "name": "H. Alshawi",
                        "slug": "H.-Alshawi",
                        "structuredName": {
                            "firstName": "Hiyan",
                            "lastName": "Alshawi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alshawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35408831"
                        ],
                        "name": "D. Carter",
                        "slug": "D.-Carter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Carter",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Carter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 153
                            }
                        ],
                        "text": "Another application of automatically extracted similar words is to help solve the problem of data sparseness in statistical natural language processing (Dagan et al., 1994; Essen and Steinbiss, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1714108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3376bc52798561e74f82ae92d2ea55bdf8b2bcce",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an automatic method for weighting the contributions of preference functions used in disambiguation. Initial scaling factors are derived as the solution to a least squares minimization problem, and improvements are then made by hill climbing. The method is applied to disambiguating sentences in the Air Travel Information System corpus, and the performance of the resulting scaling factors is compared with hand-tuned factors. We then focus on one class of preference function, those based on semantic lexical collocations. Experimental results are presented showing that such functions vary considerably in selecting correct analyses. In particular, we define a function that performs significantly better than ones based on mutual information and likelihood ratios of lexical associations."
            },
            "slug": "Training-and-Scaling-Preference-Functions-for-Alshawi-Carter",
            "title": {
                "fragments": [],
                "text": "Training and Scaling Preference Functions for Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An automatic method for weighting the contributions of preference functions used in disambiguation is presented, and a function that performs significantly better than ones based on mutual information and likelihood ratios of lexical associations is defined."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704065"
                        ],
                        "name": "D. Gentner",
                        "slug": "D.-Gentner",
                        "structuredName": {
                            "firstName": "Dedre",
                            "lastName": "Gentner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gentner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "It has been argued that similarity plays an important role in word acquisition (Gentner, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11251968,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "022bdaf499ce6ab730fb618ab90b749443f339d5",
            "isKey": false,
            "numCitedBy": 1080,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "ABSTRACT There is overwhelming evidence that children's first words are primarily nouns even across languages. These data are interpreted as evidence of a \"Natural Partitions Theory,\" one that holds that the concepts referred to by nouns are conceptually more basic than those referred to by verbs or prepositions. Analysis of data from cross-linguistic studies designed to eliminate Inonconceptual differences between words in a language that might account for the Larlier acquisition of nouns--such as the position of a word in the sentence, morphological transparency (the ease with which the root can be heard in various uses of the word), and patterns of language teaching strategies--leaves some version of the Natural Partitions hypothesis as the most reasonable view of early vocabulary acquisition. A cross-linguistic examination of a single sentence suggests that if objecthood is created by spatial relations among perceptual elements, then good concrete objects are particularly cohesive collections of percepts. These highly cohesive collections of perceptual information tend to be lexicalized as nouns by almost every language. Object concepts are given to language users by the world and can be learned one at a time, while predicate concepts form a system in each language., that, from a child's point of view, must be discovered. (HTE)"
            },
            "slug": "Why-Nouns-Are-Learned-before-Verbs:-Linguistic-No.-Gentner",
            "title": {
                "fragments": [],
                "text": "Why Nouns Are Learned before Verbs: Linguistic Relativity Versus Natural Partitioning. Technical Report No. 257."
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "There is overwhelming evidence that children's first words are primarily nouns even across languages, and a cross-linguistic examination of a single sentence suggests that if objecthood is created by spatial relations among perceptual elements, then good concrete objects are particularly cohesive collections of percepts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 32
                            }
                        ],
                        "text": "We use a broad-coverage parser (Lin, 1993; Lin, 1994) to extract dependency triples from the text corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9541345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d431d03433275a68bd4ccd6b97af665bb979294d",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Overgeneration is the main source of computational complexity in previous principle-based parsers. This paper presents a message passing algorithm for principle-based parsing that avoids the overgeneration problem. This algorithm has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "slug": "Principle-Based-Parsing-without-Overgeneration-Lin",
            "title": {
                "fragments": [],
                "text": "Principle-Based Parsing without Overgeneration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A message passing algorithm for principle-based parsing that avoids the overgeneration problem is presented and has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 55
                            }
                        ],
                        "text": "Consider the following (slightly modified) example in (Nida, 1975, p.167):\n(1) A bottle of tezgu\u0308ino is on the table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Componential Analysis of Meaning . The Hague"
            },
            "venue": {
                "fragments": [],
                "text": "Componential Analysis of Meaning . The Hague"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 55
                            }
                        ],
                        "text": "Consider the following (slightly modified) example in (Nida, 1975, p.167):\n(1) A bottle of tezgu\u0308ino is on the table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ComponentialAnalysis of Meaning . The Hague"
            },
            "venue": {
                "fragments": [],
                "text": "ComponentialAnalysis of Meaning . The Hague"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119515866"
                        ],
                        "name": "G. Ruge",
                        "slug": "G.-Ruge",
                        "structuredName": {
                            "firstName": "Gerd",
                            "lastName": "Ruge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ruge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 54
                            }
                        ],
                        "text": "Ours is similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 234359709,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "52087784e889ad4c4a9343d4a6edfb6c8b071027",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-on-linguistically-based-term-Ruge",
            "title": {
                "fragments": [],
                "text": "Experiments on linguistically based term associations"
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 4
                            }
                        ],
                        "text": "In (Smadja, 1993), automatically extracted collocations are judged by a lexicographer."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Retrieving collocations from text: Xtract. Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Retrieving collocations from text: Xtract. Computational Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frakes and R. Baeza-Yates, editors. 1992. In. formation Retrieval, Data Structure and Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet: An on-line lexi"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ComponentialAnalysis of Meaning"
            },
            "venue": {
                "fragments": [],
                "text": "The Hague, Mouton."
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frakes and R. Baeza-Yates, editors. 1992. Information Retrieval, Data Structure and Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 125
                            }
                        ],
                        "text": "The measures sim ,.- / , sim , and sim 687 , 7 % are versions of similarity measures commonly used in information retrieval (Frakes and Baeza-Yates, 1992)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "formation Retrieval, Data Structure and Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "formation Retrieval, Data Structure and Algorithms"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 32
                            }
                        ],
                        "text": "We use a broad-coverage parser (Lin, 1993; Lin, 1994) to extract dependency triples from the text corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principle-based parsing without"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 16
                            }
                        ],
                        "text": "The similarity measure can then be used to create a thesaurus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 17
                            }
                        ],
                        "text": "It was shown in (Dagan et al., 1997) that a similarity-based smoothing method achieved much better results than backoff smoothing methods in word sense disambiguation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Similarity-based method for word sense disambiguation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 35th Annual Meeting of the ACL"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 54
                            }
                        ],
                        "text": "Ours is similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 11
                            }
                        ],
                        "text": "similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experiments on linguistically based"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatic-Retrieval-and-Clustering-of-Similar-Words-Lin/fd1901f34cc3673072264104885d70555b1a4cdc?sort=total-citations"
}