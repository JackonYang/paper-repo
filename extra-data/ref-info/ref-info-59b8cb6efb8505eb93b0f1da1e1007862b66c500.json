{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719698"
                        ],
                        "name": "M. Crucianu",
                        "slug": "M.-Crucianu",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Crucianu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Crucianu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145645182"
                        ],
                        "name": "N. Vincent",
                        "slug": "N.-Vincent",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "Our column finding method is somewhat based on the algorithm described in [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18293386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "275d79256336a53141e6602d5fdf736139e90b8f",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with the extraction of tables from exchange format representations of very diverse composite documents. We put forward a flexible representation scheme for complex tables, based on a clear distinction between the physical layout of a table and its logical structure. Relying on this scheme, we develop a new method for the detection and the extraction of tables by an analysis of the graphic lines. To deal with tables that lack all or most of the graphic marks, one must focus on the regularities of the text elements alone. We propose such a method, based on a multi-level analysis of the layout of text components on a page. A general graph representation of the relative positions of blocks of text is exploited."
            },
            "slug": "Detection,-extraction-and-representation-of-tables-Ramel-Crucianu",
            "title": {
                "fragments": [],
                "text": "Detection, extraction and representation of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A flexible representation scheme for complex tables is put forward, based on a clear distinction between the physical layout of a table and its logical structure, and a new method for the detection and the extraction of tables by an analysis of the graphic lines is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "In comparison, there are numerous techniques for information extraction from tables in web pages [6], monospaced terminal documents [3] and scanned images of pages [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206405589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "108030474840ce5e1086cc8ef598ff3e6c13693c",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient approach to identify tabular structures within either electronic or paper documents. The resulting T-Recs system takes word bounding box information as input, and outputs the corresponding logical text block units. Starting with an arbitrary word as block seed the algorithm recursively expands this block to all words that interleave with their vertical neighbors. Since even smallest gaps of table columns prevent their words from mutual interleaving, this initial segmentation is able to identify and isolate such columns. In order to deal with some inherent segmentation errors caused by isolated lines, overhanging words, or cells spawning more than one column, a series of postprocessing steps is added. These steps benefit form a very simple distinction between type 1 and type 2 blocks: type 1 blocks are those of at most one word per line, all others are of type 2. This distinction allows the selective application of heuristics to each group of blocks. The conjoint decomposition of column blocks into subsets of table cells leads to the final block segmentation of a homogeneous abstraction level. These segments serve the final layout analysis which identifies table environments and cells that are stretching over several rows and/or columns."
            },
            "slug": "Table-structure-recognition-based-on-robust-block-Kieninger",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on robust block segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An efficient approach to identify tabular structures within either electronic or paper documents by taking word bounding box information as input, and outputs the corresponding logical text block units through the T-Recs system."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747132"
                        ],
                        "name": "Marco Aiello",
                        "slug": "Marco-Aiello",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Aiello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Aiello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696402"
                        ],
                        "name": "Christof Monz",
                        "slug": "Christof-Monz",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Monz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Monz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844464"
                        ],
                        "name": "L. Todoran",
                        "slug": "L.-Todoran",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Todoran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Todoran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "The majority of segmentation algorithms, such as those in [2], work on a binarized bitmap image, rather than a higher level representation of the document (such as objects from a PDF) as input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3112837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9569ead4e9e52e9f418aedb63a83448e4651834c",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a document analysis system able to assign logical labels and extract the reading order in a broad set of documents. All information sources, from geometric features and spatial relations to the textual features and content are employed in the analysis. To deal effectively with these information sources, we define a document representation general and flexible enough to represent complex documents. To handle such a broad document class, it uses generic document knowledge only, which is identified explicitly. The proposed system inte- grates components based on computer vision, artificial intelligence, and natural language processing techniques. The system is fully implemented and experimental re- sults on heterogeneous collections of documents for each component and for the entire system are presented."
            },
            "slug": "Document-understanding-for-a-broad-class-of-Aiello-Monz",
            "title": {
                "fragments": [],
                "text": "Document understanding for a broad class of documents"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A document analysis system able to assign logical labels and extract the reading order in a broad set of documents based on computer vision, artificial intelligence, and natural language processing techniques is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Document Anal. Recognit."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000882"
                        ],
                        "name": "Wolfgang Gatterbauer",
                        "slug": "Wolfgang-Gatterbauer",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Gatterbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Gatterbauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308385"
                        ],
                        "name": "Paul Bohunsky",
                        "slug": "Paul-Bohunsky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Bohunsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Bohunsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6474907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c506ce95dcdd45831eb4785c638b4767e1e995e",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables on web pages contain a huge amount of semantically explicit information, which makes them a worthwhile target for automatic information extraction and knowledge acquisition from the Web. However, the task of table extraction from web pages is difficult, because of HTML's design purpose to convey visual instead of semantic information. In this paper, we propose a robust technique for table extraction from arbitrary web pages. This technique relies upon the positional information of visualized DOM element nodes in a browser and, hereby, separates the intricacies of code implementation from the actual intended visual appearance. The novel aspect of the proposed web table extraction technique is the effective use of spatial reasoning on the CSS2 visual box model, which shows a high level of robustness even without any form of learning (F-measure \u2248 90%). We describe the ideas behind our approach, the tabular pattern recognition algorithm operating on a double topographical grid structure and allowing for effective and robust extraction, and general observations on web tables that should be borne in mind by any automatic web table extraction mechanism."
            },
            "slug": "Table-Extraction-Using-Spatial-Reasoning-on-the-Box-Gatterbauer-Bohunsky",
            "title": {
                "fragments": [],
                "text": "Table Extraction Using Spatial Reasoning on the CSS2 Visual Box Model"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a robust technique for table extraction from arbitrary web pages that relies upon the positional information of visualized DOM element nodes in a browser and separates the intricacies of code implementation from the actual intended visual appearance."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126865"
                        ],
                        "name": "Yasuto Ishitani",
                        "slug": "Yasuto-Ishitani",
                        "structuredName": {
                            "firstName": "Yasuto",
                            "lastName": "Ishitani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasuto Ishitani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3212073"
                        ],
                        "name": "Kosei Fume",
                        "slug": "Kosei-Fume",
                        "structuredName": {
                            "firstName": "Kosei",
                            "lastName": "Fume",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kosei Fume"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145111101"
                        ],
                        "name": "Kazuo Sumita",
                        "slug": "Kazuo-Sumita",
                        "structuredName": {
                            "firstName": "Kazuo",
                            "lastName": "Sumita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuo Sumita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "In comparison, there are numerous techniques for information extraction from tables in web pages [6], monospaced terminal documents [3] and scanned images of pages [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 25290073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "956761b81d37afbcfe3aff1b621f07a9eb098d05",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of table structure analysis based on cell classification and cell modification is proposed in this paper as the basis of an OCR which can convert a variety of printed tables into XML documents in accordance with a specified XML schema. The outline of this method is described as follows. Firstly, cell features defined by ruled lines, which correspond to data fields, are extracted from the input image of a table. After that, each cell is classified to identify the irregular table whose ruled lines are not gridded and is modified to form regular cell arrangement. Next, the hierarchical table structure consisting of a regular row structure of cells is extracted from the modified regular table and is described using a DOM tree. In this case, logical objects within a cell are extracted and are converted into a sub-tree in the DOM tree. Finally, this DOM tree is transformed into a target XML document by an XML parser with information extraction process. Experimental results show the method is effective in transforming various printed tables to various XML documents."
            },
            "slug": "Table-structure-analysis-based-on-cell-and-cell-for-Ishitani-Fume",
            "title": {
                "fragments": [],
                "text": "Table structure analysis based on cell classification and cell modification for XML document transformation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new method of table structure analysis based on cell classification and cell modification is proposed as the basis of an OCR which can convert a variety of printed tables into XML documents in accordance with a specified XML schema."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12345366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68da4b0057bf09c11ba157acaed006bf4931f034",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a computational paradigm called Data Driven Markov Chain Monte Carlo (DDMCMC) for image segmentation in the Bayesian, statistical framework. The paper contributes to image segmentation in three aspects. Firstly, it designs effective and well balanced Markov Chain dynamics to explore the solution space and makes the split and merge process reversible at a middle level vision formulation. Thus it achieves globally optimal solution independent of initial segmentations. Secondly, instead of computing a single maximum a posteriori solution, it proposes a mathematical principle for computing multiple distinct solutions to incorporates intrinsic ambiguities in image segmentation. A k-adventurers algorithm is proposed for extracting distinct multiple solutions from the Markov chain sequence. Thirdly, it utilizes data-driven (bottom-up) techniques, such as clustering and edge detection, to compute importance proposal probabilities, which effectively drive the Markov chain dynamics and achieve tremendous speedup in comparison to traditional jump-diffusion method. Thus DDM-CMC paradigm provides a unifying framework where the role of existing segmentation algorithms, such as; edge detection, clustering, region growing, split-merge, SNAKEs, region competition, are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities. We report some results on color and grey level image segmentation in this paper and refer to a detailed report and a web site for extensive discussion."
            },
            "slug": "Image-segmentation-by-data-driven-Markov-chain-Tu-Zhu",
            "title": {
                "fragments": [],
                "text": "Image segmentation by data driven Markov chain Monte Carlo"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The DDM-CMC paradigm provides a unifying framework where the role of existing segmentation algorithms, such as; edge detection, clustering, region growing, split-merge, SNAKEs, region competition, are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 6,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Table-Recognition-and-Understanding-from-PDF-Files-Hassan-Baumgartner/59b8cb6efb8505eb93b0f1da1e1007862b66c500?sort=total-citations"
}