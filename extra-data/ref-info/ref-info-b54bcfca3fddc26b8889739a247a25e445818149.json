{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937779"
                        ],
                        "name": "R. Kuhn",
                        "slug": "R.-Kuhn",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31924166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be1fed9544830df1137e72b1d2396c40d3e18365",
            "isKey": false,
            "numCitedBy": 580,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech-recognition systems must often decide between competing ways of breaking up the acoustic input into strings of words. Since the possible strings may be acoustically similar, a language model is required; given a word string, the model returns its linguistic probability. Several Markov language models are discussed. A novel kind of language model which reflects short-term patterns of word use by means of a cache component (analogous to cache memory in hardware terminology) is presented. The model also contains a 3g-gram component of the traditional type. The combined model and a pure 3g-gram model were tested on samples drawn from the Lancaster-Oslo/Bergen (LOB) corpus of English text. The relative performance of the two models is examined, and suggestions for the future improvements are made. >"
            },
            "slug": "A-Cache-Based-Natural-Language-Model-for-Speech-Kuhn-Mori",
            "title": {
                "fragments": [],
                "text": "A Cache-Based Natural Language Model for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A novel kind of language model which reflects short-term patterns of word use by means of a cache component (analogous to cache memory in hardware terminology) is presented and contains a 3g-gram component of the traditional type."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145502114"
                        ],
                        "name": "R. Reddy",
                        "slug": "R.-Reddy",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Reddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reddy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60893878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28bb28488c30e26b047916cbc3276bee213c7ab9",
            "isKey": false,
            "numCitedBy": 1933,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \n \nNew advances in spoken language processing: theory and practice \nIn-depth coverage of speech processing, speech recognition, speech synthesis, spoken language understanding, and speech interface design \nMany case studies from state-of-the-art systems, including examples from Microsoft's advanced research labs \n \n \nSpoken Language Processing draws on the latest advances and techniques from multiple fields: computer science, electrical engineering, acoustics, linguistics, mathematics, psychology, and beyond. Starting with the fundamentals, it presents all this and more: \n \nEssential background on speech production and perception, probability and information theory, and pattern recognition \nExtracting information from the speech signal: useful representations and practical compression solutions \nModern speech recognition techniques: hidden Markov models, acoustic and language modeling, improving resistance to environmental noises, search algorithms, and large vocabulary speech recognition \nText-to-speech: analyzing documents, pitch and duration controls; trainable synthesis, and more \nSpoken language understanding: dialog management, spoken language applications, and multimodal interfaces \n \n \nTo illustrate the book's methods, the authors present detailed case studies based on state-of-the-art systems, including Microsoft's Whisper speech recognizer, Whistler text-to-speech system, Dr. Who dialog system, and the MiPad handheld device. Whether you're planning, designing, building, or purchasing spoken language technology, this is the state of the art\u0097fromalgorithms through business productivity."
            },
            "slug": "Spoken-Language-Processing:-A-Guide-to-Theory,-and-Huang-Acero",
            "title": {
                "fragments": [],
                "text": "Spoken Language Processing: A Guide to Theory, Algorithm and System Development"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Spoken Language Processing draws on the latest advances and techniques from multiple fields: computer science, electrical engineering, acoustics, linguistics, mathematics, psychology, and beyond to create the state of the art in spoken language technology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 240
                            }
                        ],
                        "text": "Although SLP may not suffice for a course that concentrates on the stochastic approach alone, some instructors may nonetheless find J&M\u2019s tutorial level of exposition more suitable than either Charniak\u2019s (1993) terse account or Manning and Sch\u00fctze\u2019s (1999) monumental tome."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": false,
            "numCitedBy": 7802,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962472"
                        ],
                        "name": "K. Knill",
                        "slug": "K.-Knill",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Knill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Knill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62341327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d5bdd21948b057b7bd1bdef487790a8f063c387",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech is an acoustic representation of a word or sequence of words, characterized by a slowly changing spectral envelope. Humans perceive this spectral envelope, and convert it into the underlying word string and its associated meaning. The ultimate goal of speech and language processing is to mimic this process so that a machine can hold a natural conversation with a human. Speech and language processing has a far wider role to play, however, in performing less complex tasks such as transcription, language identification, or audio document retrieval, all of which are feasible to a certain extent now. The basic step in all of these systems is to perform the inverse mapping of the speech into the underlying sequence of symbols, usually words, that produced it, as shown in Fig. 2.1. This chapter describes a statistical approach to solving the automatic speech recognition problem, based on stochastic Markov process models."
            },
            "slug": "Hidden-Markov-Models-in-Speech-and-Language-Knill-Young",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Models in Speech and Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This chapter describes a statistical approach to solving the automatic speech recognition problem, based on stochastic Markov process models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5371566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b84276fe751ca4f1389549281383b151a746107b",
            "isKey": false,
            "numCitedBy": 1140,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nEugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background. \nNew, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises. \nCharniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: \"one simply gathers statistics.\" \nLanguage, Speech, and Communication"
            },
            "slug": "Statistical-language-learning-Charniak",
            "title": {
                "fragments": [],
                "text": "Statistical language learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Eugene Charniak points out that as a method of attacking NLP problems, the statistical approach has several advantages and is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38697325,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "22b6737a38179c01444d69443e327850c9956c15",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current attempts at automatic speech recognition are formulated in an artificial intelligence framework. In this paper we approach the problem from an information-theoretic point of view. We describe the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech. The input to the decoder is a string of phonetic symbols estimated by an acoustic processor (AP). For each phonetic string, the decoder finds the most likely input sentence. The decoder consists of four major subparts: 1) a statistical model of the language being recognized; 2) a phonemic dictionary and statistical phonological rules characterizing the speaker; 3) a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP; 4) a word level search control. The details of each of the subparts and their interaction during the decoding process are discussed."
            },
            "slug": "Design-of-a-linguistic-statistical-decoder-for-the-Jelinek-Bahl",
            "title": {
                "fragments": [],
                "text": "Design of a linguistic statistical decoder for the recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech and describes a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510215"
                        ],
                        "name": "M. Woszczyna",
                        "slug": "M.-Woszczyna",
                        "structuredName": {
                            "firstName": "Monika",
                            "lastName": "Woszczyna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Woszczyna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21614110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23cba88fec7f54185b286ce332a51907ff15e2fb",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate the applications of Markov Chains and HMMs to modeling of the underlying structure in spontaneous spoken language. Experiments with supervised training cover the detection of the current dialog state and identi cation of the speech act as used by the speech translation component in our JANUS Speech-to-Speech Translation System. HMM training with hidden states is used to uncover other levels of structure in the task. The possible use of the model for perplexity reduction in a continuous speech recognition system is also demonstrated. To achieve improvement over a state independent bigram language model, great care must be taken to keep the number of model parameters small in the face of limited amounts of training data from transcribed spontaneous speech."
            },
            "slug": "Inferring-linguistic-structure-in-spoken-language-Woszczyna-Waibel",
            "title": {
                "fragments": [],
                "text": "Inferring linguistic structure in spoken language"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The applications of Markov Chains and HMMs to modeling of the underlying structure in spontaneous spoken language and the possible use of the model for perplexity reduction in a continuous speech recognition system are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122690"
                        ],
                        "name": "X. Aubert",
                        "slug": "X.-Aubert",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Aubert",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Aubert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9495961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e06538e4eb5bb904f42dda1a0d4c1f74b2755b4d",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of using word graphs (or lattices) for the integration of complex knowledge sources like long span language models or acoustic cross-word models, in large vocabulary continuous speech recognition. A method for efficiently constructing a word graph is reviewed and two ways of exploiting it are presented. By assuming the word pair approximation, a phrase level search is possible while in the other case a general graph decoder is set up. We show that the predecessor-word identity provided by a first bigram decoding might be used to constrain the word graph without impairing the next pass. This procedure has been applied to 64 k-word trigram decoding in conjunction with an incremental unsupervised speaker adaptation scheme. Experimental results are given for the North American Business corpus used in the November '94 evaluation."
            },
            "slug": "Large-vocabulary-continuous-speech-recognition-word-Aubert-Ney",
            "title": {
                "fragments": [],
                "text": "Large vocabulary continuous speech recognition using word graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that the predecessor-word identity provided by a first bigram decoding might be used to constrain the word graph without impairing the next pass, and tested for the North American Business corpus used in the November '94 evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "1995 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144982775"
                        ],
                        "name": "W. Fisher",
                        "slug": "W.-Fisher",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Fisher",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35577831"
                        ],
                        "name": "J. Bernstein",
                        "slug": "J.-Bernstein",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Bernstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786370"
                        ],
                        "name": "D. Pallett",
                        "slug": "D.-Pallett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pallett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pallett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60461029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2a4080f0587dea4c4ff98d18fb1e22273a71665",
            "isKey": false,
            "numCitedBy": 394,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A database of continuous read speech has been designed and recorded within the DARPA strategic computing speech recognition program. The data is intended for use in designing and evaluating algorithms for speaker-independent, speaker-adaptive and speaker-dependent speech recognition. The data consists of read sentences appropriate to a naval resource management task built around existing interactive database and graphics programs. The 1000-word task vocabulary is intended to be logically complete and habitable. The database, which represents over 21000 recorded utterances from 160 talkers with a variety of dialects, includes a partition of sentences and talkers for training and for testing purposes.<<ETX>>"
            },
            "slug": "The-DARPA-1000-word-resource-management-database-Price-Fisher",
            "title": {
                "fragments": [],
                "text": "The DARPA 1000-word resource management database for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A database of continuous read speech has been designed and recorded within the DARPA strategic computing speech recognition program for use in designing and evaluating algorithms for speaker-independent, speaker-adaptive and speaker-dependent speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 162343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f052a08bc272130d3e4554ca9e00a190a1cb98",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the past 40 years, significant progress has been made in the fields of speech recognition and speech understanding. Current state-of-the-art speech recognition systems are capable of achieving word-level accuracies of 90% to 95% on continuous speech recognition tasks using 5000 words. Even larger systems, capable of recognizing 20,000 words are just now being developed. Speech understanding systems have recently been developed that perform fairly well within a restricted domain. \nWhile the size and performance of modern speech recognition and understanding systems are impressive, it is evident to anyone who has used these systems that the technology is primitive compared to our own human ability to understand speech. Some of the difficulties hampering progress in the fields of speech recognition and understanding stem from the many sources of variation that occur during human communication. \nOne of the sources of variation that occurs in human communication is the different ways that words can be pronounced. There are many causes of pronunciation variation, such as: the phonetic environment in which the word occurs, the dialect of the speaker, the speaker's age, the speaker's gender, and the speaking rate. Some researchers have shown improvements in speech recognition performance on a read-speech task through the use of explicit pronunciation modeling, while others have not shown any significant improvements. \nThis thesis presents an algorithm for the construction of models that attempt to capture the variation that occurs in the pronunciations of words in spontaneous (i.e., non-read) speech. A technique for developing alternate pronunciations of words and then estimating the probabilities of the alternate pronunciations is presented. Additionally, we describe the development and implementation of a spoken-language understanding system called the Berkeley Restaurant Project (BeRP). Multiple pronunciation word models constructed using the algorithm proposed in this thesis are evaluated within the context of the BeRP system. The results of this evaluation show that the explicit modeling of variation in the pronunciation of words improves the performance of both the speech recognition and the speech understanding components of the BeRP system."
            },
            "slug": "Multiple-pronunciation-lexical-modeling-in-a-speech-Wooters-Stolcke",
            "title": {
                "fragments": [],
                "text": "Multiple-pronunciation lexical modeling in a speaker independent speech understanding system"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm for the construction of models that attempt to capture the variation that occurs in the pronunciations of words in spontaneous speech, which improves the performance of both the speech recognition and the speech understanding components of the BeRP system."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20391216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f90d340bbf9854a3c4e9436ba51f5fd090571fe",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 123,
            "paperAbstract": {
                "fragments": [],
                "text": "The past decade has witnessed substantial progress toward the goal of constructing a machine capable of understanding colloquial discourse. Central to this progress has been the development and application of mathematical methods that permit modeling the speech signal as a complex code with several coexisting levels of structure. The most successful of these are \"template matching,\" stochastic modeling, and probabilistic parsing. The manifestation of common themes such as dynamic programming and finite-state descriptions accentuates a superficial likeness amongst the methods which is often mistaken for the deeper similarity arising from their shared Bayesian foundation. In this paper, we outline the mathematical bases of these methods, invariant metrics, hidden Markov chains, and formal grammars, respectively. We then recount and briefly interpret the results of experiments in speech recognition to which the various methods were applied. Since these mathematical principles seem to bear little resemblance to traditional linguistic characterizations of speech, the success of the experiments is occasionally attributed, even by their authors, merely to excellent engineering. We conclude by speculating that, quite to the contrary, these methods actually constitute a powerful theory of speech that can be reconciled with and elucidate conventional linguistic theories while being used to build truly competent mechanical speech recognizers."
            },
            "slug": "Structural-methods-in-automatic-speech-recognition-Levinson",
            "title": {
                "fragments": [],
                "text": "Structural methods in automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is speculated that these mathematical principles constitute a powerful theory of speech that can be reconciled with and elucidate conventional linguistic theories while being used to build truly competent mechanical speech recognizers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38232647"
                        ],
                        "name": "R. Iyer",
                        "slug": "R.-Iyer",
                        "structuredName": {
                            "firstName": "Rukmini",
                            "lastName": "Iyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Iyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17106480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d34bb9fdc012b1953a318465796c2774cf9e45d6",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In language modeling for speech recognition the goal is to constrain the search of the speech recognizer by providing a model which can, given a context, indicate what the next most likely word will be. In this paper, we explore how the addition of information to the text, in particular part of speech and dysfluency annotations, can be used to,build more complex language models. In particular, we ask two questions. First, in conversational speech, where there is a less clear notion of \"sentence\" than in written text, does segmenting the text into linguistically or semantically based units contribute to a better language model than merely segmenting based on broad acoustic information, such as pauses. Second, is the sentence itself a good unit to be modeling, or should we look at smaller units, for example, dividing a sentence into a \"given\" and \"new\" portion and segmenting out acknowledgments and replies. To answer these questions, we present a variety of kinds of analysis, from vocabulary distributions to perplexities on language models. The next step will be modeling conversations and incorporating those models into a speech recognizer."
            },
            "slug": "Modeling-Conversational-Speech-for-Speech-Meteer-Iyer",
            "title": {
                "fragments": [],
                "text": "Modeling Conversational Speech for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper explores how the addition of information to the text, in particular part of speech and dysfluency annotations, can be used to,build more complex language models."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866226"
                        ],
                        "name": "W. Ward",
                        "slug": "W.-Ward",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Ward",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275657"
                        ],
                        "name": "S. Issar",
                        "slug": "S.-Issar",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Issar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Issar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11152803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7de46fb5eb895b4e1323c596715292239f45234",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We have been developing a spoken language system to recognize and understand spontaneous speech. It is difficult for such systems to achieve good coverage of the lexicon and grammar that subjects might use because spontaneous speech often contains disfluencies and ungrammatical constructions. Our goal is to respond appropriately to input, even though coverage is not complete. The natural language component of our system is oriented toward the extraction of information relevant to a task, and seeks to directly optimize the correctness of the extracted information (and therefore the system response). We use a flexible frame-based parser, which parses as much of the input as possible. This approach leads both to high accuracy and robustness. We have implemented a version of this system for the Air Travel Information Service (ATIS) task, which is being used by several ARPA-funded sites to develop and evaluate speech understanding systems. Users are asked to perform a task that requires getting information from an Air Travel database. In this paper, we describe recent improvements in our system resulting from our efforts to improve the coverage given a limited amount of training data. These improvements address a number of problems including generating an adequate lexicon and grammar for the recognizer, generating and generalizing an appropriate grammar for the parser, and dealing with ambiguous parses."
            },
            "slug": "Recent-Improvements-in-the-CMU-Spoken-Language-Ward-Issar",
            "title": {
                "fragments": [],
                "text": "Recent Improvements in the CMU Spoken Language Understanding System"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Recent improvements in the spoken language system to recognize and understand spontaneous speech are described, which address a number of problems including generating an adequate lexicon and grammar for the recognizer, generating and generalizing an appropriate grammar forThe parser, and dealing with ambiguous parses."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3113488"
                        ],
                        "name": "J. Klovstad",
                        "slug": "J.-Klovstad",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Klovstad",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Klovstad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69014957"
                        ],
                        "name": "L. Mondshein",
                        "slug": "L.-Mondshein",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Mondshein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Mondshein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62711889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec5f9b44e85149faee7a7b23231c4dff82611523",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "CASPERS (Computer-Automated Speech Perception System) is a user-modifiable facility for translating strings of acoustic Symbols into sentences. Three distinctive aspects of the system's design will be discussed: the dynamic application of acoustic-phonological rules across word boundaries, an acoustic-unit splitting-and merging strategy for treating the dictionary matching problem, and an extensive capability for handling semantic routines within an augmented context-free grammar."
            },
            "slug": "The-CASPERS-linguistic-analysis-system-Klovstad-Mondshein",
            "title": {
                "fragments": [],
                "text": "The CASPERS linguistic analysis system"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Three distinctive aspects of the CASPERS system's design will be discussed: the dynamic application of acoustic-phonological rules across word boundaries, an acoustic-unit splitting-and merging strategy for treating the dictionary matching problem, and an extensive capability for handling semantic routines within an augmented context-free grammar."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745131"
                        ],
                        "name": "S. Seneff",
                        "slug": "S.-Seneff",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Seneff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seneff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6668801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac8f1fd58be8a8c9f9599fc4da981ea3040945f6",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A new natural language system, TINA, has been developed for applications involving spoken language tasks. TINA integrates key ideas from context free grammars, Augmented Transition Networks (ATN's), and the unification concept. TINA provides a seamless interface between syntactic and semantic analysis, and also produces a highly constraining probabilistic language model to improve recognition performance. An initial set of context-free rewrite rules provided by hand is first converted to a network structure. Probability assignments on all arcs in the network are obtained automatically from a set of example sentences. The parser uses a stack decoding search strategy, with a top-down control flow, and includes a feature-passing mechanism to deal with long-distance movement, agreement, and semantic constraints. TINA provides an automatic sentence generation capability that has been effective for identifying overgeneralization problems as well as in producing a word-pair language model for a recognizer. The parser is currently integrated with MIT's SUMMIT recognizer for use in two application domains, with the parser screening recognizer outputs either at the sentential level or to filter partial theories during the active search process."
            },
            "slug": "TINA:-A-Natural-Language-System-for-Spoken-Language-Seneff",
            "title": {
                "fragments": [],
                "text": "TINA: A Natural Language System for Spoken Language Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new natural language system, TINA, has been developed for applications involving spoken language tasks that provides an automatic sentence generation capability that has been effective for identifying overgeneralization problems as well as in producing a word-pair language model for a recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275657"
                        ],
                        "name": "S. Issar",
                        "slug": "S.-Issar",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Issar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Issar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866226"
                        ],
                        "name": "W. Ward",
                        "slug": "W.-Ward",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Ward",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ward"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14935534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfc0e257791185750cb16ef3096513b3feb61ed9",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the general strategies followed in developing the CMU (Carnegie Mellon University) speech understanding system. Our system is oriented toward the extraction of information relevant to a task. It uses a exible frame-based parser. Our system handles phenomena that are natural in spontaneous speech, for example, restarts, repeats and grammatically ill-formed utterances. It maintains a history of the key features of the dialogue. It can resolve elliptical, anaphoric and other indirect references. In this paper, we pay particular attention to how the context is modeled in our system. We will describe how the system handles corrections and queries that execeed its capabilities. We also address the issue of loose vs. tight coupling of speech recognition and natural language processing. The system has been used to model an Air Travel Information Service (ATIS) Task. In the November 92 DARPA Spoken Language Systems benchmark evaluation, the CMU ATIS system correctly answered 93.5% transcript inputs and 88.9% speech inputs. These were the best numbers reported for the evaluation."
            },
            "slug": "CMLPs-robust-spoken-language-understanding-system-Issar-Ward",
            "title": {
                "fragments": [],
                "text": "CMLPs robust spoken language understanding system"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "How the CMU speech understanding system handles corrections and queries that execeed its capabilities is described and the issue of loose vs. tight coupling of speech recognition and natural language processing is addressed."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70422141"
                        ],
                        "name": "Elizabeth Shriberg",
                        "slug": "Elizabeth-Shriberg",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Shriberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Shriberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5927091,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "7ca226218763f06fe108cf836c83ae10171fad3d",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "As speech recognition moves toward more unconstrained domains such as conversational speech, we encounter a need to be able to segment (or resegment) waveforms and recognizer output into linguistically meaningful units such a sentences. Toward this end, we present a simple automatic segmenter of transcripts based on N-gram language modeling. We also study the relevance of several word-level features for segmentation performance. Using only word-level information, we achieve 85% recall and 70% precision on linguistic boundary detection."
            },
            "slug": "Automatic-linguistic-segmentation-of-conversational-Stolcke-Shriberg",
            "title": {
                "fragments": [],
                "text": "Automatic linguistic segmentation of conversational speech"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple automatic segmenter of transcripts based on N-gram language modeling that achieves 85% recall and 70% precision on linguistic boundary detection and study the relevance of several word-level features for segmentation performance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145184042"
                        ],
                        "name": "J. W. Merrill",
                        "slug": "J.-W.-Merrill",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Merrill",
                            "middleNames": [
                                "W.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. W. Merrill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4660196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a733492f597c4d0a27a24c8fffdf5d116fa7e09f",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The topic of this thesis is to built an accurate automatic speech recognition system to be able to recognize speech using Kaldi, an open-source toolkit for speech recognition written in C++ and with free data. First of all, the main process of automatic speech recognition is explained in details on first steps. Secondly, different approaches of training and adaptation techniques are studied in order to improve the recognition accuracy. Furthermore, as data size is a very important point in order to achieve enough recognition accuracy, the role of it, is also studied on this thesis."
            },
            "slug": "Automatic-speech-recognition-Merrill",
            "title": {
                "fragments": [],
                "text": "Automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This thesis aims to built an accurate automatic speech recognition system to be able to recognize speech using Kaldi, an open-source toolkit for speech recognition written in C++ and with free data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895193"
                        ],
                        "name": "C. T. Hemphill",
                        "slug": "C.-T.-Hemphill",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Hemphill",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. T. Hemphill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34972608"
                        ],
                        "name": "J. Godfrey",
                        "slug": "J.-Godfrey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Godfrey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Godfrey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1094063,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "1d19708290ef3cc3f43c2c95b07acdd4f52f5cda",
            "isKey": false,
            "numCitedBy": 628,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech research has made tremendous progress in the past using the following paradigm:\u2022 define the research problem,\u2022 collect a corpus to objectively measure progress, and\u2022 solve the research problem.Natural language research, on the other hand, has typically progressed without the benefit of any corpus of data with which to test research hypotheses. We describe the Air Travel Information System (ATIS) pilot corpus, a corpus designed to measure progress in Spoken Language Systems that include both a speech and natural language component. This pilot marks the first full-scale attempt to collect such a corpus and provides guidelines for future efforts."
            },
            "slug": "The-ATIS-Spoken-Language-Systems-Pilot-Corpus-Hemphill-Godfrey",
            "title": {
                "fragments": [],
                "text": "The ATIS Spoken Language Systems Pilot Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This pilot marks the first full-scale attempt to collect a corpus to measure progress in Spoken Language Systems that include both a speech and natural language component and provides guidelines for future efforts."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182856"
                        ],
                        "name": "S. Ortmanns",
                        "slug": "S.-Ortmanns",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Ortmanns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ortmanns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122690"
                        ],
                        "name": "X. Aubert",
                        "slug": "X.-Aubert",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Aubert",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Aubert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 68236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd8bdcd6969670e8e43ff74cf458cfd5804c9e2f",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper describes a method for the construction of a word graph (or lattice) for large vocabulary, continuous speech recognition. The advantage of a word graph is that a fairly good degree of decoupling between acoustic recognition at the 10-ms level and the final search at the word level using a complicated language model can be achieved. The word graph algorithm is obtained as an extension of the one-pass beam search strategy using word dependent copies of the word models or lexical trees. The method has been tested successfully on the 20 000-word NAB'94 task (American English, continuous speech, 20 000 words, speaker independent) and compared with the integrated method. The experiments show that the word graph density can be reduced to an average number of about 10 word hypotheses, i.e. word edges in the graph, per spoken word with virtually no loss in recognition performance."
            },
            "slug": "A-word-graph-algorithm-for-large-vocabulary-speech-Ortmanns-Ney",
            "title": {
                "fragments": [],
                "text": "A word graph algorithm for large vocabulary continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A method for the construction of a word graph (or lattice) for large vocabulary, continuous speech recognition and it is shown that the word graph density can be reduced to an average number of about 10 word hypotheses, per spoken word with virtually no loss in recognition performance."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94876749"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727234"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yen-lu",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60451180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e4ca575fc5759aff9b6e7450c2f17681c75f8d5",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A search algorithm that provides a simple, clean, and efficient interface between the speech and natural language components of a spoken language system is introduced. The N-best algorithm is a time-synchronous Viterbi-style beam search procedure that is guaranteed to find the N most likely whole sentence alternatives that are within a given beam of the most likely sentence. The computation is linear with the length of the utterance, and faster than linear in N. When used together with a first-order statistical grammar, the correct sentence is usually within the first few sentence choices. The output of the algorithm, which is an ordered set of sentence hypotheses with acoustic and language model scores can easily be processed by natural language knowledge sources without the huge expansion of the search space that would be needed to include all possible knowledge sources in a top-down search. In experiments using a first-order statistical language model, the average rank of the correct answer was 1.8 and was within the first 24 choices 99% of the time.<<ETX>>"
            },
            "slug": "The-N-best-algorithms:-an-efficient-and-exact-for-N-Schwartz-Chow",
            "title": {
                "fragments": [],
                "text": "The N-best algorithms: an efficient and exact procedure for finding the N most likely sentence hypotheses"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The N-best algorithm is a time-synchronous Viterbi-style beam search procedure that is guaranteed to find the N most likely whole sentence alternatives that are within a given beam of the most likely sentence."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103150287"
                        ],
                        "name": "C. D. Forgie",
                        "slug": "C.-D.-Forgie",
                        "structuredName": {
                            "firstName": "Carma",
                            "lastName": "Forgie",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Forgie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071690336"
                        ],
                        "name": "M. Groves",
                        "slug": "M.-Groves",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Groves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Groves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52046330"
                        ],
                        "name": "F. Frick",
                        "slug": "F.-Frick",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Frick",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Frick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119384439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b349928abf6733c3028c23f6fc3cb6d09826277e",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "No necessary\u2010and\u2010sufficient stimulus, or stimuli, has been discovered for the identification of any given word, yet people can reliably recognize speech under a wide variety of conditions One implication of this fact might be that speech recognition involves a complex data processing which takes advantage of linguistic redundancy. Such a system could make possible a reliable identification on the basis of a number of discriminating conditions, no one of which was in itself dependable. An attempt was made to realize such a data processing system in a program written for an experimental computer at Lincoln Laboratory. The program input consisted of the spoken digits processed through the Haskins Laboratories' resonance vocoder. Ninety\u2010eight percent recognition was achieved on a sample of ten voices, mixed male and female. [The research reported in this talk was supported jointly by the U. S. Army, Navy, and Air Force under contract with the Massachusetts Institute of Technology.]"
            },
            "slug": "Automatic-Recognition-of-Spoken-Digits-Forgie-Groves",
            "title": {
                "fragments": [],
                "text": "Automatic Recognition of Spoken Digits"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An attempt was made to realize a speech recognition system using spoken digits processed through the Haskins Laboratories' resonance vocoder, which made possible a reliable identification on the basis of a number of discriminating conditions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1905330"
                        ],
                        "name": "C. Leggetter",
                        "slug": "C.-Leggetter",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Leggetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leggetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782065"
                        ],
                        "name": "V. Valtchev",
                        "slug": "V.-Valtchev",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Valtchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Valtchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26242583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60e352a65bfe8d10dac98313dc944d7120754acd",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes recent work on the HTK large vocabulary speech recognition system. The system uses tied-state cross-word context-dependent mixture Gaussian HMMs and a dynamic network decoder that can operate in a single pass. In the last year the decoder has been extended to produce word lattices to allow flexible and efficient system development, as well as multi-pass operation for use with computationally expensive acoustic and/or language models. The system vocabulary can now be up to 65 k words, the final acoustic models have been extended to be sensitive to more acoustic context (quinphones), a 4-gram language model has been used and unsupervised incremental speaker adaptation incorporated. The resulting system gave the lowest error rates on both the H1-P0 and H1-C1 hub tasks in the November 1994 ARPA CSR evaluation."
            },
            "slug": "The-1994-HTK-large-vocabulary-speech-recognition-Woodland-Leggetter",
            "title": {
                "fragments": [],
                "text": "The 1994 HTK large vocabulary speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The HTK large vocabulary speech recognition system uses tied-state cross-word context-dependent mixture Gaussian HMMs and a dynamic network decoder that can operate in a single pass to allow flexible and efficient system development, as well as multi-pass operation for use with computationally expensive acoustic and/or language models."
            },
            "venue": {
                "fragments": [],
                "text": "1995 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718611"
                        ],
                        "name": "L. Mangu",
                        "slug": "L.-Mangu",
                        "structuredName": {
                            "firstName": "Lidia",
                            "lastName": "Mangu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Mangu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6135726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7d08c4fdf359f5cf0946a4a86db52d273a59ba4",
            "isKey": false,
            "numCitedBy": 731,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new framework for distilling information from word lattices to improve the accuracy of the speech recognition output and obtain a more perspicuous representation of a set of alternative hypotheses. In the standard MAP decoding approach the recognizer outputs the string of words corresponding to the path with the highest posterior probability given the acoustics and a language model. However, even given optimal models, the MAP decoder does not necessarily minimize the commonly used performance metric, word error rate (WER). We describe a method for explicitly minimizing WER by extracting word hypotheses with the highest posterior probabilities from word lattices. We change the standard problem formulation by replacing global search over a large set of sentence hypotheses with local search over a small set of word candidates. In addition to improving the accuracy of the recognizer, our method produces a new representation of a set of candidate hypotheses that specifies the sequence of word-level confusions in a compact lattice format. We study the properties of confusion networks and examine their use for other tasks, such as lattice compression, word spotting, confidence annotation, and reevaluation of recognition hypotheses using higher-level knowledge sources."
            },
            "slug": "Finding-consensus-in-speech-recognition:-word-error-Mangu-Brill",
            "title": {
                "fragments": [],
                "text": "Finding consensus in speech recognition: word error minimization and other applications of confusion networks"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new framework for distilling information from word lattices is described to improve the accuracy of the speech recognition output and obtain a more perspicuous representation of a set of alternative hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781290"
                        ],
                        "name": "H. Murveit",
                        "slug": "H.-Murveit",
                        "structuredName": {
                            "firstName": "Hy",
                            "lastName": "Murveit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murveit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3148249"
                        ],
                        "name": "J. Butzberger",
                        "slug": "J.-Butzberger",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Butzberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Butzberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121786"
                        ],
                        "name": "V. Digalakis",
                        "slug": "V.-Digalakis",
                        "structuredName": {
                            "firstName": "Vassilios",
                            "lastName": "Digalakis",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Digalakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744182"
                        ],
                        "name": "M. Weintraub",
                        "slug": "M.-Weintraub",
                        "structuredName": {
                            "firstName": "Mitch",
                            "lastName": "Weintraub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weintraub"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57374243,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3492842d6ec502cd9d314ccf1080b0defdb7955f",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a technique called progressive search which is useful for developing and implementing speech recognition systems with high computational requirements. The scheme iteratively uses more and more complex recognition schemes, where each iteration constrains the speech space of the next. An algorithm called the forward-backward word-life algorithm is described. It can generate a word lattice in a progressive search that would be used as a language model embedded in a succeeding recognition pass to reduce computation requirements. It is shown that speed-ups of more than an order of magnitude are achievable with only minor costs in accuracy.<<ETX>>"
            },
            "slug": "Large-vocabulary-dictation-using-SRI's-DECIPHER-Murveit-Butzberger",
            "title": {
                "fragments": [],
                "text": "Large-vocabulary dictation using SRI's DECIPHER speech recognition system: progressive search techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The authors describe a technique called progressive search which is useful for developing and implementing speech recognition systems with high computational requirements and shows that speed-ups of more than an order of magnitude are achievable with only minor costs in accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057063782"
                        ],
                        "name": "R. Bates",
                        "slug": "R.-Bates",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bates",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107686501"
                        ],
                        "name": "R. Mart\u00edn",
                        "slug": "R.-Mart\u00edn",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Mart\u00edn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mart\u00edn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758841"
                        ],
                        "name": "K. Ries",
                        "slug": "K.-Ries",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Ries",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ries"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70422141"
                        ],
                        "name": "Elizabeth Shriberg",
                        "slug": "Elizabeth-Shriberg",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Shriberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Shriberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122297135"
                        ],
                        "name": "P. Taylor",
                        "slug": "P.-Taylor",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Taylor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406543943"
                        ],
                        "name": "C. V. Van Ess-Dykema",
                        "slug": "C.-V.-Van-Ess-Dykema",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Van Ess-Dykema",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. V. Van Ess-Dykema"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5890398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1410dc8fd2a80d0697ad8e7286426f040586b6c9",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach for statistical modeling and detection of discourse structure for natural conversational speech. Our model is based on 42 dialog acts (DAs), (question, answer, backchannel, agreement, disagreement, apology, etc.). We labeled 1155 conversations from the Switchboard (SWBD) database (Godfrey et al., 1992) of human-to-human telephone conversations with these 42 types and trained a dialog act detector based on three distinct knowledge sources: sequences of words which characterize a dialog act; prosodic features which characterize a dialog act; and a statistical discourse grammar. Our combined detector, although still in preliminary stages, already achieves a 65% dialog act detection rate based on acoustic waveforms, and 72% accuracy based on word transcripts. Using this detector to switch among the 42 dialog-act-specific trigram LMs also gave us an encouraging but not statistically significant reduction in SWBD word error."
            },
            "slug": "Automatic-detection-of-discourse-structure-for-and-Jurafsky-Bates",
            "title": {
                "fragments": [],
                "text": "Automatic detection of discourse structure for speech recognition and understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A new approach for statistical modeling and detection of discourse structure for natural conversational speech, based on 42 dialog acts, which achieves a 65% dialog act detection rate based on acoustic waveforms, and 72% accuracy based on word transcripts."
            },
            "venue": {
                "fragments": [],
                "text": "1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34546277"
                        ],
                        "name": "M. Ravishankar",
                        "slug": "M.-Ravishankar",
                        "structuredName": {
                            "firstName": "Mosur",
                            "lastName": "Ravishankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ravishankar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58162492,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c717565298acedc3ebca38c52e2cc6b0a7e5e7a",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Advances in speech technology and computing power have created a surge of interest in the practical application of speech recognition. However, the most accurate speech recognition systems in the research world are still far too slow and expensive to be used in practical, large vocabulary continuous speech applications. Their main goal has been recognition accuracy, with emphasis on acoustic and language modelling. But practical speech recognition also requires the computation to be carried out in real time within the limited resources CPU power and memory size of commonly available computers. There has been relatively little work in this direction while preserving the accuracy of research systems. In this thesis, we focus on efficient and accurate speech recognition. It is easy to improve recognition speed and reduce memory requirements by trading away accuracy, for example by greater pruning, and using simpler acoustic and language models. It is much harder to improve both the recognition speed and reduce main memory size while preserving the accuracy. This thesis presents several techniques for improving the overall performance of the CMU Sphinx-II system. Sphinx-II employs semi-continuous hidden Markov models for acoustics and trigram language models, and is one of the premier research systems of its kind. The techniques in this thesis are validated on several widely used benchmark test sets using two vocabulary sizes of about 20K and 58K words. The main contributions of this thesis are an 8-fold speedup and 4-fold memory size reduction over the baseline Sphinx-II system. The improvement in speed is obtained from the following techniques: lexical tree search, phonetic fast match heuristic, and global best path search of the word lattice."
            },
            "slug": "Efficient-Algorithms-for-Speech-Recognition.-Ravishankar",
            "title": {
                "fragments": [],
                "text": "Efficient Algorithms for Speech Recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main contributions of this thesis are an 8-fold speedup and 4-fold memory size reduction over the baseline Sphinx-II system, and the improvement in speed is obtained from the following techniques: lexical tree search, phonetic fast match heuristic, and global best path search of the word lattice."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748407"
                        ],
                        "name": "J. Bellegarda",
                        "slug": "J.-Bellegarda",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Bellegarda",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bellegarda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17002191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e0a5928465724fba6a9195dbb4717b268c2ce6b",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A multi-span framework was proposed to integrate the various constraints, both local and global, that are present in the language. In this approach, local constraints are captured via n-gram language modeling, while global constraints are taken into account through the use of latent semantic analysis. The performance of the resulting multi-span language models, as measured by the perplexity, has been shown to compare favorably with the corresponding n-gram performance. This paper reports on actual speech recognition experiments, and shows that word error rate is also substantially reduced. On a subset of the Wall Street Journal speaker-independent, 20,000-word vocabulary, continuous speech task, the multi-span framework resulted in a reduction in average word error rate of up to 17%."
            },
            "slug": "Speech-recognition-experiments-using-multi-span-Bellegarda",
            "title": {
                "fragments": [],
                "text": "Speech recognition experiments using multi-span statistical language models"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A multi-span framework to integrate the various constraints, both local and global, that are present in the language is proposed and it is shown that word error rate is also substantially reduced."
            },
            "venue": {
                "fragments": [],
                "text": "1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2692829"
                        ],
                        "name": "P. Denes",
                        "slug": "P.-Denes",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Denes",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Denes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62152631,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3552dbc833d27c7326794486920c58853ed5ba79",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of a practical speech recognizer, incorporating many of the principles discussed in a companion paper, is described. The principal parts of the recognizer are as follows:\u2013 acoustic spectrum analyser; spectral pattern matcher; store of information about linguistic statistics; phoneme sequence memory; the computer; output circuits (a) the storage of computer decisions, (b) the control of the automatic typewriter. The speech material used with the completed recognizer is described, together with the results obtained. Future developments in speech typewriter research and possible uses of a successful recognizer are indicated."
            },
            "slug": "The-design-and-operation-of-the-mechanical-speech-Denes",
            "title": {
                "fragments": [],
                "text": "The design and operation of the mechanical speech recognizer at University College London"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The design of a practical speech recognizer, incorporating many of the principles discussed in a companion paper, is described and the speech material used with the completed recognizer is described, together with the results obtained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33033096"
                        ],
                        "name": "V. M. Velichko",
                        "slug": "V.-M.-Velichko",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Velichko",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. M. Velichko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17157153"
                        ],
                        "name": "N. G. Zagoruyko",
                        "slug": "N.-G.-Zagoruyko",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Zagoruyko",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. G. Zagoruyko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60801789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4033ccc27fe2f24870a824661b76328f927edce",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-recognition-of-200-words-Velichko-Zagoruyko",
            "title": {
                "fragments": [],
                "text": "Automatic recognition of 200 words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145731155"
                        ],
                        "name": "N. Russell",
                        "slug": "N.-Russell",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Russell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984105"
                        ],
                        "name": "J. Thornton",
                        "slug": "J.-Thornton",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Thornton",
                            "middleNames": [
                                "H.",
                                "Simon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Thornton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59705956,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "963cf8f238745100ac6cc5cf730653a6e1849b62",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a simple but powerful abstract model in which connected word recognition is viewed as a process of passing tokens around a transition network The advantages of this unifying view are many The various apparently di erent connected word algorithms can be represented within the same conceptual framework simply by changing the network topology the application of grammatical constraints is straightforward and perhaps most importantly the entire structure is independent of the actual underlying pattern matching technology To illustrate the power of this conceptual model the paper concludes by describing some work done under the UK Alvey sponsored VODIS Project in which the Token Passing paradigm enabled the One Pass algorithm to be straightforwardly extended to include the generation of multiple alternatives and context free syntactic constraints"
            },
            "slug": "Token-passing:-a-simple-conceptual-model-for-speech-Young-Russell",
            "title": {
                "fragments": [],
                "text": "Token passing: a simple conceptual model for connected speech recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper describes a simple but powerful abstract model in which connected word recognition is viewed as a process of passing tokens around a transition network and some work done under the UK Alvey sponsored VODIS Project is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39015365"
                        ],
                        "name": "D. Fry",
                        "slug": "D.-Fry",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Fry",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fry"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62140967,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c0ec1c61690f0d4008b500b022abf5b09042f3e9",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The human listener is able to take in speech wave-motions and to perform a variety of operations based on them. As a device for transforming speech wave-motions into typescript, the listener is virtually free of errors in a great diversity of conditions. His recognition of speech sounds is based on the use of a language system, that is a system of linguistic units (phonemes, morphemes, words and sentences). In taking in speech, he makes use of his knowledge of the constraints operating in his language, and thus resolves uncertainties and corrects errors arising at the level of acoustic recognition. The redundancy of speech is also exploited at the level of primary or acoustic recognition. A mechanical speech recognizer needs to simulate these two features of the human mechanism if it is to achieve even a small fraction of the flexibility and accuracy of the latter; it must carry out acoustic recognition by inspecting wave-motions in a variety of ways and must then apply statistical knowledge to the results of acoustic recognition."
            },
            "slug": "Theoretical-aspects-of-mechanical-speech-Fry",
            "title": {
                "fragments": [],
                "text": "Theoretical aspects of mechanical speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A mechanical speech recognizer needs to simulate the features of the human mechanism if it is to achieve even a small fraction of the flexibility and accuracy of the latter."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705598"
                        ],
                        "name": "B. Suhm",
                        "slug": "B.-Suhm",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Suhm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Suhm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10312477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9dd1e37157df40356c4c7cbcf73d4f736b0c5715",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In our eeort to build a speech{to{speech translation system for spontaneous spoken dialogs we have developed several methods to improve the language models of the speech decoder of the system. We attempt to take advantage of natural equivalence word classes, frequently occur-ing word phrases, and discourse structure. Each of these methods was tested on spontaneous English, German and Spanish human{human dialogs."
            },
            "slug": "Towards-better-language-models-for-spontaneous-Suhm-Waibel",
            "title": {
                "fragments": [],
                "text": "Towards better language models for spontaneous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Several methods to improve the language models of the speech decoder of thespeech translation system for spontaneous spoken dialogs attempt to take advantage of natural equivalence word classes, frequently occur-ing word phrases, and discourse structure."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2763151"
                        ],
                        "name": "F. Grosjean",
                        "slug": "F.-Grosjean",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Grosjean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Grosjean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43190844,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b35b9c21e558899245dddfdec4c750bcd7279c56",
            "isKey": false,
            "numCitedBy": 714,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Words varying in length (one, two, and three syllables) and in frequency (high and low) were presented to subjects in isolation, in a short context, and in a long context. Each word was presented repeatedly, and its presentation time (duration from the onset of the word) increased at each successive pass. After each pass, subjects were asked to write down the word being presented and to indicate how confident they were about each guess. In addition to replicating a frequency, a context, and a word-length effect, this \u201cgating\u201d paradigm allowed us to study more closely the narrowing-in process employed by listeners in the isolation and recognition of words: Some delay appears to exist between the moment a word is isolated from other word candidates and the moment it is recognized; word candidates differ in number and in type from one context to the other; and, like syntactic processing, word recognition is strewn with garden paths. The active direct access model proposed by Marslen-Wilson and Welsh is discussed in light of these findings."
            },
            "slug": "Spoken-word-recognition-processes-and-the-gating-Grosjean",
            "title": {
                "fragments": [],
                "text": "Spoken word recognition processes and the gating paradigm"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Words varying in length (one, two, and three syllables) and in frequency (high and low) were presented to subjects in isolation, in a short context, and in a long context to study more closely the narrowing-in process employed by listeners in the isolation and recognition of words."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110271578"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145482266"
                        ],
                        "name": "D. Stallard",
                        "slug": "D.-Stallard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stallard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stallard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189985"
                        ],
                        "name": "R. Bobrow",
                        "slug": "R.-Bobrow",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10983275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9c1f510bcf5933d3cf8ec8108a04a9ba601a843",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a natural language interface system which is based entirely on trained statistical models. The system consists of three stages of processing: parsing, semantic interpretation, and discourse. Each of these stages is modeled as a statistical process. The models are fully integrated, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "slug": "A-Fully-Statistical-Approach-to-Natural-Language-Miller-Stallard",
            "title": {
                "fragments": [],
                "text": "A Fully Statistical Approach to Natural Language Interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work presents a natural language interface system which is based entirely on trained statistical models, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12495425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "231f6de83cfa4d641da1681e97a11b689a48e3aa",
            "isKey": false,
            "numCitedBy": 2251,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The speech recognition problem hidden Markov models the acoustic model basic language modelling the Viterbi search hypothesis search on a tree and the fast match elements of information theory the complexity of tasks - the quality of language models the expectation - maximization algorithm and its consequences decision trees and tree language models phonetics from orthography - spelling-to-base from mappings triphones and allophones maximum entropy probability estimation and language models three applications of maximum entropy estimation to language modelling estimation of probabilities from counts and the Back-Off method."
            },
            "slug": "Statistical-methods-for-speech-recognition-Jelinek",
            "title": {
                "fragments": [],
                "text": "Statistical methods for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The speech recognition problem hidden Markov models the acoustic model basic language modelling the Viterbi search hypothesis search on a tree and the fast match elements of information theory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400881722"
                        ],
                        "name": "W. Marslen-Wilson",
                        "slug": "W.-Marslen-Wilson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Marslen-Wilson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Marslen-Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97791075"
                        ],
                        "name": "Alan B. Welsh",
                        "slug": "Alan-B.-Welsh",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Welsh",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan B. Welsh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54309519,
            "fieldsOfStudy": [
                "Psychology",
                "Linguistics"
            ],
            "id": "01a572d6e13d08bf0f8fd6664b9fc2c6dfc3787d",
            "isKey": false,
            "numCitedBy": 1301,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Processing-interactions-and-lexical-access-during-Marslen-Wilson-Welsh",
            "title": {
                "fragments": [],
                "text": "Processing interactions and lexical access during word recognition in continuous speech"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752407"
                        ],
                        "name": "P. Heeman",
                        "slug": "P.-Heeman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Heeman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Heeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145844737"
                        ],
                        "name": "James F. Allen",
                        "slug": "James-F.-Allen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James F. Allen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16371363,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "d28f71b3759ca07f7a968da3fdf0dfe39e3da0e9",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Interactive spoken dialogue provides many new challenges for natural language understanding systems. One of the most critical challenges is simply determining the speaker's intended utterances: both segmenting a speaker's turn into utterances and determining the intended words in each utterance. Even assuming perfect word recognition, the latter problem is complicated by the occurrence of speech repairs, which occur where speakers go back and change (or repeat) something they just said. The words that are replaced or repeated are no longer part of the intended utterance, and so need to be identified. Segmenting turns and resolving repairs are strongly interwined with a third task: identifying discourse markers. Because of the interactions, and interactions with POS tagging and speech recognition, we need to address these tasks together and early on in the processing stream. This paper presents a statistical language model in which we redefine the speech recognition problem so that it includes the identification of POS tags, discourse markers, speech repairs, and intonational phrases. By solving these simultaneously, we obtain better results on each task than addressing them separately. Our model is able to identify 72% of turn-internal intonational boundaries with a precision of 71%, 97% of discourse markers with 96% precision, and detect and correct 66% of repairs with 74% precision."
            },
            "slug": "Speech-Repairs,-Intonational-Phrases-and-Discourse-Heeman-Allen",
            "title": {
                "fragments": [],
                "text": "Speech Repairs, Intonational Phrases and Discourse Markers: Modeling Speakers' Utterances in Spoken Dialog"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A statistical language model is presented in which the speech recognition problem is redefined so that it includes the identification of POS tags, discourse markers, speech repairs, and intonational phrases."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3103883"
                        ],
                        "name": "D. Klatt",
                        "slug": "D.-Klatt",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Klatt",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klatt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59682511,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af4ab787f077cdb3ef1c68ea5f140f9585ee03ee",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Review-of-the-ARPA-speech-understanding-project-Klatt",
            "title": {
                "fragments": [],
                "text": "Review of the ARPA speech understanding project"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721513"
                        ],
                        "name": "B. Lowerre",
                        "slug": "B.-Lowerre",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lowerre",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lowerre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61409851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdb3f20fe41bb95f6bc9d162e827de8db3f952d7",
            "isKey": false,
            "numCitedBy": 480,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The Harpy connected speech recognition system is the result of an attempt to understand the relative importance of various design choices of two earlier speech recognition systems developed at Carnegie-Mellon University: The Hearsay-1 system and the Dragon system. Knowledge is represented in the Hearsay- 1 system as procedures and in the Dragon system as a Markov network with a- priori transition probabilities between states. Systematic performance analysis of various design choices of these two systems resulted in the HARPY system, in which knowledge is represented as a finite state transition network but without the a-priori transition probabilities. Harpy searches only a few 'best' syntactic (and acoustic) paths in parallel to determine the optimal path, and uses segmentation to effectively reduce the utterance length, thereby reducing the number of state probability updates that must be done. Several new heuristics have been added to the HARPY system to improve its performance and speed: detection of common sub-nets and collapsing them to reduce overall network size and complexity, eliminating the need for doing an acoustic match for all phonemic types at every time sample, and semi-automatic techniques for learning the lexical representations (that are needed for a steady-state system of this type) and the phonemic templates from training data, thus automatically accounting for the commonly occurring intra-word coarticulation and juncture phenomena. Inter-word phenomena are handled by the use of juncture rules which are applied at network generation time, thereby eliminating the need for repetitive and time consuming application of phonological rules during the recognition phase."
            },
            "slug": "The-HARPY-speech-recognition-system-Lowerre",
            "title": {
                "fragments": [],
                "text": "The HARPY speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The HARPY system is the result of an attempt to understand the relative importance of various design choices of two earlier speech recognition systems developed at Carnegie-Mellon University, in which knowledge is represented as a finite state transition network but without the a-priori transition probabilities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122297135"
                        ],
                        "name": "P. Taylor",
                        "slug": "P.-Taylor",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Taylor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783569"
                        ],
                        "name": "Simon King",
                        "slug": "Simon-King",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901024"
                        ],
                        "name": "S. Isard",
                        "slug": "S.-Isard",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Isard",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053688120"
                        ],
                        "name": "Helen Wright",
                        "slug": "Helen-Wright",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Wright",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helen Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9773852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c117733946a940e7f34625891b95da7c800eb80",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a way of using intonation and dialog context to improve the performance of an automatic speech recognition (ASR) system. Our experiments were run on the DCIEM Maptask corpus, a corpus of spontaneous task-oriented dialog speech. This corpus has been tagged according to a dialog analysis scheme that assigns each utterance to one of 12 \u201cmove types,\u201d such as \u201cacknowledge,\u201d \u201cquery-yes/no\u201d or \u201cinstruct.\u201d Most ASR systems use a bigram language model to constrain the possible sequences of words that might be recognized. Here we use a separate bigram language model for each move type. We show that when the \u201ccorrect\u201d move-specific language model is used for each utterance in the test set, the word error rate of the recognizer drops. Of course when the recognizer is run on previously unseen data, it cannot know in advance what move type the speaker has just produced. To determine the move type we use an intonation model combined with a dialog model that puts constraints on possible sequences of move types, as well as the speech recognizer likelihoods for the different move-specific models. In the full recognition system, the combination of automatic move type recognition with the move specific language models reduces the overall word error rate by a small but significant amount when compared with a baseline system that does not take intonation or dialog acts into account. Interestingly, the word error improvement is restricted to \u201cinitiating\u201d move types, where word recognition is important. In \u201cresponse\u201d move types, where the important information is conveyed by the move type itself\u2014for example, positive versus negative response\u2014there is no word error improvement, but recognition of the response types themselves is good. The paper discusses the intonation model, the language models, and the dialog model in detail and describes the architecture in which they are combined."
            },
            "slug": "Intonation-and-Dialog-Context-as-Constraints-for-Taylor-King",
            "title": {
                "fragments": [],
                "text": "Intonation and Dialog Context as Constraints for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A way of using intonation and dialog context to improve the performance of an automatic speech recognition (ASR) system and shows that when the \u201ccorrect\u201d move-specific language model is used for each utterance in the test set, the word error rate of the recognizer drops."
            },
            "venue": {
                "fragments": [],
                "text": "Language and speech"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387789571"
                        ],
                        "name": "Vishwa Gupta",
                        "slug": "Vishwa-Gupta",
                        "structuredName": {
                            "firstName": "Vishwa",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishwa Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2959613"
                        ],
                        "name": "Matthew Lennig",
                        "slug": "Matthew-Lennig",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Lennig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Lennig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143791674"
                        ],
                        "name": "P. Mermelstein",
                        "slug": "P.-Mermelstein",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Mermelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mermelstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120960565,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d4cbda6741d0311f9b99a4b124dd52832faced5",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, a fast search algorithm is presented for generating word hypotheses for a 75\u2009000\u2010word vocabulary, speaker\u2010trained, isolated word recognizer. The algorithm is envisioned as the first pass of a total recognition system generating a small number of hypotheses with rough likelihood estimates, to be followed by more detailed hypothesis evaluation. The possible word choices are restricted by estimating the number of syllables in the unknown word using a hidden Markov model (HMM) for syllables. A heuristic search algorithm then searches through a sequence of syllable networks to find the most likely word candidates. Arcs in the syllable network correspond to phonemes. The assumption that the likelihoods of these phoneme arcs are independent of the phonetic context allows us to convert the search through a large tree into a search through a much smaller network or graph. The computational requirements are reduced by roughly a factor of 70 compared to estimating the exact likelihood scores for the..."
            },
            "slug": "Fast-search-strategy-in-a-large-vocabulary-word-Gupta-Lennig",
            "title": {
                "fragments": [],
                "text": "Fast search strategy in a large vocabulary word recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A fast search algorithm is presented for generating word hypotheses for a 75\u2009000\u2010word vocabulary, speaker\u2010trained, isolated word recognizer as the first pass of a total recognition system generating a small number of hypotheses with rough likelihood estimates, to be followed by more detailed hypothesis evaluation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81338045"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5272157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22404884bd6e2dc80691b968a1e571f873b0a774",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The dialogue strategies used by a spoken dialogue system strongly influence performance and user satisfaction. An ideal system would not use a single fixed strategy, but would adapt to the circumstances at hand. To do so, a system must be able to identify dialogue properties that suggest adaptation. This paper focuses on identifying situations where the speech recognizer is performing poorly. We adopt a machine learning approach to learn rules from a dialogue corpus for identifying these situations. Our results show a significant improvement over the baseline and illustrate that both lower-level acoustic features and higher-level dialogue features can affect the performance of the learning algorithm."
            },
            "slug": "Automatic-Detection-of-Poor-Speech-Recognition-at-Litman-Walker",
            "title": {
                "fragments": [],
                "text": "Automatic Detection of Poor Speech Recognition at the Dialogue Level"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper adopts a machine learning approach to learn rules from a dialogue corpus for identifying situations where the speech recognizer is performing poorly and shows a significant improvement over the baseline."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2215426"
                        ],
                        "name": "J. Weizenbaum",
                        "slug": "J.-Weizenbaum",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Weizenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weizenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1896290,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "a798bca71c8833e49ad9bac22da4b5c3503f1e6a",
            "isKey": false,
            "numCitedBy": 1749,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "ELIZA is a program operating within the MAC time-sharing system at MIT which makes certain kinds of natural language conversation between man and computer possible. Input sentences are analyzed on the basis of decomposition rules which are triggered by key words appearing in the input text. Responses are generated by reassembly rules associated with selected decomposition rules. The fundamental technical problems with which ELIZA is concerned are: (1) the identification of key words, (2) the discovery of minimal context, (3) the choice of appropriate transformations, (4) generation of responses in the absence of key words, and (5) the provision of an editing capability for ELIZA \"scripts\". A discussion of some psychological issues relevant to the ELIZA approach as well as of future developments concludes the paper."
            },
            "slug": "ELIZA\u2014a-computer-program-for-the-study-of-natural-Weizenbaum",
            "title": {
                "fragments": [],
                "text": "ELIZA\u2014a computer program for the study of natural language communication between man and machine"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A discussion of some psychological issues relevant to the ELIZA approach as well as of future developments concludes the paper."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13185450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b888cae7e6e288b108f9d119fc23b84b4d447029",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a number of techniques designed to help integrate semantic knowledge with N-gram language models for automatic speech recognition. Our techniques allow us to integrate Latent Semantic Analysis (LSA), a word-similarity algorithm based on word co-occurrence information, with N-gram models. While LSA is good at predicting content words which are coherent with the rest of a text, it is a bad predictor of frequent words, has a low dynamic range, and is inaccurate when combined linearly with N-grams. We show that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N-gram model."
            },
            "slug": "Towards-better-integration-of-semantic-predictors-Coccaro-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Towards better integration of semantic predictors in statistical language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N- gram model."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684010"
                        ],
                        "name": "P. Gopalakrishnan",
                        "slug": "P.-Gopalakrishnan",
                        "structuredName": {
                            "firstName": "Ponani",
                            "lastName": "Gopalakrishnan",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gopalakrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713978"
                        ],
                        "name": "D. Nahamoo",
                        "slug": "D.-Nahamoo",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nahamoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nahamoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774515"
                        ],
                        "name": "M. Picheny",
                        "slug": "M.-Picheny",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Picheny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Picheny"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62226523,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd29149d68d24bf28d7a693209ecd70177dce680",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In a large vocabulary real-time speech recognition system, there is a need for a fast method for selecting a list of candidate words from the vocabulary that match well with a given acoustic input. The authors describe a highly accurate fast acoustic match for continuous speech recognition. The algorithm uses allophonic models and efficient search techniques to select a set of candidate words. The allophonic models are derived by constructing decision trees that query the context in which each phone occurs to arrive at an allophone in a given context. The models for all the words in the vocabulary are arranged in a tree structure and efficient tree search algorithms are used to select a list of candidate words using these models. Using this method, the authors are able to obtain over 99% accuracy in the fast match for a continuous speech recognition task which has a vocabulary of 5000 words.<<ETX>>"
            },
            "slug": "A-fast-match-for-continuous-speech-recognition-Bahl-Souza",
            "title": {
                "fragments": [],
                "text": "A fast match for continuous speech recognition using allophonic models"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A highly accurate fast acoustic match for continuous speech recognition using allophonic models and efficient search techniques to select a set of candidate words from the vocabulary that match well with a given acoustic input."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70422141"
                        ],
                        "name": "Elizabeth Shriberg",
                        "slug": "Elizabeth-Shriberg",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Shriberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Shriberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758841"
                        ],
                        "name": "K. Ries",
                        "slug": "K.-Ries",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Ries",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ries"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14972057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "436c3119d16ce2e3c243ffe7a4a1a5dc40b128aa",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an integrated approach for statistical modeling of discourse structure for natural conversational speech. Our model is based on 42`dialog acts' which were hand-labeled in 1155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech. We developed several models and algorithms to automatically detect dialog acts from transcribed or automatically recognized words and from prosodic properties of the speech signal, and by using a statistical discourse grammar. All of these components were probabilistic in nature and estimated from data, employing a variety of techniques (hidden Markov models, N-gram language models, maximum entropy estimation, decision tree classiiers, and neural networks). In preliminary studies, we achieved a dialog act labeling accuracy of 65% based on recognized words and prosody, and an accuracy of 72% based on word transcripts. Since humans achieve 84% on this task (with chance performance at 35%) we nd these results encouraging."
            },
            "slug": "Dialog-Act-Modeling-for-Conversational-Speech-Shriberg-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Dialog Act Modeling for Conversational Speech"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An integrated approach for statistical modeling of discourse structure for natural conversational speech based on 42`dialog acts' which were hand-labeled in 1155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1988103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399da68d3b97218b6c80262df7963baa89dcc71b",
            "isKey": false,
            "numCitedBy": 4997,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "slug": "SRILM-an-extensible-language-modeling-toolkit-Stolcke",
            "title": {
                "fragments": [],
                "text": "SRILM - an extensible language modeling toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The functionality of the SRILM toolkit is summarized and its design and implementation is discussed, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61058350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d82e058a5c40954b8f5db170a298a889a254c37",
            "isKey": false,
            "numCitedBy": 1409,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nConnectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state-of-the-art continuous speech recognition systems based on Hidden Markov Models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e., HMM emission probability estimation and feature extraction. The book describes a successful five year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical system. Using standard databases and comparing with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods. Connectionist Speech Recognition: A Hybrid Approach is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. This book is also suitable as a text for advanced courses on neural networks or speech processing."
            },
            "slug": "Connectionist-Speech-Recognition:-A-Hybrid-Approach-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Speech Recognition: A Hybrid Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731353"
                        ],
                        "name": "Norbert Reithinger",
                        "slug": "Norbert-Reithinger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Reithinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norbert Reithinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39434433"
                        ],
                        "name": "Ralf Engel",
                        "slug": "Ralf-Engel",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Engel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ralf Engel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145616714"
                        ],
                        "name": "Michael Kipp",
                        "slug": "Michael-Kipp",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kipp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Kipp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2922093"
                        ],
                        "name": "M. Klesen",
                        "slug": "M.-Klesen",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Klesen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Klesen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12635782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e6d727b00bbcffd0d08089520f66416fce3aae1",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents the application of statistical language modeling methods for the prediction of the next dialogue act. This prediction is used by different modules of the speech-to-speech translation system VERBMOBIL. The statistical approach uses deleted interpolation of n-gram frequencies as its basis and determines the interpolation weights by a modified version of the standard optimization algorithm. Additionally, we present and evaluate different approaches to improve the prediction process, e.g. including knowledge from a dialogue grammar. Evaluation shows that including the speaker information and mirroring the data delivers the best results."
            },
            "slug": "Predicting-dialogue-acts-for-a-speech-to-speech-Reithinger-Engel",
            "title": {
                "fragments": [],
                "text": "Predicting dialogue acts for a speech-to-speech translation system"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Evaluation shows that including the speaker information and mirroring the data delivers the best results, e.g. including knowledge from a dialogue grammar."
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738675078"
                        ],
                        "name": "P. Cohen",
                        "slug": "P.-Cohen",
                        "structuredName": {
                            "firstName": "Philip R.",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807460"
                        ],
                        "name": "S. Oviatt",
                        "slug": "S.-Oviatt",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Oviatt",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Oviatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13233620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da1702d9c11dbb0a71b2857e405851d224969b75",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Optimism is growing that the near future will witness rapid growth in human-computer interaction using voice. System prototypes have recently been built that demonstrate speaker-independent real-time speech recognition, and understanding of naturally spoken utterances with vocabularies of 1000 to 2000 words, and larger. Already, computer manufacturers are building speech recognition subsystems into their new product lines. However, before this technology can be broadly useful, a substantial knowledge base is needed about human spoken language and performance during computer-based spoken interaction. This paper reviews application areas in which spoken interaction can play a significant role, assesses potential benefits of spoken interaction with machines, and compares voice with other modalities of human-computer interaction. It also discusses information that will be needed to build a firm empirical foundation for the design of future spoken and multimodal interfaces. Finally, it argues for a more systematic and scientific approach to investigating spoken input and performance with future language technology."
            },
            "slug": "The-role-of-voice-input-for-human-machine-Cohen-Oviatt",
            "title": {
                "fragments": [],
                "text": "The role of voice input for human-machine communication."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper reviews application areas in which spoken interaction can play a significant role, assesses potential benefits of spoken interaction with machines, and compares voice with other modalities of human-computer interaction."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049352"
                        ],
                        "name": "Julia Hirschberg",
                        "slug": "Julia-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Hirschberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730911"
                        ],
                        "name": "M. Swerts",
                        "slug": "M.-Swerts",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Swerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swerts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 596855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "346c52f07817c044394de26d8742bb67406a5129",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In spoken dialogue systems, it is important for a system to know how likely a speech recognition hypothesis is to be correct, so it can reprompt for fresh input, or, in cases where many errors have occurred, change its interaction strategy or switch the caller to a human attendant. We have discovered prosodic features which more accurately predict when a recognition hypothesis contains a word error than the acoustic confidence score thresholds traditionally used in automatic speech recognition. We present analytic results indicating that there are significant prosodic differences between correctly and incorrectly recognized turns in the TOOT train information corpus. We then present machine learning results showing how the use of prosodic features to automatically predict correct versus incorrectly recognized turns improves over the use of acoustic confidence scores alone."
            },
            "slug": "Predicting-Automatic-Speech-Recognition-Performance-Litman-Hirschberg",
            "title": {
                "fragments": [],
                "text": "Predicting Automatic Speech Recognition Performance Using Prosodic Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Prosodic features are discovered which more accurately predict when a recognition hypothesis contains a word error than the acoustic confidence score thresholds traditionally used in automatic speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58576075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53b50cb6dea86c52729cab4068b7ceeabf2e888d",
            "isKey": false,
            "numCitedBy": 352,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, considerable progress has been made in the eld of continuous speech recognition where the predominant technology is based on hidden Markov models (HMMs). HMMs represent sequences of time varying speech spectra using probabilistic functions of an underlying Markov chain. However, because the probability distribution represented by a HMM is very simple, its discriminative ability is limited. As a consequence, a careful choice of the units represented by each model is required in order to accurately model the variation inherent in natural speech. In practice, much of the variation is due to consistent contextual eeects and can be accounted for by using context dependent models. In large vocabulary recognition the use of context dependent models introduces two major problems. Firstly, some method must be devised to determine the set of contexts which require distinct models. Furthermore, this must be done in a way which takes account of the sparsity and unevenness of the training data. Secondly, a strategy must be devised which allows eecient decoding using models incorporating context dependencies both within words and across word boundaries. This thesis addresses both of these key problems. Firstly, a method of constructing robust and accurate recognisers using decision tree based clustering techniques is described. The strength of this approach lies in its ability to accurately model contexts not appearing in the training data. Linguistic knowledge is used, in conjunction with the data, to decide which contexts are similar and can share parameters. A key feature of this approach is that it allows the construction of models which are dependent upon contextual eeects occurring across word boundaries. The use of cross word context dependent models presents problems for conventional de-coders. The second part of the thesis therefore presents a new decoder design which is capable of using these models eeciently. The decoder is suitable for use with very large vocabularies and long span language models. It is also capable of generating a lattice of word hypotheses with little computational overhead. These lattices can be used to constrain further decoding, allowing eecient use of complex acoustic and language models. The eeectiveness of these techniques has been assessed on a variety of large vocabulary continuous speech recognition tasks and results are presented which analyse performance in terms of computational complexity and recognition accuracy. The experiments demonstrate state of the art performance and a recogniser using these techniques was used in the 1994 US \u2026"
            },
            "slug": "The-Use-of-Context-in-Large-Vocabulary-Speech-Odell",
            "title": {
                "fragments": [],
                "text": "The Use of Context in Large Vocabulary Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method of constructing robust and accurate recognisers using decision tree based clustering techniques is described and the strength of this approach lies in its ability to accurately model contexts not appearing in the training data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901373"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Evan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727234"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yen-lu",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353221"
                        ],
                        "name": "O. Kimball",
                        "slug": "O.-Kimball",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Kimball",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kimball"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4953636"
                        ],
                        "name": "M. Krasner",
                        "slug": "M.-Krasner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Krasner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krasner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60579533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df53e0dc66eb13bb51c6e4803ceae56d3ebe6f23",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of our work in designing a system for phonetic recognition of unrestricted continuous speech. We describe several algorithms used to recognize phonemes using context-dependent Hidden Markov Models of the phonemes. We present results for several variations of the parameters of the algorithms. In addition, we propose a technique that makes it possible to integrate traditional acoustic-phonetic features into a hidden Markov process. The categorical decisions usually associated with heuristic acoustic-phonetic algorithms are replaced by automated training techniques and global search strategies. The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "slug": "Context-dependent-modeling-for-acoustic-phonetic-of-Schwartz-Chow",
            "title": {
                "fragments": [],
                "text": "Context-dependent modeling for acoustic-phonetic recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '85. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70422141"
                        ],
                        "name": "Elizabeth Shriberg",
                        "slug": "Elizabeth-Shriberg",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Shriberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Shriberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057063782"
                        ],
                        "name": "R. Bates",
                        "slug": "R.-Bates",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bates",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122297135"
                        ],
                        "name": "P. Taylor",
                        "slug": "P.-Taylor",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Taylor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758841"
                        ],
                        "name": "K. Ries",
                        "slug": "K.-Ries",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Ries",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ries"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46776641"
                        ],
                        "name": "Rachel Martin",
                        "slug": "Rachel-Martin",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rachel Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403242564"
                        ],
                        "name": "C. V. Ess-Dykema",
                        "slug": "C.-V.-Ess-Dykema",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Ess-Dykema",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. V. Ess-Dykema"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2352988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26e7a79fc061e5907298732e8ad2a5055f34b32c",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 177,
            "paperAbstract": {
                "fragments": [],
                "text": "Identifying whether an utterance is a statement, question, greeting, and so forth is integral to effective automatic understanding of natural dialog. Little is known, however, about how such dialog acts (DAs) can be automatically classified in truly natural conversation. This study asks whether current approaches, which use mainly word information, could be improved by adding prosodic information. The study is based on more than 1000 conversations from the Switchboard corpus. DAs were hand-annotated, and prosodic features (duration, pause, F0, energy, and speaking rate) were automatically extracted for each DA. In training, decision trees based on these features were inferred; trees were then applied to unseen test data to evaluate performance. Performance was evaluated for prosody models alone, and after combining the prosody models with word information\u2014either from true words or from the output of an automatic speech recognizer. For an overall classification task, as well as three subtasks, prosody made significant contributions to classification. Feature-specific analyses further revealed that although canonical features (such as F0 for questions) were important, less obvious features could compensate if canonical features were removed. Finally, in each task, integrating the prosodic model with a DA-specific statistical language model improved performance over that of the language model alone, especially for the case of recognized words. Results suggest that DAs are redundantly marked in natural conversation, and that a variety of automatically extractable prosodic features could aid dialog processing in speech applications."
            },
            "slug": "Can-Prosody-Aid-the-Automatic-Classification-of-in-Shriberg-Bates",
            "title": {
                "fragments": [],
                "text": "Can Prosody Aid the Automatic Classification of Dialog Acts in Conversational Speech?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is suggested that DAs are redundantly marked in natural conversation, and that a variety of automatically extractable prosodic features could aid dialog processing in speech applications."
            },
            "venue": {
                "fragments": [],
                "text": "Language and speech"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702447"
                        ],
                        "name": "Owen Rambow",
                        "slug": "Owen-Rambow",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Rambow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Rambow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31658241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf582ef4ca7d5db0b6baa95d376f032d3d9d32a7",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spoken-language-generation-Walker-Rambow",
            "title": {
                "fragments": [],
                "text": "Spoken language generation"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143789092"
                        ],
                        "name": "A. Cutler",
                        "slug": "A.-Cutler",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Cutler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cutler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35408831"
                        ],
                        "name": "D. Carter",
                        "slug": "D.-Carter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Carter",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Carter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20293367,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6dddc4ce1aedea992f4ee0e814805056e1c5adfe",
            "isKey": false,
            "numCitedBy": 767,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-predominance-of-strong-initial-syllables-in-the-Cutler-Carter",
            "title": {
                "fragments": [],
                "text": "The predominance of strong initial syllables in the English vocabulary"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7476333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce84d43e5bbb05434f6871296b7c1c3946b9c868",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We have been focusing on improving pronunciation models for automatic transcription of television and radio news reports by modeling phone, syllable, and word pronunciation distributions with decision trees. These models were employed in two separate sets of experiments. First, decision trees facilitated selection of word pronunciations derived automatically from data for use in a standard speech recognizer dictionary. We have seen a small but significant improvement with these automatically constructed dictionaries in our one-pass decoding system. In a second set of experiments, we allowed decision tree models to determine the probability of word pronunciations dynamically, dependent on the linguistic context of the word during recognition. Dynamic models provided an additional insignificant decrease in error, but improvements were focused within the spontaneous speech portion of the test set."
            },
            "slug": "Multi-level-decision-trees-for-static-and-dynamic-Fosler-Lussier",
            "title": {
                "fragments": [],
                "text": "Multi-level decision trees for static and dynamic pronunciation models"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This work has been focusing on improving pronunciation models for automatic transcription of television and radio news reports by modeling phone, syllable, and word pronunciation distributions with decision trees, and allowing decision tree models to determine the probability of word pronunciations dynamically."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685310"
                        ],
                        "name": "F. Itakura",
                        "slug": "F.-Itakura",
                        "structuredName": {
                            "firstName": "Fumitada",
                            "lastName": "Itakura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Itakura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61601418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf2b0948ec73e21f6d5a67b22a31a20d503cc9e",
            "isKey": false,
            "numCitedBy": 1242,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a time pattern of linear prediction coefficients (LPC). The total log prediction residual of an input signal is minimized by optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm (DP). The input signal is recognized as the reference word which produces the minimum prediction residual. A sequential decision procedure is used to reduce the amount of computation in DP. A frequency normalization with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of telephone connections. The system has been implemented on a DDP-516 computer for the 200-word recognition experiment. The recognition rate for a designated male talker is 97.3 percent for telephone input, and the recognition time is about 22 times real time."
            },
            "slug": "Minimum-prediction-residual-principle-applied-to-Itakura",
            "title": {
                "fragments": [],
                "text": "Minimum prediction residual principle applied to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual through optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7788300,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "df50c6e1903b1e2d657f78c28ab041756baca86a",
            "isKey": false,
            "numCitedBy": 8924,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition."
            },
            "slug": "Fundamentals-of-speech-recognition-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Fundamentals of speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book presents a meta-modelling framework for speech recognition that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually modeling speech."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall signal processing series"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390103475"
                        ],
                        "name": "Reinhold H\u00e4b-Umbach",
                        "slug": "Reinhold-H\u00e4b-Umbach",
                        "structuredName": {
                            "firstName": "Reinhold",
                            "lastName": "H\u00e4b-Umbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhold H\u00e4b-Umbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39047410,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "25c7c505653b42da5f59700f987fdd14931684c1",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe the improvements in a time-synchronous beam search strategy for a 10000-word continuous-speech recognition task. Basically they introduced two measures, namely a tree organization of the pronunciation lexicon and a novel look-ahead technique at the phoneme level. The experimental tests performed showed that the number of state hypotheses could be reduced from 50000 to 3000, i.e., by a factor of about 17. At the same time, the word error rate did not increase. >"
            },
            "slug": "Improvements-in-beam-search-for-10000-word-H\u00e4b-Umbach-Ney",
            "title": {
                "fragments": [],
                "text": "Improvements in beam search for 10000-word continuous-speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Two measures are introduced, namely a tree organization of the pronunciation lexicon and a novel look-ahead technique at the phoneme level, which improve the improvements in a time-synchronous beam search strategy for a 10000-word continuous-speech recognition task."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713807"
                        ],
                        "name": "Gunnar Evermann",
                        "slug": "Gunnar-Evermann",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Evermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar Evermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11673607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd8e340c7d54816ed80d47a1291f8988ae0aba37",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper investigates the estimation of word posterior probabilities based on word lattices and presents applications of these posteriors in a large vocabulary speech recognition system. A novel approach to integrating these word posterior probability distributions into a conventional Viterbi decoder is presented. The problem of the robust estimation of confidence scores from word posteriors is examined and a method based on decision trees is suggested. The effectiveness of these techniques is demonstrated on the broadcast news and the conversational telephone speech corpora where improvements both in terms of word error rate and normalised cross entropy were achieved compared to the baseline HTK evaluation systems."
            },
            "slug": "Large-vocabulary-decoding-and-confidence-estimation-Evermann-Woodland",
            "title": {
                "fragments": [],
                "text": "Large vocabulary decoding and confidence estimation using word posterior probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The paper investigates the estimation of word posterior probabilities based on word lattices and presents applications of these posteriors in a large vocabulary speech recognition system and a novel approach to integrating these word posterior probability distributions into a conventional Viterbi decoder is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703046"
                        ],
                        "name": "R. Passonneau",
                        "slug": "R.-Passonneau",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Passonneau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Passonneau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1043632,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3574e248fdf0a45456257ffab90df25f893e9def",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Certain spans of utterances in a discourse, referred to here as segments, are widely assumed to form coherent units. Further, the segmental structure of discourse has been claimed to constrain and be constrained by many phenomena. However, there is weak consensus on the nature of segments and the criteria for recognizing or generating them. We present quantitative results of a two part study using a corpus of spontaneous, narrative monologues. The first part evaluates the statistical reliability of human segmentation of our corpus, where speaker intention is the segmentation criterion. We then use the subjects' segmentations to evaluate the correlation of discourse segmentation with three linguistic cues (referential noun phrases, cue words, and pauses), using information retrieval metrics."
            },
            "slug": "Intention-Based-Segmentation:-Human-Reliability-and-Passonneau-Litman",
            "title": {
                "fragments": [],
                "text": "Intention-Based Segmentation: Human Reliability and Correlation with Linguistic Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A two part study evaluates the statistical reliability of human segmentation of a corpus of spontaneous, narrative monologues, where speaker intention is the segmentation criterion."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049352"
                        ],
                        "name": "Julia Hirschberg",
                        "slug": "Julia-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Hirschberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730911"
                        ],
                        "name": "M. Swerts",
                        "slug": "M.-Swerts",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Swerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swerts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9824473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54399c4719fae2eb2426f2e88d26a0f956b5e060",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present results of machine learning experiments designed to identify user corrections of speech recognition errors in a corpus collected from a train information spoken dialogue system. We investigate the predictive power of features automatically computable from the prosody of the turn, the speech recognition process, experimental conditions, and the dialogue history. Our best performing features reduce classification error from baselines of 25.70-28.99% to 15.72%."
            },
            "slug": "Identifying-User-Corrections-Automatically-in-Hirschberg-Litman",
            "title": {
                "fragments": [],
                "text": "Identifying User Corrections Automatically in Spoken Dialogue Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The predictive power of features automatically computable from the prosody of the turn, the speech recognition process, experimental conditions, and the dialogue history, as well as the best performing features reduce classification error."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150603996"
                        ],
                        "name": "L. Nguyen",
                        "slug": "L.-Nguyen",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21250154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9942d4ac23892f7e51ed7a401a6e50faa3aade4",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a very fast and accurate fast-match algorithm which, when followed by a regular beam search restricted within only the subset of words selected by the fast-match, can speed up the recognition process by at least two orders of magnitude in comparison to a typical single-pass speech recognizer utilizing the Viterbi (or beam) search algorithm. In this search strategy, the recognition vocabulary is structured as a single phonetic tree in the fast-match pass. The search on this phonetic tree is a variation of the Viterbi algorithm. Especially, we are able to use a word bigram language model without making copies of the tree during the search. This is a novel fast-match algorithm that has two important properties: high-accuracy recognition and run-time proportional to only the cube root of the vocabulary size."
            },
            "slug": "Single-tree-method-for-grammar-directed-search-Nguyen-Schwartz",
            "title": {
                "fragments": [],
                "text": "Single-tree method for grammar-directed search"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel fast-match algorithm that has high-accuracy recognition and run-time proportional to only the cube root of the vocabulary size and is able to use a word bigram language model without making copies of the tree during the search."
            },
            "venue": {
                "fragments": [],
                "text": "1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108972595"
                        ],
                        "name": "Ronnie W. Smith",
                        "slug": "Ronnie-W.-Smith",
                        "structuredName": {
                            "firstName": "Ronnie",
                            "lastName": "Smith",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronnie W. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34584339"
                        ],
                        "name": "Steven A. Gordon",
                        "slug": "Steven-A.-Gordon",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Gordon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven A. Gordon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 849264,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b9022ebc128d23bc1f39111097da4b06ea47198b",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an analysis of the dialogue structure of actual human-computer interactions. The 141 dialogues analyzed were produced from experiments with a variable initiative spoken natural language dialogue system organized around the paradigm of the Missing Axiom Theory for language use. Results about utterance classification into subdialogues, frequency of user-initiated subdialogue transitions, regularity of subdialogue transitions, frequency of linguistic control shifts, and frequency of user-initiated error corrections are presented. These results indicate there are differences in user behavior and dialogue structure as a function of the computer's level of initiative. Furthermore, they provide evidence that a spoken natural language dialogue system must be capable of varying its level of initiative in order to facilitate effective interaction with users of varying levels of expertise and experience."
            },
            "slug": "Effects-of-Variable-Initiative-on-Linguistic-in-Smith-Gordon",
            "title": {
                "fragments": [],
                "text": "Effects of Variable Initiative on Linguistic Behavior in Human-Computer Spoken Natural Language Dialogue"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Analysis of the dialogue structure of actual human-computer interactions indicates there are differences in user behavior and dialogue structure as a function of the computer's level of initiative, and provides evidence that a spoken natural language dialogue system must be capable of varying itslevel of initiative to facilitate effective interaction with users of varying levels of expertise and experience."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049352"
                        ],
                        "name": "Julia Hirschberg",
                        "slug": "Julia-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Hirschberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8976925,
            "fieldsOfStudy": [
                "Sociology",
                "Linguistics"
            ],
            "id": "ec179f9b30d3a4e0f8a50c86d951557dfcbb20d1",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Cue phrases are linguistic expressions such as now and well that function as explicit indicators of the structure of a discourse. For example, now may signal the beginning of a subtopic or a return to a previous topic, while well may mark subsequent material as a response to prior material, or as an explanatory comment. However, while cue phrases may convey discourse structure, each also has one or more alternate uses. While incidentally may be used sententially as an adverbial, for example, the discourse use initiates a digression. Although distinguishing discourse and sentential uses of cue phrases is critical to the interpretation and generation of discourse, the question of how speakers and hearers accomplish this disambiguation is rarely addressed.This paper reports results of empirical studies on discourse and sentential uses of cue phrases, in which both text-based and prosodic features were examined for disambiguating power. Based on these studies, it is proposed that discourse versus sentential usage may be distinguished by intonational features, specifically, pitch accent and prosodic phrasing. A prosodic model that characterizes these distinctions is identified. This model is associated with features identifiable from text analysis, including orthography and part of speech, to permit the application of the results of the prosodic analysis to the generation of appropriate intonational features for discourse and sentential uses of cue phrases in synthetic speech."
            },
            "slug": "Empirical-Studies-on-the-Disambiguation-of-Cue-Hirschberg-Litman",
            "title": {
                "fragments": [],
                "text": "Empirical Studies on the Disambiguation of Cue Phrases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reports results of empirical studies on discourse and sentential uses of cue phrases, in which both text-based and prosodic features were examined for disambiguating power."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681543"
                        ],
                        "name": "G. Zweig",
                        "slug": "G.-Zweig",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zweig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10494385,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21339e43ba099c5729f936031c24cfaf38a95ccd",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 159,
            "paperAbstract": {
                "fragments": [],
                "text": "Dynamic Bayesian networks (DBNs) are a powerful and flexible methodology for representing and computing with probabilistic models of stochastic processes. In the past decade, there has been increasing interest in applying them to practical problems, and this thesis shows that they can be used effectively in the field of automatic speech recognition. \nA principle characteristic of dynamic Bayesian networks is that they can model an arbitrary set of variables as they evolve over time. Moreover, an arbitrary set of conditional independence assumptions can be specified, and this allows the joint distribution to be represented in a highly factored way. Factorization allows for models with relatively few parameters, and computational efficiency. Standardized inference and learning routines allow a variety of model structures to be tested without deriving new formulae, or writing new code. \nThe contribution of this thesis is to show how DBNs can be used in automatic speech recognition. This involves solving problems related to both representation and inference. Representationally, the thesis shows how to encode stochastic finite-state word models as DBNs, and how to construct DBNs that explicitly model the speech-articulators, accent, gender, speaking-rate, and other important phenomena. Technically, the thesis presents inference routines that are especially tailored to the requirements of speech recognition: efficient inference with deterministic constraints, variable-length utterances, and online inference. Finally, the thesis presents experimental results that indicate that real systems can be built, and that modeling important phenomena with DBNs results in higher recognition accuracy."
            },
            "slug": "Speech-Recognition-with-Dynamic-Bayesian-Networks-Zweig-Russell",
            "title": {
                "fragments": [],
                "text": "Speech Recognition with Dynamic Bayesian Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This thesis shows that dynamic Bayesian networks can be used effectively in the field of automatic speech recognition, and presents inference routines that are especially tailored to the requirements of speech recognition: efficient inference with deterministic constraints, variable-length utterances, and online inference."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721830"
                        ],
                        "name": "L. Gillick",
                        "slug": "L.-Gillick",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Gillick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gillick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132323"
                        ],
                        "name": "S. Cox",
                        "slug": "S.-Cox",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 312937,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "774c6a9405b6d52d5d30a15e82601ca4635369c6",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present two simple tests for deciding whether the difference in error rates between two algorithms tested on the same data set is statistically significant. The first (McNemar's test) requires the errors made by an algorithm to be independent events and is found to be most appropriate for isolated-word algorithms. The second (a matched-pairs test) can be used even when errors are not independent events and is more appropriate for connected speech.<<ETX>>"
            },
            "slug": "Some-statistical-issues-in-the-comparison-of-speech-Gillick-Cox",
            "title": {
                "fragments": [],
                "text": "Some statistical issues in the comparison of speech recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present two simple tests for deciding whether the difference in error rates between two algorithms tested on the same data set is statistically significant."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7272120,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3e6cc67fdf67be26baf7c6fe51d87b53cae3aa99",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "\u201cFamiliar\u201d speaker information is explored using non-acoustic features in NIST\u2019s new \u201cextended data\u201d speaker detection task.[1] Word unigrams and bigrams, used in a traditional target/background likelihood ratio framework, are shown to give surprisingly good performance. Performance continues to improve with additional training and/or test data. Bigram performance is also found to be a function of target/model sex and age difference. These initial experiments strongly suggest that further exploration of \u201cfamiliar\u201d speaker characteristics will likely be an extremely interesting and valuable research direction for recognition of speakers in conversational speech."
            },
            "slug": "Speaker-recognition-based-on-idiolectal-differences-Doddington",
            "title": {
                "fragments": [],
                "text": "Speaker recognition based on idiolectal differences between speakers"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "These initial experiments strongly suggest that further exploration of \u201cfamiliar\u201d speaker characteristics will likely be an extremely interesting and valuable research direction for recognition of speakers in conversational speech."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326473"
                        ],
                        "name": "S. Carberry",
                        "slug": "S.-Carberry",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Carberry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carberry"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61773853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac35db33f6d1c0ae93ae3bafc9b7a3226af5feb8",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nIn most current natural language systems each query is treated as an isolated request for information regardless of its context in dialogue. Sandra Carberry addresses the problem of creating computational strategies that can improve user-computer communication by assimilating ongoing dialogue and reasoning on the acquired knowledge. \nPlan Recognition in Natural Language Dialogue critically examines plan recognition - the inference of an agent's goals and how he or she intends to achieve them. It describes significant models of plan inference and presents in detail the author's own model, which infers new goals from user utterances and integrates them into the system's model of the user's plan, incrementally expanding and adding detail to its beliefs about what the information seeker wants to do. Carberry then outlines computational strategies for interpreting two kinds of problematic utterances: utterances that violate the pragmatic rules of the system's world model and intersentential elliptical fragments. She also suggests directions for future research. \nSandra Carberry is Assistant Professor in the Department of Computer and Information Sciences at the University of Delaware. Plan Recognition in Natural Language Dialogue is included in the ACL-MIT Press Series in Natural Language Processing edited by Aravind Joshi."
            },
            "slug": "Plan-Recognition-in-Natural-Language-Dialogue-Carberry",
            "title": {
                "fragments": [],
                "text": "Plan Recognition in Natural Language Dialogue"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The author's own model is presented, which infers new goals from user utterances and integrates them into the system's model of the user's plan, incrementally expanding and adding detail to its beliefs about what the information seeker wants to do."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744182"
                        ],
                        "name": "M. Weintraub",
                        "slug": "M.-Weintraub",
                        "structuredName": {
                            "firstName": "Mitch",
                            "lastName": "Weintraub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weintraub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360345"
                        ],
                        "name": "Kelsey Taussig",
                        "slug": "Kelsey-Taussig",
                        "structuredName": {
                            "firstName": "Kelsey",
                            "lastName": "Taussig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kelsey Taussig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405792322"
                        ],
                        "name": "Kate Hunicke-Smith",
                        "slug": "Kate-Hunicke-Smith",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Hunicke-Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kate Hunicke-Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123644978"
                        ],
                        "name": "Amy Snodgrass",
                        "slug": "Amy-Snodgrass",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Snodgrass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy Snodgrass"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2491977,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "9ed4cd6b7ab43117b7dc3919f4baf673b1db037e",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "SRI collected a corpus to study how spontaneous speech differs from other types of speech. The corpus was collected in two parts: (1) a spontaneous Switchboard-style conversation on an assigned topic, and (2) a reading session in which participants read transcripts of their conversation from part 1. Experiments were conducted on sentences with identical transcripts that varied in speaking style. The word-error rates varied from 29% (careful dictation) to 53% (spontaneous conversation) depending on the speaking style. These experiments show that speaking style is a dominant factor in determining the performance of large-vocabulary conversational speech recognition (LVCSR) systems."
            },
            "slug": "Effect-of-Speaking-Style-on-LVCSR-Performance-Weintraub-Taussig",
            "title": {
                "fragments": [],
                "text": "Effect of Speaking Style on LVCSR Performance"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "These experiments show that speaking style is a dominant factor in determining the performance of large-vocabulary conversational speech recognition (LVCSR) systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6264658"
                        ],
                        "name": "A. Salasoo",
                        "slug": "A.-Salasoo",
                        "structuredName": {
                            "firstName": "Aita",
                            "lastName": "Salasoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Salasoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859196"
                        ],
                        "name": "D. Pisoni",
                        "slug": "D.-Pisoni",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pisoni",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pisoni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 28346628,
            "fieldsOfStudy": [
                "Linguistics",
                "Psychology"
            ],
            "id": "1df5665690f6f739c4dca6d0252758a4cf170e62",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interaction-of-Knowledge-Sources-in-Spoken-Word-Salasoo-Pisoni",
            "title": {
                "fragments": [],
                "text": "Interaction of Knowledge Sources in Spoken Word Identification."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of memory and language"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171861"
                        ],
                        "name": "Thomas Hain",
                        "slug": "Thomas-Hain",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 259104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d820041b0ab2e60b1357acc301d669e612a34541",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Modelling of pronunciation variability is an important part of the acoustic model of a speech recognition system. Good pronunciation models contribute to the robustness and portability of a speech recogniser. Usually pronunciation modelling is associated with the recognition lexicon which allows a direct control of HMM selection. However, in state-of-the-art systems the use of clustering techniques has considerable cross-effects for the dictionary design. Most large vocabulary speech recognition systems make use of a dictionary with multiple possible pronunciation variants per word. In this paper a method for a consistent reduction of the number of pronunciation variants to one pronunciation per word is described. Using the single pronunciation dictionaries similar or better word error rate performance is achieved both on Wall Street Journal and Switchboard data."
            },
            "slug": "IMPLICIT-PRONUNCIATION-MODELLING-IN-ASR-Hain",
            "title": {
                "fragments": [],
                "text": "IMPLICIT PRONUNCIATION MODELLING IN ASR"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "In this paper a method for a consistent reduction of the number of pronunciation variants to one pronunciation per word is described and similar or better word error rate performance is achieved both on Wall Street Journal and Switchboard data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143789092"
                        ],
                        "name": "A. Cutler",
                        "slug": "A.-Cutler",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Cutler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cutler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144730709"
                        ],
                        "name": "D. Norris",
                        "slug": "D.-Norris",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Norris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Norris"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9625180,
            "fieldsOfStudy": [
                "Linguistics",
                "Physics"
            ],
            "id": "ab59fdacbd55e9be570493afa8560065742e7258",
            "isKey": false,
            "numCitedBy": 1066,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "A model of speech segmentation in a stress language is proposed, according to which the occurrence of a strong syllable triggers segmentation of the speech signal, whereas occurrence of a weak syllable does not trigger segmentation. We report experiments in which listeners detected words embedded in nonsense bisyllables more slowly when the bisyllable had two strong syllables than when it had a strong and a weak syllable; mint was detected more slowly in mintayve than in minlesh. According to our proposed model, this result is an effect of segmentation: When the second syllable is strong, it is segmented from the first syllable, and successful detection of the embedded word therefore requires assembly of speech material across a segmentation position. Speech recognition models involving phonemic or syllabic receding, or based on strictly left-toright processes, do not predict this result. It is argued that segmentation at strong syllables in continuous speech recognition serves the purpose of detecting the most efficient locations at which to initiate lexical access."
            },
            "slug": "The-role-of-strong-syllables-in-segmentation-for-Cutler-Norris",
            "title": {
                "fragments": [],
                "text": "The role of strong syllables in segmentation for lexical access"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is argued that segmentation at strong syllables in continuous speech recognition serves the purpose of detecting the most efficient locations at which to initiate lexical access."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684353"
                        ],
                        "name": "Jennifer Chu-Carroll",
                        "slug": "Jennifer-Chu-Carroll",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Chu-Carroll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Chu-Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18930141,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "e129e554abf2cfede606459a4ac83f2759f2ffe5",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses a statistical model for recognizing discourse intentions of utterances during dialogue interactions. We argue that this recognition process should be based on features of the current utterance as well as on discourse history, and show that taking into account utterance features such as speaker information and syntactic forms of utterances dramatically improves the system\u2019s performance as compared with a simple trigram model of discourse acts. In addition, we propose that taking into account information about discourse structure may allow the system to construct a more accurate discourse act model and thus improve recognition results. Experiments show this proposal to be promising."
            },
            "slug": "A-Statistical-Model-for-Discourse-Act-Recognition-Chu-Carroll",
            "title": {
                "fragments": [],
                "text": "A Statistical Model for Discourse Act Recognition in Dialogue Interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that taking into account utterance features such as speaker information and syntactic forms of utterances dramatically improves the system\u2019s performance as compared with a simple trigram model of discourse acts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686491"
                        ],
                        "name": "J. Polifroni",
                        "slug": "J.-Polifroni",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Polifroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Polifroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745131"
                        ],
                        "name": "S. Seneff",
                        "slug": "S.-Seneff",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Seneff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seneff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2261254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d10ae238c48f138ebec0084a8b0b5fcea2356f4",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "As the DARPA spoken language community moves towards developing useful systems for interactive problem solving, we must explore alternative evaluation procedures that measure whether these systems aid people in solving problems within the task domain. In this paper, we describe several experiments exploring new evaluation procedures. To look at end-to-end evaluation, we modified our data collection procedure slightly in order to experiment with several objective task completion measures. We found that the task completion time is well correlated with the number of queries used. We also explored log file evaluation, where evaluators were asked to judge the clarity of the query and the correctness of the response based on examination of the log file. Our results show that seven evaluators were unanimous on more than 80% of the queries, and that at least 6 out of 7 evaluators agreed over 90% of the time. Finally, we applied these new procedures to compare two systems, one system requiring a complete parse and the other using the more flexible robust parsing mechanism. We found that these metrics could distinguish between these systems: there were significant differences in ability to complete the task, number of queries required to complete the task, and score (as computed through a log file evaluation) between the robust and the non-robust modes."
            },
            "slug": "Experiments-in-Evaluating-Interactive-Spoken-Polifroni-Hirschman",
            "title": {
                "fragments": [],
                "text": "Experiments in Evaluating Interactive Spoken Language Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "To look at end-to-end evaluation, a data collection procedure was modified slightly in order to experiment with several objective task completion measures, and it was found that the task completion time is well correlated with the number of queries used."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2138347"
                        ],
                        "name": "K. Kita",
                        "slug": "K.-Kita",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Kita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096436271"
                        ],
                        "name": "Y. Fukui",
                        "slug": "Y.-Fukui",
                        "structuredName": {
                            "firstName": "Yoshikazu",
                            "lastName": "Fukui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Fukui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364073"
                        ],
                        "name": "M. Nagata",
                        "slug": "M.-Nagata",
                        "structuredName": {
                            "firstName": "Masaaki",
                            "lastName": "Nagata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nagata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334773"
                        ],
                        "name": "T. Morimoto",
                        "slug": "T.-Morimoto",
                        "structuredName": {
                            "firstName": "Tsuyoshi",
                            "lastName": "Morimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Morimoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35653896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da62399eb0f69d020a5476fab7e2a61d8b5ea753",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "In the work described, we automatically deduce dialogue structures from a corpus with probabilistic methods. Each utterance in the corpus is annotated with a speaker label and an utterance type called IFT (Illocutionary Force Type). We use an ergodic HMM (hidden Markov model) and the ALERGIA algorithm, an algorithm for learning probabilistic automata by means of state merging, to model the speaker-IFT sequences. Our experiments successfully extract typical dialogue structures such as turn taking and speech act sequencing."
            },
            "slug": "Automatic-acquisition-of-probabilistic-dialogue-Kita-Fukui",
            "title": {
                "fragments": [],
                "text": "Automatic acquisition of probabilistic dialogue models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An ergodic HMM and the ALERGIA algorithm, an algorithm for learning probabilistic automata by means of state merging, are used to model the speaker-IFT sequences and successfully extract typical dialogue structures such as turn taking and speech act sequencing."
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866226"
                        ],
                        "name": "W. Ward",
                        "slug": "W.-Ward",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Ward",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ward"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17387902,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0d53102faeda7f3015a34adcac8839f128dd7a8e",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "When speech understanding systems are used in real applications, they encounter incidental noise generated by the speaker and the environment. Such noises can cause serious problems for speech recognizers not designed to cope with them. We attempt to model these noises by training HMM \"noise words\" to match classes of noises. The noise words were incorporated into the Sphinx system and performance compared to the system without noise words. Initial results suggest that the technique does increase system performance significantly."
            },
            "slug": "Modelling-Non-verbal-Sounds-for-Speech-Recognition-Ward",
            "title": {
                "fragments": [],
                "text": "Modelling Non-verbal Sounds for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Initial results suggest that the technique does increase system performance significantly, and the technique was incorporated into the Sphinx system and performance compared to the system without noise words."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705045"
                        ],
                        "name": "J. Junqua",
                        "slug": "J.-Junqua",
                        "structuredName": {
                            "firstName": "Jean-Claude",
                            "lastName": "Junqua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Junqua"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7763550,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "86b9166223e6875257444bbed813cb092b5035c1",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic speech recognition experiments show that, depending on the task performed and how speech variability is modeled, automatic speech recognizers are more or less sensitive to the Lombard reflex. To gain an understanding about the Lombard effect with the prospect of improving performance of automatic speech recognizers, (1) an analysis was made of the acoustic-phonetic changes occurring in Lombard speech, and (2) the influence of the Lombard effect on speech perception was studied. Both acoustic and perceptual analyses suggest that the influence of the Lombard effect on male and female speakers is different. The analyses also bring to light that, even if some tendencies across speakers can be observed consistently, the Lombard reflex is highly variable from speaker to speaker. Based on the results of the acoustic and perceptual studies, some ways of dealing with Lombard speech variability in automatic speech recognition are also discussed."
            },
            "slug": "The-Lombard-reflex-and-its-role-on-human-listeners-Junqua",
            "title": {
                "fragments": [],
                "text": "The Lombard reflex and its role on human listeners and automatic speech recognizers."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Both acoustic and perceptual analyses suggest that the influence of the Lombard effect on male and female speakers is different and bring to light that, even if some tendencies across speakers can be observed consistently, the Lombardy reflex is highly variable from speaker to speaker."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069194860"
                        ],
                        "name": "Ken Samuel",
                        "slug": "Ken-Samuel",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Samuel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ken Samuel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326473"
                        ],
                        "name": "S. Carberry",
                        "slug": "S.-Carberry",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Carberry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carberry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400820110"
                        ],
                        "name": "K. Vijay-Shanker",
                        "slug": "K.-Vijay-Shanker",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Vijay-Shanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Vijay-Shanker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 643470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2684e9843e0378e6ca62b1068d87732876637e8c",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "For the task of recognizing dialogue acts, we are applying the Transformation-Based Learning (TBL) machine learning algorithm. To circumvent a sparse data problem, we extract values of well-motivated features of utterances, such as speaker direction, punctuation marks, and a new feature, called dialogue act cues, which we find to be more effective than cue phrases and word n-grams in practice. We present strategies for constructing a set of dialogue act cues automatically by minimizing the entropy of the distribution of dialogue acts in a training corpus, filtering out irrelevant dialogue act cues, and clustering semantically-related words. In addition, to address limitations of TBL, we introduce a Monte Carlo strategy for training efficiently and a committee method for computing confidence measures. These ideas are combined in our working implementation, which labels held-out data as accurately as any other reported system for the dialogue act tagging task."
            },
            "slug": "Dialogue-Act-Tagging-with-Transformation-Based-Samuel-Carberry",
            "title": {
                "fragments": [],
                "text": "Dialogue Act Tagging with Transformation-Based Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work extracts values of well-motivated features of utterances, such as speaker direction, punctuation marks, and a new feature, called dialogue act cues, which it finds to be more effective than cue phrases and word n-grams in practice."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60956831,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "911dcf64fddfda2b178bcba52007e7e3e2d7daef",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "One promising computational approach to understanding dialogues has involved modeling the goals of the speakers in the domain of discourse. In general, these models work well as long as the topic follows the goal structure closely, but they have difficulty accounting for interrupting subdialogues such as clarifications and corrections. Furthermore, such models are typically unable to use many processing clues provided by the linguistic phenomena of the dialogues. \nThis dissertation presents a computational theory and partial implementation of a discourse level model of dialogue understanding. The theory extends and integrates plan-based and linguistic-based approaches to language processing, arguing that such a synthesis is needed to computationally handle many discourse level phenomena present in naturally occurring dialogues. The simple, fairly syntactic results of discourse analysis (for example, explanations of phenomena in terms of very local discourse contexts as well as correlations between syntactic devices and discourse function) will be input to the plan recognition system, while the more complex inferential processes relating utterances have been totally reformulated within a plan-based framework. Such an integration has led to a new model of plan recognition, one that constructs a hierarchy of domain and meta-plans via the process of constraint satisfaction. Furthermore, the processing of the plan recognizer is explicitly coordinated with a set of linguistic clues. The resulting framework handles a wide variety of difficult linguistic phenomena (for example, interruptions, fragmental and elliptical utterances, and presence as well as absence of syntactic discourse clues), while maintaining the computational advantages of the plan-based approach. The implementation of the plan recognition aspects of this framework also addresses two difficult issues of knowledge representation inherent in any plan recognition task."
            },
            "slug": "Plan-recognition-and-discourse-analysis:-an-for-Litman",
            "title": {
                "fragments": [],
                "text": "Plan recognition and discourse analysis: an integrated approach for understanding dialogues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The theory extends and integrates plan-based and linguistic-based approaches to language processing, arguing that such a synthesis is needed to computationally handle many discourse level phenomena present in naturally occurring dialogues."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2959613"
                        ],
                        "name": "Matthew Lennig",
                        "slug": "Matthew-Lennig",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Lennig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Lennig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122134411"
                        ],
                        "name": "F. Seitz",
                        "slug": "F.-Seitz",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Seitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Seitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143791674"
                        ],
                        "name": "P. Mermelstein",
                        "slug": "P.-Mermelstein",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Mermelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mermelstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62742206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "478d55e984ab2226b209cf8aa8cb0d2e65241246",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Large-vocabulary-word-recognition-using-allophonic-Deng-Lennig",
            "title": {
                "fragments": [],
                "text": "Large vocabulary word recognition using context-dependent allophonic hidden Markov models\u2606"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47263765"
                        ],
                        "name": "D. Novick",
                        "slug": "D.-Novick",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Novick",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Novick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40472905"
                        ],
                        "name": "D. Burnett",
                        "slug": "D.-Burnett",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Burnett",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064554176"
                        ],
                        "name": "Brian Hansen",
                        "slug": "Brian-Hansen",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060185505"
                        ],
                        "name": "Stephen Sutton",
                        "slug": "Stephen-Sutton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102659278"
                        ],
                        "name": "M. Fant",
                        "slug": "M.-Fant",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fant"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37851657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c83e1c129f47f0765991b21f6aa4c6ae38644199",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a study to determine the feasibility of using automatic speech recognition to collect information over the telephone for the Year 2000 census in the United States. The stages of research are protocol development, speech data collection and transcription, system development, and system evaluation. We developed a rapid prototyping methodology to produce two protocols now being used to collect data from callers solicited by the bureau of the census. We have collected speech from over 1000 callers, with a goal of 3000 complete calls. Two hundred calls have been transcribed at the word level. Initial results are reported for a baseline system tested on the transcribed calls. The baseline system is both speaker and vocabulary independent-it has not been trained on words from the recognition vocabulary. The system's error rate ranges between 2% and 21% for responses to the different prompts. We describe research now underway intended to produce a system that is sufficiently accurate and graceful to demonstrate feasibility of a voice response questionnaire.<<ETX>>"
            },
            "slug": "Towards-automatic-collection-of-the-US-census-Cole-Novick",
            "title": {
                "fragments": [],
                "text": "Towards automatic collection of the US census"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A rapid prototyping methodology was developed to produce two protocols now being used to collect data from callers solicited by the bureau of the census, and a system that is sufficiently accurate and graceful to demonstrate feasibility of a voice response questionnaire is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICASSP '94. IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731353"
                        ],
                        "name": "Norbert Reithinger",
                        "slug": "Norbert-Reithinger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Reithinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norbert Reithinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2922093"
                        ],
                        "name": "M. Klesen",
                        "slug": "M.-Klesen",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Klesen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Klesen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14505712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e38f451f265a8eda99878ee351a89f18bf26044",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Pragmatically important information as e.g. dialogue acts that describe the illocution of an utterance depend in traditional processing approaches on error prone syn-tactic/semantic processing. We present a statistically based method for dialogue act classiication that has word strings as input. An experimental evaluation shows that this method can be successfully used to determine dialogue acts. The overall recognition rate in the experiments is in the range of 65%{67% for German test data, and 74% for an experiment with English dialogues."
            },
            "slug": "Dialogue-act-classification-using-language-models-Reithinger-Klesen",
            "title": {
                "fragments": [],
                "text": "Dialogue act classification using language models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A statistically based method for dialogue act classiication that has word strings as input is presented and it is shown that this method can be successfully used to determine dialogue acts."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47263765"
                        ],
                        "name": "D. Novick",
                        "slug": "D.-Novick",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Novick",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Novick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35941561"
                        ],
                        "name": "Pieter J. E. Vermeulen",
                        "slug": "Pieter-J.-E.-Vermeulen",
                        "structuredName": {
                            "firstName": "Pieter",
                            "lastName": "Vermeulen",
                            "middleNames": [
                                "J.",
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pieter J. E. Vermeulen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060185505"
                        ],
                        "name": "Stephen Sutton",
                        "slug": "Stephen-Sutton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681269"
                        ],
                        "name": "M. Fanty",
                        "slug": "M.-Fanty",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fanty",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fanty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066621920"
                        ],
                        "name": "L. F. A. Wessels",
                        "slug": "L.-F.-A.-Wessels",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Wessels",
                            "middleNames": [
                                "F.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. F. A. Wessels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73598336"
                        ],
                        "name": "J. Villiers",
                        "slug": "J.-Villiers",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Villiers",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Villiers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698491"
                        ],
                        "name": "J. Schalkwyk",
                        "slug": "J.-Schalkwyk",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Schalkwyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schalkwyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064554176"
                        ],
                        "name": "Brian Hansen",
                        "slug": "Brian-Hansen",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40472905"
                        ],
                        "name": "D. Burnett",
                        "slug": "D.-Burnett",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Burnett",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burnett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24072012,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2445ed8f63b3ff19eba812ae6e48e504263500c3",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-with-a-spoken-dialogue-system-for-the-Cole-Novick",
            "title": {
                "fragments": [],
                "text": "Experiments with a spoken dialogue system for taking the US census"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115311"
                        ],
                        "name": "R. Pieraccini",
                        "slug": "R.-Pieraccini",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Pieraccini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pieraccini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15886461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d115356bcb38514589fe56aac6d9fa220722284",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a model for a statistical representation of the conceptual structure in a restricted subset of spoken natural language. The model is used for segmenting a sentence into phrases and labeling them with concept relations (or cases). The model is trained using a corpus of annotated transcribed sentences. The performance of the model was assessed on two tasks, including DARPA ATIS class A sentences."
            },
            "slug": "Stochastic-Representation-of-Conceptual-Structure-Pieraccini-Levin",
            "title": {
                "fragments": [],
                "text": "Stochastic Representation of Conceptual Structure in the ATIS Task"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A model for a statistical representation of the conceptual structure in a restricted subset of spoken natural language used for segmenting a sentence into phrases and labeling them with concept relations (or cases) is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46299348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a6ae3d667a5c2601c1852a0753c8b1c749fec1e",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes, and evaluates on a large scale, the lattice based framework for discriminative training of large vocabulary speech recognition systems based on Gaussian mixture hidden Markov models (HMMs). This paper concentrates on the maximum mutual information estimation (MMIE) criterion which has been used to train HMM systems for conversational telephone speech transcription using up to 265 hours of training data. These experiments represent the largest-scale application of discriminative training techniques for speech recognition of which the authors are aware. Details are given of the MMIE lattice-based implementation used with the extended Baum-Welch algorithm, which makes training of such large systems computationally feasible. Techniques for improving generalization using acoustic scaling and weakened language models are discussed. The overall technique has allowed the estimation of triphone and quinphone HMM parameters which has led to significant reductions in word error rate for the transcription of conversational telephone speech relative to our best systems trained using maximum likelihood estimation (MLE). This is in contrast to some previous studies, which have concluded that there is little benefit in using discriminative training for the most difficult large vocabulary speech recognition tasks. The lattice MMIE-based discriminative training scheme is also shown to out-perform the frame discrimination technique. Various properties of the lattice-based MMIE training scheme are investigated including comparisons of different lattice processing strategies (full search and exact-match) and the effect of lattice size on performance. Furthermore a scheme based on the linear interpolation of the MMIE and MLE objective functions is shown to reduce the danger of over-training. It is shown that HMMs trained with MMIE benefit as much as MLE-trained HMMs from applying model adaptation using maximum likelihood linear regression (MLLR). This has allowed the straightforward integration of MMIE-trained HMMs into complex multi-pass systems for transcription of conversational telephone speech and has contributed to our MMIE-trained systems giving the lowest word error rates in both the 2000 and 2001 NIST Hub5 evaluations."
            },
            "slug": "Large-scale-discriminative-training-of-hidden-for-Woodland-Povey",
            "title": {
                "fragments": [],
                "text": "Large scale discriminative training of hidden Markov models for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that HMMs trained with MMIE benefit as much as MLE-trained HMMs from applying model adaptation using maximum likelihood linear regression (MLLR), which has allowed the straightforward integration of MMIe- trained HMMs into complex multi-pass systems for transcription of conversational telephone speech."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145502114"
                        ],
                        "name": "R. Reddy",
                        "slug": "R.-Reddy",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Reddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reddy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39233108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1a93cd7f9302e93462c7d694a84527ae23bab7f",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual and speech perception tasks, which can be performed with no apparent effort by people, have proved to be difficult for machines. This may be in part due to the absence of cognitive models of perception of the type proposed above by Jakobson. In this paper we attempt to give a unified view of the research in machine perception of speech and vision in the hope that a clear appreciation of similarities and differences may lead to better information processing models of perception. Being active in research in both computer vision and speech, we have found it useful to look at the problems that have arisen in one domain and anticipate corresponding problems in the other (Reddy, 1969). Thus, this paper represents a comparitive study of the issues, systems and unsolved problems that are, at present, of interest to visual and speech recognition research."
            },
            "slug": "Eyes-and-Ears-for-Computers-Reddy",
            "title": {
                "fragments": [],
                "text": "Eyes and Ears for Computers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper represents a comparitive study of the issues, systems and unsolved problems that are, at present, of interest to visual and speech recognition research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364073"
                        ],
                        "name": "M. Nagata",
                        "slug": "M.-Nagata",
                        "structuredName": {
                            "firstName": "Masaaki",
                            "lastName": "Nagata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nagata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334773"
                        ],
                        "name": "T. Morimoto",
                        "slug": "T.-Morimoto",
                        "structuredName": {
                            "firstName": "Tsuyoshi",
                            "lastName": "Morimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Morimoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35910422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6d2d51adbf12ab3740cb7ce07ebb6ee85b387fd",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "First-steps-towards-statistical-modeling-of-to-the-Nagata-Morimoto",
            "title": {
                "fragments": [],
                "text": "First steps towards statistical modeling of dialogue to predict the speech act type of the next utterance"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Communication"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684353"
                        ],
                        "name": "Jennifer Chu-Carroll",
                        "slug": "Jennifer-Chu-Carroll",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Chu-Carroll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Chu-Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579894"
                        ],
                        "name": "B. Carpenter",
                        "slug": "B.-Carpenter",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Carpenter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Carpenter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14229502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbbf137fba6062820b98dba6ec5e500b33d1e2ec",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a domain-independent, automatically trained natural language call router for directing incoming calls in a call center. Our call router directs customer calls based on their response to an open-ended How may I direct your call? prompt. Routing behavior is trained from a corpus of transcribed and hand-routed calls and then carried out using vector-based information retrieval techniques. Terms consist of n-gram sequences of morphologically reduced content words, while documents representing routing destinations consist of weighted term frequencies derived from calls to that destination in the training corpus. Based on the statistical discriminating power of the n-gram terms extracted from the caller's request, the caller is 1) routed to the appropriate destination, 2) transferred to a human operator, or 3) asked a disambiguation question. In the last case, the system dynamically generates queries tailored to the caller's request and the destinations with which it is consistent, based on our extension of the vector model. Evaluation of the call router performance over a financial services call center using both accurate transcriptions of calls and fairly noisy speech recognizer output demonstrated robustness in the face of speech recognition errors. More specifically, using accurate transcriptions of speech input, our system correctly routed 93.8% of the calls after redirecting 10.2% of all calls to a human operator. Using speech recognizer output with a 23% error rate reduced the number of correctly routed calls by 4%."
            },
            "slug": "Vector-based-Natural-Language-Call-Routing-Chu-Carroll-Carpenter",
            "title": {
                "fragments": [],
                "text": "Vector-based Natural Language Call Routing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Evaluation of the call router performance over a financial services call center using both accurate transcriptions of calls and fairly noisy speech recognizer output demonstrated robustness in the face of speech recognition errors."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116335514"
                        ],
                        "name": "Joanne L. Miller",
                        "slug": "Joanne-L.-Miller",
                        "structuredName": {
                            "firstName": "Joanne",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joanne L. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31014025,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "41cba58c46d13bb1f7171586d4dd7b3f27901224",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-internal-structure-of-phonetic-categories:-a-Miller",
            "title": {
                "fragments": [],
                "text": "On the internal structure of phonetic categories: a progress report"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779846"
                        ],
                        "name": "H. Sakoe",
                        "slug": "H.-Sakoe",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Sakoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35805230"
                        ],
                        "name": "S. Chiba",
                        "slug": "S.-Chiba",
                        "structuredName": {
                            "firstName": "Seibi",
                            "lastName": "Chiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chiba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17900407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18f355d7ef4aa9f82bf5c00f84e46714efa5fd77",
            "isKey": false,
            "numCitedBy": 5373,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm."
            },
            "slug": "Dynamic-programming-algorithm-optimization-for-word-Sakoe-Chiba",
            "title": {
                "fragments": [],
                "text": "Dynamic programming algorithm optimization for spoken word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition, in which the warping function slope is restricted so as to improve discrimination between words in different categories."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2535627"
                        ],
                        "name": "M. Sara\u00e7lar",
                        "slug": "M.-Sara\u00e7lar",
                        "structuredName": {
                            "firstName": "Murat",
                            "lastName": "Sara\u00e7lar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sara\u00e7lar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1956222"
                        ],
                        "name": "H. Nock",
                        "slug": "H.-Nock",
                        "structuredName": {
                            "firstName": "Harriet",
                            "lastName": "Nock",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6164277,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "715908ccb336699656cc56916c4171ef8120153f",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Conversational speech exhibits considerable pronunciation variability, which has been shown to have a detrimental effect on the accuracy of automatic speech recognition. There have been many attempts to model pronunciation variation, including the use of decision trees to generate alternate word pronunciations from phonemic baseforms. Use of pronunciation models during recognition is known to improve accuracy. This paper describes the incorporation of pronunciation models into acoustic model training in addition to recognition. Subtle difficulties in the straightforward use of alternatives to canonical pronunciations are first illustrated: it is shown that simply improving the accuracy of the phonetic transcription used for acoustic model training is of little benefit. Acoustic models trained on the most accurate phonetic transcriptions result in worse recognition than acoustic models trained on canonical baseforms. Analysis of this counterintuitive result leads to a new method of accommodating nonstandard pronunciations: rather than allowing a phoneme in the canonical pronunciation to be realized as one of a few distinct alternate phones, the hidden Markov model (HMM) states of the phoneme?s model are instead allowed to share Gaussian mixture components with the HMM states of the model(s) of the alternate realization(s). Qualitatively, this amounts to making a soft decision about which surface form is realized. Quantitatively, experiments show that this method is particularly well suited for acoustic model training for spontaneous speech: a 1.7 %(absolute) improvement in recognition accuracy on the Switchboard corpus is presented."
            },
            "slug": "Pronunciation-modeling-by-sharing-gaussian-across-Sara\u00e7lar-Nock",
            "title": {
                "fragments": [],
                "text": "Pronunciation modeling by sharing gaussian densities across phonetic models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The incorporation of pronunciation models into acoustic model training in addition to recognition is described, showing a 1.7 % improvement in recognition accuracy on the Switchboard corpus is presented."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807460"
                        ],
                        "name": "S. Oviatt",
                        "slug": "S.-Oviatt",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Oviatt",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Oviatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2305444"
                        ],
                        "name": "Philip R. Cohen",
                        "slug": "Philip-R.-Cohen",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Cohen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip R. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108608896"
                        ],
                        "name": "Michelle Wang",
                        "slug": "Michelle-Wang",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michelle Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40404599"
                        ],
                        "name": "Jeremy Gaston",
                        "slug": "Jeremy-Gaston",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Gaston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Gaston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11110465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecda0a336aff3c969673c18d978c5d38f0c0dd4b",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Basic research is critically needed to guide the development of a new generation of multimodal and multilingual NL systems. This paper summarizes the goals, capabilities, computing environment, and performance characteristics of a new semi-automatic simulation technique. This technique has been designed to support a wide spectrum of empirical studies on highly interactive speech, writing, and multi-modal systems incorporating pen and voice. Initial studies using this technique have provided information on people's language, performance, and preferential use of these communication modalities, either alone or in multimodal combination. One aim of this research has been to explore how the selection of input modality and presentation format can be used to reduce difficult sources of linguistic variability in people's speech and writing, such that more robust system processing results. The development of interface techniques for channeling users' language will be important to the ability of complex NL systems to function successfully in actual field use, as well as to the overall commercialization of this technology. Future extensions of the present simulation research also are discussed."
            },
            "slug": "A-Simulation-Based-Research-Strategy-for-Designing-Oviatt-Cohen",
            "title": {
                "fragments": [],
                "text": "A Simulation-Based Research Strategy for Designing Complex NL Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "One aim of this research has been to explore how the selection of input modality and presentation format can be used to reduce difficult sources of linguistic variability in people's speech and writing, such that more robust system processing results are obtained."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20866393"
                        ],
                        "name": "Heidi Fox",
                        "slug": "Heidi-Fox",
                        "structuredName": {
                            "firstName": "Heidi",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heidi Fox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8945340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2124f8995a9cdf4e168baba426472d2d811c0f1",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard. In this paper we report adapting a lexicalized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations."
            },
            "slug": "A-Novel-Use-of-Statistical-Parsing-to-Extract-from-Miller-Fox",
            "title": {
                "fragments": [],
                "text": "A Novel Use of Statistical Parsing to Extract Information from Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A lexicalized, probabilistic context-free parser is adapted to information extraction and this new technique is evaluated on MUC-7 template elements and template relations."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807460"
                        ],
                        "name": "S. Oviatt",
                        "slug": "S.-Oviatt",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Oviatt",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Oviatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826902"
                        ],
                        "name": "M. MacEachern",
                        "slug": "M.-MacEachern",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "MacEachern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. MacEachern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733034"
                        ],
                        "name": "Gina-Anne Levow",
                        "slug": "Gina-Anne-Levow",
                        "structuredName": {
                            "firstName": "Gina-Anne",
                            "lastName": "Levow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gina-Anne Levow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2409742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "beaf06a542b05d84da38726ae9bb7a05610a262a",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Predicting-hyperarticulate-speech-during-error-Oviatt-MacEachern",
            "title": {
                "fragments": [],
                "text": "Predicting hyperarticulate speech during human-computer error resolution"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 16667309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "618c54f2ee1ebffdb8dc8fc501166b01f8731496",
            "isKey": false,
            "numCitedBy": 749,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The key problem to be faced when building a HMM-based continuous speech recogniser is maintaining the balance between model complexity and available training data. For large vocabulary systems requiring cross-word context dependent modelling, this is particularly acute since many such contexts will never occur in the training data. This paper describes a method of creating a tied-state continuous speech recognition system using a phonetic decision tree. This tree-based clustering is shown to lead to similar recognition performance to that obtained using an earlier data-driven approach but to have the additional advantage of providing a mapping for unseen triphones. State-tying is also compared with traditional model-based tying and shown to be clearly superior. Experimental results are presented for both the Resource Management and Wall Street Journal tasks."
            },
            "slug": "Tree-based-state-tying-for-high-accuracy-acoustic-Young-Odell",
            "title": {
                "fragments": [],
                "text": "Tree-based state tying for high accuracy acoustic modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes a method of creating a tied-state continuous speech recognition system using a phonetic decision tree, which is shown to lead to similar recognition performance to that obtained using an earlier data-driven approach but to have the additional advantage of providing a mapping for unseen triphones."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20370792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "affcf19551b01c4c8009d061750700d91c2f79e9",
            "isKey": false,
            "numCitedBy": 3833,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A classic introduction to artificial intelligence intended to bridge the gap between theory and practice, \"Principles of Artificial Intelligence\" describes fundamental AI ideas that underlie applications such as natural language processing, automatic programming, robotics, machine vision, automatic theorem proving, and intelligent data retrieval. Rather than focusing on the subject matter of the applications, the book is organized around general computational concepts involving the kinds of data structures used, the types of operations performed on the data structures, and the properties of the control strategies used. \"Principles of Artificial Intelligence\"evolved from the author's courses and seminars at Stanford University and University of Massachusetts, Amherst, and is suitable for text use in a senior or graduate AI course, or for individual study."
            },
            "slug": "Principles-of-Artificial-Intelligence-Nilsson",
            "title": {
                "fragments": [],
                "text": "Principles of Artificial Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This classic introduction to artificial intelligence describes fundamental AI ideas that underlie applications such as natural language processing, automatic programming, robotics, machine vision, automatic theorem proving, and intelligent data retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103093652"
                        ],
                        "name": "Chao Huang",
                        "slug": "Chao-Huang",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708592"
                        ],
                        "name": "Eric Chang",
                        "slug": "Eric-Chang",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867071"
                        ],
                        "name": "Jian-Lai Zhou",
                        "slug": "Jian-Lai-Zhou",
                        "structuredName": {
                            "firstName": "Jian-Lai",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian-Lai Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8149365,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5424498ed4bf2624248a60d6115dd5e5a300ba62",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of accent modeling through Pronunciation Dictionary Adaptation (PDA) is presented. We derive the pronunciation variation between canonical speaker groups and accent groups and add an encoding of the differences to a canonical dictionary to create a new, adapted dictionary that reflects the accent characteristics. The pronunciation variation information is then integrated with acoustic and language models into a one-pass search framework. It is assumed that acoustic deviation and pronunciation variation are independent but complementary phenomena that cause poor performance among accented speakers. Therefore, MLLR, an efficient model adaptation technique, is also presented both alone and in combination with PDA. It is shown that when PDA, MLLR and PDA+MLLR are used, error rate reductions of 13.9%, 24.1% and 28.4% respectively are achieved."
            },
            "slug": "Accent-modeling-based-on-pronunciation-dictionary-Huang-Chang",
            "title": {
                "fragments": [],
                "text": "Accent modeling based on pronunciation dictionary adaptation for large vocabulary Mandarin speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "MLLR, an efficient model adaptation technique, is presented both alone and in combination with PDA and it is shown that when PDA, MLLR and PDA+M LLR are used, error rate reductions of 13.9%, 24.1% and 28.4% respectively are achieved."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58472288,
            "fieldsOfStudy": [
                "Physics",
                "Linguistics",
                "Computer Science"
            ],
            "id": "f1b35c0952f6a308a79a5e0686514cc599dc6803",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The best ebooks about Prosody And Speech Recognition that you can get for free here by download this Prosody And Speech Recognition and save to your desktop. This ebooks is under topic such as prosody dependent speech recognition on radio news book reviews: prosody and speech recognition aclweb prosody modeling for automatic speech recognition and prosodic and accentual information for automatic speech modeling the prosody of hidden events for improved word prosody modeling for automatic speech understanding: an prosody in speech recognition ida which words are hard to recognize? prosodic, lexical, and prosody recognition in male infant-directed speech prosody-enriched lattices for improved syllable recognition using prosody for the improvement of automatic speech prosody as a conditioning variable in speech recognition prosody dependent speech recognition with explicit using prosody to improve automatic speech recognition prosody for mandarin speech recognition: a comparative use of prosodic features for speech recognition a prosody-only decision-tree model for disfluency detection recognition of prosodic factors and detection of landmarks towards using prosody in speech recognition/understanding prosodic parsing for swedish speech recognition prosody dependent speech recognition with explicit direct modeling of prosody: an overview of applications in recognition and understanding of prosody speech recognition university of maryland modeling prosodic dynamics for speaker recognition cnbc automatic detection of prosody phrase boundaries for text predicting automatic speech recognition performance using two methods for assessing oral reading prosody prosody unsupervised adaptation sail asa speech prosody pal aging and speech prosody illinois speech and language a study on prosody analysis ijcer prosody modeling in concept-to-speech generation the contributions of prosody and semantic context in how prosody improves word recognition modeling and recognition of phonetic and prosodic factors using prosody to improve mandarin automatic speech recognition implications of prosody modeling for prosody recognition the limits of speech recognition university of maryland prosody and focus in speech to infants and adults the prosody-voice screening profile (pvsp): psychometric applications 5: speech recognition theme 1 speech importance of prosodic features in language identification a factored language model for prosody dependent speech modeling and recognition of phonetic and prosodic factors improvement of speech summarization using prosodic information"
            },
            "slug": "Prosody-and-speech-recognition-Waibel",
            "title": {
                "fragments": [],
                "text": "Prosody and speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This ebooks is under topic such as prosody dependent speech recognition on radio news book reviews: prosody and speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145601251"
                        ],
                        "name": "Alan Bell",
                        "slug": "Alan-Bell",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685731"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791714"
                        ],
                        "name": "C. Girand",
                        "slug": "C.-Girand",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Girand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Girand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31799507"
                        ],
                        "name": "William D. Raymond",
                        "slug": "William-D.-Raymond",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Raymond",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William D. Raymond"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11233542,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3f0944cb20407f8636ae585ac581cca0c44135ff",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The causes of pronunciation reduction in 8458 occurrences of ten frequent English function words in a four-hour sample from conversations from the Switchboard corpus were examined. Using ordinary linear and logistic regression models, we examined the length of the words, the form of their vowel (basic, full, or reduced), and final obstruent deletion. For all of these we found strong, independent effects of speaking rate, predictability, the form of the following word, and planning problem disfluencies. The results bear on issues in speech recognition, models of speech production, and conversational analysis."
            },
            "slug": "Reduction-of-English-function-words-in-switchboard-Jurafsky-Bell",
            "title": {
                "fragments": [],
                "text": "Reduction of English function words in switchboard"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The causes of pronunciation reduction in 8458 occurrences of ten frequent English function words in a four-hour sample from conversations from the Switchboard corpus were examined, finding strong, independent effects of speaking rate, predictability, the form of the following word, and planning problem disfluencies."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085811"
                        ],
                        "name": "G. Oden",
                        "slug": "G.-Oden",
                        "structuredName": {
                            "firstName": "Gregg",
                            "lastName": "Oden",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Oden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2618025"
                        ],
                        "name": "D. Massaro",
                        "slug": "D.-Massaro",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Massaro",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Massaro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12224868,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "235eb67e3ef3cf221319a73e78d9195cfc7be214",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "A model for the identification of speech sounds is proposed that assumes that (a) the acoustic cues are perceived independently, (b) feature evaluation provides information about the degree to which each quality is present in the speech sound, (c) each speech sound is denned by a propositional prototype in longterm memory that determines how the featural information is integrated, and (d) the speech sound is identified on the basis of the relative degree to which it matches the various alternative prototypes. The model was supported by the results of an experiment in which subjects identified stop-consonant-vowel syllables that were factorially generated by independently varying acoustic cues for voicing and for place of articulation. This experiment also replicated previous findings of changes in the identification boundary of one acoustic dimension as a function of the level of another dimension. These results have previously been interpreted as evidence for the interaction of the perceptions of the acoustic features themselves. In contrast, the present model provides a good description of the data, including these boundary changes, while still maintaining complete noninteraction at the feature evaluation stage of processing. Although considerable progress has been made in the field of speech perception in recent years, there is still much that is unknown about the details of how speech sounds are perceived and discriminated. In particular, while there has been considerable success in isolating the dimensions of acoustic information that are important in perceiving and identifying speech sounds, very little is known about how the information from the various acoustic dimensions is put together in order to actually accomplish identification. The present article proposes and tests a model of these fundamental integration processes that take place during speech perception. Much of the study of features in speech has focused on the stop consonants of English. The stop consonants are a set of speech sounds"
            },
            "slug": "Integration-of-featural-information-in-speech-Oden-Massaro",
            "title": {
                "fragments": [],
                "text": "Integration of featural information in speech perception."
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A model for the identification of speech sounds is proposed that assumes that the acoustic cues are perceived independently, and provides a good description of the data, including these boundary changes, while still maintaining complete noninteraction at the feature evaluation stage of processing."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2252965"
                        ],
                        "name": "R. Reichman",
                        "slug": "R.-Reichman",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Reichman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reichman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53931475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07285ebe31c2a1e00e96d268d31017ca92e3fa32",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Getting-computers-to-talk-like-you-and-me-Reichman",
            "title": {
                "fragments": [],
                "text": "Getting computers to talk like you and me"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144339506"
                        ],
                        "name": "Mari Ostendorf",
                        "slug": "Mari-Ostendorf",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Ostendorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mari Ostendorf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121786"
                        ],
                        "name": "V. Digalakis",
                        "slug": "V.-Digalakis",
                        "structuredName": {
                            "firstName": "Vassilios",
                            "lastName": "Digalakis",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Digalakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353221"
                        ],
                        "name": "O. Kimball",
                        "slug": "O.-Kimball",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Kimball",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kimball"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15742861,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8658d645b716d59c5edc80e33e1936e33574bc26",
            "isKey": false,
            "numCitedBy": 702,
            "numCiting": 147,
            "paperAbstract": {
                "fragments": [],
                "text": "Many alternative models have been proposed to address some of the shortcomings of the hidden Markov model (HMM), which is currently the most popular approach to speech recognition. In particular, a variety of models that could be broadly classified as segment models have been described for representing a variable-length sequence of observation vectors in speech recognition applications. Since there are many aspects in common between these approaches, including the general recognition and training problems, it is useful to consider them in a unified framework. The paper describes a general stochastic model that encompasses most of the models proposed in the literature, pointing out similarities of the models in terms of correlation and parameter tying assumptions, and drawing analogies between segment models and HMMs. In addition, we summarize experimental results assessing different modeling assumptions and point out remaining open questions."
            },
            "slug": "From-HMM's-to-segment-models:-a-unified-view-of-for-Ostendorf-Digalakis",
            "title": {
                "fragments": [],
                "text": "From HMM's to segment models: a unified view of stochastic modeling for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A general stochastic model is described that encompasses most of the models proposed in the literature for speech recognition, pointing out similarities in terms of correlation and parameter tying assumptions, and drawing analogies between segment models and HMMs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866057"
                        ],
                        "name": "V. Warnke",
                        "slug": "V.-Warnke",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Warnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Warnke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290244"
                        ],
                        "name": "H. Niemann",
                        "slug": "H.-Niemann",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Niemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Niemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739326"
                        ],
                        "name": "E. N\u00f6th",
                        "slug": "E.-N\u00f6th",
                        "structuredName": {
                            "firstName": "Elmar",
                            "lastName": "N\u00f6th",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. N\u00f6th"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14955633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bba48db6de8fdacc5db6203c06e2230dc30f962d",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an integrated approach for the segmentation and classi cation of dialog acts (DA) in the Verbmobil project. In Verbmobil it is often su cient to recognize the sequence of DAs occurring during a dialog between the two partners. In our previous work [5] we segmented and classi ed a dialog in two steps: rst we calculated hypotheses for the segment boundaries and decided for a boundary if the probabilities exceeded a prede ned threshold level. Second we classi ed the segments into DAs using semantic classi cation trees or stochastic language models. In our new approach we integrate the segmentation and classi cation in the A {algorithm to search for the optimal segmentation and classi cation of DAs on the basis of word hypotheses graphs (WHGs). The hypotheses for the segment boundaries are calculated with the help of a stochastic language model operating on the word chain and a multi-layer perceptron (MLP) classifying prosodic features. The DA classi cation is done using a category based language model for each DA. For our experiments we used data from the Verbmobil-corpus."
            },
            "slug": "Integrated-dialog-act-segmentation-and-using-and-Warnke-Kompe",
            "title": {
                "fragments": [],
                "text": "Integrated dialog act segmentation and classification using prosodic features and language models"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An integrated approach for the segmentation and classi cation of dialog acts (DA) in the Verbmobil project with the help of a stochastic language model operating on the word chain and a multi-layer perceptron (MLP) classifying prosodic features."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918411"
                        ],
                        "name": "G. Tajchman",
                        "slug": "G.-Tajchman",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Tajchman",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tajchman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685731"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44584782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7517aca65444cc67e5405d258377c8e303295777",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a completely automatic algorithm that builds multiple pronunciation word models by expanding baseform pronunciations with a set of candidate phonological rules. We show how to train the probabilities of these phonological rules, and how to use these probabilities to assign pronunciation probabilities to words not seen in the training corpus. The algorithm we propose is an instance of the class of techniques we call Exploratory Computational Phonology."
            },
            "slug": "Building-multiple-pronunciation-models-for-novel-Tajchman-Fosler-Lussier",
            "title": {
                "fragments": [],
                "text": "Building multiple pronunciation models for novel words using exploratory computational phonology"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper describes a completely automatic algorithm that builds multiple pronunciation word models by expanding baseform pronunciations with a set of candidate phonological rules and shows how to train the probabilities of these phonologicalrules."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758841"
                        ],
                        "name": "K. Ries",
                        "slug": "K.-Ries",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Ries",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ries"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70422141"
                        ],
                        "name": "Elizabeth Shriberg",
                        "slug": "Elizabeth-Shriberg",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Shriberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Shriberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057063782"
                        ],
                        "name": "R. Bates",
                        "slug": "R.-Bates",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bates",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122297135"
                        ],
                        "name": "P. Taylor",
                        "slug": "P.-Taylor",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Taylor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46776641"
                        ],
                        "name": "Rachel Martin",
                        "slug": "Rachel-Martin",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rachel Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403242564"
                        ],
                        "name": "C. V. Ess-Dykema",
                        "slug": "C.-V.-Ess-Dykema",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Ess-Dykema",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. V. Ess-Dykema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215825908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22d45dadde6b5837eff11dc031045754bc5901c3",
            "isKey": false,
            "numCitedBy": 1012,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speech-act-like units such as STATEMENT, Question, BACKCHANNEL, Agreement, Disagreement, and Apology. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy. Models are trained and evaluated using a large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech. We achieved good dialogue act labeling accuracy (65% based on errorful, automatically recognized words and prosody, and 71% based on word transcripts, compared to a chance baseline accuracy of 35% and human accuracy of 84%) and a small reduction in word recognition error."
            },
            "slug": "Dialogue-act-modeling-for-automatic-tagging-and-of-Stolcke-Ries",
            "title": {
                "fragments": [],
                "text": "Dialogue act modeling for automatic tagging and recognition of conversational speech"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A probabilistic integration of speech recognition with dialogue modeling is developed, to improve both speech recognition and dialogue act classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121786"
                        ],
                        "name": "V. Digalakis",
                        "slug": "V.-Digalakis",
                        "structuredName": {
                            "firstName": "Vassilios",
                            "lastName": "Digalakis",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Digalakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61765200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93184bec4d315c55cf8ef911653f2d47bb9081d2",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation addresses the problem of modeling the joint time-spectral structure of speech for recognition. Four areas are covered in this work: segment modeling, estimation, recognition search algorithms, and extension to a more general class of models. A unified view of the acoustic models that are currently used in speech recognition is presented; the research is then focused on segment-based models that provide a better framework for modeling the intrasegmental statistical dependencies than the conventional hidden Markov models (HMMs). The validity of a linearity assumption for modeling the intrasegmental statistical dependencies is first checked, and it is shown that the basic assumption of conditionally independent observations given the underlying state sequence that is inherent to HMMs is inaccurate. Based on these results, linear models are chosen for the distribution of the observations within a segment of speech. Motivated by the original work of the stochastic segment model, a dynamical system segment model is proposed for continuous speech recognition. Training of this model is equivalent to the maximum likelihood identification of a stochastic linear system, and a simple alternative to the traditional approach is developed. This procedure is based on the Expectation-Maximization algorithm and is analogous to the Baum-Welch algorithm for HMMs, since the dynamical system segment model can be thought of as a continuous state HMM. Recognition involves computing the probability of the innovations given by Kalman filtering. The large computational complexity of segment-based models is dealt with by the introduction of fast recognition search algorithms as alternatives to the typical Dynamic Programming search. A Split-and-Merge segmentation algorithm is developed that achieves a significant computation reduction with no loss in recognition performance. Finally, the models are extended to the family of embedded segment models that are better suited for capturing the hierarchical structure of speech and modeling intersegmental statistical dependencies. Experimental results are based on speaker-independent phoneme recognition using the TIMIT database, and represent the best context-independent phoneme recognition performance reported on this task. In addition, the proposed dynamical system segment model is the first that removes the output independence assumption."
            },
            "slug": "Segment-based-stochastic-models-of-spectral-for-Digalakis",
            "title": {
                "fragments": [],
                "text": "Segment-based stochastic models of spectral dynamics for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This dissertation addresses the problem of modeling the joint time-spectral structure of speech for recognition by focusing on segment-based models that provide a better framework for modeling the intrasegmental statistical dependencies than the conventional hidden Markov models (HMMs)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70422141"
                        ],
                        "name": "Elizabeth Shriberg",
                        "slug": "Elizabeth-Shriberg",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Shriberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Shriberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144793576"
                        ],
                        "name": "Elizabeth Wade",
                        "slug": "Elizabeth-Wade",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Wade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Wade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7238837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8dca295d3b52a1802baf386d72f5a2dae5f1668",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We have analyzed three factors affecting user satisfaction and system performance using an SLS implemented in the ATIS domain. We have found that: (1) trade-offs between speed and accuracy have different implications for user satisfaction; (2) recognition performance improves over time, at least in part because of a reduction in sentence perplexity; and (3) hyperarticulation increases recognition errors, and while instructions can reduce this behavior, they do not result in improved recognition performance. We conclude that while users may adapt to some aspects of an SLS, certain types of user behavior may require technological solutions."
            },
            "slug": "Human-Machine-Problem-Solving-Using-Spoken-Language-Shriberg-Wade",
            "title": {
                "fragments": [],
                "text": "Human-Machine Problem Solving Using Spoken Language Systems (SLS): Factors Affecting Performance and User Satisfaction"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "While users may adapt to some aspects of an SLS, certain types of user behavior may require technological solutions and hyperarticulation increases recognition errors, and while instructions can reduce this behavior, they do not result in improved recognition performance."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143745589"
                        ],
                        "name": "M. Mast",
                        "slug": "M.-Mast",
                        "structuredName": {
                            "firstName": "Marion",
                            "lastName": "Mast",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mast"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797644"
                        ],
                        "name": "S. Harbeck",
                        "slug": "S.-Harbeck",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Harbeck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harbeck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37909376"
                        ],
                        "name": "A. Kiessling",
                        "slug": "A.-Kiessling",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Kiessling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kiessling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290244"
                        ],
                        "name": "H. Niemann",
                        "slug": "H.-Niemann",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Niemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Niemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739326"
                        ],
                        "name": "E. N\u00f6th",
                        "slug": "E.-N\u00f6th",
                        "structuredName": {
                            "firstName": "Elmar",
                            "lastName": "N\u00f6th",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. N\u00f6th"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403379723"
                        ],
                        "name": "E. G. Schukat-Talamazzini",
                        "slug": "E.-G.-Schukat-Talamazzini",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Schukat-Talamazzini",
                            "middleNames": [
                                "G\u00fcnter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. G. Schukat-Talamazzini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866057"
                        ],
                        "name": "V. Warnke",
                        "slug": "V.-Warnke",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Warnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Warnke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13956702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92d5079b696d8ec2c35761c4d22256bc298967f6",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents automatic methods for the segmentation and classification of dialog acts (DA). In VERBMOBIL it is often sufficient to recognize the sequence of DAs occurring during a dialog between the two partners. Since a turn can consist of one or more successive DAs we conduct the classification of DAs in a two step procedure. First each turn has to be segmented into units which correspond to a DA and second the DA categories have to be identified. For the segmentation we use polygrams and multi-layer perceptrons, using prosodic features. The classification of DAs is done with semantic classification trees and polygrams."
            },
            "slug": "Dialog-act-classification-with-the-help-of-prosody-Mast-Kompe",
            "title": {
                "fragments": [],
                "text": "Dialog act classification with the help of prosody"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper presents automatic methods for the segmentation and classification of dialog acts (DA) in VERBMOBIL and uses polygrams and multi-layer perceptrons, using prosodic features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110271578"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189985"
                        ],
                        "name": "R. Bobrow",
                        "slug": "R.-Bobrow",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319612"
                        ],
                        "name": "R. Ingria",
                        "slug": "R.-Ingria",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Ingria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18903447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70d2b25dfe4fbadfa3c816e01666f811dae9a4d1",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate hidden understanding models, a statistical learning approach to natural language understanding. Given a string of words, hidden understanding models determine the most likely meaning for the string. We discuss 1) the problem of representing meaning in this framework, 2) the structure of the statistical model, 3) the process of training the model, and 4) the process of understanding using the model. Finally, we give experimental results, including results on an ARPA evaluation."
            },
            "slug": "Hidden-Understanding-Models-of-Natural-Language-Miller-Bobrow",
            "title": {
                "fragments": [],
                "text": "Hidden Understanding Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This work describes and evaluates hidden understanding models, a statistical learning approach to natural language understanding that determines the most likely meaning for the string of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799096"
                        ],
                        "name": "A. Gorin",
                        "slug": "A.-Gorin",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gorin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gorin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719162"
                        ],
                        "name": "G. Riccardi",
                        "slug": "G.-Riccardi",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Riccardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Riccardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49095270"
                        ],
                        "name": "Jeremy H. Wright",
                        "slug": "Jeremy-H.-Wright",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wright",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy H. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "(University of Colorado, Boulder)\nUpper Saddle River, NJ: Prentice Hall (Prentice Hall series in artificial intelligence, edited by Stuart Russell and Peter Norvig), 2000, xxvi+934 pp; hardbound, ISBN 0-13-095069-6, $64.00\nReviewed by Virginia Teller Hunter College and the Graduate Center, The City\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 132
                            }
                        ],
                        "text": "(University of Colorado, Boulder)\nUpper Saddle River, NJ: Prentice Hall (Prentice Hall series in artificial intelligence, edited by Stuart Russell and Peter Norvig), 2000, xxvi+934 pp; hardbound, ISBN 0-13-095069-6, $64.00\nReviewed by Virginia Teller Hunter College and the Graduate Center, The City University of New York"
                    },
                    "intents": []
                }
            ],
            "corpusId": 3121738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0368d671d9fbdee082491ed1cd977d976416bb47",
            "isKey": true,
            "numCitedBy": 636,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We are interested in providing automated services via natural spoken dialog systems. There are many issues that arise when such systems are targeted for large populations of non-expert users. In this paper, we describe an experimental vehicle to explore these issues, that of automatically routing calls based on a user's fluently spoken response to open-ended prompts such as 'How may I help you?' A spoken dialog system for call-routing has been constructed, with subsequent processing for information retrieval and form-filling. To enable experimental evaluations, a database has been generated of 10000 fluently spoken transactions between customers and human agents. We report on preliminary experimental results for that database."
            },
            "slug": "How-may-I-help-you-Gorin-Riccardi",
            "title": {
                "fragments": [],
                "text": "How may I help you?"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper focuses on the task of automatically routing telephone calls based on a user's fluently spoken response to the open-ended prompt of \u201c How may I help you? \u201d."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IVTTA '96. Workshop on Interactive Voice Technology for Telecommunications Applications"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171861"
                        ],
                        "name": "Thomas Hain",
                        "slug": "Thomas-Hain",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713807"
                        ],
                        "name": "Gunnar Evermann",
                        "slug": "Gunnar-Evermann",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Evermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar Evermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12476212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d352d32443677f1068a0ca783402a3b437fc545b",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Discusses new features integrated into the Cambridge University HTK (CU-HTK) system for the transcription of conversational telephone speech. Major improvements have been achieved by the use of maximum mutual information estimation in training as well as maximum likelihood estimation; the use of a full variance transform for adaptation; the inclusion of unigram pronunciation probabilities; and word-level posterior probability estimation using confusion networks for use in minimum word error rate decoding, confidence score estimation and system combination. Improvements are demonstrated via performance on the NIST March 2000 evaluation of English conversational telephone speech transcription (Hub5E). In this evaluation the CU-HTK system gave an overall word error rate of 25.4%, which was the best performance by a statistically significant margin."
            },
            "slug": "New-features-in-the-CU-HTK-system-for-transcription-Hain-Woodland",
            "title": {
                "fragments": [],
                "text": "New features in the CU-HTK system for transcription of conversational telephone speech"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Discusses new features integrated into the Cambridge University HTK (CU-HTK) system for the transcription of conversational telephone speech, which gave an overall word error rate of 25.4%, which was the best performance by a statistically significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692242"
                        ],
                        "name": "B. Grosz",
                        "slug": "B.-Grosz",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Grosz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Grosz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049352"
                        ],
                        "name": "Julia Hirschberg",
                        "slug": "Julia-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Hirschberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6322021,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "43c4b766f7fdae2ae867651d40716387d34168e5",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "and speech, following Grosz & Sidner 1986; average inter-labeler agreement for structural elements varied from 74.3%-95.1%, depending upon feature. These elements of global structure, together with elements of local structure such as parentheticals and attributive tags, were correlated with variation in intonational and acoustic features such as pitch range, contour, timing, and amplitude. We found statistically signiicant associations between aspects of pitch range, amplitude, and timing with features of global and local structure both for labelings from text alone and for labelings from speech. We further found that global and local structures can be reliably identiied from acoustic and prosodic features with (cross-validated) success rates of 86-97%."
            },
            "slug": "Some-intonational-characteristics-of-discourse-Grosz-Hirschberg",
            "title": {
                "fragments": [],
                "text": "Some intonational characteristics of discourse structure"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is found that global and local structures can be reliably identiied from acoustic and prosodic features with (cross-validated) success rates of 86-97%."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145860194"
                        ],
                        "name": "J. Allwood",
                        "slug": "J.-Allwood",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Allwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Allwood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3074458"
                        ],
                        "name": "E. Ahls\u00e9n",
                        "slug": "E.-Ahls\u00e9n",
                        "structuredName": {
                            "firstName": "Elisabeth",
                            "lastName": "Ahls\u00e9n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ahls\u00e9n"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 981694,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0e64f559626c691dd3d6a597acaa2e8b4bf599d0",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is an exploration in the semantics and pragmatics of linguistic feedback, i.e., linguistic mechanisms which enable the participants in spoken interaction to exchange information about basic communicative functions, such as contact, perception, understanding, and attitudinal reactions to the communicated content. Special attention is given to the type of reaction conveyed by feedback utterances, the communicative status of the information conveyed (i. e., the level of awareness and intentionality of the communicating sender), and the context sensitivity of feedback expressions. With regard to context sensitivity, which is one of the most characteristic features of feedback expressions, the discussion focuses on the way in which the type of speech act (mood), the factual polarity and the information status of the preceding utterance influence the interpretation of feedback utterances. The different content dimensions are exemplified by data from recorded dialogues and by data given through linguistic intuition. Finally, two different ways of formalizing the analysis are examined, one using attribute-value matrices and one based on the theory of situation semantics."
            },
            "slug": "On-the-Semantics-and-Pragmatics-of-Linguistic-Allwood-Nivre",
            "title": {
                "fragments": [],
                "text": "On the Semantics and Pragmatics of Linguistic Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper is an exploration in the semantics and pragmatics of linguistic feedback, i.e., linguistic mechanisms which enable the participants in spoken interaction to exchange information about basic communicative functions, such as contact, perception, understanding, and attitudinal reactions to the communicated content."
            },
            "venue": {
                "fragments": [],
                "text": "J. Semant."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47352233"
                        ],
                        "name": "D. Howes",
                        "slug": "D.-Howes",
                        "structuredName": {
                            "firstName": "Davis",
                            "lastName": "Howes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Howes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122333459,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "38750db8dd59ade3db8a077a35182cf262f732d1",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The threshold of intelligibility for a word in a wide\u2010spectrum noise is shown to be a decreasing function of the frequency with which the word occurs in general linguistic usage (word frequency). The drop in threshold is about 4.5 db per logarithmic unit of word frequency. This rate is independent of the length of the word, although the thresholds for words of given frequency of occurrence are lower for long words.The effect of restricting the listener's alternatives in an intelligibility test to a specified number of words is calculated from this relationship. These calculations come within 1 db of published experimental data. Theoretical functions relating intelligibility threshold to word length are also calculated from the word\u2010frequency effect, on the assumption that listeners can discriminate the length of a word at levels too low for it to be identified. These functions are in general agreement with the experimental results.Implications for intelligibility testing procedures are discussed."
            },
            "slug": "On-the-Relation-between-the-Intelligibility-and-of-Howes",
            "title": {
                "fragments": [],
                "text": "On the Relation between the Intelligibility and Frequency of Occurrence of English Words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753394"
                        ],
                        "name": "D. Bobrow",
                        "slug": "D.-Bobrow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803660"
                        ],
                        "name": "R. Kaplan",
                        "slug": "R.-Kaplan",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaplan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728478"
                        ],
                        "name": "D. Norman",
                        "slug": "D.-Norman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Norman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Norman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073432002"
                        ],
                        "name": "Henry S. Thompson",
                        "slug": "Henry-S.-Thompson",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Thompson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry S. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699245"
                        ],
                        "name": "T. Winograd",
                        "slug": "T.-Winograd",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35280186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2505e3f0e19d50bdd418ca9becf8cbb08f61dc1",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "GUS,-A-Frame-Driven-Dialog-System-Bobrow-Kaplan",
            "title": {
                "fragments": [],
                "text": "GUS, A Frame-Driven Dialog System"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2349671"
                        ],
                        "name": "Cecilia E. Ford",
                        "slug": "Cecilia-E.-Ford",
                        "structuredName": {
                            "firstName": "Cecilia",
                            "lastName": "Ford",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cecilia E. Ford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35122449"
                        ],
                        "name": "Barbara A. Fox",
                        "slug": "Barbara-A.-Fox",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Fox",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara A. Fox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20082155"
                        ],
                        "name": "S. Thompson",
                        "slug": "S.-Thompson",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thompson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 60596491,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "cb13fbd9f054e48fb16010b1fa274dda3dd7c818",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This study began with a simple question that has been on our minds, indMdually and collectively, for some time: What are the basic units of talk-in-conversation? Units in conversation must be understood as usable for the construction of joint activities, not merely as packages of information to be parsed. Features of turn construction are adapted to such functions as displaying responsiveness to other turns and making interpretable contributions to an ongoing interactional sequence. Furthermore, timing of speaker onset is crucial to the making of meaning in conversation, whether that onset is produced in overlap, after some gap, or precisely at the point where a current speaker stops. It has been manifestly clear for some time that, for the description of the basic units of talk-in-interaction, neither a strictly syntactic/semantic nor a strictly prosodic approach to conversational units will suffice by itself (Schegloff 1996); \"sentences\" and \"clauses\" are only part of the picture, but \"tone units\" (Crystal 7969; Cruttenden 1986) or \"intonation units\" (Chafe 1987, 1988, 1992, 7993, 1994; Du Bois et al. 1993) are also only part of the picture. The basic conversational unit must be an amalgam of at least these two types of units, but its niche in a developing interactional context must also play a major part in its construction. An obvious place to turn for discussion of this question is to Conversation Analysis (CA), since this framework has concerned itself intensively with the organization of turn-taking. In their celebrated and highly influential paper outlining the practices under$ing conversational turn-taking, Sacks et al. (1974) propose a model in which turns at talk are analyzed as being made up of \"turn-constructional"
            },
            "slug": "Practices-in-the-Construction-of-Turns:-The-\"TCU\"-Ford-Fox",
            "title": {
                "fragments": [],
                "text": "Practices in the Construction of Turns: The \"TCU\" Revisited"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32668171"
                        ],
                        "name": "P. Ramesh",
                        "slug": "P.-Ramesh",
                        "structuredName": {
                            "firstName": "Padma",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ramesh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10322003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31b9451e9e0bf28de64d445d4d38d356c3a4fa80",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An important aspect of distinctive feature based approaches to automatic speech recognition is the formulation of a framework for robust detection of these features. We discuss the application of the support vector machines (SVM) that arise when the structural risk minimization principle is applied to such feature detection problems. In particular, we describe the problem of detecting stop consonants in continuous speech and discuss an SVM framework for detecting these sounds. In this paper we use both linear and nonlinear SVMs for stop detection and present experimental results to show that they perform better than a cepstral features based hidden Markov model (HMM) system, on the same task."
            },
            "slug": "Distinctive-feature-detection-using-support-vector-Niyogi-Burges",
            "title": {
                "fragments": [],
                "text": "Distinctive feature detection using support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes the problem of detecting stop consonants in continuous speech and discusses an SVM framework for detecting these sounds and presents experimental results to show that they perform better than a cepstral features based hidden Markov model (HMM) system, on the same task."
            },
            "venue": {
                "fragments": [],
                "text": "1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801681"
                        ],
                        "name": "L. Tomokiyo",
                        "slug": "L.-Tomokiyo",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Tomokiyo",
                            "middleNames": [
                                "Mayfield"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tomokiyo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17598433,
            "fieldsOfStudy": [
                "Physics",
                "Linguistics"
            ],
            "id": "1420bd0f662a25edf792a61211da4b13c76a92c3",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "LVCSR performance is consistently poor on low-pro ciency non-native speech. While gains from speaker adaptation can often bring recognizer performance on highpro ciency non-native speakers close to that seen for native speakers [12], recognition for lower-pro ciency speakers remains low even after individual speaker adaptation [2]. The challenge for accent adaptation is to maximize recognizer performance without collecting large amounts of acoustic data for each native-language/targetlanguage pair. In this paper, we focus on adaptation for lower-pro ciency speakers, exploring how acoustic data from up to 15 adaptation speakers can be put to its most e ective use."
            },
            "slug": "Adaptation-Methods-For-Non-Native-Speech-Tomokiyo-Waibel",
            "title": {
                "fragments": [],
                "text": "Adaptation Methods For Non-Native Speech"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper focuses on adaptation for lower-pro ciency speakers, exploring how acoustic data from up to 15 adaptation speakers can be put to its most e ective use."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31408841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a175b36ec7f2f08cb3dfac30ce141e144ec9e9",
            "isKey": false,
            "numCitedBy": 991,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical methods useful in automatic recognition of continuous speech are described. They concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding. Experimental results are presented that indicate the power of the methods."
            },
            "slug": "Continuous-speech-recognition-by-statistical-Jelinek",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by statistical methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Experimental results are presented that indicate the power of the methods and concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352703"
                        ],
                        "name": "David Goodine",
                        "slug": "David-Goodine",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Goodine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Goodine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796273"
                        ],
                        "name": "H. Leung",
                        "slug": "H.-Leung",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Leung",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49551529"
                        ],
                        "name": "M. S. Phillips",
                        "slug": "M.-S.-Phillips",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Phillips",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686491"
                        ],
                        "name": "J. Polifroni",
                        "slug": "J.-Polifroni",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Polifroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Polifroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745131"
                        ],
                        "name": "S. Seneff",
                        "slug": "S.-Seneff",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Seneff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seneff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3527591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "466ef3c3dfd2e605a5d61b45da972f2ee18c15ea",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "VOYAGER is a speech understanding system currently under development at MIT. It provides information and navigational assistance for a geographical area within the city of Cambridge, Massachusetts. Recently, we have completed the initial implementation of the system. This paper describes the preliminary evaluation of VOYAGER, using a spontaneous speech database that was also recently collected."
            },
            "slug": "Preliminary-Evaluation-of-the-VOYAGER-Spoken-System-Zue-Glass",
            "title": {
                "fragments": [],
                "text": "Preliminary Evaluation of the VOYAGER Spoken Language System"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The preliminary evaluation of VOYAGER is described, using a spontaneous speech database that was recently collected, that provides information and navigational assistance for a geographical area within the city of Cambridge, Massachusetts."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35104253"
                        ],
                        "name": "M. Danieli",
                        "slug": "M.-Danieli",
                        "structuredName": {
                            "firstName": "Morena",
                            "lastName": "Danieli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Danieli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512649"
                        ],
                        "name": "Elisabetta Gerbino",
                        "slug": "Elisabetta-Gerbino",
                        "structuredName": {
                            "firstName": "Elisabetta",
                            "lastName": "Gerbino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elisabetta Gerbino"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8738472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a38faf8bfc7ff634a63d27999d16bab21858710f",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a set of metrics for the evaluation of different dialogue management strategies in an implemented real-time spoken language system. The set of metrics we propose tries to offer useful insights in evaluating how particular choices in the dialogue management can affect the overall quality of the man-machine dialogue. The evaluation makes use of established metrics: the transaction success, the contextual appropriateness of system answers, the calculation of normal and correction turns in a dialogue. We also define a new metric, the implicit recovery, which allows to measure the ability of a dialogue manager to deal with errors by different levels of analysis. We report evaluation data from several experiments, and we compare two different approaches to dialogue repair strategies using the set of metrics we argue for."
            },
            "slug": "Metrics-for-Evaluating-Dialogue-Strategies-in-a-Danieli-Gerbino",
            "title": {
                "fragments": [],
                "text": "Metrics for Evaluating Dialogue Strategies in a Spoken Language System"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new metric is defined, the implicit recovery, which allows to measure the ability of a dialogue manager to deal with errors by different levels of analysis and is compared to two different approaches to dialogue repair strategies."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400881722"
                        ],
                        "name": "W. Marslen-Wilson",
                        "slug": "W.-Marslen-Wilson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Marslen-Wilson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Marslen-Wilson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4220775,
            "fieldsOfStudy": [
                "Physics",
                "Psychology"
            ],
            "id": "1a6b2d237b873703b3f0af644f7953e3f2c7116e",
            "isKey": false,
            "numCitedBy": 433,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "SPEECH shadowing is an experimental task in which the subject is required to repeat (shadow) speech as he hears it. When the shadower is presented with a sentence, he will start to repeat it before he has heard all of it. The response latency to each word of a sentence can therefore be measured."
            },
            "slug": "Linguistic-Structure-and-Speech-Shadowing-at-Very-Marslen-Wilson",
            "title": {
                "fragments": [],
                "text": "Linguistic Structure and Speech Shadowing at Very Short Latencies"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper presents an experimental task in which the subject is required to repeat (shadow) speech as he hears it, and the response latency to each word of a sentence is measured."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37909376"
                        ],
                        "name": "A. Kiessling",
                        "slug": "A.-Kiessling",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Kiessling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kiessling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128980"
                        ],
                        "name": "T. Kuhn",
                        "slug": "T.-Kuhn",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143745589"
                        ],
                        "name": "M. Mast",
                        "slug": "M.-Mast",
                        "structuredName": {
                            "firstName": "Marion",
                            "lastName": "Mast",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mast"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290244"
                        ],
                        "name": "H. Niemann",
                        "slug": "H.-Niemann",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Niemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Niemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739326"
                        ],
                        "name": "E. N\u00f6th",
                        "slug": "E.-N\u00f6th",
                        "structuredName": {
                            "firstName": "Elmar",
                            "lastName": "N\u00f6th",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. N\u00f6th"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066490089"
                        ],
                        "name": "K. Ott",
                        "slug": "K.-Ott",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Ott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745089"
                        ],
                        "name": "A. Batliner",
                        "slug": "A.-Batliner",
                        "structuredName": {
                            "firstName": "Anton",
                            "lastName": "Batliner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Batliner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10265697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3394a80e93fd69c251bfe62fa679b35eb5b2652c",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper first experiments with naive persons using the speech understanding and dialog system EVAR are discussed. The domain of EVAR is train table inquiry. We observed that in real human-human dialogs when the officer transmits the information the customer very often interrupts. Many of these interruptions are just repetitions of the time of day given by the officer. The functional role of these interruptions is determined by prosodic cues only. An important result of the experiments with EVAR is that it is hard to follow the system giving the train connection via speech synthesis. In this case it is even more important than in human-human dialogs that the user has the opportunity to interact during the answer phase. Therefore we extended the dialog module to allow the user to repeat the time of day and we added a prosody module guiding the continuation of the dialog."
            },
            "slug": "Prosody-takes-over:-a-prosodically-guided-dialog-Kompe-Kiessling",
            "title": {
                "fragments": [],
                "text": "Prosody takes over: a prosodically guided dialog system"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "First experiments with naive persons using the speech understanding and dialog system EVAR are discussed and the dialog module is extended to allow the user to repeat the time of day and a prosody module guiding the continuation of the dialog."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657837"
                        ],
                        "name": "L. Tyler",
                        "slug": "L.-Tyler",
                        "structuredName": {
                            "firstName": "Lorraine",
                            "lastName": "Tyler",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tyler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11571106,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e3a777d977bce26f259a6128554093b74b1cc782",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjects heard successive fragments of words both in and out of context, and after each fragment they wrote down the word they thought they were hearing. Responses were analyzed for word frequency, length, and compatibility with both contextual constraints and the sensory input. These responses, pooled across subjects, enabled us to evaluate a number of claims concerning the use of top-down and bottom-up information in the process of word recognition. The analyses show that, in the process of recognizing a spoken word, subjects initially produce a large number of responses compatible with the sensory input. This set diminishes in size as more of the word is presented. The rate at which responses drop out of the initial set differs, depending on whether words are heard in isolation or in context. These properties of the elicited responses are compatible with claims made by the cohort model for the integration of top-down and bottom-up information in the process of recognizing a spoken word."
            },
            "slug": "The-structure-of-the-initial-cohort:-Evidence-from-Tyler",
            "title": {
                "fragments": [],
                "text": "The structure of the initial cohort: Evidence from gating"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The analyses show that, in the process of recognizing a spoken word, subjects initially produce a large number of responses compatible with the sensory input, which diminishes in size as more of the word is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049352"
                        ],
                        "name": "Julia Hirschberg",
                        "slug": "Julia-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Hirschberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844268"
                        ],
                        "name": "C. H. Nakatani",
                        "slug": "C.-H.-Nakatani",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Nakatani",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Nakatani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1036150,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "52c8c1285e8a90b0a0b2b5fce047b7fde766b09e",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on corpus-based research into the relationship between intonational variation and discourse structure. We examine the effects of speaking style (read versus spontaneous) and of discourse segmentation method (text-alone versus text-and-speech) on the nature of this relationship. We also compare the acoustic-prosodic features of initial, medial, and final utterances in a discourse segment."
            },
            "slug": "A-Prosodic-Analysis-of-Discourse-Segments-in-Hirschberg-Nakatani",
            "title": {
                "fragments": [],
                "text": "A Prosodic Analysis of Discourse Segments in Direction-Giving Monologues"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The effects of speaking style and of discourse segmentation method (text-alone versus text-and-speech) on the nature of this relationship between intonational variation and discourse structure are examined."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4023408"
                        ],
                        "name": "C. Connine",
                        "slug": "C.-Connine",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Connine",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Connine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144020294"
                        ],
                        "name": "C. Clifton",
                        "slug": "C.-Clifton",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Clifton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clifton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45727566,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d5503253937d7acb76e955a8300cd21fd0fe912a",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Two experiments are reported that demonstrate contextual effects on identification of speech voicing continua. Experiment 1 demonstrated the influence of lexical knowledge on identification of ambiguous tokens from word-nonword and nonword-word continua. Reaction times for word and non-word responses showed a word advantage only for ambiguous stimulus tokens (at the category boundary); no word advantage was found for clear stimuli (at the continua endpoints). Experiment 2 demonstrated an effect of a postperceptual variable, monetary payoff, on nonword-nonword continua. Identification responses were influenced by monetary payoff, but reaction times for bias-consistent and bias-inconsistent responses did not differ at the category boundary. An advantage for bias-consistent responses was evident at the continua endpoints. The contrasting patterns of reaction-time data in the two experiments indicate different underlying mechanisms. We argue that the lexical status effect is attributable to a mechanism in which lexical knowledge directly influences perceptual processes."
            },
            "slug": "Interactive-use-of-lexical-information-in-speech-Connine-Clifton",
            "title": {
                "fragments": [],
                "text": "Interactive use of lexical information in speech perception."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that the lexical status effect is attributable to a mechanism in which lexical knowledge directly influences perceptual processes in which bias-consistent and bias-inconsistent responses did not differ at the category boundary."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47147237"
                        ],
                        "name": "Johanna D. Moore",
                        "slug": "Johanna-D.-Moore",
                        "structuredName": {
                            "firstName": "Johanna",
                            "lastName": "Moore",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johanna D. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10213745"
                        ],
                        "name": "M. Pollack",
                        "slug": "M.-Pollack",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Pollack",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6817372,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "57d78d899b1977c8170a9d2ca98b07ad0e71a832",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Rhetorical Structure Theory (RST) (Mann and Thompson 1987), argues that in most coherent discourse, consecutive discourse elements are related by a small set of rhetorical relations. Moreover, RST suggests that the information conveyed in a discourse over and above what is conveyed in its component clauses can be derived from the rhetorical relation-based structure of the discourse. A large number of natural language generation systems rely on the rhetorical relations defined in RST to impose structure on multi-sentential text (Hovy 1991; Knott 1991; Moore and Paris 1989; Rosner and Stede 1992). In addition, many descriptive studies of discourse have employed RST (Fox 1987; Linden, Cumming, and Martin 1992; Matthiessen and Thompson 1988). However, recent work by Moore and Paris (1992) noted that RST cannot be used as the sole means of controlling discourse structure in an interactive dialogue system, because RST representations provide insufficient information to support the generation of appropriate responses to \"follow-up questions.\" The basic problem is that an RST representation of a discourse does not fully specify the intentional structure (Grosz and Sidner 1986) of that discourse. Intentional structure is crucial for responding effectively to questions that address a previous utterance: without a record of what an utterance was intended to achieve, it is impossible to elaborate or clarify that utterance. 1 Further consideration has led us to conclude that the difficulty observed by Moore and Paris stems from a more fundamental problem with RST analyses. RST presumes that, in general, there will be a single, preferred rhetorical relation holding between consecutive discourse elements. In fact, as has been noted in other work on discourse structure (Grosz and Sidner 1986), discourse elements are related simultaneously on multiple levels. In this paper, we focus on two levels of analysis. The first involves the relation between the information conveyed in consecutive elements of a coherent discourse. Thus, for example, one utterance may describe an event that can be presumed to be the cause of another event described in the subsequent utterance. This causal relation is at what we will call the informational level. The second level of relation results from the fact that discourses are produced to effect changes in the mental state of the discourse participants. In coherent discourse, a speaker is carrying out a consistent plan to achieve the intended changes, and consecutive discourse elements are related to one another by means of the ways in which they participate in that plan. Thus, one utterance may be intended to increase the likelihood that the hearer will come to"
            },
            "slug": "A-Problem-for-RST:-The-Need-for-Multi-Level-Moore-Pollack",
            "title": {
                "fragments": [],
                "text": "A Problem for RST: The Need for Multi-Level Discourse Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2006080"
                        ],
                        "name": "J. D. Gould",
                        "slug": "J.-D.-Gould",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Gould",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143666366"
                        ],
                        "name": "John Conti",
                        "slug": "John-Conti",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Conti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Conti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235018"
                        ],
                        "name": "Todd Hovanyecz",
                        "slug": "Todd-Hovanyecz",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Hovanyecz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Todd Hovanyecz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 394274,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "793c2f9e333f8c264b0810d77d04428e9ccb003f",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is not yet advanced enough to provide people with a reliable listening typewriter with which they could compose documents. The aim of this experiment was to determine if an imperfect listening typewriter would be useful for highly experienced dictators. Participants dictated either in isolated words or in continuous speech, and used a simulated listening typewriter which recognized a limited vocabulary as well as one which recognized an unlimited one. Results suggest that reducing the rate at which people dictate, either through limitations in vocabulary size or through speaking in isolated words, led to reductions in people's performance. For these first-time users, no version of the listening typewriter was better than traditional dictating methods."
            },
            "slug": "Composing-letters-with-a-simulated-listening-Gould-Conti",
            "title": {
                "fragments": [],
                "text": "Composing letters with a simulated listening typewriter"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results suggest that reducing the rate at which people dictate, either through limitations in vocabulary size or through speaking in isolated words, led to reductions in people's performance."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '82"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050344"
                        ],
                        "name": "Lisa Stifelman",
                        "slug": "Lisa-Stifelman",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Stifelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lisa Stifelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931458"
                        ],
                        "name": "B. Arons",
                        "slug": "B.-Arons",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Arons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Arons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729321"
                        ],
                        "name": "C. Schmandt",
                        "slug": "C.-Schmandt",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Schmandt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmandt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2492319"
                        ],
                        "name": "Eric A. Hulteen",
                        "slug": "Eric-A.-Hulteen",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hulteen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric A. Hulteen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1629532,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "1a33971cf4a97e0d9bb0927650946703037e5a14",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "VoiceNotes is an application for a voice-controlled hand-held computer that allows the creation, management, and retrieval of user-authored voice notes\u2014small segments of digitized speech containing thoughts, ideas, reminders, or things to do. Iterative design and user testing helped to refine the initial user interface design. VoiceNotes explores the problem of capturing and retrieving spontaneous ideas, the use of speech as data, and the use of speech input and output in the user interface for a hand-held computer without a visual display. In addition, VoiceNotes serves as a step toward new uses of voice technology and interfaces for future portable devices."
            },
            "slug": "VoiceNotes:-a-speech-interface-for-a-hand-held-Stifelman-Arons",
            "title": {
                "fragments": [],
                "text": "VoiceNotes: a speech interface for a hand-held voice notetaker"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "VoiceNotes explores the problem of capturing and retrieving spontaneous ideas, the use of speech as data, and theUse of speech input and output in the user interface for a hand-held computer without a visual display."
            },
            "venue": {
                "fragments": [],
                "text": "INTERCHI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730911"
                        ],
                        "name": "M. Swerts",
                        "slug": "M.-Swerts",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Swerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049352"
                        ],
                        "name": "Julia Hirschberg",
                        "slug": "Julia-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Hirschberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 193883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56e5fd18a271d1e030c4fdf05114ca2177bdfb92",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This study analyzes user corrections of system errors in the TOOT spoken dialogue system. We find that corrections differ from noncorrections prosodically, in ways consistent with hyperarticulated speech, although many corrections are not hyperarticulated. Yet both are misrecognized more frequently than non-corrections \u2014 though no more likely to be rejected by the system. Corrections more distant from the error they correct tend to exhibit greater prosodic differences, and also to be recognized more poorly. System dialogue strategy affects users\u2019 choice of correction type, suggesting that strategy-specific methods of detecting or coaching users on corrections may be useful. Strategies that produce longer tasks but fewer misrecognitions and subsequent corrections are preferred by users."
            },
            "slug": "Corrections-in-spoken-dialogue-systems-Swerts-Litman",
            "title": {
                "fragments": [],
                "text": "Corrections in spoken dialogue systems"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "It is found that corrections differ from noncorrections prosodically, in ways consistent with hyperarticulated speech, although many corrections are not hyperartICulated, and strategies that produce longer tasks but fewer misrecognitions and subsequent corrections are preferred by users."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61904772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c180f387357d9302a558bcd643209831744c639b",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities."
            },
            "slug": "The-DRAGON-system--An-overview-Baker",
            "title": {
                "fragments": [],
                "text": "The DRAGON system--An overview"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system, which makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692242"
                        ],
                        "name": "B. Grosz",
                        "slug": "B.-Grosz",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Grosz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Grosz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61114426,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "987767d4d3652be8e78ba8e6ac0658b7ab1fd432",
            "isKey": false,
            "numCitedBy": 475,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This report develops a representation of focus of attention thatcircumscribes discourse contexts within a general representation ofknowledge. Focus of attention is essential to any comprehension processbecause what and how a person understands is strongly influenced bywhere his attention is directed at a given moment. To formalize thenotion of focus, the need for and the use of focus mechanisms areconsidered from the standpoint of building a computer system that canparticipate in a natural language dialogue with a ser, Two ranges offocus, global and immediate, are investigated, and representations forincorporating them in a computer system are developed.The global focus in which an utterance is interpreted is determinedby the total discourse and situational setting of the utterance. Itinfluences what is talked about, how different concepts are introduced,and how concepts are referenced. To encode global focuscomputationally, a representation is developed that highlights thoseitems that are relevant at a given place in a dialogue. The underlyingknowledge representation is segmented into subunits, called focusspaces, that contain those items that are in the focus of attention of adialogue participant during a particular part of the dialogue.Mechanisms are required for updating the focus representation,because, as a dialogue progresses, the objects and actions that arerelevant to the conversation, and therefore in the participants' focusof attention, change. Procedures are described for deciding when andhow to shift focus in task-oriented dialogues, i.e., in dialogues inwhich the participants are cooperating in a shared task. Theseprocedures are guided by a representation of the task being performed.The ability to represent focus of attention in a languageunderstanding system results in a new approach to an important problemin discourse comprehension -- the identification of the referents ofdefinite noun phrases."
            },
            "slug": "The-representation-and-use-of-focus-in-dialogue-Grosz",
            "title": {
                "fragments": [],
                "text": "The representation and use of focus in dialogue understanding."
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The ability to represent focus of attention in a languageunderstanding system results in a new approach to an important problemin discourse comprehension -- the identification of the referents ofdefinite noun phrases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94876749"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143811539"
                        ],
                        "name": "S. Austin",
                        "slug": "S.-Austin",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Austin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Austin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122232431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "307142db035938bef49b232e371238d895db4df2",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors introduce a new, more efficient algorithm, the word-dependent N-best algorithm, for finding multiple sentence hypotheses. The proposed algorithm is based on the assumption that the beginning time of a word depends only on the preceding word. The authors compare this algorithm with two other algorithms for finding the N-best hypotheses: the exact sentence-dependent method and a computationally efficient lattice N-best method. Although the word-dependent algorithm is computationally much less expensive than the exact algorithm, it appears to result in the same accuracy. The lattice method, which is still more efficient, has a significantly higher error rate. It is demonstrated that algorithms that use Viterbi scoring have significantly higher error rates than those that use total likelihood scoring.<<ETX>>"
            },
            "slug": "A-comparison-of-several-approximate-algorithms-for-Schwartz-Austin",
            "title": {
                "fragments": [],
                "text": "A comparison of several approximate algorithms for finding multiple (N-best) sentence hypotheses"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The authors introduce a new, more efficient algorithm, the word-dependent N-best algorithm, for finding multiple sentence hypotheses, based on the assumption that the beginning time of a word depends only on the preceding word."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769629"
                        ],
                        "name": "C. Kamm",
                        "slug": "C.-Kamm",
                        "structuredName": {
                            "firstName": "Candace",
                            "lastName": "Kamm",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kamm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8194846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5940c8bfd16728c5f9bb66e807f78f43dc7a38e4",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of methods for performance evaluation is a major open research issue in the area of spoken language dialogue systems. This paper presents the PARADISE methodology for developing predictive models of spoken dialogue performance, and shows how to evaluate the predictive power and generalizability of such models. To illustrate the methodology, we develop a number of models for predicting system usability (as measured by user satisfaction), based on the application of PARADISE to experimental data from three different spoken dialogue systems. We then measure the extent to which the models generalize across different systems, different experimental conditions, and different user populations, by testing models trained on a subset of the corpus against a test set of dialogues. The results show that the models generalize well across the three systems, and are thus a first approximation towards a general performance model of system usability."
            },
            "slug": "Towards-developing-general-models-of-usability-with-Walker-Kamm",
            "title": {
                "fragments": [],
                "text": "Towards developing general models of usability with PARADISE"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A number of models for predicting system usability (as measured by user satisfaction), based on the application of PARADISE to experimental data from three different spoken dialogue systems, are developed and shown to generalize well."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2618025"
                        ],
                        "name": "D. Massaro",
                        "slug": "D.-Massaro",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Massaro",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Massaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944727"
                        ],
                        "name": "M. Cohen",
                        "slug": "M.-Cohen",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Cohen",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12598311,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "316e1054da27f5f9eb07f0a5cbb3d05f626c9b99",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Three experiments were carried out to investigate the evaluation and integration of visual and auditory information in speech perception. In the first two experiments, subjects identified /ba/ or /da/ speech events consisting of high-quality synthetic syllables ranging from /ba/ to /da/ combined with a videotaped /ba/ or /da/ or neutral articulation. Although subjects were specifically instructed to report what they heard, visual articulation made a large contribution to identification. The tests of quantitative models provide evidence for the integration of continuous and independent, as opposed to discrete or nonindependent, sources of information. The reaction times for identification were primarily correlated with the perceived ambiguity of the speech event. In a third experiment, the speech events were identified with an unconstrained set of response alternatives. In addition to /ba/ and /da/ responses, the /bda/ and /tha/ responses were well described by a combination of continuous and independent features. This body of results provides strong evidence for a fuzzy logical model of perceptual recognition."
            },
            "slug": "Evaluation-and-integration-of-visual-and-auditory-Massaro-Cohen",
            "title": {
                "fragments": [],
                "text": "Evaluation and integration of visual and auditory information in speech perception."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A fuzzy logical model of perceptual recognition is provided for the integration of continuous and independent, as opposed to discrete or nonindependent, sources of information in speech perception."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127386"
                        ],
                        "name": "D. Reynolds",
                        "slug": "D.-Reynolds",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Reynolds",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reynolds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786323"
                        ],
                        "name": "R. Rose",
                        "slug": "R.-Rose",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rose",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rose"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7319345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "381a00152b08160b0802c34eb66aa44317911089",
            "isKey": false,
            "numCitedBy": 3155,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces and motivates the use of Gaussian mixture models (GMM) for robust text-independent speaker identification. The individual Gaussian components of a GMM are shown to represent some general speaker-dependent spectral shapes that are effective for modeling speaker identity. The focus of this work is on applications which require high identification rates using short utterance from unconstrained conversational speech and robustness to degradations produced by transmission over a telephone channel. A complete experimental evaluation of the Gaussian mixture speaker model is conducted on a 49 speaker, conversational telephone speech database. The experiments examine algorithmic issues (initialization, variance limiting, model order selection), spectral variability robustness techniques, large population performance, and comparisons to other speaker modeling techniques (uni-modal Gaussian, VQ codebook, tied Gaussian mixture, and radial basis functions). The Gaussian mixture speaker model attains 96.8% identification accuracy using 5 second clean speech utterances and 80.8% accuracy using 15 second telephone speech utterances with a 49 speaker population and is shown to outperform the other speaker modeling techniques on an identical 16 speaker telephone speech task. >"
            },
            "slug": "Robust-text-independent-speaker-identification-Reynolds-Rose",
            "title": {
                "fragments": [],
                "text": "Robust text-independent speaker identification using Gaussian mixture speaker models"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The individual Gaussian components of a GMM are shown to represent some general speaker-dependent spectral shapes that are effective for modeling speaker identity and is shown to outperform the other speaker modeling techniques on an identical 16 speaker telephone speech task."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9567965"
                        ],
                        "name": "Shankar Kumar",
                        "slug": "Shankar-Kumar",
                        "structuredName": {
                            "firstName": "Shankar",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shankar Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716907"
                        ],
                        "name": "W. Byrne",
                        "slug": "W.-Byrne",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Byrne",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Byrne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15472078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "517398bde648e110cc8658dcc43206c3107d65f1",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimum Bayes-Risk (MBR) speech recognizers have been shown to give improvements over the conventional maximum a-posteriori probability (MAP) decoders through N-best list rescoring and search over word lattices. Segmental MBR (SMBR) decoders simplify the implementation of MBR recognizers by segmenting the N-best lists or lattices over which the recognition is performed. We present a lattice cutting procedure that attempts to minimize the total Bayes-Risk of all word strings in the segmented lattice. We provide experimental results on the Switchboard conversational speech corpus showing that this segmentation procedure, in conjunction with SMBR decoding, gives modest but significant improvements over MAP decoders as well as MBR decoders on unsegmented lattices."
            },
            "slug": "Risk-based-lattice-cutting-for-segmental-minimum-Kumar-Byrne",
            "title": {
                "fragments": [],
                "text": "Risk based lattice cutting for segmental minimum Bayes-risk decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a lattice cutting procedure that attempts to minimize the total Bayes-Risk of all word strings in the segmented lattice and provides experimental results on the Switchboard conversational speech corpus showing that this segmentation procedure, in conjunction with SMBR decoding, gives modest but significant improvements over MAP decoders as well as MBR decoder on unsegmented lattices."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17458278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3905c2369edf44a9a5133fbd57ff06ceeceebd0e",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews some popular speaker adaptation schemes that can be applied to continuous density hidden Markov models. These fall into three families based on MAP adaptation; linear transforms of model parameters such as maximum likelihood linear regression; and speaker clustering/speaker space methods such as eigenvoices. The strengths and weaknesses of each adaptation family are discussed along with extensions that have been proposed to improve the basic schemes which result in a number of hybrid approaches. A number of general extensions are discussed which include methods for improved unsupervised adaptation and discriminative adaptation. There is also a brief discussion of speaker normalisation and the relationship to model-based adaptation. The paper includes a brief discussion of other factors that directly interact with speaker adaptation of HMMs is included, such as adaptation to the acoustic environment and speaker-specific pronunciation dictionaries."
            },
            "slug": "Speaker-adaptation-for-continuous-density-HMMs:-a-Woodland",
            "title": {
                "fragments": [],
                "text": "Speaker adaptation for continuous density HMMs: a review"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper reviews some popular speaker adaptation schemes that can be applied to continuous density hidden Markov models; linear transforms of model parameters such as maximum likelihood linear regression; and speaker clustering/speaker space methods such as eigenvoices."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145844737"
                        ],
                        "name": "James F. Allen",
                        "slug": "James-F.-Allen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James F. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735258"
                        ],
                        "name": "C. Raymond Perrault",
                        "slug": "C.-Raymond-Perrault",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Perrault",
                            "middleNames": [
                                "Raymond"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Raymond Perrault"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10693016,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "39cf55b9500a38b5b32f29cc7a9b8457a804f1b9",
            "isKey": false,
            "numCitedBy": 875,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Analyzing-Intention-in-Utterances-Allen-Perrault",
            "title": {
                "fragments": [],
                "text": "Analyzing Intention in Utterances"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145844737"
                        ],
                        "name": "James F. Allen",
                        "slug": "James-F.-Allen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James F. Allen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 9924296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0c648dc61746be6e14edc6bcfc12ee3818886e9",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous plan-based models of dialogue understanding have been unable to account for many types of subdialogues present in naturally occurring conversations. One reason for this is that the models have not clearly differentiated between the varoius ways that an utterance can relate to a plan structure representing a topic. In this paper we present a plan-based theory that allows a wide variety of utterance-plan relationships. We introduce a set of discourse plans, each one corresponding to a particular way that an utterance can relate to a discourse topic, and distinguish such plans from the set of plans that are actually used to model the topics. By incorporating knowledge about discourse into a plan-based framework, we can account for a wide variety of subdialogues while maintaining the computational advantages of the plan-based approach."
            },
            "slug": "A-Plan-Recognition-Model-for-Subdialogues-in-Litman-Allen",
            "title": {
                "fragments": [],
                "text": "A Plan Recognition Model for Subdialogues in Conversations"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces a set of discourse plans, each one corresponding to a particular way that an utterance can relate to a discourse topic, and distinguish such plans from the set of plans that are actually used to model the topics."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15052804,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b578f4faeb00b808e8786d897447f2493b12b4e9",
            "isKey": false,
            "numCitedBy": 2939,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, is presented and examined. This technique uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum: (1) the critical-band spectral resolution, (2) the equal-loudness curve, and (3) the intensity-loudness power law. The auditory spectrum is then approximated by an autoregressive all-pole model. A 5th-order all-pole model is effective in suppressing speaker-dependent details of the auditory spectrum. In comparison with conventional linear predictive (LP) analysis, PLP analysis is more consistent with human hearing. The effective second formant F2' and the 3.5-Bark spectral-peak integration theories of vowel perception are well accounted for. PLP analysis is computationally efficient and yields a low-dimensional representation of speech. These properties are found to be useful in speaker-independent automatic-speech recognition."
            },
            "slug": "Perceptual-linear-predictive-(PLP)-analysis-of-Hermansky",
            "title": {
                "fragments": [],
                "text": "Perceptual linear predictive (PLP) analysis of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, which uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum, and yields a low-dimensional representation of speech."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29224904"
                        ],
                        "name": "H. H. Clark",
                        "slug": "H.-H.-Clark",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Clark",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. H. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71320953"
                        ],
                        "name": "E. Schaefer",
                        "slug": "E.-Schaefer",
                        "structuredName": {
                            "firstName": "Ed",
                            "lastName": "Schaefer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Schaefer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29541163,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "85ca4bcbd1b59d73cf10bc0e482389788cf70e3c",
            "isKey": false,
            "numCitedBy": 1714,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "For people to contribute to discourse, they must do more than utter the right sentence at the right time. The basic requirement is that they odd to their common ground in on orderly way. To do this, we argue, they try to establish for each utterance the mutual belief that the addressees hove understood what the speaker meant well enough for current purposes. This is accomplished by the collective actions of the current contributor and his or her partners, and these result in units of conversation called contributions. We present a model of contributions and show how it accounts for o variety of features of everyday conversations. People take part in conversation in order to plan, debate, discuss, gossip, and carry out other social processes. When they do take part, they could be said to contribute to the discourse. But how do they contribute? At first the answer seems obvious. A discourse is a sequence of utterances produced as the participants proceed turn by turn. All that participants have to do to contribute is utter the right sentence at the right time. They may make errors, but once they have corrected them, they are done. The other participants have merely to listen and understand. This is the view subscribed to in most discourse theories in psychology, linguistics, philosophy; and artificial intelligence. A closer look at actual conversations, however, suggests that they are much more than sequences of utterances produced turn by turn. They are highly coordinated activities in which the current speaker tries to make sure he or she is being attended to, heard, and understood by the other participants, and they in turn try to let the speaker know when he or she has succeeded. Contributing to a discourse, then, appears to require more than just uttering the right words at the right time. It seems to consist of collective acts performed by the participants working together. In this paper we describe a model of contributions as parts of collective acts. We first describe the need for such a model, next present the model"
            },
            "slug": "Contributing-to-Discourse-Clark-Schaefer",
            "title": {
                "fragments": [],
                "text": "Contributing to Discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A model of contributions is described as parts of collective acts performed by the participants working together and it is shown how it accounts for o variety of features of everyday conversations."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390051006"
                        ],
                        "name": "I. Langkilde-Geary",
                        "slug": "I.-Langkilde-Geary",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Langkilde-Geary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Langkilde-Geary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49095270"
                        ],
                        "name": "Jeremy H. Wright",
                        "slug": "Jeremy-H.-Wright",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wright",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy H. Wright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799096"
                        ],
                        "name": "A. Gorin",
                        "slug": "A.-Gorin",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gorin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gorin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17139469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "628176f850f7ba7bb0db10c9e458d80b1cd46766",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Current spoken dialogue systems are deficient in their strategies for preventing, identifying and repairing problems that arise in the conversation. This paper reports results on learning to automatically identify and predict problematic human-computer dialogues in a corpus of 4774 dialogues collected with the How May I Help You spoken dialogue system. Our expectation is that the ability to predict problematic dialogues will allow the system's dialogue manager to modify its behavior to repair problems, and even perhaps, to prevent them. We train a problematic dialogue classifier using automatically-obtainable features that can identify problematic dialogues significantly better (23%) than the baseline. A classifier trained with only automatic features from the first exchange in the dialogue can predict problematic dialogues 7% more accurately than the baseline, and one trained with automatic features from the first two exchanges can perform 14% better than the baseline."
            },
            "slug": "Learning-to-Predict-Problematic-Situations-in-a-How-Walker-Langkilde-Geary",
            "title": {
                "fragments": [],
                "text": "Learning to Predict Problematic Situations in a Spoken Dialogue System: Experiments with How May I Help You?"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Results on learning to automatically identify and predict problematic human-computer dialogues in a corpus of 4774 dialogues collected with the How May I Help You spoken dialogue system are reported."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421939"
                        ],
                        "name": "G. Bouwman",
                        "slug": "G.-Bouwman",
                        "structuredName": {
                            "firstName": "Gies",
                            "lastName": "Bouwman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bouwman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738656914"
                        ],
                        "name": "J. Sturm",
                        "slug": "J.-Sturm",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Sturm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sturm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728633"
                        ],
                        "name": "L. Boves",
                        "slug": "L.-Boves",
                        "structuredName": {
                            "firstName": "Lou",
                            "lastName": "Boves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Boves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14477145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d58a81a663c61e8c90b1465984a249e85a997cdd",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of confidence measures (CMs) in spoken dialog system (SDS) applications to suppress the number of verification turns for 'reliably correctly recognised utterances' can greatly reduce average dialog length which enhances usability and increases user satisfaction. This paper gives a clear review of the method of CM assessment, which was presented by Boves, Herberts and Russel (see Proceedings of the IEEE Third Workshop Interactive Voice Technology for Telecommunications Applications, Granada, Spain, p.89-92, 1996). It proceeds by demonstrating how the Dutch ARISE (Automatic Railways Information Systems in Europe) SDS was equipped with this technology and shows in deep detail how the parameters involved are to be optimised. The evaluation reveals and explains a typical behaviour of this method with train timetable information-alike systems. This results in a set of conclusions that were not foreseen when the method was first developed for a directory information system. The paper ends with an outlook for solutions in new research directions."
            },
            "slug": "Incorporating-confidence-measures-in-the-Dutch-in-Bouwman-Sturm",
            "title": {
                "fragments": [],
                "text": "Incorporating confidence measures in the Dutch train timetable information system developed in the ARISE project"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper gives a clear review of the method of CM assessment, which was presented by Boves, Herberts and Russel, and demonstrates how the Dutch ARISE SDS was equipped with this technology and shows in deep detail how the parameters involved are to be optimised."
            },
            "venue": {
                "fragments": [],
                "text": "1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320076"
                        ],
                        "name": "W. Chou",
                        "slug": "W.-Chou",
                        "structuredName": {
                            "firstName": "Wu",
                            "lastName": "Chou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Chou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57374964,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "6dde2d0391dbffcd5a4c2291d8f11dc8711b8cc4",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors study issues related to string level acoustic modeling in continuous speech recognition. They derive the formulation of minimum string error rate training. A minimum string error rate training algorithm, segmental minimum string error rate training, is described. It takes a further step in modeling the basic speech recognition units by directly applying discriminative analysis to string level acoustic model matching. One of the advantages of this training algorithm lies in its ability to model strings which are competitive with the correct string but are unseen in the training material. The robustness and acoustic resolution of the unit model set can therefore be significantly improved. Various experimental results have shown that significant error rate reduction can be achieved using this approach.<<ETX>>"
            },
            "slug": "Minimum-error-rate-training-based-on-N-best-string-Chou-Lee",
            "title": {
                "fragments": [],
                "text": "Minimum error rate training based on N-best string models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A minimum string error rate training algorithm, segmental minimum stringerror rate training, is described, which takes a further step in modeling the basic speech recognition units by directly applying discriminative analysis to string level acoustic model matching."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53142908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3524cdf7cf8344e7eb74886f71fcbb5c6732c337",
            "isKey": false,
            "numCitedBy": 26735,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence."
            },
            "slug": "Artificial-Intelligence:-A-Modern-Approach-Russell-Norvig",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence: A Modern Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708531"
                        ],
                        "name": "N. Yankelovich",
                        "slug": "N.-Yankelovich",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Yankelovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Yankelovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733034"
                        ],
                        "name": "Gina-Anne Levow",
                        "slug": "Gina-Anne-Levow",
                        "structuredName": {
                            "firstName": "Gina-Anne",
                            "lastName": "Levow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gina-Anne Levow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40464784"
                        ],
                        "name": "Matthew Marx",
                        "slug": "Matthew-Marx",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Marx",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Marx"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9313029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc0c476feb6fe1b3257f99b555f82f8ae51d2edf",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "SpeechActs is an experimental conversational speech system. Experience with redesigning the system based on user feedback indicates the importance of adhering to conversational conventions when designing speech interfaces, particularly in the face of speech recognition errors. Study results also suggest that speech-only interfaces should be designed from scratch rather than directly translated from their graphical counterparts. This paper examines a set of challenging issues facing speech interface designers and describes approaches to address some of these challenges."
            },
            "slug": "Designing-SpeechActs:-issues-in-speech-user-Yankelovich-Levow",
            "title": {
                "fragments": [],
                "text": "Designing SpeechActs: issues in speech user interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A set of challenging issues facing speech interface designers is examined and approaches to address some of these challenges are described, including adhering to conversational conventions."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692242"
                        ],
                        "name": "B. Grosz",
                        "slug": "B.-Grosz",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Grosz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Grosz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2668280"
                        ],
                        "name": "C. Sidner",
                        "slug": "C.-Sidner",
                        "structuredName": {
                            "firstName": "Candace",
                            "lastName": "Sidner",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sidner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2570492,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "0b144f3ca00d98df1d8f9456d29c7fce3290924d",
            "isKey": false,
            "numCitedBy": 3390,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we explore a new theory of discourse structure that stresses the role of purpose and processing in discourse. In this theory, discourse structure is composed of three separate but interrelated components: the structure of the sequence of utterances (called the linguistic structure), a structure of purposes (called the intentional structure), and the state of focus of attention (called the attentional state). The linguistic structure consists of segments of the discourse into which the utterances naturally aggregate. The intentional structure captures the discourse-relevant purposes, expressed in each of the linguistic segments as well as relationships among them. The attentional state is an abstraction of the focus of attention of the participants as the discourse unfolds. The attentional state, being dynamic, records the objects, properties, and relations that are salient at each point of the discourse. The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases, referring expressions, and interruptions.The theory of attention, intention, and aggregation of utterances is illustrated in the paper with a number of example discourses. Various properties of discourse are described, and explanations for the behavior of cue phrases, referring expressions, and interruptions are explored.This theory provides a framework for describing the processing of utterances in a discourse. Discourse processing requires recognizing how the utterances of the discourse aggregate into segments, recognizing the intentions expressed in the discourse and the relationships among intentions, and tracking the discourse through the operation of the mechanisms associated with attentional state. This processing description specifies in these recognition tasks the role of information from the discourse and from the participants' knowledge of the domain."
            },
            "slug": "Attention,-Intentions,-and-the-Structure-of-Grosz-Sidner",
            "title": {
                "fragments": [],
                "text": "Attention, Intentions, and the Structure of Discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new theory of discourse structure that stresses the role of purpose and processing in discourse is explored and various properties of discourse are described, and explanations for the behavior of cue phrases, referring expressions, and interruptions are explored."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735258"
                        ],
                        "name": "C. Raymond Perrault",
                        "slug": "C.-Raymond-Perrault",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Perrault",
                            "middleNames": [
                                "Raymond"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Raymond Perrault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145844737"
                        ],
                        "name": "James F. Allen",
                        "slug": "James-F.-Allen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James F. Allen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3069430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "895dfdabbbd5155bbb559d3f144db6f7c195ce75",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an account of indirect forms of speech acts to request and inform based on the hypothesis that language users can recognize actions being performed by others, infer goals being sought, and cooperate in their achievement. This cooperative behaviour is independently motivated and may or may not be intended by speakers. If the hearer believes it is intended, he or she can recognize the speech act as indirect; otherwise it is interpreted directly. Heuristics are suggested to decide among the interpretations."
            },
            "slug": "A-Plan-Based-Analysis-of-Indirect-Speech-Acts-Perrault-Allen",
            "title": {
                "fragments": [],
                "text": "A Plan-Based Analysis of Indirect Speech Acts"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An account of indirect forms of speech acts to request and inform based on the hypothesis that language users can recognize actions being performed by others, infer goals being sought, and cooperate in their achievement is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Am. J. Comput. Linguistics"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 145765400,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "dae5b97f0790c2ff5f8cc02a5d83ab862b0a7b60",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Ss heard a passage from Lewis Carroll\u2019s Through the Looking Glass and were asked to indicate, as quickly as possible, whenever they heard a mispronunciation. Mispronunciations were produced by changing one consonant sound in a three-syllable word by one, two, or four distinctive features (e.g., busily to \u201cpizily,\u201d \u201cvisily,\u201d or \u201csizily\u201d). Mispronunciations involving a single feature change were seldom detected, while two and four feature changes were readily detected. The syllable in which a mispronunciation occurred did not affect the probability of detecting a mispronunciation. However, reaction times to mispronounced words were at least a third of a second slower when they occurred in the-first syllable of the word. The results were taken to support the notion that words are identified by their distinctive features."
            },
            "slug": "Listening-for-mispronunciations:-A-measure-of-what-Cole",
            "title": {
                "fragments": [],
                "text": "Listening for mispronunciations: A measure of what we hear during speech"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143965889"
                        ],
                        "name": "S. Whittaker",
                        "slug": "S.-Whittaker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Whittaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Whittaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1006472,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "4e6795d8406bde57551d6acff131d4f47435bcb6",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Conversation between two people is usually of MIXED-INITIATIVE, with CONTROL over the conversation being transferred from one person to another. We apply a set of rules for the transfer of control to 4 sets of dialogues consisting of a total of 1862 turns. The application of the control rules lets us derive domain-independent discourse structures. The derived structures indicate that initiative plays a role in the structuring of discourse. In order to explore the relationship of control and initiative to discourse processes like centering, we analyze the distribution of four different classes of anaphora for two data sets. This distribution indicates that some control segments are hierarchically related to others. The analysis suggests that discourse participants often mutually agree to a change of topic. We also compared initiative in Task Oriented and Advice Giving dialogues and found that both allocation of control and the manner in which control is transferred is radically different for the two dialogue types. These differences can be explained in terms of collaborative planning principles."
            },
            "slug": "Mixed-Initiative-in-Dialogue:-An-Investigation-into-Walker-Whittaker",
            "title": {
                "fragments": [],
                "text": "Mixed Initiative in Dialogue: An Investigation into Discourse Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of rules for the transfer of control is applied to 4 sets of dialogues and it is found that both allocation of control and the manner in which control is transferred is radically different for the two dialogue types."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866226"
                        ],
                        "name": "W. Ward",
                        "slug": "W.-Ward",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Ward",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890070"
                        ],
                        "name": "Zhang Banping",
                        "slug": "Zhang-Banping",
                        "structuredName": {
                            "firstName": "Zhang",
                            "lastName": "Banping",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhang Banping"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060592415"
                        ],
                        "name": "K. Herold",
                        "slug": "K.-Herold",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Herold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Herold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2972454"
                        ],
                        "name": "Xiuyang Yu",
                        "slug": "Xiuyang-Yu",
                        "structuredName": {
                            "firstName": "Xiuyang",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiuyang Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075991931"
                        ],
                        "name": "Zhang Sen",
                        "slug": "Zhang-Sen",
                        "structuredName": {
                            "firstName": "Zhang",
                            "lastName": "Sen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhang Sen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15488842,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "458b0e772babf4bd123207dd3e3409b3343ff759",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to help understand why gains in pronunciation modeling have proven so elusive, we investigated which kinds of pronunciation variation are well captured by triphone models, and which are not. We do this by examining the change in behavior of a recognizer as it receives further triphone training. We show that many of the kinds of variation which previous pronunciation models attempt to capture, including phone substitution or phone reduction, are in fact already well captured by triphones. Our analysis suggests new areas where future pronunciation models should focus, including syllable deletion."
            },
            "slug": "What-kind-of-pronunciation-variation-is-hard-for-to-Jurafsky-Ward",
            "title": {
                "fragments": [],
                "text": "What kind of pronunciation variation is hard for triphones to model?"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work investigates which kinds of pronunciation variation are well captured by triphone models, and which are not, by examining the change in behavior of a recognizer as it receives further triphone training."
            },
            "venue": {
                "fragments": [],
                "text": "2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144436858"
                        ],
                        "name": "Jeanne Fromer",
                        "slug": "Jeanne-Fromer",
                        "structuredName": {
                            "firstName": "Jeanne",
                            "lastName": "Fromer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeanne Fromer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145254843"
                        ],
                        "name": "Shrikanth S. Narayanan",
                        "slug": "Shrikanth-S.-Narayanan",
                        "structuredName": {
                            "firstName": "Shrikanth",
                            "lastName": "Narayanan",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shrikanth S. Narayanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11308277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8332944fb0cd6571095c371d3a65621c6ae77cd4",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a novel method by which a dialogue agent can learn to choose an optimal dialogue strategy. While it is widely agreed that dialogue strategies should be formulated in terms of communicative intentions, there has been little work on automatically optimizing an agent's choices when there are multiple ways to realize a communicative intention. Our method is based on a combination of learning algorithms and empirical evaluation techniques. The learning component of our method is based on algorithms for reinforcement learning, such as dynamic programming and Q-learning. The empirical component uses the PARADISE evaluation framework (Walker et al., 1997) to identify the important performance factors and to provide the performance function needed by the learning algorithm. We illustrate our method with a dialogue agent named ELVIS (EmaiL Voice Interactive System), that supports access to email over the phone. We show how ELVIS can learn to choose among alternate strategies for agent initiative, for reading messages, and for summarizing email folders."
            },
            "slug": "Learning-Optimal-Dialogue-Strategies:-A-Case-Study-Walker-Fromer",
            "title": {
                "fragments": [],
                "text": "Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A novel method by which a dialogue agent can learn to choose an optimal dialogue strategy is described, based on a combination of learning algorithms and empirical evaluation techniques."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150023694"
                        ],
                        "name": "A. N\u00e1das",
                        "slug": "A.-N\u00e1das",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "N\u00e1das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N\u00e1das"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120638127,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "79eb272eaf061cf4e65b8e61c9f02c027b3b6933",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The choice of method for training a speech recognizer is posed as an optimization problem. The currently used method of maximum likelihood, while heuristic, is shown to be superior under certain assumptions to another heuristic: the method of conditional maximum likelihood."
            },
            "slug": "A-decision-theorectic-formulation-of-a-training-in-N\u00e1das",
            "title": {
                "fragments": [],
                "text": "A decision theorectic formulation of a training problem in speech recognition and a comparison of training by unconditional versus conditional maximum likelihood"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The currently used method of maximum likelihood, while heuristic, is shown to be superior under certain assumptions to another heuristic: the method of conditional maximum likelihood."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054241"
                        ],
                        "name": "H. McGurk",
                        "slug": "H.-McGurk",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "McGurk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. McGurk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144239757"
                        ],
                        "name": "J. MacDonald",
                        "slug": "J.-MacDonald",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacDonald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacDonald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4171157,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "eef41ae597a20ea377461d522fd5100da6a7a9b7",
            "isKey": false,
            "numCitedBy": 5484,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "MOST verbal communication occurs in contexts where the listener can see the speaker as well as hear him. However, speech perception is normally regarded as a purely auditory process. The study reported here demonstrates a previously unrecognised influence of vision upon speech perception. It stems from an observation that, on being shown a film of a young woman's talking head, in which repeated utterances of the syllable [ba] had been dubbed on to lip movements for [ga], normal adults reported hearing [da]. With the reverse dubbing process, a majority reported hearing [bagba] or [gaba]. When these subjects listened to the soundtrack from the film, without visual input, or when they watched untreated film, they reported the syllables accurately as repetitions of [ba] or [ga]. Subsequent replications confirm the reliability of these findings; they have important implications for the understanding of speech perception."
            },
            "slug": "Hearing-lips-and-seeing-voices-McGurk-MacDonald",
            "title": {
                "fragments": [],
                "text": "Hearing lips and seeing voices"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The study reported here demonstrates a previously unrecognised influence of vision upon speech perception, on being shown a film of a young woman's talking head in which repeated utterances of the syllable [ba] had been dubbed on to lip movements for [ga]."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60541109,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9f7d5a98f22bd880f42775f6300ae984ebcfc8c2",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Some Important Facts about Speech, The Trace Model, Factors Influencing Phoneme Identification, The Time Course of Spoken Word Recognition, General Discussion, Conclusion, Acknowledgments"
            },
            "slug": "Interactive-processes-in-speech-perception:-the-McClelland-Elman",
            "title": {
                "fragments": [],
                "text": "Interactive processes in speech perception: the TRACE model"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Some Important Facts about Speech, The Trace Model, Factors Influencing Phoneme Identification, The Time Course of Spoken Word Recognition, General Discussion, Conclusion, Acknowledgments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46386736"
                        ],
                        "name": "E. Schegloff",
                        "slug": "E.-Schegloff",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Schegloff",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Schegloff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142784493,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "004c813971bccce14011a815837eb6ba36eb0f92",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Presequences-and-indirection:-Applying-speech-act-Schegloff",
            "title": {
                "fragments": [],
                "text": "Presequences and indirection: Applying speech act theory to ordinary conversation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801692"
                        ],
                        "name": "Y. Normandin",
                        "slug": "Y.-Normandin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Normandin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Normandin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60832448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47cdade65e2cd0c8d09ab5d9ad37a31eca17614e",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter describes ways in which the concept of maximum mutual information estimation (MMIE) can be used to improve the performance of HMM-based speech recognition systems. First, the basic MMIE concept is introduced with some intuition on how it works. Then we show how the concept can be extended to improve the power of the basic models. Since estimating HMM parameters with MMIE training can be computationally expensive, this problem is studied at length and some solutions proposed and demonstrated. Experiments are presented to demonstrate the usefulness of the MMIE technique."
            },
            "slug": "Maximum-Mutual-Information-Estimation-of-Hidden-Normandin",
            "title": {
                "fragments": [],
                "text": "Maximum Mutual Information Estimation of Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter describes ways in which the concept of maximum mutual information estimation (MMIE) can be used to improve the performance of HMM-based speech recognition systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2305444"
                        ],
                        "name": "Philip R. Cohen",
                        "slug": "Philip-R.-Cohen",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Cohen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip R. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735258"
                        ],
                        "name": "C. Raymond Perrault",
                        "slug": "C.-Raymond-Perrault",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Perrault",
                            "middleNames": [
                                "Raymond"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Raymond Perrault"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2166355,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "205a38b9a32f7907f07dd6778805a0b6ee7b109d",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the truism that people think about what they say. It proposes hat, to satisfy their own goals, people often plan their speech acts to affect their listeners' beliefs, goals, and emotional states. Such language use can be modelled by viewing speech acts as operators in a planning system, thus allowing both physical and speech acts to be integrated into plans. \n \nMethodological issues of how speech acts should be defined in a plan-based theory are illustrated by defining operators for requesting and informing. Plans containing those operators are presented and comparisons are drawn with Searle's formulation. The operators are shown to be inadequate since they cannot be composed to form questions (requests to inform) and multiparty requests (requests to request). By refining the operator definitions and by identifying some of the side effects of requesting, compositional adequacy is achieved. The solution leads to a metatheoretical principle for modelling speech acts as planning operators."
            },
            "slug": "Elements-of-a-Plan-Based-Theory-of-Speech-Acts-Cohen-Perrault",
            "title": {
                "fragments": [],
                "text": "Elements of a Plan-Based Theory of Speech Acts"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper explores the truism that people think about what they say and proposes hat, to satisfy their own goals, people often plan their speech acts to affect their listeners' beliefs, goals, and emotional states."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798583"
                        ],
                        "name": "W. Bledsoe",
                        "slug": "W.-Bledsoe",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Bledsoe",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bledsoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085594395"
                        ],
                        "name": "I. Browning",
                        "slug": "I.-Browning",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Browning",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Browning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 15672245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e7311b9e560f3a12c895b751d275bac161b31b",
            "isKey": false,
            "numCitedBy": 399,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Many efforts have been made to discriminate, categorize, and quantitate patterns, and to reduce them into a usable machine language. The results have ordinarily been methods or devices with a high degree of specificity. For example, some devices require a special type font; others can read only one type font; still others require magnetic ink."
            },
            "slug": "Pattern-recognition-and-reading-by-machine-Bledsoe-Browning",
            "title": {
                "fragments": [],
                "text": "Pattern recognition and reading by machine"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Many efforts have been made to discriminate, categorize, and quantitate patterns, and to reduce them into a usable machine language, and the results have ordinarily been methods or devices with a high degree of specificity."
            },
            "venue": {
                "fragments": [],
                "text": "IRE-AIEE-ACM '59 (Eastern)"
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2618025"
                        ],
                        "name": "D. Massaro",
                        "slug": "D.-Massaro",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Massaro",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Massaro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142430363,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0b50e5c28d20ce2c49836a9b9741c6f842e119f0",
            "isKey": false,
            "numCitedBy": 562,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Perceiving talking faces: bimodal speech perception speech as pattern recognition perceptual events and time a universal law. Part 2 Broadening the domain: individual variability ecological variability emotion in the face emotion from the face and the voice. Part 3 Broadening the framework: broadening the model broadening the tests addressing critiques. Part 4 Creating talking faces, Michael M. Cohen, Michael A. Berger: synthesizing talking faces evaluating talking faces applying talking faces."
            },
            "slug": "Perceiving-talking-faces:-from-speech-perception-to-Massaro",
            "title": {
                "fragments": [],
                "text": "Perceiving talking faces: from speech perception to a behavioral principle"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2372800"
                        ],
                        "name": "J. Cooley",
                        "slug": "J.-Cooley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cooley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cooley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016914"
                        ],
                        "name": "J. Tukey",
                        "slug": "J.-Tukey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tukey",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tukey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121744946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e6beb95b5150ce99b108acdefabf70ccd3fee30",
            "isKey": false,
            "numCitedBy": 11239,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient method for the calculation of the interactions of a 2' factorial ex- periment was introduced by Yates and is widely known by his name. The generaliza- tion to 3' was given by Box et al. (1). Good (2) generalized these methods and gave elegant algorithms for which one class of applications is the calculation of Fourier series. In their full generality, Good's methods are applicable to certain problems in which one must multiply an N-vector by an N X N matrix which can be factored into m sparse matrices, where m is proportional to log N. This results inma procedure requiring a number of operations proportional to N log N rather than N2. These methods are applied here to the calculation of complex Fourier series. They are useful in situations where the number of data points is, or can be chosen to be, a highly composite number. The algorithm is here derived and presented in a rather different form. Attention is given to the choice of N. It is also shown how special advantage can be obtained in the use of a binary computer with N = 2' and how the entire calculation can be performed within the array of N data storage locations used for the given Fourier coefficients. Consider the problem of calculating the complex Fourier series N-1 (1) X(j) = EA(k)-Wjk, j = 0 1, * ,N- 1, k=0"
            },
            "slug": "An-algorithm-for-the-machine-calculation-of-complex-Cooley-Tukey",
            "title": {
                "fragments": [],
                "text": "An algorithm for the machine calculation of complex Fourier series"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Good generalized these methods and gave elegant algorithms for which one class of applications is the calculation of Fourier series, applicable to certain problems in which one must multiply an N-vector by an N X N matrix which can be factored into m sparse matrices."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755630"
                        ],
                        "name": "K. Lochbaum",
                        "slug": "K.-Lochbaum",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Lochbaum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lochbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10301019,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "15067b5cd95d11efe9c6e06a8ba3fb544a6697cc",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "An agent's ability to understand an utterance depends upon its ability to relate that utterance to the preceding discourse. The agent must determine whether the utterance begins a new segment of the discourse, completes the current segment, or contributes to it. The intentional structure of the discourse, comprised of discourse segment purposes and their interrelationships, plays a central role in this process (Grosz and Sidner 1986). In this paper, we provide a computational model for recognizing intentional structure and utilizing it in discourse processing. The model is based on the collaborative planning framework of SharedPlans (Grosz and Kraus 1996)."
            },
            "slug": "A-Collaborative-Planning-Model-of-Intentional-Lochbaum",
            "title": {
                "fragments": [],
                "text": "A Collaborative Planning Model of Intentional Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A computational model for recognizing intentional structure and utilizing it in discourse processing is provided based on the collaborative planning framework of SharedPlans (Grosz and Kraus 1996)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145844737"
                        ],
                        "name": "James F. Allen",
                        "slug": "James-F.-Allen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James F. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144436424"
                        ],
                        "name": "G. Ferguson",
                        "slug": "G.-Ferguson",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Ferguson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ferguson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690152"
                        ],
                        "name": "Amanda Stent",
                        "slug": "Amanda-Stent",
                        "structuredName": {
                            "firstName": "Amanda",
                            "lastName": "Stent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amanda Stent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5664074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "379d84eb2a3fb4994d23ffeec18feedae18d0e11",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an architecture for conversational systems that enables human-like performance along several important dimensions. First, interpretation is incremental, multi-level, and involves both general and task- and domain-specific knowledge. Second, generation is also incremental, proceeds in parallel with interpretation, and accounts for phenomena such as turn-taking, grounding and interruptions. Finally, the overall behavior of the system in the task at hand is determined by the (incremental) results of interpretation, the persistent goals and obligations of the system, and exogenous events of which it becomes aware. As a practical matter, the architecture supports a separation of responsibilities that enhances portability to new tasks and domains."
            },
            "slug": "An-architecture-for-more-realistic-conversational-Allen-Ferguson",
            "title": {
                "fragments": [],
                "text": "An architecture for more realistic conversational systems"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An architecture for conversational systems that enables human-like performance along several important dimensions and supports a separation of responsibilities that enhances portability to new tasks and domains is described."
            },
            "venue": {
                "fragments": [],
                "text": "IUI '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3122851"
                        ],
                        "name": "Mark G. Core",
                        "slug": "Mark-G.-Core",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Core",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark G. Core"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592307"
                        ],
                        "name": "M. Ishizaki",
                        "slug": "M.-Ishizaki",
                        "structuredName": {
                            "firstName": "Masato",
                            "lastName": "Ishizaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ishizaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47147237"
                        ],
                        "name": "Johanna D. Moore",
                        "slug": "Johanna-D.-Moore",
                        "structuredName": {
                            "firstName": "Johanna",
                            "lastName": "Moore",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johanna D. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844268"
                        ],
                        "name": "C. H. Nakatani",
                        "slug": "C.-H.-Nakatani",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Nakatani",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Nakatani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29942835"
                        ],
                        "name": "Norbert Reithinger",
                        "slug": "Norbert-Reithinger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Reithinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norbert Reithinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518646"
                        ],
                        "name": "D. Traum",
                        "slug": "D.-Traum",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Traum",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Traum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272334"
                        ],
                        "name": "S. Tutiya",
                        "slug": "S.-Tutiya",
                        "structuredName": {
                            "firstName": "Syun",
                            "lastName": "Tutiya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tutiya"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 150432888,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "abf960cdaa494c09b0408ff1dd802412322a3206",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "The workshop organizers are glad to acknowledge the generous financial support from Nissan Science Foundation and Chiba University, which made the workshop possible. The graduate and undergraduate students of Chiba University who helped us organize the tutorials and workshop are to be thanked. Special thanks are to go to Mika Enomoto, who patiently followed the wild and winding discussions in the workshop, preparing the minutes. Toshiyuki Kawashima, who maintained the computer and network environment in Kazusa, will be fondly recalled by email addicts. Junko Arao and Eri Ishizaki deserve hearty gratitude from all the participants though they were in the backstage, for they were responsible for most of the secretarial chores, from sending and receiving mail, to listing the participants, to accounting, to photocopying, and finally to babysitting. The tutorial presenters should be applauded for their impressive talks, which convinced the Japanese audience of the importance of collaborative corpus building efforts. The contributers to this report are to be thanked by the editors and workshop organizers for their efforts in reconstructing what was going on in Chiba in May, 1998. Norbert Reithinger deserves special praise both for his having inadvertently volunteered to edit this report and now keeping his word. All the people involved in this workshop and report writing are to be remembered for their contribution to the advancement of discourse and dialogue research in worldwide cooperation. Traum, who compiled all the texts in this report and all the other contributors who provided them with input. My task was finally just to do some formatting and provide basic consistency of the different parts. The first workshop revealed the shared interest in exchanging the information on the existing discourse annotation schemes for illocution-ary acts, discourse structure and co-reference and, in addition, discussed such issues as segmentation of discourse for analysis and the availability of computer tools. The second workshop examined the homework by the committed participants of applying the results of the first workshop to a limited but significant set of dialogues, focusing on the issues like categories, units and tools, and finally proposed a tentative annotation scheme which was called DAMSL (Dialog Act Markup in Several Layers), as stated in the report from the second workshop [Carletta et al., 1997a, Allen and Core, Draft 1997]. The first and second workshops were held on invitation basis. That was because the workshops were intended to produce concrete proposals and standards for \u2026"
            },
            "slug": "The-Report-of-The-Third-Workshop-of-the-Discourse-Core-Ishizaki",
            "title": {
                "fragments": [],
                "text": "The Report of The Third Workshop of the Discourse Resource Initiative, Chiba University and Kazusa Academia Hall"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46386736"
                        ],
                        "name": "E. Schegloff",
                        "slug": "E.-Schegloff",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Schegloff",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Schegloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70054821"
                        ],
                        "name": "G. Jefferson",
                        "slug": "G.-Jefferson",
                        "structuredName": {
                            "firstName": "Gail",
                            "lastName": "Jefferson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jefferson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51480662"
                        ],
                        "name": "Harvey Sacks",
                        "slug": "Harvey-Sacks",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Sacks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harvey Sacks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143617589,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "191a416ea8d6673a7c2ceecc3b36e2b118430ccd",
            "isKey": false,
            "numCitedBy": 3815,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "An \"organization of repair' operates in conversation, addressed to recurrent problems in speaking, hearing, and understanding. Several features of that organization are introduced to explicate the mechanism which produces a strong empirical skewing in which self-repair predominates over other-repair, and to show the operation of a preference for self-repair in the organization of repair. Several consequences of the preference for self-repair for conversational interaction are sketched.* 1. SELF- AND OTHER-CORRECTION. Among linguists and others who have at all concerned themselves with the phenomenon of'correction' (or, as we shall refer to it, 'repair'; cf. below, ?2.1), a distinction is commonly drawn between 'selfcorrection' and 'other-correction', i.e. correction by the speaker of that which is being corrected vs. correction by some 'other'.l Sociologists take an interest in such a distinction; its terms-'self' and 'other'-have long been understood as central to the study of social organization and social interaction.2 For our concerns in this paper, 'self' and 'other' are two classes of participants in interactive social"
            },
            "slug": "The-preference-for-self-correction-in-the-of-repair-Schegloff-Jefferson",
            "title": {
                "fragments": [],
                "text": "The preference for self-correction in the organization of repair in conversation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15000287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d46cd5ab029f7b01956c1158859da0042842234",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Two algorithms are presented for accelerating the operation of a stack decoder. The first is a method for computing the true least upper bound so that an optimal admissible A* search can be performed. The second is a set of methods for linearizing the computation required by a stack decoder. The A* search has been implemented in a continuous speech recognizer simulator and has demonstrated a significant speedup. The linearizing algorithm has been partially implemented in the simulator and has also shown significant computational savings.<<ETX>>"
            },
            "slug": "Algorithms-for-an-Optimal-A*-Search-and-Linearizing-Paul",
            "title": {
                "fragments": [],
                "text": "Algorithms for an Optimal A* Search and Linearizing the Search in the Stack Decoder*"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Two algorithms are presented for accelerating the operation of a stack decoder using a method for computing the true least upper bound so that an optimal admissible A* search can be performed."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115311"
                        ],
                        "name": "R. Pieraccini",
                        "slug": "R.-Pieraccini",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Pieraccini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pieraccini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31717617"
                        ],
                        "name": "W. Eckert",
                        "slug": "W.-Eckert",
                        "structuredName": {
                            "firstName": "Wieland",
                            "lastName": "Eckert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Eckert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1985491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abe0bd94e134c7ac0b1c78922ed17cf3bec08d5e",
            "isKey": false,
            "numCitedBy": 579,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a quantitative model for dialog systems that can be used for learning the dialog strategy. We claim that the problem of dialog design can be formalized as an optimization problem with an objective function reflecting different dialog dimensions relevant for a given application. We also show that any dialog system can be formally described as a sequential decision process in terms of its state space, action set, and strategy. With additional assumptions about the state transition probabilities and cost assignment, a dialog system can be mapped to a stochastic model known as Markov decision process (MDP). A variety of data driven algorithms for finding the optimal strategy (i.e., the one that optimizes the criterion) is available within the MDP framework, based on reinforcement learning. For an effective use of the available training data we propose a combination of supervised and reinforcement learning: the supervised learning is used to estimate a model of the user, i.e., the MDP parameters that quantify the user's behavior. Then a reinforcement learning algorithm is used to estimate the optimal strategy while the system interacts with the simulated user. This approach is tested for learning the strategy in an air travel information system (ATIS) task. The experimental results we present in this paper show that it is indeed possible to find a simple criterion, a state space representation, and a simulated user parameterization in order to automatically learn a relatively complex dialog behavior, similar to one that was heuristically designed by several research groups."
            },
            "slug": "A-stochastic-model-of-human-machine-interaction-for-Levin-Pieraccini",
            "title": {
                "fragments": [],
                "text": "A stochastic model of human-machine interaction for learning dialog strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The experimental results show that it is indeed possible to find a simple criterion, a state space representation, and a simulated user parameterization in order to automatically learn a relatively complex dialog behavior, similar to one that was heuristically designed by several research groups."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144883333"
                        ],
                        "name": "J. Hintikka",
                        "slug": "J.-Hintikka",
                        "structuredName": {
                            "firstName": "Jaakko",
                            "lastName": "Hintikka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hintikka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 197438729,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "c2709beadedb8455021267c61d314f72c7b5abbd",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In the philosophy of logic a distinction is often made between the theory of reference and the theory of meaning.1 In this paper I shall suggest (inter alia) that this distinction, though not without substance, is profoundly misleading. The theory of reference is, I shall argue, the theory of meaning for certain simple types of language. The only entities needed in the so-called theory of meaning are, in many interesting cases and perhaps even in all cases, merely what is required in order for the expressions of our language to be able to refer in certain more complicated situations. Instead of the theory of reference and the theory of meaning we perhaps ought to speak in some cases of the theory of simple and of multiple reference, respectively. Quine has regretted that the term \u2018semantics\u2019, which etymologically ought to refer to the theory of meaning, has come to mean the theory of reference.1 I submit that this usage is happier than Quine thinks, and that large parts of the theory of meaning in reality are \u2014 or ought to be \u2014 but semantical theories for notions transcending the range of certain elementary types of concepts."
            },
            "slug": "Semantics-for-Propositional-Attitudes-Hintikka",
            "title": {
                "fragments": [],
                "text": "Semantics for Propositional Attitudes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4314925"
                        ],
                        "name": "A. Samuel",
                        "slug": "A.-Samuel",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Samuel",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14068685,
            "fieldsOfStudy": [
                "Psychology",
                "Physics"
            ],
            "id": "cc8f344905cc6796111f7bf573b64cebb24bb7d7",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Phonemic restoration is a powerful auditory illusion in which listeners \"hear\" parts of words that are not really there. In earlier studies of the illusion, segments of words (phonemes) were replaced by an extraneous sound; listeners were asked whether anything was missing and where the extraneous noise had occurred. Most listeners reported that the utterance was intact and mislocalized the noise, suggesting that they had restored the missing phoneme. In the present study, a second type of stimulus was also presented: items in which the extraneous sound was merely superimposed on the critical phoneme. On each trial, listeners were asked to report whether they thought a stimulus utterance was intact (noise superimposed) or not (noise replacing). Since this procedure yields both a miss rate P(intact/replaced), and a false alarm rate P(replaced/intact), signal detection parameters of discriminability and bias can be calculated. The discriminability parameter reflects how similar the two types of stimuli sound; perceptual restoration of replaced items should make them sound intact, producing low discriminability scores. The bias parameter measures the tendency of listeners to report utterances as intact; it reflects postperceptual decision processes. This improved methodology was used to test the hypothesis that restoration (and more generally, speech perception) depends upon the bottom-up confirmation of expectations generated at higher levels. Perceptual restoration varied greatly wih the phone class of the replaced segment and its acoustic similarity to the replacement sound, supporting a bottom-up component to the illusion. Increasing listeners' expectations of a phoneme increased perceptual restoration: missing segments in words were better restored than corresponding pieces in phonologically legal pseudowords; priming the words produced even more restoration. In contrast, sentential context affected the postperceptual decision stage, biasing listeners to report utterances as intact. A limited interactive model of speech perception, with both bottom-up and top-down components, is used to explain the results."
            },
            "slug": "Phonemic-restoration:-insights-from-a-new-Samuel",
            "title": {
                "fragments": [],
                "text": "Phonemic restoration: insights from a new methodology."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Improved methodology was used to test the hypothesis that restoration depends upon the bottom-up confirmation of expectations generated at higher levels, and increasing listeners' expectations of a phoneme increased perceptual restoration: missing segments in words were better restored than corresponding pieces in phonologically legal pseudowords."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. General"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152676840"
                        ],
                        "name": "V. L. Smith",
                        "slug": "V.-L.-Smith",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Smith",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. L. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29224904"
                        ],
                        "name": "H. H. Clark",
                        "slug": "H.-H.-Clark",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Clark",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. H. Clark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144897050,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "37503a0a272949dd09f26fdf67757b49765fccfa",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract People responding to questions are sometimes uncertain, slow, or unable to answer. They handle these problems of self-presentation, we propose, by the way they respond. Twenty-five respondents were each asked 40 factual questions in a conversational setting. Later, they rated for each question their feeling that they would recognize the correct answer, then took a recognition test on all 40 questions. As found previously, the weaker their feeling of knowing, the slower their answers, the faster their nonanswers (\"I don\u2032t know\"), and the worse their recognition. But further, as proposed, the weaker their feeling of knowing, the more often they answered with rising intonation, used hedges such as \"I guess,\" responded \"I don\u2032t know\" instead of \"I can\u2032t remember,\" and added \"uh\" or \"um,\" self-talk, and other face-saving comments. They reliably used \"uh\" to signal brief delays and \"um\" longer ones."
            },
            "slug": "On-the-Course-of-Answering-Questions-Smith-Clark",
            "title": {
                "fragments": [],
                "text": "On the Course of Answering Questions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56128297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f09ce0dd760857e0d0e4879f6e2543f04c5d33",
            "isKey": false,
            "numCitedBy": 926,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for estimating the parameters of hidden Markov models of speech is described. Parameter values are chosen to maximize the mutual information between an acoustic observation sequence and the corresponding word sequence. Recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "slug": "Maximum-mutual-information-estimation-of-hidden-for-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Maximum mutual information estimation of hidden Markov model parameters for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method for estimating the parameters of hidden Markov models of speech is described and recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145421878"
                        ],
                        "name": "R. Sproat",
                        "slug": "R.-Sproat",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sproat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sproat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3265939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "110fd6d66c7380556b377ada84cfb5cd0b6bbaa0",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on a method for compiling decision trees into weighted finite-state transducers. The key assumptions are that the tree predictions specify how to rewrite symbols from an input string, and the decision at each tree node is stateable in terms of regular expressions on the input string. Each leaf node can then be treated as a separate rule where the left and right contexts are constructable from the decisions made traversing the tree from the root to the leaf. These rules are compiled into transducers using the weighted rewite-rule rule-compilation algorithm described in (Mohri and Sproat, 1996)."
            },
            "slug": "Compilation-of-Weighted-Finite-State-Transducers-Sproat-Riley",
            "title": {
                "fragments": [],
                "text": "Compilation of Weighted Finite-State Transducers from Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A method for compiling decision trees into weighted finite-state transducers using the weighted rewite-rule rule-compilation algorithm described in (Mohri and Sproat, 1996)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518646"
                        ],
                        "name": "D. Traum",
                        "slug": "D.-Traum",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Traum",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Traum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145844737"
                        ],
                        "name": "James F. Allen",
                        "slug": "James-F.-Allen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James F. Allen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 71028,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "e1e3ce99f3230901339bd528ada5f9b7bc887f23",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that in modeling social interaction, particularly dialogue, the attitude of obligation can be a useful adjunct to the popularly considered attitudes of belief, goal, and intention and their mutual and shared counterparts. In particular, we show how discourse obligations can be used to account in a natural manner for the connection between a question and its answer in dialogue and how obligations can be used along with other parts of the discourse context to extend the coverage of a dialogue system."
            },
            "slug": "Discourse-Obligations-in-Dialogue-Processing-Traum-Allen",
            "title": {
                "fragments": [],
                "text": "Discourse Obligations in Dialogue Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown how discourse obligations can be used to account in a natural manner for the connection between a question and its answer in dialogue and how obligationsCan be used along with other parts of the discourse context to extend the coverage of a dialogue system."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153582857"
                        ],
                        "name": "M. Good",
                        "slug": "M.-Good",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Good",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Good"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33312609"
                        ],
                        "name": "J. Whiteside",
                        "slug": "J.-Whiteside",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Whiteside",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Whiteside"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755222"
                        ],
                        "name": "Dennis R. Wixon",
                        "slug": "Dennis-R.-Wixon",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Wixon",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis R. Wixon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115857312"
                        ],
                        "name": "Sandra J. Jones",
                        "slug": "Sandra-J.-Jones",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sandra J. Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12598211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "180d2efd064ba69bba61080c3b54bec466fd8c5d",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Many human-computer interfaces are designed with the assumption that the user must adapt to the system, that users must be trained and their behavior altered to fit a given interface. The research presented here proceeds from the alternative assumption: Novice behavior is inherently sensible, and the computer system can be made to adapt to it. Specifically, a measurably easy-to-use interface was built to accommodate the actual behavior of novice users. Novices attempted an electronic mail task using a command-line interface containing no help, no menus, no documentation, and no instruction. A hidden operator intercepted commands when necessary, creating the illusion of an interactive session. The software was repeatedly revised to recognize users' new commands; in essence, the interface was derived from user behavior. This procedure was used on 67 subjects. The first version of the software could recognize only 7 percent of all the subjects' spontaneously generated commands; the final version could recognize 76 percent of these commands. This experience contradicts the idea that user input is irrelevant to the design of command languages. Through careful observation and analysis of user behavior, a mail interface unusable by novices evolved into one that let novices do useful work within minutes."
            },
            "slug": "Building-a-user-derived-interface-Good-Whiteside",
            "title": {
                "fragments": [],
                "text": "Building a user-derived interface"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Through careful observation and analysis of user behavior, a mail interface unusable byNovices evolved into one that let novices do useful work within minutes."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14754287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81a5952532cdd48eec5e3dc326907c36a70e0a24",
            "isKey": false,
            "numCitedBy": 2922,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "A vector quantizer is a system for mapping a sequence of continuous or discrete vectors into a digital sequence suitable for communication over or storage in a digital channel. The goal of such a system is data compression: to reduce the bit rate so as to minimize communication channel capacity or digital storage memory requirements while maintaining the necessary fidelity of the data. The mapping for each vector may or may not have memory in the sense of depending on past actions of the coder, just as in well established scalar techniques such as PCM, which has no memory, and predictive quantization, which does. Even though information theory implies that one can always obtain better performance by coding vectors instead of scalars, scalar quantizers have remained by far the most common data compression system because of their simplicity and good performance when the communication rate is sufficiently large. In addition, relatively few design techniques have existed for vector quantizers. During the past few years several design algorithms have been developed for a variety of vector quantizers and the performance of these codes has been studied for speech waveforms, speech linear predictive parameter vectors, images, and several simulated random processes. It is the purpose of this article to survey some of these design techniques and their applications."
            },
            "slug": "Vector-quantization-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "During the past few years several design algorithms have been developed for a variety of vector quantizers and the performance of these codes has been studied for speech waveforms, speech linear predictive parameter vectors, images, and several simulated random processes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ASSP Magazine"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81338045"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145866886"
                        ],
                        "name": "S. Singh",
                        "slug": "S.-Singh",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2198541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb53b7c13156e3acacb47c1e51d93cefeabfaeb0",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing the dialogue policy of a spoken dialogue system involves many nontrivial choices. This paper presents a reinforcement learning approach for automatically optimizing a dialogue policy, which addresses the technical challenges in applying reinforcement learning to a working dialogue system with human users. We report on the design, construction and empirical evaluation of NJFun, an experimental spoken dialogue system that provides users with access to information about fun things to do in New Jersey. Our results show that by optimizing its performance via reinforcement learning, NJFun measurably improves system performance."
            },
            "slug": "Optimizing-Dialogue-Management-with-Reinforcement-Kearns-Litman",
            "title": {
                "fragments": [],
                "text": "Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The design, construction and empirical evaluation of NJFun, an experimental spoken dialogue system that provides users with access to information about fun things to do in New Jersey, are reported on."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786202"
                        ],
                        "name": "H. Bunt",
                        "slug": "H.-Bunt",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Bunt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13076371,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics",
                "Psychology"
            ],
            "id": "b529d039e2ab0ebf95a52f8720811c3760de7274",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Dialogues are usually motivated by some underlying, noncommunicative goal. Participants in a dialogue therefore perform two tasks at once: that of trying to achieve the underlying noncommunicative goal, and that of communicating in order to achieve the associated communicative goal. This is reeected in the fact that dialogues consist not only of elements motivated by the underlying task, but also of elements motivated by the communicative task and dealing with aspects that require constant attention in communication, such as ensuring contact, providing feedback, monitoring the attention, taking turns, repairing communicative failures, etc. We use the term dialogue control to refer to these aspects of dialogue. In this paper we present an analysis of the various aspects of dialogue control, focusing on the identiication and deenition of the communicative functions of dialogue control acts in information-seeking dialogues."
            },
            "slug": "Context-and-Dialogue-Control-Bunt",
            "title": {
                "fragments": [],
                "text": "Context and Dialogue Control"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents an analysis of the various aspects of Dialogue control, focusing on the identiication and deenition of the communicative functions of dialogue control acts in information-seeking dialogues."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51480662"
                        ],
                        "name": "Harvey Sacks",
                        "slug": "Harvey-Sacks",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Sacks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harvey Sacks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46386736"
                        ],
                        "name": "E. Schegloff",
                        "slug": "E.-Schegloff",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Schegloff",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Schegloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70054821"
                        ],
                        "name": "G. Jefferson",
                        "slug": "G.-Jefferson",
                        "structuredName": {
                            "firstName": "Gail",
                            "lastName": "Jefferson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jefferson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 107534488,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "88811ee8953981c26bf23c8d335474eae121ab91",
            "isKey": false,
            "numCitedBy": 2404,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-simplest-systematics-for-the-organization-of-for-Sacks-Schegloff",
            "title": {
                "fragments": [],
                "text": "A simplest systematics for the organization of turn-taking for conversation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32711353"
                        ],
                        "name": "R. M. Warren",
                        "slug": "R.-M.-Warren",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Warren",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. M. Warren"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30356740,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "566d11da14d0fdac259d70ba6e0751d8bf91af3c",
            "isKey": false,
            "numCitedBy": 1030,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "When an extraneous sound (such as a cough or tone) completely replaces a speech sound in a recorded sentence, listeners believe they hear the missing sound. The extraneous sound seems to occur during another portion of the sentence without interfering with the intelligibility of any phoneme. If silence replaces a speech sound, the gap is correctly localized and the absence of the speech sound detected."
            },
            "slug": "Perceptual-Restoration-of-Missing-Speech-Sounds-Warren",
            "title": {
                "fragments": [],
                "text": "Perceptual Restoration of Missing Speech Sounds"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "When an extraneous sound (such as a cough or tone) completely replaces a speech sound in a recorded sentence, listeners believe they hear the missing sound."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46386736"
                        ],
                        "name": "E. Schegloff",
                        "slug": "E.-Schegloff",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Schegloff",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Schegloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 144618448,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "a048cea20fa2c0015e4f97ee708f2ac47d8f1a0d",
            "isKey": false,
            "numCitedBy": 2200,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "An attempt is made to ascertain rules for the sequencing of a limited part of natural conversation and to determine some properties and empirical consequences of the operation of those rules. Two formulations of conversational openings are suggested and the properties \"nonterminality\" and \"conditional relevance\" are developed to explicate the operation of one of them and to suggest some of its interactional consequences. Some discussion is offered of the fit between the sequencing structure and the tasks of conversational openings."
            },
            "slug": "Sequencing-in-Conversational-Openings-Schegloff",
            "title": {
                "fragments": [],
                "text": "Sequencing in Conversational Openings"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119142953"
                        ],
                        "name": "S. Khamis",
                        "slug": "S.-Khamis",
                        "structuredName": {
                            "firstName": "Samar",
                            "lastName": "Khamis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khamis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47976263"
                        ],
                        "name": "F. Mosteller",
                        "slug": "F.-Mosteller",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Mosteller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mosteller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144087709"
                        ],
                        "name": "D. L. Wallace",
                        "slug": "D.-L.-Wallace",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wallace",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. L. Wallace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124790138,
            "fieldsOfStudy": [
                "Sociology",
                "Computer Science",
                "Mathematics",
                "Political Science",
                "Philosophy"
            ],
            "id": "ad07d4e62a4873821e4d5c8adf489f160aae14d4",
            "isKey": false,
            "numCitedBy": 700,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The 1964 publication of \"Inference and Disputed Authorship\" made the cover of \"Time\" magazine and drew the attention of academics and the public alike for its use of statistical methodology to solve one of American history's most notorious questions: the disputed authorship of the \"Federalist Papers\". Back in print for a new generation of readers, this classic volume applies mathematics, including the once-controversial Bayesian analysis, to the heart of a literary and historical problem by studying frequently used words in the texts. The reissue of this landmark book will be welcomed by anyone interested in the juncture of history, political science, and authorship."
            },
            "slug": "Inference-and-Disputed-Authorship:-The-Federalist-Khamis-Mosteller",
            "title": {
                "fragments": [],
                "text": "Inference and Disputed Authorship: The Federalist"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694130"
                        ],
                        "name": "J. Carletta",
                        "slug": "J.-Carletta",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Carletta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carletta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2722475"
                        ],
                        "name": "Amy Isard",
                        "slug": "Amy-Isard",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901024"
                        ],
                        "name": "S. Isard",
                        "slug": "S.-Isard",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Isard",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128176"
                        ],
                        "name": "J. C. Kowtko",
                        "slug": "J.-C.-Kowtko",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Kowtko",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Kowtko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401226124"
                        ],
                        "name": "G. Doherty-Sneddon",
                        "slug": "G.-Doherty-Sneddon",
                        "structuredName": {
                            "firstName": "Gwyneth",
                            "lastName": "Doherty-Sneddon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doherty-Sneddon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3074521"
                        ],
                        "name": "A. Anderson",
                        "slug": "A.-Anderson",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Anderson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Anderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29816847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26e700cd2856a60cb82d5c94662564cda272ca69",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the reliability of a dialogue structure coding scheme based on utterance function, game structure, and higher-level transaction structure that has been applied to a corpus of spontaneous task-oriented spoken dialogues."
            },
            "slug": "The-Reliability-of-a-Dialogue-Structure-Coding-Carletta-Isard",
            "title": {
                "fragments": [],
                "text": "The Reliability of a Dialogue Structure Coding Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper describes the reliability of a dialogue structure coding scheme based on utterance function, game structure, and higher-level transaction structure that has been applied to a corpus of spontaneous task-oriented spoken dialogues."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056933609"
                        ],
                        "name": "J. Jansen",
                        "slug": "J.-Jansen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Jansen",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116518564"
                        ],
                        "name": "Dg Ollason",
                        "slug": "Dg-Ollason",
                        "structuredName": {
                            "firstName": "Dg",
                            "lastName": "Ollason",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dg Ollason"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16197350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a98e481ce418a437cdfae107d85f009a5da6a790",
            "isKey": false,
            "numCitedBy": 2086,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "1 The Fundamentals of HTK 2 1.1 General Principles of HMMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Isolated Word Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Output Probability Specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.4 Baum-Welch Re-Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.5 Recognition and Viterbi Decoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.6 Continuous Speech Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.7 Speaker Adaptation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13"
            },
            "slug": "The-HTK-book-Young-Jansen",
            "title": {
                "fragments": [],
                "text": "The HTK book"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The Fundamentals of HTK: General Principles of HMMs, Recognition and Viterbi Decoding, and Continuous Speech Recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70054821"
                        ],
                        "name": "G. Jefferson",
                        "slug": "G.-Jefferson",
                        "structuredName": {
                            "firstName": "Gail",
                            "lastName": "Jefferson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jefferson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61152531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e401ede01ec947a7c5d0ecd11002381b97b1a25",
            "isKey": false,
            "numCitedBy": 416,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In one of his lectures, Harvey Sacks proposes that the social sciences have tended to view a society as having \u201crelatively few orderly products, where then much of what else takes place is more or less random.\u201d; He offers \u201can image of a machine with a couple of holes in the front. It spews out some nice stuff from those holes, and out of the back it spews out garbage.\u201d; Where, then, \u201cthe concern to find that data generated by the machine which is orderly\u201d; tends to focus on \u201cwhat are in the first instance known to be \u2018big issues\u2019, and not that which is terribly mundane, occasional, local, and the like.\u201d; Sacks offers as an alternative approach, that \u201cit is perfectly possible...to suppose...that wherever one happens to attack the phenomenon one is going to find detailed order. That is, one may alternatively take it that there is order at all points.\u201d; As a student of Sacks\u2019, I use \u2018order at all points\u2019 as a research presupposition, a working hypothesis, a base. But every now and then it appears th..."
            },
            "slug": "Notes-on-a-systematic-deployment-of-the-tokens-and-Jefferson",
            "title": {
                "fragments": [],
                "text": "Notes on a systematic deployment of the acknowledgement tokens \u201cYeah\u201d; and \u201cMm Hm\u201d;"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "It is proposed that the social sciences have tended to view a society as having \u201crelatively few orderly products, where then much of what else takes place is more or less random."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35674406"
                        ],
                        "name": "Shigeo Abe DrEng",
                        "slug": "Shigeo-Abe-DrEng",
                        "structuredName": {
                            "firstName": "Shigeo",
                            "lastName": "DrEng",
                            "middleNames": [
                                "Abe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shigeo Abe DrEng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9384346,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science"
            ],
            "id": "65a69968bb8c41aad0113cec4c2d981bddf50bc8",
            "isKey": false,
            "numCitedBy": 13095,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification \u2022 Supervised \u2013 parallelpiped \u2013 minimum distance \u2013 maximum likelihood (Bayes Rule) > non-parametric > parametric \u2013 support vector machines \u2013 neural networks \u2013 context classification \u2022 Unsupervised (clustering) \u2013 K-Means \u2013 ISODATA \u2022 Pattern recognition in remote sensing has been based on the intuitive notion that pixels belonging to the same class should have similar gray values in a given band. \u2013 Given two spectral bands, pixels from the same class plotted in a two-dimensional histogram should appear as a localized cluster. \u2013 If n images, each in a different spectral band, are available, pixels from the same class should form a localized cluster in n-space."
            },
            "slug": "Pattern-Classification-DrEng",
            "title": {
                "fragments": [],
                "text": "Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": "Springer London"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33340475"
                        ],
                        "name": "A. Oppenheim",
                        "slug": "A.-Oppenheim",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Oppenheim",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oppenheim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693333"
                        ],
                        "name": "R. Schafer",
                        "slug": "R.-Schafer",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Schafer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schafer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124649"
                        ],
                        "name": "T. Stockham",
                        "slug": "T.-Stockham",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Stockham",
                            "middleNames": [
                                "G."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Stockham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36949595,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "174cf6d13ad02785e25c69c8d38ac6272b311879",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to some nonlinear filtering problems through a generalized notion of superposition has proven useful. In this paper this approach is investigated for the nonlinear filtering of signals which can be expressed as products or as convolutions of components. The applications of this approach in audio dynamic range compression and expansion, image enhancement with applications to bandwidth reduction, echo removal, and speech waveform processing are presented."
            },
            "slug": "Nonlinear-filtering-of-multiplied-and-convolved-Oppenheim-Schafer",
            "title": {
                "fragments": [],
                "text": "Nonlinear filtering of multiplied and convolved signals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684353"
                        ],
                        "name": "Jennifer Chu-Carroll",
                        "slug": "Jennifer-Chu-Carroll",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Chu-Carroll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Chu-Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111287403"
                        ],
                        "name": "Michael K. Brown",
                        "slug": "Michael-K.-Brown",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brown",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael K. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3260915,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c448af000e7a7db13da2a8d0de1821eeec9a911c",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we argue for the need to distinguish between task and dialogue initiatives, and present a model for tracking shifts in both types of initiatives in dialogue interactions. Our model predicts the initiative holders in the next dialogue turn based on the current initiative holders and the effect that observed cues have on changing them. Our evaluation across various corpora shows that the use of cues consistently improves the accuracy in the system's prediction of task and dialogue initiative holders by 2-4 and 8-13 percentage points, respectively, thus illustrating the generality of our model."
            },
            "slug": "Tracking-Initiative-in-Collaborative-Dialogue-Chu-Carroll-Brown",
            "title": {
                "fragments": [],
                "text": "Tracking Initiative in Collaborative Dialogue Interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The use of cues consistently improves the accuracy in the system's prediction of task and dialogue initiative holders by 2-4 and 8-13 percentage points, respectively, thus illustrating the generality of the model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1970864"
                        ],
                        "name": "J. Pierrehumbert",
                        "slug": "J.-Pierrehumbert",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Pierrehumbert",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pierrehumbert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142740222,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b44fb1397ea10c4252bfcf10ef5b5ff52431bfcf",
            "isKey": false,
            "numCitedBy": 2274,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Thesis (Ph.D.)--Massachusetts Institute of Technology, Dept. of Linguistics and Philosophy, 1980."
            },
            "slug": "The-phonology-and-phonetics-of-English-intonation-Pierrehumbert",
            "title": {
                "fragments": [],
                "text": "The phonology and phonetics of English intonation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103072546"
                        ],
                        "name": "J. Eagon",
                        "slug": "J.-Eagon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eagon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eagon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14153120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69fc8c03d21e22e30d6642824c37158b314f36c3",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. The object of this note is to prove the theorem below and sketch two applications, one to statistical estimation for (proba-bilistic) functions of Markov processes [l] and one to Blakley's model for ecology [4]. 2. Result. THEOREM. Let P(x)=P({xij}) be a polynomial with nonnegative coefficients homogeneous of degree d in its variables {##}. Let x= {##} be any point of the domain D: ## \u00a7:(), ]pLi ## = 1, i = l, \u2022 \u2022 \u2022 , p, j=l, \u2022 \u2022 \u2022 , q%. For x= {xij} \u00a3\u00a3> let 3(#) = 3{##} denote the point of D whose i, j coordinate is (dP\\ \\ f \u00ab dP 3(*)<i = (Xij 7\u2014) / 2* *<i \u2014 \\ dXij\\(X)// ,-i dXij (\u00bb> Then P(3(x))>P(x) unless 3(x)=x. Notation, fi will denote a doubly indexed array of nonnegative integers: fx= {M#}> i = l> \u2022 \u2022 \u2022 > <lu i=l, \u2022 \u2022 \u2022 , A #* then denotes Ilf-iH\u00ee-i^* Similarly, c M is an abbreviation for C[ MiJ }. The polynomial P({xij}) is then written P(x) = ]CM V^-In our notation : (1) 3(&)*i = (Z) \u00abWnys*) / JLH CpiiijX\u00bb."
            },
            "slug": "An-inequality-with-applications-to-statistical-for-Baum-Eagon",
            "title": {
                "fragments": [],
                "text": "An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123001"
                        ],
                        "name": "K. Colby",
                        "slug": "K.-Colby",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Colby",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Colby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47864374"
                        ],
                        "name": "S. Weber",
                        "slug": "S.-Weber",
                        "structuredName": {
                            "firstName": "Sylvia",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5981444"
                        ],
                        "name": "F. D. Hilf",
                        "slug": "F.-D.-Hilf",
                        "structuredName": {
                            "firstName": "Franklin",
                            "lastName": "Hilf",
                            "middleNames": [
                                "Dennis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Hilf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9395521,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "93ae8b487a312fb6bce19d6db220a26e82623b60",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Artificial-Paranoia-Colby-Weber",
            "title": {
                "fragments": [],
                "text": "Artificial Paranoia"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266388"
                        ],
                        "name": "N. Fraser",
                        "slug": "N.-Fraser",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39762878"
                        ],
                        "name": "N. Gilbert",
                        "slug": "N.-Gilbert",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Gilbert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gilbert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62599969,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "53fb49c7836698ae74b4559e78aeb34c7fe73a6a",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Simulating-speech-systems-Fraser-Gilbert",
            "title": {
                "fragments": [],
                "text": "Simulating speech systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62562997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae9443b39a5abfbf3cc9776173c1ae4f94732408",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a new sequential decoding algorithm is introduced that uses stack storage at the receiver. It is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp the rate below which the average number of decoding steps is bounded by a constant. Practical problems connected with implementing the stack algorithm are discussed and a scheme is described that facilitates satisfactory performance even with limited stack storage capacity. Preliminary simulation results estimating the decoding effort and the needed stack siazree presented."
            },
            "slug": "Fast-sequential-decoding-algorithm-using-a-stack-Jelinek",
            "title": {
                "fragments": [],
                "text": "Fast sequential decoding algorithm using a stack"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new sequential decoding algorithm is introduced that uses stack storage at the receiver that is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2006080"
                        ],
                        "name": "J. D. Gould",
                        "slug": "J.-D.-Gould",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Gould",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145961032"
                        ],
                        "name": "C. Lewis",
                        "slug": "C.-Lewis",
                        "structuredName": {
                            "firstName": "Clayton",
                            "lastName": "Lewis",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13865423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96e5e68087b38a0ea3c9b99145432ad99c9759ca",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Any system designed for people to use should be (a) easy to learn; (b) useful, i.e., contain functions people really need in their work; (c) easy to use; and (d) pleasant to use. In this note we present theoretical considerations and empirical data relevant to attaining these goals. First, we mention four principles for system design which we believe are necessary to attain these goals; Then we present survey results that demonstrate that our principles are not really all that obvious, but just seem obvious once presented. The responses of designers suggest they may sometimes think they are doing what we recommend when in fact they are not. This is consistent with the experience that systems designers do not often recommend or use them themselves. We contrast some of these responses with what we have in mind in order to provide a more useful description of our principles. Lastly, we consider why this might be so. These sections are summaries of those in a longer paper to appear elsewhere (Gould & Lewis, 1983). In that paper we elaborate on our four principles, showing how they form the basis for a general methodology of design, and we describe a successful example of using them in actual system design (IBM's Audio Distribution System)."
            },
            "slug": "Designing-for-usability\u2014key-principles-and-what-Gould-Lewis",
            "title": {
                "fragments": [],
                "text": "Designing for usability\u2014key principles and what designers think"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Any system designed for people to use should be (a) easy to learn; (b) useful, i.e., contain functions people really need in their work; (c)easy to use; and (d) pleasant to use."
            },
            "venue": {
                "fragments": [],
                "text": "CHI '83"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145324717"
                        ],
                        "name": "P. Kidwell",
                        "slug": "P.-Kidwell",
                        "structuredName": {
                            "firstName": "Peggy",
                            "lastName": "Kidwell",
                            "middleNames": [
                                "Aldrich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kidwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6731597,
            "fieldsOfStudy": [
                "Political Science"
            ],
            "id": "0fa2bcaf58ad65d304ecf0306e13cf72cd7532f2",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Taylor & Francis makes every effort to ensure the accuracy of all the information (the \u201cContent\u201d) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content."
            },
            "slug": "The-trouble-with-computers:-Usefulness,-usability-Kidwell",
            "title": {
                "fragments": [],
                "text": "The trouble with computers: Usefulness, usability and productivity"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Annals of the History of Computing"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145738423"
                        ],
                        "name": "Wei Xu",
                        "slug": "Wei-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783635"
                        ],
                        "name": "Alexander I. Rudnicky",
                        "slug": "Alexander-I.-Rudnicky",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Rudnicky",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander I. Rudnicky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15359787,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "092eb54f54947de82718677e90f283016b74d313",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Dialog management addresses two specific problems: (1) providing a coherent overall structure to interaction that extends beyond the single turn, (2) correctly managing mixed-initiative interaction. We propose a dialog management architecture based on the following elements: handlers that manage interaction focussed on tightly coupled sets of information, a product that reflects mutually agreed-upon information and an agenda that orders the topics relevant to task completion."
            },
            "slug": "Task-based-dialog-management-using-an-agenda-Xu-Rudnicky",
            "title": {
                "fragments": [],
                "text": "Task-based dialog management using an agenda"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769629"
                        ],
                        "name": "C. Kamm",
                        "slug": "C.-Kamm",
                        "structuredName": {
                            "firstName": "Candace",
                            "lastName": "Kamm",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kamm"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17056314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "300e4985f44b284bb27cb8264a8caff6cccc704d",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses some of the aspects of task requirements, user expectations, and technological capabilities that influence the design of a voice interface and then identifies several components of user interfaces that are particularly critical in successful voice applications. Examples from several applications are provided to demonstrate how these components are used to produce effective voice interfaces."
            },
            "slug": "User-interfaces-for-voice-applications.-Kamm",
            "title": {
                "fragments": [],
                "text": "User interfaces for voice applications."
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Some of the aspects of task requirements, user expectations, and technological capabilities that influence the design of a voice interface and several components of user interfaces that are particularly critical in successful voice applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748956"
                        ],
                        "name": "R. Fikes",
                        "slug": "R.-Fikes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Fikes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fikes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8623866,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c547e1f79e6039d05c5ae433a36612d7f8e4d3f5",
            "isKey": false,
            "numCitedBy": 5887,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "STRIPS:-A-New-Approach-to-the-Application-of-to-Fikes-Nilsson",
            "title": {
                "fragments": [],
                "text": "STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684353"
                        ],
                        "name": "Jennifer Chu-Carroll",
                        "slug": "Jennifer-Chu-Carroll",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Chu-Carroll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Chu-Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326473"
                        ],
                        "name": "S. Carberry",
                        "slug": "S.-Carberry",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Carberry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carberry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8704366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04be396504a56ba43de4bcc85c637b5c28641ff2",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "In collaborative planning dialogues, the agents have different beliefs about the domain and about each other; thus, it is inevitable that conflicts arise during the planning process. In this paper, we present a plan-based model for response generation during collaborative planning, based on a recursive Propose-Evaluate-Modify framework for modeling collaboration. We focus on identifying strategies for content selection when 1) the system initiates information-sharing to gather further information in order to make an informed decision about whether to accept a proposal from the user, and 2) the system initiates collaborative negotiation to negotiate with the user to resolve a detected conflict in the user's proposal. When our model determines that information-sharing should be pursued, it selects a focus of information-sharing from among multiple uncertainties that might be addressed, chooses an appropriate information-sharing strategy, and formulates a response that initiates an information-sharing subdialogue. When our model determines that conflicts must be resolved, it selects the most effective conflicts to address in resolving disagreement about the user's proposal, identifies appropriate justification for the system's claims, and formulates a response that initiates a negotiation subdialogue."
            },
            "slug": "Collaborative-Response-Generation-in-Planning-Chu-Carroll-Carberry",
            "title": {
                "fragments": [],
                "text": "Collaborative Response Generation in Planning Dialogues"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A plan-based model for response generation during collaborative planning, based on a recursive Propose-Evaluate-Modify framework for modeling collaboration, is presented, which focuses on identifying strategies for content selection when the system initiates information-sharing to gather further information in order to make an informed decision about whether to accept a proposal."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054183458"
                        ],
                        "name": "Jens Allwood",
                        "slug": "Jens-Allwood",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Allwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Allwood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18409651,
            "fieldsOfStudy": [
                "Philosophy",
                "Psychology",
                "Computer Science"
            ],
            "id": "138c9f8bdb4359465c22dfd36f6a7ce22e23ee46",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Le but de l'article est de decrire une approche de la communication et de la pragmatique developpee depuis la moitie des annees 70 sous le nom de Activity based Communication Analysis or Communicative Activity Analysis. L'A. apporte quelques critiques sur les principales contributions theoriques dans lesquelles l'approche a ete articulee comme une reponse, puis presente les idees et les concepts les plus importants en donnant les references d'articles ou l'on peut trouver des argumentations detaillees"
            },
            "slug": "An-activity-based-approach-to-pragmatics-Allwood",
            "title": {
                "fragments": [],
                "text": "An activity-based approach to pragmatics"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Le but de l'article est de decrire une approche de la communication and of the pragmatique developpee depuis la moitie des annees 70 sous le nom of Activity based Communication Analysis or Communicative Activity Analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Abduction, Belief and Context in Dialogue"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400972796"
                        ],
                        "name": "Rub\u00e9n San-Segundo-Hern\u00e1ndez",
                        "slug": "Rub\u00e9n-San-Segundo-Hern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Rub\u00e9n",
                            "lastName": "San-Segundo-Hern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rub\u00e9n San-Segundo-Hern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400972768"
                        ],
                        "name": "J. Montero-Mart\u00ednez",
                        "slug": "J.-Montero-Mart\u00ednez",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Montero-Mart\u00ednez",
                            "middleNames": [
                                "Manuel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Montero-Mart\u00ednez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33913506"
                        ],
                        "name": "J. Pardo",
                        "slug": "J.-Pardo",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Pardo",
                            "middleNames": [
                                "Manuel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pardo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6626547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "222555fee314e36a9c32ec0bf4f2b016b55ffc8f",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose an approach for designing the confirmation strategies in a Railway Information system for Spanish, based on confidence measures obtained from recognition. We also present several error recover and user modelling techniques incorporated in this system. In the field evaluation, it is shown that more than 60% of the confirmations were implicit ones. This kind of confirmations, in combination with fast error recover and user modelling techniques, makes the dialogue faster, obtaining a mean call duration of 204 seconds."
            },
            "slug": "Designing-Confirmation-Mechanisms-and-Error-Recover-San-Segundo-Hern\u00e1ndez-Montero-Mart\u00ednez",
            "title": {
                "fragments": [],
                "text": "Designing Confirmation Mechanisms and Error Recover Techniques in a Railway Information System for Spanish"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An approach for designing the confirmation strategies in a Railway Information system for Spanish, based on confidence measures obtained from recognition, is proposed, and it is shown that more than 60% of the confirmations were implicit ones."
            },
            "venue": {
                "fragments": [],
                "text": "SIGDIAL Workshop"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755630"
                        ],
                        "name": "K. Lochbaum",
                        "slug": "K.-Lochbaum",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Lochbaum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lochbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692242"
                        ],
                        "name": "B. Grosz",
                        "slug": "B.-Grosz",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Grosz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Grosz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2668280"
                        ],
                        "name": "C. Sidner",
                        "slug": "C.-Sidner",
                        "structuredName": {
                            "firstName": "Candace",
                            "lastName": "Sidner",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sidner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16152637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17a9de5698dec2f2edeef93404b5c3542677c677",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Agents collaborating to achieve a goal bring to their joint activity different beliefs about ways in which to achieve the goal and the actions necessary for doing so. Thus, a model of collaboration must provide a way of representing and distinguishing among agents' beliefs and of stating the ways in which the intentions of different agents contribute to achieving their goal. Furthermore, in collaborative activity, collaboration occurs in the planning process itself. Thus, rather than modelling plan recognition, per se, what must be modelled is the augmentation of beliefs about the actions of multiple agents and their intentions. In this paper, we modify and expand the SharedPlan model of collaborative behavior (Grosz & Sidner 1990). We present an algorithm for updating an agent's beliefs about a partial SharedPlan and describe an initial implementation of this algorithm in the domain of network management."
            },
            "slug": "Models-of-Plans-to-Support-Communication:-An-Report-Lochbaum-Grosz",
            "title": {
                "fragments": [],
                "text": "Models of Plans to Support Communication: An Initial Report"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The SharedPlan model of collaborative behavior is modified and expanded and an algorithm for updating an agent's beliefs about a partial SharedPlan is presented and an initial implementation of this algorithm is described in the domain of network management."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2305444"
                        ],
                        "name": "Philip R. Cohen",
                        "slug": "Philip-R.-Cohen",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Cohen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip R. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144039163"
                        ],
                        "name": "Michael Johnston",
                        "slug": "Michael-Johnston",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Johnston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Johnston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31748715"
                        ],
                        "name": "David R. McGee",
                        "slug": "David-R.-McGee",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McGee",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. McGee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807460"
                        ],
                        "name": "S. Oviatt",
                        "slug": "S.-Oviatt",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Oviatt",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Oviatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414661"
                        ],
                        "name": "Josh Clow",
                        "slug": "Josh-Clow",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Clow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh Clow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1989199"
                        ],
                        "name": "Ira A. Smith",
                        "slug": "Ira-A.-Smith",
                        "structuredName": {
                            "firstName": "Ira",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ira A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14172989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f27ebd3735fbf9cb5557c6ceafd7337679bac0e",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on a case study comparison of a directmanipulation-based graphical user interface (GUI) with the QuickSet pen/voice multimodal interface for supporting the task of military force \u201claydown.\u201d In this task, a user places military units and \u201ccontrol measures,\u201d such as various types of lines, obstacles, objectives, etc., on a map. A military expert designed his own scenario and entered it via both interfaces. Usage of QuickSet led to a speed improvement of 3.2 to 8.7fold, depending on the kind of object being created. These results suggest that there may be substantial efficiency advantages to multimodal interaction over GUIs for map-based tasks."
            },
            "slug": "The-efficiency-of-multimodal-interaction:-a-case-Cohen-Johnston",
            "title": {
                "fragments": [],
                "text": "The efficiency of multimodal interaction: a case study"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A case study comparison of a directmanipulation-based graphical user interface (GUI) with the QuickSet pen/voice multi-modal interface for supporting the task of military force \u201claydown\u201d suggests that there may be substantial efficiency advantages to multimodal interaction over GUIs for map-based tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634377"
                        ],
                        "name": "H. Levesque",
                        "slug": "H.-Levesque",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Levesque",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Levesque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2305444"
                        ],
                        "name": "Philip R. Cohen",
                        "slug": "Philip-R.-Cohen",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Cohen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip R. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054462753"
                        ],
                        "name": "Jos\u00e9 H. T. Nunes",
                        "slug": "Jos\u00e9-H.-T.-Nunes",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Nunes",
                            "middleNames": [
                                "H.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 H. T. Nunes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 325504,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "bb4b002a7110a2cc48f86906c65a39dde8d2aba4",
            "isKey": false,
            "numCitedBy": 676,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Joint action by a team does not consist merely of simultaneous and coordinated individual actions; to act together, a team must be aware of and care about the status of the group effort as a whole. We present a formal definition of what it could mean for a group to jointly commit to a common goal, and explore how these joint commitments relate to the individual commitments of the team members. We then consider the case of joint intention, where the goal in question involves the team performing some action. In both cases, the theory is formulated in a logical language of belief, action, and time previously used to characterize individual commitment and intention. An important consequence of the theory is the types of communication among the team members that it predicts will often be necessary."
            },
            "slug": "On-Acting-Together-Levesque-Cohen",
            "title": {
                "fragments": [],
                "text": "On Acting Together"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A formal definition of what it could mean for a group to jointly commit to a common goal is presented, and how these joint commitments relate to the individual commitments of the team members are explored."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414906"
                        ],
                        "name": "J. Nielsen",
                        "slug": "J.-Nielsen",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nielsen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1052093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24be9600fa9b3cbb9cf1b9e3c0666a95afdb073d",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A practical usability engineering process that can be incorporated into the software product development process to ensure the usability of interactive computer products is presented. It is shown that the most basic elements in the usability engineering model are empirical user testing and prototyping, combined with iterative design. Usability activities are presented for three main phases of a software project: before, during, and after product design and implementation. Some of the recommended methods are not really single steps but should be used throughout the development process.<<ETX>>"
            },
            "slug": "The-usability-engineering-life-cycle-Nielsen",
            "title": {
                "fragments": [],
                "text": "The usability engineering life cycle"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the most basic elements in the usability engineering model are empirical user testing and prototyping, combined with iterative design."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786202"
                        ],
                        "name": "H. Bunt",
                        "slug": "H.-Bunt",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Bunt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067413113"
                        ],
                        "name": "W. Black",
                        "slug": "W.-Black",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Black"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6380894,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "cc3e73f0de4835e6b8d5e416542322704e6b75b3",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "1."
            },
            "slug": "The-ABC-of-Computational-Pragmatics-Bunt-Black",
            "title": {
                "fragments": [],
                "text": "The ABC of Computational Pragmatics"
            },
            "venue": {
                "fragments": [],
                "text": "Abduction, Belief and Context in Dialogue"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728478"
                        ],
                        "name": "D. Norman",
                        "slug": "D.-Norman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Norman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Norman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691661"
                        ],
                        "name": "J. Stasko",
                        "slug": "J.-Stasko",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Stasko",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stasko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144972746"
                        ],
                        "name": "Jeff Pierce",
                        "slug": "Jeff-Pierce",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Pierce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Pierce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144297077"
                        ],
                        "name": "C. Potts",
                        "slug": "C.-Potts",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Potts",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Potts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068346878"
                        ],
                        "name": "Chris Shaw",
                        "slug": "Chris-Shaw",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Shaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Shaw"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60305346,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "66de365a8475968897dda4885472c36c5d5e524c",
            "isKey": false,
            "numCitedBy": 8250,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Revealing how smart design is the new competitive frontier, this innovative book is a powerful primer on how--and why--some products satisfy customers while others only frustrate them."
            },
            "slug": "Design-of-Everyday-Things-Norman-Stasko",
            "title": {
                "fragments": [],
                "text": "Design of Everyday Things"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Revealing how smart design is the new competitive frontier, this innovative book is a powerful primer on how--and why--some products satisfy customers while others only frustrate them."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104165905"
                        ],
                        "name": "H. Grice",
                        "slug": "H.-Grice",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Grice",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Grice"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222342276,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "45c33abccd70ac1c016ba32791c463dc2841d0cb",
            "isKey": false,
            "numCitedBy": 506,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Further-Notes-on-Logic-and-Conversation-Grice",
            "title": {
                "fragments": [],
                "text": "Further Notes on Logic and Conversation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69547851"
                        ],
                        "name": "\u6728\u6751 \u548c\u592b",
                        "slug": "\u6728\u6751-\u548c\u592b",
                        "structuredName": {
                            "firstName": "\u6728\u6751",
                            "lastName": "\u548c\u592b",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u6728\u6751 \u548c\u592b"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 211814011,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "eed21ec2be5278a929f03bbbd82a719a2715f270",
            "isKey": false,
            "numCitedBy": 3777,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\u8a9e\u7528\u8ad6(Pragmatics)\u3092\u8003\u3048\u308b-\u6728\u6751",
            "title": {
                "fragments": [],
                "text": "\u8a9e\u7528\u8ad6(Pragmatics)\u3092\u8003\u3048\u308b"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2349671"
                        ],
                        "name": "Cecilia E. Ford",
                        "slug": "Cecilia-E.-Ford",
                        "structuredName": {
                            "firstName": "Cecilia",
                            "lastName": "Ford",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cecilia E. Ford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20082155"
                        ],
                        "name": "S. Thompson",
                        "slug": "S.-Thompson",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 146169809,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6d56316acc55259f6aabd7f4a4dd77ca3707d61f",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interaction-and-grammar:-Interactional-units-in-and-Ford-Thompson",
            "title": {
                "fragments": [],
                "text": "Interaction and grammar: Interactional units in conversation: syntactic, intonational, and pragmatic resources for the management of turns"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114418885"
                        ],
                        "name": "R. Dodge",
                        "slug": "R.-Dodge",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Dodge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dodge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143973938,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c48c677da1dbaef8ad6b3963c5b4d12ed879cb20",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-apperception-of-the-spoken-sentence:-A-study-in-Dodge",
            "title": {
                "fragments": [],
                "text": "The apperception of the spoken sentence: A study in the psychology of language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1901
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2928409"
                        ],
                        "name": "V. Yngve",
                        "slug": "V.-Yngve",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Yngve",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Yngve"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143317921,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "17eb496543b004b9c4215ab51380aae2640d5695",
            "isKey": false,
            "numCitedBy": 887,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-getting-a-word-in-edgewise-Yngve",
            "title": {
                "fragments": [],
                "text": "On getting a word in edgewise"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46386736"
                        ],
                        "name": "E. Schegloff",
                        "slug": "E.-Schegloff",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Schegloff",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Schegloff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142295195,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "06a5daa8d1cb5e06156bcb3120db97c693e9c741",
            "isKey": false,
            "numCitedBy": 1389,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discourse-as-an-interactional-achievement-:-Some-of-Schegloff",
            "title": {
                "fragments": [],
                "text": "Discourse as an interactional achievement : Some uses of \"Uh huh\" and other things that come between sentences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101417471"
                        ],
                        "name": "T. K. Vintsyuk",
                        "slug": "T.-K.-Vintsyuk",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Vintsyuk",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. K. Vintsyuk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123081024,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ade2cc4da5bd8cf447b8435340edcd8b8b10a90a",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-discrimination-by-dynamic-programming-Vintsyuk",
            "title": {
                "fragments": [],
                "text": "Speech discrimination by dynamic programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120208815,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "603bdbb17ba1f909280405a076455ac4f878fbf3",
            "isKey": false,
            "numCitedBy": 2773,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Inference-for-Probabilistic-Functions-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "Statistical Inference for Probabilistic Functions of Finite State Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1451669581"
                        ],
                        "name": "T. Bayes",
                        "slug": "T.-Bayes",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bayes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47633347"
                        ],
                        "name": "W. Deming",
                        "slug": "W.-Deming",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Deming",
                            "middleNames": [
                                "Edwards"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Deming"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056641815"
                        ],
                        "name": "Richard Price",
                        "slug": "Richard-Price",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Price",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98815997"
                        ],
                        "name": "E. C. Molina",
                        "slug": "E.-C.-Molina",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Molina",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. C. Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1451667519"
                        ],
                        "name": "J. Canton",
                        "slug": "J.-Canton",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118486554,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "079e11379044e58ac95599cc581ec30343850bb5",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Facsimiles-of-two-papers-by-Bayes-Bayes-Deming",
            "title": {
                "fragments": [],
                "text": "Facsimiles of two papers by Bayes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1941
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779846"
                        ],
                        "name": "H. Sakoe",
                        "slug": "H.-Sakoe",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Sakoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35805230"
                        ],
                        "name": "S. Chiba",
                        "slug": "S.-Chiba",
                        "structuredName": {
                            "firstName": "Seibi",
                            "lastName": "Chiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chiba"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 107516844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d2eb229c21269ffaa8a85b0961a2bda1116a6c7",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Dynamic-Programming-Approach-to-Continuous-Speech-Sakoe-Chiba",
            "title": {
                "fragments": [],
                "text": "A Dynamic Programming Approach to Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2752827"
                        ],
                        "name": "P. Luce",
                        "slug": "P.-Luce",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Luce",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Luce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859196"
                        ],
                        "name": "D. Pisoni",
                        "slug": "D.-Pisoni",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pisoni",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pisoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34952963"
                        ],
                        "name": "S. Goldinger",
                        "slug": "S.-Goldinger",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Goldinger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldinger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60903251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ede9fe4841eddff99018ab12a2b2842fbae26fc1",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Similarity-neighborhoods-of-spoken-words-Luce-Pisoni",
            "title": {
                "fragments": [],
                "text": "Similarity neighborhoods of spoken words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718274"
                        ],
                        "name": "L. Zadeh",
                        "slug": "L.-Zadeh",
                        "structuredName": {
                            "firstName": "Lotfi",
                            "lastName": "Zadeh",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zadeh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60979109,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "c499c9c21a4aebb1a06ab089e3df1e23148be10b",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Phonological-structures-for-speech-recognition-Cohen-Zadeh",
            "title": {
                "fragments": [],
                "text": "Phonological structures for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145210073"
                        ],
                        "name": "E. Krahmer",
                        "slug": "E.-Krahmer",
                        "structuredName": {
                            "firstName": "Emiel",
                            "lastName": "Krahmer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Krahmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70028865"
                        ],
                        "name": "M. Swerts",
                        "slug": "M.-Swerts",
                        "structuredName": {
                            "firstName": "Mgj",
                            "lastName": "Swerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742430"
                        ],
                        "name": "M. Theune",
                        "slug": "M.-Theune",
                        "structuredName": {
                            "firstName": "Mari\u00ebt",
                            "lastName": "Theune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Theune"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996795"
                        ],
                        "name": "M. F. Weegels",
                        "slug": "M.-F.-Weegels",
                        "structuredName": {
                            "firstName": "Mieke",
                            "lastName": "Weegels",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. F. Weegels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59910869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c09a2d6c44e8fba21242a6ce5549e78b30cdee4",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Error-spotting-in-human-machine-interaction-Krahmer-Swerts",
            "title": {
                "fragments": [],
                "text": "Error spotting in human-machine interaction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4023408"
                        ],
                        "name": "C. Connine",
                        "slug": "C.-Connine",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Connine",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Connine"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57489656,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3839077761a91e6e99b7d3c4be8feadd901241d8",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Effects-of-sentence-context-and-lexical-knowledge-Connine",
            "title": {
                "fragments": [],
                "text": "Effects of sentence context and lexical knowledge in speech processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783635"
                        ],
                        "name": "Alexander I. Rudnicky",
                        "slug": "Alexander-I.-Rudnicky",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Rudnicky",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander I. Rudnicky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28221416,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "0a9c3e87d8521d39ce5167d4c375d1ddd0953951",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "What's-new-in-speech-perception-The-research-and-of-Cole-Rudnicky",
            "title": {
                "fragments": [],
                "text": "What's new in speech perception? The research and ideas of William Chandler Bagley, 1874-1946."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733034"
                        ],
                        "name": "Gina-Anne Levow",
                        "slug": "Gina-Anne-Levow",
                        "structuredName": {
                            "firstName": "Gina-Anne",
                            "lastName": "Levow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gina-Anne Levow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219303300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0da35ce885d46e8f46c77982ad1cf7640227c5ee",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Characterizing-and-Recognizing-Spoken-Corrections-Levow",
            "title": {
                "fragments": [],
                "text": "Characterizing and Recognizing Spoken Corrections in Human-Computer Dialogue"
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892223"
                        ],
                        "name": "Nancy A. Daly",
                        "slug": "Nancy-A.-Daly",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Daly",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy A. Daly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13343004,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "39c6506b38630a612b3228a6477a09ea3fec1ebe",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-and-linguistic-analyses-of-F0-in-read-Daly-Zue",
            "title": {
                "fragments": [],
                "text": "Statistical and linguistic analyses of F0 in read and spontaneous speech"
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145211865"
                        ],
                        "name": "Christine Pao",
                        "slug": "Christine-Pao",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Pao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christine Pao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30673362,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "966e3db3e6286339b2ac339108d4135e8cfb23db",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-cost-of-errors-in-a-spoken-language-system-Hirschman-Pao",
            "title": {
                "fragments": [],
                "text": "The cost of errors in a spoken language system"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1970864"
                        ],
                        "name": "J. Pierrehumbert",
                        "slug": "J.-Pierrehumbert",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Pierrehumbert",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pierrehumbert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049352"
                        ],
                        "name": "Julia Hirschberg",
                        "slug": "Julia-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Hirschberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8959407,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3967a37fc97547eb6a3304166fc29b211dfe96dc",
            "isKey": false,
            "numCitedBy": 1422,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent investigations of the contribution that intonation makes to overall utterance and discourse interpretation promise new sources of information for the investigation of long-time concerns in natural-language processing. In Hirschberg and Pierrehumbert 1986 we proposed that intonational features such as phrasing, accmt pUuttTWIt, pilch rangt, and huIe represent important sources of information about the attmh0ru3l and the rntmt10rIJAl structures of discourse. I In this paper we examine the particular contribution of choice of tune, or int0ru3h0ru3l cantour, to discourse interpretation. In particular, we propose that a speaker (5) chooses a particular tune to convey a particular relationship between an utterance, currently perceived beliefs of a hearer or hearers (H), and anticipated contributions of subsequent utterances. We claim that these relationships are compositionalcomposed from the pitch aumts, phrase QCcmts, and bowndary tones that make up tunes. We further propose that the different aspects of tune meaning can be associated with different phonological domains. We assume the intorIJAtional phrase as our primary unit of meaning analysis. In the following discussion we put forward a first approximation of a compositional theory of tune interpretation. together with the phonological assumptions on which it is based and the evidence from which we have drawn our proposals. We assume Pierrehumbert's Wierrehumbert 198{); Beckman and Pierrehurnbert 1986a) theory of intonational description. which we describe in sections 2-3. In section 4 we present our general approach to intonational meaning. In sections 5 -7 we present the data upon which we base this account. In section 8 we explore avenues of further development for the theory and discuss implications for the study of discourse."
            },
            "slug": "The-Meaning-of-Intonational-Contours-in-the-of-Pierrehumbert-Hirschberg",
            "title": {
                "fragments": [],
                "text": "The Meaning of Intonational Contours in the Interpretation of Discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes that a speaker chooses a particular tune to convey a particular relationship between an utterance, currently perceived beliefs of a hearer or hearers, and anticipated contributions of subsequent utterances, and claims that these relationships are compositionalcomposed from the pitch aumts, phrase QCcmts, and bowndary tones that make up tunes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731353"
                        ],
                        "name": "Norbert Reithinger",
                        "slug": "Norbert-Reithinger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Reithinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norbert Reithinger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56661417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dbe2722c37e200ee458ea871da159ddaf1a7bdf",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Standards-for-Dialogue-Coding-in-Natural-Language-Walker-Reithinger",
            "title": {
                "fragments": [],
                "text": "Standards for Dialogue Coding in Natural Language Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Section 19.10. Summary 77"
            },
            "venue": {
                "fragments": [],
                "text": "Section 19.10. Summary 77"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intonational Phonology. Cambridge Studies in Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Intonational Phonology. Cambridge Studies in Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Section 19.10. Summary 75"
            },
            "venue": {
                "fragments": [],
                "text": "Section 19.10. Summary 75"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meaning. Philosophical Review"
            },
            "venue": {
                "fragments": [],
                "text": "Meaning. Philosophical Review"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic interpretation and dialogue theory, volume 2 The structure of multimodal dialogue"
            },
            "venue": {
                "fragments": [],
                "text": "Dynamic interpretation and dialogue theory, volume 2 The structure of multimodal dialogue"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing non-native speech: Characterizing and adapting to non-native usage in speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Recognizing non-native speech: Characterizing and adapting to non-native usage in speech recognition"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The forwardbackward search algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ICASSP-91"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chapter 19. Dialogue and Conversational Agents"
            },
            "venue": {
                "fragments": [],
                "text": "Chapter 19. Dialogue and Conversational Agents"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SWITCH- BOARD: Telephone speech corpus for research and development"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ICASSP-92"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In recent years her research has focused on machine translation and parameter-based models of first-language syntax acquisition. Teller's address is: Computer Science Department"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Outline of discourse transcription"
            },
            "venue": {
                "fragments": [],
                "text": "Talking Data: Transcription and Coding in Discourse Research"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Carnegie Mellon Pronouncing Dictionary v0"
            },
            "venue": {
                "fragments": [],
                "text": "CMU"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intonational structure in English and Japanese"
            },
            "venue": {
                "fragments": [],
                "text": "Phonology Yearbook"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech analysis and synthesis by prediction of the speech wave"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Acoustical Society of America"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 52
                            }
                        ],
                        "text": "Unlike other texts I have used for this course (see Teller 1995), no supplementary reading is required with SLP."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Review of Natural Language Processing (second edition) by James Allen"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood linear regression for speaker adaptation of HMMs"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Speech and Language"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conversational postulates University of Chicago"
            },
            "venue": {
                "fragments": [],
                "text": "CLS-71 Speech Acts: Syntax and Semantics"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "LDC Catalog: Hub5-LVCSR project. University of Pennsylvania"
            },
            "venue": {
                "fragments": [],
                "text": "LDC"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A taxonomy of illocutionary acts Language, Mind and Knowledge"
            },
            "venue": {
                "fragments": [],
                "text": "Also appears in John R. Searle, Expression and Meaning: Studies in the Theory of Speech Acts"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Natural Language Understanding, second edition"
            },
            "venue": {
                "fragments": [],
                "text": "Benjamin/Cummings, Redwood City, CA."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spoken dialogue and interactive planning"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings ARPA Speech and Natural Language Workshop"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Available at http://www.nist.gov/speech/tools"
            },
            "venue": {
                "fragments": [],
                "text": "Available at http://www.nist.gov/speech/tools"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Penn multiparty standard coding scheme: Draft annotation manual"
            },
            "venue": {
                "fragments": [],
                "text": "Penn multiparty standard coding scheme: Draft annotation manual"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The 1996 Broadcast News speech and language-model corpus"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings DARPA Speech Recognition Workshop"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-site evaluation in DARPA Communicator: The June 2000 data collection"
            },
            "venue": {
                "fragments": [],
                "text": "Cross-site evaluation in DARPA Communicator: The June 2000 data collection"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy approach to adaptive statistical language modeling"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Speech and Language"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The intonational disambiguation of indirect speech acts"
            },
            "venue": {
                "fragments": [],
                "text": "CLS-75"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "State clustering in HMM-based continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Speech and Language"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Transparent vision"
            },
            "venue": {
                "fragments": [],
                "text": "Interaction and Grammar"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dialogue Acts"
            },
            "venue": {
                "fragments": [],
                "text": "Dialogue Acts"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effects of speaking rate and word predictability on conversational pronunciations"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Communication"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The organization of purposeful dialogs"
            },
            "venue": {
                "fragments": [],
                "text": "Linguistics"
            },
            "year": 1979
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 263,
        "totalPages": 27
    },
    "page_url": "https://www.semanticscholar.org/paper/Speech-and-language-processing-an-introduction-to-Jurafsky-Martin/b54bcfca3fddc26b8889739a247a25e445818149?sort=total-citations"
}