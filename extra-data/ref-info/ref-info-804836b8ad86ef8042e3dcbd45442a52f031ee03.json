{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518778"
                        ],
                        "name": "A. Wedel",
                        "slug": "A.-Wedel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Wedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713941"
                        ],
                        "name": "C. Zach",
                        "slug": "C.-Zach",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Zach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Zach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We refine and extend the evaluation methodology of [2] in terms of (1) the performance measures used, (2) the statistics computed, (3) the sub-regions of the images considered, and (4) the use of the World Wide Web for data distribution, results scoring, and results dissemination."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "We obtain our test sequence by downsampling every 20th image taken under visible light\nby a factor of 8, yielding images of size 438\u00d7292, with motions of up to 5 pixels between frames."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17563777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f671859d83f6c19e0af5f5ccfe8aad3681ccc1b",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A look at the Middlebury optical flow benchmark [5] reveals that nowadays variational methods yield the most accurate optical flow fields between two image frames. In this work we propose an improvement variant of the original duality based TV-L 1 optical flow algorithm in [31] and provide implementation details. This formulation can preserve discontinuities in the flow field by employing total variation (TV) regularization. Furthermore, it offers robustness against outliers by applying the robust L 1 norm in the data fidelity term. \n \nOur contributions are as follows. First, we propose to perform a structure-texture decomposition of the input images to get rid of violations in the optical flow constraint due to illumination changes. Second, we propose to integrate a median filter into the numerical scheme to further increase the robustness to sampling artefacts in the image data. We experimentally show that very precise and robust estimation of optical flow can be achieved with a variational approach in real-time. The numerical scheme and the implementation are described in a detailed way, which enables reimplementation of this high-end method."
            },
            "slug": "An-Improved-Algorithm-for-TV-L-1-Optical-Flow-Wedel-Pock",
            "title": {
                "fragments": [],
                "text": "An Improved Algorithm for TV-L 1 Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes an improvement variant of the original duality based TV-L 1 optical flow algorithm that can preserve discontinuities in the flow field by employing total variation (TV) regularization and integrates a median filter into the numerical scheme to further increase the robustness to sampling artefacts in the image data."
            },
            "venue": {
                "fragments": [],
                "text": "Statistical and Geometrical Approaches to Visual Motion Analysis"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697964"
                        ],
                        "name": "S. Negahdaripour",
                        "slug": "S.-Negahdaripour",
                        "structuredName": {
                            "firstName": "Shahriar",
                            "lastName": "Negahdaripour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Negahdaripour"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1451247,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "73db80cfd94e1cce946a1cad6f0865ec71a024b8",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow has been commonly defined as the apparent motion of image brightness patterns in an image sequence. In this paper, we propose a revised definition to overcome shortcomings in interpreting optical flow merely as a geometric transformation field. The new definition is a complete representation of geometric and radiometric variations in dynamic imagery. We argue that this is more consistent with the common interpretation of optical flow induced by various scene events. This leads to a general framework for the investigation of problems in dynamic scene analysis, based on the integration and unified treatment of both geometric and radiometric cues in time-varying imagery. We discuss selected models, including the generalized dynamic image model, for the estimation of optical flow. We show how various 3D scene information are encoded in, and thus may be extracted from, the geometric and radiometric components of optical flow. We provide selected examples based on experiments with real images."
            },
            "slug": "Revised-Definition-of-Optical-Flow:-Integration-of-Negahdaripour",
            "title": {
                "fragments": [],
                "text": "Revised Definition of Optical Flow: Integration of Radiometric and Geometric Cues for Dynamic Scene Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A revised definition of optical flow is proposed to overcome shortcomings in interpreting optical flow merely as a geometric transformation field and leads to a general framework for the investigation of problems in dynamic scene analysis, based on the integration and unified treatment of both geometric and radiometric cues in time-varying imagery."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716758"
                        ],
                        "name": "B. McCane",
                        "slug": "B.-McCane",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "McCane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. McCane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2169548"
                        ],
                        "name": "K. Novins",
                        "slug": "K.-Novins",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Novins",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Novins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3258424"
                        ],
                        "name": "D. Crannitch",
                        "slug": "D.-Crannitch",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Crannitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Crannitch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38011631"
                        ],
                        "name": "B. Galvin",
                        "slug": "B.-Galvin",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Galvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Galvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "We also crosscheck the results by tracking each pixel both forwards and backwards through the sequence and require perfect correspondence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2481018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9db7704e2a1dfbd2b97d51f77638c6c4efa0680c",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Evaluating the performance of optical flow algorithms has been difficult because of the lack of ground truth data sets for complex scenes. We present a new method for generating motion fields from real sequences containing polyhedral objects and present a test suite for benchmarking optical flow algorithms consisting of complex synthetic sequences and real scenes with ground truth. We provide a preliminary quantitative evaluation of seven optical flow algorithms using these synthetic and real sequences. Ultimately, we feel that researchers should benchmark their own algorithms using a standard suite. To that end, we offer our Web site as a repository for standard sequences and results."
            },
            "slug": "On-Benchmarking-Optical-Flow-McCane-Novins",
            "title": {
                "fragments": [],
                "text": "On Benchmarking Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new method for generating motion fields from real sequences containing polyhedral objects is presented and a test suite for benchmarking optical flow algorithms consisting of complex synthetic sequences and real scenes with ground truth is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1849941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5a42788e0ffcf73f59cdc1f8eca5144f4054c43",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new methodology for evaluating the quality of motion estimation and stereo correspondence algorithms. Motivated by applications such as novel view generation and motion-compensated compression, we suggest that the ability to predict new views or frames is a natural metric for evaluating such algorithms. Our new metric has several advantages over comparing algorithm outputs to true motions or depths. First of all, it does not require the knowledge of ground truth data, which may be difficult or laborious to obtain. Second, it more closely matches the ultimate requirements of the application, which are typically tolerant of errors in uniform color regions, but very sensitive to isolated pixel errors or disocclusion errors. In the paper we develop a number of error metrics based on this paradigm, including forward and inverse prediction errors, residual motion error and local motion-compensated prediction error. We show results on a number of widely used motion and stereo sequences, many of which do not have associated ground truth data."
            },
            "slug": "Prediction-error-as-a-quality-metric-for-motion-and-Szeliski",
            "title": {
                "fragments": [],
                "text": "Prediction error as a quality metric for motion and stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A number of error metrics are developed, including forward and inverse prediction errors, residual motion error and local motion-compensated prediction error, which match the ultimate requirements of the application, which are typically tolerant of errors in uniform color regions, but very sensitive to isolated pixel errors or disocclusion errors."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32310897"
                        ],
                        "name": "T. Nir",
                        "slug": "T.-Nir",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Nir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143610924"
                        ],
                        "name": "A. Bruckstein",
                        "slug": "A.-Bruckstein",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Bruckstein",
                            "middleNames": [
                                "Marcel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bruckstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143923265"
                        ],
                        "name": "R. Kimmel",
                        "slug": "R.-Kimmel",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Kimmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kimmel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 51
                            }
                        ],
                        "text": "These constraints have both been strictly enforced (Adiv 1985; Hanna 1991; Nir et al. 2008) and added as a soft prior (Wedel et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 45
                            }
                        ],
                        "text": "A related approach is to use an affine prior (Ju et al. 1996; Ju 1998; Nir et al. 2008; Seitz and Baker 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 46
                            }
                        ],
                        "text": "One approach is to over-parameterize the flow (Nir et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 73
                            }
                        ],
                        "text": "A wide variety of energy functions do satisfy this requirement including (Horn and Schunck 1981; Bruhn et al. 2005; Brox et al. 2004; Nir et al. 2008; Zimmer et al. 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7726895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8c2872f450abd501008244da0a16cc2da530cfbd",
            "isKey": true,
            "numCitedBy": 129,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nA novel optical flow estimation process based on a spatio-temporal model with varying coefficients multiplying a set of basis functions at each pixel is introduced. Previous optical flow estimation methodologies did not use such an over parameterized representation of the flow field as the problem is ill-posed even without introducing any additional parameters: Neighborhood based methods of the Lucas\u2013Kanade type determine the flow at each pixel by constraining the flow to be described by a few parameters in small neighborhoods. Modern variational methods represent the optic flow directly via the flow field components at each pixel. The benefit of over-parametrization becomes evident in the smoothness term, which instead of directly penalizing for changes in the optic flow, accumulates a cost of deviating from the assumed optic flow model. Our proposed method is very general and the classical variational optical flow techniques are special cases of it, when used in conjunction with constant basis functions. Experimental results with the novel flow estimation process yield significant improvements with respect to the best results published so far.\n"
            },
            "slug": "Over-Parameterized-Variational-Optical-Flow-Nir-Bruckstein",
            "title": {
                "fragments": [],
                "text": "Over-Parameterized Variational Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A novel optical flow estimation process based on a spatio-temporal model with varying coefficients multiplying a set of basis functions at each pixel is introduced, which results in significant improvements with respect to the best results published so far."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 218
                            }
                        ],
                        "text": "Rather than manually making these decision and tuning parameters, learning algorithms have been used to choose the data and prior terms and optimize their parameters by maximizing performance on a set of training data (Roth and Black 2007; Sun et al. 2008; Li and Huttenlocher 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 134
                            }
                        ],
                        "text": "Note that some penalty (log probability) functions have probabilistic interpretations related to the distribution of flow derivatives (Roth and Black 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2127708,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a15488466ee9d465e5caf739b4b035d2b8dda197",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an analysis of the spatial and temporal statistics of \u201cnatural\u201d optical flow fields and a novel flow algorithm that exploits their spatial statistics. Training flow fields are constructed using range images of natural scenes and 3D camera motions recovered from hand-held and car-mounted video sequences. A detailed analysis of optical flow statistics in natural scenes is presented and machine learning methods are developed to learn a Markov random field model of optical flow. The prior probability of a flow field is formulated as a Field-of-Experts model that captures the spatial statistics in overlapping patches and is trained using contrastive divergence. This new optical flow prior is compared with previous robust priors and is incorporated into a recent, accurate algorithm for dense optical flow computation. Experiments with natural and synthetic sequences illustrate how the learned optical flow prior quantitatively improves flow accuracy and how it captures the rich spatial structure found in natural scene motion."
            },
            "slug": "On-the-Spatial-Statistics-of-Optical-Flow-Roth-Black",
            "title": {
                "fragments": [],
                "text": "On the Spatial Statistics of Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experiments with natural and synthetic sequences illustrate how the learned optical flow prior quantitatively improves flow accuracy and how it captures the rich spatial structure found in natural scene motion."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144574904"
                        ],
                        "name": "Li Xu",
                        "slug": "Li-Xu",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108284086"
                        ],
                        "name": "Jianing Chen",
                        "slug": "Jianing-Chen",
                        "structuredName": {
                            "firstName": "Jianing",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianing Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729056"
                        ],
                        "name": "Jiaya Jia",
                        "slug": "Jiaya-Jia",
                        "structuredName": {
                            "firstName": "Jiaya",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiaya Jia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 105
                            }
                        ],
                        "text": "Several methods first segment the scene using nonmotion cues and then estimate the flow in these regions (Black and Jepson 1996; Xu et al. 2008; Fuh and Maragos 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 208
                            }
                        ],
                        "text": "Explicit occlusion estimation, for example through crosschecking flows computed forwards and backwards in time, is another approach that can be used to improve robustness to occlusions and visibility changes (Xu et al. 2008; Lei and Yang 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 116
                            }
                        ],
                        "text": "Such sparse matching method can be combined with the continuous energy minimization approaches in a variety of ways (Brox et al. 2009; Liu et al. 2008; Ren 2008; Xu et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117945678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d69fef93c360d2d00ea39a7bbff2430817b10ee0",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation has gained in popularity in stereo matching. However, it is not trivial to incorporate it in optical flow estimation due to the possible non-rigid motion problem. In this paper, we describe a new optical flow scheme containing three phases. First, we partition the input images and integrate the segmentation information into a variational model where each of the segments is constrained by an affine motion. Then the errors brought in by segmentation are measured and stored in a confidence map. The final flow estimation is achieved through a global optimization phase that minimizes an energy function incorporating the confidence map. Extensive experiments show that the proposed method not only produces quantitatively accurate optical flow estimates but also preserves sharp motion boundaries, which makes the optical flow result usable in a number of computer vision applications, such as image/video segmentation and editing."
            },
            "slug": "A-Segmentation-Based-Variational-Model-for-Accurate-Xu-Chen",
            "title": {
                "fragments": [],
                "text": "A Segmentation Based Variational Model for Accurate Optical Flow Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new optical flow scheme containing three phases that not only produces quantitatively accurate optical flow estimates but also preserves sharp motion boundaries, which makes the optical flow result usable in a number of computer vision applications, such as image/video segmentation and editing."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055354"
                        ],
                        "name": "M. Otte",
                        "slug": "M.-Otte",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Otte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Otte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37550305,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "90c2b51a82968c3ee7d3a2b83b6de80237b94d56",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution investigates local differential techniques for estimating optical flow and its derivatives based on the brightness change constraint. By using the tensor calculus representation we build the Taylor expansion of the gray-value derivatives as well as of the optical flow in a spatiotemporal neighborhood. Such a formulation simplifies a unifying framework for all existing local differential approaches and allows to derive new systems of equations to estimate the optical flow and its derivatives. We also tested various optical flow estimation approaches on real image sequences recorded by a calibrated camera fixed on the arm of a robot. By moving the arm of the robot along a precisely defined trajectory we can determine the true displacement rate of scene surface elements projected into the image plane and compare it quantitatively with the results of different optical flow estimators."
            },
            "slug": "Optical-Flow-Estimation:-Advances-and-Comparisons-Otte-Nagel",
            "title": {
                "fragments": [],
                "text": "Optical Flow Estimation: Advances and Comparisons"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This contribution investigates local differential techniques for estimating optical flow and its derivatives based on the brightness change constraint by using the tensor calculus representation and builds the Taylor expansion of the gray-value derivatives as well as of the optical flow in a spatiotemporal neighborhood."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110423572"
                        ],
                        "name": "Yunpeng Li",
                        "slug": "Yunpeng-Li",
                        "structuredName": {
                            "firstName": "Yunpeng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunpeng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather than manually making these decision and tuning parameters, learning algorithms have been used to choose the data and prior terms and optimize their parameters by maximizing performance on a set of training data (Roth and Black 2007; Sun et al. 2008;  Li and Huttenlocher 2008 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "CBF (Trobin et al. 2008) 69 SPSA-learn ( Li and Huttenlocher 2008 ) 200"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The training set includes the ground truth and is meant to be used for debugging, parameter estimation, and possibly even learning (Sun et al. 2008;  Li and Huttenlocher 2008 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14924989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "845cdefd119f5c9afc79dee410d74885595959b4",
            "isKey": true,
            "numCitedBy": 46,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for learning the parameters of a continuous-state Markov random field (MRF) model of optical flow, by minimizing the training loss for a set of ground-truth images using simultaneous perturbation stochastic approximation (SPSA). The use of SPSA to directly minimize the training loss offers several advantages over most previous work on learning MRF models for low-level vision, which instead seek to maximize the likelihood of the data given the model parameters. In particular, our approach explicitly optimizes the error criterion used to evaluate the quality of the flow field, naturally handles missing data values in the ground truth, and does not require the kinds of approximations that current methods use to address the intractable nature of maximum-likelihood estimation for such problems. We show that our method achieves state-of-the-art results and requires only a very small number of training images. We also find that our method generalizes well to unseen data, including data with quite different characteristics than the training set."
            },
            "slug": "Learning-for-Optical-Flow-Using-Stochastic-Li-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Learning for Optical Flow Using Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work presents a technique for learning the parameters of a continuous-state Markov random field model of optical flow, by minimizing the training loss for a set of ground-truth images using simultaneous perturbation stochastic approximation (SPSA)."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2677311"
                        ],
                        "name": "W. Enkelmann",
                        "slug": "W.-Enkelmann",
                        "structuredName": {
                            "firstName": "Wilfried",
                            "lastName": "Enkelmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Enkelmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling (Lucas and Kanade 1981; Glazer et al. 1983 ;B urt et al.1983;  Enkelman 1986;  Anandan 1989; Black and Anandan 1996; Battiti et al. 1991; Bruhn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2461604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36161ff10beeaf8bc2edb585d91dc1dad31bda80",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Investigations-of-multigrid-algorithms-for-the-of-Enkelmann",
            "title": {
                "fragments": [],
                "text": "Investigations of multigrid algorithms for the estimation of optical flow fields in image sequences"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144542135"
                        ],
                        "name": "D. Mahajan",
                        "slug": "D.-Mahajan",
                        "structuredName": {
                            "firstName": "Dhruv",
                            "lastName": "Mahajan",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mahajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37021642"
                        ],
                        "name": "Fu-Chung Huang",
                        "slug": "Fu-Chung-Huang",
                        "structuredName": {
                            "firstName": "Fu-Chung",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fu-Chung Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752521"
                        ],
                        "name": "W. Matusik",
                        "slug": "W.-Matusik",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Matusik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Matusik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752236"
                        ],
                        "name": "R. Ramamoorthi",
                        "slug": "R.-Ramamoorthi",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Ramamoorthi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ramamoorthi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16721163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d746c54a1636c448e98c16bc6fb8ce07aeeb042e",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for plausible interpolation of images, with a wide range of applications like temporal up-sampling for smooth playback of lower frame rate video, smooth view interpolation, and animation of still images. The method is based on the intuitive idea, that a given pixel in the interpolated frames traces out a path in the source images. Therefore, we simply move and copy pixel gradients from the input images along this path. A key innovation is to allow arbitrary (asymmetric) transition points, where the path moves from one image to the other. This flexible transition preserves the frequency content of the originals without ghosting or blurring, and maintains temporal coherence. Perhaps most importantly, our framework makes occlusion handling particularly simple. The transition points allow for matches away from the occluded regions, at any suitable point along the path. Indeed, occlusions do not need to be handled explicitly at all in our initial graph-cut optimization. Moreover, a simple comparison of computed path lengths after the optimization, allows us to robustly identify occluded regions, and compute the most plausible interpolation in those areas. Finally, we show that significant improvements are obtained by moving gradients and using Poisson reconstruction."
            },
            "slug": "Moving-gradients:-a-path-based-method-for-plausible-Mahajan-Huang",
            "title": {
                "fragments": [],
                "text": "Moving gradients: a path-based method for plausible image interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A method for plausible interpolation of images, with a wide range of applications like temporal up-sampling for smooth playback of lower frame rate video, smooth view interpolation, and animation of still images, to allow arbitrary (asymmetric) transition points, where the path moves from one image to the other."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681442"
                        ],
                        "name": "Ce Liu",
                        "slug": "Ce-Liu",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Of the various possible techniques\u2014synthetic data (Barron et al. 1994; McCane et al. 2001), some form of hidden markers (Mova LLC 2004; Tappen et al. 2006; Ramnath et al. 2008), human annotation ( Liu et al. 2008 ), interpolation data (Szeliski 1999), and modified stereo data (Scharstein and Szeliski 2003)\u2014the authors believe that synthetic data is probably the best approach (although generating high-quality synthetic data is not as easy as ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example a Field-of-Experts formulation is used in Sun et al. (2008) and SIFT features are used in  Liu et al. (2008) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, Liu et al. recently proposed a method to obtain ground-truth using human annotation ( Liu et al. 2008 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Such sparse matching method can be combined with the continuous energy minimization approaches in a variety of ways (Brox et al. 2009;  Liu et al. 2008 ; R en2008; Xu et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Most recently  Liu et al. (2008)  proposed a dataset of real imagery that uses hand segmentation and computed flow estimates within the segmented regions to generate the ground truth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 274393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e34055f68c0fcf439dfb986b126189a55c53d22",
            "isKey": true,
            "numCitedBy": 191,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Obtaining ground-truth motion for arbitrary, real-world video sequences is a challenging but important task for both algorithm evaluation and model design. Existing ground-truth databases are either synthetic, such as the Yosemite sequence, or limited to indoor, experimental setups, such as the database developed by Baker et al (2007). We propose a human-in-loop methodology to create a ground-truth motion database for the videos taken with ordinary cameras in both indoor and outdoor scenes, using the fact that human beings are experts at segmenting objects and inspecting the match between two frames. We designed an interactive computer vision system to allow a user to efficiently annotate motion. Our methodology is cross-validated by showing that human annotated motion is repeatable, consistent across annotators, and close to the ground truth obtained by Baker et al (2007). Using our system, we collected and annotated 10 indoor and outdoor real-world videos to form a ground-truth motion database. The source code, annotation tool and database is online for public evaluation and benchmarking."
            },
            "slug": "Human-assisted-motion-annotation-Liu-Freeman",
            "title": {
                "fragments": [],
                "text": "Human-assisted motion annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a human-in-loop methodology to create a ground-truth motion database for the videos taken with ordinary cameras in both indoor and outdoor scenes, using the fact that human beings are experts at segmenting objects and inspecting the match between two frames."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232265"
                        ],
                        "name": "Deqing Sun",
                        "slug": "Deqing-Sun",
                        "structuredName": {
                            "firstName": "Deqing",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deqing Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153024876"
                        ],
                        "name": "J. P. Lewis",
                        "slug": "J.-P.-Lewis",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lewis",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another extremal approach ( Sun et al. 2008 ), closely related to the variational algorithms is to use:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather than manually making these decision and tuning parameters, learning algorithms have been used to choose the data and prior terms and optimize their parameters by maximizing performance on a set of training data (Roth and Black 2007;  Sun et al. 2008;  Li and Huttenlocher 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, Nagel and Enkelmann (1986) and Werlberger et al. (2009) weight the direction along the image gradient less than the direction orthogonal to it, and  Sun et al. (2008)  learn a Steerable Random Field to define the weighting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Complementary OF (Zimmer et al. 2009) 44 Learning Flow ( Sun et al. 2008 ) 825"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The training set includes the ground truth and is meant to be used for debugging, parameter estimation, and possibly even learning ( Sun et al. 2008;  Li and Huttenlocher 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "One advantage of the early parameterization and the subsequent use of (17) is that it reduces the restrictions on the functional form of EGlobal, important in learning-based approaches ( Sun et al. 2008 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example a Field-of-Experts formulation is used in  Sun et al. (2008)  and SIFT features are used in Liu et al. (2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 969406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad61eebde119131f845dc902e1c8f7a4c6d66233",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Assumptions of brightness constancy and spatial smoothness underlie most optical flow estimation methods. In contrast to standard heuristic formulations, we learn a statistical model of both brightness constancy error and the spatial properties of optical flow using image sequences with associated ground truth flow fields. The result is a complete probabilistic model of optical flow. Specifically, the ground truth enables us to model how the assumption of brightness constancy is violated in naturalistic sequences, resulting in a probabilistic model of \"brightness inconstancy\". We also generalize previous high-order constancy assumptions, such as gradient constancy, by modeling the constancy of responses to various linear filters in a high-order random field framework. These filters are free variables that can be learned from training data. Additionally we study the spatial structure of the optical flow and how motion boundaries are related to image intensity boundaries. Spatial smoothness is modeled using a Steerable Random Field, where spatial derivatives of the optical flow are steered by the image brightness structure. These models provide a statistical motivation for previous methods and enable the learning of all parameters from training data. All proposed models are quantitatively compared on the Middlebury flow dataset."
            },
            "slug": "Learning-Optical-Flow-Sun-Roth",
            "title": {
                "fragments": [],
                "text": "Learning Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The ground truth enables us to model how the assumption of brightness constancy is violated in naturalistic sequences, resulting in a probabilistic model of \"brightness inconstancy\", and generalize previous high- order constancy assumptions by modeling the constancy of responses to various linear filters in a high-order random field framework."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Brox et al. (Brox et al. 2004) 18 Group Flow ( Ren 2008 ) 600"
                    },
                    "intents": []
                }
            ],
            "corpusId": 7023164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63ae1ec3d0754b073f90eaa7f5aa5ee9a9b49612",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow estimation requires spatial integration, which essentially poses a grouping question: what points belong to the same motion and what do not. Classical local approaches to optical flow, such as Lucas-Kanade, use isotropic neighborhoods and have considerable difficulty near motion boundaries. In this work we utilize image-based grouping to facilitate spatial- and scale-adaptive integration. We define soft spatial support using pairwise affinities computed through intervening contour. We sample images at edges and corners, and iteratively estimate affine motion at sample points. Figure-ground organization further improves grouping and flow estimation near boundaries. We show that affinity-based spatial integration enables reliable flow estimation and avoids erroneous motion propagation from and/or across object boundaries. We demonstrate our approach on the Middlebury flow dataset."
            },
            "slug": "Local-grouping-for-optical-flow-Ren",
            "title": {
                "fragments": [],
                "text": "Local grouping for optical flow"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work utilizes image-based grouping to facilitate spatial- and scale-adaptive integration and defines soft spatial support using pairwise affinities computed through intervening contour, and iteratively estimate affine motion at sample points."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700994"
                        ],
                        "name": "R. Battiti",
                        "slug": "R.-Battiti",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Battiti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Battiti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704341"
                        ],
                        "name": "E. Amaldi",
                        "slug": "E.-Amaldi",
                        "structuredName": {
                            "firstName": "Edoardo",
                            "lastName": "Amaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Amaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling (Lucas and Kanade 1981; Glazer et al. 1983 ;B urt et al.1983; Enkelman 1986; Anandan 1989; Black and Anandan 1996;  Battiti et al. 1991;  Bruhn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24439033,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "fe0670cf66aa89326358647d2d0d7044174a55fc",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Single-scale approaches to the determination of the optical flow field from the time-varying brightness pattern assume that spatio-temporal discretization is adequate for representing the patterns and motions in a scene. However, the choice of an appropriate spatial resolution is subject to conflicting, scene-dependent, constraints. In intensity-base methods for recovering optical flow, derivative estimation is more accurate for long wavelengths and slow velocities (with respect to the spatial and temporal discretization steps). On the contrary, short wavelengths and fast motions are required in order to reduce the errors caused by noise in the image acquisition and quantization process.Estimating motion across different spatial scales should ameliorate this problem. However, homogeneous multiscale approaches, such as the standard multigrid algorithm, do not improve this situation, because an optimal velocity estimate at a given spatial scale is likely to be corrupted at a finer scale. We propose an adaptive multiscale method, where the discretization scale is chosen locally according to an estimate of the relative error in the velocity estimation, based on image properties.Results for synthetic and video-acquired images show that our coarse-to-fine method, fully parallel at each scale, provides substantially better estimates of optical flow than do conventional algorithms, while adding little computational cost."
            },
            "slug": "Computing-optical-flow-across-multiple-scales:-An-Battiti-Amaldi",
            "title": {
                "fragments": [],
                "text": "Computing optical flow across multiple scales: An adaptive coarse-to-fine strategy"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes an adaptive multiscale method, where the discretization scale is chosen locally according to an estimate of the relative error in the velocity estimation, based on image properties, and provides substantially better estimates of optical flow than do conventional algorithms, while adding little computational cost."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98661254"
                        ],
                        "name": "C. Lei",
                        "slug": "C.-Lei",
                        "structuredName": {
                            "firstName": "Cheng",
                            "lastName": "Lei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "DPOF ( Lei and Yang 2009 ), which involves segmentation and performs best on Grove, does particular poorly on Yosemite presumably because segmenting the grayscale Yosemite sequence is difficult."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Algorithms such as CBF (Trobin et al. 2008) and DPOF ( Lei and Yang 2009 ), which are relatively robust but not so accurate (compare the performance of these algorithms for R0.5 and R2.0 in Fig. 9), therefore perform worse in terms of R2.5 than they do in terms of R5.0 and R10.0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Only a few algorithms (e.g., DPOF\u2014 Lei and Yang 2009,  Fusion\u2014Lempitsky et al. 2008, and Dynamic MRF\u2014Glocker et al. 2008) perform well in this region."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A possible exception is DPOF ( Lei and Yang 2009 )"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The algorithm of  Lei and Yang (2009)  also sparsely allocates states across space and for the possible flows at each spatial location."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Fig. 13 A comparison of the flow and interpolation results for DPOF ( Lei and Yang 2009 ) and CBF (Trobin et al. 2008 )o n theTeddy sequence to illustrate the differences between the two measures of performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "DPOF ( Lei and Yang 2009 ) is a segmentation-based discrete optimization algorithm, followed by a continuous refinement (Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An illustration of this point is included in Fig. 13 .W e include both flow and interpolation results for DPOF ( Lei and Yang 2009 ) and CBF (Trobin et al. 2008 )o n theTeddy sequence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, the performance of DPOF ( Lei and Yang 2009 ) improves dramatically from R0.5 to R2.0 and similarly from A50 to A95."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A possible exception is DPOF ( Lei and Yang 2009 )."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "DPOF ( Lei and Yang 2009 ) 261 Graph Cuts (Cooke 2008) 1,200"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Explicit occlusion estimation, for example through crosschecking flows computed forwards and backwards in time, is another approach that can be used to improve robustness to occlusions and visibility changes (Xu et al. 2008;  Lei and Yang 2009 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6978040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f17ef1fbce97d082b480e160d837a17ff9f5cc41",
            "isKey": true,
            "numCitedBy": 79,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new region-based method for accurate motion estimation using discrete optimization. In particular, the input image is represented as a tree of over-segmented regions and the optical flow is estimated by optimizing an energy function defined on such a region-tree using dynamic programming. To accommodate the sampling-inefficiency problem intrinsic to discrete optimization compared to the continuous optimization based methods, both spatial and solution domain coarse-to-fine (C2F) strategies are used. That is, multiple region-trees are built using different over-segmentation granularities. Starting from a global displacement label discretization, optical flow estimation on the coarser level region-tree is used for defining region-wise finer displacement samplings for finer level region-trees. Furthermore, cross-checking based occlusion detection and correction and continuous optimization are also used to improve accuracy. Extensive experiments using the Middlebury benchmark datasets have shown that our proposed method can produce top-ranking results."
            },
            "slug": "Optical-flow-estimation-on-coarse-to-fine-using-Lei-Yang",
            "title": {
                "fragments": [],
                "text": "Optical flow estimation on coarse-to-fine region-trees using discrete optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new region-based method for accurate motion estimation using discrete optimization of over-segmented regions and the optical flow is estimated by optimizing an energy function defined on a region-tree using dynamic programming."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15808204"
                        ],
                        "name": "J. Barron",
                        "slug": "J.-Barron",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Barron",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Barron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46818737"
                        ],
                        "name": "S. Beauchemin",
                        "slug": "S.-Beauchemin",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Beauchemin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Beauchemin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "We follow the procedure in [19] and compute the error measure statistics over 3 types of region masks: all, motion discontinuities, and textureless regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Optical flow was actually one of the first areas to have such benchmark datasets for quantitative comparison [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "Although the full histograms are available in a longer technical report, Barron et al. [2] report averages (AV) and standard deviations (SD) of the error measures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "We build a scene that can be moved in very small steps by a computercontrolled motion stage."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 177
                            }
                        ],
                        "text": "This high-frequency texture then effectively disappears in the low-resolution images, while the fluorescent paint is very visible in the highresolution UV images (see Figure 2, rightmost column)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1290100,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "400f4afb2a055d95483d83c4bedab10281a8639d",
            "isKey": true,
            "numCitedBy": 4068,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": "While different optical flow techniques continue to appear, there has been a lack of quantitative evaluation of existing methods. For a common set of real and synthetic image sequences, we report the results of a number of regularly cited optical flow techniques, including instances of differential, matching, energy-based, and phase-based methods. Our comparisons are primarily empirical, and concentrate on the accuracy, reliability, and density of the velocity measurements; they show that performance can differ significantly among the techniques we implemented."
            },
            "slug": "Performance-of-optical-flow-techniques-Barron-Fleet",
            "title": {
                "fragments": [],
                "text": "Performance of optical flow techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These comparisons are primarily empirical, and concentrate on the accuracy, reliability, and density of the velocity measurements; they show that performance can differ significantly among the techniques the authors implemented."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83165362"
                        ],
                        "name": "Iain Matthews",
                        "slug": "Iain-Matthews",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Matthews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iain Matthews"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The goal is then to optimize EGlobal with respect to f .T he simplest gradient descent algorithm is steepest descent ( Baker and Matthews 2004 ), which takes steps in the direction of the negative gradient \u2212 \u2202EGlobal \u2202f . An important question with"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2202fi \u2202fj . Algorithms that use the Hessian matrix or approximations to it such as the Newton method, Quasi-Newton methods, the Gauss-Newton method, and the Levenberg-Marquardt algorithm ( Baker and Matthews 2004 ) all converge far faster."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 186689463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "389110a28961ebe80d8856cd204f8d8305a260ef",
            "isKey": false,
            "numCitedBy": 3039,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow and tracking to layered motion, mosaic construction, and face coding. Numerous algorithms have been proposed and a wide variety of extensions have been made to the original formulation. We present an overview of image alignment, describing most of the algorithms and their extensions in a consistent framework. We concentrate on the inverse compositional algorithm, an efficient algorithm that we recently proposed. We examine which of the extensions to Lucas-Kanade can be used with the inverse compositional algorithm without any significant loss of efficiency, and which cannot. In this paper, Part 1 in a series of papers, we cover the quantity approximated, the warp update rule, and the gradient descent approximation. In future papers, we will cover the choice of the error function, how to allow linear appearance variation, and how to impose priors on the parameters."
            },
            "slug": "Lucas-Kanade-20-Years-On:-A-Unifying-Framework-Baker-Matthews",
            "title": {
                "fragments": [],
                "text": "Lucas-Kanade 20 Years On: A Unifying Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An overview of image alignment is presented, describing most of the algorithms and their extensions in a consistent framework and concentrating on the inverse compositional algorithm, an efficient algorithm that was recently proposed."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703041"
                        ],
                        "name": "C. Fuh",
                        "slug": "C.-Fuh",
                        "structuredName": {
                            "firstName": "Chiou-Shann",
                            "lastName": "Fuh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fuh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750686"
                        ],
                        "name": "P. Maragos",
                        "slug": "P.-Maragos",
                        "structuredName": {
                            "firstName": "Petros",
                            "lastName": "Maragos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Maragos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Several methods first segment the scene using nonmotion cues and then estimate the flow in these regions (Black and Jepson 1996 ;X u et al.2008;  Fuh and Maragos 1989 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14559905,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0481bc55132203d9662abec744fadace3b041d14",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A correspondence method is developed for determining optical flow where the primitive motion tokens to be matched between consecutive time frames are regions. The computation of optical flow consists of three stages: region extraction, region matching, and optical flow smoothing. The computation is completed by smoothing the initial optical flow, where the sparse velocity data are either smoothed with a vector median filter or interpolated to obtain dense velocity estimates by using a motion-coherence regularization. The proposed region-based method for optical flow is simple, computationally efficient, and more robust than iterative gradient methods, especially for medium-range motion.<<ETX>>"
            },
            "slug": "Region-based-optical-flow-estimation-Fuh-Maragos",
            "title": {
                "fragments": [],
                "text": "Region-based optical flow estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A correspondence method is developed for determining optical flow where the primitive motion tokens to be matched between consecutive time frames are regions, which is simple, computationally efficient, and more robust than iterative gradient methods, especially for medium-range motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '89: IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679944"
                        ],
                        "name": "C. Schn\u00f6rr",
                        "slug": "C.-Schn\u00f6rr",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Schn\u00f6rr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schn\u00f6rr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "EE) results for 2D-CLG ( Bruhn et al. 2005 ) (overall the best-performing algorithm in our preliminary study, Baker et al. 2007) and the best result uploaded to the evaluation website at the time of writing (Fig. 7)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling (Lucas and Kanade 1981; Glazer et al. 1983 ;B urt et al.1983; Enkelman 1986; Anandan 1989; Black and Anandan 1996; Battiti et al. 1991;  Bruhn et al. 2005 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Four of these methods were contributed by us (our implementations of Horn and Schunck 1981, Lucas-Kanade 1981, Combined Local-Global\u2014 Bruhn et al. 2005,  and Black and Anandan 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rannacher (Rannacher 2009) 0.12 2D-CLG ( Bruhn et al. 2005 ) 844"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some algorithms use the first approach (Black and Anandan 1996), while others use the second ( Bruhn et al. 2005 ; B rox et al.2004; Wedel et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that (14) imposes limitations on the functional form of the energy, i.e., that it is just a function of the flow u, v, the spatial coordinates x,y and the gradients of the flow ux ,u y ,v x and vy . A wide variety of energy functions do satisfy this requirement including (Horn and Schunck 1981;  Bruhn et al. 2005 ; B rox et al.2004; Nir et al. 2008 ;Z immer et al.2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The best-performing algorithm (both in terms of average endpoint error and average angular error) in our preliminary study (Baker et al. 2007) was 2D-CLG ( Bruhn et al. 2005 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15374825,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c0222b86881860bf61a5c11d39bd9254a6196633",
            "isKey": true,
            "numCitedBy": 718,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "Differential methods belong to the most widely used techniques for optic flow computation in image sequences. They can be classified into local methods such as the Lucas\u2013Kanade technique or Big\u00fcn's structure tensor method, and into global methods such as the Horn/Schunck approach and its extensions. Often local methods are more robust under noise, while global techniques yield dense flow fields. The goal of this paper is to contribute to a better understanding and the design of novel differential methods in four ways; (i) We juxtapose the role of smoothing/regularisation processes that are required in local and global differential methods for optic flow computation. (ii) This discussion motivates us to describe and evaluate a novel method that combines important advantages of local and global approaches: It yields dense flow fields that are robust against noise. (iii) Spatiotemporal and nonlinear extensions as well as multiresolution frameworks are presented for this hybrid method. (iv) We propose a simple confidence measure for optic flow methods that minimise energy functionals. It allows to sparsify a dense flow field gradually, depending on the reliability required for the resulting flow. Comparisons with experiments from the literature demonstrate the favourable performance of the proposed methods and the confidence measure."
            },
            "slug": "Lucas/Kanade-Meets-Horn/Schunck:-Combining-Local-Bruhn-Weickert",
            "title": {
                "fragments": [],
                "text": "Lucas/Kanade Meets Horn/Schunck: Combining Local and Global Optic Flow Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The role of smoothing/regularisation processes that are required in local and global differential methods for optic flow computation are contrasted and a simple confidence measure is proposed that allows to sparsify a dense flow field gradually, depending on the reliability required for the resulting flow."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The algorithm by  Black and Anandan (1996 ) a lso uses afi rstorder prior, but can use an arbitrary robust penalty function on the prior term rather than the L2 norm in (9)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling (Lucas and Kanade 1981; Glazer et al. 1983 ;B urt et al.1983; Enkelman 1986; Anandan 1989;  Black and Anandan 1996;  Battiti et al. 1991; Bruhn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another approach used in  Black and Anandan (1996)  is to set the step size to be:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This assumption is rarely true in practice, particularly near occlusion boundaries where pixels at time t may not be visible at time t + 1.  Black and Anandan (1996)  present an algorithm that can use an arbitrary robust penalty function, illustrating their approach with the specific choice of a Lorentzian penalty function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some algorithms use the first approach ( Black and Anandan 1996 ), while others use the second (Bruhn et al. 2005 ;B rox et al.2004; Wedel et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A common approach to improve robustness in this case is Graduated Non-Convexity (GNC) (Blake and Zisserman 1987;  Black and Anandan 1996 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Four of these methods were contributed by us (our implementations of Horn and Schunck 1981, Lucas-Kanade 1981, Combined Local-Global\u2014Bruhn et al. 2005, and  Black and Anandan 1996 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "TV-L1-improved (Wedel et al. 2008) 2.9 Black & Anandan ( Black and Anandan 1996 ) 328"
                    },
                    "intents": []
                }
            ],
            "corpusId": 14070356,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eee90c038f43370a29b07e46f38dfe6527143a2c",
            "isKey": false,
            "numCitedBy": 1786,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper focuses on the recovery of multiple parametric motion models within a region, as well as the recovery of piecewise-smooth flow fields, and provides examples with natural and synthetic image sequences."
            },
            "slug": "The-Robust-Estimation-of-Multiple-Motions:-and-Flow-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A framework based on robust estimation is presented that addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions of optical flow, and is applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Fusion Flow ( Lempitsky et al. 2008  )u ses as equence of binary graph-cut optimizations to refine the current flow estimate by selectively replacing portions with one of the candidate solutions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is likely that stereo and flow algorithms will become more similar in the future, in particular with the advance of discrete/continuous optimization techniques ( Lempitsky et al. 2008;  Bleyer et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Only a few algorithms (e.g., DPOF\u2014Lei and Yang 2009, Fusion\u2014 Lempitsky et al. 2008,  and Dynamic MRF\u2014Glocker et al. 2008) perform well in this region."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Fusion ( Lempitsky et al. 2008 ) 2,666 FOLKI (Le Besnerais and Champagnat 2005 )1 .4"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Algorithms such as Jung et al. (2008),  Lempitsky et al. (2008)  and Trobin et al. (2008) assume that a number of candidate flow fields have been generated by running standard algorithms such as Lucas and Kanade (1981), and Horn and Schunck (1981), possibly multiple times with a number of different parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6857929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43de2e3389e6a75e4beb0b575a90c07f796ee9d2",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Accurate estimation of optical flow is a challenging task, which often requires addressing difficult energy optimization problems. To solve them, most top-performing methods rely on continuous optimization algorithms. The modeling accuracy of the energy in this case is often traded for its tractability. This is in contrast to the related problem of narrow-baseline stereo matching, where the top-performing methods employ powerful discrete optimization algorithms such as graph cuts and message-passing to optimize highly non-convex energies. In this paper, we demonstrate how similar non-convex energies can be formulated and optimized discretely in the context of optical flow estimation. Starting with a set of candidate solutions that are produced by fast continuous flow estimation algorithms, the proposed method iteratively fuses these candidate solutions by the computation of minimum cuts on graphs. The obtained continuous-valued fusion result is then further improved using local gradient descent. Experimentally, we demonstrate that the proposed energy is an accurate model and that the proposed discrete-continuous optimization scheme not only finds lower energy solutions than traditional discrete or continuous optimization techniques, but also leads to flow estimates that outperform the current state-of-the-art."
            },
            "slug": "FusionFlow:-Discrete-continuous-optimization-for-Lempitsky-Roth",
            "title": {
                "fragments": [],
                "text": "FusionFlow: Discrete-continuous optimization for optical flow estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated how similar non-convex energies can be formulated and optimized discretely in the context of optical flow estimation and that the proposed discrete-continuous optimization scheme not only finds lower energy solutions than traditional discrete or continuous optimization techniques, but also leads to flow estimates that outperform the current state-of-the-art."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518778"
                        ],
                        "name": "A. Wedel",
                        "slug": "A.-Wedel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Wedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 61
                            }
                        ],
                        "text": "2008) does poorly on the non-rigid scenes, however, Adaptive (Wedel et al. 2009) (a subsequent algorithm by the same researchers) does well on all sequences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14652562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37c59708043e4ebcb1af711e4388c965bda1826",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The accurate estimation of motion in image sequences is of central importance to numerous computer vision applications. Most competitive algorithms compute flow fields by minimizing an energy made of a data and a regularity term. To date, the best performing methods rely on rather simple purely geometric regularizes favoring smooth motion. In this paper, we revisit regularization and show that appropriate adaptive regularization substantially improves the accuracy of estimated motion fields. In particular, we systematically evaluate regularizes which adoptively favor rigid body motion (if supported by the image data) and motion field discontinuities that coincide with discontinuities of the image structure. The proposed algorithm relies on sequential convex optimization, is real-time capable and outperforms all previously published algorithms by more than one average rank on the Middlebury optic flow benchmark."
            },
            "slug": "Structure-and-motion-adaptive-regularization-for-Wedel-Cremers",
            "title": {
                "fragments": [],
                "text": "Structure- and motion-adaptive regularization for high accuracy optic flow"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper revisits regularization and shows that appropriate adaptive regularization substantially improves the accuracy of estimated motion fields and systematically evaluates regularizes which adoptively favor rigid body motion (if supported by the image data) and motion field discontinuities that coincide with discontinUities of the image structure."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47810178"
                        ],
                        "name": "Changming Sun",
                        "slug": "Changming-Sun",
                        "structuredName": {
                            "firstName": "Changming",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changming Sun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 83
                            }
                        ],
                        "text": "Crosschecking identifies the occluded regions, whose motion we mark as \u201cunknown\u201d; it also helps identify regions with insufficient texture, which we can eliminate by applying more paint."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16910731,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "850959c72031f09791ed1e01769d6e591608a6ba",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow or image motion estimation is important in the area of computer vision. This paper presents a fast and reliable optical flow algorithm which produces a dense optical flow map by using fast cross-correlation and shortest-path techniques. Fast correlation is achieved by using the box filtering technique which is invariant to the size of the correlation window. The motion for each scan line of the input image is obtained from the correlation volume by finding the best 3D path using dynamic programming rather than simply choosing the position that gives the maximum cross correlation coefficient. Sub-pixel accuracy is achieved by fitting the local correlation coefficients to a quadratic surface. Typical running time for a 256 256 image is in the order of a few seconds rather than minutes. A variety of synthetic and real images have been tested, and good results have been obtained."
            },
            "slug": "Fast-Optical-Flow-Using-Cross-Correlation-and-Sun",
            "title": {
                "fragments": [],
                "text": "Fast Optical Flow Using Cross Correlation and Shortest-Path Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents a fast and reliable optical flow algorithm which produces a dense optical flow map by using fast cross-correlation and shortest-path techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Most methods have focused on the use of parametric models that estimate motion in layers ( Jepson and Black 1993;  Wang and Adelson 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 47379266,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d237b135d9cb6c5ea76faa421fa461d3128b61e8",
            "isKey": false,
            "numCitedBy": 308,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The computation of optical flow relies on merging information available over an image patch to form an estimate of 2-D image velocity at a point. This merging process raises many issues. These include the treatment of outliers in component velocity measurements and the modeling of multiple motions within a patch which arise from occlusion boundaries or transparency. A new approach for dealing with these issues is presented. It is based on the use of a probabilistic mixture model to explicitly represent multiple motions within a patch. A simple extension of the EM-algorithm is used to compute a maximum likelihood estimate for the various motion parameters. Preliminary experiments indicate that this approach is computationally efficient, and that it can provide robust estimates of the optical flow values in the presence of outliers and multiple motions.<<ETX>>"
            },
            "slug": "Mixture-models-for-optical-flow-computation-Jepson-Black",
            "title": {
                "fragments": [],
                "text": "Mixture models for optical flow computation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new approach based on the use of a probabilistic mixture model to explicitly represent multiple motions within a patch is presented, which can provide robust estimates of the optical flow values in the presence of outliers and multiple motions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 219
                            }
                        ],
                        "text": "We encourage researchers to develop their own interpolation algorithms and submit interpolated images for direct comparison with the ground truth; for example, by looking at more than pairs of frames to estimate motion [25, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2386506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9e74a4233bb2479f74dbb0aa9f118bb764efedf",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach to computing dense depth and motion estimates from multiple images. Rather than computing a single depth or motion map from such a collection, we associate motion or depth estimates with each image in the collection (or at least some subset of the images). This has the advantage that the depth or motion of regions occluded in one image will still be represented in some other image. Thus, tasks such as novel view interpolation or motion-compensated prediction can be solved with greater fidelity. Furthermore, the natural variation in appearance between different images can be captured. To formulate motion and structure recovery, we cast the problem as a global optimization over the unknown motion or depth maps, and use robust smoothness constraints to constrain the space of possible solutions. We develop and evaluate some motion and depth estimation algorithms based on this framework."
            },
            "slug": "A-multi-view-approach-to-motion-and-stereo-Szeliski",
            "title": {
                "fragments": [],
                "text": "A multi-view approach to motion and stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "To formulate motion and structure recovery, the problem is cast as a global optimization over the unknown motion or depth maps, and robust smoothness constraints are used to constrain the space of possible solutions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709824"
                        ],
                        "name": "Ben Glocker",
                        "slug": "Ben-Glocker",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Glocker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Glocker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680727"
                        ],
                        "name": "N. Paragios",
                        "slug": "N.-Paragios",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Paragios",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Paragios"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2505902"
                        ],
                        "name": "N. Komodakis",
                        "slug": "N.-Komodakis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Komodakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Komodakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441655"
                        ],
                        "name": "G. Tziritas",
                        "slug": "G.-Tziritas",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Tziritas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tziritas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145587210"
                        ],
                        "name": "Nassir Navab",
                        "slug": "Nassir-Navab",
                        "structuredName": {
                            "firstName": "Nassir",
                            "lastName": "Navab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nassir Navab"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Only a few algorithms (e.g., DPOF\u2014Lei and Yang 2009, Fusion\u2014Lempitsky et al. 2008, and Dynamic MRF\u2014 Glocker et al. 2008 ) perform well in this region."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Dynamic MRF ( Glocker et al. 2008 ) 366 Pyramid LK (Lucas and Kanade 1981) 11.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The flow fields for Dynamic MRF ( Glocker et al. 2008 ) all appear to be over-smoothed; however, quantitatively, the performance degradation is only apparent on the sequences with strong discontinuities (Grove, Urban, and Teddy)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "More recently,  Glocker et al. (2008)  initially use a sparse sampling of possible motions on a coarse version of the problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17114092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "868a755cbb1d0af0331f9600fd759ce1d0faeb46",
            "isKey": true,
            "numCitedBy": 94,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel dynamic discrete framework to address image morphing with application to optical flow estimation. We reformulate the problem using a number of discrete displacements, and therefore the estimation of the morphing parameters becomes a tractable matching criteria independent combinatorial problem which is solved through the FastPD algorithm. In order to overcome the main limitation of discrete approaches (low dimensionality of the label space is unable to capture the continuous nature of the expected solution), we introduce a dynamic behavior in the model where the plausible discrete deformations (displacements) are varying in space (across the domain) and time (different states of the process - successive morphing states) according to the local uncertainty of the obtained solution."
            },
            "slug": "Optical-flow-estimation-with-uncertainties-through-Glocker-Paragios",
            "title": {
                "fragments": [],
                "text": "Optical flow estimation with uncertainties through dynamic MRFs"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A novel dynamic discrete framework to address image morphing with application to optical flow estimation is proposed and the estimation of the morphing parameters becomes a tractable matching criteria independent combinatorial problem which is solved through the FastPD algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110239969"
                        ],
                        "name": "John Y. A. Wang",
                        "slug": "John-Y.-A.-Wang",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wang",
                            "middleNames": [
                                "Y.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Y. A. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Most methods have focused on the use of parametric models that estimate motion in layers (Jepson and Black 1993;  Wang and Adelson 1993 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5556692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e33474350c94badff77eec1c48e24ba59c8cd05",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard approaches to motion analysis assume that the optic flow is smooth; such techniques have trouble dealing with occlusion boundaries. The image sequence can be decomposed into a set of overlapping layers, where each layer's motion is described by a smooth flow field. The discontinuities in the description are then attributed to object opacities rather than to the flow itself, mirroring the structure of the scene. A set of techniques is devised for segmenting images into coherently moving regions using affine motion analysis and clustering techniques. It is possible to decompose an image into a set of layers along with information about occlusion and depth ordering. The techniques are applied to a flower garden sequence. The scene can be analyzed into four layers, and, the entire 30-frame sequence can be represented with a single image of each layer, along with associated motion parameters.<<ETX>>"
            },
            "slug": "Layered-representation-for-motion-analysis-Wang-Adelson",
            "title": {
                "fragments": [],
                "text": "Layered representation for motion analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A set of techniques is devised for segmenting images into coherently moving regions using affine motion analysis and clustering techniques and it is possible to decompose an image into a set of layers along with information about occlusion and depth ordering."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2188270"
                        ],
                        "name": "N. Papenberg",
                        "slug": "N.-Papenberg",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Papenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The two constraints are therefore essentially equivalent in practical algorithms ( Brox et al. 2004 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "One recently popular choice (for example used in  Brox et al. 2004  among others) is to augment or replace (2) with a similar term based on the gradient of the image: \u2207I(x,y,t) =\u2207 I( x+ u, y + v, t + 1). (7)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Brox et al. ( Brox et al. 2004 ) 18 Group Flow (Ren 2008) 600"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The L1 norm is also a popular choice of penalty function ( Brox et al. 2004;  Wedel et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A common choice by a number of recent algorithms ( Brox et al. 2004;  Wedel et al. 2008) is the L1 norm, which is sometimes approximated with a differentiable version:"
                    },
                    "intents": []
                }
            ],
            "corpusId": 76390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91228e00fe33ed6072cfe849ab9e98160461549d",
            "isKey": true,
            "numCitedBy": 2733,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We study an energy functional for computing optical flow that combines three assumptions: a brightness constancy assumption, a gradient constancy assumption, and a discontinuity-preserving spatio-temporal smoothness constraint. In order to allow for large displacements, linearisations in the two data terms are strictly avoided. We present a consistent numerical scheme based on two nested fixed point iterations. By proving that this scheme implements a coarse-to-fine warping strategy, we give a theoretical foundation for warping which has been used on a mainly experimental basis so far. Our evaluation demonstrates that the novel method gives significantly smaller angular errors than previous techniques for optical flow estimation. We show that it is fairly insensitive to parameter variations, and we demonstrate its excellent robustness under noise."
            },
            "slug": "High-Accuracy-Optical-Flow-Estimation-Based-on-a-Brox-Bruhn",
            "title": {
                "fragments": [],
                "text": "High Accuracy Optical Flow Estimation Based on a Theory for Warping"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By proving that this scheme implements a coarse-to-fine warping strategy, this work gives a theoretical foundation for warping which has been used on a mainly experimental basis so far and demonstrates its excellent robustness under noise."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6376655"
                        ],
                        "name": "E. Herbst",
                        "slug": "E.-Herbst",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Herbst",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Herbst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679223"
                        ],
                        "name": "S. Seitz",
                        "slug": "S.-Seitz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Seitz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 89
                            }
                        ],
                        "text": "base will be used both by researchers working on optical flow and on frame interpolation (Mahajan et al. 2009; Herbst et al. 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27749986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d41b37c103e3a09f327f28fac6ce18680f3b068e",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an optical-flow-based algorithm to smoothly interpolate between two images. We reason about the depth ordering of objects, and show how bidirectional flow can be used to reduce holes in the estimated flow at the interpolated time and perform occlusion reasoning. We develop a purely pixel-wise algorithm and then add spatial regularization. We evaluate our algorithm on the interpolation set of the Middlebury flow benchmark."
            },
            "slug": "Occlusion-Reasoning-for-Temporal-Interpolation-Flow-Herbst-Seitz",
            "title": {
                "fragments": [],
                "text": "Occlusion Reasoning for Temporal Interpolation using Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "An optical-flow-based algorithm to smoothly interpolate between two images that develops a purely pixel-wise algorithm and then adds spatial regularization and evaluates the algorithm on the interpolation set of the Middlebury flow benchmark."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698689"
                        ],
                        "name": "N. Jojic",
                        "slug": "N.-Jojic",
                        "structuredName": {
                            "firstName": "Nebojsa",
                            "lastName": "Jojic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Jojic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738740"
                        ],
                        "name": "S. B. Kang",
                        "slug": "S.-B.-Kang",
                        "structuredName": {
                            "firstName": "Sing",
                            "lastName": "Kang",
                            "middleNames": [
                                "Bing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Kang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": ": We used the author\u2019s implementation of this algorithm [28] that uses consistent segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11173587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9453f52ff42edad19aea15c076bd234bce23439",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method for jointly computing optical flow and segmenting video while accounting for mixed pixels (matting). Our method is based on statistical modeling of an image pair using constraints on appearance and motion. Segments are viewed as overlapping regions with fractional (alpha) contributions. Bidirectional motion is estimated based on spatial coherence and similarity of segment colors. Our model is extended to video by chaining the pairwise models to produce a joint probability distribution to be maximized. To make the problem more tractable, we factorize the posterior distribution and iteratively minimize its parts. We demonstrate our method on frame interpolation"
            },
            "slug": "Consistent-segmentation-for-optical-flow-estimation-Zitnick-Jojic",
            "title": {
                "fragments": [],
                "text": "Consistent segmentation for optical flow estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This method is based on statistical modeling of an image pair using constraints on appearance and motion and is extended to video by chaining the pairwise models to produce a joint probability distribution to be maximized."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39335615"
                        ],
                        "name": "S. Vedula",
                        "slug": "S.-Vedula",
                        "structuredName": {
                            "firstName": "Sundar",
                            "lastName": "Vedula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vedula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885955"
                        ],
                        "name": "P. Rander",
                        "slug": "P.-Rander",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Rander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980462"
                        ],
                        "name": "R. Collins",
                        "slug": "R.-Collins",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Collins",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This assumption combines a number of assumptions about the reflectance properties of the scene (e.g., that it is Lambertian), the illumination in the scene (e.g., that it is uniform\u2014 Vedula et al. 2005 ) and about the image formation process in the camera (e.g., that there is no vignetting)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1241772,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f572bfbf7835203bd39af9cfab0bb9e376ff693f",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Just as optical flow is the two-dimensional motion of points in an image, scene flow is the three-dimensional motion of points in the world. The fundamental difficulty with optical flow is that only the normal flow can be computed directly from the image measurements, without some form of smoothing or regularization. In this paper, we begin by showing that the same fundamental limitation applies to scene flow; however, many cameras are used to image the scene. There are then two choices when computing scene flow: 1) perform the regularization in the images or 2) perform the regularization on the surface of the object in the scene. In this paper, we choose to compute scene flow using regularization in the images. We describe three algorithms, the first two for computing scene flow from optical flows and the third for constraining scene structure from the inconsistencies in multiple optical flows."
            },
            "slug": "Three-dimensional-scene-flow-Vedula-Baker",
            "title": {
                "fragments": [],
                "text": "Three-dimensional scene flow"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Three algorithms are described, the first two for computing scene flow from optical flows and the third for constraining scene structure from the inconsistencies in multiple optical flows."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31557997"
                        ],
                        "name": "B. Buxton",
                        "slug": "B.-Buxton",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Buxton",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Buxton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Given more than two frames in the video, it is also possible to add temporal smoothness terms \u2202u \u2202t and \u2202v \u2202t to (9) ( Murray and Buxton 1987;"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18987058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa3794165cfea264cfa171ee65abf1b47bfe8d48",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents results from computer experiments with an algorithm to perform scene disposition and motion segmentation from visual motion or optic flow. The maximum a posteriori (MAP) criterion is used to formulate what the best segmentation or interpretation of the scene should be, where the scene is assumed to be made up of some fixed number of moving planar surface patches. The Bayesian approach requires, first, specification of prior expectations for the optic flow field, which here is modeled as spatial and temporal Markov random fields; and, secondly, a way of measuring how well the segmentation predicts the measured flow field. The Markov random fields incorporate the physical constraints that objects and their images are probably spatially continuous, and that their images are likely to move quite smoothly across the image plane. To compute the flow predicted by the segmentation, a recent method for reconstructing the motion and orientation of planar surface facets is used. The search for the globally optimal segmentation is performed using simulated annealing."
            },
            "slug": "Scene-Segmentation-from-Visual-Motion-Using-Global-Murray-Buxton",
            "title": {
                "fragments": [],
                "text": "Scene Segmentation from Visual Motion Using Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "To compute the flow predicted by the segmentation, a recent method for reconstructing the motion and orientation of planar surface facets is used and the search for the globally optimal segmentation is performed using simulated annealing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In fact, some of the earliest optical flow algorithms used filtered images to reduce the effects of shadows (Burt et al. 1983;  Anandan 1989 )."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling (Lucas and Kanade 1981; Glazer et al. 1983 ;B urt et al.1983; Enkelman 1986;  Anandan 1989;  Black and Anandan 1996; Battiti et al. 1991; Bruhn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8369403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eca65cc62a3fcc02f4cfce9761c2c4857ad2f262",
            "isKey": false,
            "numCitedBy": 835,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The robust measurement of visual motion from digitized image sequences has been an important but difficult problem in computer vision. This paper describes a hierarchical computational framework for the determination of dense displacement fields from a pair of images, and an algorithm consistent with that framework. Our framework is based on a scale-based separation of the image intensity information and the process of measuring motion. The large-scale intensity information is first used to obtain rough estimates of image motion, which are then refined by using intensity information at smaller scales. The estimates are in the form of displacement (or velocity) vectors for pixels and are accompanied by a direction-dependent confidence measure. A smoothness constraint is employed to propagate measurements with high confidence to neighboring areas where the confidences are low. At all levels, the computations are pixel-parallel, uniform across the image, and based on information from a small neighborhood of a pixel. Results of applying our algorithm to pairs of real images are included. In addition to our own matching algorithm, we also show that two different hierarchical gradient-based algorithms are consistent with our framework."
            },
            "slug": "A-computational-framework-and-an-algorithm-for-the-Anandan",
            "title": {
                "fragments": [],
                "text": "A computational framework and an algorithm for the measurement of visual motion"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This paper describes a hierarchical computational framework for the determination of dense displacement fields from a pair of images, and an algorithm consistent with that framework, based on a scale-based separation of the image intensity information and the process of measuring motion."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717435"
                        ],
                        "name": "B. G. Schunck",
                        "slug": "B.-G.-Schunck",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Schunck",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. G. Schunck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 78
                            }
                        ],
                        "text": "A baseline approach is to use an L2 norm as in the Horn and Schunck algorithm (Horn and Schunck 1981):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 73
                            }
                        ],
                        "text": "A wide variety of energy functions do satisfy this requirement including (Horn and Schunck 1981; Bruhn et al. 2005; Brox et al. 2004; Nir et al. 2008; Zimmer et al. 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1371968,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a3229dc33ecb80c59a75b906c46b586dd059b781",
            "isKey": false,
            "numCitedBy": 11343,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantized rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image."
            },
            "slug": "Determining-Optical-Flow-Horn-Schunck",
            "title": {
                "fragments": [],
                "text": "Determining Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences and is robust in that it can handle image sequences that are quantified rather coarsely in space and time."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 105
                            }
                        ],
                        "text": "Several methods first segment the scene using nonmotion cues and then estimate the flow in these regions (Black and Jepson 1996; Xu et al. 2008; Fuh and Maragos 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14716701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1365bc5de434771f05f186c6be75bb9400b15495",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new model for estimating optical flow based on the motion of planar regions plus local deformations. The approach exploits brightness information to organize and constrain the interpretation of the motion by using segmented regions of piecewise smooth brightness to hypothesize planar regions in the scene. Parametric flow models are estimated in these regions in a two step process which first computes a coarse fit and then estimates the appropriate parametrization of the motion of the region. The initial fit is refined using a generalization of the standard area-based regression approaches. Since the assumption of planarity is likely to be violated, we allow local deformations from the planar assumption in the same spirit as physically-based approaches which model shape using coarse parametric models plus local deformations. This parametric plus deformation model exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches. Experimental results on a variety of images model produces accurate flow estimates while the incorporation of brightness segmentation boundaries."
            },
            "slug": "Estimating-Optical-Flow-in-Segmented-Images-Using-Black-Jepson",
            "title": {
                "fragments": [],
                "text": "Estimating Optical Flow in Segmented Images Using Variable-Order Parametric Models With Local Deformations"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new model for estimating optical flow based on the motion of planar regions plus local deformations which exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679223"
                        ],
                        "name": "S. Seitz",
                        "slug": "S.-Seitz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Seitz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 76
                            }
                        ],
                        "text": "One concern with this data is that algorithms may take advantage of the knowledge that the motions are all horizontal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2662958,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "3337470f8037924da3657f7552ef783c143e7632",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The filter flow problem is to compute a space-variant linear filter that transforms one image into another. This framework encompasses a broad range of transformations including stereo, optical flow, lighting changes, blur, and combinations of these effects. Parametric models such as affine motion, vignetting, and radial distortion can also be modeled within the same framework. All such transformations are modeled by selecting a number of constraints and objectives on the filter entries from a catalog which we enumerate. Most of the constraints are linear, leading to globally optimal solutions (via linear programming) for affine transformations, depth-from-defocus, and other problems. Adding a (non-convex) compactness objective enables solutions for optical flow with illumination changes, space-variant defocus, and higher-order smoothness."
            },
            "slug": "Filter-flow-Seitz-Baker",
            "title": {
                "fragments": [],
                "text": "Filter flow"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Adding a (non-convex) compactness objective enables solutions for optical flow with illumination changes, space-variant defocus, and higher-order smoothness."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2886023"
                        ],
                        "name": "Manuel Werlberger",
                        "slug": "Manuel-Werlberger",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Werlberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manuel Werlberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996106"
                        ],
                        "name": "Werner Trobin",
                        "slug": "Werner-Trobin",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Trobin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Werner Trobin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518778"
                        ],
                        "name": "A. Wedel",
                        "slug": "A.-Wedel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Wedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, Nagel and Enkelmann (1986) and  Werlberger et al. (2009)  weight the direction along the image gradient less than the direction orthogonal to it, and Sun et al. (2008) learn a Steerable Random Field to define the weighting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Aniso. Huber-L1 ( Werlberger et al. 2009 ) 2 Filter Flow (Seitz and Baker 2009) 34,000"
                    },
                    "intents": []
                }
            ],
            "corpusId": 28080459,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "65635c3a61b979625e44c986ac281c35ac3b0667",
            "isKey": false,
            "numCitedBy": 435,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "TV regularization is an L1 penalization of the flow gradient magnitudes, and due to the tendency of the L1 norm to favor sparse solutions (i.e. lots of \u2018zeros\u2019), the fill-in effect caused by the regularizer leads to piecewise constant solutions in weakly textured areas. This effect, known as \u2018staircasing\u2019 in a 1D setting, can be reduced significantly by using a quadratic penalization for small gradient magnitudes while sticking to linear penalization for larger magnitudes to maintain the discontinuity preserving properties known from TV. A comparison of isotropic TV and isotropic Huber regularity is shown in Fig. 1 by means of rendering the disparities u1 of the Dimetrodon dataset. The color coded flow (cf. Fig. 1(a)) is superimposed as texture. Based on the two observations that motion discontinuities often occur along object boundaries and that in turn object boundaries often coincide"
            },
            "slug": "Anisotropic-Huber-L1-Optical-Flow-Werlberger-Trobin",
            "title": {
                "fragments": [],
                "text": "Anisotropic Huber-L1 Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "TV regularization is an L1 penalization of the flow gradient magnitudes, and due to the tendency of the L1 norm to favor sparse solutions, the fill-in effect caused by the regularizer leads to piecewise constant solutions in weakly textured areas that can be reduced significantly by using a quadratic penalization for small gradient magnitude while sticking to linear penalization to maintain the discontinuity preserving properties known from TV."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035958"
                        ],
                        "name": "C. Cassisa",
                        "slug": "C.-Cassisa",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Cassisa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cassisa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277570"
                        ],
                        "name": "S. Simoens",
                        "slug": "S.-Simoens",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Simoens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Simoens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234769"
                        ],
                        "name": "V. Prinet",
                        "slug": "V.-Prinet",
                        "structuredName": {
                            "firstName": "V\u00e9ronique",
                            "lastName": "Prinet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Prinet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Second-order prior (Trobin et al. 2008) 14 TI-DOFE ( Cassisa et al. 2009 ) 260"
                    },
                    "intents": []
                }
            ],
            "corpusId": 5670566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36e3d16d0f8f3ea2e7bd380389d60461cd535804",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new formulation of the Differential Optical Flow Equation (DOFE) between two consecutive images considering spatial and temporal information from both. The displacement field is computed in a Markov Random Field (MRF) framework. The solution is done by minimization of the Gibbs energy using a Direct Descent Energy (DDE) algorithm. A hybrid multiresolution approach, combining pyramidal decomposition and two-step multigrid techniques, is used to estimate small and large displacements. A new pyramidal decomposition method without warping process between pyramid levels is introduced. The experiments carried out on benchmark dataset sequences show the effectiveness of the new optical flow formulation using the proposed unwarped pyramid decomposition schema."
            },
            "slug": "Two-Frame-Optical-Flow-Formulation-in-an-Unwarping-Cassisa-Simoens",
            "title": {
                "fragments": [],
                "text": "Two-Frame Optical Flow Formulation in an Unwarping Multiresolution Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new pyramidal decomposition method without warping process between pyramid levels is introduced and the effectiveness of the new optical flow formulation using the proposed unwarped pyramid decomposition schema is shown."
            },
            "venue": {
                "fragments": [],
                "text": "CIARP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679223"
                        ],
                        "name": "S. Seitz",
                        "slug": "S.-Seitz",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Seitz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800609"
                        ],
                        "name": "B. Curless",
                        "slug": "B.-Curless",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Curless",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Curless"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144065185"
                        ],
                        "name": "J. Diebel",
                        "slug": "J.-Diebel",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Diebel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Diebel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 Statistics: In addition to computing averages and standard deviations as in Barron et al. (1994), we also compute robustness measures (Scharstein and Szeliski 2002) and percentile-based accuracy measures ( Seitz et al. 2006 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2002) or range scanning ( Seitz et al. 2006 ) can be used to obtain dense, pixel-accurate ground truth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The presence of nonrigid or independent motion makes collecting a ground-truth dataset for optical flow far harder than for stereo, say, where structured light (Scharstein and Szeliski 2002) or range scanning ( Seitz et al. 2006 ) can be used to obtain ground truth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39265f8247f2dc6c394de0378a7027b435246fe3",
            "isKey": false,
            "numCitedBy": 2367,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a quantitative comparison of several multi-view stereo reconstruction algorithms. Until now, the lack of suitable calibrated multi-view image datasets with known ground truth (3D shape models) has prevented such direct comparisons. In this paper, we first survey multi-view stereo algorithms and compare them qualitatively using a taxonomy that differentiates their key properties. We then describe our process for acquiring and calibrating multiview image datasets with high-accuracy ground truth and introduce our evaluation methodology. Finally, we present the results of our quantitative comparison of state-of-the-art multi-view stereo reconstruction algorithms on six benchmark datasets. The datasets, evaluation details, and instructions for submitting new models are available online at http://vision.middlebury.edu/mview."
            },
            "slug": "A-Comparison-and-Evaluation-of-Multi-View-Stereo-Seitz-Curless",
            "title": {
                "fragments": [],
                "text": "A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper first survey multi-view stereo algorithms and compare them qualitatively using a taxonomy that differentiates their key properties, then describes the process for acquiring and calibrating multiview image datasets with high-accuracy ground truth and introduces the evaluation methodology."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681442"
                        ],
                        "name": "Ce Liu",
                        "slug": "Ce-Liu",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143738177"
                        ],
                        "name": "Jenny Yuen",
                        "slug": "Jenny-Yuen",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Yuen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenny Yuen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1181823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae01610370105f87eeb0d4a90aa723c43f4393bc",
            "isKey": false,
            "numCitedBy": 665,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "While image registration has been studied in different areas of computer vision, aligning images depicting different scenes remains a challenging problem, closer to recognition than to image matching. Analogous to optical flow, where an image is aligned to its temporally adjacent frame, we propose SIFT flow, a method to align an image to its neighbors in a large image collection consisting of a variety of scenes. For a query image, histogram intersection on a bag-of-visual-words representation is used to find the set of nearest neighbors in the database. The SIFT flow algorithm then consists of matching densely sampled SIFT features between the two images, while preserving spatial discontinuities. The use of SIFT features allows robust matching across different scene/object appearances and the discontinuity-preserving spatial model allows matching of objects located at different parts of the scene. Experiments show that the proposed approach is able to robustly align complicated scenes with large spatial distortions. We collect a large database of videos and apply the SIFT flow algorithm to two applications: (i) motion field prediction from a single static image and (ii) motion synthesis via transfer of moving objects."
            },
            "slug": "SIFT-Flow:-Dense-Correspondence-across-Different-Liu-Yuen",
            "title": {
                "fragments": [],
                "text": "SIFT Flow: Dense Correspondence across Different Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method to align an image to its neighbors in a large image collection consisting of a variety of scenes, and applies the SIFT flow algorithm to two applications: motion field prediction from a single static image and motion synthesis via transfer of moving objects."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112189"
                        ],
                        "name": "Shijun Sun",
                        "slug": "Shijun-Sun",
                        "structuredName": {
                            "firstName": "Shijun",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijun Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891779"
                        ],
                        "name": "D. Haynor",
                        "slug": "D.-Haynor",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haynor",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haynor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39888030"
                        ],
                        "name": "Yongmin Kim",
                        "slug": "Yongmin-Kim",
                        "structuredName": {
                            "firstName": "Yongmin",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongmin Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 219
                            }
                        ],
                        "text": "We encourage researchers to develop their own interpolation algorithms and submit interpolated images for direct comparison with the ground truth; for example, by looking at more than pairs of frames to estimate motion [25, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45658021,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0035cd403dbee96de67cf6d6ca297703ceef6460",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow has been widely used in motion estimation. By initializing adaptive gradients, we have developed a technique to reduce the occlusion problem in computing optical flow with the Horn and Schunck (1981) method. The adaptive gradients are derived from the forward and backward image gradients based on the optical flow equation during iterations. Improved optical flow solutions with the elimination of 'double-image' artifacts caused by occlusions have been obtained."
            },
            "slug": "Motion-estimation-based-on-optical-flow-with-Sun-Haynor",
            "title": {
                "fragments": [],
                "text": "Motion estimation based on optical flow with adaptive gradients"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Optical flow solutions with the elimination of 'double-image' artifacts caused by occlusions have been obtained by initializing adaptive gradients."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2000 International Conference on Image Processing (Cat. No.00CH37101)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The regularization of transparent motion in the framework of global energy minimization, however, has received little attention with the exception of Ju et al. (1996),  Weiss (1997) , and Shizawa and Mase (1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1921007,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a79836ffd64bb3111f5247567a1cb43a8ad6e621",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Grouping based on common motion, or \"common fate\" provides a powerful cue for segmenting image sequences. Recently a number of algorithms have been developed that successfully perform motion segmentation by assuming that the motion of each group can be described by a low dimensional parametric model (e.g. affine). Typically the assumption is that motion segments correspond to planar patches in 3D undergoing rigid motion. Here we develop an alternative approach, where the motion of each group is described by a smooth dense flow field and the stability of the estimation is ensured by means of a prior distribution on the class of flow fields. We present a variant of the EM algorithm that can segment image sequences by fitting multiple smooth flow fields to the spatiotemporal data. Using the method of Green's functions, we show how the estimation of a single smooth flow field can be performed in closed form, thus making the multiple model estimation computationally feasible. Furthermore, the number of models is estimated automatically using similar methods to those used in the parametric approach. We illustrate the algorithm's performance on synthetic and real image sequences."
            },
            "slug": "Smoothness-in-layers:-Motion-segmentation-using-Weiss",
            "title": {
                "fragments": [],
                "text": "Smoothness in layers: Motion segmentation using nonparametric mixture estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a variant of the EM algorithm that can segment image sequences by fitting multiple smooth flow fields to the spatiotemporal data and shows how the estimation of a single smooth flow field can be performed in closed form, thus making the multiple model estimation computationally feasible."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518778"
                        ],
                        "name": "A. Wedel",
                        "slug": "A.-Wedel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Wedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060379849"
                        ],
                        "name": "J. Braun",
                        "slug": "J.-Braun",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Braun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Braun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49634061"
                        ],
                        "name": "U. Franke",
                        "slug": "U.-Franke",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Franke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Franke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14552508,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5d49d7b32b70511dc6c9ff7564f75eb3e7bf7ed5",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational techniques yield the most accurate results for dense optical flow fields between two images. They have the nice property of inherent smoothness to cope with untextured image regions: the filling-in of such regions is driven by neighbouring pixels. Such filling-in is not always the best choice. If the scene is mostly stationary and the camera is moving, the direction of the optical flow vectors can be restricted using the fundamental matrix. In this paper we propose an exact solution of the variational optical flow, using the fundamental matrix geometry as an additional weak prior. Our novel approach currently performs best on the Middlebury flow evaluation which includes images from stationary and dynamic scenes."
            },
            "slug": "Duality-TV-L1-flow-with-fundamental-matrix-prior-Wedel-Pock",
            "title": {
                "fragments": [],
                "text": "Duality TV-L1 flow with fundamental matrix prior"
            },
            "venue": {
                "fragments": [],
                "text": "2008 23rd International Conference Image and Vision Computing New Zealand"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190675"
                        ],
                        "name": "Gilad Adiv",
                        "slug": "Gilad-Adiv",
                        "structuredName": {
                            "firstName": "Gilad",
                            "lastName": "Adiv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilad Adiv"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These constraints have both been strictly enforced ( Adiv 1985;  Hanna 1991; Nir et al. 2008) and added as a soft prior (Wedel et al. 2008; Wedel et al. 2009; Valgaerts et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18974396,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3733124d9fedd380e7e0c6b82eef9f2db3344fc3",
            "isKey": false,
            "numCitedBy": 899,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A new approach for the interpretation of optical flow fields is presented. The flow field, which can be produced by a sensor moving through an environment with several independently moving, rigid objects, is allowed to be sparse, noisy, and partially incorrect. The approach is based on two main stages. In the first stage, the flow field is partitioned into connected segments of flow vectors, where each segment is consistent with a rigid motion of a roughly planar surface. In the second stage, segments are grouped under the hypothesis that they are induced by a single, rigidly moving object. Each hypothesis is tested by searching for three-dimensional (3-D) motion parameters which are compatible with all the segments in the corresponding group. Once the motion parameters are recovered, the relative environmental depth can be estimated as well. Experiments based on real and simulated data are presented."
            },
            "slug": "Determining-Three-Dimensional-Motion-and-Structure-Adiv",
            "title": {
                "fragments": [],
                "text": "Determining Three-Dimensional Motion and Structure from Optical Flow Generated by Several Moving Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A new approach for the interpretation of optical flow fields is presented, where the flow field is partitioned into connected segments of flow vectors, where each segment is consistent with a rigid motion of a roughly planar surface."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145943163"
                        ],
                        "name": "J. Shade",
                        "slug": "J.-Shade",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Shade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2415843"
                        ],
                        "name": "S. Gortler",
                        "slug": "S.-Gortler",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Gortler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gortler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689581"
                        ],
                        "name": "Li-wei He",
                        "slug": "Li-wei-He",
                        "structuredName": {
                            "firstName": "Li-wei",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-wei He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our algorithm is closely related to previous algorithms for depth-based frame interpolation ( Shade et al. 1998;  Zitnick et al. 2004):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1240104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ce715b4c541f38648fbfc6e1788c50e0460e472",
            "isKey": false,
            "numCitedBy": 1211,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a set of efficient image based rendering methods capable of rendering multiple frames per second on a PC. The first method warps Sprites with Depth representing smooth surfaces without the gaps found in other techniques. A second method for more general scenes performs warping from an intermediate representation called a Layered Depth Image (LDI). An LDI is a view of the scene from a single input camera view, but with multiple pixels along each line of sight. The size of the representation grows only linearly with the observed depth complexity in the scene. Moreover, because the LDI data are represented in a single image coordinate system, McMillan\u2019s warp ordering algorithm can be successfully adapted. As a result, pixels are drawn in the output image in back-to-front order. No z-buffer is required, so alphacompositing can be done efficiently without depth sorting. This makes splatting an efficient solution to the resampling problem."
            },
            "slug": "Layered-depth-images-Shade-Gortler",
            "title": {
                "fragments": [],
                "text": "Layered depth images"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A set of efficient image based rendering methods capable of rendering multiple frames per second on a PC that warps Sprites with Depth representing smooth surfaces without the gaps found in other techniques and splatting an efficient solution to the resampling problem."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688991"
                        ],
                        "name": "A. Mitiche",
                        "slug": "A.-Mitiche",
                        "structuredName": {
                            "firstName": "Amar",
                            "lastName": "Mitiche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mitiche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716733"
                        ],
                        "name": "P. Bouthemy",
                        "slug": "P.-Bouthemy",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Bouthemy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bouthemy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For more extensive coverage of older work, the reader is referred to previous surveys such as those by Aggarwal and Nandhakumar (1988), Barron et al. (1994), Otte and Nagel (1994),  Mitiche and Bouthemy (1996) , and Stiller and Konrad (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21816814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d783f3929458095da524a7c075471b7a2c70bd6",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this paper is to offer a structured synopsis of the problems in image motion computation and analysis, and of the methods proposed, exposing the underlying models and supporting assumptions. A sufficient number of pointers to the literature will be given, concentrating mostly on recent contributions. Emphasis will be on the detection, measurement and segmentation of image motion. Tracking, and deformable motion issues will be also addressed. Finally, a number of related questions which could require more investigations will be presented."
            },
            "slug": "Computation-and-analysis-of-image-motion:-A-of-and-Mitiche-Bouthemy",
            "title": {
                "fragments": [],
                "text": "Computation and analysis of image motion: A synopsis of current problems and methods"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A structured synopsis of the problems in image motion computation and analysis, and of the methods proposed, exposing the underlying models and supporting assumptions are offered."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797649"
                        ],
                        "name": "Levi Valgaerts",
                        "slug": "Levi-Valgaerts",
                        "structuredName": {
                            "firstName": "Levi",
                            "lastName": "Valgaerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Levi Valgaerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These constraints have both been strictly enforced (Adiv 1985; Hanna 1991; Nir et al. 2008) and added as a soft prior (Wedel et al. 2008; Wedel et al. 2009;  Valgaerts et al. 2008 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1407108,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0726da672ed9fb725563c47d1839b6bc3bc0e170",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional estimation methods for the fundamental matrix rely on a sparse set of point correspondences that have been established by matching salient image features between two images. Recovering the fundamental matrix from dense correspondences has not been extensively researched until now. In this paper we propose a new variational model that recovers the fundamental matrix from a pair of uncalibrated stereo images, and simultaneously estimates an optical flow field that is consistent with the corresponding epipolar geometry. The model extends the highly accurate optical flow technique of Brox et al.(2004) by taking the epipolar constraint into account. In experiments we demonstrate that our approach is able to produce excellent estimates for the fundamental matrix and that the optical flow computation is on par with the best techniques to date."
            },
            "slug": "A-Variational-Model-for-the-Joint-Recovery-of-the-Valgaerts-Bruhn",
            "title": {
                "fragments": [],
                "text": "A Variational Model for the Joint Recovery of the Fundamental Matrix and the Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new variational model is proposed that recovers the fundamental matrix from a pair of uncalibrated stereo images, and simultaneously estimates an optical flow field that is consistent with the corresponding epipolar geometry."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, for the stereo sequences, pixels where cross-checking failed are excluded ( Scharstein and Szeliski 2003 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Specifically we include the Teddy dataset in the evaluation set, the ground truth for which was obtained using structured lighting ( Scharstein and Szeliski 2003 ) (Fig. 5). Stereo datasets typically have an asymmetric disparity range [0 ,d max], which is appropriate for stereo, but not for optical flow."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Of the various possible techniques\u2014synthetic data (Barron et al. 1994; McCane et al. 2001), some form of hidden markers (Mova LLC 2004; Tappen et al. 2006; Ramnath et al. 2008), human annotation (Liu et al. 2008), interpolation data (Szeliski 1999), and modified stereo data ( Scharstein and Szeliski 2003 )\u2014the authors believe that synthetic data is probably the best approach (although generating high-quality synthetic data is not as easy as ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 Real Stereo Imagery of Rigid Scenes: Dense ground truth is captured using structured light ( Scharstein and Szeliski 2003 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(The original stereo data comes with pixel-accurate ground truth but is four times higher resolution\u2014 Scharstein and Szeliski 2003 .) The most appropriate performance statistics for this data, therefore, are the robustness statistics used in the Middlebury stereo dataset (Scharstein and Szeliski 2002) (Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We cropped the stereo dataset Teddy ( Scharstein and Szeliski 2003 ) to convert the asymmetric stereo disparity range into a roughly symmetric flow field."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9766024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2566f3905ab398694a1f40603192f50712a85769",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Progress in stereo algorithm performance is quickly outpacing the ability of existing stereo data sets to discriminate among the best-performing algorithms, motivating the need for more challenging scenes with accurate ground truth information. This paper describes a method for acquiring high-complexity stereo image pairs with pixel-accurate correspondence information using structured light. Unlike traditional range-sensing approaches, our method does not require the calibration of the light sources and yields registered disparity maps between all pairs of cameras and illumination projectors. We present new stereo data sets acquired with our method and demonstrate their suitability for stereo algorithm evaluation. Our results are available at http://www.middlebury.edu/stereo/."
            },
            "slug": "High-accuracy-stereo-depth-maps-using-structured-Scharstein-Szeliski",
            "title": {
                "fragments": [],
                "text": "High-accuracy stereo depth maps using structured light"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method for acquiring high-complexity stereo image pairs with pixel-accurate correspondence information using structured light that does not require the calibration of the light sources and yields registered disparity maps between all pairs of cameras and illumination projectors."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749805"
                        ],
                        "name": "Timo Kohlberger",
                        "slug": "Timo-Kohlberger",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Kohlberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timo Kohlberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679944"
                        ],
                        "name": "C. Schn\u00f6rr",
                        "slug": "C.-Schn\u00f6rr",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Schn\u00f6rr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schn\u00f6rr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "A related approach is to use a multigrid algorithm (Bruhn et al. 2006) where estimates of the flow are passed both up and down the hierarchy of approximations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3040718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa59f0c8f4a9376b1e8ec6b5045669b5a6d9c0c7",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational methods are among the most accurate techniques for estimating the optic flow. They yield dense flow fields and can be designed such that they preserve discontinuities, estimate large displacements correctly and perform well under noise and varying illumination. However, such adaptations render the minimisation of the underlying energy functional very expensive in terms of computational costs: Typically one or more large linear or nonlinear equation systems have to be solved in order to obtain the desired solution. Consequently, variational methods are considered to be too slow for real-time performance. In our paper we address this problem in two ways: (i) We present a numerical framework based on bidirectional multigrid methods for accelerating a broad class of variational optic flow methods with different constancy and smoothness assumptions. Thereby, our work focuses particularly on regularisation strategies that preserve discontinuities. (ii) We show by the examples of five classical and two recent variational techniques that real-time performance is possible in all cases\u2014even for very complex optic flow models that offer high accuracy. Experiments show that frame rates up to 63 dense flow fields per second for image sequences of size 160 \u00d7 120 can be achieved on a standard PC. Compared to classical iterative methods this constitutes a speedup of two to four orders of magnitude."
            },
            "slug": "A-Multigrid-Platform-for-Real-Time-Motion-with-Bruhn-Weickert",
            "title": {
                "fragments": [],
                "text": "A Multigrid Platform for Real-Time Motion Computation with Discontinuity-Preserving Variational Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a numerical framework based on bidirectional multigrid methods for accelerating a broad class of variational optic flow methods with different constancy and smoothness assumptions and focuses particularly on regularisation strategies that preserve discontinuities."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996106"
                        ],
                        "name": "Werner Trobin",
                        "slug": "Werner-Trobin",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Trobin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Werner Trobin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "12 F-TV-L1 [79] 8 Second-order prior [75] 14 Fusion [40] 2,666 Dynamic MRF [27] 366 Algorithm Runtime"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "[54] X X X X X F-TV-L1 [79] X X X X Second-order prior [75] X X X Fusion [40] X X X X X X X Dynamic MRF [27] X X X Seg OF [83] X X X X X X Learning Flow [70] X X X X X X Filter Flow [65] X X X X X X X Graph Cuts [20] X X X X Black & Anandan [11] X X X SPSA-learn [41] X X X X X Horn & Schunck [33] X"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 153
                            }
                        ],
                        "text": "1 can be replaced with priors that encourage the secondorder derivatives ( 2u \u2202x2 , \u2202 2u \u2202y2 , \u2202 2u \u2202x\u2202y , \u2202 2v \u2202x2 , \u2202 2v \u2202y2 , \u2202 2v \u2202x\u2202y ) to be small [4, 75]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2429111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ac4d71354f682fc57c8da39c0b4668ec5e6f1a2",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Virtually all variational methods for motion estimation regularize the gradient of the flow field, which introduces a bias towards piecewise constant motions in weakly textured areas. We propose a novel regularization approach, based on decorrelated second-order derivatives, that does not suffer from this shortcoming. We then derive an efficient numerical scheme to solve the new model using projected gradient descent. A comparison to a TV regularized model shows that the proposed second-order prior exhibits superior performance, in particular in low-textured areas (where the prior becomes important). Finally, we show that the proposed model yields state-of-the-art results on the Middlebury optical flow database."
            },
            "slug": "An-Unbiased-Second-Order-Prior-for-High-Accuracy-Trobin-Pock",
            "title": {
                "fragments": [],
                "text": "An Unbiased Second-Order Prior for High-Accuracy Motion Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This work proposes a novel regularization approach, based on decorrelated second-order derivatives, that does not suffer from a bias towards piecewise constant motions in weakly textured areas and derives an efficient numerical scheme to solve the new model using projected gradient descent."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802944"
                        ],
                        "name": "M. Tappen",
                        "slug": "M.-Tappen",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Tappen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tappen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Of the various possible techniques\u2014synthetic data (Barron et al. 1994; McCane et al. 2001), some form of hidden markers (Mova LLC 2004;  Tappen et al. 2006;  Ramnath et al. 2008), human annotation (Liu et al. 2008), interpolation data (Szeliski 1999), and modified stereo data (Scharstein and Szeliski 2003)\u2014the authors believe that synthetic data is probably the best approach (although generating high-quality synthetic data is not as easy as ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that a related technique is being used commercially for motion capture (Mova LLC 2004) and  Tappen et al. (2006)  recently used certain wavelengths to hide ground truth in intrinsic images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12373622,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "82643305e02361d1342e6499e5b7a254bbe1a4bc",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Images can be represented as the composition of multiple intrinsic component images, such as shading, albedo, and noise images. In this paper, we present a method for estimating intrinsic component images from a single image, which we apply to the problems of estimating shading and albedo images and image denoising. Our method is based on learning estimators that predict filtered versions of the desired image. Unlike previous approaches, our method does not require unnatural discretizations of the problem. We also demonstrate how to learn a weighting function that properly weights the local estimates when constructing the estimated image. For shading estimation, we introduce a new training set of real-world images. The accuracy of our method is measured both qualitatively and quantitatively, showing better performance on the shading/albedo separation problem than previous approaches. The performance on denoising is competitive with the current state of the art."
            },
            "slug": "Estimating-Intrinsic-Component-Images-using-Tappen-Adelson",
            "title": {
                "fragments": [],
                "text": "Estimating Intrinsic Component Images using Non-Linear Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A method for estimating intrinsic component images from a single image, which is based on learning estimators that predict filtered versions of the desired image, and shows better performance on the shading/albedo separation problem than previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1972076"
                        ],
                        "name": "C. Pal",
                        "slug": "C.-Pal",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Pal",
                            "middleNames": [
                                "Joseph"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Specifically we include the Teddy dataset [62] in the evaluation set, the ground truth for which was obtained using structured lighting [64] (Figure 5)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13154466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c36b842780c81333cbbb87628b49f9911a5936b",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art stereo vision algorithms utilize color changes as important cues for object boundaries. Most methods impose heuristic restrictions or priors on disparities, for example by modulating local smoothness costs with intensity gradients. In this paper we seek to replace such heuristics with explicit probabilistic models of disparities and intensities learned from real images. We have constructed a large number of stereo datasets with ground-truth disparities, and we use a subset of these datasets to learn the parameters of conditional random fields (CRFs). We present experimental results illustrating the potential of our approach for automatically learning the parameters of models with richer structure than standard hand-tuned MRF models."
            },
            "slug": "Learning-Conditional-Random-Fields-for-Stereo-Scharstein-Pal",
            "title": {
                "fragments": [],
                "text": "Learning Conditional Random Fields for Stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper has constructed a large number of stereo datasets with ground-truth disparities, and a subset of these datasets are used to learn the parameters of conditional random fields (CRFs) and presents experimental results illustrating the potential of this approach for automatically learning the Parameters of models with richer structure than standard hand-tuned MRF models."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760556"
                        ],
                        "name": "C. Stiller",
                        "slug": "C.-Stiller",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Stiller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055319"
                        ],
                        "name": "J. Konrad",
                        "slug": "J.-Konrad",
                        "structuredName": {
                            "firstName": "Janusz",
                            "lastName": "Konrad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Konrad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120689267,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "967ffbdfebbdf9e6d655f1dbb8377b89494c55e7",
            "isKey": false,
            "numCitedBy": 375,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We have reviewed the estimation of 2D motion from time-varying images, paying particular attention to the underlying models, estimation criteria, and optimization strategies. Several parametric and nonparametric models for the representation of motion vector fields and motion trajectory fields have been discussed. For a given region of support, these models determine the dimensionality of the estimation problem as well as the amount of data that has to be interpreted or transmitted thereafter. Also, the interdependence of motion and image data has been addressed. We have shown that even ideal constraints may not provide a well-defined estimation criterion. Therefore, the data term of an estimation criterion is usually supplemented with a smoothness term that can be expressed explicitly or implicitly via a constraining motion model. We have paid particular attention to the statistical criteria based on Markov random fields. Because the optimization of an estimation criterion typically involves a large number of unknowns, we have presented several fast search strategies."
            },
            "slug": "Estimating-motion-in-image-sequences-Stiller-Konrad",
            "title": {
                "fragments": [],
                "text": "Estimating motion in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The estimation of 2D motion from time-varying images is reviewed, showing that even ideal constraints may not provide a well-defined estimation criterion and presenting several fast search strategies for the optimization of an estimation criterion."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Process. Mag."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392676976"
                        ],
                        "name": "Michael J. Blacky",
                        "slug": "Michael-J.-Blacky",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Blacky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Blacky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 45
                            }
                        ],
                        "text": "A related approach is to use an affine prior (Ju et al. 1996; Ju 1998; Nir et al. 2008; Seitz and Baker 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11784109,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c49c093bbb4bda6cb2210bc89008f8ce30eb4326",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 130,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for estimating optical flow that strikes a balance between the flexibility of regularization techniques and the robustness and accuracy of area-based regression techniques. The approach assumes that image motion can be represented by an affine flow model within local image patchs. Since some image regions may not have sufficient information to estimate an affine motion model robustly, we define a spatial smoothness constraint on the affine flow parameters of neighboring patches. We refer to this as a \u201cSkin and Bones\u201d model in which the affine patches can be thought of as rigid patches of \u201cbone\u201d connected by a flexible \u201cskin.\u201d Since local image patches may contain multiple motions we use a layered representation for the affine bones. With the possibility of multiple motions at a given point, standard regularization schemes cannot be used to smooth the multiple sets of affine parameters. We therefore develop a new framework for regularization with transparency that can applied to produce a smoothed layered motion representation. The motion estimation problem, with layered locally affine bones and transparent regularization, is formulated as an objective function that is minimized using a variant of the EM-algorithm. Experiments with synthetic and natural images are provided throughout the paper to illustrate the method. Submitted as a Regular Paper."
            },
            "slug": "Estimating-Image-Motion-in-Layers:-The-\u201cSkin-and-Ju-Blacky",
            "title": {
                "fragments": [],
                "text": "Estimating Image Motion in Layers: The \u201cSkin and Bones\u201d Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "We follow the procedure in [19] and compute the error measure statistics over 3 types of region masks: all, motion discontinuities, and textureless regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27667388,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1e91e17ee1135bcdfc03a0c56fae3affe7812d8b",
            "isKey": false,
            "numCitedBy": 831,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for the computation of 2D component velocity from image sequences. Initially, the image sequence is represented by a family of spatiotemporal velocity-tuned linear filters. Component velocity, computed from spatiotemporal responses of identically tuned filters, is expressed in terms of the local first-order behavior of surfaces of constant phase. Justification for this definition is discussed from the perspectives of both 2D image translation and deviations from translation that are typical in perspective projections of 3D scenes. The resulting technique is predominantly linear, efficient, and suitable for parallel processing. Moreover, it is local in space-time, robust with respect to noise, and permits multiple estimates within a single neighborhood. Promising quantiative results are reported from experiments with realistic image sequences, including cases with sizeable perspective deformation."
            },
            "slug": "Computation-of-component-image-velocity-from-local-Fleet-Jepson",
            "title": {
                "fragments": [],
                "text": "Computation of component image velocity from local phase information"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The resulting technique is predominantly linear, efficient, and suitable for parallel processing, and is local in space-time, robust with respect to noise, and permits multiple estimates within a single neighborhood."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3315356"
                        ],
                        "name": "K. Hanna",
                        "slug": "K.-Hanna",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Hanna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hanna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These constraints have both been strictly enforced (Adiv 1985;  Hanna 1991;  Nir et al. 2008) and added as a soft prior (Wedel et al. 2008; Wedel et al. 2009; Valgaerts et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 86862810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "396ffa315a2944832c7c2f8a58e909b77afb841d",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes an iterative algorithm that estimates the motion of a camera through an environment directly from brightness derivatives of an image pair. A global ego-motion constraint is combined with the local brightness constancy constraint to relate local surface models with the global ego-motion model and local brightness derivatives. In an iterative process, the author first refines the local surface models using the ego-motion as a constraint, and then refines the ego-motion model using the local surface models as constraints. He performs this analysis at multiple resolutions. He shows how information from local corner-like and edge-like image structures contribute to the refinement of the global ego-motion estimate, and how the ego-motion constraint can help resolve local motion ambiguities that arise from the aperture problem. Results of the algorithm are shown on uncalibrated outdoor image sequences, and also on a computer-rendered image sequence.<<ETX>>"
            },
            "slug": "Direct-multi-resolution-estimation-of-ego-motion-Hanna",
            "title": {
                "fragments": [],
                "text": "Direct multi-resolution estimation of ego-motion and structure from motion"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An iterative algorithm that estimates the motion of a camera through an environment directly from brightness derivatives of an image pair and how the ego-motion constraint can help resolve local motion ambiguities that arise from the aperture problem is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085182964"
                        ],
                        "name": "H. Landis",
                        "slug": "H.-Landis",
                        "structuredName": {
                            "firstName": "Hayden",
                            "lastName": "Landis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Landis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The rendered scenes use the ambient occlusion approximation to global illumination ( Landis 2002 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59828047,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "4a9de79235445fdf346b274603dfa5447321aab6",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Global illumination can provide great visual benefits, but we\u2019re not always willing to pay the price. In production we often have constraints of time and resources that can make traditional global illumination approaches unrealistic. \u201cReflection Occlusion\u201d and \u201cAmbient Environments\u201d have provided us with several reasonably efficient and flexible methods for achieving a similar look but with a minimum of expense. This chapter will cover how Industrial Light and Magic (ILM) uses Reflection Occlusion and Ambient Environment techniques to integrate aspects of global illumination into our standard RenderMan pipeline. Both techniques use a ray-traced occlusion pass that is independent of the final lighting. The information they contain is passed on to our RenderMan shaders where they are used in the final lighting calculations. This allows lighting and materials too be altered and re-rendered without having to recalculate the occlusion passes themselves. We will show that when used together these two techniques have given us an integrated solution for realistically lighting scenes. They allow us to decrease setup time, lighting complexity, and computational expense while at the same time increasing the overall visual impact of our images."
            },
            "slug": "Production-Ready-Global-Illumination-Landis",
            "title": {
                "fragments": [],
                "text": "Production-Ready Global Illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This chapter will cover how Industrial Light and Magic (ILM) uses Reflection Occlusion and Ambient Environment techniques to integrate aspects of global illumination into the authors' standard RenderMan pipeline and show that when used together these two techniques have given us an integrated solution for realistically lighting scenes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787751"
                        ],
                        "name": "G. L. Besnerais",
                        "slug": "G.-L.-Besnerais",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Besnerais",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. L. Besnerais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776378"
                        ],
                        "name": "F. Champagnat",
                        "slug": "F.-Champagnat",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Champagnat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Champagnat"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These algorithms are applicable to problems with fewer parameters such as the Lucas-Kanade algorithm (Lucas and Kanade 1981) and variants ( Le Besnerais and Champagnat 2005 ), which solve for a single flow vector (2 unknowns) independently for each block of pixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Fusion (Lempitsky et al. 2008) 2,666 FOLKI ( Le Besnerais and Champagnat 2005  )1 .4"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9992584,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f390ae21b1b586f9b0f6469becf2c6588987a45d",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We study dense optical flow estimation using iterative registration of local window, also known as iterative Lucas-Kanade (LK) [B. Lucas et al, 1981]. We show that the usual iterative-warping scheme encounters divergence problems and propose a modified scheme with better behavior. It yields good results with a much lower cost than the exact dense LK algorithm, on simulated and real sequences."
            },
            "slug": "Dense-optical-flow-by-iterative-local-window-Besnerais-Champagnat",
            "title": {
                "fragments": [],
                "text": "Dense optical flow by iterative local window registration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the usual iterative-warping scheme encounters divergence problems and a modified scheme with better behavior is proposed, which yields good results with a much lower cost than the exact dense LK algorithm, on simulated and real sequences."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Image Processing 2005"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2188270"
                        ],
                        "name": "N. Papenberg",
                        "slug": "N.-Papenberg",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Papenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2915154"
                        ],
                        "name": "Stephan Didas",
                        "slug": "Stephan-Didas",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Didas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Didas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 126
                            }
                        ],
                        "text": "Given more than two frames in the video, it is also possible to add temporal smoothness terms \u2202u \u2202t and \u2202v \u2202t to Equation (9) [10, 49, 54]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 73
                            }
                        ],
                        "text": "A wide variety of energy functions do satisfy this requirement including [16,33,52,54,84]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 57
                            }
                        ],
                        "text": "The L1 norm is also a popular choice of penalty function [54, 80]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 73
                            }
                        ],
                        "text": "Some algorithms use the first approach [11], while others use the second [16,54,80]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 49
                            }
                        ],
                        "text": "A common choice by a number of recent algorithms [54, 80] is the L1 norm, which is sometimes approximated with the differentiable version:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "The two constraints are therefore essentially equivalent in practical algorithms [54]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "One recently popular choice (for example used in [54] among others) is to augment or replace Equation (2) with a similar term based on the gradient of the image:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[54] X X X X X F-TV-L1 [79] X X X X Second-order prior [75] X X X Fusion [40] X X X X X X X Dynamic MRF [27] X X X Seg OF [83] X X X X X X Learning Flow [70] X X X X X X Filter Flow [65] X X X X X X X Graph Cuts [20] X X X X Black & Anandan [11] X X X SPSA-learn [41] X X X X X Horn & Schunck [33] X"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1998629,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "396749086172f824ec555adca5daf0d40e0723ef",
            "isKey": true,
            "numCitedBy": 471,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we suggest a variational model for optic flow computation based on non-linearised and higher order constancy assumptions. Besides the common grey value constancy assumption, also gradient constancy, as well as the constancy of the Hessian and the Laplacian are proposed. Since the model strictly refrains from a linearisation of these assumptions, it is also capable to deal with large displacements. For the minimisation of the rather complex energy functional, we present an efficient numerical scheme employing two nested fixed point iterations. Following a coarse-to-fine strategy it turns out that there is a theoretical foundation of so-called warping techniques hitherto justified only on an experimental basis. Since our algorithm consists of the integration of various concepts, ranging from different constancy assumptions to numerical implementation issues, a detailed account of the effect of each of these concepts is included in the experimental section. The superior performance of the proposed method shows up by significantly smaller estimation errors when compared to previous techniques. Further experiments also confirm excellent robustness under noise and insensitivity to parameter variations."
            },
            "slug": "Highly-Accurate-Optic-Flow-Computation-with-Warping-Papenberg-Bruhn",
            "title": {
                "fragments": [],
                "text": "Highly Accurate Optic Flow Computation with Theoretically Justified Warping"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A variational model for optic flow computation based on non-linearised and higher order constancy assumptions, including the common grey value constancy assumption, as well as the constancy of the Hessian and the Laplacian are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729630"
                        ],
                        "name": "P. Golland",
                        "slug": "P.-Golland",
                        "structuredName": {
                            "firstName": "Polina",
                            "lastName": "Golland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Golland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143610924"
                        ],
                        "name": "A. Bruckstein",
                        "slug": "A.-Bruckstein",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Bruckstein",
                            "middleNames": [
                                "Marcel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bruckstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 48
                            }
                        ],
                        "text": "Another issue, addressed by a number of authors (Ohta 1989; Markandey and Flinchbaugh 1990; Golland and Bruckstein 1997), is how to modify the data term for color or multi-band images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13321003,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d7bec83d4723cbc5b33462e40362e34a5cc2012e",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The use of color images for motion estimation is investigated in this work. Beyond the straightforward approach of using the color components as separate images of the same scene, a new method, based on exploiting color invariance under motion, is discussed. Two different sets of color-related, locally computable motion \u201cinvariants\u201d are analyzed and tested in this paper, and the results of motion estimation based on them are compared to the direct use of the RGB brightness functions."
            },
            "slug": "Motion-from-Color-Golland-Bruckstein",
            "title": {
                "fragments": [],
                "text": "Motion from Color"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two different sets of color-related, locally computable motion \u201cinvariants\u201d are analyzed and tested in this paper, and the results of motion estimation based on them are compared to the direct use of the RGB brightness functions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751663"
                        ],
                        "name": "Krishnan Ramnath",
                        "slug": "Krishnan-Ramnath",
                        "structuredName": {
                            "firstName": "Krishnan",
                            "lastName": "Ramnath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Krishnan Ramnath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711695"
                        ],
                        "name": "I. Matthews",
                        "slug": "I.-Matthews",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Matthews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Matthews"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another form of hidden markers was also used in  Ramnath et al. (2008 ) t o provide a sparse ground-truth alignment (or flow) of face images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Of the various possible techniques\u2014synthetic data (Barron et al. 1994; McCane et al. 2001), some form of hidden markers (Mova LLC 2004; Tappen et al. 2006;  Ramnath et al. 2008 ), human annotation (Liu et al. 2008), interpolation data (Szeliski 1999), and modified stereo data (Scharstein and Szeliski 2003)\u2014the authors believe that synthetic data is probably the best approach (although generating high-quality synthetic data is not as easy as ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5768704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23635e4d490edcaccdb0d218fabc40dc4734fd76",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Active appearance models (AAMs) typically only use 50-100 mesh vertices because they are usually constructed from a set of training images with the vertices hand-labeled on them. In this paper, we propose an algorithm to increase the density of an AAM. Our algorithm operates by iteratively building the AAM, refitting the AAM to the training data, and refining the AAM.We compare our algorithm with the state of the art in optical flow algorithms and find it to be significantly more accurate. We also show that dense AAMs can be fit more robustly than sparse ones. Finally, we show how our algorithm can be used to construct AAMs automatically, starting with a single affine model that is subsequently refined to model non-planarity and non-rigidity."
            },
            "slug": "Increasing-the-density-of-Active-Appearance-Models-Ramnath-Baker",
            "title": {
                "fragments": [],
                "text": "Increasing the density of Active Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes an algorithm to increase the density of an AAM, and shows how the algorithm can be used to construct AAMs automatically, starting with a single affine model that is subsequently refined to model non-planarity and non-rigidity."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A related approach is to use an affine prior ( Ju et al. 1996; "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The regularization of transparent motion in the framework of global energy minimization, however, has received little attention with the exception of  Ju et al. (1996) , Weiss (1997), and Shizawa and Mase (1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "above. Ju et al. formulate the prior so that neighboring affine parameters should be similar ( Ju et al. 1996 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7771830,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69b22ec0935d6996470a369cbd54e53548e6e2f5",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new method for estimating optical flow that strikes a balance between the flexibility of local dense computations and the robustness and accuracy of global parameterized flow models. An affine model of image motion is used within local image patches while a spatial smoothness constraint on the affine flow parameters of neighboring patches enforces continuity of the motion. We refer to this as a \"Skin and Bones\" model in which the affine patches can be thought of as rigid \"bones\" connected by a flexible \"skin\". Since local image patches may contain multiple motions we use a layered representation for the affine bones. To regularize this layered motion representation we develop a new framework for regularization with transparency."
            },
            "slug": "Skin-and-bones:-multi-layer,-locally-affine,-flow-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Skin and bones: multi-layer, locally affine, optical flow and regularization with transparency"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new method for estimating optical flow that strikes a balance between the flexibility of local dense computations and the robustness and accuracy of global parameterized flow models is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 95
                            }
                        ],
                        "text": "Many areas of computer vision, such as stereo (Scharstein and Szeliski 2002), face recognition (Philips et al. 2005; Sim et al. 2003; Gross et al. 2008; Georghiades et al. 2001), and object recognition (Fei-Fei et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9234219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6642e9c6cf7432e2d11b7edf7cd47f1285acd54e",
            "isKey": false,
            "numCitedBy": 4696,
            "numCiting": 163,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions."
            },
            "slug": "From-Few-to-Many:-Illumination-Cone-Models-for-Face-Georghiades-Belhumeur",
            "title": {
                "fragments": [],
                "text": "From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A generative appearance-based method for recognizing human faces under variation in lighting and viewpoint that exploits the fact that the set of images of an object in fixed pose but under all possible illumination conditions, is a convex cone in the space of images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2677311"
                        ],
                        "name": "W. Enkelmann",
                        "slug": "W.-Enkelmann",
                        "structuredName": {
                            "firstName": "Wilfried",
                            "lastName": "Enkelmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Enkelmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For example,  Nagel and Enkelmann (1986)  and Werlberger et al. (2009) weight the direction along the image gradient less than the direction orthogonal to it, and Sun et al. (2008) learn a Steerable Random Field to define the weighting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6399274,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8454b1f86a3ad5a7b692b956fc8ef7fb4aca9377",
            "isKey": false,
            "numCitedBy": 993,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A mapping between one frame from an image sequence and the preceding or following frame can be represented as a displacement vector field. In most situations, the mere gray value variations do not provide sufficient information in order to estimate such a displacement vector field. Supplementary constraints are necessary, for example the postulate that a displacement vector field varies smoothly as a function of the image position. Taken as a general requirement, this creates difficulties at gray value transitions which correspond to occluding contours. Nagel therefore introduced the ``oriented smoothness'' requirement which restricts variations of the displacement vector field only in directions with small or no variation of gray values. This contribution reports results of an investigation about how such an ``oriented smoothness'' constraint may be formulated and evaluated."
            },
            "slug": "An-Investigation-of-Smoothness-Constraints-for-the-Nagel-Enkelmann",
            "title": {
                "fragments": [],
                "text": "An Investigation of Smoothness Constraints for the Estimation of Displacement Vector Fields from Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Results are reported of an investigation about how an ``oriented smoothness'' constraint may be formulated and evaluated about how variations of the displacement vector field only in directions with small or no variation of gray values are restricted."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An early use of this idea for flow estimation employed simulated annealing with a state space that adapted based on the local shape of the objective function ( Black and Anandan 1991 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Given more than two frames in the video, it is also possible to add temporal smoothness terms \u2202u \u2202t and \u2202v \u2202t to (9) (Murray and Buxton 1987;  Black and Anandan 1991 ; B rox et al.2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15551602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5b4091691a32076c78a0f354994977230f95c23",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach to incrementally estimating visual motion over a sequence of images is presented. The authors start by formulating constraints on image motion to account for the possibility of multiple motions. This is achieved by exploiting the notions of weak continuity and robust statistics in the formulation of a minimization problem. The resulting objective function is non-convex. Traditional stochastic relaxation techniques for minimizing such functions prove inappropriate for the task. A highly parallel incremental stochastic minimization algorithm is presented which has a number of advantages over previous approaches. The incremental nature of the scheme makes it dynamic and permits the detection of occlusion and disocclusion boundaries.<<ETX>>"
            },
            "slug": "Robust-dynamic-motion-estimation-over-time-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "Robust dynamic motion estimation over time"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A highly parallel incremental stochastic minimization algorithm is presented which has a number of advantages over previous approaches and the incremental nature of the scheme makes it dynamic and permits the detection of occlusion and disocclusion boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023166"
                        ],
                        "name": "N. Nandhakumar",
                        "slug": "N.-Nandhakumar",
                        "structuredName": {
                            "firstName": "Nagaraj",
                            "lastName": "Nandhakumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nandhakumar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "We build a scene that can be moved in very small steps by a computercontrolled motion stage."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53680608,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "a03c5a0bbe99c87a6fdcb5ea8c37cbc776fde993",
            "isKey": false,
            "numCitedBy": 766,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments are reviewed in the computation of motion and structure of objects in a scene from a sequence of images. Two distinct paradigms are highlighted: (i) the feature-based approach and (ii) the optical-flow-based approach. The comparative merits/demerits of these approaches are discussed. The current status of research in these areas is reviewed and future research directions are indicated. >"
            },
            "slug": "On-the-computation-of-motion-from-sequences-of-Aggarwal-Nandhakumar",
            "title": {
                "fragments": [],
                "text": "On the computation of motion from sequences of images-A review"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Two distinct paradigms are highlighted: (i) the feature- based approach and (ii) the optical-flow-based approach: the comparative merits/demerits of these approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13905674"
                        ],
                        "name": "F. Glazer",
                        "slug": "F.-Glazer",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Glazer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Glazer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143816432"
                        ],
                        "name": "G. Reynolds",
                        "slug": "G.-Reynolds",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Reynolds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Reynolds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 134
                            }
                        ],
                        "text": "Various correlation constraints can be used for computing dense flow including normalized cross correlation and Laplacian correlation (Burt et al. 1983; Glazer et al. 1983; Sun 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 90
                            }
                        ],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling (Lucas and Kanade 1981; Glazer et al. 1983; Burt et al. 1983; Enkelman 1986; Anandan 1989; Black and Anandan 1996; Battiti et al. 1991; Bruhn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117033770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80ae9639809cda98d69f2f873c12251531604078",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In this paper the authors present an implementation of hierarchical scene matching in the VISIONS image processing cone - a pyramidal processing architecture. The problem of scene matching is common to many applications in machine vision including registration, motion detection, and stereo vision. Scene matching by feature correlation can solve this problem but suffers from computational expense and failure in highly textured images. Hierarchical correlation provides both a cheaper matching algorithm and a coarse-to-fine matching strategy that overcomes textural problems by matching on gross image structures first. These methods fit naturally into the processing cone or pyramid architectures that have been proposed for image processing. Presented is a discussion of the architecture of the processing cone, the construction of image pyramids, and the use of these pyramids in hierarchical correlation. A set of experiments illustrates the operation of these ideas."
            },
            "slug": "Scene-Matching-by-Hierarchical-Correlation-Glazer-Reynolds",
            "title": {
                "fragments": [],
                "text": "Scene Matching by Hierarchical Correlation"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An implementation of hierarchical scene matching in the VISIONS image processing cone - a pyramidal processing architecture that provides both a cheaper matching algorithm and a coarse-to-fine matching strategy that overcomes textural problems by matching on gross image structures first."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "The computer repeatedly takes a pair of high-resolution images both under ambient lighting and under UV lighting, and then moves the scene (and possibly the camera) by a small amount."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34995520,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "a0d00264c3f5616a9c8f00ca70d0864a31a38cf2",
            "isKey": false,
            "numCitedBy": 2258,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book presents a coherent approach to the fast-moving field of computer vision, using a consistent notation based on a detailed understanding of the image formation process. It covers even the most recent research and will provide a useful and current reference for professionals working in the fields of machine vision, image processing, and pattern recognition. \nAn outgrowth of the author's course at MIT, Robot Vision presents a solid framework for understanding existing work and planning future research. Its coverage includes a great deal of material that is important to engineers applying machine vision methods in the real world. The chapters on binary image processing, for example, help explain and suggest how to improve the many commercial devices now available. And the material on photometric stereo and the extended Gaussian image points the way to what may be the next thrust in commercialization of the results in this area. \nChapters in the first part of the book emphasize the development of simple symbolic descriptions from images, while the remaining chapters deal with methods that exploit these descriptions. The final chapter offers a detailed description of how to integrate a vision system into an overall robotics system, in this case one designed to pick parts out of a bin. \nThe many exercises complement and extend the material in the text, and an extensive bibliography will serve as a useful guide to current research. \nErrata (164k PDF)"
            },
            "slug": "Robot-vision-Horn",
            "title": {
                "fragments": [],
                "text": "Robot vision"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This book presents a coherent approach to the fast-moving field of computer vision, using a consistent notation based on a detailed understanding of the image formation process, and will provide a useful and current reference for professionals working in the fields of machine vision, image processing, and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "MIT electrical engineering and computer science series"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35137706"
                        ],
                        "name": "J. Bouguet",
                        "slug": "J.-Bouguet",
                        "structuredName": {
                            "firstName": "J.-Y.",
                            "lastName": "Bouguet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bouguet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Pyramid LK: An implementation [5] of the Lucas-Kanade algorithm [11] on a pyramid, subsequently refined at Microsoft Research."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9350588,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aa972b40c0f8e20b07e02d1fd320bc7ebadfdfc7",
            "isKey": false,
            "numCitedBy": 2527,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Problem Statement Let I and J be two 2D grayscaled images. The two quantities I(x) = I(x, y) and J(x) = J(x, y) are then the grayscale value of the two images are the location x = [x y] , where x and y are the two pixel coordinates of a generic image point x. The image I will sometimes be referenced as the first image, and the image J as the second image. For practical issues, the images I and J are discret function (or arrays), and the upper left corner pixel coordinate vector is [0 0] . Let nx and ny be the width and height of the two images. Then the lower right pixel coordinate vector is [nx \u2212 1 ny \u2212 1] . Consider an image point u = [ux uy] on the first image I. The goal of feature tracking is to find the location v = u + d = [ux+dx uy +dy] on the second image J such as I(u) and J(v) are \u201csimilar\u201d. The vector d = [dx dy] is the image velocity at x, also known as the optical flow at x. Because of the aperture problem, it is essential to define the notion of similarity in a 2D neighborhood sense. Let \u03c9x and \u03c9y two integers. We define the image velocity d as being the vector that minimizes the residual function defined as follows:"
            },
            "slug": "Pyramidal-implementation-of-the-lucas-kanade-Bouguet",
            "title": {
                "fragments": [],
                "text": "Pyramidal implementation of the lucas kanade feature tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is essential to define the notion of similarity in a 2D neighborhood sense and the image velocity d is defined as being the vector that minimizes the residual function defined as follows."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52026794"
                        ],
                        "name": "R. Gmbh",
                        "slug": "R.-Gmbh",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gmbh",
                            "middleNames": [
                                "Bosch"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gmbh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085826290"
                        ],
                        "name": "INRS-T\u00e9l\u00e9communications",
                        "slug": "INRS-T\u00e9l\u00e9communications",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "INRS-T\u00e9l\u00e9communications",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "INRS-T\u00e9l\u00e9communications"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Note that our taxonomy is similar to those of Stiller and Konrad [69] for optical flow and Scharstein and Szeliski [63] for stereo."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "[7], Otte and Nagel [53], Mitiche and Bouthemy [47], and Stiller and Konrad [69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 156
                            }
                        ],
                        "text": "Interested readers are referred to previous surveys by Aggarwal and Nandhakumar [1], Barron et al. [2], Otte and Nagel [16], Mitiche and Bouthemy [14],\nand Stiller and Konrad [23]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14272415,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "6ba88ed675cc7aafb77e00739dfe1ca9e985cd37",
            "isKey": true,
            "numCitedBy": 120,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "christoph.stiller@@fr.bosch.de konrad@@inrs-telecom.uquebec.ca c \u00a9 1999 IEEE. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE."
            },
            "slug": "Estimating-Motion-in-Image-Sequences-A-tutorial-on-Gmbh-INRS-T\u00e9l\u00e9communications",
            "title": {
                "fragments": [],
                "text": "Estimating Motion in Image Sequences A tutorial on modeling and computation of 2 D motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405719070"
                        ],
                        "name": "H. Zimmer",
                        "slug": "H.-Zimmer",
                        "structuredName": {
                            "firstName": "Henning",
                            "lastName": "Zimmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zimmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144031005"
                        ],
                        "name": "Andr\u00e9s Bruhn",
                        "slug": "Andr\u00e9s-Bruhn",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Bruhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Bruhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797649"
                        ],
                        "name": "Levi Valgaerts",
                        "slug": "Levi-Valgaerts",
                        "structuredName": {
                            "firstName": "Levi",
                            "lastName": "Valgaerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Levi Valgaerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2531425"
                        ],
                        "name": "A. D. L. Nuez",
                        "slug": "A.-D.-L.-Nuez",
                        "structuredName": {
                            "firstName": "Agust\u00edn",
                            "lastName": "Nuez",
                            "middleNames": [
                                "Salgado",
                                "de",
                                "la"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. L. Nuez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779035"
                        ],
                        "name": "B. Rosenhahn",
                        "slug": "B.-Rosenhahn",
                        "structuredName": {
                            "firstName": "Bodo",
                            "lastName": "Rosenhahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rosenhahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145156858"
                        ],
                        "name": "H. Seidel",
                        "slug": "H.-Seidel",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Seidel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seidel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Adaptive (Wedel et al. 2009) 9.2 Seg OF ( Xu et al. 2008  )6 0"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Such sparse matching method can be combined with the continuous energy minimization approaches in a variety of ways (Brox et al. 2009; Liu et al. 2008 ;R en2008;  Xu et al. 2008 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Explicit occlusion estimation, for example through crosschecking flows computed forwards and backwards in time, is another approach that can be used to improve robustness to occlusions and visibility changes ( Xu et al. 2008;  Lei and Yang 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12858219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "614feffdcac35006e0c2870e9215911e6dff60cb",
            "isKey": true,
            "numCitedBy": 127,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the concept of complementarity between data and smoothness term in modern variational optic flow methods. First we design a sophisticated data term that incorporates HSV colour representation with higher order constancy assumptions, completely separate robust penalisation, and constraint normalisation. Our anisotropic smoothness term reduces smoothing in the data constraint direction instead of the image edge direction, while enforcing a strong filling-in effect orthogonal to it. This allows optimal complementarity between both terms and avoids undesirable interference. The high quality of our complementary optic flow (COF) approach is demonstrated by the current top ranking result at the Middlebury benchmark."
            },
            "slug": "Complementary-Optic-Flow-Zimmer-Bruhn",
            "title": {
                "fragments": [],
                "text": "Complementary Optic Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work designs a sophisticated data term that incorporates HSV colour representation with higher order constancy assumptions, completely separate robust penalisation, and constraint normalisation and introduces the concept of complementarity between data and smoothness term in modern variational optic flow methods."
            },
            "venue": {
                "fragments": [],
                "text": "EMMCVPR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996106"
                        ],
                        "name": "Werner Trobin",
                        "slug": "Werner-Trobin",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Trobin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Werner Trobin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Second-order prior ( Trobin et al. 2008 ) 14 TI-DOFE (Cassisa et al. 2009) 260"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The second optimization is often simpler because it does not depend directly on the nonlinear data term ( Trobin et al. 2008;  Wedel et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2202x\u2202y ) to be small (Anandan and Weiss 1985;  Trobin et al. 2008 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Algorithms such as Jung et al. (2008), Lempitsky et al. (2008) and  Trobin et al. (2008)  assume that a number of candidate flow fields have been generated by running standard algorithms such as Lucas and Kanade (1981), and Horn and Schunck (1981), possibly multiple times with a number of different parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An illustration of this point is included in Fig. 13 .W e include both flow and interpolation results for DPOF (Lei and Yang 2009) and CBF ( Trobin et al. 2008  )o n theTeddy sequence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, CBF ( Trobin et al. 2008 ) performs better on the All and Disc regions than it does on the Untext regions, which explains why the NE rank for this algorithm is slightly higher than the IE rank."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " Trobin et al. (2008)  perform a similar sequence of fusion steps, at each step solving a continuous [0, 1] optimization problem and then thresholding the results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Algorithms such as CBF ( Trobin et al. 2008 ) and DPOF (Lei and Yang 2009), which are relatively robust but not so accurate (compare the performance of these algorithms for R0.5 and R2.0 in Fig. 9), therefore perform worse in terms of R2.5 than they do in terms of R5.0 and R10.0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Fig. 13 A comparison of the flow and interpolation results for DPOF (Lei and Yang 2009) and CBF ( Trobin et al. 2008  )o n theTeddy sequence to illustrate the differences between the two measures of performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "CBF ( Trobin et al. 2008 ) 69 SPSA-learn (Li and Huttenlocher 2008) 200"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another approach ( Trobin et al. 2008;  Wedel et al. 2008 )i s to decouple the data and prior terms through the introduction of two sets of flow parameters, say (udata ,v data) for the data term and (uprior ,v prior) for the prior:"
                    },
                    "intents": []
                }
            ],
            "corpusId": 14241171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cc91fb467f963ec948eee7346d022becb6a13cb",
            "isKey": true,
            "numCitedBy": 41,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational problems, which are commonly used to solve low-level vision tasks, are typically minimized via a local, iterative optimization strategy, e.g. gradient descent. Since every iteration is restricted to a small, local improvement, the overall convergence can be slow and the algorithm may get stuck in an undesirable local minimum. In this paper, we propose to approximate the minimization by solving a series of binary subproblems to facilitate large optimization moves. The proposed method can be interpreted as an extension of discrete graph-cut based methods such as \u03b1-expansion or LogCut to a spatially continuous setting. In order to demonstrate the viability of the approach, we evaluated the novel optimization strategy in the context of optical flow estimation, yielding excellent results on the Middlebury optical flow datasets."
            },
            "slug": "Continuous-Energy-Minimization-Via-Repeated-Binary-Trobin-Pock",
            "title": {
                "fragments": [],
                "text": "Continuous Energy Minimization Via Repeated Binary Fusion"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The proposed method can be interpreted as an extension of discrete graph-cut based methods such as \u03b1-expansion or LogCut to a spatially continuous setting to facilitate large optimization moves."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730097"
                        ],
                        "name": "T. Pock",
                        "slug": "T.-Pock",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076653685"
                        ],
                        "name": "M. Pock",
                        "slug": "M.-Pock",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Pock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One disadvantage of variational algorithms is that the discretization of the Euler-Lagrange equations is not always exact with respect to the original energy ( Pock et al. 2007 )."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1513882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2fb57c3fce6f82b6d49b9988aaa7d4d071eef7",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "Many vision problems can be formulated as minimization of appropriate energy functionals. These energy functionals are usually minimized, based on the calculus of variations (Euler-Lagrange equation). Once the Euler-Lagrange equation has been determined, it needs to be discretized in order to implement it on a digital computer. This is not a trivial task and, is moreover, error- prone. In this paper, we propose a flexible alternative. We discretize the energy functional and, subsequently, apply the mathematical concept of algorithmic differentiation to directly derive algorithms that implement the energy functional's derivatives. This approach has several advantages: First, the computed derivatives are exact with respect to the implementation of the energy functional. Second, it is basically straightforward to compute second-order derivatives and, thus, the Hessian matrix of the energy functional. Third, algorithmic differentiation is a process which can be automated. We demonstrate this novel approach on three representative vision problems (namely, denoising, segmentation, and stereo) and show that state-of-the-art results are obtained with little effort."
            },
            "slug": "Algorithmic-Differentiation:-Application-to-in-Pock-Pock",
            "title": {
                "fragments": [],
                "text": "Algorithmic Differentiation: Application to Variational Problems in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper discretize the energy functional and, subsequently, applies the mathematical concept of algorithmic differentiation to directly derive algorithms that implement the energyfunctional's derivatives."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143895392"
                        ],
                        "name": "T. Cooke",
                        "slug": "T.-Cooke",
                        "structuredName": {
                            "firstName": "Tristrom",
                            "lastName": "Cooke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cooke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18011652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a8f223302febf4d30e547cdfeeb4ecac0d4e08f",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Graph-cut methods have become an intensive area of research in image processing, with applications to stereo vision, binary thresholding, classification and image de-noising amongst other areas. This paper describes novel graph-cut implementations for use in two applications: 2D optical flow and interactive object delineation. The optical flow implementation is based on recursive application of graph-cuts, and is shown to perform favourably with state-of-the-art methods. The delineation method is novel in that it requires only a single point to be selected for a delineation to be achieved, and uses a different type of graph topology compared to the traditional methods."
            },
            "slug": "Two-Applications-of-Graph-Cuts-to-Image-Processing-Cooke",
            "title": {
                "fragments": [],
                "text": "Two Applications of Graph-Cuts to Image Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The delineation method is novel in that it requires only a single point to be selected for a delineation to be achieved, and uses a different type of graph topology compared to the traditional methods."
            },
            "venue": {
                "fragments": [],
                "text": "2008 Digital Image Computing: Techniques and Applications"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2278902"
                        ],
                        "name": "V. Markandey",
                        "slug": "V.-Markandey",
                        "structuredName": {
                            "firstName": "Vishal",
                            "lastName": "Markandey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Markandey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3252851"
                        ],
                        "name": "B. Flinchbaugh",
                        "slug": "B.-Flinchbaugh",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Flinchbaugh",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flinchbaugh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another issue, addressed by a number of authors (Ohta 1989;  Markandey and Flinchbaugh 1990;  Golland and Bruckstein 1997), is how to modify the data term for color or multi-band images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31581537,
            "fieldsOfStudy": [
                "Physics",
                "Environmental Science",
                "Mathematics"
            ],
            "id": "e8ee6d73f077541e35a85f2f796ff5c2006ac9bd",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Multispectral constraints are exploited for optical flow computation. The theoretical basis and conditions for using multispectral images are described. An optical flow algorithm using multispectral constraints is outlined. Tests of the algorithm on real image sequences show that various multispectral constraints from the visible and infrared spectrum can be used to compute optical flow fields in the presence of noise.<<ETX>>"
            },
            "slug": "Multispectral-constraints-for-optical-flow-Markandey-Flinchbaugh",
            "title": {
                "fragments": [],
                "text": "Multispectral constraints for optical flow computation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Tests of the algorithm on real image sequences show that various multispectral constraints from the visible and infrared spectrum can be used to compute optical flow fields in the presence of noise."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067993"
                        ],
                        "name": "W. T. Scruggs",
                        "slug": "W.-T.-Scruggs",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Scruggs",
                            "middleNames": [
                                "Todd"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. T. Scruggs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400601690"
                        ],
                        "name": "A. O'Toole",
                        "slug": "A.-O'Toole",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "O'Toole",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Toole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704876"
                        ],
                        "name": "P. Flynn",
                        "slug": "P.-Flynn",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Flynn",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Flynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144601844"
                        ],
                        "name": "K. W. Boyer",
                        "slug": "K.-W.-Boyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Boyer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. W. Boyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153531021"
                        ],
                        "name": "Cathy L. Schott",
                        "slug": "Cathy-L.-Schott",
                        "structuredName": {
                            "firstName": "Cathy",
                            "lastName": "Schott",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cathy L. Schott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055055507"
                        ],
                        "name": "Matthew Sharpe",
                        "slug": "Matthew-Sharpe",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Sharpe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Sharpe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Many areas of computer vision, such as stereo [19], face recognition [17], and object recognition [8], have challenging datasets to track the progress made by leading algorithms and to stimulate new ideas."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58409227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "189a7b14efb53fc0e66aea1ac005782b8a073e38",
            "isKey": false,
            "numCitedBy": 460,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This report describes the large-scale experimental results from the Face Recognition Vendor Test (FRVT) 2006 and the Iris Challenge Evaluation (ICE) 2006. The FRVT 2006 looks at recognition from high-resolution still images and three-dimensional (3D) face images, and measures performance for still images taken under controlled and uncontrolled illumination. The ICE 2006 reports iris recognition performance from left and right iris images. The FRVT 2006 results from controlled still images and 3D images document an order-of-magnitude improvement in recognition performance over the FRVT 2002. This order-of-magnitude improvement was one of the goals of the preceding technology development effort, the Face Recognition Grand Challenge (FRGC). The FRVT 2006 and the ICE 2006 compared recognition performance from very-high resolution still face images, 3D face images, and single-iris images. On the FRVT 2006 and the ICE 2006 datasets, recognition performance was comparable for all three biometrics. In an experiment comparing human and algorithm performance, the best-performing face recognition algorithms were more accurate than humans. These and other results are discussed in detail. \u2217Please direct correspondence to P. Jonathon Phillips at jonathon@nist.gov. We acknowledge the support of Department of Homeland Security\u2019s Science and Technology Department and Transportation Security Administration (TSA), the Director of National Intelligence\u2019s Information Technology Innovation Center, the Federal Bureau of Investigation (FBI), the National Institute of Justice, and the Technical Support Working Group (TSWG). The identification of any commercial product or trade name does not imply endorsement or recommendation by the National Institute of Standards and Technology, SAIC, Schafer Corp., U. of Texas at Dallas or U. of Notre Dame. 1"
            },
            "slug": "FRVT-2006-and-ICE-2006-large-scale-results-Phillips-Scruggs",
            "title": {
                "fragments": [],
                "text": "FRVT 2006 and ICE 2006 large-scale results"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "On the FRVT 2006 and the ICE 2006 datasets, recognition performance was comparable for all three biometrics and the best-performing face recognition algorithms were more accurate than humans."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling ( Lucas and Kanade 1981;  Glazer et al. 1983 ;B urt et al.1983; Enkelman 1986; Anandan 1989; Black and Anandan 1996; Battiti et al. 1991; Bruhn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Dynamic MRF (Glocker et al. 2008) 366 Pyramid LK ( Lucas and Kanade 1981 ) 11.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Algorithms such as Jung et al. (2008), Lempitsky et al. (2008) and Trobin et al. (2008) assume that a number of candidate flow fields have been generated by running standard algorithms such as  Lucas and Kanade (1981) , and Horn and Schunck (1981), possibly multiple times with a number of different parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These algorithms are applicable to problems with fewer parameters such as the Lucas-Kanade algorithm ( Lucas and Kanade 1981 ) and variants (Le Besnerais and Champagnat 2005), which solve for a single flow vector (2 unknowns) independently for each block of pixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": true,
            "numCitedBy": 13329,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31155131"
                        ],
                        "name": "M. Shizawa",
                        "slug": "M.-Shizawa",
                        "structuredName": {
                            "firstName": "Masahiko",
                            "lastName": "Shizawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shizawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722602"
                        ],
                        "name": "K. Mase",
                        "slug": "K.-Mase",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Mase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mase"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7298011,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dc82711ccafdddcaf707d683d34b8ba26ee3ef47",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A unified theoretical framework for motion transparency and motion boundaries by devising fundamental constraint equations of multiple optical flow is proposed. This framework can handle flow discontinuities at motion boundaries as well as flow multiplicities due to transparency of objects in a unified manner. The constraint equations are formulated by a composition of homogeneously parametrized differential operators on the space-time image. Fitting algorithms for the constraints which result in eigensystem analyses are described. To determine the number of flows, the authors use the margin energy, a measure of goodness of fit which is the difference between the first and the second lower eigenenergy of the eigensystem. They also hypothesize a criterion for multiplicity. The measure and the criterion are derived from the analogy of quantum mechanics. It is demonstrated that the margin energy can determine the transparency and discontinuities of the flow field as regions of more than one flow.<<ETX>>"
            },
            "slug": "Unified-computational-theory-for-motion-and-motion-Shizawa-Mase",
            "title": {
                "fragments": [],
                "text": "Unified computational theory for motion transparency and motion boundaries based on eigenenergy analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated that the margin energy can determine the transparency and discontinuities of the flow field as regions of more than one flow, and hypothesize a criterion for multiplicity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3315356"
                        ],
                        "name": "K. Hanna",
                        "slug": "K.-Hanna",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Hanna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hanna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055557"
                        ],
                        "name": "R. Hingorani",
                        "slug": "R.-Hingorani",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Hingorani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hingorani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We also exclude more global representations of the motion such as parametric motion estimates ( Bergen et al. 1992 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another set of examples are parametric motion algorithms ( Bergen et al. 1992 ), which also just solve for a small number of unknowns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Incremental warping of the flow between pyramid levels ( Bergen et al. 1992 ) helps keep the flow update at any given level small (i.e., under one pixel)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Within each image segment, Black and Jepson (1996) use a parametric model (e.g., affine) ( Bergen et al. 1992 ), which simplifies the problem by reducing the number of parameters to be estimated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6267598,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "404f3544a7db67c38ba3b8f78f02759d2326684e",
            "isKey": true,
            "numCitedBy": 1510,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a hierarchical estimation framework for the computation of diverse representations of motion information. The key features of the resulting framework (or family of algorithms) are a global model that constrains the overall structure of the motion estimated, a local model that is used in the estimation process, and a coarse-fine refinement strategy. Four specific motion models: affine flow, planar surface flow, rigid body motion, and general optical flow, are described along with their application to specific examples."
            },
            "slug": "Hierarchical-Model-Based-Motion-Estimation-Bergen-Anandan",
            "title": {
                "fragments": [],
                "text": "Hierarchical Model-Based Motion Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper describes a hierarchical estimation framework for the computation of diverse representations of motion information that constrains the overall structure of the motion estimated, a local model that is used in the estimation process, and a coarse-fine refinement strategy."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801789"
                        ],
                        "name": "M. Levoy",
                        "slug": "M.-Levoy",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Levoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Levoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2291796,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "da56fd4c768715af5e455847d8e8c018a2e87d90",
            "isKey": false,
            "numCitedBy": 2732,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of volume-rendering techniques to the display of surfaces from sampled scalar functions of three spatial dimensions is discussed. It is not necessary to fit geometric primitives to the sampled data; images are formed by directly shading each sample and projecting it onto the picture plane. Surface-shading calculations are performed at every voxel with local gradient vectors serving as surface normals. In a separate step, surface classification operators are applied to compute a partial opacity of every voxel. Operators that detect isovalue contour surfaces and region boundary surfaces are examined. The technique is simple and fast, yet displays surfaces exhibiting smooth silhouettes and few other aliasing artifacts. The use of selective blurring and supersampling to further improve image quality is described. Examples from molecular graphics and medical imaging are given.<<ETX>>"
            },
            "slug": "Display-of-surfaces-from-volume-data-Levoy",
            "title": {
                "fragments": [],
                "text": "Display of surfaces from volume data"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The application of volume-rendering techniques to the display of surfaces from sampled scalar functions of three spatial dimensions and the use of selective blurring and supersampling to further improve image quality is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Graphics and Applications"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067071261"
                        ],
                        "name": "Terence Sim",
                        "slug": "Terence-Sim",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Sim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terence Sim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3240967"
                        ],
                        "name": "Maan Bsat",
                        "slug": "Maan-Bsat",
                        "structuredName": {
                            "firstName": "Maan",
                            "lastName": "Bsat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maan Bsat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Many areas of computer vision, such as stereo (Scharstein and Szeliski 2002), face recognition (Philips et al. 2005;  Sim et al. 2003;  Gross et al. 2008; Georghiades et al. 2001), and object recognition (Fei-Fei et al. 2006; Everingham et al. 2009), have challenging datasets to track the progress made by leading algorithms and to stimulate new ideas."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16950643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ffa7a36e5414a0f2b16b1d8f93442ab15e2235d",
            "isKey": false,
            "numCitedBy": 1796,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In the Fall of 2000, we collected a database of more than 40,000 facial images of 68 people. Using the Carnegie Mellon University 3D Room, we imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions. We call this the CMU pose, illumination, and expression (PIE) database. We describe the imaging hardware, the collection procedure, the organization of the images, several possible uses, and how to obtain the database."
            },
            "slug": "The-CMU-Pose,-Illumination,-and-Expression-Database-Sim-Baker",
            "title": {
                "fragments": [],
                "text": "The CMU Pose, Illumination, and Expression Database"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "In the Fall of 2000, a database of more than 40,000 facial images of 68 people was collected using the Carnegie Mellon University 3D Room to imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704876"
                        ],
                        "name": "P. Flynn",
                        "slug": "P.-Flynn",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Flynn",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Flynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067993"
                        ],
                        "name": "W. T. Scruggs",
                        "slug": "W.-T.-Scruggs",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Scruggs",
                            "middleNames": [
                                "Todd"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. T. Scruggs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143759604"
                        ],
                        "name": "K. Bowyer",
                        "slug": "K.-Bowyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Bowyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bowyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153056438"
                        ],
                        "name": "Jin Chang",
                        "slug": "Jin-Chang",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054926934"
                        ],
                        "name": "Kevin Hoffman",
                        "slug": "Kevin-Hoffman",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Hoffman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39544740"
                        ],
                        "name": "Joe Marques",
                        "slug": "Joe-Marques",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Marques",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joe Marques"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3221917"
                        ],
                        "name": "Jaesik Min",
                        "slug": "Jaesik-Min",
                        "structuredName": {
                            "firstName": "Jaesik",
                            "lastName": "Min",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaesik Min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061326"
                        ],
                        "name": "W. Worek",
                        "slug": "W.-Worek",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Worek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Worek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " Otte and Nagel (1994)  introduced ground truth for a real scene consisting of polyhedral objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 Error Metrics: We report both average angular error (Barron et al. 1994) and flow endpoint error (pixel distance) ( Otte and Nagel 1994 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For more extensive coverage of older work, the reader is referred to previous surveys such as those by Aggarwal and Nandhakumar (1988), Barron et al. (1994),  Otte and Nagel (1994) , Mitiche and Bouthemy (1996), and Stiller and Konrad (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 844981,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "279538cc476114a415a96d5889e01f26a4a9a00a",
            "isKey": true,
            "numCitedBy": 2531,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the last couple of years, face recognition researchers have been developing new techniques. These developments are being fueled by advances in computer vision techniques, computer design, sensor design, and interest in fielding face recognition systems. Such advances hold the promise of reducing the error rate in face recognition systems by an order of magnitude over Face Recognition Vendor Test (FRVT) 2002 results. The face recognition grand challenge (FRGC) is designed to achieve this performance goal by presenting to researchers a six-experiment challenge problem along with data corpus of 50,000 images. The data consists of 3D scans and high resolution still imagery taken under controlled and uncontrolled conditions. This paper describes the challenge problem, data corpus, and presents baseline performance and preliminary results on natural statistics of facial imagery."
            },
            "slug": "Overview-of-the-face-recognition-grand-challenge-Phillips-Flynn",
            "title": {
                "fragments": [],
                "text": "Overview of the face recognition grand challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The face recognition grand challenge (FRGC) is designed to achieve this performance goal by presenting to researchers a six-experiment challenge problem along with data corpus of 50,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33731953"
                        ],
                        "name": "R. Gross",
                        "slug": "R.-Gross",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711695"
                        ],
                        "name": "I. Matthews",
                        "slug": "I.-Matthews",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Matthews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Matthews"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737918"
                        ],
                        "name": "J. Cohn",
                        "slug": "J.-Cohn",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Cohn",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "Instead we focus here on the evaluation of optical flow algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208935309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5194ab36d5cb9d773a86bd4e9c8e181d70e2e34",
            "isKey": false,
            "numCitedBy": 1200,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A close relationship exists between the advancement of face recognition algorithms and the availability of face databases varying factors that affect facial appearance in a controlled manner. The CMU PIE database has been very influential in advancing research in face recognition across pose and illumination. Despite its success the PIE database has several shortcomings: a limited number of subjects, a single recording session and only few expressions captured. To address these issues we collected the CMU Multi-PIE database. It contains 337 subjects, imaged under 15 view points and 19 illumination conditions in up to four recording sessions. In this paper we introduce the database and describe the recording procedure. We furthermore present results from baseline experiments using PCA and LDA classifiers to highlight similarities and differences between PIE and Multi-PIE."
            },
            "slug": "Multi-PIE-Gross-Matthews",
            "title": {
                "fragments": [],
                "text": "Multi-PIE"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper introduces the database, describes the recording procedure, and presents results from baseline experiments using PCA and LDA classifiers to highlight similarities and differences between PIE and Multi-PIE."
            },
            "venue": {
                "fragments": [],
                "text": "2008 8th IEEE International Conference on Automatic Face & Gesture Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Many areas of computer vision, such as stereo (Scharstein and Szeliski 2002), face recognition (Philips et al. 2005; Sim et al. 2003; Gross et al. 2008; Georghiades et al. 2001), and object recognition ( Fei-Fei et al. 2006;  Everingham et al. 2009), have challenging datasets to track the progress made by leading algorithms and to stimulate new ideas."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6953475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812355cec91fa30bb50e9e992a3549af39e4f6eb",
            "isKey": false,
            "numCitedBy": 2365,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by maximum likelihood (ML) and maximum a posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "slug": "One-shot-learning-of-object-categories-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "One-shot learning of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is found that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019208"
                        ],
                        "name": "Thaddeus Beier",
                        "slug": "Thaddeus-Beier",
                        "structuredName": {
                            "firstName": "Thaddeus",
                            "lastName": "Beier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thaddeus Beier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094398048"
                        ],
                        "name": "Shawn Neely",
                        "slug": "Shawn-Neely",
                        "structuredName": {
                            "firstName": "Shawn",
                            "lastName": "Neely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shawn Neely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If both pixels are visible, i.e., O0(x0) = 0 and O1(x1) = 0, blend the two images ( Beier and Neely 1992 ):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9124441,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "be73726c6a538bc3ed05e62ba5faec183f777ff6",
            "isKey": false,
            "numCitedBy": 833,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "2.1 Conventional Metamorphosis Techniques Mc[:ml(wpht)iii twlween lWo or mor\u2019c imafys (wer lime i) u uwi\u2019ul \\ i~u;ii tcchniquc. (Jflen uwd f\u2019orCducaliomd (n\u2019tMCid;liMll Cnt purpt>wi. \u20181\u2019l-:idi(ional Iilmmahing techniques for (his cflcc[ include ~\u2019lckcr c\u2019ut~(iuc\u2019h LISu chwwwr cxhibi(ing ch:mgm while running thr(mgll ;! toreil and prosing behind several trws ) tind op[ic:d cro\\\\diswdv<\u2019. in which onc image is f:ide(i out while wwther is sinwlt:lnLNNI\\l)f\u2019:idcdin (Mith makeup ch:mge. tippliwcm, or nhjecl subs[i [u[I(m ). Sc\\\u2019~\u2019riilclawic horror lilm~ illu$tfiite [he process: who ctwld hnycl ~hc b:lir-tai~ing (fiiniform;ilml of the Woitman. or the drw m:itic lllct;itll(~rpll(~sii from Dr. Jchyll [o Mr. Hyde\u2019? This pupcr prcwmls ii c(mtcnlp{mmy w~lu(i(mto the vi~u:d translonmrtion pnh lL\u2019nl."
            },
            "slug": "Feature-based-image-metamorphosis-Beier-Neely",
            "title": {
                "fragments": [],
                "text": "Feature-based image metamorphosis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "2.1 Conventional Metamorphosis Techniques Mc[:ml(wpht)iii twlween lWo or mor\u2019c imafys (wer lime i) u uwi\u2019ul \\ i~u;ii tcchniquc."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35202510"
                        ],
                        "name": "W. Pratt",
                        "slug": "W.-Pratt",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pratt",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pratt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An alternative to the assumption of \u201cconstancy\u201d is that the signals (images) at times t and t +1 are highly correlated ( Pratt 1974 ; B urt et al.1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51664713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b02664dc5ede65abcd764090fd859a1e2be4f22",
            "isKey": false,
            "numCitedBy": 346,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "An extension to the basic concept of correlation detection as a means of image registration is developed. The technique involves linear spatial preprocessing of the inages to be registered prior to the application of a correlation measure. This preprocessing operation utilizes the spatial correlation within each image and greatly improves the detectability of image misregistration. An analysis of the computational aspects of the algorithm is given. Also, results of a computer simulation to evaluate the technique are given."
            },
            "slug": "Correlation-Techniques-of-Image-Registration-Pratt",
            "title": {
                "fragments": [],
                "text": "Correlation Techniques of Image Registration"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "An extension to the basic concept of correlation detection as a means of image registration is developed that utilizes the spatial correlation within each image and greatly improves the detectability of image misregistration."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Aerospace and Electronic Systems"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915287313"
                        ],
                        "name": "H. Jung",
                        "slug": "H.-Jung",
                        "structuredName": {
                            "firstName": "Ho",
                            "lastName": "Jung",
                            "middleNames": [
                                "Yub"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135837"
                        ],
                        "name": "Kyoung Mu Lee",
                        "slug": "Kyoung-Mu-Lee",
                        "structuredName": {
                            "firstName": "Kyoung",
                            "lastName": "Lee",
                            "middleNames": [
                                "Mu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyoung Mu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153310963"
                        ],
                        "name": "Sang Uk Lee",
                        "slug": "Sang-Uk-Lee",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Lee",
                            "middleNames": [
                                "Uk"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sang Uk Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Algorithms such as  Jung et al. (2008) , Lempitsky et al. (2008) and Trobin et al. (2008) assume that a number of candidate flow fields have been generated by running standard algorithms such as Lucas and Kanade (1981), and Horn and Schunck (1981), possibly multiple times with a number of different parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10931137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60d3a1b8c558bca60d108d59a090565edf48a230",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many local and greedy algorithms for energy minimization over Markov Random Field (MRF) such as iterated condition mode (ICM) and various gradient descent methods. Local minima solutions can be obtained with simple implementations and usually require smaller computational time than global algorithms. Also, methods such as ICM can be readily implemented in a various difficult problems that may involve larger than pairwise clique MRFs. However, their short comings are evident in comparison to newer methods such as graph cut and belief propagation. The local minimum depends largely on the initial state, which is the fundamental problem of its kind. In this paper, disadvantages of local minima techniques are addressed by proposing ways to combine multiple local solutions. First, multiple ICM solutions are obtained using different initial states. The solutions are combined with random partitioning based greedy algorithm called Combined Local Minima (CLM). There are numerous MRF problems that cannot be efficiently implemented with graph cut and belief propagation, and so by introducing ways to effectively combine local solutions, we present a method to dramatically improve many of the pre-existing local minima algorithms. The proposed approach is shown to be effective on pairwise stereo MRF compared with graph cut and sequential tree re-weighted belief propagation (TRW-S). Additionally, we tested our algorithm against belief propagation (BP) over randomly generated 30 \u00d730 MRF with 2 \u00d72 clique potentials, and we experimentally illustrate CLM's advantage over message passing algorithms in computation complexity and performance."
            },
            "slug": "Toward-Global-Minimum-through-Combined-Local-Minima-Jung-Lee",
            "title": {
                "fragments": [],
                "text": "Toward Global Minimum through Combined Local Minima"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "There are numerous MRF problems that cannot be efficiently implemented with graph cut and belief propagation, and so by introducing ways to effectively combine local solutions, this paper presents a method to dramatically improve many of the pre-existing local minima algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Many areas of computer vision, such as stereo ( Scharstein and Szeliski 2002 ), face recognition (Philips et al. 2005; Sim et al. 2003; Gross et al. 2008; Georghiades et al. 2001), and object recognition (Fei-Fei et al. 2006; Everingham et al. 2009), have challenging datasets to track the progress made by leading algorithms and to stimulate new ideas."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3.4, evaluating the flow algorithms on the modified Teddy stereo dataset allows a comparison with current stereo methods from the online Middlebury stereo evaluation at http://vision.middlebury.edu/stereo/ ( Scharstein and Szeliski 2002 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 Statistics: In addition to computing averages and standard deviations as in Barron et al. (1994), we also compute robustness measures ( Scharstein and Szeliski 2002 ) and percentile-based accuracy measures (Seitz et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(The original stereo data comes with pixel-accurate ground truth but is four times higher resolution\u2014Scharstein and Szeliski 2003.) The most appropriate performance statistics for this data, therefore, are the robustness statistics used in the Middlebury stereo dataset ( Scharstein and Szeliski 2002 ) (Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The presence of nonrigid or independent motion makes collecting a ground-truth dataset for optical flow far harder than for stereo, say, where structured light ( Scharstein and Szeliski 2002 ) or range scanning (Seitz et al. 2006) can be used to obtain ground truth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The same can be said for any real data where the ground truth is measured, including, for example, in the Middlebury stereo dataset ( Scharstein and Szeliski 2002 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that our taxonomy is similar to those of Stiller and Konrad (1999) for optical flow and  Scharstein and Szeliski (2002)  for stereo."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207745496,
            "fieldsOfStudy": [],
            "id": "fa3f9b31b5e70fa5af458b4c00c7ea18886489ed",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 45
                            }
                        ],
                        "text": "10 Results of the Complementary OF algorithm (Zimmer et al. 2009) on the Urban sequence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 39
                            }
                        ],
                        "text": ", by using different weights or norms) (Zimmer et al. 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 17
                            }
                        ],
                        "text": "Complementary OF (Zimmer et al. 2009) 44 Learning Flow (Sun et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "10 for the Complementary OF algorithm (Zimmer et al. 2009) on the Urban sequence leads to a different conclusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 73
                            }
                        ],
                        "text": "A wide variety of energy functions do satisfy this requirement including (Horn and Schunck 1981; Bruhn et al. 2005; Brox et al. 2004; Nir et al. 2008; Zimmer et al. 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 17
                            }
                        ],
                        "text": "Complementary OF (Zimmer et al. 2009) does well on the hidden texture data (Army, Mequon, Schefflera, Wooden) presumably due to the use of a relatively sophisticated data term, including the use of a different robust penalization function for each channel in HSV color space (the hidden texture data contains a number of moving shadows and other illumination-related effects), but not as well on the sequences with large motion (Urban) and complex discontinuities (Grove)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Complementary optic flow. In Proceedings of seventh international workshop on energy minimization methods in computer vision and pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "12 F-TV-L1 [79] 8 Second-order prior [75] 14 Fusion [40] 2,666 Dynamic MRF [27] 366 Algorithm Runtime"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 19
                            }
                        ],
                        "text": "Algorithms such as [37, 40, 74] assume that a number of candidate flow fields have been generated by running standard algorithms such as Lucas-Kanade [44] and Horn-Schunck [33], possibly multiple times with a number of different parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Fusion Flow [40] uses a sequence of binary graph-cut optimizations to refine the current flow estimate by selectively replacing portions with one of the candidate solutions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "[54] X X X X X F-TV-L1 [79] X X X X Second-order prior [75] X X X Fusion [40] X X X X X X X Dynamic MRF [27] X X X Seg OF [83] X X X X X X Learning Flow [70] X X X X X X Filter Flow [65] X X X X X X X Graph Cuts [20] X X X X Black & Anandan [11] X X X SPSA-learn [41] X X X X X Horn & Schunck [33] X"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": ", DPOF [39], Fusion [40], and Dynamic MRF [27]) perform well in this region."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fusion flow"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 157
                            }
                        ],
                        "text": "In October 2007 we published the performance of several well-known algorithms on a preliminary version of our data to establish the current state of the art (Baker et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 47
                            }
                        ],
                        "text": "Since the publication of our preliminary paper (Baker et al. 2007), a large number of authors have uploaded results to our online evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 123
                            }
                        ],
                        "text": "The best-performing algorithm (both in terms of average endpoint error and average angular error) in our preliminary study (Baker et al. 2007) was 2D-CLG (Bruhn et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "1 by outlining the evolution of our online evaluation since the publication of our preliminary paper (Baker et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 24
                            }
                        ],
                        "text": "Prior to our evaluation (Baker et al. 2007), there were three major attempts to quantitatively evaluate optical flow algorithms, each proposing sequences with ground truth."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "A preliminary version of this paper appeared in the IEEE International Conference on Computer Vision (Baker et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 88
                            }
                        ],
                        "text": "Seeded with the handful of methods that we implemented as part of our preliminary paper (Baker et al. 2007), the evaluation has quickly grown."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41823768,
            "fieldsOfStudy": [],
            "id": "32b64ce1dac6ac041697db5be9e1d4e097b4f4a1",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Database and Evaluation Methodology for Optical Flow"
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 134
                            }
                        ],
                        "text": "Various correlation constraints can be used for computing dense flow including normalized cross correlation and Laplacian correlation [18,26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 108
                            }
                        ],
                        "text": "In fact, some of the earliest optical flow algorithms used filtered images to reduce the effects of shadows [3,18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 90
                            }
                        ],
                        "text": "The most common approach is to build image pyramids by repeated blurring and downsampling [3, 11, 18, 22, 26, 44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multi-resolution flow-through motion analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 246\u2013252,"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 163
                            }
                        ],
                        "text": "It is likely that stereo and flow algorithms will become more similar in the future, in particular with the advance of discrete/continuous optimization techniques (Lempitsky et al. 2008; Bleyer et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 12
                            }
                        ],
                        "text": "Fusion Flow (Lempitsky et al. 2008) uses a sequence of binary graph-cut optimizations to refine the current flow estimate by selectively replacing portions with one of the candidate solutions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 7
                            }
                        ],
                        "text": "Fusion (Lempitsky et al. 2008) 2,666 FOLKI (Le Besnerais and Champagnat 2005) 1."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fusion flow: discretecontinuous optimization for optical flow estimation"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the IEEE conference on computer vision and pattern recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1877929"
                        ],
                        "name": "N. Ohta",
                        "slug": "N.-Ohta",
                        "structuredName": {
                            "firstName": "Naoya",
                            "lastName": "Ohta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ohta"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 48
                            }
                        ],
                        "text": "Another issue, addressed by a number of authors (Ohta 1989; Markandey and Flinchbaugh 1990; Golland and Bruckstein 1997), is how to modify the data term for color or multi-band images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 114535545,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "175b5b5407aa15f74512ee03a56eaf0c4cc93c91",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optical-flow-detection-by-color-images-Ohta",
            "title": {
                "fragments": [],
                "text": "Optical flow detection by color images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 133
                            }
                        ],
                        "text": "A number of recent approaches use discrete optimization algorithms, similar to those employed in stereo matching, such as graph cuts (Boykov et al. 2001) and belief propagation (Sun et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45232003,
            "fieldsOfStudy": [],
            "id": "a57520b68e73b5e1fc3668b443daf74ebe957cc7",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast Approximate Energy Minimization via Graph Cuts"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571813"
                        ],
                        "name": "Thomas Driemeyer",
                        "slug": "Thomas-Driemeyer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Driemeyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Driemeyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "These scenes were generated using the Mental Ray renderer [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9332632,
            "fieldsOfStudy": [],
            "id": "3dc6b8beb114d4b15ff1eef491870ee5ab553e28",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Rendering-with-mental-ray\u00ae-Driemeyer",
            "title": {
                "fragments": [],
                "text": "Rendering with mental ray\u00ae"
            },
            "venue": {
                "fragments": [],
                "text": "mental ray\u00ae Handbooks"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 153
                            }
                        ],
                        "text": "1 can be replaced with priors that encourage the secondorder derivatives ( 2u \u2202x2 , \u2202 2u \u2202y2 , \u2202 2u \u2202x\u2202y , \u2202 2v \u2202x2 , \u2202 2v \u2202y2 , \u2202 2v \u2202x\u2202y ) to be small [4, 75]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introducing smoothness constraint in a matching approach for the computation of displacement fields"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the DARPA Image Understanding Workshop, pages 186\u2013196,"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DNA Research. 3Delight rendering software"
            },
            "venue": {
                "fragments": [],
                "text": "DNA Research. 3Delight rendering software"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Many areas of computer vision, such as stereo [19], face recognition [17], and object recognition [8], have challenging datasets to track the progress made by leading algorithms and to stimulate new ideas."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "One-shot learning of object"
            },
            "venue": {
                "fragments": [],
                "text": "categories. PAMI,"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weickert , and C . Schnorr . Lucas / Kanade meets Horn / Schunck : Combining local and global optic flow meth"
            },
            "venue": {
                "fragments": [],
                "text": "IJCV"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Urban Teddy Backyd. Basktb. Dumptr. Evergr. Correlation in group: Avg 1"
            },
            "venue": {
                "fragments": [],
                "text": "Avg R2.5 R5.0 R10 A90 A95 A99 all disc untext Mequ"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Media player 9 video quality demos"
            },
            "venue": {
                "fragments": [],
                "text": "Media player 9 video quality demos"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3Delight rendering software"
            },
            "venue": {
                "fragments": [],
                "text": "http://www. 3delight.com/."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Media player 9 video quality demos"
            },
            "venue": {
                "fragments": [],
                "text": "CVIU"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3Delight rendering software"
            },
            "venue": {
                "fragments": [],
                "text": "DNA Research"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Take the flow from I 0 to I 1 and forward warp (or splat) each flow value to the nearest destination pixel: u t (round(x + tu 0 (x))) = u 0 (x)"
            },
            "venue": {
                "fragments": [],
                "text": "Take the flow from I 0 to I 1 and forward warp (or splat) each flow value to the nearest destination pixel: u t (round(x + tu 0 (x))) = u 0 (x)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "The combination of these datasets provides a basis for a rigorous evaluation of current optical flow algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contour reality capture"
            },
            "venue": {
                "fragments": [],
                "text": "Contour reality capture"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 119
                            }
                        ],
                        "text": "An alternative to the assumption of \u201cconstancy\u201d is that the signals (images) at times t and t+ 1 are highly correlated [17,57]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local correlation measures for motion analysis: A comparative study"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Proc. PRIP , pages 269\u2013274,"
            },
            "year": 1982
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 64,
            "methodology": 51,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 110,
        "totalPages": 11
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Database-and-Evaluation-Methodology-for-Optical-Baker-Scharstein/804836b8ad86ef8042e3dcbd45442a52f031ee03?sort=total-citations"
}