{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077372"
                        ],
                        "name": "V. Cuperman",
                        "slug": "V.-Cuperman",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Cuperman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cuperman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45320422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ef0d444274c20449918171517b999e62ba7f32d",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector quantization, in its simplest form, may be regarded as a generalization of PCM (independent quantization of each sample of a waveform) to what might be called \"vector PCM,\" where a block of consecutive samples, a vector, is simultaneously quantized as one unit. In theory, a performance arbitrarily close to the ultimate rate-distortion limit is achievable with waveform vector quantization if the dimension of the vector, k , is large enough. The main obstacle in effectively using vector quantization is complexity. A vector quantizer of dimension k operating at a rate of r bits/sample requires a number of computations on the order of k2^{kr} and a memory of the same order. However, a low-dimensional vector quantizer (dimensions 4-8) achieves a remarkable improvement over scalar quantization (PCM). Consequently, using the vector quantizer as a building block and imbedding it with other waveform data compression techniques may lead to the development of a new and powerful class of waveform coding systems. This paper proposes and analyzes a waveform coding system, adaptive vector predictive coding (AVPC), in which a low-dimensionality vector quantizer is used in an adaptive predictive coding scheme. In the encoding process, a locally generated prediction of the current input vector is subtracted from the current vector, and the resulting error vector is coded by a vector quantizer. Each frame consisting of many vectors is classified into one of m statistical types. This classification determines which one of m fixed predictors and of m vector quantizers will be used for encoding the current frame."
            },
            "slug": "Vector-Predictive-Coding-of-Speech-at-16-kbits/s-Cuperman-Gersho",
            "title": {
                "fragments": [],
                "text": "Vector Predictive Coding of Speech at 16 kbits/s"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes and analyzes a waveform coding system, adaptive vector predictive coding (AVPC), in which a low-dimensional vector quantizer is used in an adaptive predictive coding scheme."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6637655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60927dd520f34890007c33ae6727e1e136f19971",
            "isKey": false,
            "numCitedBy": 346,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector quantization is intrinsically superior to predictive coding, transform coding, and other suboptimal and {\\em ad hoc} procedures since it achieves optimal rate distortion performance subject only to a constraint on memory or block length of the observable signal segment being encoded. The key limitation of existing techniques is the very large randomly generated code books which must be stored, and the computational complexity of the associated encoding procedures. The quantization operation is decomposed into its rudimentary structural components. This leads to a simple and elegant approach to derive analytical properties of optimal quantizers. Some useful properties of quantizers and algorithmic approaches are given, which are relevant to the complexity of both storage and processing in the encoding operation. Highly disordered quantizers, which have been designed using a clustering algorithm, are considered. Finally, lattice quantizers are examined which circumvent the need for a code book by using a highly structured code based on lattices. The code vectors are algorithmically generated in a simple manner rather than stored in a code book, and fast algorithms perform the encoding algorithm with negligible complexity."
            },
            "slug": "On-the-structure-of-vector-quantizers-Gersho",
            "title": {
                "fragments": [],
                "text": "On the structure of vector quantizers"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Vector quantization is intrinsically superior to predictive coding, transform coding, and other suboptimal and {\\em ad hoc} procedures since it achieves optimal rate distortion performance subject only to a constraint on memory or block length of the observable signal segment being encoded."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793645"
                        ],
                        "name": "H. Gish",
                        "slug": "H.-Gish",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Gish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18820742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3f073ac7513183a9bf3a76154dcd245748d2ab6",
            "isKey": false,
            "numCitedBy": 903,
            "numCiting": 154,
            "paperAbstract": {
                "fragments": [],
                "text": "Quantization, the process of approximating continuous-amplitude signals by digital (discrete-amplitude) signals, is an important aspect of data compression or coding, the field concerned with the reduction of the number of bits necessary to transmit or store analog data, subject to a distortion or fidelity criterion. The independent quantization of each signal value or parameter is termed scalar quantization, while the joint quantization of a block of parameters is termed block or vector quantization. This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization. Vector quantization is presented as a process of redundancy removal that makes effective use of four interrelated properties of vector parameters: linear dependency (correlation), nonlinear dependency, shape of the probability density function (pdf), and vector dimensionality itself. In contrast, scalar quantization can utilize effectively only linear dependency and pdf shape. The basic concepts are illustrated by means of simple examples and the theoretical limits of vector quantizer performance are reviewed, based on results from rate-distortion theory. Practical issues relating to quantizer design, implementation, and performance in actual applications are explored. While many of the methods presented are quite general and can be used for the coding of arbitrary signals, this paper focuses primarily on the coding of speech signals and parameters."
            },
            "slug": "Vector-quantization-in-speech-coding-Makhoul-Roukos",
            "title": {
                "fragments": [],
                "text": "Vector quantization in speech coding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization, and focuses primarily on the coding of speech signals and parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123543067"
                        ],
                        "name": "J. Foster",
                        "slug": "J.-Foster",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Foster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Foster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941347"
                        ],
                        "name": "M. O. Dunham",
                        "slug": "M.-O.-Dunham",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Dunham",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. O. Dunham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34366638,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1769c81e58ab772ce405314cae48ee048a71843",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A finite-state vector quantizer is a finite-state machine used for data compression: Each successive source vector is encoded into a codeword using a minimum distortion rule, and into a code book, depending on the encoder state. The current state and the selected codeword then determine the next encoder state. A finite-state vector quantizer is capable of making better use of the memory in a source than is an ordinary memoryless vector quantizer of the same dimension or blocklength. Design techniques are introduced for finite-state vector quantizers that combine ad hoc algorithms with an algorithm for the design of memoryless vector quantizers. Finite-state vector quantizers are designed and simulated for Gauss-Markov sources and sampled speech data, and the resulting performance and storage requirements are compared with ordinary memoryless vector quantization."
            },
            "slug": "Finite-state-vector-quantization-for-waveform-Foster-Gray",
            "title": {
                "fragments": [],
                "text": "Finite-state vector quantization for waveform coding"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Finite-state vector quantizers are designed and simulated for Gauss-Markov sources and sampled speech data, and the resulting performance and storage requirements are compared with ordinary memoryless vector quantization."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395615041"
                        ],
                        "name": "M. Sabin",
                        "slug": "M.-Sabin",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Sabin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sabin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122059816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "886177ca3c5da9f3ccf1327dc71eb4eeada9e015",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory and computation requirements imply fundamental limitations on the quality that can be achieved in vector quantization systems used for speech waveform coding and linear predictive voice coding (LPC). One approach to reducing storage and computation requirements is to organize the set of reproduction vectors as the Cartesian product of a vector codebook describing the shape of each reproduction vector and a scalar codebook describing the gain or energy. Such shape-gain vector quantizers can be applied both to waveform coding using a quadratic-error distortion measure and to voice coding using an Itakura-Saito distortion measure. In each case, the minimum distortion reproduction vector can be found by first selecting a shape code-word, and then, based on that choice, selecting a gain codeword. Several algorithms are presented for the design of shape-gain vector quantizers based on a traning sequence of data or a probabilistic model. The algorithms are used to design shape-gain vector quantizers for both the waveform coding and voice coding application. The quantizers are simulated, and their performance is compared to that of previously reported vector quantization systems."
            },
            "slug": "Product-code-vector-quantizers-for-waveform-and-Sabin-Gray",
            "title": {
                "fragments": [],
                "text": "Product code vector quantizers for waveform and voice coding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Several algorithms are presented for the design of shape-gain vector quantizers based on a traning sequence of data or a probabilistic model, and their performance is compared to that of previously reported vector quantization systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101639166"
                        ],
                        "name": "S. P. Lloyd",
                        "slug": "S.-P.-Lloyd",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Lloyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Lloyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10833328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9241ea3d8cb85633d314ecb74b31567b8e73f6af",
            "isKey": false,
            "numCitedBy": 11645,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for 2^{b} quanta, b=1,2, \\cdots, 7 , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes."
            },
            "slug": "Least-squares-quantization-in-PCM-Lloyd",
            "title": {
                "fragments": [],
                "text": "Least squares quantization in PCM"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758920"
                        ],
                        "name": "H. Abut",
                        "slug": "H.-Abut",
                        "structuredName": {
                            "firstName": "H\u00fcseyin",
                            "lastName": "Abut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Abut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3349348"
                        ],
                        "name": "G. Rebolledo",
                        "slug": "G.-Rebolledo",
                        "structuredName": {
                            "firstName": "Guillermo",
                            "lastName": "Rebolledo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rebolledo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119583050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42704ee7edbd19c1ac59891782d7cbbfe255aec3",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for the design of vector quantizers that are locally optimum in the sense of minimizing an average quantitative distortion measure is used to design 1 and 2 bit/sample vector quantizers for both real sampled speech and a simulated speech-like auto-regressive random process. Both weighted and unweighted squared-error distortion measures are considered. Several comparisons are made and discussed based on the average distortions of the vector quantization schemes. The results for the simulated speech are compared to mathematical performance bounds from information theory to provide an indication of how nearly globally optimal vector quantization is for such highly correlated sources. A comparison of the results for the real speech and the simulated speech provides a quantitative measure of the accuracy of such models and, hence, of the applicability of information theory bounds and code designs based on probabilistic models. The signal-to-quantization-noise ratios of vector quantizers designed to minimize squared-error distortion are compared to those of several popular speech waveform coding systems of similar rates."
            },
            "slug": "Vector-quantization-of-speech-and-speech-like-Abut-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization of speech and speech-like waveforms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A comparison of the results for the real speech and the simulated speech provides a quantitative measure of the accuracy of such models and, hence, of the applicability of information theory bounds and code designs based on probabilistic models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67024873"
                        ],
                        "name": "R. Rice",
                        "slug": "R.-Rice",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Rice",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71622963"
                        ],
                        "name": "J. Plaunt",
                        "slug": "J.-Plaunt",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Plaunt",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Plaunt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61525240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03caa5c8c4c411f7eddb14bfdc621b8d76800ec8",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "An adaptive variable length coding system is presented. Although developed primarily for the proposed Grand Tour missions, many features of this system clearly indicate a much wider applicability. Using sample to sample prediction, the coding system produces output rates within 0.25 bit/picture element (pixel) of the onedimensional difference entropy for entropy values ranging from 0 to 8 bit/pixel. This is accomplished without the necessity of storing any code words. Performance improvements of 0.5 bit/pixel can be simply achieved by utilizing previous line correlation. A Basic Compressor, using concatenated codes, adapts to rapid changes in source statistics by automatically selecting one of three codes to use for each block of 21 pixels. The system adapts to less frequent, but more dramatic, changes in source statistics by adjusting the mode in which the Basic Compressor operates on a line-to-line basis. Furthermore, the compression system is independent of the quantization requirements of the pulse-code modulation system."
            },
            "slug": "Adaptive-Variable-Length-Coding-for-Efficient-of-Rice-Plaunt",
            "title": {
                "fragments": [],
                "text": "Adaptive Variable-Length Coding for Efficient Compression of Spacecraft Television Data"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An adaptive variable length coding system is presented, developed primarily for the proposed Grand Tour missions, but many features of this system clearly indicate a much wider applicability."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767147"
                        ],
                        "name": "D. Arnstein",
                        "slug": "D.-Arnstein",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Arnstein",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Arnstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122847102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6318ecfd286403f1d72073946d6363966e9dd7a",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Predictive coders have been suggested for use as analog data compression devices. Exact expressions for reconstructed signal error have been rare in the literature. In fact most results reported in the literature are based on the assumption of Gaussian statistics for prediction error. Predictive coding of first-order Gaussian Markov sequences are considered in this paper. A numerical iteration technique is used to solve for the prediction error statistics expressed as an infinite series in terms of Hermite polynomials. Several interesting properties of predictive coding are thereby demonstrated. First, prediction error is in fact close to Gaussian, even for the binary quantizer. Sencond, quantizer levels may be optimized at each iteration according to the calculated density. Finally, the existence of correlation between successive quantizer outputs is shown. Using the series solutions described above, performance in terms of meansquare reconstruction error versus bit rate can be shown to parallel the theoretical rate distortion function for the first-order Markov process by about 0.6 bits/sample at low bit rates."
            },
            "slug": "Quantization-Error-in-Predictive-Coders-Arnstein",
            "title": {
                "fragments": [],
                "text": "Quantization Error in Predictive Coders"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Performance in terms of meansquare reconstruction error versus bit rate can be shown to parallel the theoretical rate distortion function for the first-order Markov process by about 0.6 bits/sample at low bit rates."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46667852"
                        ],
                        "name": "V. Cuperman",
                        "slug": "V.-Cuperman",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Cuperman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cuperman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19868457,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b83c7d2924e3a33f792b559aa1e6bffea06a3e9",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "V ECTOR QUANTIZATION (VQ), a new direction in source coding, has recently emerged as a powerful and widely applicable coding technique. I t was first applied to analysis/synthesis of speech, and has allowed Linear Predictive Coding (LPC) rates to be dramatically reduced to 800 b/s with very slight reduction in quality, and further compressed to rates as low as 150 b/s while retaining intelligibility [ 1,2]. More recently, the technique has found its way to waveform coding [3-51, where its applicability and effectiveness is less obvious and not widely known. There is currently a great need for a low-complexity speech coder at the rate of 16 kb/s which attains essentially \u201ctoll\u201d quality, roughly equivalent to that of standard 64-kb/s log PCM codecs. Adaptive DPCM schemes can attain this quality with low complexity for the proposed 32 kb/s CCITT standard, but at 16 kb/s the quality of ADPCM or adaptive delta modulation schemes is inadequate. More powerful methods, such as subband coding or transform coding, are capable of producing acceptable speech quality at 16kb/s but have a much higher implementation complexity. The difficulty is further compounded by the need for a scheme that can handle both speech and voiceband data at the 16 kb/s rate. These two types of waveforms occupy the same bandwidth in the subscriber loop part of the telephone network, yet they have a widely different statistical character. Effective speech coding at this rate must be geared to the specific character of speech and must exploit our knowledge of human hearing. On the other hand, a waveform that carries data must be coded and later reconstructed so that a modem can still extract the data with an acceptably low error rate. This is purely a signal processing operation not involving human perception. Vector quantization appears to be a suitable coding technique which caters to this dual requirement. VQ may become the key to 16 kb/s coding; it may also lead to improved quality waveform coding at 8 or 9.6 kb/s. In this paper, we review recent results obtained in waveform coding of speech with vector quantization and"
            },
            "slug": "Vector-quantization:-A-pattern-matching-technique-Gersho-Cuperman",
            "title": {
                "fragments": [],
                "text": "Vector quantization: A pattern-matching technique for speech coding"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Recent results obtained in waveform coding of speech with vector quantization are reviewed, with Vector quantization appearing to be a suitable coding technique which caters to this dual requirement of effective speech coding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Communications Magazine"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145720405"
                        ],
                        "name": "J. Ziv",
                        "slug": "J.-Ziv",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Ziv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ziv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50154247"
                        ],
                        "name": "A. Lempel",
                        "slug": "A.-Lempel",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Lempel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lempel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20900807,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5be4e0eccca2892d31406a03b0c485f7a395fe5a",
            "isKey": false,
            "numCitedBy": 3487,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Compressibility of individual sequences by the class of generalized finite-state information-lossless encoders is investigated. These encoders can operate in a variable-rate mode as well as a fixed-rate one, and they allow for any finite-state scheme of variable-length-to-variable-length coding. For every individual infinite sequence x a quantity \\rho(x) is defined, called the compressibility of x , which is shown to be the asymptotically attainable lower bound on the compression ratio that can be achieved for x by any finite-state encoder. This is demonstrated by means of a constructive coding theorem and its converse that, apart from their asymptotic significance, also provide useful performance criteria for finite and practical data-compression tasks. The proposed concept of compressibility is also shown to play a role analogous to that of entropy in classical information theory where one deals with probabilistic ensembles of sequences rather than with individual sequences. While the definition of \\rho(x) allows a different machine for each different sequence to be compressed, the constructive coding theorem leads to a universal algorithm that is asymptotically optimal for all sequences."
            },
            "slug": "Compression-of-individual-sequences-via-coding-Ziv-Lempel",
            "title": {
                "fragments": [],
                "text": "Compression of individual sequences via variable-rate coding"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The proposed concept of compressibility is shown to play a role analogous to that of entropy in classical information theory where one deals with probabilistic ensembles of sequences rather than with individual sequences."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143798160"
                        ],
                        "name": "J. Kieffer",
                        "slug": "J.-Kieffer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kieffer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kieffer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28275450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cfb73ab4d2da06fc7ff79a99e06a3b3727e25d6",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Feedback quantization schemes (such as delta modulation. adaptive quantization, differential pulse code modulation (DPCM), and adaptive differential pulse code modulation (ADPCM) encode an information source by quantizing the source letter at each time i using a quantizer, which is uniquely determined by examining some function of the past outputs and inputs called the state of the encoder at time i . The quantized output letter at time i is fed back to the encoder, which then moves to a new state at time i+1 which is a function of the state at time i and the encoder output at time i . In an earlier paper a stochastic stability result was obtained for a class of feedback quantization schemes which includes delta modulation and some adaptive quantization schemes. In this paper a similar result is obtained for a class of feedback quantization schemes which includes linear DPCM and some ADPCM encoding schemes. The type of stochastic stability obtained gives almost-sure convergence of time averages of functions of the joint input-state-output process. This is stronger than the type of stochastic stability obtained previously by Gersho, Goodman, Goldstein, and Liu, who showed convergence in distribution of the time i input-state-output as i \\rightarrow \\infty ."
            },
            "slug": "Stochastic-stability-for-feedback-quantization-Kieffer",
            "title": {
                "fragments": [],
                "text": "Stochastic stability for feedback quantization schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The type of stochastic stability obtained gives almost-sure convergence of time averages of functions of the joint input-state-output process."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41489902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8b700d14fdac6b5773a4d39985952c746fff015",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a multiple stage vector quantization technique which allows easy expansion of the original vector quantizer design to operate at higher bit rates for lower distortion. The computation and storage reduction is achieved by the fact that the overall requirements are the sum of the requirements of each stage instead of an exponentially increasing function of the bit rate as in the original one stage design. In the case of Euclidean distance measures such as the log area ratio measure, experimental results show that the quantizer performance is very close to a theoretically predicted asymptotically optimal rate distortion relationship."
            },
            "slug": "Multiple-stage-vector-quantization-for-speech-Juang-Gray",
            "title": {
                "fragments": [],
                "text": "Multiple stage vector quantization for speech coding"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that the quantizer performance is very close to a theoretically predicted asymptotically optimal rate distortion relationship for Euclidean distance measures."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3294127"
                        ],
                        "name": "A. Haoui",
                        "slug": "A.-Haoui",
                        "structuredName": {
                            "firstName": "Amine",
                            "lastName": "Haoui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Haoui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815712"
                        ],
                        "name": "D. Messerschmitt",
                        "slug": "D.-Messerschmitt",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Messerschmitt",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Messerschmitt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11502783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03083201f94cb831c5387803294afc135a387f88",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A proposed class of vector quantizers with memory, called Predictive Vector Quantizers (PVQ), exhibits good performance (as measured by mean-squared error distortion) for the encoding of speech signals at 16 kbits/sec. Two methods for designing PVQ's are described, and their performance is compared to that of memoryless VQ's by computer simulation. These results indicate that, for comparable performance, the PVQ has a smaller block size and computational load than the memoryless VQ. In addition, preliminary simulations indicate that PVQ's are less speaker dependent than memoryless vector quantizers."
            },
            "slug": "Predictive-vector-quantization-Haoui-Messerschmitt",
            "title": {
                "fragments": [],
                "text": "Predictive vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Results indicate that, for comparable performance, the PVQ has a smaller block size and computational load than the memoryless VQ, and preliminary simulations indicate that PVQ's are less speaker dependent than memoryless vector quantizers."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145244008"
                        ],
                        "name": "C. Tsao",
                        "slug": "C.-Tsao",
                        "structuredName": {
                            "firstName": "Chieh",
                            "lastName": "Tsao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tsao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32830015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9732e8c6e446a1522bf2fd14c3894d005155b21",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been recently demonstrated that the principles of vector quantization for LPC speech can be simply extended to encompass matrices of LPC vectors with significant savings in bit rate. Unfortunately, however, such locally optimal matrix quantizers have prohibitively high complexity and memory requirements when implemented in a speech vocoder at bit rates giving acceptable quality speech. One approach to solving the problem is to separately code gain and shape in the matrix quantizer. This paper generalizes the principles of shape-gain vector quantizer design for LPC speech to matrix quantization and investigates the properties of the resulting quantizers. In particular, we present a design which combines shape matrices consisting of N shape vectors with K-dimensional gain vectors, where N and K are small integers, in practice, with K \\geq N . Experimental results show that with K, N \\geq 3 , significant reductions in bit rate over locally optimal vector quantizers are obtained for comparable performance. Simulations indicate that a shape-gain matrix quantizer, using a 10 bit shape codebook and an 8 bit codebook with K = N = 3 operating at 6 bits/frame for the LPC model, gives speech quality comparable to a locally optimal vector quantizer at 9 bits/frame. The matrix quantizer has somewhat greater than 5.7 times the memory requirement of the above vector quantizer, but less than 2.1 times the complexity. Subjective tests show that the speech from this matrix quantizer is intelligible to native speakers of English."
            },
            "slug": "Shape-gain-matrix-quantizers-for-LPC-speech-Tsao-Gray",
            "title": {
                "fragments": [],
                "text": "Shape-gain matrix quantizers for LPC speech"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Simulations indicate that a shape-gain matrix quantizer, using a 10 bit shape codebook and an 8 bit codebook with K = N = 3 operating at 6 bits/frame for the LPC model, gives speech quality comparable to a locally optimal vector quantizer at 9 bits/ frame."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2720005"
                        ],
                        "name": "J. Markel",
                        "slug": "J.-Markel",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Markel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Markel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29755416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b51befa43150d014ccb13170f3303157237449d2",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "With rare exception, all presently available narrow-band speech coding systems implement scalar quantization (independent quantization) of the transmission parameters (such as reflection coefficients or transformed reflection coefficients in LPC systems). This paper presents a new approach called vector quantization. For very low data rates, realistic experiments have shown that vector quantization can achieve a given level of average distortion with 15 to 20 fewer bits/frame than that required for the optimized scalar quantizing approaches presently in use. The vector quantizing approach is shown to be a mathematically and computationally tractable method which builds upon knowledge obtained in linear prediction analysis studies. This paper introduces the theory in a nonrigorous form, along with practical results to date and an extensive list of research topics for this new area of speech coding."
            },
            "slug": "Speech-coding-based-upon-vector-quantization-Buzo-Gray",
            "title": {
                "fragments": [],
                "text": "Speech coding based upon vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The vector quantizing approach is shown to be a mathematically and computationally tractable method which builds upon knowledge obtained in linear prediction analysis studies and is introduced in a nonrigorous form."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15649178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "803367ea78d349d310a224503270a006c2bc0c66",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In 1948 W. R. Bennett used a companding model for nonuniform quantization and proposed the formula D \\: = \\: \\frac{1}{12N^{2}} \\: \\int \\: p(x) [ E(x) ]^{-2} \\dx for the mean-square quantizing error where N is the number of levels, p (x) is the probability density of the input, and E \\prime (x) is the slope of the compressor curve. The formula, an approximation based on the assumption that the number of levels is large and overload distortion is negligible, is a useful tool for analytical studies of quantization. This paper gives a heuristic argument generalizing Bennett's formula to block quantization where a vector of random variables is quantized. The approach is again based on the asymptotic situation where N , the number of quantized output vectors, is very large. Using the resulting heuristic formula, an optimization is performed leading to an expression for the minimum quantizing noise attainable for any block quantizer of a given block size k . The results are consistent with Zador's results and specialize to known results for the one- and two-dimensional cases and for the case of infinite block length (k \\rightarrow \\infty) . The same heuristic approach also gives an alternate derivation of a bound of Elias for multidimensional quantization. Our approach leads to a rigorous method for obtaining upper bounds on the minimum distortion for block quantizers. In particular, for k = 3 we give a tight upper bound that may in fact be exact. The idea of representing a block quantizer by a block \"compressor\" mapping followed with an optimal quantizer for uniformly distributed random vectors is also explored. It is not always possible to represent an optimal quantizer with this block companding model."
            },
            "slug": "Asymptotically-optimal-block-quantization-Gersho",
            "title": {
                "fragments": [],
                "text": "Asymptotically optimal block quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A heuristic argument generalizing Bennett's formula to block quantization where a vector of random variables is quantized is given, leading to a rigorous method for obtaining upper bounds on the minimum distortion for block quantizers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130184"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43811955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c173a661921514ac1bd53d4d3db086f4976eba9",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a Hierarchical Vector Quantization (HVQ) scheme that can operate on \"supervectors\" of dimensionality in the hundreds of samples. HVQ is based on a tree-structured decomposition of the original super-vector into a large number of low dimensional vectors. The supervector is partitioned into subvectors, the subvectors into minivectors and so on. The \"glue\" that links subvectors at one level to the parent vector at the next higher level is a feature vector that characterizes the correlation pattern of the parent vector and controls the quantization of lower level feature vectors and ultimately of the final descendant data vectors. Each component of a feature vector is a scalar parameter that partially describes a corresponding subvector. The paper presents a three level HVQ for which the feature vectors are based on subvector energies. Gain normalization and dynamic codebook allocation are used in coding both feature vectors and the final data subvectors. Simulation results demonstrate the effectiveness of HVQ for speech waveform coding at 9.6 and 16 Kb/s."
            },
            "slug": "Hierarchical-vector-quantization-of-speech-with-Gersho-Shoham",
            "title": {
                "fragments": [],
                "text": "Hierarchical vector quantization of speech with dynamic codebook allocation"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A Hierarchical Vector Quantization scheme that can operate on \"supervectors\" of dimensionality in the hundreds of samples is introduced and Gain normalization and dynamic codebook allocation are used in coding both feature vectors and the final data subvectors."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18530691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c46799502bebfe6a9ae0f457b7b8b92248ec260",
            "isKey": false,
            "numCitedBy": 7891,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data. The basic properties of the algorithm are discussed and demonstrated by examples. Quite general distortion measures and long blocklengths are allowed, as exemplified by the design of parameter vector quantizers of ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with a complicated distortion measure arising in LPC analysis that does not depend only on the error vector."
            },
            "slug": "An-Algorithm-for-Vector-Quantizer-Design-Linde-Buzo",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Vector Quantizer Design"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3349348"
                        ],
                        "name": "G. Rebolledo",
                        "slug": "G.-Rebolledo",
                        "structuredName": {
                            "firstName": "Guillermo",
                            "lastName": "Rebolledo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rebolledo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060841768"
                        ],
                        "name": "J. Burg",
                        "slug": "J.-Burg",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Burg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62739990,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea5df82160946a21d2f881f37dd64150bbc74bd6",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The importance of integrating voice and data over digital networks has increased during the last few years primarily because of the growing popularity of such networks. Of particular interest are efficient voice digitizing terminals, capable of operating at various data rates in both circuit-switched and packet-switched data networks. Several such terminals, including two or more speech compression algorithms, have been proposed and implemented. Typically the terminal switches between a low-rate (500 - 4000 bits/s) vocoding scheme and a medium-rate (7000 - 16000 bits/s) waveform coding algorithm, depending on, among other things, the network congestion and on the desired voice quality and robustness. We here describe the design and simulation of a multirate voice digitizer (MRVD) that switches between two speech compression systems, each based on a recently developed vector quantization (VQ) coding technique. This technique consists of the off-line interactive design of a codebook minimizing an average distortion measure, followed by the use of the codebook in an on-line nearest neighbor encoding scheme. One of the two systems is a rate-distortion speech coder that resembles a linear predictive coding (LPC) speech compression system but has a much lower rate (800 bits/s and below). We call this the LPC-VQ system, and it is similar to other previously reported systems [15],[19],[21]. The only difference is that the LPC parameters are extracted using the Burg method instead of the autocorrelation method. We here show that this provides both qualitative and quantitative improvements. The other system of our MRVD is a residual-excited linear predictive (RELP) speech compression system using VQ in both model selection and residual digitization. The residual waveform is digitized at 1 or 2 bits/sample, resulting in rates of 7300 and 13800 bits/s, respectively. We call this the RELP-VQ system. When compared to other RELP systems [6]-[8], it is shown to have a simpler architecture and to provide comparable speech quality. In a direct comparison with an APC scheme, our RELP-VQ system was determined to provide a more natural speech sound. Another interesting result presented is the quantitative comparison of the application of the VQ algorithm to the original speech waveform and its residuals."
            },
            "slug": "A-Multirate-Voice-Digitizer-Based-Upon-Vector-Rebolledo-Gray",
            "title": {
                "fragments": [],
                "text": "A Multirate Voice Digitizer Based Upon Vector Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The design and simulation of a multirate voice digitizer (MRVD) that switches between two speech compression systems, each based on a recently developed vector quantization (VQ) coding technique, which is shown to have a simpler architecture and to provide comparable speech quality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1877245"
                        ],
                        "name": "J. Adoul",
                        "slug": "J.-Adoul",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Adoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Adoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692895"
                        ],
                        "name": "P. Mabilleau",
                        "slug": "P.-Mabilleau",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Mabilleau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mabilleau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29665826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fd4b29d8eb4f993a894b0987246708a82534df1",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents the full description and discusses the performances of a 4800 bit per second residual excited linear prediction vocoder. The LPC analysis is efficiently performed using a type of binary-tree search vector-quantization approach. The technique, which is described in ref (1), uses a set of hyperplane equations to perform a hierarchical pattern classification of the input autocorrelation vector in the autocorrelation space. The end result of the search is the integer i 1 which is the index of the most appropriate (in the Itakura-distance sense) prediction filter out of a set of N preset filters. The search requires only \\Log_{2}N dot products. In this case vector quantization presents two advantages over the classical approach of the Durbin algorithm followed by scalar quantization. First, a faster algorithm is obtained. Second, the same accuracy in filter representation is possible with less bits per second and consequently more bits can be allocated for representing the residual and gain. The residual is vector quantized in the time domain by blocks of 16 the samples according to the approach of ref (2). The 16 sample block is essentially encoded using the integer I 2 which is the index of the most appropriate 16-sample waveform out of set of M preset prototype waveforms stored in memory. The paper includes preference testings for comparison with other types of 4800 Kbit/sec vocoders. Some sample recordings will be presented at the conference. Finally, preliminary results in the attempt to implement the vocoder in real time on a MAP 200 array processor are discussed."
            },
            "slug": "4800-Bps-RELP-Vocoder-using-vector-quantization-for-Adoul-Mabilleau",
            "title": {
                "fragments": [],
                "text": "4800 Bps RELP Vocoder using vector quantization for both filter and residual representations"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The paper presents the full description and discusses the performances of a 4800 bit per second residual excited linear prediction vocoder using a type of binary-tree search vector-quantization approach and includes preference testings for comparison with other types of 4800 Kbit/sec vocoders."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39119328"
                        ],
                        "name": "B. Ramamurthi",
                        "slug": "B.-Ramamurthi",
                        "structuredName": {
                            "firstName": "Bhaskar",
                            "lastName": "Ramamurthi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ramamurthi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206637648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3aad75ce0854cc6048a464a3138c2c80c6a69b2e",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector quantization (VQ) provides many attractive features for image coding with high compression ratios. However, initial studies of image coding with VQ have revealed several difficulties, most notably edge degradation and high computational complexity. We address these two problems and propose a new coding method, classified vector quantization (CVQ), which is based on a composite source model. Blocks with distinct perceptual features, such as edges, are generated from different subsources, i.e., belong to different classes. In CVQ, a classifier determines the class for each block, and the block is then coded with a vector quantizer designed specifically for that class. We obtain better perceptual quality with significantly lower complexity with CVQ when compared to ordinary VQ. We demonstrate with CVQ visual quality which is comparable to that produced by existing coders of similar complexity, for rates in the range 0.6-1.0 bits/pixel."
            },
            "slug": "Classified-Vector-Quantization-of-Images-Ramamurthi-Gersho",
            "title": {
                "fragments": [],
                "text": "Classified Vector Quantization of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a new coding method, classified vector quantization (CVQ), which is based on a composite source model and obtains better perceptual quality with significantly lower complexity with CVQ when compared to ordinary VQ."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39119328"
                        ],
                        "name": "B. Ramamurthi",
                        "slug": "B.-Ramamurthi",
                        "structuredName": {
                            "firstName": "Bhaskar",
                            "lastName": "Ramamurthi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ramamurthi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37544108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04006b3c696f3a11388cee7b99c6f7f8425986b1",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "An image is partitioned into cells of pxp pixels. Each cell is regarded as a vector of dimension p2and is encoded by searching through a codebook for a nearest matching representative vector. A binary word identifying the selected representative vector is assigned as the codeword to describe the original cell. The decoder uses this codeword to address a codebook. Each entry of the codebook contains a full precision digital representation of one of the N representative vectors. The codebook design is based on a clustering technique for vector quantizer design preceded by a classification of training cells into edge or shade cells. Results for coding rates from 0.5 to 1.5 bits/pixel are discussed. Vector quantization appears to be a powerful and promising technique for image coding."
            },
            "slug": "Image-coding-using-vector-quantization-Gersho-Ramamurthi",
            "title": {
                "fragments": [],
                "text": "Image coding using vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Vector quantization appears to be a powerful and promising technique for image coding and results for coding rates from 0.5 to 1.5 bits/pixel are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987652"
                        ],
                        "name": "E. Karnin",
                        "slug": "E.-Karnin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Karnin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Karnin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27035775,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20b10fc54b6f906bb836bd5cd7da50eeabec0d99",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Two results are presented on vector quantizers meeting necessary conditions for optimality. First a simple generalization of well-known centroid and moment properties of the squared-error distortion measure to a weighted quadratic distortion measure with an input dependent weighting is presented. The second result is an application of the squared-error special case of the first result to a simulation study of the design of 1 bit per sample two- and three-dimensional quantizers for a memoryless Gaussian source using the generalized Lloyd technique. The existence of multiple distinct local optima is demonstrated, thereby showing that sufficient conditions for unique local optima do not exist for this simple common case. It is also shown that at least three dimensions are required for a vector quantizer to outperform a scalar quantizer for this source."
            },
            "slug": "Multiple-local-optima-in-vector-quantizers-Gray-Karnin",
            "title": {
                "fragments": [],
                "text": "Multiple local optima in vector quantizers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that at least three dimensions are required for a vector quantizer to outperform a scalar quantizer for this source and multiple distinct local optima are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 110747198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73f059e14d470446de396c8a1ee3a06f58a55814",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Low-rate vector quantizers are designed and simulated for highly correlated Gauss-Markov sources and the resulting performance is compared with Arnstein's optimized predictive quantizer and with Huang and Schultheiss' optimized transform coder. Two implementations of vector quantizers are considered: full search vector quantizers-which are optimal but require large codebook searches-and tree searched vector quantizers-which are suboptimal but require far less searching. The various systems are compared on the basis of performance, complexity, and generality of design techniques."
            },
            "slug": "Vector-Quantizers-and-Predictive-Quantizers-for-Gray-Linde",
            "title": {
                "fragments": [],
                "text": "Vector Quantizers and Predictive Quantizers for Gauss-Markov Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Low-rate vector quantizers are designed and simulated for highly correlated Gauss-Markov sources and the resulting performance is compared with Arnstein's optimized predictive quantizer and with Huang and Schultheiss' optimized transform coder."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143798160"
                        ],
                        "name": "J. Kieffer",
                        "slug": "J.-Kieffer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kieffer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kieffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 12565085,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a8fac7ac6a48af06bb99e1def1db4ec37edfe496",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Locally-Optimal-Block-Quantizer-Design-Gray-Kieffer",
            "title": {
                "fragments": [],
                "text": "Locally Optimal Block Quantizer Design"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40363432"
                        ],
                        "name": "C. Bei",
                        "slug": "C.-Bei",
                        "structuredName": {
                            "firstName": "Chang-da",
                            "lastName": "Bei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45729295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3355939e5e365c82ea232f7edbc96311f39aac3b",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Most tree or trellis encoding data compression systems use decoders which form scalar outputs as a (possibly nonlinear) function of the contents of a shift register containing received channel symbols. We here develop design algorithms for trellis encoding systems having decoders not constrained to have such a scalar sliding-block code structure. In particular, we consider using the decoder of a finite-state vector quantizer together with a vector trellis search. Simulation results are presented for vector trellis encoding systems for Gauss-Markov sources, sampled speech data, and LPC speech data."
            },
            "slug": "Simulation-of-Vector-Trellis-Encoding-Systems-Bei-Gray",
            "title": {
                "fragments": [],
                "text": "Simulation of Vector Trellis Encoding Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work develops design algorithms for trellis encoding systems having decoders not constrained to have such a scalar sliding-block code structure, and considers using the decoder of a finite-state vector quantizer together with a vector Trellis search."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144478790"
                        ],
                        "name": "D. Wong",
                        "slug": "D.-Wong",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62258903,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "9430a4fa1db5e942639be9f5225e72d04aa43d4d",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "An 800 bit/s vector quantization linear predictive coding (LPC) vocoder has been developed. The recently developed LPC vector quantization theory is applied to reduce the bit rate for LPC coefficients coding by a factor of four. Branch search techniques and separation of voiced and unvoiced codebooks are applied for better algorithm efficiency. Differential coding is applied to reduce the bit rate for the pitch and gain parameters by one third. Formal subjective evaluation shows that the 800 bit/s vocoder preserves most of the intelligibility of an LPC system. It is also robust under different transmission error and acoustic conditions. Informal listening comparisons show the quality to be acceptable and sometimes very close to 2400 bit/s LPC speech. The computational cost of the 800 bit/s vocoder is equivalent to or even lower than the 2400 bit/s LPC-10. Compatibility with any LPC-10 vocoder is guaranteed because the 800 bit/s design only differs in the quantization and encoding algorithms. Further bit rate reduction can be achieved by removing frame to frame redundancy in the code."
            },
            "slug": "An-800-bit/s-vector-quantization-LPC-vocoder-Wong-Juang",
            "title": {
                "fragments": [],
                "text": "An 800 bit/s vector quantization LPC vocoder"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An 800 bit/s vector quantization linear predictive coding (LPC) vocoder has been developed that preserves most of the intelligibility of an LPC system and compatibility with any LPC-10 vocoder is guaranteed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49395872"
                        ],
                        "name": "J. Dunn",
                        "slug": "J.-Dunn",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Dunn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dunn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62260841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c27c622f852c6a1c5b03f5bd3b12f4807a583252",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "An experimental model of a coder for transmission of speech over a 9600-bits/s digital channel was built to demonstrate feasibility of an adaptive prediction-coding technique. After analog-to-digital conversion of the speech input, the coder employs digital processing using a computer type organization. Resonances in the short-term speech spectrum are removed by a nonrecursive digital transmit filter and the resulting uncorrelated signal is coded by an 8000-bits/s direct feedback delta coder. The transmit filter parameters are adapted to the input spectrum by a least squares algorithm involving calculation of short term correlation coefficients of the sequence of input samples. These filter parameters are multiplexed with the delta coder output for transmission to the receiver. A recursive receive filter restores the original speech spectrum. A computer simulation of the voice digitizer was performed to determine the order of the digital filters and to optimize other parameters prior to the design of the experimental model. The results of the simulation and design considerations for the experimental model are described."
            },
            "slug": "An-Experimental-9600-bits/s-Voice-Digitizer-Dunn",
            "title": {
                "fragments": [],
                "text": "An Experimental 9600-bits/s Voice Digitizer Employing Adaptive Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An experimental model of a coder for transmission of speech over a 9600-bits/s digital channel was built to demonstrate feasibility of an adaptive prediction-coding technique."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107455267"
                        ],
                        "name": "D. Chen",
                        "slug": "D.-Chen",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56799778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "321ad1c38b4f70aa4cf2de6b9e0f863e97d49785",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "It is hard to compute the performance of an N-level K-dimensional optimum quantizer \\hat{Q}_{N} directly. In this paper the performance of \\hat{Q}_{N} is studied more closely from the performance of Q' N , a class of stationary quantizers. An analytical derivation of the algorithm for generating Q' N quantizers and a computer experimental study on the performance of Q' N for two dimensional case are given. The results show that it is possible to bound the performance of \\hat{Q}N more closely from Q' N ."
            },
            "slug": "On-two-or-more-dimensional-optimum-quantizers-Chen",
            "title": {
                "fragments": [],
                "text": "On two or more dimensional optimum quantizers"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The results show that it is possible to bound the performance of Q'N more closely from Q' N, a class of stationary quantizers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256388"
                        ],
                        "name": "D. Burton",
                        "slug": "D.-Burton",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Burton",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35201459"
                        ],
                        "name": "J. Shore",
                        "slug": "J.-Shore",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shore",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143855885"
                        ],
                        "name": "J. Buck",
                        "slug": "J.-Buck",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buck"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35161223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5d11cb76a8c6c1b2443e4392a43939fc6b86ab8",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of vector quantization (VQ) for isolated-word speech recognition of a 20-word vocabulary was shown in previous work to achieve more than 99% accuracy for speaker-dependent recognition and 87% accuracy for speaker-independent recognition. Separate VQ codebooks were designed for each word in the recognition vocabulary, and input words were classified by performing VQ and finding the codebook that achieves the smallest average distortion. The method obviates time-normalization and makes no use of time-sequence information. This paper presents results for a generalization that incorporates time-sequence information. The generalization, which was motivated by work of Martinez, Riveria, and Buzo, is more accurate and faster than the previous method. Words in the training and input sequences are normalized linearly to the same length and then divided into sections. Separate VQ codebooks are designed for each section of each vocabulary word. Each vocabulary word is then represented by a \"multisection\" codebook - a time-dependent sequence of section-codebooks. New words are classified by performing VQ and finding the multi-section codebook that achieves the smallest average distortion. Initial tests on a twenty-word vocabulary resulted in accuracies greater than 97% for speaker-independent recognition."
            },
            "slug": "A-generalization-of-isolated-word-recognition-using-Burton-Shore",
            "title": {
                "fragments": [],
                "text": "A generalization of isolated word recognition using vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper presents results for a generalization of vector quantization for isolated-word speech recognition of a 20-word vocabulary that incorporates time-sequence information, which is more accurate and faster than the previous method."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3349348"
                        ],
                        "name": "G. Rebolledo",
                        "slug": "G.-Rebolledo",
                        "structuredName": {
                            "firstName": "Guillermo",
                            "lastName": "Rebolledo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rebolledo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35201459"
                        ],
                        "name": "J. Shore",
                        "slug": "J.-Shore",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shore",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40272879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e16afced04247c02fb99036b7e00a1256fdbe066",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An information theory approach to the theory and practice of linear predictive coded (LPC) speech compression systems is developed. It is shown that a traditional LPC system can be viewed as a minimum distortion or nearest-neighbor system where the distortion measure is a minimum discrimination information between a speech process model and an observed frame of actual speech. This distortion measure is used in an algorithm for computer-aided design of block source codes subject to a fidelity criterion to obtain a 750-bits/s speech compression system that resembles an LPC system but has a much lower rate, a larger memory requirement, and requires no on-line LPC analysis. Quantitative and informal subjective comparisons are made among our system and LPC systems."
            },
            "slug": "Rate-distortion-speech-coding-with-a-minimum-Gray-Gray",
            "title": {
                "fragments": [],
                "text": "Rate-distortion speech coding with a minimum discrimination information distortion measure"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An information theory approach to the theory and practice of linear predictive coded speech compression systems is developed and it is shown that a traditional LPC system can be viewed as a minimum distortion or nearest-neighbor system where the distortion measure is a minimum discrimination information between a speech process model and an observed frame of actual speech."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25179305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8acf7cb1d476ba09b401b0c13abe81d4b96d128e",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an approach to speaker-independent, isolated word recognition in which the well-known techniques of vector quantization and hidden Markov modeling are combined with a linear predictive coding analysis front end. This is done in the framework of a standard statistical pattern recognition model. Both the vector quantizer and the hidden Markov models need to be trained for the vocabulary being recognized. Such training results in a distinct hidden Markov model for each word of the vocabulary. Classification consists of computing the probability of generating the test word with each word model and choosing the word model that gives the highest probability. There are several factors, in both the vector quantizer and the hidden Markov modeling, that affect the performance of the overall word recognition system, including the size of the vector quantizer, the structure of the hidden Markov model, the ways of handling insufficient training data, etc. The effects, on recognition accuracy, of many of these factors are discussed in this paper. The entire recognizer (training and testing) has been evaluated on a 10-word digits vocabulary. For training, a set of 100 talkers spoke each of the digits one time. For testing, an independent set of 100 tokens of each of the digits was obtained. The overall recognition accuracy was found to be 96.5 percent for the 100-talker test set. These results are comparable to those obtained in earlier work, using a dynamic time-warping recognition algorithm with multiple templates per digit. It is also shown that the computation and storage requirements of the new recognizer were an order of magnitude less than that required for a conventional pattern recognition system using linear prediction with dynamic time warping."
            },
            "slug": "On-the-application-of-vector-quantization-and-to-Rabiner-Levinson",
            "title": {
                "fragments": [],
                "text": "On the application of vector quantization and hidden Markov models to speaker-independent, isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper presents an approach to speaker-independent, isolated word recognition in which the well-known techniques of vector quantization and hidden Markov modeling are combined with a linear predictive coding analysis front end in the framework of a standard statistical pattern recognition model."
            },
            "venue": {
                "fragments": [],
                "text": "The Bell System Technical Journal"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699744"
                        ],
                        "name": "E. Ayanoglu",
                        "slug": "E.-Ayanoglu",
                        "structuredName": {
                            "firstName": "Ender",
                            "lastName": "Ayanoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ayanoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41612240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5526d7652ff94a49d5928b6bf2e2bbe83224656d",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Trellis source codes consist of a finite-state machine decoder and a trellis search algorithm, such as the Viterbi algorithm, as the encoder. The encoder experiments with a local copy of the decoder and determines the best channel path map in the sense that it will yield the smallest average distortion between the source sequence and the reproduction sequence given the codebook. In this paper we present a coding system and a design algorithm for predictive trellis coding. Results obtained via simulation are compared for trellis and predictive trellis codes designed for first-order autoregressive sources with Gaussian and Laplacian innovations and for sampled speech. On a random source which models speech, simulation results of the predictive and nonpredictive trellis codes designed by the generalized Lloyd algorithm and those obtained by other researchers are compared. Issues related to computational complexity, the effects of initial codebook selection, training sequence segmentation, search length, channel errors, and algorithm convergence are addressed."
            },
            "slug": "The-Design-of-Predictive-Trellis-Waveform-Coders-Ayanoglu-Gray",
            "title": {
                "fragments": [],
                "text": "The Design of Predictive Trellis Waveform Coders Using the Generalized Lloyd Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Simulation results of the predictive and nonpredictive trellis codes designed by the generalized Lloyd algorithm and those obtained by other researchers are compared."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680714"
                        ],
                        "name": "J. Conway",
                        "slug": "J.-Conway",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Conway",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Conway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143992833"
                        ],
                        "name": "N. Sloane",
                        "slug": "N.-Sloane",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sloane",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sloane"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6020922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15525b54f23553c6163d9be812a886357f82cd21",
            "isKey": false,
            "numCitedBy": 430,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "For each of the lattices A_{n}(n \\geq 1), D_{n}(n \\geq 2), E_{6}, E_{7}, E_{8} , and their duals a very fast algorithm is given for finding the closest lattice point to an arbitrary point. If these lattices are used for vector quantizing of uniformly distributed data, the algorithm finds the minimum distortion lattice point. If the lattices are used as codes for a Gaussian channel, the algorithm performs maximum likelihood decoding."
            },
            "slug": "Fast-quantizing-and-decoding-and-algorithms-for-and-Conway-Sloane",
            "title": {
                "fragments": [],
                "text": "Fast quantizing and decoding and algorithms for lattice quantizers and codes"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A very fast algorithm is given for finding the closest lattice point to an arbitrary point if these lattices are used for vector quantizing of uniformly distributed data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1877245"
                        ],
                        "name": "J. Adoul",
                        "slug": "J.-Adoul",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Adoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Adoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38531185"
                        ],
                        "name": "S. Morissette",
                        "slug": "S.-Morissette",
                        "structuredName": {
                            "firstName": "Sarto",
                            "lastName": "Morissette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Morissette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46951832"
                        ],
                        "name": "M. Rudko",
                        "slug": "M.-Rudko",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Rudko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rudko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36987922,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "d372ab6941ffb44cea348a6ba78cc70772962447",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper present an original numerical algorithm for reducing by a factor of two (32 Kbits/ sec) the bit rate of telephone speech already digitized in standard PCM. At the end of the line (i.e. expensive media) an inverse algorithm resynthesizes a PCM signal which preserves a high telephone quality. This bit-rate compression algorithm is thus essentially \"transparent\" to PCM transmissions and therefore finds immediate applications for increasing carrier capacity. In particular when used in connection with speech interpolation techniques [1] it enables a fourfold increase in the number of channels per carrier."
            },
            "slug": "Bit-rate-halving-algorithm-for-PCM-encoded-speech-a-Adoul-Morissette",
            "title": {
                "fragments": [],
                "text": "Bit-rate-halving algorithm for PCM-encoded speech using a new bidimensional data compression scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An original numerical algorithm for reducing by a factor of two the bit rate of telephone speech already digitized in standard PCM, which enables a fourfold increase in the number of channels per carrier."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34886891"
                        ],
                        "name": "A. Gray",
                        "slug": "A.-Gray",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Gray",
                            "middleNames": [
                                "H."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2233956"
                        ],
                        "name": "Y. Matsuyama",
                        "slug": "Y.-Matsuyama",
                        "structuredName": {
                            "firstName": "Yasuo",
                            "lastName": "Matsuyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Matsuyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124419055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "508aaa8c28b538214b7cb76dfeb6cdb9994e664d",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Several properties, interrelations, and interpretations are developed for various speech spectral distortion measures. The principle results are 1) the development of notions of relative strength and equivalence of the various distortion measures both in a mathematical sense corresponding to subjective equivalence and in a coding sense when used in minimum distortion or nearest neighbor speech processing systems; 2) the demonstration that the Itakura-Saito and related distortion measures possess a property similar to the triangle inequality when used in nearest neighbor systems such as quantization and cluster analysis; and 3) that the Itakura-Saito and normalized model distortion measures yield efficient computation algorithms for generalized centroids or minimum distortion points of groups or clusters of speech frames, an important computation in both classical cluster analysis techniques and in algorithms for optimal quantizer design. We also argue that the Itakura-Saito and related distortions are well-suited computationally, mathematically, and intuitively for such applications."
            },
            "slug": "Distortion-measures-for-speech-processing-Gray-Buzo",
            "title": {
                "fragments": [],
                "text": "Distortion measures for speech processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that the Itakura-Saito and related distortions are well-suited computationally, mathematically, and intuitively for such applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758920"
                        ],
                        "name": "H. Abut",
                        "slug": "H.-Abut",
                        "structuredName": {
                            "firstName": "H\u00fcseyin",
                            "lastName": "Abut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Abut"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6013737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2c92b17682db0a42b8e1cc35a08ee514dcd3d15",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector quantizers of one and two bits per sample are designed for a training sequence of 640000 speech samples and tested on a speaker not in the training sequence. Both full search vector quantizers and tree search vector quantizers are considered. The tree searched codes are suboptimal in an information theory sense, but they have a greatly reduced search effort and provide a vector successive approximation quantizer."
            },
            "slug": "Full-search-and-tree-searched-vector-quantization-Gray-Abut",
            "title": {
                "fragments": [],
                "text": "Full search and tree searched vector quantization of speech waveforms"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Vector quantizers of one and two bits per sample are designed for a training sequence of 640000 speech samples and tested on a speaker not in the training sequence and the tree searched codes are considered."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35201459"
                        ],
                        "name": "J. Shore",
                        "slug": "J.-Shore",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shore",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1164127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df9e447a5d34e9dcc6ae3234129911674f44acd7",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers the problem of classifying an input vector of measurements by a nearest neighbor rule applied to a fixed set of vectors. The fixed vectors are sometimes called characteristic feature vectors, codewords, cluster centers, models, reproductions, etc. The nearest neighbor rule considered uses a non-Euclidean information-theoretic distortion measure that is not a metric, but that nevertheless leads to a classification method that is optimal in a well-defined sense and is also computationally attractive. Furthermore, the distortion measure results in a simple method of computing cluster centroids. Our approach is based on the minimization of cross-entropy (also called discrimination information, directed divergence, K-L number), and can be viewed as a refinement of a general classification method due to Kullback. The refinement exploits special properties of cross-entropy that hold when the probability densities involved happen to be minimum cross-entropy densities. The approach is a generalization of a recently developed speech coding technique called speech coding by vector quantization."
            },
            "slug": "Minimum-Cross-Entropy-Pattern-Classification-and-Shore-Gray",
            "title": {
                "fragments": [],
                "text": "Minimum Cross-Entropy Pattern Classification and Cluster Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The approach is a generalization of a recently developed speech coding technique called speech coding by vector quantization based on the minimization of cross-entropy, and can be viewed as a refinement of a general classification method due to Kullback."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1877245"
                        ],
                        "name": "J. Adoul",
                        "slug": "J.-Adoul",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Adoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Adoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076468900"
                        ],
                        "name": "J. Debray",
                        "slug": "J.-Debray",
                        "structuredName": {
                            "firstName": "Jean-Louis",
                            "lastName": "Debray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Debray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077109223"
                        ],
                        "name": "D. Dalle",
                        "slug": "D.-Dalle",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Dalle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dalle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33185844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89b204923608e3ed2bf5acdc247cd2154c54c88a",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the intermediate solutions between fixed prediction and forward adaptative prediction in ADPCM which consists of using a finite number, L, of preselected linear predictors of order M. The design problem of selecting the optimum set of predictors with respect to the overall prediction gain is formulated and an iterative procedure is described to obtain the solutions. The relative prediction-gain improvement is computed for a 3 sec. speech sample and for several values of L,M, and block size showing that \\frac{1}{2} of the adaptative over fixed-prediction improvement in dB is reached with only L=4 and 2/3 with L=8 . The design problem solved by minimizing Itakura distance is shown to yield essentially identical performances. A linear discriminant property in the autocorrelation space is pointed out. Based on that property a pattern classification approach is proposed as an hardware-efficient coding algorithm."
            },
            "slug": "Spectral-distance-measure-applied-to-the-optimum-of-Adoul-Debray",
            "title": {
                "fragments": [],
                "text": "Spectral distance measure applied to the optimum design of DPCM coders with L predictors"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This paper explores the intermediate solutions between fixed prediction and forward adaptative prediction in ADPCM which consists of using a finite number of preselected linear predictors of order M to select the optimum set of predictors with respect to the overall prediction gain."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144478790"
                        ],
                        "name": "D. Wong",
                        "slug": "D.-Wong",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053697413"
                        ],
                        "name": "D. Cheng",
                        "slug": "D.-Cheng",
                        "structuredName": {
                            "firstName": "Duan",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1935428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f05bdf361ed9fc59aea32a4aa10b3be5389c0da",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Frame predictive vector quantization is developed to compress the bit rate for coding the LPC filter coefficients to under 250 bits/sec. An innovative LPC compression technique, matrix quantization, is also developed to compress the LPC filter coefficients to a rate under 150 bits/sec. Subjective evaluation with the diagnostic rhyme test (DRT) finds the proposed techniques to be feasible for intelligible speech transmission at bit rates between 400 bits/sec and 200 bits/sec."
            },
            "slug": "Very-low-data-rate-speech-compression-with-LPC-and-Wong-Juang",
            "title": {
                "fragments": [],
                "text": "Very low data rate speech compression with LPC vector and matrix quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Subjective evaluation with the diagnostic rhyme test (DRT) finds the proposed techniques to be feasible for intelligible speech transmission at bit rates between 400 bits/sec and 200 bit/sec."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680714"
                        ],
                        "name": "J. Conway",
                        "slug": "J.-Conway",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Conway",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Conway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143992833"
                        ],
                        "name": "N. Sloane",
                        "slug": "N.-Sloane",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sloane",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sloane"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1064224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399b0319a6b720d4afc953d43341d162b0402ef5",
            "isKey": false,
            "numCitedBy": 306,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "If a point is picked at random inside a regular simplex, octahedron, 600 -cell, or other polytope, what is its average squared distance from the centroid? In n -dimensional space, what is the average squared distance of a random point from the closest point of the lattice A_{n} (or D_{n}, E_{n}, A_{n}^{\\ast} or D_{n}^{\\ast})? The answers are given here, together with a description of the Voronoi (or nearest neighbor) regions of these lattices. The results have applications to quantization and to the design of signals for the Gaussian channel. For example, a quantizer based on the eight-dimensional lattice E8 has a mean-squared error per symbol of 0.0717 \\cdots when applied to uniformly distributed data, compared with 0.08333 \\cdots for the best one-dimensional quantizer."
            },
            "slug": "Voronoi-regions-of-lattices,-second-moments-of-and-Conway-Sloane",
            "title": {
                "fragments": [],
                "text": "Voronoi regions of lattices, second moments of polytopes, and quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The answers to the squared distance questions and a description of the Voronoi (or nearest neighbor) regions of these lattices have applications to quantization and to the design of signals for the Gaussian channel."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35201459"
                        ],
                        "name": "J. Shore",
                        "slug": "J.-Shore",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shore",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256388"
                        ],
                        "name": "D. Burton",
                        "slug": "D.-Burton",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Burton",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37213455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b603268827235dc0d5f4323b17a6f9bc64e24d08",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The results of a new method are presented for discrete utterance speech recognition. The method is based on rate-distortion speech coding (speech coding by vector quantization), minimum cross-entropy pattern classification, and information-theoretic spectral distortion measures. Separate vector quantization code books are designed from training sequences for each word in the recognition vocabulary. Inputs from outside the training sequence are classified by performing vector quantization and finding the code book that achieves the lowest average distortion per speech frame. The new method obviates time alignment. It achieves 99 percent accuracy for speaker-dependent recognition of a 20 -word vocabulary that includes the ten digits, with higher accuracy for recognition of the digit subset. For speaker-independent recognition, the method achieves 88 percent accuracy for the 20 -word vocabulary and 95 percent for the digit subset. Background of the method, detailed empirical results, and an analysis of computational requirements are presented."
            },
            "slug": "Discrete-utterance-speech-recognition-without-time-Shore-Burton",
            "title": {
                "fragments": [],
                "text": "Discrete utterance speech recognition without time alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The results of a new method based on rate-distortion speech coding (speech coding by vector quantization), minimum cross-entropy pattern classification, and information-theoretic spectral distortion measures for discrete utterance speech recognition are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144649822"
                        ],
                        "name": "C. D. Heron",
                        "slug": "C.-D.-Heron",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Heron",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Heron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657626"
                        ],
                        "name": "R. Crochiere",
                        "slug": "R.-Crochiere",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Crochiere",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Crochiere"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3261454"
                        ],
                        "name": "R. Cox",
                        "slug": "R.-Cox",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Cox",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cox"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30092019,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d31579e9bdf5934f7d2331485c780674d47b95e6",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we report on a study of a technique for 32-band subband/transform coding at 16 kb/s. This approach occupies the middle range of algorithm complexities and frequency resolution between that of Sub-Band Coding (SBC) and Adaptive Transform Coding (ATC). Two designs for 16 kb/s 32-band coders have been simulated on a laboratory computer. The results of informal listening tests indicate that the new designs offer performance comparable to existing ATC techniques while having complexities roughly three times that of existing 4 and 5 band sub-band coders."
            },
            "slug": "A-32-band-sub-band/Transform-coder-incorporating-Heron-Crochiere",
            "title": {
                "fragments": [],
                "text": "A 32-band sub-band/Transform coder incorporating vector quantization for dynamic bit allocation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The results of informal listening tests indicate that the new designs offer performance comparable to existing ATC techniques while having complexities roughly three times that of existing 4 and 5 band sub-band coders."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442185"
                        ],
                        "name": "J. Gibson",
                        "slug": "J.-Gibson",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Gibson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gibson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107761201"
                        ],
                        "name": "S. Jones",
                        "slug": "S.-Jones",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3051300"
                        ],
                        "name": "J. Melsa",
                        "slug": "J.-Melsa",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Melsa",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Melsa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62525673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "caf7e0f49ac170258933f295e497173ec9462a52",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of speech digitization called residual encoding is introduced, and its application to the speech digitization problem is studied. The residual encoding system is a form of differential pulse code modulation which utilizes both an adaptive quantizer and an adaptive predictor. The residual encoder differs from previous systems in two ways. First, a sequential estimation method is used to continuously update the predictor coefficients, and second, the predictor coefficients are not transmitted, but are extracted from the estimate of the speech signal at both the transmitter and receiver. No form of pitch extraction is employed. The residual encoding system with a Kalman filter or a stochastic approximation algorithm for identifying the predictor coefficients has produced good quality speech at a data rate of 16 kbit/s."
            },
            "slug": "Sequentially-Adaptive-Prediction-and-Coding-of-Gibson-Jones",
            "title": {
                "fragments": [],
                "text": "Sequentially Adaptive Prediction and Coding of Speech Signals"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The residual encoding system with a Kalman filter or a stochastic approximation algorithm for identifying the predictor coefficients has produced good quality speech at a data rate of 16 kbit/s."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056846574"
                        ],
                        "name": "L. C. Stewart",
                        "slug": "L.-C.-Stewart",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Stewart",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. C. Stewart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56584598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90cd60efe7e29866a10e97aa57ab90f229031166",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "New algorithms for the design of trellis encoding data compression systems are described. The mare algorithm uses a training sequence of actual data from a source to improve an initial trellis decoder. An additional algorithm extends the constraint length of a given decoder. Combined, these algorithms allow the automatic design of a trellis encoding system for a particular source. The algorithms' effectiveness for random sources is demonstrated through performance comparisons with other source coding systems and with theoretical bounds. The algorithms are applied to the practical problem of the design of trellis and hybrid codes for medium-to-lowrate speech compression."
            },
            "slug": "The-Design-of-Trellis-Waveform-Coders-Stewart-Gray",
            "title": {
                "fragments": [],
                "text": "The Design of Trellis Waveform Coders"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The mare algorithm uses a training sequence of actual data from a source to improve an initial trellis decoder and an additional algorithm extends the constraint length of a given decoder to allow the automatic design of a Trellis encoding system for a particular source."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143798160"
                        ],
                        "name": "J. Kieffer",
                        "slug": "J.-Kieffer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kieffer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kieffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69560096"
                        ],
                        "name": "M. Rahe",
                        "slug": "M.-Rahe",
                        "structuredName": {
                            "firstName": "Maurice",
                            "lastName": "Rahe",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rahe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121899815,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ab68d392f42fd70d334abb5be0154c074ad72cdf",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A type of discrete channel is defined which includes the finite-state channel of Blackwell et al. (Ann. Math. Statist., 29 (1958), pp. 1209\u20131220) and the finite-state source encoder of Shannon (Bell System Tech. J., 27 (1948), pp. 379\u2013423, 623\u2013656) as special cases. It is shown that if the input source to the Markov channel is asymptotically mean stationary in the sense of Gray and Kiefler, then the resulting input-output pair measure is asymptotically mean stationary also. An application to probability theory is given regarding the asymptotic behavior of a sequence of random stochastic matrices."
            },
            "slug": "Markov-Channels-are-Asymptotically-Mean-Stationary-Kieffer-Rahe",
            "title": {
                "fragments": [],
                "text": "Markov Channels are Asymptotically Mean Stationary"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that if the input source to the Markov channel is asymptotically mean stationary in the sense of Gray and Kiefler, then the resulting input-output pair measure is ascyptotical mean stationary also."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056664063"
                        ],
                        "name": "Horacio G. Martinez",
                        "slug": "Horacio-G.-Martinez",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Martinez",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Horacio G. Martinez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059157795"
                        ],
                        "name": "C. Rivera",
                        "slug": "C.-Rivera",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Rivera",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rivera"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8909202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "358626cf193aaa4916852ebd459c42765fa7bea7",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A speaker-independent isolated word recognition system is described which is based on some techniques and results from rate-distortion speech coders. The recognition system can be viewed as a minimum distortion or nearest-neighbor system where the distortion measure is defined between an observed sequence of frames of speech and a reference pattern. The patterns are sequences of sets of LPC models. Every one of the sets of each pattern consist of a collection of LPC models that \"best\" reproduces a given frame of a word from a training sequence. The Itakura Saito distortion measure is used to design the system (or selection of the patterns) and for the decision step."
            },
            "slug": "Discrete-utterance-recognition-based-upon-source-Buzo-Martinez",
            "title": {
                "fragments": [],
                "text": "Discrete utterance recognition based upon source coding techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A speaker-independent isolated word recognition system is described which is based on some techniques and results from rate-distortion speech coders and the Itakura Saito distortion measure is used to design the system (or selection of the patterns) and for the decision step."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474834"
                        ],
                        "name": "H. Fehn",
                        "slug": "H.-Fehn",
                        "structuredName": {
                            "firstName": "Heinz",
                            "lastName": "Fehn",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980396"
                        ],
                        "name": "P. Noll",
                        "slug": "P.-Noll",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Noll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Noll"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62753411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "127ab061d6970da7b6adbc39757d84cb4bca4213",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the application of multipath search coding (MSC) concepts to the coding of stationary memoryless and correlated sources and of speech signals at a rate of one bit per sample. We have made use of three MSC classes: 1) codebook coding (vector quantization), 2) tree coding, and 3) trellis coding. This paper explains the performances of these coders and compares them both with those of conventional coders and with rate-distortion bounds. Figs. 2 and 3 demonstrate the potentials of MSC coding strategies. The paper reports also on results of MSC coding of speech, where both the strategy of adaptive quantization and of adaptive prediction were included in coder design."
            },
            "slug": "Multipath-Search-Coding-of-Stationary-Signals-with-Fehn-Noll",
            "title": {
                "fragments": [],
                "text": "Multipath Search Coding of Stationary Signals with Applications to Speech"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The paper reports also on results of MSC coding of speech, where both the strategy of adaptive quantization and of adaptive prediction were included in coder design."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48235382"
                        ],
                        "name": "R. Fontana",
                        "slug": "R.-Fontana",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fontana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fontana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143798160"
                        ],
                        "name": "J. Kieffer",
                        "slug": "J.-Kieffer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kieffer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kieffer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19591385,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "8d73d338dec6749608c6db040ce951b228304883",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A necessary and sufficient condition for a source to satisfy the ergodic theorem and the Shannon-McMillan theorem--the two basic mathematical tools of the Shannon theory--is that it be asymptotically mean stationary (AMS). A channel is defined here to be AMS if whenever an AMS input source is connected to the channel, the resulting input/output process is AMS. We develop several characterizations and properties of AMS channels that resemble those of AMS sources. As an application we show that these ideas are useful in characterizing composite sources, and in particular that there exist sources that exhibit distinct short term and long term stationarity properties. Thus \"locally stationary\" or \"quasi-stationary\" processes such as those used to model speech waveforms may also be stationary. In addition, some preliminary results on coding for AMS channels are presented."
            },
            "slug": "Asymptotically-mean-stationary-channels-Fontana-Gray",
            "title": {
                "fragments": [],
                "text": "Asymptotically mean stationary channels"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that there exist sources that exhibit distinct short term and long term stationarity properties and that \"locally stationary\" or \"quasi-stationary\" processes such as those used to model speech waveforms may also be stationary."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575575"
                        ],
                        "name": "N. Gaarder",
                        "slug": "N.-Gaarder",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Gaarder",
                            "middleNames": [
                                "Thomas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gaarder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480110"
                        ],
                        "name": "D. Slepian",
                        "slug": "D.-Slepian",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Slepian",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Slepian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3116606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20340aaf18de2adfe61310fa8081a87ade0b293e",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The digital transmission of signals by transmitters and receivers that are time-invariant finite-state machines were investigated in general form. An average distortion criterion is used. Some general structure theorems are proved and some examples given that show improvement in performance as the memories of the transmitter and receiver are increased. Many conjectures and unsolved problems are mentioned, and areas for further study are indicated."
            },
            "slug": "On-optimal-finite-state-digital-transmission-Gaarder-Slepian",
            "title": {
                "fragments": [],
                "text": "On optimal finite-state digital transmission systems"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The digital transmission of signals by transmitters and receivers that are time-invariant finite-state machines were investigated in general form and examples given that show improvement in performance as the memories of the transmitter and receiver are increased."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104537710"
                        ],
                        "name": "J. MacQueen",
                        "slug": "J.-MacQueen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "MacQueen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacQueen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6278891,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac8ab51a86f1a9ae74dd0e4576d1a019f5e654ed",
            "isKey": false,
            "numCitedBy": 24210,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to describe a process for partitioning an N-dimensional population into k sets on the basis of a sample. The process, which is called 'k-means,' appears to give partitions which are reasonably efficient in the sense of within-class variance. That is, if p is the probability mass function for the population, S = {S1, S2, * *, Sk} is a partition of EN, and ui, i = 1, 2, * , k, is the conditional mean of p over the set Si, then W2(S) = ff=ISi f z u42 dp(z) tends to be low for the partitions S generated by the method. We say 'tends to be low,' primarily because of intuitive considerations, corroborated to some extent by mathematical analysis and practical computational experience. Also, the k-means procedure is easily programmed and is computationally economical, so that it is feasible to process very large samples on a digital computer. Possible applications include methods for similarity grouping, nonlinear prediction, approximating multivariate distributions, and nonparametric tests for independence among several variables. In addition to suggesting practical classification methods, the study of k-means has proved to be theoretically interesting. The k-means concept represents a generalization of the ordinary sample mean, and one is naturally led to study the pertinent asymptotic behavior, the object being to establish some sort of law of large numbers for the k-means. This problem is sufficiently interesting, in fact, for us to devote a good portion of this paper to it. The k-means are defined in section 2.1, and the main results which have been obtained on the asymptotic behavior are given there. The rest of section 2 is devoted to the proofs of these results. Section 3 describes several specific possible applications, and reports some preliminary results from computer experiments conducted to explore the possibilities inherent in the k-means idea. The extension to general metric spaces is indicated briefly in section 4. The original point of departure for the work described here was a series of problems in optimal classification (MacQueen [9]) which represented special"
            },
            "slug": "Some-methods-for-classification-and-analysis-of-MacQueen",
            "title": {
                "fragments": [],
                "text": "Some methods for classification and analysis of multivariate observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680714"
                        ],
                        "name": "J. Conway",
                        "slug": "J.-Conway",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Conway",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Conway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143992833"
                        ],
                        "name": "N. Sloane",
                        "slug": "N.-Sloane",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sloane",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sloane"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16523257,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a4ca74c1096efd34780b2c8dae8261ab403b5ade",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The Voronoi region of a lattice $L_n \\subseteq \\mathbb{R}^n $ is the convex polytope consisting of all points of $\\mathbb{R}^{\\text{n}} $ that are closer to the origin than to any other point of $L_n $. In this paper we calculate the second moments of the Voronoi regions of the lattices $E_6^ * ,E_7^ * ,K_{12} ,\\Lambda _{16} $ and $\\Lambda _{24} $. The results show that these lattices are the best quantizers presently known in dimensions 6, 7,12,16 and 24. The calculations are performed by Monte Carlo integration, and make use of fast algorithms for finding the closest lattice point to an arbitrary point of the space. We also establish two general theorems concerning the number of faces of the Voronoi region of a lattice."
            },
            "slug": "On-the-Voronoi-Regions-of-Certain-Lattices-Conway-Sloane",
            "title": {
                "fragments": [],
                "text": "On the Voronoi Regions of Certain Lattices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "96917156"
                        ],
                        "name": "E. S. Barnes",
                        "slug": "E.-S.-Barnes",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Barnes",
                            "middleNames": [
                                "Shippen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. S. Barnes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143992833"
                        ],
                        "name": "N. Sloane",
                        "slug": "N.-Sloane",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sloane",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sloane"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122148647,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "29c94f6a2c16458f3b36a084f386477573d361b6",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The body-centered cubic lattice is shown to have the smallest mean squared error of any lattice quantizer in three dimensions, assuming that the input to the quantizer has a uniform distribution."
            },
            "slug": "The-Optimal-Lattice-Quantizer-in-Three-Dimensions-Barnes-Sloane",
            "title": {
                "fragments": [],
                "text": "The Optimal Lattice Quantizer in Three Dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The body-centered cubic lattice is shown to have the smallest mean squared error of any lattice quantizer in three dimensions, assuming that the input to the quantizer has a uniform distribution."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143798160"
                        ],
                        "name": "J. Kieffer",
                        "slug": "J.-Kieffer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kieffer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kieffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120950487,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fedfd8b4021495fa85eac73a7972082ff3ebddbd",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Numerous properties are developed of measures that are asymptotically mean stationary with respect to a possibly nonsingular and noninvertible measurable transformation on a probability space. In particular, several necessary and sufficient conditions for the measure and transformation to satisfy the ergodic theorem are given, an asymptotic form of the Radon-Nikodym theorem for asymptotically dominated measures is developed, and the asymptotic behavior of the resulting Radon-Nikodym derivatives is described. As an application we prove a Shannon-McMillan-Breiman theorem for the case considered. Several examples are given to illustrate the results."
            },
            "slug": "Asymptotically-Mean-Stationary-Measures-Gray-Kieffer",
            "title": {
                "fragments": [],
                "text": "Asymptotically Mean Stationary Measures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31408841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a175b36ec7f2f08cb3dfac30ce141e144ec9e9",
            "isKey": false,
            "numCitedBy": 991,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical methods useful in automatic recognition of continuous speech are described. They concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding. Experimental results are presented that indicate the power of the methods."
            },
            "slug": "Continuous-speech-recognition-by-statistical-Jelinek",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by statistical methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Experimental results are presented that indicate the power of the methods and concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30752333"
                        ],
                        "name": "J. Omura",
                        "slug": "J.-Omura",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Omura",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Omura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 290
                            }
                        ],
                        "text": "\u2026instead of scalars, even if the data source is memoryless, e.g., consists of a sequence of independent random variables, or if the data compression system can have memory, i.e., the action of an encoder at each time is permitted to depend on past encoder inputs or outputs [4] [5] [6] [7] [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195895025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "893caf4196d0fce0c287e7c8099beda28abf0ada",
            "isKey": false,
            "numCitedBy": 943,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Principles of digital communication and coding , Principles of digital communication and coding , \u0645\u0631\u06a9\u0632 \u0641\u0646\u0627\u0648\u0631\u06cc \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u0648 \u0627\u0637\u0644\u0627\u0639 \u0631\u0633\u0627\u0646\u06cc \u06a9\u0634\u0627\u0648\u0631\u0632\u06cc"
            },
            "slug": "Principles-of-Digital-Communication-and-Coding-Viterbi-Omura",
            "title": {
                "fragments": [],
                "text": "Principles of Digital Communication and Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The principles of digital communication and coding are presented and a practical application of these principles, called \"Principles of Digital Communication and coding\", are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145456212"
                        ],
                        "name": "P. Chang",
                        "slug": "P.-Chang",
                        "structuredName": {
                            "firstName": "Pao-Chi",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059711352"
                        ],
                        "name": "J. May",
                        "slug": "J.-May",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "May",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. May"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 230430613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb47aae283f5647790444a9f84ad68462bf71a83",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-vector-quantizers-with-table-lookup-Chang-Gray",
            "title": {
                "fragments": [],
                "text": "Hierarchical vector quantizers with table-lookup encoders"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143644766"
                        ],
                        "name": "G. Gabor",
                        "slug": "G.-Gabor",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Gabor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gabor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125735"
                        ],
                        "name": "Z. Gy\u00f6rfi",
                        "slug": "Z.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "Zolt\u00e1n",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Gy\u00f6rfi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124238349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdbbc01e681828d840379306a621753307117fd2",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-source-coding-Gabor-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "Recursive source coding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22904118"
                        ],
                        "name": "K. H. Barratt",
                        "slug": "K.-H.-Barratt",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Barratt",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. H. Barratt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109950677,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "71bc7b7e454337656656b656ce615c9cc17f0e59",
            "isKey": false,
            "numCitedBy": 1167,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Digital-Coding-of-Waveforms-Barratt",
            "title": {
                "fragments": [],
                "text": "Digital Coding of Waveforms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143834737"
                        ],
                        "name": "D. A. Bell",
                        "slug": "D.-A.-Bell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Bell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 282
                            }
                        ],
                        "text": "\u2026instead of scalars, even if the data source is memoryless, e.g., consists of a sequence of independent random variables, or if the data compression system can have memory, i.e., the action of an encoder at each time is permitted to depend on past encoder inputs or outputs [4] [5] [6] [7] [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 109410157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e163fb03f549ab2bb1dbbf746005553ea15a575",
            "isKey": false,
            "numCitedBy": 2797,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Theory-and-Reliable-Communication-Bell",
            "title": {
                "fragments": [],
                "text": "Information Theory and Reliable Communication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395615041"
                        ],
                        "name": "M. Sabin",
                        "slug": "M.-Sabin",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Sabin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sabin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59868614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3e1f33af8fdbafdd3d97adf0a9e90f9b44d1dc6",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Product-code-vector-quantizers-for-speech-waveform-Sabin-Gray",
            "title": {
                "fragments": [],
                "text": "Product code vector quantizers for speech waveform coding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Info. Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Info. Theory"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tree-searched Block Source Codes"
            },
            "venue": {
                "fragments": [],
                "text": "Il Proceedings of the 1980 Allerton Conference"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector quantization of video signals"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Annual Conference o f I\u20acC\u20ac"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis synthesis telephony based on the maximum liklihood method"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 6th International Congress o f Acoustics"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A method for constructing successive approximation vector quantizers for video signals"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings ofthe Annual Conference"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector quantizer of video signals"
            },
            "venue": {
                "fragments": [],
                "text": "Vector quantizer of video signals"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IIPractical Universal Noiseless Coding,t1 SPIE Symposium Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IIPractical Universal Noiseless Coding,t1 SPIE Symposium Proceedings"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "I I A Technique for High-performance Data Compression,It Computer"
            },
            "venue": {
                "fragments": [],
                "text": "I I A Technique for High-performance Data Compression,It Computer"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector quantization and Markov models applied to speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICASSP 82"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image coding using segmented codebooks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings International Picture Coding Symposium"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "posium on lnformation Theory"
            },
            "venue": {
                "fragments": [],
                "text": "posium on lnformation Theory"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Il IEEE ASSP Magazine"
            },
            "venue": {
                "fragments": [],
                "text": "Il IEEE ASSP Magazine"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IIArithmetic Coding for Data Compressionttl Communications of the ACM"
            },
            "venue": {
                "fragments": [],
                "text": "IIArithmetic Coding for Data Compressionttl Communications of the ACM"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Design of Time-invariant Trellis Source Codes, Abstracts of the"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Symposium on Information Theory"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A speech recognition system using inverse filter matching technique"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings o f the Ann. Conf. Inst. o f Television Engineers"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The design of time-invariant trellis source codes"
            },
            "venue": {
                "fragments": [],
                "text": "Abstracts o f the 1983 /\u20acE\u20ac International Symposium on Information Theory"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image compression using non-adaptive spatial vector quantization"
            },
            "venue": {
                "fragments": [],
                "text": "Conference Record of the Sixteenth Asilomar Conference on Circuits Systems and Computers"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for the design o f labeled-transition finite-state vector quantizers , submitted for publication"
            },
            "venue": {
                "fragments": [],
                "text": "An algorithm for the design o f labeled-transition finite-state vector quantizers , submitted for publication"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Locally optipp"
            },
            "venue": {
                "fragments": [],
                "text": "Locally optipp"
            },
            "year": 1948
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IITrellis Data Compression"
            },
            "venue": {
                "fragments": [],
                "text": "IITrellis Data Compression"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Design and Analysis of Trellis Source Codes"
            },
            "venue": {
                "fragments": [],
                "text": "Design and Analysis of Trellis Source Codes"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Editor, Waveform coding quantization and Coding"
            },
            "venue": {
                "fragments": [],
                "text": "Editor, Waveform coding quantization and Coding"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector quantizer design for video signals"
            },
            "venue": {
                "fragments": [],
                "text": "Vector quantizer design for video signals"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Differential Vector Quantization of Achromatic Imagery"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Picture Coding Symposium"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast Nearest Neighbor Search for Nonstructured Euclidean Codes, It Abstracts of the"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Symposium on Information Theory"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On Measuring by Cornparison,l1 Zastos"
            },
            "venue": {
                "fragments": [],
                "text": "Mat"
            },
            "year": 1955
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 88,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Vector-quantization-Gray/81a5952532cdd48eec5e3dc326907c36a70e0a24?sort=total-citations"
}