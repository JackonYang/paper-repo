{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3344005"
                        ],
                        "name": "C. Dance",
                        "slug": "C.-Dance",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Dance",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dance"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 38
                            }
                        ],
                        "text": "This paper extends our previous work (Perronnin and Dance, 2007, Perronnin et al, 2010c, Sa\u0301nchez and Perronnin,\n2011) with: (1) a more detailed description of the FK framework and especially of the computation of the Fisher information matrix, (2) a more detailed analysis of the recent related\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 115
                            }
                        ],
                        "text": "The goal of the next set of experiments is to evaluate the impact of the improvements over the original FK work of Perronnin and Dance (2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 75
                            }
                        ],
                        "text": "The first line (no modification applied) corresponds to the baseline FK of Perronnin and Dance (2007). Between parentheses: the absolute improvement with respect to the baseline FK."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 29
                            }
                        ],
                        "text": "over the original FK work of Perronnin and Dance (2007). This includes the use of the power-normalization, the `2normalization, and SPs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12795415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23694b6d61668e62bb11f17c1d75dde3b4951948",
            "isKey": false,
            "numCitedBy": 1613,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Within the field of pattern classification, the Fisher kernel is a powerful framework which combines the strengths of generative and discriminative approaches. The idea is to characterize a signal with a gradient vector derived from a generative probability model and to subsequently feed this representation to a discriminative classifier. We propose to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images. We show that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms. Our approach demonstrates excellent performance on two challenging databases: an in-house database of 19 object/scene categories and the recently released VOC 2006 database. It is also very practical: it has low computational needs both at training and test time and vocabularies trained on one set of categories can be applied to another set without any significant loss in performance."
            },
            "slug": "Fisher-Kernels-on-Visual-Vocabularies-for-Image-Perronnin-Dance",
            "title": {
                "fragments": [],
                "text": "Fisher Kernels on Visual Vocabularies for Image Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms, and proposes to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722052"
                        ],
                        "name": "Thomas Mensink",
                        "slug": "Thomas-Mensink",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Mensink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Mensink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 64
                            }
                        ],
                        "text": "Attempts have been made also to go beyond additive classifiers (Perronnin et al, 2010b, Sreekanth et al, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 251
                            }
                        ],
                        "text": "For instance, as of today, ImageNet1 consists of more than 14M images of 22K concepts (Deng et al, 2009) and Flickr contains thousands of groups2 \u2013 some of which with hundreds of thousands of pictures \u2013 which can be exploited to learn object classifiers (Perronnin et al, 2010c, Wang et al, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 196
                            }
                        ],
                        "text": "For the soft-BoV, we perform a square-rooting of the BoV (which is identical to the power-normalization of the FV) as this leads to large improvements at negligible additional computational cost (Perronnin et al, 2010b, Vedaldi and Zisserman, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "In Perronnin et al (2010c), the `2-normalization is justified as a way to cancel-out the fact that different images contain different amounts of background information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 65
                            }
                        ],
                        "text": "This paper extends our previous work (Perronnin and Dance, 2007, Perronnin et al, 2010c, Sa\u0301nchez and Perronnin,\n2011) with: (1) a more detailed description of the FK framework and especially of the computation of the Fisher information matrix, (2) a more detailed analysis of the recent related\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 196
                            }
                        ],
                        "text": "The square-rooting operation can be viewed as an explicit data representation of the Hellinger or Bhattacharyya kernel, which has also been found effective for BOV image representations, see e.g. Perronnin et al (2010b) or Vedaldi and Zisserman (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 33
                            }
                        ],
                        "text": "Vedaldi and Zisserman (2010) and Perronnin et al (2010b) subsequently generalized this principle to any additive classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) argued that, as the number of Gaussian components of the GMM increases, the FV becomes sparser which negatively impacts the dot-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 35
                            }
                        ],
                        "text": "Another interpretation proposed in Perronnin et al (2010a) is that the power normalization downplays the\ninfluence of descriptors which happen frequently within a given image (bursty visual features) in a manner similar to Je\u0301gou et al (2009)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "In Perronnin et al (2010c), it was proposed to perform a power normalization of the form:\nz\u2190 sign(z)|z|\u03c1 with 0   \u03c1 \u2264 1 (30)\nto each dimension of the FV."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) chose the `2-norm because it is the natural norm associated with the dot-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) proposed to `2-normalize FVs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 52
                            }
                        ],
                        "text": "The improved performance compared to the results in Perronnin et al (2010c), is probably due to denser sampling and a different layout of the spatial pyramids."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 73
                            }
                        ],
                        "text": "The first interpretation is specific to the FV and was first proposed in Perronnin et al (2010c)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "2.3 FV normalization\nWe now describe two normalization steps which were introduced in Perronnin et al (2010c) and which were shown to\nbe necessary to obtain competitive results when the FV is combined with a linear classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "We finally note that the use of the square-root transform is not specific to the FV and is also beneficial to the BoV as shown for instance by Perronnin et al (2010b), Vedaldi and Zisserman (2010), Winn et al (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10402702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39f3b1804b8df5be645a1dcb4a876e128385d9be",
            "isKey": false,
            "numCitedBy": 2662,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The Fisher kernel (FK) is a generic framework which combines the benefits of generative and discriminative approaches. In the context of image classification the FK was shown to extend the popular bag-of-visual-words (BOV) by going beyond count statistics. However, in practice, this enriched representation has not yet shown its superiority over the BOV. In the first part we show that with several well-motivated modifications over the original framework we can boost the accuracy of the FK. On PASCAL VOC 2007 we increase the Average Precision (AP) from 47.9% to 58.3%. Similarly, we demonstrate state-of-the-art accuracy on CalTech 256. A major advantage is that these results are obtained using only SIFT descriptors and costless linear classifiers. Equipped with this representation, we can now explore image classification on a larger scale. In the second part, as an application, we compare two abundant resources of labeled images to learn classifiers: ImageNet and Flickr groups. In an evaluation involving hundreds of thousands of training images we show that classifiers learned on Flickr groups perform surprisingly well (although they were not intended for this purpose) and that they can complement classifiers learned on more carefully annotated datasets."
            },
            "slug": "Improving-the-Fisher-Kernel-for-Large-Scale-Image-Perronnin-S\u00e1nchez",
            "title": {
                "fragments": [],
                "text": "Improving the Fisher Kernel for Large-Scale Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "In an evaluation involving hundreds of thousands of training images, it is shown that classifiers learned on Flickr groups perform surprisingly well and that they can complement classifier learned on more carefully annotated datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144651486"
                        ],
                        "name": "Liefeng Bo",
                        "slug": "Liefeng-Bo",
                        "structuredName": {
                            "firstName": "Liefeng",
                            "lastName": "Bo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liefeng Bo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 155
                            }
                        ],
                        "text": "While efficient approximation exists for the original (poorly performing) MK of equation (38) when there exists an explicit embedding of the kernel k(\u00b7, \u00b7) (Bo and Sminchisescu, 2009), such approximations do not exist for kernels such as the one defined in (Lyu, 2005, Wallraven et al, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Bo and Sminchisescu (2009) make use of the Efficient Match Kernel (EMK) framework which embeds patches in a higher-dimensional space in a non-linear fashion (see also Section 2.5)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa1fa18231b8c6b35a21796af446899fc681a107",
            "isKey": true,
            "numCitedBy": 251,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In visual recognition, the images are frequently modeled as unordered collections of local features (bags). We show that bag-of-words representations commonly used in conjunction with linear classifiers can be viewed as special match kernels, which count 1 if two local features fall into the same regions partitioned by visual words and 0 otherwise. Despite its simplicity, this quantization is too coarse, motivating research into the design of match kernels that more accurately measure the similarity between local features. However, it is impractical to use such kernels for large datasets due to their significant computational cost. To address this problem, we propose efficient match kernels (EMK) that map local features to a low dimensional feature space and average the resulting vectors to form a set-level feature. The local feature maps are learned so their inner products preserve, to the best possible, the values of the specified kernel function. Classifiers based on EMK are linear both in the number of images and in the number of local features. We demonstrate that EMK are extremely efficient and achieve the current state of the art in three difficult computer vision datasets: Scene-15, Caltech-101 and Caltech-256."
            },
            "slug": "Efficient-Match-Kernel-between-Sets-of-Features-for-Bo-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "Efficient Match Kernel between Sets of Features for Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "It is shown that bag-of-words representations commonly used in conjunction with linear classifiers can be viewed as special match kernels, which count 1 if two local features fall into the same regions partitioned by visual words and 0 otherwise."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398811"
                        ],
                        "name": "Yan Liu",
                        "slug": "Yan-Liu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50228329"
                        ],
                        "name": "H. Poirier",
                        "slug": "H.-Poirier",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Poirier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Poirier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 64
                            }
                        ],
                        "text": "Attempts have been made also to go beyond additive classifiers (Perronnin et al, 2010b, Sreekanth et al, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 251
                            }
                        ],
                        "text": "For instance, as of today, ImageNet1 consists of more than 14M images of 22K concepts (Deng et al, 2009) and Flickr contains thousands of groups2 \u2013 some of which with hundreds of thousands of pictures \u2013 which can be exploited to learn object classifiers (Perronnin et al, 2010c, Wang et al, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 196
                            }
                        ],
                        "text": "For the soft-BoV, we perform a square-rooting of the BoV (which is identical to the power-normalization of the FV) as this leads to large improvements at negligible additional computational cost (Perronnin et al, 2010b, Vedaldi and Zisserman, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "In Perronnin et al (2010c), the `2-normalization is justified as a way to cancel-out the fact that different images contain different amounts of background information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 65
                            }
                        ],
                        "text": "This paper extends our previous work (Perronnin and Dance, 2007, Perronnin et al, 2010c, Sa\u0301nchez and Perronnin,\n2011) with: (1) a more detailed description of the FK framework and especially of the computation of the Fisher information matrix, (2) a more detailed analysis of the recent related\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 196
                            }
                        ],
                        "text": "The square-rooting operation can be viewed as an explicit data representation of the Hellinger or Bhattacharyya kernel, which has also been found effective for BOV image representations, see e.g. Perronnin et al (2010b) or Vedaldi and Zisserman (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 33
                            }
                        ],
                        "text": "Vedaldi and Zisserman (2010) and Perronnin et al (2010b) subsequently generalized this principle to any additive classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) argued that, as the number of Gaussian components of the GMM increases, the FV becomes sparser which negatively impacts the dot-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 35
                            }
                        ],
                        "text": "Another interpretation proposed in Perronnin et al (2010a) is that the power normalization downplays the\ninfluence of descriptors which happen frequently within a given image (bursty visual features) in a manner similar to Je\u0301gou et al (2009)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "In Perronnin et al (2010c), it was proposed to perform a power normalization of the form:\nz\u2190 sign(z)|z|\u03c1 with 0   \u03c1 \u2264 1 (30)\nto each dimension of the FV."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) chose the `2-norm because it is the natural norm associated with the dot-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) proposed to `2-normalize FVs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 52
                            }
                        ],
                        "text": "The improved performance compared to the results in Perronnin et al (2010c), is probably due to denser sampling and a different layout of the spatial pyramids."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 73
                            }
                        ],
                        "text": "The first interpretation is specific to the FV and was first proposed in Perronnin et al (2010c)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "2.3 FV normalization\nWe now describe two normalization steps which were introduced in Perronnin et al (2010c) and which were shown to\nbe necessary to obtain competitive results when the FV is combined with a linear classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "We finally note that the use of the square-root transform is not specific to the FV and is also beneficial to the BoV as shown for instance by Perronnin et al (2010b), Vedaldi and Zisserman (2010), Winn et al (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16161770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48257a889a9aa61998ae20fa52b25d90c441f63a",
            "isKey": false,
            "numCitedBy": 763,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of large-scale image search has been traditionally addressed with the bag-of-visual-words (BOV). In this article, we propose to use as an alternative the Fisher kernel framework. We first show why the Fisher representation is well-suited to the retrieval problem: it describes an image by what makes it different from other images. One drawback of the Fisher vector is that it is high-dimensional and, as opposed to the BOV, it is dense. The resulting memory and computational costs do not make Fisher vectors directly amenable to large-scale retrieval. Therefore, we compress Fisher vectors to reduce their memory footprint and speed-up the retrieval. We compare three binarization approaches: a simple approach devised for this representation and two standard compression techniques. We show on two publicly available datasets that compressed Fisher vectors perform very well using as little as a few hundreds of bits per image, and significantly better than a very recent compressed BOV approach."
            },
            "slug": "Large-scale-image-retrieval-with-compressed-Fisher-Perronnin-Liu",
            "title": {
                "fragments": [],
                "text": "Large-scale image retrieval with compressed Fisher vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article shows why the Fisher representation is well-suited to the retrieval problem: it describes an image by what makes it different from other images, and why it should be compressed to reduce their memory footprint and speed-up the retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1939006"
                        ],
                        "name": "R. G. Cinbis",
                        "slug": "R.-G.-Cinbis",
                        "structuredName": {
                            "firstName": "Ramazan",
                            "lastName": "Cinbis",
                            "middleNames": [
                                "Gokberk"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. G. Cinbis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721683"
                        ],
                        "name": "J. Verbeek",
                        "slug": "J.-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verbeek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 574,
                                "start": 13
                            }
                        ],
                        "text": "In contrast, Cinbis et al. (2012) proposed to go beyond this independence assumption by introducing an exchangeable model which ties all local descriptors together by means of latent variables that represent the GMM parameters. It was shown that such a model leads to discounting transformations in the FV similar to the simpler square-root transform, and with a comparable positive impact on performance. We finally note that the use of the square-root transform is not specific to the FV and is also beneficial to the BoV as shown for instance by Perronnin et al. (2010b); Vedaldi and Zisserman (2010); Winn et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 13
                            }
                        ],
                        "text": "In contrast, Cinbis et al. (2012) proposed to go beyond this independence assumption by introducing an exchangeable model which ties all local descriptors together by means of latent variables that represent the GMM parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 13
                            }
                        ],
                        "text": "In contrast, Cinbis et al (2012) proposed to go beyond this independence assumption by introducing an exchangeable model which ties all local descriptors together by means of latent variables that represent the GMM parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16932216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45fa259ad3c2453226093ae72d8a88e2e5ed2252",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The bag-of-words (BoW) model treats images as an unordered set of local regions and represents them by visual word histograms. Implicitly, regions are assumed to be identically and independently distributed (iid), which is a poor assumption from a modeling perspective. We introduce non-iid models by treating the parameters of BoW models as latent variables which are integrated out, rendering all local regions dependent. Using the Fisher kernel we encode an image by the gradient of the data log-likelihood w.r.t. hyper-parameters that control priors on the model parameters. Our representation naturally involves discounting transformations similar to taking square-roots, providing an explanation of why such transformations have proven successful. Using variational inference we extend the basic model to include Gaussian mixtures over local descriptors, and latent topic models to capture the co-occurrence structure of visual words, both improving performance. Our models yield state-of-the-art categorization performance using linear classifiers; without using non-linear transformations such as taking square-roots of features, or using (approximate) explicit embeddings of non-linear kernels."
            },
            "slug": "Image-categorization-using-Fisher-kernels-of-image-Cinbis-Verbeek",
            "title": {
                "fragments": [],
                "text": "Image categorization using Fisher kernels of non-iid image models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces non-iid models by treating the parameters of BoW models as latent variables which are integrated out, rendering all local regions dependent, and extends the basic model to include Gaussian mixtures over local descriptors, and latent topic models to capture the co-occurrence structure of visual words, both improving performance."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Boureau et al (2010), Wang et al (2010), Yang et al (2009b) showed that replacing the average pooling stage in the BoV computation by a max-pooling yielded excellent results."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 131
                            }
                        ],
                        "text": "\u2026based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 90113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498efaa51f5eda731dc6199c3547b9465717fa68",
            "isKey": false,
            "numCitedBy": 1101,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Many successful models for scene or object recognition transform low-level descriptors (such as Gabor filter responses, or SIFT descriptors) into richer representations of intermediate complexity. This process can often be broken down into two steps: (1) a coding step, which performs a pointwise transformation of the descriptors into a representation better adapted to the task, and (2) a pooling step, which summarizes the coded features over larger neighborhoods. Several combinations of coding and pooling schemes have been proposed in the literature. The goal of this paper is threefold. We seek to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules (hard and soft vector quantization, sparse coding) and pooling schemes (by taking the average, or the maximum), which obtains state-of-the-art performance or better on several recognition benchmarks. We show how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding. We provide theoretical and empirical insight into the remarkable performance of max pooling. By teasing apart components shared by modern mid-level feature extractors, our approach aims to facilitate the design of better recognition architectures."
            },
            "slug": "Learning-mid-level-features-for-recognition-Boureau-Bach",
            "title": {
                "fragments": [],
                "text": "Learning mid-level features for recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work seeks to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules and pooling schemes and shows how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398811"
                        ],
                        "name": "Yan Liu",
                        "slug": "Yan-Liu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 64
                            }
                        ],
                        "text": "Attempts have been made also to go beyond additive classifiers (Perronnin et al, 2010b, Sreekanth et al, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 251
                            }
                        ],
                        "text": "For instance, as of today, ImageNet1 consists of more than 14M images of 22K concepts (Deng et al, 2009) and Flickr contains thousands of groups2 \u2013 some of which with hundreds of thousands of pictures \u2013 which can be exploited to learn object classifiers (Perronnin et al, 2010c, Wang et al, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 196
                            }
                        ],
                        "text": "For the soft-BoV, we perform a square-rooting of the BoV (which is identical to the power-normalization of the FV) as this leads to large improvements at negligible additional computational cost (Perronnin et al, 2010b, Vedaldi and Zisserman, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "In Perronnin et al (2010c), the `2-normalization is justified as a way to cancel-out the fact that different images contain different amounts of background information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 65
                            }
                        ],
                        "text": "This paper extends our previous work (Perronnin and Dance, 2007, Perronnin et al, 2010c, Sa\u0301nchez and Perronnin,\n2011) with: (1) a more detailed description of the FK framework and especially of the computation of the Fisher information matrix, (2) a more detailed analysis of the recent related\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 196
                            }
                        ],
                        "text": "The square-rooting operation can be viewed as an explicit data representation of the Hellinger or Bhattacharyya kernel, which has also been found effective for BOV image representations, see e.g. Perronnin et al (2010b) or Vedaldi and Zisserman (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 33
                            }
                        ],
                        "text": "Vedaldi and Zisserman (2010) and Perronnin et al (2010b) subsequently generalized this principle to any additive classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) argued that, as the number of Gaussian components of the GMM increases, the FV becomes sparser which negatively impacts the dot-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 35
                            }
                        ],
                        "text": "Another interpretation proposed in Perronnin et al (2010a) is that the power normalization downplays the\ninfluence of descriptors which happen frequently within a given image (bursty visual features) in a manner similar to Je\u0301gou et al (2009)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "In Perronnin et al (2010c), it was proposed to perform a power normalization of the form:\nz\u2190 sign(z)|z|\u03c1 with 0   \u03c1 \u2264 1 (30)\nto each dimension of the FV."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) chose the `2-norm because it is the natural norm associated with the dot-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al (2010c) proposed to `2-normalize FVs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 52
                            }
                        ],
                        "text": "The improved performance compared to the results in Perronnin et al (2010c), is probably due to denser sampling and a different layout of the spatial pyramids."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 73
                            }
                        ],
                        "text": "The first interpretation is specific to the FV and was first proposed in Perronnin et al (2010c)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "2.3 FV normalization\nWe now describe two normalization steps which were introduced in Perronnin et al (2010c) and which were shown to\nbe necessary to obtain competitive results when the FV is combined with a linear classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "We finally note that the use of the square-root transform is not specific to the FV and is also beneficial to the BoV as shown for instance by Perronnin et al (2010b), Vedaldi and Zisserman (2010), Winn et al (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11943675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b282b22975e7220059616d6b08eb87482926db3",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel machines rely on an implicit mapping of the data such that non-linear classification in the original space corresponds to linear classification in the new space. As kernel machines are difficult to scale to large training sets, it has been proposed to perform an explicit mapping of the data and to learn directly linear classifiers in the new space. In this paper, we consider the problem of learning image categorizers on large image sets (e.g. > 100k images) using bag-of-visual-words (BOV) image representations and Support Vector Machine classifiers. We experiment with three approaches to BOV embedding: 1) kernel PCA (kPCA) [15], 2) a modified kPCA we propose for additive kernels and 3) random projections for shift-invariant kernels [14]. We report experiments on 3 datasets: Cal-tech101, VOC07 and ImageNet. An important conclusion is that simply square-rooting BOV vectors \u2013 which corresponds to an exact mapping for the Bhattacharyya kernel \u2013 already leads to large improvements, often quite close to the best results obtained with additive kernels. Another conclusion is that, although it is possible to go beyond additive kernels, the embedding comes at a much higher cost."
            },
            "slug": "Large-scale-image-categorization-with-explicit-data-Perronnin-S\u00e1nchez",
            "title": {
                "fragments": [],
                "text": "Large-scale image categorization with explicit data embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper considers the problem of learning image categorizers on large image sets (e.g. > 100k images) using bag-of-visual-words (BOV) image representations and Support Vector Machine classifiers and experiments with three approaches to BOV embedding."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7245737"
                        ],
                        "name": "Nicolas Le Roux",
                        "slug": "Nicolas-Le-Roux",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Le Roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Le Roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 89
                            }
                        ],
                        "text": "Wang et al (2010), Yang et al (2009b) considered different variants of sparse coding and Boureau et al (2011), Feng et al (2011) different spatial pooling strategies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15377387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9791f1e47a48fa05387cb8dd93da53bf8f43c1f4",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Invariant representations in object recognition systems are generally obtained by pooling feature vectors over spatially local neighborhoods. But pooling is not local in the feature vector space, so that widely dissimilar features may be pooled together if they are in nearby locations. Recent approaches rely on sophisticated encoding methods and more specialized codebooks (or dictionaries), e.g., learned on subsets of descriptors which are close in feature space, to circumvent this problem. In this work, we argue that a common trait found in much recent work in image recognition or retrieval is that it leverages locality in feature space on top of purely spatial locality. We propose to apply this idea in its simplest form to an object recognition system based on the spatial pyramid framework, to increase the performance of small dictionaries with very little added engineering. State-of-the-art results on several object recognition benchmarks show the promise of this approach."
            },
            "slug": "Ask-the-locals:-Multi-way-local-pooling-for-image-Boureau-Roux",
            "title": {
                "fragments": [],
                "text": "Ask the locals: Multi-way local pooling for image recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work argues that a common trait found in much recent work in image recognition or retrieval is that it leverages locality in feature space on top of purely spatial locality, and proposes to apply this idea in its simplest form to an object recognition system based on the spatial pyramid framework to increase the performance of small dictionaries with very little added engineering."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46574912"
                        ],
                        "name": "Naveen Kulkarni",
                        "slug": "Naveen-Kulkarni",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Kulkarni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Kulkarni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913552"
                        ],
                        "name": "Baoxin Li",
                        "slug": "Baoxin-Li",
                        "structuredName": {
                            "firstName": "Baoxin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baoxin Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Kulkarni and Li (2011) extracts on the order of a million patches per image by computing SIFT descriptors from several affine transforms of the original image and uses sparse coding in combination with Adaboost."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5230283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b29fd4acc2358010c6e6e59885357c023f03e5d",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Images in general are captured under a diverse set of conditions. An image of the same object can be captured with varied poses, illuminations, scales, backgrounds and probably different camera parameters. The task of image classification then lies in forming features of the input images in a representational space where classifiers can be better supported in spite of the above variations. Existing methods have mostly focused on obtaining features which are invariant to scale and translation, and thus they generally suffer from performance degradation on datasets which consist of images with varied poses or camera orientations. In this paper we present a new framework for image classification, which is built upon a novel way of feature extraction that generates largely affine-invariant features called affine sparse codes. This is achieved through learning a compact dictionary of features from affine-transformed input images. Analysis and experiments indicate that this novel feature is highly discriminative in addition to being largely affine-invariant. A classifier using AdaBoost is then designed using the affine sparse codes as the input. Extensive experiments with standard databases demonstrate that the proposed approach can obtain the state-of-the-art results, outperforming existing leading approaches in the literature."
            },
            "slug": "Discriminative-affine-sparse-codes-for-image-Kulkarni-Li",
            "title": {
                "fragments": [],
                "text": "Discriminative affine sparse codes for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a new framework for image classification, which is built upon a novel way of feature extraction that generates largely affine-invariant features called affine sparse codes through learning a compact dictionary of features from affin-transformed input images."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144565371"
                        ],
                        "name": "P. P\u00e9rez",
                        "slug": "P.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 25
                            }
                        ],
                        "text": "The VLAD was proposed in Je\u0301gou et al (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1912782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "400e09ceca374f0621335f84a4daf2049d5902be",
            "isKey": false,
            "numCitedBy": 2305,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of image search on a very large scale, where three constraints have to be considered jointly: the accuracy of the search, its efficiency, and the memory usage of the representation. We first propose a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation. We then show how to jointly optimize the dimension reduction and the indexing algorithm, so that it best preserves the quality of vector comparison. The evaluation shows that our approach significantly outperforms the state of the art: the search accuracy is comparable to the bag-of-features approach for an image representation that fits in 20 bytes. Searching a 10 million image dataset takes about 50ms."
            },
            "slug": "Aggregating-local-descriptors-into-a-compact-image-J\u00e9gou-Douze",
            "title": {
                "fragments": [],
                "text": "Aggregating local descriptors into a compact image representation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation, and shows how to jointly optimize the dimension reduction and the indexing algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109615009"
                        ],
                        "name": "Xi Zhou",
                        "slug": "Xi-Zhou",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49104973"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 176
                            }
                        ],
                        "text": "We see in Figure 4 that there is an increase in performance from 0-order (BoV) to the combination of 0-order and 1st-order statistics (similar to the statistics used in the SV(Zhou et al, 2010)), and even further when the 1st-order and 2nd-order statistics are combined."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 23
                            }
                        ],
                        "text": "The SV was proposed in Zhou et al (2010) and consists in concatenating in a weighted fashion a BoV and a VLAD (see equation (2) in their paper)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Zhou et al (2010) reports 64.0% with SV representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "4 that there is an increase in performance from zero-order (BoV) to the combination of zero-order and first-order statistics (similar to the statistics used in the SV (Zhou et al. 2010)), and even further when the first-order and second-order statistics are"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7405065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e65c9f0a64b6a4333b12e2adc3861ad75aca83b",
            "isKey": true,
            "numCitedBy": 555,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new framework for image classification using local visual descriptors. The pipeline first performs a non-linear feature transformation on descriptors, then aggregates the results together to form image-level representations, and finally applies a classification model. For all the three steps we suggest novel solutions which make our approach appealing in theory, more scalable in computation, and transparent in classification. Our experiments demonstrate that the proposed classification method achieves state-of-the-art accuracy on the well-known PASCAL benchmarks."
            },
            "slug": "Image-Classification-Using-Super-Vector-Coding-of-Zhou-Yu",
            "title": {
                "fragments": [],
                "text": "Image Classification Using Super-Vector Coding of Local Image Descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper introduces a new framework for image classification using local visual descriptors that first performs a non-linear feature transformation on descriptors, then aggregates the results together to form image-level representations, and finally applies a classification model."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2875887"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3502855"
                        ],
                        "name": "Marcin Marszalek",
                        "slug": "Marcin-Marszalek",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Marszalek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcin Marszalek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 337,
                                "start": 292
                            }
                        ],
                        "text": "The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 269
                            }
                        ],
                        "text": "\u2026used a similar paradigm: many types of lowlevel local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and nonlinear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al, 2010, Zhang et al, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1486613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dee20a7ce7745fc367c8bc7ede4f7b8c22efa52d",
            "isKey": false,
            "numCitedBy": 2175,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, methods based on local image features have shown promise for texture and object recognition tasks. This paper presents a large-scale evaluation of an approach that represents images as distributions (signatures or histograms) of features extracted from a sparse set of keypoint locations and learns a Support Vector Machine classifier with kernels based on two effective measures for comparing distributions, the Earth Mover\u2019s Distance and the \u03c72 distance. We first evaluate the performance of our approach with different keypoint detectors and descriptors, as well as different kernels and classifiers. We then conduct a comparative evaluation with several state-of-the-art recognition methods on four texture and five object databases. On most of these databases, our implementation exceeds the best reported results and achieves comparable performance on the rest. Finally, we investigate the influence of background correlations on recognition performance via extensive tests on the PASCAL database, for which ground-truth object localization information is available. Our experiments demonstrate that image representations based on distributions of local features are surprisingly effective for classification of texture and object images under challenging real-world conditions, including significant intra-class variations and substantial background clutter."
            },
            "slug": "Local-Features-and-Kernels-for-Classification-of-A-Zhang-Marszalek",
            "title": {
                "fragments": [],
                "text": "Local Features and Kernels for Classification of Texture and Object Categories: A Comprehensive Study"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A large-scale evaluation of an approach that represents images as distributions of features extracted from a sparse set of keypoint locations and learns a Support Vector Machine classifier with kernels based on two effective measures for comparing distributions, the Earth Mover\u2019s Distance and the \u03c72 distance."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2723374"
                        ],
                        "name": "Junzhou Chen",
                        "slug": "Junzhou-Chen",
                        "structuredName": {
                            "firstName": "Junzhou",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junzhou Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1930238"
                        ],
                        "name": "Qing Li",
                        "slug": "Qing-Li",
                        "structuredName": {
                            "firstName": "Qing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143740449"
                        ],
                        "name": "Qiang Peng",
                        "slug": "Qiang-Peng",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144893100"
                        ],
                        "name": "K. Wong",
                        "slug": "K.-Wong",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Wong",
                            "middleNames": [
                                "Hong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Wong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 137
                            }
                        ],
                        "text": "\u20262 http://www.flickr.com/groups\ntechniques based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the use of spatial pyramids to take into account\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 205
                            }
                        ],
                        "text": "In the computer vision literature, a GMM which models the generation process of local descriptors in any image has been referred to as a universal (probabilistic) visual vocabulary (Perronnin et al, 2006, Winn et al, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 198
                            }
                        ],
                        "text": "We finally note that the use of the square-root transform is not specific to the FV and is also beneficial to the BoV as shown for instance by Perronnin et al (2010b), Vedaldi and Zisserman (2010), Winn et al (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 93
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005), the average number of assignments to Gaussian k can be computed as:\n1 T\nT\n\u2211 t=1 \u03b3t(k) = S0k T ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8896696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c97b8d8cd1412a4d34bf3bac8d641a843e69e9c4",
            "isKey": true,
            "numCitedBy": 24,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In the past decade, SIFT descriptor has been witnessed as one of the most robust local invariant feature descriptors and widely used in various vision tasks. Most traditional image-classification systems depend on the gray-based SIFT descriptors, which only analyze the gray level variations of the images. Misclassification may happen since their color contents are ignored. In this article, we concentrate on improving the performance of existing image-classification algorithms by adding color information. To achieve this purpose, different kinds of colored SIFT descriptors are introduced and implemented. locality-constrained linear coding (LLC), a state-of-the-art sparse coding technology, is employed to construct the image-classification system for the evaluation. Moreover, we propose a simple $$\\ell _2$$\u21132-norm regularized local distance to improve the traditional LLC method. The real experiments are carried out on several benchmarks. With the enhancements to color SIFT and $$\\ell _2$$\u21132-norm regularization, the proposed image-classification system obtains approximately $$2\\,\\%$$2% improvement of classification accuracy on the Caltech-101 dataset and approximately $$5\\,\\%$$5% improvement of classification accuracy on the Caltech-256 dataset."
            },
            "slug": "CSIFT-based-locality-constrained-linear-coding-for-Chen-Li",
            "title": {
                "fragments": [],
                "text": "CSIFT based locality-constrained linear coding for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article proposes a simple $$\\ell _2$$\u21132-norm regularized local distance to improve the traditional LLC method and introduces different kinds of colored SIFT descriptors, which obtains approximately 2% improvement of classification accuracy on the Caltech-101 dataset and approximately 5% improvement on theCaltech-256 dataset."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Applications"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995443"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144565371"
                        ],
                        "name": "P. P\u00e9rez",
                        "slug": "P.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 44
                            }
                        ],
                        "text": "A more formal justification was provided in Je\u0301gou et al (2012) as it was shown that FVs can be viewed as emissions of a compound distribution whose variance depends on the mean."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 16
                            }
                        ],
                        "text": "As mentioned in Je\u0301gou et al (2012), the same normalization steps which were introduced for the FV \u2013 the square-root and `2-normalization \u2013 can also be applied to the VLAD with significant improvements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 16
                            }
                        ],
                        "text": "It was shown in Je\u0301gou et al (2012) that the square-rooting had such a stabilization effect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 16
                            }
                        ],
                        "text": "It was shown in Je\u0301gou et al (2012) that the VLAD is a simplified version of the FV under the following approximations: 1) the soft assignment is replaced by a hard assignment and 2) only the gradient with respect to the mean is considered."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9437674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5183230b706b72f6f6c19415c423d93c79ddde53",
            "isKey": false,
            "numCitedBy": 1431,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of large-scale image search. Three constraints have to be taken into account: search accuracy, efficiency, and memory usage. We first present and evaluate different ways of aggregating local image descriptors into a vector and show that the Fisher kernel achieves better performance than the reference bag-of-visual words approach for any given vector dimension. We then jointly optimize dimensionality reduction and indexing in order to obtain a precise vector comparison as well as a compact representation. The evaluation shows that the image representation can be reduced to a few dozen bytes while preserving high accuracy. Searching a 100 million image data set takes about 250 ms on one processor core."
            },
            "slug": "Aggregating-Local-Image-Descriptors-into-Compact-J\u00e9gou-Perronnin",
            "title": {
                "fragments": [],
                "text": "Aggregating Local Image Descriptors into Compact Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper first presents and evaluates different ways of aggregating local image descriptors into a vector and shows that the Fisher kernel achieves better performance than the reference bag-of-visual words approach for any given vector dimension."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 137
                            }
                        ],
                        "text": "\u20262 http://www.flickr.com/groups\ntechniques based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the use of spatial pyramids to take into account\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 205
                            }
                        ],
                        "text": "In the computer vision literature, a GMM which models the generation process of local descriptors in any image has been referred to as a universal (probabilistic) visual vocabulary (Perronnin et al, 2006, Winn et al, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 198
                            }
                        ],
                        "text": "We finally note that the use of the square-root transform is not specific to the FV and is also beneficial to the BoV as shown for instance by Perronnin et al (2010b), Vedaldi and Zisserman (2010), Winn et al (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 93
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005), the average number of assignments to Gaussian k can be computed as:\n1 T\nT\n\u2211 t=1 \u03b3t(k) = S0k T ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5893207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03a073589eaf8ce3440464d020e0d0b26df5869b",
            "isKey": true,
            "numCitedBy": 997,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new algorithm for the automatic recognition of object classes from images (categorization). Compact and yet discriminative appearance-based object class models are automatically learned from a set of training images. The method is simple and extremely fast, making it suitable for many applications such as semantic image retrieval, Web search, and interactive image editing. It classifies a region according to the proportions of different visual words (clusters in feature space). The specific visual words and the typical proportions in each object are learned from a segmented training set. The main contribution of this paper is twofold: i) an optimally compact visual dictionary is learned by pair-wise merging of visual words from an initially large dictionary. The final visual words are described by GMMs. ii) A novel statistical measure of discrimination is proposed which is optimized by each merge operation. High classification accuracy is demonstrated for nine object classes on photographs of real objects viewed under general lighting conditions, poses and viewpoints. The set of test images used for validation comprise: i) photographs acquired by us, ii) images from the Web and iii) images from the recently released Pascal dataset. The proposed algorithm performs well on both texture-rich objects (e.g. grass, sky, trees) and structure-rich ones (e.g. cars, bikes, planes)"
            },
            "slug": "Object-categorization-by-learned-universal-visual-Winn-Criminisi",
            "title": {
                "fragments": [],
                "text": "Object categorization by learned universal visual dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An optimally compact visual dictionary is learned by pair-wise merging of visual words from an initially large dictionary, and a novel statistical measure of discrimination is proposed which is optimized by each merge operation."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706007"
                        ],
                        "name": "Jianchao Yang",
                        "slug": "Jianchao-Yang",
                        "structuredName": {
                            "firstName": "Jianchao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianchao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108863279"
                        ],
                        "name": "Thomas Huang",
                        "slug": "Thomas-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 440212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c9633aedafe4ee8cf238fa06c40b84f47e17362",
            "isKey": false,
            "numCitedBy": 1468,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently SVMs using spatial pyramid matching (SPM) kernel have been highly successful in image classification. Despite its popularity, these nonlinear SVMs have a complexity O(n2 ~ n3) in training and O(n) in testing, where n is the training size, implying that it is nontrivial to scaleup the algorithms to handle more than thousands of training images. In this paper we develop an extension of the SPM method, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and propose a linear SPM kernel based on SIFT sparse codes. This new approach remarkably reduces the complexity of SVMs to O(n) in training and a constant in testing. In a number of image categorization experiments, we find that, in terms of classification accuracy, the suggested linear SPM based on sparse coding of SIFT descriptors always significantly outperforms the linear SPM kernel on histograms, and is even better than the nonlinear SPM kernels, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors."
            },
            "slug": "Linear-spatial-pyramid-matching-using-sparse-coding-Yang-Yu",
            "title": {
                "fragments": [],
                "text": "Linear spatial pyramid matching using sparse coding for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An extension of the SPM method is developed, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and a linear SPM kernel based on SIFT sparse codes is proposed, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764761"
                        ],
                        "name": "K. Chatfield",
                        "slug": "K.-Chatfield",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Chatfield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chatfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13126996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b7908f71188b89adf62ce9126a0466e1a34338f",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A large number of novel encodings for bag of visual words models have been proposed in the past two years to improve on the standard histogram of quantized local features. Examples include locality-constrained linear encoding [23], improved Fisher encoding [17], super vector encoding [27], and kernel codebook encoding [20]. While several authors have reported very good results on the challenging PASCAL VOC classification data by means of these new techniques, differences in the feature computation and learning algorithms, missing details in the description of the methods, and different tuning of the various components, make it impossible to compare directly these methods and hard to reproduce the results reported. This paper addresses these shortcomings by carrying out a rigorous evaluation of these new techniques by: (1) fixing the other elements of the pipeline (features, learning, tuning); (2) disclosing all the implementation details, and (3) identifying both those aspects of each method which are particularly important to achieve good performance, and those aspects which are less critical. This allows a consistent comparative analysis of these encoding methods. Several conclusions drawn from our analysis cannot be inferred from the original publications."
            },
            "slug": "The-devil-is-in-the-details:-an-evaluation-of-Chatfield-Lempitsky",
            "title": {
                "fragments": [],
                "text": "The devil is in the details: an evaluation of recent feature encoding methods"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A rigorous evaluation of novel encodings for bag of visual words models by identifying both those aspects of each method which are particularly important to achieve good performance, and those aspects which are less critical, which allows a consistent comparative analysis of these encoding methods."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722052"
                        ],
                        "name": "Thomas Mensink",
                        "slug": "Thomas-Mensink",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Mensink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Mensink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721683"
                        ],
                        "name": "J. Verbeek",
                        "slug": "J.-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verbeek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Mensink et al. (2012). However, this is outside the scope of the current paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 84
                            }
                        ],
                        "text": "In such a case, it can be beneficial to employ metric learning techniques, see e.g. Mensink et al (2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 1
                            }
                        ],
                        "text": "(Mensink et al, 2012) obtained 13.9% using the same features and PQ compression as we used in this paper, but with a nearest mean classifier which only requires a fraction of the training time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9296691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a4a53fe47036ac89dad070ab87a9d8795b139b1",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We are interested in large-scale image classification and especially in the setting where images corresponding to new or existing classes are continuously added to the training set. Our goal is to devise classifiers which can incorporate such images and classes on-the-fly at (near) zero cost. We cast this problem into one of learning a metric which is shared across all classes and explore k-nearest neighbor (k-NN) and nearest class mean (NCM) classifiers. We learn metrics on the ImageNet 2010 challenge data set, which contains more than 1.2M training images of 1K classes. Surprisingly, the NCM classifier compares favorably to the more flexible k-NN classifier, and has comparable performance to linear SVMs. We also study the generalization performance, among others by using the learned metric on the ImageNet-10K dataset, and we obtain competitive performance. Finally, we explore zero-shot classification, and show how the zero-shot model can be combined very effectively with small training datasets."
            },
            "slug": "Metric-Learning-for-Large-Scale-Image-Generalizing-Mensink-Verbeek",
            "title": {
                "fragments": [],
                "text": "Metric Learning for Large Scale Image Classification: Generalizing to New Classes at Near-Zero Cost"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The goal is to devise classifiers which can incorporate images and classes on-the-fly at (near) zero cost and to explore k-nearest neighbor (k-NN) and nearest class mean (NCM) classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738975"
                        ],
                        "name": "J. V. Gemert",
                        "slug": "J.-V.-Gemert",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Gemert",
                            "middleNames": [
                                "C.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Gemert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696916"
                        ],
                        "name": "C. Veenman",
                        "slug": "C.-Veenman",
                        "structuredName": {
                            "firstName": "Cor",
                            "lastName": "Veenman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Veenman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720149"
                        ],
                        "name": "J. Geusebroek",
                        "slug": "J.-Geusebroek",
                        "structuredName": {
                            "firstName": "Jan-Mark",
                            "lastName": "Geusebroek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Geusebroek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 193
                            }
                        ],
                        "text": "Several systems are based on the combination of multiple channels corresponding to many different features including (Bergamo and Torresani, 2012, Boiman et al, 2008, Gehler and Nowozin, 2009, VanGemert et al, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 132
                            }
                        ],
                        "text": "There have been several extensions of this popular framework including the use of better coding techniques based on soft assignment (Farquhar et al. 2005; Perronnin et al. 2006; VanGemert et al. 2010; Winn et al. 2005) or sparse coding (Boureau et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "\u2026coding\n1 http://www.image-net.org 2 http://www.flickr.com/groups\ntechniques based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the use of spatial pyramids\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 24
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al. 2005; Perronnin et al. 2006; VanGemert et al. 2010; Winn et al. 2005), the average number of assignments to Gaussian k can be computed as:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 70
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005), the average number of assignments to Gaussian k can be computed as:\n1 T\nT\n\u2211 t=1 \u03b3t(k) = S0k T ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 14
                            }
                        ],
                        "text": "For instance, VanGemert et al (2010) reports 60.5% with a soft-BoV representation and several color descriptors and Yang et al (2009a) reports 62.2% using a group sensitive form of Multiple Kernel Learning (MKL)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 856319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8889bb01d0752f989077362d75e9338f9cad2ad5",
            "isKey": true,
            "numCitedBy": 829,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies automatic image classification by modeling soft assignment in the popular codebook model. The codebook model describes an image as a bag of discrete visual words selected from a vocabulary, where the frequency distributions of visual words in an image allow classification. One inherent component of the codebook model is the assignment of discrete visual words to continuous image features. Despite the clear mismatch of this hard assignment with the nature of continuous features, the approach has been successfully applied for some years. In this paper, we investigate four types of soft assignment of visual words to image features. We demonstrate that explicitly modeling visual word assignment ambiguity improves classification performance compared to the hard assignment of the traditional codebook model. The traditional codebook model is compared against our method for five well-known data sets: 15 natural scenes, Caltech-101, Caltech-256, and Pascal VOC 2007/2008. We demonstrate that large codebook vocabulary sizes completely deteriorate the performance of the traditional model, whereas the proposed model performs consistently. Moreover, we show that our method profits in high-dimensional feature spaces and reaps higher benefits when increasing the number of image categories."
            },
            "slug": "Visual-Word-Ambiguity-Gemert-Veenman",
            "title": {
                "fragments": [],
                "text": "Visual Word Ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated that explicitly modeling visual word assignment ambiguity improves classification performance compared to the hard assignment of the traditional codebook model, and the proposed model performs consistently."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145041406"
                        ],
                        "name": "A. Bergamo",
                        "slug": "A.-Bergamo",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Bergamo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bergamo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732879"
                        ],
                        "name": "L. Torresani",
                        "slug": "L.-Torresani",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Torresani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torresani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14586670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3066535461ea7c8c5a9a902905f6cc65d70456ad",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce a novel image descriptor enabling accurate object categorization even with linear models. Akin to the popular attribute descriptors, our feature vector comprises the outputs of a set of classifiers evaluated on the image. However, unlike traditional attributes which represent hand-selected object classes and predefined visual properties, our features are learned automatically and correspond to \u201cabstract\u201d categories, which we name meta-classes. Each meta-class is a super-category obtained by grouping a set of object classes such that, collectively, they are easy to distinguish from other sets of categories. By using \u201clearnability\u201d of the meta-classes as criterion for feature generation, we obtain a set of attributes that encode general visual properties shared by multiple object classes and that are effective in describing and recognizing even novel categories, i.e., classes not present in the training set. We demonstrate that simple linear SVMs trained on our meta-class descriptor significantly outperform the best known classifier on the Caltech256 benchmark. We also present results on the 2010 ImageNet Challenge database where our system produces results approaching those of the best systems, but at a much lower computational cost."
            },
            "slug": "Meta-class-features-for-large-scale-object-on-a-Bergamo-Torresani",
            "title": {
                "fragments": [],
                "text": "Meta-class features for large-scale object categorization on a budget"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A novel image descriptor enabling accurate object categorization even with linear models and it is demonstrated that simple linear SVMs trained on the authors' meta-class descriptor significantly outperform the best known classifier on the Caltech256 benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737253"
                        ],
                        "name": "M. Guillaumin",
                        "slug": "M.-Guillaumin",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Guillaumin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Guillaumin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721683"
                        ],
                        "name": "J. Verbeek",
                        "slug": "J.-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verbeek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this work, we propose an alternative patch aggregation mechanism based on the Fisher Kernel (FK) principle of Jaakkola and Haussler (1998). The FK combines the benefits of generative and discriminative approaches to pattern classification by deriving a kernel from a generative model of the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 9
                            }
                        ],
                        "text": "Finally, Guillaumin et al (2010) reports 66.7% but assuming that one has access to the image tags."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2754209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0f49caabbf79ffda35432219bb0ec9b41753dff",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In image categorization the goal is to decide if an image belongs to a certain category or not. A binary classifier can be learned from manually labeled images; while using more labeled examples improves performance, obtaining the image labels is a time consuming process. We are interested in how other sources of information can aid the learning process given a fixed amount of labeled images. In particular, we consider a scenario where keywords are associated with the training images, e.g. as found on photo sharing websites. The goal is to learn a classifier for images alone, but we will use the keywords associated with labeled and unlabeled images to improve the classifier using semi-supervised learning. We first learn a strong Multiple Kernel Learning (MKL) classifier using both the image content and keywords, and use it to score unlabeled images. We then learn classifiers on visual features only, either support vector machines (SVM) or least-squares regression (LSR), from the MKL output values on both the labeled and unlabeled images. In our experiments on 20 classes from the PASCAL VOC'07 set and 38 from the MIR Flickr set, we demonstrate the benefit of our semi-supervised approach over only using the labeled images. We also present results for a scenario where we do not use any manual labeling but directly learn classifiers from the image tags. The semi-supervised approach also improves classification accuracy in this case."
            },
            "slug": "Multimodal-semi-supervised-learning-for-image-Guillaumin-Verbeek",
            "title": {
                "fragments": [],
                "text": "Multimodal semi-supervised learning for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work considers a scenario where keywords are associated with the training images, e.g. as found on photo sharing websites, and learns a strong Multiple Kernel Learning (MKL) classifier using both the image content and keywords, and uses it to score unlabeled images."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004454"
                        ],
                        "name": "Josip Krapac",
                        "slug": "Josip-Krapac",
                        "structuredName": {
                            "firstName": "Josip",
                            "lastName": "Krapac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josip Krapac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721683"
                        ],
                        "name": "J. Verbeek",
                        "slug": "J.-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verbeek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 60
                            }
                        ],
                        "text": "Spatial Pyramids The spatial pyramid (SP) was introduced in Lazebnik et al. (2006) to take into account the rough geometry of a scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 80
                            }
                        ],
                        "text": "Gradient Formulas For the weight parameters, we adopt the soft-max formalism of Krapac et al. (2011) and define"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 118
                            }
                        ],
                        "text": "We note that more sophisticated models have been proposed to take into account the scene geometry in the FV framework (Krapac et al. 2011; S\u00e1nchez et al. 2012) but we will not consider such extensions in this work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 119
                            }
                        ],
                        "text": "We note that more sophisticated models have been proposed to take into account the scene geometry in the FV framework (Krapac et al, 2011, Sa\u0301nchez et al, 2012) but we will not consider such extensions in this work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 62
                            }
                        ],
                        "text": "For the weight parameters, we adopt the soft-max formalism of Krapac et al (2011) and define\nwk = exp(\u03b1k)\n\u2211Kj=1 exp(\u03b1 j) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 23
                            }
                        ],
                        "text": "In a very recent work, Krizhevsky et al. (2012) reported significantly better results using a deep learning network."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7051208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f0b4de1c20aa108b30b99e1e231e97d1ca7f9ee",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an extension of bag-of-words image representations to encode spatial layout. Using the Fisher kernel framework we derive a representation that encodes the spatial mean and the variance of image regions associated with visual words. We extend this representation by using a Gaussian mixture model to encode spatial layout, and show that this model is related to a soft-assign version of the spatial pyramid representation. We also combine our representation of spatial layout with the use of Fisher kernels to encode the appearance of local features. Through an extensive experimental evaluation, we show that our representation yields state-of-the-art image categorization results, while being more compact than spatial pyramid representations. In particular, using Fisher kernels to encode both appearance and spatial layout results in an image representation that is computationally efficient, compact, and yields excellent performance while using linear classifiers."
            },
            "slug": "Modeling-spatial-layout-with-fisher-vectors-for-Krapac-Verbeek",
            "title": {
                "fragments": [],
                "text": "Modeling spatial layout with fisher vectors for image categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An extension of bag-of-words image representations to encode spatial layout using the Fisher kernel framework and a Gaussian mixture model is introduced, which yields an image representation that is computationally efficient, compact, and yields excellent performance while using linear classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2871555"
                        ],
                        "name": "P. Gehler",
                        "slug": "P.-Gehler",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Gehler",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gehler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388416"
                        ],
                        "name": "S. Nowozin",
                        "slug": "S.-Nowozin",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Nowozin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowozin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 149
                            }
                        ],
                        "text": "\u2026popular framework including the use of better coding\n1 http://www.image-net.org 2 http://www.flickr.com/groups\ntechniques based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 25
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005), the average number of assignments to Gaussian k can be computed as:\n1 T\nT\n\u2211 t=1 \u03b3t(k) = S0k T ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15536375,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba0548583a5ab3dca551f60e30f85ea42b2a4873",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A key ingredient in the design of visual object classification systems is the identification of relevant class specific aspects while being robust to intra-class variations. While this is a necessity in order to generalize beyond a given set of training images, it is also a very difficult problem due to the high variability of visual appearance within each class. In the last years substantial performance gains on challenging benchmark datasets have been reported in the literature. This progress can be attributed to two developments: the design of highly discriminative and robust image features and the combination of multiple complementary features based on different aspects such as shape, color or texture. In this paper we study several models that aim at learning the correct weighting of different features from training data. These include multiple kernel learning as well as simple baseline methods. Furthermore we derive ensemble methods inspired by Boosting which are easily extendable to several multiclass setting. All methods are thoroughly evaluated on object classification datasets using a multitude of feature descriptors. The key results are that even very simple baseline methods, that are orders of magnitude faster than learning techniques are highly competitive with multiple kernel learning. Furthermore the Boosting type methods are found to produce consistently better results in all experiments. We provide insight of when combination methods can be expected to work and how the benefit of complementary features can be exploited most efficiently."
            },
            "slug": "On-feature-combination-for-multiclass-object-Gehler-Nowozin",
            "title": {
                "fragments": [],
                "text": "On feature combination for multiclass object classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Several models that aim at learning the correct weighting of different features from training data are studied, including multiple kernel learning as well as simple baseline methods and ensemble methods inspired by Boosting are derived."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 603266,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28bd46aff7451166970b46d0639bfddb013a1c7c",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient learning with non-linear kernels is often based on extracting features from the data that \u201clinearise\u201d the kernel. While most constructions aim at obtaining low-dimensional and dense features, in this work we explore high-dimensional and sparse ones. We give a method to compute sparse features for arbitrary kernels, re-deriving as a special case a popular map for the intersection kernel and extending it to arbitrary additive kernels. We show that bundle optimisation methods can handle efficiently these sparse features in learning. As an application, we show that product quantisation can be interpreted as a sparse feature encoding, and use this to significantly accelerate learning with this technique. We demonstrate these ideas on image classification with Fisher kernels and object detection with deformable part models on the challenging PASCAL VOC data, obtaining five to ten-fold speed-ups as well as reducing memory use by an order of magnitude."
            },
            "slug": "Sparse-kernel-approximations-for-efficient-and-Vedaldi-Zisserman",
            "title": {
                "fragments": [],
                "text": "Sparse kernel approximations for efficient classification and detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work gives a method to compute sparse features for arbitrary kernels, re-deriving as a special case a popular map for the intersection kernel and extending it to arbitrary additive kernels, and shows that bundle optimisation methods can handle efficiently these sparse features in learning."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398811"
                        ],
                        "name": "Yan Liu",
                        "slug": "Yan-Liu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 116
                            }
                        ],
                        "text": "Several works proposed to model an image as a GMM adapted\nfrom a universal (i.e. image-independent) distribution u\u03bb (Liu and Perronnin, 2008, Yan et al, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 88
                            }
                        ],
                        "text": "We consider two types of patch descriptors in this work: the 128dim SIFT descriptors of Lowe (2004) and the 96-dim local color statistic (LCS) descriptors of Clinchant et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 35
                            }
                        ],
                        "text": "image-independent) distribution u\u03bb (Liu and Perronnin 2008; Yan et al. 2008)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15635577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b14d94baadbbc1e0960af57119cbc33c7ff26e",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to compute the similarity between two unordered variable-sized vector sets. To solve this problem, several authors have proposed to model each vector set with a Gaussian mixture model (GMM) and to compute a probabilistic measure of similarity between the GMMs. The main contribution of this paper is to model each vector set with a GMM adapted from a common ldquouniversalrdquo GMM using the maximum a posteriori (MAP) criterion. The advantages of this approach are twofold. MAP provides a more accurate estimate of the GMM parameters compared to standard maximum likelihood estimation (MLE) in the challenging case where the cardinality of the vector set is small. Moreover, there is a correspondence between the Gaussians of two GMMs adapted from a common distribution and one can take advantage of this fact to compute efficiently the probabilistic similarity. This work is applied to the image categorization problem: images are modeled as bags of low-level features and classification is performed using a kernel classifier based on the proposed similarity measure. Experimental results on the PASCAL VOC 2006 and VOC 2007 databases show the excellent performance of our approach."
            },
            "slug": "A-similarity-measure-between-unordered-vector-sets-Liu-Perronnin",
            "title": {
                "fragments": [],
                "text": "A similarity measure between unordered vector sets with application to image categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A novel approach to compute the similarity between two unordered variable-sized vector sets using the maximum a posteriori (MAP) criterion, which provides a more accurate estimate of the GMM parameters compared to standard maximum likelihood estimation (MLE) in the challenging case where the cardinality of the vector set is small."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 104
                            }
                        ],
                        "text": "By far, the most popular image representation for classification has been the Bag-of-Visual words (BoV) (Csurka et al. 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 70
                            }
                        ],
                        "text": "First, the FV can be viewed as a generalization of the BoV framework (Csurka et al, 2004, Sivic and Zisserman, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 95
                            }
                        ],
                        "text": "Relationship with the BoV First, the FV can be viewed as a generalization of the BoV framework (Csurka et al. 2004; Sivic and Zisserman 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 105
                            }
                        ],
                        "text": "By far, the most popular image representation for classification has been the Bag-of-Visual words (BoV) (Csurka et al, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17606900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b91180d8853d00e8f2df7ee3532e07d3d0cce2af",
            "isKey": true,
            "numCitedBy": 5008,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "slug": "Visual-categorization-with-bags-of-keypoints-Csurka",
            "title": {
                "fragments": [],
                "text": "Visual categorization with bags of keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches and shows that it is simple, computationally efficient and intrinsically invariant."
            },
            "venue": {
                "fragments": [],
                "text": "eccv 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2893664"
                        ],
                        "name": "Zeynep Akata",
                        "slug": "Zeynep-Akata",
                        "structuredName": {
                            "firstName": "Zeynep",
                            "lastName": "Akata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeynep Akata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753355"
                        ],
                        "name": "Z. Harchaoui",
                        "slug": "Z.-Harchaoui",
                        "structuredName": {
                            "firstName": "Za\u00efd",
                            "lastName": "Harchaoui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harchaoui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 53
                            }
                        ],
                        "text": "To train the one-vs-rest linear SVMs, we also follow Perronnin et al (2012) and subsample the negatives."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 18
                            }
                        ],
                        "text": "As an example, in S\u00e1nchez and Perronnin (2011) we used FV representations with up to 512K dimensions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 128
                            }
                        ],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al. 2012; S\u00e1nchez and Perronnin 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "Using similar features Perronnin et al (2012) improved these results to 19.1% by carefully cross-validating the balance between the positive and negative samples, a good practice we also used in the current work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 129
                            }
                        ],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1312964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e69d4430a8a70b53fe0b71482193262995b6e27b",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a benchmark of several objective functions for large-scale image classification: we compare the one-vs-rest, multiclass, ranking and weighted average ranking SVMs. Using stochastic gradient descent optimization, we can scale the learning to millions of images and thousands of classes. Our experimental evaluation shows that ranking based algorithms do not outperform a one-vs-rest strategy and that the gap between the different algorithms reduces in case of high-dimensional data. We also show that for one-vs-rest, learning through cross-validation the optimal degree of imbalance between the positive and the negative samples can have a significant impact. Furthermore, early stopping can be used as an effective regularization strategy when training with stochastic gradient algorithms. Following these \"good practices\", we were able to improve the state-of-the-art on a large subset of 10K classes and 9M of images of lmageNet from 16.7% accuracy to 19.1%."
            },
            "slug": "Towards-good-practice-in-large-scale-learning-for-Akata-Perronnin",
            "title": {
                "fragments": [],
                "text": "Towards good practice in large-scale learning for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that for one-vs-rest, learning through cross-validation the optimal degree of imbalance between the positive and the negative samples can have a significant impact and early stopping can be used as an effective regularization strategy when training with stochastic gradient algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48173155"
                        ],
                        "name": "Jason D. R. Farquhar",
                        "slug": "Jason-D.-R.-Farquhar",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Farquhar",
                            "middleNames": [
                                "D.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason D. R. Farquhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540580"
                        ],
                        "name": "S. Szedm\u00e1k",
                        "slug": "S.-Szedm\u00e1k",
                        "structuredName": {
                            "firstName": "S\u00e1ndor",
                            "lastName": "Szedm\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Szedm\u00e1k"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37192632"
                        ],
                        "name": "H. Meng",
                        "slug": "H.-Meng",
                        "structuredName": {
                            "firstName": "Hongying",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 149
                            }
                        ],
                        "text": "\u2026popular framework including the use of better coding\n1 http://www.image-net.org 2 http://www.flickr.com/groups\ntechniques based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 25
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005), the average number of assignments to Gaussian k can be computed as:\n1 T\nT\n\u2211 t=1 \u03b3t(k) = S0k T ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 425056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b771f8abc2470c9db421a664c144c9450299113",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose two distinct enhancements to the basic \u201cbag-of-keypoints\u201d image categorisation scheme proposed in [4]. In this approach images are represented as a variable sized set of local image features (keypoints). Thus, we require machine learning tools which can operate on sets of vectors. In [4] this is achieved by representing the set as a histogram over bins found by k-means. We show how this approach can be improved and generalised using Gaussian Mixture Models (GMMs). Alternatively, the set of keypoints can be represented directly as a probability density function, over which a kernel can be defined. This approach is shown to give state of the art categorisation performance."
            },
            "slug": "Improving-\"bag-of-keypoints\"-image-categorisation:-Farquhar-Szedm\u00e1k",
            "title": {
                "fragments": [],
                "text": "Improving \"bag-of-keypoints\" image categorisation: Generative Models and PDF-Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Two distinct enhancements to the basic \u201cbag-of-keypoints\u201d image categorisation scheme are proposed, which can be improved and generalised using Gaussian Mixture Models (GMMs) or represented directly as a probability density function over which a kernel can be defined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "(S\u00e1nchez and Perronnin, 2011) reported slightly better results \u2013 74."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 101
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al (2010), S\u00e1nchez and Perronnin (2011)), Krizhevsky et al (2012), Le et al (2012) report a per-image accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 18
                            }
                        ],
                        "text": "As an example, in Sa\u0301nchez and Perronnin (2011) we used FV representations with up to 512K dimensions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 46
                            }
                        ],
                        "text": "In our experiments, we follow the protocol of Sa\u0301nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 89
                            }
                        ],
                        "text": "This paper extends our previous work (Perronnin and Dance, 2007, Perronnin et al, 2010c, Sa\u0301nchez and Perronnin,\n2011) with: (1) a more detailed description of the FK framework and especially of the computation of the Fisher information matrix, (2) a more detailed analysis of the recent related\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 18
                            }
                        ],
                        "text": "As an example, in S\u00e1nchez and Perronnin (2011) we used FV representations with up to 512K dimensions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 46
                            }
                        ],
                        "text": "In our experiments, we follow the protocol of S\u00e1nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Sa\u0301nchez and Perronnin (2011) reported a 16.7% accuracy using FVs but without color information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 101
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al (2010), Sa\u0301nchez and Perronnin (2011)), Krizhevsky et al (2012), Le et al (2012) report a per-image accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 540,
                                "start": 101
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al (2010), S\u00e1nchez and Perronnin (2011)), Krizhevsky et al (2012), Le et al (2012) report a per-image accuracy. This results in a more optimistic number since those classes which are over-represented in the test data also have more training samples and therefore have (on average) a higher accuracy than those classes which are under-represented. This was clarified through a personal correspondence with the first authors of Krizhevsky et al (2012), Le et al (2012)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 151
                            }
                        ],
                        "text": "We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al, 2010, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 152
                            }
                        ],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 1
                            }
                        ],
                        "text": "(Sa\u0301nchez and Perronnin, 2011) reported slightly better results \u2013 74.5% top-5 accuracy \u2013 using 1Mdim FVs (with more Gaussians and spatial pyramids) but such high-dimensional features are significantly more costly than the 64K-dim features we used in the present paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16199577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eefcc7bcc05436dac9881acb4ff4e4a0b730e175",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We address image classification on a large-scale, i.e. when a large number of images and classes are involved. First, we study classification accuracy as a function of the image signature dimensionality and the training set size. We show experimentally that the larger the training set, the higher the impact of the dimensionality on the accuracy. In other words, high-dimensional signatures are important to obtain state-of-the-art results on large datasets. Second, we tackle the problem of data compression on very large signatures (on the order of 105 dimensions) using two lossy compression strategies: a dimensionality reduction technique known as the hash kernel and an encoding technique based on product quantizers. We explain how the gain in storage can be traded against a loss in accuracy and/or an increase in CPU cost. We report results on two large databases \u2014 ImageNet and a dataset of lM Flickr images \u2014 showing that we can reduce the storage of our signatures by a factor 64 to 128 with little loss in accuracy. Integrating the decompression in the classifier learning yields an efficient and scalable training algorithm. On ILSVRC2010 we report a 74.3% accuracy at top-5, which corresponds to a 2.5% absolute improvement with respect to the state-of-the-art. On a subset of 10K classes of ImageNet we report a top-1 accuracy of 16.7%, a relative improvement of 160% with respect to the state-of-the-art."
            },
            "slug": "High-dimensional-signature-compression-for-image-S\u00e1nchez-Perronnin",
            "title": {
                "fragments": [],
                "text": "High-dimensional signature compression for large-scale image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work reports results on two large databases \u2014 ImageNet and a dataset of lM Flickr images \u2014 showing that it can reduce the storage of the authors' signatures by a factor 64 to 128 with little loss in accuracy and integrating the decompression in the classifier learning yields an efficient and scalable training algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33221685"
                        ],
                        "name": "Jiashi Feng",
                        "slug": "Jiashi-Feng",
                        "structuredName": {
                            "firstName": "Jiashi",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiashi Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5796401"
                        ],
                        "name": "Bingbing Ni",
                        "slug": "Bingbing-Ni",
                        "structuredName": {
                            "firstName": "Bingbing",
                            "lastName": "Ni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bingbing Ni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876831"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5573206,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "d2810567138cb8a17b73de8913013487300d4b89",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern visual classification models generally include a feature pooling step, which aggregates local features over the region of interest into a statistic through a certain spatial pooling operation. Two commonly used operations are the average and max poolings. However, recent theoretical analysis has indicated that neither of these two pooling techniques may be qualified to be optimal. Besides, we further reveal in this work that more severe limitations of these two pooling methods are from the unrecoverable loss of the spatial information during the statistical summarization and the underlying over-simplified assumption about the feature distribution. We aim to address these inherent issues in this work and generalize previous pooling methods as follows. We define a weighted \u2113p-norm spatial pooling function tailored for the class-specific feature spatial distribution. Moreover, a sensible prior for the feature spatial correlation is incorporated. Optimizing such pooling function towards optimal class separability yields a so-called geometric \u2113p-norm pooling (GLP) method. The described GLP method is capable of preserving the class-specific spatial/geometric information in the pooled features and significantly boosts the discriminating capability of the resultant features for image classification. Comprehensive evaluations on several image benchmarks demonstrate that the proposed GLP method can boost the image classification performance with a single type of feature to outperform or be comparable with the state-of-the-arts."
            },
            "slug": "Geometric-\u2113p-norm-feature-pooling-for-image-Feng-Ni",
            "title": {
                "fragments": [],
                "text": "Geometric \u2113p-norm feature pooling for image classification"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71563118"
                        ],
                        "name": "Jinjun Wang",
                        "slug": "Jinjun-Wang",
                        "structuredName": {
                            "firstName": "Jinjun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinjun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706007"
                        ],
                        "name": "Jianchao Yang",
                        "slug": "Jianchao-Yang",
                        "structuredName": {
                            "firstName": "Jianchao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianchao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39157653"
                        ],
                        "name": "Fengjun Lv",
                        "slug": "Fengjun-Lv",
                        "structuredName": {
                            "firstName": "Fengjun",
                            "lastName": "Lv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fengjun Lv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 22
                            }
                        ],
                        "text": "Boureau et al (2010), Wang et al (2010), Yang et al (2009b) showed that replacing the average pooling stage in the BoV computation by a max-pooling yielded excellent results."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Wang et al (2010), Yang et al (2009b) considered different variants of sparse coding and Boureau et al (2011), Feng et al (2011) different spatial pooling strategies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 23
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 146
                            }
                        ],
                        "text": "\u2026on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6718692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f7713dcc35e7c05becf3be5522f36c9546b0364",
            "isKey": true,
            "numCitedBy": 3240,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The traditional SPM approach based on bag-of-features (BoF) requires nonlinear classifiers to achieve good image classification performance. This paper presents a simple but effective coding scheme called Locality-constrained Linear Coding (LLC) in place of the VQ coding in traditional SPM. LLC utilizes the locality constraints to project each descriptor into its local-coordinate system, and the projected coordinates are integrated by max pooling to generate the final representation. With linear classifier, the proposed approach performs remarkably better than the traditional nonlinear SPM, achieving state-of-the-art performance on several benchmarks. Compared with the sparse coding strategy [22], the objective function used by LLC has an analytical solution. In addition, the paper proposes a fast approximated LLC method by first performing a K-nearest-neighbor search and then solving a constrained least square fitting problem, bearing computational complexity of O(M + K2). Hence even with very large codebooks, our system can still process multiple frames per second. This efficiency significantly adds to the practical values of LLC for real applications."
            },
            "slug": "Locality-constrained-Linear-Coding-for-image-Wang-Yang",
            "title": {
                "fragments": [],
                "text": "Locality-constrained Linear Coding for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper presents a simple but effective coding scheme called Locality-constrained Linear Coding (LLC) in place of the VQ coding in traditional SPM, using the locality constraints to project each descriptor into its local-coordinate system, and the projected coordinates are integrated by max pooling to generate the final representation."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39219747"
                        ],
                        "name": "Sreekanth Vempati",
                        "slug": "Sreekanth-Vempati",
                        "structuredName": {
                            "firstName": "Sreekanth",
                            "lastName": "Vempati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sreekanth Vempati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 408394,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5578f3d9e6931c3762b2275f5265113e8f94369a",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel methods yield state-of-the-art performance in certain applications such as image classification and object detection. However, large scale problems require machine learning techniques of at most linear complexity and these are usually limited to linear kernels. This unfortunately rules out gold-standard kernels such as the generalized RBF kernels (e.g. exponential-c 2 ). Recently, Maji and Berg [13] and Vedaldi and Zisserman [20] proposed explicit feature maps to approximate the additive kernels (intersection, c 2 , etc.) by linear ones, thus enabling the use of fast machine learning technique in a non-linear context. An analogous technique was proposed by Rahimi and Recht [14] for the translation invariant RBF kernels. In this paper, we complete the construction and combine the two techniques to obtain explicit feature maps for the generalized RBF kernels. Furthermore, we investigate a learning method using l 1 regularization to encourage sparsity in the final vector representation, and thus reduce its dimension. We evaluate this technique on the VOC 2007 detection challenge, showing when it can improve on fast additive kernels, and the trade-offs in complexity and accuracy."
            },
            "slug": "Generalized-RBF-feature-maps-for-Efficient-Vempati-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Generalized RBF feature maps for Efficient Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper completes the construction and combines the two techniques to obtain explicit feature maps for the generalized RBF kernels, and investigates a learning method using l 1 regularization to encourage sparsity in the final vector representation, and thus reduce its dimension."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47655614"
                        ],
                        "name": "G. Griffin",
                        "slug": "G.-Griffin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Griffin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144160673"
                        ],
                        "name": "Alex Holub",
                        "slug": "Alex-Holub",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Holub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Holub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118828957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a5effa909cdeafaddbbb7855037e02f8e25d632",
            "isKey": false,
            "numCitedBy": 2545,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 [1] was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching [2] algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions."
            },
            "slug": "Caltech-256-Object-Category-Dataset-Griffin-Holub",
            "title": {
                "fragments": [],
                "text": "Caltech-256 Object Category Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A challenging set of 256 object categories containing a total of 30607 images is introduced and the clutter category is used to train an interest detector which rejects uninformative background regions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756979"
                        ],
                        "name": "K. V. D. Sande",
                        "slug": "K.-V.-D.-Sande",
                        "structuredName": {
                            "firstName": "Koen",
                            "lastName": "Sande",
                            "middleNames": [
                                "E.",
                                "A.",
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. V. D. Sande"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145404204"
                        ],
                        "name": "Cees G. M. Snoek",
                        "slug": "Cees-G.-M.-Snoek",
                        "structuredName": {
                            "firstName": "Cees",
                            "lastName": "Snoek",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cees G. M. Snoek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 243
                            }
                        ],
                        "text": "\u2026used a similar paradigm: many types of lowlevel local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and nonlinear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al, 2010, Zhang et al, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 828465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1aa5a8ad5b7031ba39e1dc0537484694364a1312",
            "isKey": false,
            "numCitedBy": 2099,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Image category recognition is important to access visual information on the level of objects and scene types. So far, intensity-based descriptors have been widely used for feature extraction at salient points. To increase illumination invariance and discriminative power, color descriptors have been proposed. Because many different descriptors exist, a structured overview is required of color invariant descriptors in the context of image category recognition. Therefore, this paper studies the invariance properties and the distinctiveness of color descriptors (software to compute the color descriptors from this paper is available from http://www.colordescriptors.com) in a structured way. The analytical invariance properties of color descriptors are explored, using a taxonomy based on invariance properties with respect to photometric transformations, and tested experimentally using a data set with known illumination conditions. In addition, the distinctiveness of color descriptors is assessed experimentally using two benchmarks, one from the image domain and one from the video domain. From the theoretical and experimental results, it can be derived that invariance to light intensity changes and light color changes affects category recognition. The results further reveal that, for light intensity shifts, the usefulness of invariance is category-specific. Overall, when choosing a single descriptor and no prior knowledge about the data set and object and scene categories is available, the OpponentSIFT is recommended. Furthermore, a combined set of color descriptors outperforms intensity-based SIFT and improves category recognition by 8 percent on the PASCAL VOC 2007 and by 7 percent on the Mediamill Challenge."
            },
            "slug": "Evaluating-Color-Descriptors-for-Object-and-Scene-Sande-Gevers",
            "title": {
                "fragments": [],
                "text": "Evaluating Color Descriptors for Object and Scene Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "From the theoretical and experimental results, it can be derived that invariance to light intensity changes and light color changes affects category recognition and the usefulness of invariance is category-specific."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119916460"
                        ],
                        "name": "Yuanqing Lin",
                        "slug": "Yuanqing-Lin",
                        "structuredName": {
                            "firstName": "Yuanqing",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuanqing Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39157653"
                        ],
                        "name": "Fengjun Lv",
                        "slug": "Fengjun-Lv",
                        "structuredName": {
                            "firstName": "Fengjun",
                            "lastName": "Lv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fengjun Lv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682028"
                        ],
                        "name": "Shenghuo Zhu",
                        "slug": "Shenghuo-Zhu",
                        "structuredName": {
                            "firstName": "Shenghuo",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shenghuo Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41216159"
                        ],
                        "name": "Ming Yang",
                        "slug": "Ming-Yang",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807482"
                        ],
                        "name": "Timoth\u00e9e Cour",
                        "slug": "Timoth\u00e9e-Cour",
                        "structuredName": {
                            "firstName": "Timoth\u00e9e",
                            "lastName": "Cour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timoth\u00e9e Cour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48749954"
                        ],
                        "name": "Liangliang Cao",
                        "slug": "Liangliang-Cao",
                        "structuredName": {
                            "firstName": "Liangliang",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangliang Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 145
                            }
                        ],
                        "text": "This is to be compared with the winning NEC-UIUC-Rutgers system which obtained 71.8% accuracy during the challenge (Berg et al, 2010), see also (Lin et al, 2011)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1346314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54d48a42a34f368240b79e7c98c7d9283f79b350",
            "isKey": true,
            "numCitedBy": 412,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Most research efforts on image classification so far have been focused on medium-scale datasets, which are often defined as datasets that can fit into the memory of a desktop (typically 4G\u223c48G). There are two main reasons for the limited effort on large-scale image classification. First, until the emergence of ImageNet dataset, there was almost no publicly available large-scale benchmark data for image classification. This is mostly because class labels are expensive to obtain. Second, large-scale classification is hard because it poses more challenges than its medium-scale counterparts. A key challenge is how to achieve efficiency in both feature extraction and classifier training without compromising performance. This paper is to show how we address this challenge using ImageNet dataset as an example. For feature extraction, we develop a Hadoop scheme that performs feature extraction in parallel using hundreds of mappers. This allows us to extract fairly sophisticated features (with dimensions being hundreds of thousands) on 1.2 million images within one day. For SVM training, we develop a parallel averaging stochastic gradient descent (ASGD) algorithm for training one-against-all 1000-class SVM classifiers. The ASGD algorithm is capable of dealing with terabytes of training data and converges very fast\u2013typically 5 epochs are sufficient. As a result, we achieve state-of-the-art performance on the ImageNet 1000-class classification, i.e., 52.9% in classification accuracy and 71.8% in top 5 hit rate."
            },
            "slug": "Large-scale-image-classification:-Fast-feature-and-Lin-Lv",
            "title": {
                "fragments": [],
                "text": "Large-scale image classification: Fast feature extraction and SVM training"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A parallel averaging stochastic gradient descent (ASGD) algorithm for training one-against-all 1000-class SVM classifiers and a Hadoop scheme that performs feature extraction in parallel using hundreds of mappers, which achieves state-of-the-art performance on the ImageNet 1000- class classification."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1910299"
                        ],
                        "name": "Oren Boiman",
                        "slug": "Oren-Boiman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Boiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Boiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177801"
                        ],
                        "name": "E. Shechtman",
                        "slug": "E.-Shechtman",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Shechtman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shechtman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144611617"
                        ],
                        "name": "M. Irani",
                        "slug": "M.-Irani",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Irani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 147
                            }
                        ],
                        "text": "Several systems are based on the combination of multiple channels corresponding to many different features including (Bergamo and Torresani, 2012, Boiman et al, 2008, Gehler and Nowozin, 2009, VanGemert et al, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 84
                            }
                        ],
                        "text": "Second, the descriptor quantization is a lossy process as underlined in the work of Boiman et al (2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 74543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ae4d5ec354f2a54b5cd70395cb12283390d0638",
            "isKey": false,
            "numCitedBy": 1205,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art image classification methods require an intensive learning/training stage (using SVM, Boosting, etc.) In contrast, non-parametric nearest-neighbor (NN) based image classifiers require no training time and have other favorable properties. However, the large performance gap between these two families of approaches rendered NN-based image classifiers useless. We claim that the effectiveness of non-parametric NN-based image classification has been considerably undervalued. We argue that two practices commonly used in image classification methods, have led to the inferior performance of NN-based image classifiers: (i) Quantization of local image descriptors (used to generate \"bags-of-words \", codebooks). (ii) Computation of 'image-to-image' distance, instead of 'image-to-class' distance. We propose a trivial NN-based classifier - NBNN, (Naive-Bayes nearest-neighbor), which employs NN- distances in the space of the local image descriptors (and not in the space of images). NBNN computes direct 'image- to-class' distances without descriptor quantization. We further show that under the Naive-Bayes assumption, the theoretically optimal image classifier can be accurately approximated by NBNN. Although NBNN is extremely simple, efficient, and requires no learning/training phase, its performance ranks among the top leading learning-based image classifiers. Empirical comparisons are shown on several challenging databases (Caltech-101 ,Caltech-256 and Graz-01)."
            },
            "slug": "In-defense-of-Nearest-Neighbor-based-image-Boiman-Shechtman",
            "title": {
                "fragments": [],
                "text": "In defense of Nearest-Neighbor based image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is argued that two practices commonly used in image classification methods, have led to the inferior performance of NN-based image classifiers: Quantization of local image descriptors (used to generate \"bags-of-words \", codebooks) and Computation of 'image-to-image' distance, instead of ' image- to-class' distance."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 16
                            }
                        ],
                        "text": "2010), see also Lin et al. (2011). Their system combined six sub-systems with different patch descriptors, patch encoding schemes and spatial pyramids."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 56
                            }
                        ],
                        "text": "It was shown to be effective both for scene recognition (Lazebnik et al. 2006) and loosely structured object recognition as demonstrated during the PASCAL VOC evaluations (Everingham et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 89
                            }
                        ],
                        "text": "The baseline of Griffin et al (2007) is a reimplementation of the spatial pyramid BoV of Lazebnik et al (2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 277
                            }
                        ],
                        "text": "\u2026assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al, 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 43
                            }
                        ],
                        "text": "The Spatial Pyramid (SP) was introduced in Lazebnik et al (2006) to take into account the rough geometry of a scene."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 108
                            }
                        ],
                        "text": "2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": "It was shown to be effective both for scene recognition (Lazebnik et al, 2006) and loosely structured object recognition as demonstrated during the PASCAL VOC evaluations (Everingham et al, 2007, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": true,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390562671"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144228782"
                        ],
                        "name": "T. Campos",
                        "slug": "T.-Campos",
                        "structuredName": {
                            "firstName": "Te\u00f3filo",
                            "lastName": "Campos",
                            "middleNames": [
                                "Em\u00eddio",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Campos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9892293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3babec90d7234913e792462bd336637ef7ae3651",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-the-spatial-layout-of-images-beyond-S\u00e1nchez-Perronnin",
            "title": {
                "fragments": [],
                "text": "Modeling the spatial layout of images beyond spatial pyramids"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 30
                            }
                        ],
                        "text": "1.4M images) and ImageNet10K (Deng et al, 2010) (approx."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 27
                            }
                        ],
                        "text": "4M images) and ImageNet10K (Deng et al. 2010) (approximately 10K classes and 9M images)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Deng et al (2010) achive 6.4% accuracy using a BoV representation and the fast Intesection kernel SVM (IKSVM) technique of Maji and Berg (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al (2010), Sa\u0301nchez and Perronnin (2011)), Krizhevsky et al (2012), Le et al (2012) report a per-image accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 28
                            }
                        ],
                        "text": "5.2 ImageNet10K\nImageNet10K Deng et al (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 57
                            }
                        ],
                        "text": "We now report results on the large-scale ILSVRC 2010 and ImageNet10K datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 16
                            }
                        ],
                        "text": "The baseline of Griffin et al. (2007) is a reimplementation of the spatial pyramid BoV of Lazebnik et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 79
                            }
                        ],
                        "text": "This proves to be a crucial property when handling very large datasets such as ImageNet10K, see Section 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 16
                            }
                        ],
                        "text": "The baseline of Griffin et al. (2007) is a reimplementation of the spatial pyramid BoV of Lazebnik et al. (2006). Several systems are based on the combination of multiple channels corresponding to many different features including Bergamo and Torresani (2012), Boiman et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 133
                            }
                        ],
                        "text": "We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al, 2010, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 132
                            }
                        ],
                        "text": "We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al. 2010; S\u00e1nchez and Perronnin 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1274537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9800e3c3394c569be83379ee2ebe3424e09c2919",
            "isKey": true,
            "numCitedBy": 528,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Image classification is a critical task for both humans and computers. One of the challenges lies in the large scale of the semantic space. In particular, humans can recognize tens of thousands of object classes and scenes. No computer vision algorithm today has been tested at this scale. This paper presents a study of large scale categorization including a series of challenging experiments on classification with more than 10, 000 image classes. We find that a) computational issues become crucial in algorithm design; b) conventional wisdom from a couple of hundred image categories on relative performance of different classifiers does not necessarily hold when the number of categories increases; c) there is a surprisingly strong relationship between the structure of WordNet (developed for studying language) and the difficulty of visual categorization; d) classification can be improved by exploiting the semantic hierarchy. Toward the future goal of developing automatic vision algorithms to recognize tens of thousands or even millions of image categories, we make a series of observations and arguments about dataset scale, category density, and image hierarchy."
            },
            "slug": "What-Does-Classifying-More-Than-10,-000-Image-Tell-Deng-Berg",
            "title": {
                "fragments": [],
                "text": "What Does Classifying More Than 10, 000 Image Categories Tell Us?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A study of large scale categorization including a series of challenging experiments on classification with more than 10,000 image classes finds that computational issues become crucial in algorithm design and conventional wisdom from a couple of hundred image categories does not necessarily hold when the number of categories increases."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089272"
                        ],
                        "name": "R. Monga",
                        "slug": "R.-Monga",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Monga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145139947"
                        ],
                        "name": "Matthieu Devin",
                        "slug": "Matthieu-Devin",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Devin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Devin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206741597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72e93aa6767ee683de7f001fa72f1314e40a8f35",
            "isKey": false,
            "numCitedBy": 2100,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a deep sparse autoencoder on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200\u00d7200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting from these learned features, we trained our network to recognize 22,000 object categories from ImageNet and achieve a leap of 70% relative improvement over the previous state-of-the-art."
            },
            "slug": "Building-high-level-features-using-large-scale-Le-Ranzato",
            "title": {
                "fragments": [],
                "text": "Building high-level features using large scale unsupervised learning"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Contrary to what appears to be a widely-held intuition, the experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3344005"
                        ],
                        "name": "C. Dance",
                        "slug": "C.-Dance",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Dance",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dance"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3454299"
                        ],
                        "name": "M. Bressan",
                        "slug": "M.-Bressan",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Bressan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bressan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 65
                            }
                        ],
                        "text": "We now describe two normalization steps which were introduced in Perronnin et al. (2010c) and which were shown to be necessary to obtain competitive results when the FV is combined with a linear classifier. 2-Normalization Perronnin et al. (2010c) proposed to 2-normalize FVs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 132
                            }
                        ],
                        "text": "There have been several extensions of this popular framework including the use of better coding techniques based on soft assignment (Farquhar et al. 2005; Perronnin et al. 2006; VanGemert et al. 2010; Winn et al. 2005) or sparse coding (Boureau et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "\u2026the use of better coding\n1 http://www.image-net.org 2 http://www.flickr.com/groups\ntechniques based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Perronnin et al. (2010c) chose the 2-norm because it is the natural norm associated with the dot-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 24
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al. 2005; Perronnin et al. 2006; VanGemert et al. 2010; Winn et al. 2005), the average number of assignments to Gaussian k can be computed as:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 486,
                                "start": 65
                            }
                        ],
                        "text": "We now describe two normalization steps which were introduced in Perronnin et al. (2010c) and which were shown to be necessary to obtain competitive results when the FV is combined with a linear classifier. 2-Normalization Perronnin et al. (2010c) proposed to 2-normalize FVs. We provide two complementary interpretations to explain why such a normalization can lead to improved results. The first interpretation is specific to the FV and was first proposed in Perronnin et al. (2010c). The second interpretation is valid for any high-dimensional vector."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005), the average number of assignments to Gaussian k can be computed as:\n1 T\nT\n\u2211 t=1 \u03b3t(k) = S0k T ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 583,
                                "start": 65
                            }
                        ],
                        "text": "We now describe two normalization steps which were introduced in Perronnin et al. (2010c) and which were shown to be necessary to obtain competitive results when the FV is combined with a linear classifier. 2-Normalization Perronnin et al. (2010c) proposed to 2-normalize FVs. We provide two complementary interpretations to explain why such a normalization can lead to improved results. The first interpretation is specific to the FV and was first proposed in Perronnin et al. (2010c). The second interpretation is valid for any high-dimensional vector. In Perronnin et al. (2010c), the 2-normalization is justified as a way to cancel-out the fact that different images contain different amounts of background information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 65
                            }
                        ],
                        "text": "We now describe two normalization steps which were introduced in Perronnin et al. (2010c) and which were shown to be necessary to obtain competitive results when the FV is combined with a linear classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 182
                            }
                        ],
                        "text": "In the computer vision literature, a GMM which models the generation process of local descriptors in any image has been referred to as a universal (probabilistic) visual vocabulary (Perronnin et al, 2006, Winn et al, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 181
                            }
                        ],
                        "text": "In the computer vision literature, a GMM which models the generation process of local descriptors in any image has been referred to as a universal (probabilistic) visual vocabulary (Perronnin et al. 2006; Winn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6076287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd9a38bc11272b254cb9f84e01e6d432b5fc3ede",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Several state-of-the-art Generic Visual Categorization (GVC) systems are built around a vocabulary of visual terms and characterize images with one histogram of visual word counts. We propose a novel and practical approach to GVC based on a universal vocabulary, which describes the content of all the considered classes of images, and class vocabularies obtained through the adaptation of the universal vocabulary using class-specific data. An image is characterized by a set of histograms \u2013 one per class \u2013 where each histogram describes whether the image content is best modeled by the universal vocabulary or the corresponding class vocabulary. It is shown experimentally on three very different databases that this novel representation outperforms those approaches which characterize an image with a single histogram."
            },
            "slug": "Adapted-Vocabularies-for-Generic-Visual-Perronnin-Dance",
            "title": {
                "fragments": [],
                "text": "Adapted Vocabularies for Generic Visual Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel and practical approach to GVC is proposed, which describes the content of all the considered classes of images, and class vocabularies obtained through the adaptation of the universal vocabulary using class-specific data."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144651486"
                        ],
                        "name": "Liefeng Bo",
                        "slug": "Liefeng-Bo",
                        "structuredName": {
                            "firstName": "Liefeng",
                            "lastName": "Bo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liefeng Bo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145197953"
                        ],
                        "name": "D. Fox",
                        "slug": "D.-Fox",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 9
                            }
                        ],
                        "text": "those of Bo et al. (2012) which uses a deep architecture which stacks three layers, each one consisting of three steps: coding, pooling and contrast normalization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 55
                            }
                        ],
                        "text": "Finally, the best results we are aware of are those of Bo et al (2012) which uses a deep architecture which stacks three layers, each one consisting of three steps: coding, pooling and contrast normalization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 9
                            }
                        ],
                        "text": "those of Bo et al. (2012) which uses a deep architecture which stacks three layers, each one consisting of three steps: coding, pooling and contrast normalization. Note that the deep architecture of Bo et al. (2012) makes use of color information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 35
                            }
                        ],
                        "text": "Note that the deep architecture of Bo et al (2012) makes use of color information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 804924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16849f9ef7a750ce85675592d283f1c0330ab2e4",
            "isKey": true,
            "numCitedBy": 206,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Complex real-world signals, such as images, contain discriminative structures that differ in many aspects including scale, invariance, and data channel. While progress in deep learning shows the importance of learning features through multiple layers, it is equally important to learn features through multiple paths. We propose Multipath Hierarchical Matching Pursuit (M-HMP), a novel feature learning architecture that combines a collection of hierarchical sparse features for image classification to capture multiple aspects of discriminative structures. Our building blocks are MI-KSVD, a codebook learning algorithm that balances the reconstruction error and the mutual incoherence of the codebook, and batch orthogonal matching pursuit (OMP), we apply them recursively at varying layers and scales. The result is a highly discriminative image representation that leads to large improvements to the state-of-the-art on many standard benchmarks, e.g., Caltech-101, Caltech-256, MITScenes, Oxford-IIIT Pet and Caltech-UCSD Bird-200."
            },
            "slug": "Multipath-Sparse-Coding-Using-Hierarchical-Matching-Bo-Ren",
            "title": {
                "fragments": [],
                "text": "Multipath Sparse Coding Using Hierarchical Matching Pursuit"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Multipath Hierarchical Matching Pursuit (M-HMP), a novel feature learning architecture that combines a collection of hierarchical sparse features for image classification to capture multiple aspects of discriminative structures, is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109615009"
                        ],
                        "name": "Xi Zhou",
                        "slug": "Xi-Zhou",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153699253"
                        ],
                        "name": "Ming Liu",
                        "slug": "Ming-Liu",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744418"
                        ],
                        "name": "Mark Hasegawa-Johnson",
                        "slug": "Mark-Hasegawa-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Hasegawa-Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Hasegawa-Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 141
                            }
                        ],
                        "text": "Several works proposed to model an image as a GMM adapted\nfrom a universal (i.e. image-independent) distribution u\u03bb (Liu and Perronnin, 2008, Yan et al, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "image-independent) distribution u\u03bb (Liu and Perronnin 2008; Yan et al. 2008)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15261447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fe66f19ceb1e0712dcc69eaad090ec97012ad78",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a patch-based regression framework for addressing the human age and head pose estimation problems. Firstly, each image is encoded as an ensemble of orderless coordinate patches, the global distribution of which is described by Gaussian mixture models (GMM), and then each image is further expressed as a specific distribution model by Maximum a Posteriori adaptation from the global GMM. Then the patch-kernel is designed for characterizing the Kullback-Leibler divergence between the derived models for any two images, and its discriminating power is further enhanced by a weak learning process, called inter-modality similarity synchronization. Finally, kernel regression is employed for ultimate human age or head pose estimation. These three stages are complementary to each other, and jointly minimize the regression error. The effectiveness of this regression framework is validated by three experiments: 1) on the YAMAHA aging database, our solution brings a more than 50% reduction in age estimation error compared with the best reported results; 2) on the FG-NET aging database, our solution based on raw image features performs even better than the state-of-the-art algorithms which require fine face alignment for extracting warped appearance features; and 3) on the CHIL head pose database, our solution significantly outperforms the best one reported in the CLEAR07 evaluation."
            },
            "slug": "Regression-from-patch-kernel-Yan-Zhou",
            "title": {
                "fragments": [],
                "text": "Regression from patch-kernel"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A patch-based regression framework for addressing the human age and head pose estimation problems by characterizing the Kullback-Leibler divergence between the derived models for any two images, and its discriminating power is further enhanced by a weak learning process, called inter-modality similarity synchronization."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2990061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7086378e68dae59975cf749c101c53a0fa90eab",
            "isKey": false,
            "numCitedBy": 1082,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Straightforward classification using kernelized SVMs requires evaluating the kernel for a test vector and each of the support vectors. For a class of kernels we show that one can do this much more efficiently. In particular we show that one can build histogram intersection kernel SVMs (IKSVMs) with runtime complexity of the classifier logarithmic in the number of support vectors as opposed to linear for the standard approach. We further show that by precomputing auxiliary tables we can construct an approximate classifier with constant runtime and space requirements, independent of the number of support vectors, with negligible loss in classification accuracy on various tasks. This approximation also applies to 1 - chi2 and other kernels of similar form. We also introduce novel features based on a multi-level histograms of oriented edge energy and present experiments on various detection datasets. On the INRIA pedestrian dataset an approximate IKSVM classifier based on these features has the current best performance, with a miss rate 13% lower at 10-6 False Positive Per Window than the linear SVM detector of Dalal & Triggs. On the Daimler Chrysler pedestrian dataset IKSVM gives comparable accuracy to the best results (based on quadratic SVM), while being 15times faster. In these experiments our approximate IKSVM is up to 2000times faster than a standard implementation and requires 200times less memory. Finally we show that a 50times speedup is possible using approximate IKSVM based on spatial pyramid features on the Caltech 101 dataset with negligible loss of accuracy."
            },
            "slug": "Classification-using-intersection-kernel-support-is-Maji-Berg",
            "title": {
                "fragments": [],
                "text": "Classification using intersection kernel support vector machines is efficient"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that one can build histogram intersection kernel SVMs (IKSVMs) with runtime complexity of the classifier logarithmic in the number of support vectors as opposed to linear for the standard approach."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813423"
                        ],
                        "name": "Arnulf B. A. Graf",
                        "slug": "Arnulf-B.-A.-Graf",
                        "structuredName": {
                            "firstName": "Arnulf",
                            "lastName": "Graf",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulf B. A. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4573035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c393b31ca71e8c4dd7c8c5a11653b18447c90466",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in computer vision have shown that local features can provide efficient representations suitable for robust object recognition. Support vector machines have been established as powerful learning algorithms with good generalization capabilities. We combine these two approaches and propose a general kernel method for recognition with local features. We show that the proposed kernel satisfies the Mercer condition and that it is, suitable for many established local feature frameworks. Large-scale recognition results are presented on three different databases, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features. In addition, experiments on noisy and occluded images show that local feature representations significantly outperform global approaches."
            },
            "slug": "Recognition-with-local-features:-the-kernel-recipe-Wallraven-Caputo",
            "title": {
                "fragments": [],
                "text": "Recognition with local features: the kernel recipe"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Large-scale recognition results are presented, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features and that local feature representations significantly outperform global approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 226
                            }
                        ],
                        "text": "The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4246903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "isKey": false,
            "numCitedBy": 11683,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension."
            },
            "slug": "The-Pascal-Visual-Object-Classes-(VOC)-Challenge-Everingham-Gool",
            "title": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The state-of-the-art in evaluated methods for both classification and detection are reviewed, whether the methods are statistically different, what they are learning from the images, and what the methods find easy or confuse."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096527"
                        ],
                        "name": "G. Wang",
                        "slug": "G.-Wang",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6207138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd4e88248e2db62866e9ed130907a704e71d9f10",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Measuring image similarity is a central topic in computer vision. In this paper, we learn similarity from Flickr groups and use it to organize photos. Two images are similar if they are likely to belong to the same Flickr groups. Our approach is enabled by a fast Stochastic Intersection Kernel MAchine (SIKMA) training algorithm, which we propose. This proposed training method will be useful for many vision problems, as it can produce a classifier that is more accurate than a linear classifier, trained on tens of thousands of examples in two minutes. The experimental results show our approach performs better on image matching, retrieval, and classification than using conventional visual features."
            },
            "slug": "Learning-image-similarity-from-Flickr-groups-using-Wang-Hoiem",
            "title": {
                "fragments": [],
                "text": "Learning image similarity from Flickr groups using Stochastic Intersection Kernel MAchines"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper learns similarity from Flickr groups and uses it to organize photos, and shows the approach performs better on image matching, retrieval, and classification than using conventional visual features."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 115
                            }
                        ],
                        "text": "The MSE for a quantizer q is given as the expected squared error between v \u2208 E and its reproduction value q(v) \u2208 C (J\u00e9gou et al. 2011):"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 120
                            }
                        ],
                        "text": "This has also been used for nearest neighbor image retrieval using an PQ encoded dataset and uncompressed query images (Je\u0301gou et al, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 135
                            }
                        ],
                        "text": "A solution is to use product quantizers which were introduced as a principled way to deal with high dimensional input spaces (see e.g. Je\u0301gou et al (2011) for an excellent introduction to the topic)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 140
                            }
                        ],
                        "text": "We address this problem using Product Quantization (PQ) (Gray and Neuhoff, 1998) which has been popularized in the computer vision field by Je\u0301gou et al (2011) for large-scale nearest neighbor search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 112
                            }
                        ],
                        "text": "The MSE for a quantizer q is given as the expected squared error between v \u2208\u211cE and its reproduction value q(v) \u2208 C (Je\u0301gou et al, 2011): MSE(q) = \u222b p(v)\u2016q(v)\u2212 v\u20162dv, (42)\nwhere p is a density function defined over the input vector space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 119
                            }
                        ],
                        "text": "This has also been used for nearest neighbor image retrieval using an PQ encoded dataset and uncompressed query images (J\u00e9gou et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5850884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4748d22348e72e6e06c2476486afddbc76e5eca7",
            "isKey": true,
            "numCitedBy": 2049,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a product quantization-based approach for approximate nearest neighbor search. The idea is to decompose the space into a Cartesian product of low-dimensional subspaces and to quantize each subspace separately. A vector is represented by a short code composed of its subspace quantization indices. The euclidean distance between two vectors can be efficiently estimated from their codes. An asymmetric version increases precision, as it computes the approximate distance between a vector and a code. Experimental results show that our approach searches for nearest neighbors efficiently, in particular in combination with an inverted file system. Results for SIFT and GIST image descriptors show excellent search accuracy, outperforming three state-of-the-art approaches. The scalability of our approach is validated on a data set of two billion vectors."
            },
            "slug": "Product-Quantization-for-Nearest-Neighbor-Search-J\u00e9gou-Douze",
            "title": {
                "fragments": [],
                "text": "Product Quantization for Nearest Neighbor Search"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper introduces a product quantization-based approach for approximate nearest neighbor search to decompose the space into a Cartesian product of low-dimensional subspaces and to quantize each subspace separately."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 20
                            }
                        ],
                        "text": "Le et al (2012) and Krizhevsky et al (2012) also report results on the same subset of 10K classes using deep architectures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 64
                            }
                        ],
                        "text": "Le\net al (2012) reports a top-1 per-image accuracy of 19.2% and Krizhevsky et al (2012) of 32.6%.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 23
                            }
                        ],
                        "text": "In a very recent work, Krizhevsky et al (2012) reported significantly better results using a deep learning network."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 132
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al (2010), Sa\u0301nchez and Perronnin (2011)), Krizhevsky et al (2012), Le et al (2012) report a per-image accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 79
                            }
                        ],
                        "text": "This was clarified through a personal correspondence with the first authors of Krizhevsky et al (2012), Le et al (2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 4
                            }
                        ],
                        "text": "In (Krizhevsky et al, 2012) the network consists of 6 convolutional layers plus three fully connected layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": true,
            "numCitedBy": 80897,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14457153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642e328cae81c5adb30069b680cf60ba6b475153",
            "isKey": false,
            "numCitedBy": 6760,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films."
            },
            "slug": "Video-Google:-a-text-retrieval-approach-to-object-Sivic-Zisserman",
            "title": {
                "fragments": [],
                "text": "Video Google: a text retrieval approach to object matching in videos"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video, represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40599257"
                        ],
                        "name": "Jianxiong Xiao",
                        "slug": "Jianxiong-Xiao",
                        "structuredName": {
                            "firstName": "Jianxiong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxiong Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48966748"
                        ],
                        "name": "James Hays",
                        "slug": "James-Hays",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hays",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hays"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865091"
                        ],
                        "name": "Krista A. Ehinger",
                        "slug": "Krista-A.-Ehinger",
                        "structuredName": {
                            "firstName": "Krista",
                            "lastName": "Ehinger",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Krista A. Ehinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1309931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "908091b4a8757c3b2f7d9cfa2c4f616ee12c5157",
            "isKey": false,
            "numCitedBy": 2352,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene categorization is a fundamental problem in computer vision. However, scene understanding research has been constrained by the limited scope of currently-used databases which do not capture the full variety of scene categories. Whereas standard databases for object categorization contain hundreds of different classes of objects, the largest available dataset of scene categories contains only 15 classes. In this paper we propose the extensive Scene UNderstanding (SUN) database that contains 899 categories and 130,519 images. We use 397 well-sampled categories to evaluate numerous state-of-the-art algorithms for scene recognition and establish new bounds of performance. We measure human scene classification performance on the SUN database and compare this with computational methods. Additionally, we study a finer-grained scene representation to detect scenes embedded inside of larger scenes."
            },
            "slug": "SUN-database:-Large-scale-scene-recognition-from-to-Xiao-Hays",
            "title": {
                "fragments": [],
                "text": "SUN database: Large-scale scene recognition from abbey to zoo"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes the extensive Scene UNderstanding (SUN) database that contains 899 categories and 130,519 images and uses 397 well-sampled categories to evaluate numerous state-of-the-art algorithms for scene recognition and establish new bounds of performance."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 190
                            }
                        ],
                        "text": "Indeed, VOC 2007 is small enough (20 classes and approximately 10K images) to enable running a large number of experiments in a reasonable amount of time but challenging enough (as shown in (Torralba and Efros 2011)) so that the conclusions we draw from our experiments extrapolate to other (equally challenging) datasets."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "\u2026enough (20 classes and approximately 10K images) to enable running a large number of experiments in a reasonable amount of time but challenging enough (as shown in (Torralba and Efros, 2011)) so that the conclusions we draw from our experiments extrapolate to other (equally challenging) datasets."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2777306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0302bb2d5476540cfb21467473f5eca843caf90b",
            "isKey": false,
            "numCitedBy": 1756,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algorithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, reducing it to a single benchmark performance number. Indeed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech-101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study using a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset generalization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regarding this very important, but largely neglected issue."
            },
            "slug": "Unbiased-look-at-dataset-bias-Torralba-Efros",
            "title": {
                "fragments": [],
                "text": "Unbiased look at dataset bias"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A comparison study using a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset generalization, effects of closed-world assumption, and sample value is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 87
                            }
                        ],
                        "text": "For instance, as of today, ImageNet1 consists of more than 14M images of 22K concepts (Deng et al, 2009) and Flickr contains thousands of groups2 \u2013 some of which with hundreds of thousands of pictures \u2013 which can be exploited to learn object classifiers (Perronnin et al, 2010c, Wang et al, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 711,
                                "start": 12
                            }
                        ],
                        "text": "ImageNet10K Deng et al. (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes. For these experiments, we used the exact same setting as for our ILSVRC 2010 experiments: we do not use spatial pyramids and the SIFT- and LCS-FVs are concatenated to obtain either a 4K-dim of a 64K-dim FV. For the compression, we use the default setting (b = 1 bit per dimension and G = 8). To train the one-vs-rest linear SVMs, we also follow Perronnin et al. (2012) and subsample the negatives. At test time, we also compress FVs because of the large of number of test images to store on disk (4.5M). In our experiments, we follow the protocol of S\u00e1nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 86
                            }
                        ],
                        "text": "For instance, as of today, ImageNet1 consists of more than 14M images of 22K concepts (Deng et al. 2009) and Flickr contains thousands of groups2\u2014 some of which with hundreds of thousands of pictures\u2014 which can be exploited to learn object classifiers (Perronnin et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1254,
                                "start": 12
                            }
                        ],
                        "text": "ImageNet10K Deng et al. (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes. For these experiments, we used the exact same setting as for our ILSVRC 2010 experiments: we do not use spatial pyramids and the SIFT- and LCS-FVs are concatenated to obtain either a 4K-dim of a 64K-dim FV. For the compression, we use the default setting (b = 1 bit per dimension and G = 8). To train the one-vs-rest linear SVMs, we also follow Perronnin et al. (2012) and subsample the negatives. At test time, we also compress FVs because of the large of number of test images to store on disk (4.5M). In our experiments, we follow the protocol of S\u00e1nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing. We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al. 2010; S\u00e1nchez and Perronnin 2011). Using the 4K-dim FVs, we achieve a top-1 accuracy of 14.0 % and using the 64K-dim FVs 21.9 %. Comparison with the State-of-the-Art Deng et al. (2010) achive 6.4 % accuracy using a BoV representation and the fast Intesection kernel SVM (IKSVM) technique of Maji and Berg (2009). Our compressed FV results are more than three times higher."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1868,
                                "start": 12
                            }
                        ],
                        "text": "ImageNet10K Deng et al. (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes. For these experiments, we used the exact same setting as for our ILSVRC 2010 experiments: we do not use spatial pyramids and the SIFT- and LCS-FVs are concatenated to obtain either a 4K-dim of a 64K-dim FV. For the compression, we use the default setting (b = 1 bit per dimension and G = 8). To train the one-vs-rest linear SVMs, we also follow Perronnin et al. (2012) and subsample the negatives. At test time, we also compress FVs because of the large of number of test images to store on disk (4.5M). In our experiments, we follow the protocol of S\u00e1nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing. We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al. 2010; S\u00e1nchez and Perronnin 2011). Using the 4K-dim FVs, we achieve a top-1 accuracy of 14.0 % and using the 64K-dim FVs 21.9 %. Comparison with the State-of-the-Art Deng et al. (2010) achive 6.4 % accuracy using a BoV representation and the fast Intesection kernel SVM (IKSVM) technique of Maji and Berg (2009). Our compressed FV results are more than three times higher. S\u00e1nchez and Perronnin (2011) reported a 16.7 % accuracy using FVs but without color information. Using similar features Perronnin et al. (2012) improved these results to 19.1 % by carefully cross-validating the balance between the positive and negative samples, a good practice we also used in the current work. (Mensink et al. 2012) obtained 13.9 % using the same features and PQ compression as we used in this paper, but with a nearest mean classifier which only requires a fraction of the training time. Le et al. (2012) and Krizhevsky et al. (2012) also report results on the same subset of 10K classes using deep architectures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2554,
                                "start": 12
                            }
                        ],
                        "text": "ImageNet10K Deng et al. (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes. For these experiments, we used the exact same setting as for our ILSVRC 2010 experiments: we do not use spatial pyramids and the SIFT- and LCS-FVs are concatenated to obtain either a 4K-dim of a 64K-dim FV. For the compression, we use the default setting (b = 1 bit per dimension and G = 8). To train the one-vs-rest linear SVMs, we also follow Perronnin et al. (2012) and subsample the negatives. At test time, we also compress FVs because of the large of number of test images to store on disk (4.5M). In our experiments, we follow the protocol of S\u00e1nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing. We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al. 2010; S\u00e1nchez and Perronnin 2011). Using the 4K-dim FVs, we achieve a top-1 accuracy of 14.0 % and using the 64K-dim FVs 21.9 %. Comparison with the State-of-the-Art Deng et al. (2010) achive 6.4 % accuracy using a BoV representation and the fast Intesection kernel SVM (IKSVM) technique of Maji and Berg (2009). Our compressed FV results are more than three times higher. S\u00e1nchez and Perronnin (2011) reported a 16.7 % accuracy using FVs but without color information. Using similar features Perronnin et al. (2012) improved these results to 19.1 % by carefully cross-validating the balance between the positive and negative samples, a good practice we also used in the current work. (Mensink et al. 2012) obtained 13.9 % using the same features and PQ compression as we used in this paper, but with a nearest mean classifier which only requires a fraction of the training time. Le et al. (2012) and Krizhevsky et al. (2012) also report results on the same subset of 10K classes using deep architectures. Both networks have nine layers but they are quite different. In (Le et al. 2012), the features are learned using a deep autoencoder which is constructed by replicating three times the same three layers\u2014made of local filtering, local pooling and contrast normalization. Classification is then performed using linear classifiers (trained with a logistic loss). In (Krizhevsky et al. 2012) the network consists of six convolutional layers plus three fully connected layers. The output of the last fully connected layer is fed to a softmax which produces a distribution over the class labels. Le et al. (2012) reports a top-1 per-image accuracy of 19."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 112
                            }
                        ],
                        "text": "2010) would take almost 3TBs, and storing the signatures for the approximately 14M of the full ImageNet dataset (Deng et al. 2009) around 27TBs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 34
                            }
                        ],
                        "text": "14M of the full ImageNet dataset (Deng et al, 2009) around 27TBs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 12
                            }
                        ],
                        "text": "ImageNet10K Deng et al. (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 501,
                                "start": 12
                            }
                        ],
                        "text": "ImageNet10K Deng et al. (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes. For these experiments, we used the exact same setting as for our ILSVRC 2010 experiments: we do not use spatial pyramids and the SIFT- and LCS-FVs are concatenated to obtain either a 4K-dim of a 64K-dim FV. For the compression, we use the default setting (b = 1 bit per dimension and G = 8). To train the one-vs-rest linear SVMs, we also follow Perronnin et al. (2012) and subsample the negatives."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1459,
                                "start": 12
                            }
                        ],
                        "text": "ImageNet10K Deng et al. (2010) is a subset of ImageNet which contains approximately 9M images corresponding to roughly 10K classes. For these experiments, we used the exact same setting as for our ILSVRC 2010 experiments: we do not use spatial pyramids and the SIFT- and LCS-FVs are concatenated to obtain either a 4K-dim of a 64K-dim FV. For the compression, we use the default setting (b = 1 bit per dimension and G = 8). To train the one-vs-rest linear SVMs, we also follow Perronnin et al. (2012) and subsample the negatives. At test time, we also compress FVs because of the large of number of test images to store on disk (4.5M). In our experiments, we follow the protocol of S\u00e1nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing. We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al. 2010; S\u00e1nchez and Perronnin 2011). Using the 4K-dim FVs, we achieve a top-1 accuracy of 14.0 % and using the 64K-dim FVs 21.9 %. Comparison with the State-of-the-Art Deng et al. (2010) achive 6.4 % accuracy using a BoV representation and the fast Intesection kernel SVM (IKSVM) technique of Maji and Berg (2009). Our compressed FV results are more than three times higher. S\u00e1nchez and Perronnin (2011) reported a 16.7 % accuracy using FVs but without color information. Using similar features Perronnin et al. (2012) improved these results to 19."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 82
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al. 2010; S\u00e1nchez and Perronnin 2011), Krizhevsky et al. (2012); Le et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b47265245e8db53a553049dcb27ed3e495fd625",
            "isKey": true,
            "numCitedBy": 27367,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823362"
                        ],
                        "name": "J. Uijlings",
                        "slug": "J.-Uijlings",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Uijlings",
                            "middleNames": [
                                "R.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Uijlings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081727"
                        ],
                        "name": "R. Scha",
                        "slug": "R.-Scha",
                        "structuredName": {
                            "firstName": "Remko",
                            "lastName": "Scha",
                            "middleNames": [
                                "J.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Scha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Uijlings et al (2009) reports 59.4% using a BoV representation and a single channel but assuming that one has access to the ground-truth object bounding box annotations at both training and test time (which they use to crop the image to the rectangles that contain the objects, and thus suppress the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 79
                            }
                        ],
                        "text": "3 Influence of the parameter p of the `p-norm on the FV on PASCAL VOC 2007.\nin Uijlings et al (2009), foreground patches (i.e. object patches) are more informative than background object patches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 468493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "076f011e09b9788c022c0578ab8dd0bb3fdf8908",
            "isKey": true,
            "numCitedBy": 37,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the question: Can we improve the recognition of objects by using their spatial context? We start from Bag-of-Words models and use the Pascal 2007 dataset. We use the rough object bounding boxes that come with this dataset to investigate the fundamental gain context can bring. Our main contributions are: (I) The result of Zhang et al. in CVPR07 that context is superfluous derived from the Pascal 2005 data set of 4 classes does not generalize to this dataset. For our larger and more realistic dataset context is important indeed. (II) Using the rough bounding box to limit or extend the scope of an object during both training and testing, we find that the spatial extent of an object is determined by its category: (a) well-defined, rigid objects have the object itself as the preferred spatial extent. (b) Non-rigid objects have an unbounded spatial extent : all spatial extents produce equally good results. (c) Objects primarily categorised based on their function have the whole image as their spatial extent. Finally, (III) using the rough bounding box to treat object and context separately, we find that the upper bound of improvement is 26% (12% absolute) in terms of mean average precision, and this bound is likely to be higher if the localisation is done using segmentation. It is concluded that object localisation, if done sufficiently precise, helps considerably in the recognition of objects for the Pascal 2007 dataset."
            },
            "slug": "What-is-the-spatial-extent-of-an-object-Uijlings-Smeulders",
            "title": {
                "fragments": [],
                "text": "What is the spatial extent of an object?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is concluded that object localisation, if done sufficiently precise, helps considerably in the recognition of objects for the Pascal 2007 dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820887"
                        ],
                        "name": "Hedi Harzallah",
                        "slug": "Hedi-Harzallah",
                        "structuredName": {
                            "firstName": "Hedi",
                            "lastName": "Harzallah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hedi Harzallah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Harzallah et al (2009) reports 63.5% using a standard classification pipeline in combination with an image detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8879271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fae850e7b85e91b11a2874252ec617c3cb064c6",
            "isKey": true,
            "numCitedBy": 338,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a combined approach for object localization and classification. Our contribution is twofold. (a) A contextual combination of localization and classification which shows that classification can improve detection and vice versa. (b) An efficient two stage sliding window object localization method that combines the efficiency of a linear classifier with the robustness of a sophisticated non-linear one. Experimental results evaluate the parameters of our two stage sliding window approach and show that our combined object localization and classification methods outperform the state-of-the-art on the PASCAL VOC 2007 and 2008 datasets."
            },
            "slug": "Combining-efficient-object-localization-and-image-Harzallah-Jurie",
            "title": {
                "fragments": [],
                "text": "Combining efficient object localization and image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An efficient two stage sliding window object localization method that combines the efficiency of a linear classifier with the robustness of a sophisticated non-linear one and shows that classification can improve detection and vice versa is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121280287"
                        ],
                        "name": "Jingjing Yang",
                        "slug": "Jingjing-Yang",
                        "structuredName": {
                            "firstName": "Jingjing",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingjing Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110429865"
                        ],
                        "name": "Yuanning Li",
                        "slug": "Yuanning-Li",
                        "structuredName": {
                            "firstName": "Yuanning",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuanning Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40161651"
                        ],
                        "name": "Yonghong Tian",
                        "slug": "Yonghong-Tian",
                        "structuredName": {
                            "firstName": "Yonghong",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonghong Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7667912"
                        ],
                        "name": "Ling-yu Duan",
                        "slug": "Ling-yu-Duan",
                        "structuredName": {
                            "firstName": "Ling-yu",
                            "lastName": "Duan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling-yu Duan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153575918"
                        ],
                        "name": "Wen Gao",
                        "slug": "Wen-Gao",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen Gao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10792613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "defaadaeaf5422f1172e61c2831f8170ed3b5406",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a group-sensitive multiple kernel learning (GS-MKL) method to accommodate the intra-class diversity and the inter-class correlation for object categorization. By introducing an intermediate representation \u201cgroup\u201d between images and object categories, GS-MKL attempts to find appropriate kernel combination for each group to get a finer depiction of object categories. For each category, images within a group share a set of kernel weights while images from different groups may employ distinct sets of kernel weights. In GS-MKL, such group-sensitive kernel combinations together with the multi-kernels based classifier are optimized in a joint manner to seek a trade-off between capturing the diversity and keeping the invariance for each category. Extensive experiments show that our proposed GS-MKL method has achieved encouraging performance over three challenging datasets."
            },
            "slug": "Group-sensitive-multiple-kernel-learning-for-object-Yang-Li",
            "title": {
                "fragments": [],
                "text": "Group-sensitive multiple kernel learning for object categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A group-sensitive multiple kernel learning method to accommodate the intra-class diversity and the inter-class correlation for object categorization by introducing an intermediate representation \u201cgroup\u201d between images and object categories is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794837"
                        ],
                        "name": "Siwei Lyu",
                        "slug": "Siwei-Lyu",
                        "structuredName": {
                            "firstName": "Siwei",
                            "lastName": "Lyu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siwei Lyu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2262078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cba5ad0b755434eda25c0147633a843e5b9cbd24",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A new class of kernels for object recognition based on local image feature representations are introduced in this paper. These kernels satisfy the Mercer condition and incorporate multiple types of local features and semilocal constraints between them. Experimental results of SVM classifiers coupled with the proposed kernels are reported on recognition tasks with the COIL-100 database and compared with existing methods. The proposed kernels achieved competitive performance and were robust to changes in object configurations and image degradations."
            },
            "slug": "Mercer-kernels-for-object-recognition-with-local-Lyu",
            "title": {
                "fragments": [],
                "text": "Mercer kernels for object recognition with local features"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new class of kernels for object recognition based on local image feature representations that satisfy the Mercer condition and incorporate multiple types of local features and semilocal constraints between them are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Maji and Berg (2009) and Wang et al (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 123
                            }
                        ],
                        "text": "Deng et al (2010) achive 6.4% accuracy using a BoV representation and the fast Intesection kernel SVM (IKSVM) technique of Maji and Berg (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13243510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03a8f53058127798bc2bc0245d21e78354f6c93b",
            "isKey": true,
            "numCitedBy": 228,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present methods for training high quality object detectors very quickly. The core contribution is a pair of fast training algorithms for piece-wise linear classifiers, which can approximate arbitrary additive models. The classifiers are trained in a max-margin framework and significantly outperform linear classifiers on a variety of vision datasets. We report experimental results quantifying training time and accuracy on image classification tasks and pedestrian detection, including detection results better than the best previous on the INRIA dataset with faster training."
            },
            "slug": "Max-margin-additive-classifiers-for-detection-Maji-Berg",
            "title": {
                "fragments": [],
                "text": "Max-margin additive classifiers for detection"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A pair of fast training algorithms for piece-wise linear classifiers, which can approximate arbitrary additive models, are presented, which are trained in a max-margin framework and significantly outperform linear classifier on a variety of vision datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14336127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e45c2420e6dc59ba6d357fb0c996ebf43c861560",
            "isKey": false,
            "numCitedBy": 1619,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Generative probability models such as hidden Markov models provide a principled way of treating missing information and dealing with variable length sequences. On the other hand, discriminative methods such as support vector machines enable us to construct flexible decision boundaries and often result in classification performance superior to that of the model based approaches. An ideal classifier should combine these two complementary approaches. In this paper, we develop a natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models. We provide a theoretical justification for this combination as well as demonstrate a substantial improvement in the classification performance in the context of DNA and protein sequence analysis."
            },
            "slug": "Exploiting-Generative-Models-in-Discriminative-Jaakkola-Haussler",
            "title": {
                "fragments": [],
                "text": "Exploiting Generative Models in Discriminative Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models is developed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395615041"
                        ],
                        "name": "M. Sabin",
                        "slug": "M.-Sabin",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Sabin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sabin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 42
                            }
                        ],
                        "text": "as a first step towards gain/shape coding (Sabin and Gray, 1984), i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 204
                            }
                        ],
                        "text": "\u2026the bit is 1, then we encode the 2D mean and standard-deviation gradient values of this Gaussian using PQ.\nNote that adding this per Gaussian bit can be viewed as a first step towards gain/shape coding (Sabin and Gray, 1984), i.e. encoding separately the norm and direction of the gradient vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122059816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "886177ca3c5da9f3ccf1327dc71eb4eeada9e015",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory and computation requirements imply fundamental limitations on the quality that can be achieved in vector quantization systems used for speech waveform coding and linear predictive voice coding (LPC). One approach to reducing storage and computation requirements is to organize the set of reproduction vectors as the Cartesian product of a vector codebook describing the shape of each reproduction vector and a scalar codebook describing the gain or energy. Such shape-gain vector quantizers can be applied both to waveform coding using a quadratic-error distortion measure and to voice coding using an Itakura-Saito distortion measure. In each case, the minimum distortion reproduction vector can be found by first selecting a shape code-word, and then, based on that choice, selecting a gain codeword. Several algorithms are presented for the design of shape-gain vector quantizers based on a traning sequence of data or a probabilistic model. The algorithms are used to design shape-gain vector quantizers for both the waveform coding and voice coding application. The quantizers are simulated, and their performance is compared to that of previously reported vector quantization systems."
            },
            "slug": "Product-code-vector-quantizers-for-waveform-and-Sabin-Gray",
            "title": {
                "fragments": [],
                "text": "Product code vector quantizers for waveform and voice coding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Several algorithms are presented for the design of shape-gain vector quantizers based on a traning sequence of data or a probabilistic model, and their performance is compared to that of previously reported vector quantization systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9474837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "378238376d5011963309eb9eeffa8d09f0b18d49",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Burstiness, a phenomenon initially observed in text retrieval, is the property that a given visual element appears more times in an image than a statistically independent model would predict. In the context of image search, burstiness corrupts the visual similarity measure, i.e., the scores used to rank the images. In this paper, we propose a strategy to handle visual bursts for bag-of-features based image search systems. Experimental results on three reference datasets show that our method significantly and consistently outperforms the state of the art."
            },
            "slug": "On-the-burstiness-of-visual-elements-J\u00e9gou-Douze",
            "title": {
                "fragments": [],
                "text": "On the burstiness of visual elements"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results on three reference datasets show that the proposed strategy to handle visual bursts for bag-of-features based image search systems significantly and consistently outperforms the state of the art."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2207074"
                        ],
                        "name": "S. Clinchant",
                        "slug": "S.-Clinchant",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Clinchant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clinchant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 159
                            }
                        ],
                        "text": "We consider two types of patch descriptors in this work: the 128-dim SIFT descriptors of Lowe (2004) and the 96-dim Local Color Statistic (LCS) descriptors of Clinchant et al (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "In practice we use SIFT (Lowe, 2004) or Local Color Statistics (Clinchant et al, 2007) as descriptors computed on a dense multi-scale grid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 773638,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f38f166137d6a5b063719f983831b05c39198d95",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "This document describes XRCE\u2019s participation to Imageval, more specifically to the mixed Text-Image search. After reviewing stateof-the-art methods to exploit the correlations between texts and images in multimedia retrieval, we will examine the single-media search components and describe how we have combined them in the framework of ImagEval. It appeared that, with our current settings and the Imageval corpus, no \u201cearly fusion\u201d approach gave significantly better results than a \u201clate fusion\u201d method, so that this paper is mainly dedicated to the latter approach. In this track, exploiting textual information with the Language Modelling approach alone already offered very satisfying performance, much larger than purely visual search. Still, late fusion was able to increase monomedia results by more than 10% (relative), showing the usefulness of combining both types of information, even if the purely visual retrieval component gives relatively poor results."
            },
            "slug": "XRCE-\u2019-s-participation-to-ImagEval-Clinchant-Csurka",
            "title": {
                "fragments": [],
                "text": "XRCE \u2019 s participation to ImagEval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper is mainly dedicated to the late fusion approach, which was able to increase monomedia results by more than 10% (relative), showing the usefulness of combining both types of information, even if the purely visual retrieval component gives relatively poor results."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16096318,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3",
            "isKey": false,
            "numCitedBy": 993,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well known that the addition of noise to the input data of a neural network during training can, in some circumstances, lead to significant improvements in generalization performance. Previous work has shown that such training with noise is equivalent to a form of regularization in which an extra term is added to the error function. However, the regularization term, which involves second derivatives of the error function, is not bounded below, and so can lead to difficulties if used directly in a learning algorithm based on error minimization. In this paper we show that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping. For a sum-of-squares error function, the regularization term belongs to the class of generalized Tikhonov regularizers. Direct minimization of the regularized error function provides a practical alternative to training with noise."
            },
            "slug": "Training-with-Noise-is-Equivalent-to-Tikhonov-Bishop",
            "title": {
                "fragments": [],
                "text": "Training with Noise is Equivalent to Tikhonov Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper shows that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116829524"
                        ],
                        "name": "N. Smith",
                        "slug": "N.-Smith",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 98
                            }
                        ],
                        "text": "To avoid the dependence on the sample size (see for instance the sequence length normalization in Smith and Gales (2001)), we normalize the resulting FV by the sample size T , i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 98
                            }
                        ],
                        "text": "To avoid the dependence on the sample size (see for instance the sequence length normalization in Smith and Gales (2001)), we normalize the resulting FV by the sample size T , i.e. we perform the following operation:\nG X\u03bb \u2190 1 T G X\u03bb (19)\nIn practice, T is almost constant in our experiments since we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1435919,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6bc69b22ea6418b70893ce3501a6a0cd9c0549d",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "An important issue in applying SVMs to speech recognition is the ability to classify variable length sequences. This paper presents extensions to a standard scheme for handling this variable length data, the Fisher score. A more useful mapping is introduced based on the likelihood-ratio. The score-space defined by this mapping avoids some limitations of the Fisher score. Class-conditional generative models are directly incorporated into the definition of the score-space. The mapping, and appropriate normalisation schemes, are evaluated on a speaker-independent isolated letter task where the new mapping outperforms both the Fisher score and HMMs trained to maximise likelihood."
            },
            "slug": "Speech-Recognition-using-SVMs-Smith-Gales",
            "title": {
                "fragments": [],
                "text": "Speech Recognition using SVMs"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Extensions to a standard scheme for handling variable length data, the Fisher score, are presented and a more useful mapping is introduced based on the likelihood-ratio, which outperforms both the fisher score and HMMs trained to maximise likelihood."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 123
                            }
                        ],
                        "text": "used an argument based on the Taylor expansion of non-linear functions which is similar to the one offered by Jaakkola and Haussler (1998) to justify the FK4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 111
                            }
                        ],
                        "text": "The MK measures the similarity between two images as a sum of similarities between the individual descriptors (Haussler, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 42
                            }
                        ],
                        "text": "2 in the extended version of Jaakkola and Haussler (1998) which is available at: http://people."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 41
                            }
                        ],
                        "text": "Following this observation, Jaakkola and Haussler (1998)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "inally proposed in Jaakkola and Haussler (1998). Using the identity matrix, we observe a decrease of the performance to 59."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 126
                            }
                        ],
                        "text": "In this work, we propose an alternative patch aggregation mechanism based on the Fisher Kernel (FK) principle of Jaakkola and Haussler (1998). The FK combines the benefits of generative and discriminative approaches to pattern classification by deriving a kernel from a generative model"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17702358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac",
            "isKey": true,
            "numCitedBy": 1371,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs. The method can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set. The family of kernels generated generalizes the family of radial basis kernels. It can also be used to deene kernels in the form of joint Gibbs probability distributions. Kernels can be built from hidden Markov random elds, generalized regular expressions, pair-HMMs, or ANOVA de-compositions. Uses of the method lead to open problems involving the theory of innnitely divisible positive deenite functions. Fundamentals of this theory and the theory of reproducing kernel Hilbert spaces are reviewed and applied in establishing the validity of the method."
            },
            "slug": "Convolution-kernels-on-discrete-structures-Haussler",
            "title": {
                "fragments": [],
                "text": "Convolution kernels on discrete structures"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs is introduced, which can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2611648"
                        ],
                        "name": "Tianli Yu",
                        "slug": "Tianli-Yu",
                        "structuredName": {
                            "firstName": "Tianli",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianli Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145857599"
                        ],
                        "name": "N. Xu",
                        "slug": "N.-Xu",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2119004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "004d652a1102cd6e3119b316cb1cbd978cb6f2be",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of estimating the 3D shape and reflectance properties of an object made of a single material from a set of calibrated views. To model the reflectance, we propose to use the View Independent Reflectance Map (VIRM), which is a representation of the joint effect of the diffuse+specular Bidirectional Reflectance Distribution Function (BRDF) and the environment illumination. The object shape is parameterized using a triangular mesh. We pose the estimation problem as minimizing the cost of matching input images, and the images synthesized using the shape and VIRM estimates. We show that by enforcing a constant value of VIRM as a global constraint, we can minimize the cost function by iterating between the VIRM and shape estimation. Experimental results on both synthetic and real objects show that our algorithm can recover both the 3D shape and the diffuse/specular reflectance information. Our algorithm does not require the light sources to be known or calibrated. The estimated VIRM can be used to predict the appearances of objects with the same material from novel viewpoints and under transformed illumination."
            },
            "slug": "Shape-and-View-Independent-Reflectance-Map-from-Yu-Xu",
            "title": {
                "fragments": [],
                "text": "Shape and View Independent Reflectance Map from Multiple Views"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The View Independent Reflectance Map (VIRM), which is a representation of the joint effect of the diffuse+specular Bidirectional Reflectance Distribution Function (BRDF) and the environment illumination, is used to model the reflectance of an object."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706280"
                        ],
                        "name": "Nathan Srebro",
                        "slug": "Nathan-Srebro",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Srebro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Srebro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658292"
                        ],
                        "name": "Andrew Cotter",
                        "slug": "Andrew-Cotter",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Cotter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Cotter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53306004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9691f67f5075bde2fd70da0135a4a70f25ef042b",
            "isKey": false,
            "numCitedBy": 2003,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and analyze a simple and effective stochastic sub-gradient descent algorithm for solving the optimization problem cast by Support Vector Machines (SVM). We prove that the number of iterations required to obtain a solution of accuracy $${\\epsilon}$$ is $${\\tilde{O}(1 / \\epsilon)}$$, where each iteration operates on a single training example. In contrast, previous analyses of stochastic gradient descent methods for SVMs require $${\\Omega(1 / \\epsilon^2)}$$ iterations. As in previously devised SVM solvers, the number of iterations also scales linearly with 1/\u03bb, where \u03bb is the regularization parameter of SVM. For a linear kernel, the total run-time of our method is $${\\tilde{O}(d/(\\lambda \\epsilon))}$$, where d is a bound on the number of non-zero features in each example. Since the run-time does not depend directly on the size of the training set, the resulting algorithm is especially suited for learning from large datasets. Our approach also extends to non-linear kernels while working solely on the primal objective function, though in this case the runtime does depend linearly on the training set size. Our algorithm is particularly well suited for large text classification problems, where we demonstrate an order-of-magnitude speedup over previous SVM learning methods."
            },
            "slug": "Pegasos:-primal-estimated-sub-gradient-solver-for-Shalev-Shwartz-Singer",
            "title": {
                "fragments": [],
                "text": "Pegasos: primal estimated sub-gradient solver for SVM"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A simple and effective stochastic sub-gradient descent algorithm for solving the optimization problem cast by Support Vector Machines, which is particularly well suited for large text classification problems, and demonstrates an order-of-magnitude speedup over previous SVM learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716704"
                        ],
                        "name": "D. Neuhoff",
                        "slug": "D.-Neuhoff",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Neuhoff",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Neuhoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 106
                            }
                        ],
                        "text": "A vector quantizer q : \u211cE \u2192 C maps a vector v \u2208 \u211cE to a codeword ck \u2208 \u211cE in the codebook C = {ck,k = 1, . . . ,K} (Gray and Neuhoff, 1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 57
                            }
                        ],
                        "text": "We address this problem using Product Quantization (PQ) (Gray and Neuhoff, 1998) which has been popularized in the computer vision field by Je\u0301gou et al (2011) for large-scale nearest neighbor search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 212653679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4810fee58d520cf61c01eb78a482b18919a9bca7",
            "isKey": false,
            "numCitedBy": 1541,
            "numCiting": 968,
            "paperAbstract": {
                "fragments": [],
                "text": "Quantization is a process that maps a continous or discrete set of values into approximations that belong to a smaller set. Quantization is a lossy: some information about the original data is lost in the process. The key to a successful quantization is therefore the selection of an error criterion \u2013 such as entropy and signal-to-noise ratio \u2013 and the development of optimal quantizers for this criterion."
            },
            "slug": "Quantization-Gray-Neuhoff",
            "title": {
                "fragments": [],
                "text": "Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The key to a successful quantization is the selection of an error criterion \u2013 such as entropy and signal-to-noise ratio \u2013 and the development of optimal quantizers for this criterion."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 27
                            }
                        ],
                        "text": "As an example, in Sa\u0301nchez and Perronnin (2011) we used FV representations with up to 512K dimensions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "In our experiments, we follow the protocol of Sa\u0301nchez and Perronnin (2011) and use half of the images for training, 50K for validation and the rest for testing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 6
                            }
                        ],
                        "text": "Jorge Sa\u0301nchez CIEM-CONICET, FaMAF, Universidad Nacional de Co\u0301rdoba, X5000HUA, Co\u0301rdoba, Argentine E-mail: jsanchez@famaf.unc.edu.ar\nFlorent Perronnin Xerox Research Centre Europe, 6 chemin de Maupertuis, 38240 Meylan, France E-mail: florent.perronnin@xrce.xerox.com\nThomas Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Sa\u0301nchez and Perronnin (2011) reported a 16.7% accuracy using FVs but without color information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 101
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al (2010), Sa\u0301nchez and Perronnin (2011)), Krizhevsky et al (2012), Le et al (2012) report a per-image accuracy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 151
                            }
                        ],
                        "text": "We compute the top-1 classification accuracy for each class and report the average per-class acuracy as is standard on this dataset (Deng et al, 2010, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 152
                            }
                        ],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 1
                            }
                        ],
                        "text": "(Sa\u0301nchez and Perronnin, 2011) reported slightly better results \u2013 74.5% top-5 accuracy \u2013 using 1Mdim FVs (with more Gaussians and spatial pyramids) but such high-dimensional features are significantly more costly than the 64K-dim features we used in the present paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 139
                            }
                        ],
                        "text": "We note that more sophisticated models have been proposed to take into account the scene geometry in the FV framework (Krapac et al, 2011, Sa\u0301nchez et al, 2012) but we will not consider such extensions in this work."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 66
                            }
                        ],
                        "text": "We first report a set of detailed experiments on PASCAL VOC 2007 (Everingham et al, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 118
                            }
                        ],
                        "text": "In Section 3, we provide a first set of experimental results on three smalland medium-scale datasets \u2013 PASCAL VOC 2007 (Everingham et al, 2007), Caltech 256 (Griffin et al, 2007) and SUN 397 (Xiao et al, 2010) \u2013 showing that the FV outperforms significantly the BoV."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 89
                            }
                        ],
                        "text": "This paper extends our previous work (Perronnin and Dance, 2007, Perronnin et al, 2010c, Sa\u0301nchez and Perronnin,\n2011) with: (1) a more detailed description of the FK framework and especially of the computation of the Fisher information matrix, (2) a more detailed analysis of the recent related work, (3) a detailed experimental validation of the proposed normalizations of the FV, (4) more experiments on several small- medium-scale datasets with state-of-theart results, (5) a theoretical analysis of PQ compression for linear classifier learning and (6) more detailed experiments on large-scale image classification with, especially, a comparison to k-NN classification."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 172
                            }
                        ],
                        "text": "It was shown to be effective both for scene recognition (Lazebnik et al, 2006) and loosely structured object recognition as demonstrated during the PASCAL VOC evaluations (Everingham et al, 2007, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": true,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71049875"
                        ],
                        "name": "M. C. Spruill",
                        "slug": "M.-C.-Spruill",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Spruill",
                            "middleNames": [
                                "Carlton"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Spruill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15302898,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c670ea405f997524e8de3dd821a502a5bc94615a",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The coordinates $x_i$ of a point $x = (x_1, x_2, \\dots, x_n)$ chosen at random according to a uniform distribution on the $\\ell_2(n)$-sphere of radius $n^{1/2}$ have approximately a normal distribution when $n$ is large. The coordinates $x_i$ of points uniformly distributed on the $\\ell_1(n)$-sphere of radius $n$ have approximately a double exponential distribution. In these and all the $\\ell_p(n),1 \\le p \\le \\infty,$ convergence of the distribution of coordinates as the dimension $n$ increases is at the rate $\\sqrt{n}$ and is described precisely in terms of weak convergence of a normalized empirical process to a limiting Gaussian process, the sum of a Brownian bridge and a simple normal process."
            },
            "slug": "Asymptotic-Distribution-of-Coordinates-on-High-Spruill",
            "title": {
                "fragments": [],
                "text": "Asymptotic Distribution of Coordinates on High Dimensional Spheres"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2738145"
                        ],
                        "name": "P. Burrascano",
                        "slug": "P.-Burrascano",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Burrascano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burrascano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 714,
                                "start": 22
                            }
                        ],
                        "text": "To support this claim Burrascano showed that, for a given value of the dispersion as measured with the `p-norm, fp is the distribution which maximizes the entropy and therefore the amount of information. Note that for p = 2, equation (29) corresponds to a Gaussian distribution. From the above and after noting that: a) FVs are high dimensional signatures, b) we rely on linear SVMs, where the similarity between samples is measured using simple dot-products, and that c) the dot-product between `2-normalized vectors relates to the `2-distance as kx yk(2)2 = 2(1 x0y), for kxk2 = kyk2 = 1, it follows that choosing p = 2 for the normalization of the FV is natural. Power normalization. In Perronnin et al (2010c), it was proposed to perform a power normalization of the form:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 10
                            }
                        ],
                        "text": "Moreover, Burrascano (1991) suggested that the `p metric is a good measure between data points if they are distributed according to a generalized Gaussian:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 10
                            }
                        ],
                        "text": "Moreover, Burrascano (1991) suggested that the `p metric is a good measure between data points if they are distributed according to a generalized Gaussian:\nfp(x) = p(1\u22121/p) 2\u0393 (1/p) exp ( \u2212|x\u2212 x0| p p ) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5761785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b96100becc2855e5fa61abcb752156e28bc5322",
            "isKey": true,
            "numCitedBy": 35,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The derivation of a supervised training algorithm for a neural network implies the selection of a norm criterion which gives a suitable global measure of the particular distribution of errors. The author addresses this problem and proposes a correspondence between error distribution at the output of a layered feedforward neural network and L(p) norms. The generalized delta rule is investigated in order to verify how its structure can be modified in order to perform a minimization in the generic L(p) norm. The particular case of the Chebyshev norm is developed and tested."
            },
            "slug": "A-norm-selection-criterion-for-the-generalized-rule-Burrascano",
            "title": {
                "fragments": [],
                "text": "A norm selection criterion for the generalized delta rule"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The author proposes a correspondence between error distribution at the output of a layered feedforward neural network and L(p) norms and investigates how the generalized delta rule can be modified in order to perform a minimization in the generic L( p) norm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 25
                            }
                        ],
                        "text": "In practice we use SIFT (Lowe, 2004) or Local Color Statistics (Clinchant et al, 2007) as descriptors computed on a dense multi-scale grid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 99
                            }
                        ],
                        "text": "In a nutshell, the BoV consists in extracting a set of local descriptors, such as SIFT descriptors (Lowe, 2004),"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 100
                            }
                        ],
                        "text": "In a nutshell, the BoV consists in extracting a set of local descriptors, such as SIFT descriptors (Lowe, 2004), in an image and in assigning each descriptor to the closest entry in a \u201cvisual vocabulary\u201d: a codebook learned offline by clustering a large set of descriptors with k-means."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 89
                            }
                        ],
                        "text": "We consider two types of patch descriptors in this work: the 128-dim SIFT descriptors of Lowe (2004) and the 96-dim Local Color Statistic (LCS) descriptors of Clinchant et al (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 89
                            }
                        ],
                        "text": "We consider two types of patch descriptors in this work: the 128-dim SIFT descriptors of Lowe (2004) and the 96-dim Local Color Statistic (LCS) descriptors of Clinchant et al (2007). In both cases, unless specified otherwise, they are reduced down to 64-dim using PCA, so as to better fit the diagonal covariance matrix assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 134
                            }
                        ],
                        "text": "Let X = {xt , t = 1, . . . ,T} be the set of D-dimensional local descriptors extracted from an image, e.g. a set of SIFT descriptors (Lowe, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 82
                            }
                        ],
                        "text": "Other works, considered a single type of descriptors, typically SIFT descriptors (Lowe, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": true,
            "numCitedBy": 25497,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079246689"
                        ],
                        "name": "Axthonv G. Oettinger",
                        "slug": "Axthonv-G.-Oettinger",
                        "structuredName": {
                            "firstName": "Axthonv",
                            "lastName": "Oettinger",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Axthonv G. Oettinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 106
                            }
                        ],
                        "text": "A vector quantizer q : \u211cE \u2192 C maps a vector v \u2208 \u211cE to a codeword ck \u2208 \u211cE in the codebook C = {ck,k = 1, . . . ,K} (Gray and Neuhoff, 1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 57
                            }
                        ],
                        "text": "We address this problem using Product Quantization (PQ) (Gray and Neuhoff, 1998) which has been popularized in the computer vision field by Je\u0301gou et al (2011) for large-scale nearest neighbor search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207762321,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "04a5241e96d0e7ac63eb44ed8cfbcdcda9df1583",
            "isKey": false,
            "numCitedBy": 1598,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Since at most T of these equations can come from (7), at least (m T) of them come from (8\u2019). Thus, for the distribution (PI\u2019, . . . , p,\u2018), at most T of the probabilities are nonzero. The proof of our contention now follows by letting plo, . . . , 10~0 in the above argument be a distribution for which channel capacity is attained. It should be remarked that this proof provides (via the Simplex Method of linear programming) a means for reducing any transmitter with more than r symbols, to another, equally good or better, with at most T symbols. For a discussion of the possibility of reducing the number of receiver symbols, see Feinstein.5"
            },
            "slug": "IEEE-TRANSACTIONS-ON-INFORMATION-THEORY-Oettinger",
            "title": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON INFORMATION THEORY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102729464"
                        ],
                        "name": "D. Song",
                        "slug": "D.-Song",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50179125"
                        ],
                        "name": "A. K. Gupta",
                        "slug": "A.-K.-Gupta",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gupta",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K. Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If u \u223cUp,E , then a closed form solution for the marginals over the `p-normalized coordinates ui = ui/\u2016u\u2016p, is given in Song and Gupta (1997):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 116
                            }
                        ],
                        "text": "If u\u223cUp,E , then a closed form solution for the marginals over the `p-normalized coordinates ui = ui/\u2016u\u2016p, is given in Song and Gupta (1997):\ngp,E(ui) = p\u0393 (E/p)\n2\u0393 (1/p)\u0393 ((E\u22121)/p) (1\u2212|ui|p)(E\u22121)/p\u22121 (28)\nwith ui \u2208 [\u22121,1]\nFor p = 2, as the dimensionality E grows, this distribution converges to a\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119015406,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fb356f861f356816130c246dae462734f1ef8a79",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the Lp-norm uniform distribution, which is a generalization of the uniform distribution studied by Cambanis, Huang, and Simon (1981), is defined for any p > 0. Then its marginal distributions and order statistics are studied."
            },
            "slug": "_{}-norm-uniform-distribution-Song-Gupta",
            "title": {
                "fragments": [],
                "text": "_{}-norm uniform distribution"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698617"
                        ],
                        "name": "O. Bousquet",
                        "slug": "O.-Bousquet",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bousquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bousquet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A significant benefit of linear classifiers is that they are very efficient to evaluate and efficient to learn (linear in the number of training samples) using techniques such as stochastic gradient descent (SGD) (Bottou and Bousquet 2007; Shalev-Shwartz et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7431525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5936754b5762260bf102ac95d7b26cfc9d31956a",
            "isKey": false,
            "numCitedBy": 1485,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems. Small-scale learning problems are subject to the usual approximation-estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways."
            },
            "slug": "The-Tradeoffs-of-Large-Scale-Learning-Bottou-Bousquet",
            "title": {
                "fragments": [],
                "text": "The Tradeoffs of Large Scale Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms and shows distinct tradeoffs for the case of small-scale and large-scale learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102729464"
                        ],
                        "name": "D. Song",
                        "slug": "D.-Song",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50179125"
                        ],
                        "name": "A. K. Gupta",
                        "slug": "A.-K.-Gupta",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gupta",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K. Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 125
                            }
                        ],
                        "text": "If u\u223cUp,E , then a closed form solution for the marginals over the `p-normalized coordinates ui = ui/\u2016u\u2016p, is given in Song and Gupta (1997):\ngp,E(ui) = p\u0393 (E/p)\n2\u0393 (1/p)\u0393 ((E\u22121)/p) (1\u2212|ui|p)(E\u22121)/p\u22121 (28)\nwith ui \u2208 [\u22121,1]\nFor p = 2, as the dimensionality E grows, this distribution converges to a\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120162214,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7a22b085d149f4da6b7ce4cdcbb346e7f9941101",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the Lp-norm uniform distribution, which is a generalization of the uniform distribution studied by Cambanis, Huang, and Simon (1981), is defined for any p > 0. Then its marginal distributions and order statistics are studied."
            },
            "slug": "Lp-NORM-UNIFORM-DISTRIBUTION-Song-Gupta",
            "title": {
                "fragments": [],
                "text": "Lp-NORM UNIFORM DISTRIBUTION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152591573"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15974963"
                        ],
                        "name": "A. F. Smith",
                        "slug": "A.-F.-Smith",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. F. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580190"
                        ],
                        "name": "U. Makov",
                        "slug": "U.-Makov",
                        "structuredName": {
                            "firstName": "Udi",
                            "lastName": "Makov",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Makov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, Fr can be seen as the amount of \u201cinformation\u201d lost by not knowing the true mixture component generating each of the x\u2019s Titterington et al. (1985). By requiring the distribution of the \u03b3x (k) to be \u201csharply peaked\u201d we are making the approximation zk \u2248 \u03b3x (k)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Uijlings et al. (2009) reports 59."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In what follows, we choose u\u03bb to be a GMM as one can approximate with arbitrary precision any continuous distribution with a GMM (Titterington et al. 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124992180,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "54a1f6ab4cc6cb749c2b8d15c1dd3449e072362f",
            "isKey": true,
            "numCitedBy": 3447,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical Problems. Applications of Finite Mixture Models. Mathematical Aspects of Mixtures. Learning About the Parameters of a Mixture. Learning About the Components of a Mixture. Sequential Problems and Procedures."
            },
            "slug": "Statistical-analysis-of-finite-mixture-Titterington-Smith",
            "title": {
                "fragments": [],
                "text": "Statistical analysis of finite mixture distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This course discusses Mathematical Aspects of Mixtures, Sequential Problems and Procedures, and Applications of Finite Mixture Models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2623914"
                        ],
                        "name": "C. H. Bennett",
                        "slug": "C.-H.-Bennett",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bennett",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756931"
                        ],
                        "name": "P. Shor",
                        "slug": "P.-Shor",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Shor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Shor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14380552,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "d53d4c726e232060e10a70cb9b0e5f666741e6ef",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We survey the field of quantum information theory. In particular, we discuss the fundamentals of the field, source coding, quantum error-correcting codes, capacities of quantum channels, measures of entanglement and quantum cryptography."
            },
            "slug": "Quantum-Information-Theory-Bennett-Shor",
            "title": {
                "fragments": [],
                "text": "Quantum Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The fundamentals of the field, source coding, quantum error-correcting codes, capacities of quantum channels, measures of entanglement and quantum cryptography are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 116
                            }
                        ],
                        "text": "This is to be compared with the winning NEC-UIUC-Rutgers system which obtained 71.8% accuracy during the challenge (Berg et al, 2010), see also (Lin et al, 2011)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 40
                            }
                        ],
                        "text": "1.4M images of the ILSVRC 2010 dataset (Berg et al, 2010) would take almost 3TBs, and storing the signatures for the approx."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "In Section 5, we present results on two large datasets, namely ILSVRC 2010 (Berg et al, 2010) (1K classes and approx."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 13
                            }
                        ],
                        "text": "ILSVRC 2010 (Berg et al, 2010) contains approx."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ILSVRC 2010"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 234
                            }
                        ],
                        "text": "While in our experience, we have never observed a drastic influence of the initialization on the end result, we\n10 Available at: http://htk.eng.cam.ac.uk/.\nstrongly advise the use of an iterative process as suggested for instance in (Young et al, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "HTK suggest a value \u03b1 = 0.01."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 139
                            }
                        ],
                        "text": "For a public GMM implementation and for more details on how to train and test GMMs, we refer the reader to the excellent HMM ToolKit (HTK) Young et al. (2002)10."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 189
                            }
                        ],
                        "text": "While in our experience, we have never observed a drastic influence of the initialization on the end result, we strongly advise the use of an iterative process as suggested for instance in Young et al. (2002). This iterative procedure consists in starting with a single Gaussian (for which a closed-form formula exists), splitting all Gaussians by slightly perturbing the mean and then re-estimating the GMM parameters with EM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 139
                            }
                        ],
                        "text": "For a public GMM implementation and for more details on how to train and test GMMs, we refer the reader to the excellent HMM ToolKit (HTK) Young et al (2002)10."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The HTK book (version 3.2.1)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "When a signature is passed to the SGD algorithm, it is decompressed on the fly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "4.3 SGD Learning with quantization\nWe propose to learn the linear classifiers directly in the uncompressed high-dimensional space rather than in the space of codebook indices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "As for the SVM training, we also use SGD to train onevs-rest linear SVM classifiers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "We therefore integrate the decompression algorithm in the SGD training code."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "As for learning, we employ linear SVMs and train them using Stochastic Gradient Descent (SGD) (Bottou, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "The major advantage of our SGDbased approach is that we decompress only one sample at a time, and typically do not even need to access the complete dataset to obtain good results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 208
                            }
                        ],
                        "text": "A significant benefit of linear classifiers is that they are very efficient to evaluate and efficient to learn (linear in the number of training samples) using techniques such as Stochastic Gradient Descent (SGD) (Bottou and Bousquet, 2007, Shalev-Shwartz et al, 2007)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "Finally learning the 20 SVM classifiers using the SGD training takes about 2% of the time and classification of the test images is in the order of seconds (0.1% of the total computational cost)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "Subsequently, we explain how PQ encoding / decoding can be combined with Stochastic Gradient Descent (SGD) learning for large-scale optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "While the proposed approach combines on-the-fly decompression with SGD learning, an alternative has been recently proposed by Vedaldi and Zisserman (2012) which avoids the decompression step and which leverages bundle methods with a non-isotropic regularizer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "In Section 4, we present PQ compression, explain how it can be combined with largescale SGD learning and provide a theoretical analysis of why such a compression algorithm makes sense when learning a linear classifier."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic gradient descent. http://leon.bottou.org/ projects/sgd"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "When a signature is passed to the SGD algorithm, it is decompressed on the fly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "4.3 SGD Learning with quantization\nWe propose to learn the linear classifiers directly in the uncompressed high-dimensional space rather than in the space of codebook indices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "As for the SVM training, we also use SGD to train onevs-rest linear SVM classifiers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "We therefore integrate the decompression algorithm in the SGD training code."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "As for learning, we employ linear SVMs and train them using Stochastic Gradient Descent (SGD) (Bottou, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "The major advantage of our SGDbased approach is that we decompress only one sample at a time, and typically do not even need to access the complete dataset to obtain good results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 64
                            }
                        ],
                        "text": "As for learning, we employ linear SVMs and train them using SGD (Bottou 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 208
                            }
                        ],
                        "text": "A significant benefit of linear classifiers is that they are very efficient to evaluate and efficient to learn (linear in the number of training samples) using techniques such as Stochastic Gradient Descent (SGD) (Bottou and Bousquet, 2007, Shalev-Shwartz et al, 2007)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "Finally learning the 20 SVM classifiers using the SGD training takes about 2% of the time and classification of the test images is in the order of seconds (0.1% of the total computational cost)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "Subsequently, we explain how PQ encoding / decoding can be combined with Stochastic Gradient Descent (SGD) learning for large-scale optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "While the proposed approach combines on-the-fly decompression with SGD learning, an alternative has been recently proposed by Vedaldi and Zisserman (2012) which avoids the decompression step and which leverages bundle methods with a non-isotropic regularizer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "In Section 4, we present PQ compression, explain how it can be combined with largescale SGD learning and provide a theoretical analysis of why such a compression algorithm makes sense when learning a linear classifier."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic gradient descent. Retrieved from http:// leon.bottou.org/projects/sgd"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "When a signature is passed to the SGD algorithm, it is decompressed on the fly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "4.3 SGD Learning with quantization\nWe propose to learn the linear classifiers directly in the uncompressed high-dimensional space rather than in the space of codebook indices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "As for the SVM training, we also use SGD to train onevs-rest linear SVM classifiers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "We therefore integrate the decompression algorithm in the SGD training code."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "As for learning, we employ linear SVMs and train them using Stochastic Gradient Descent (SGD) (Bottou, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Given the size of these datasets, at each pass of the SGD routine we sample all positives but only a random subset of negatives (Perronnin et al, 2012, Sa\u0301nchez and Perronnin, 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "The major advantage of our SGDbased approach is that we decompress only one sample at a time, and typically do not even need to access the complete dataset to obtain good results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 208
                            }
                        ],
                        "text": "A significant benefit of linear classifiers is that they are very efficient to evaluate and efficient to learn (linear in the number of training samples) using techniques such as Stochastic Gradient Descent (SGD) (Bottou and Bousquet, 2007, Shalev-Shwartz et al, 2007)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "Finally learning the 20 SVM classifiers using the SGD training takes about 2% of the time and classification of the test images is in the order of seconds (0.1% of the total computational cost)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "Subsequently, we explain how PQ encoding / decoding can be combined with Stochastic Gradient Descent (SGD) learning for large-scale optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "While the proposed approach combines on-the-fly decompression with SGD learning, an alternative has been recently proposed by Vedaldi and Zisserman (2012) which avoids the decompression step and which leverages bundle methods with a non-isotropic regularizer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "In Section 4, we present PQ compression, explain how it can be combined with largescale SGD learning and provide a theoretical analysis of why such a compression algorithm makes sense when learning a linear classifier."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic gradient descent. Retrieved from http"
            },
            "venue": {
                "fragments": [],
                "text": "Stochastic gradient descent. Retrieved from http"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1873,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation. Maji and Berg (2009) and Wang et al. (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples. Vedaldi and Zisserman (2010) and Perronnin et al. (2010b) subsequently generalized this principle to any additive classifier. Attempts have been made also to go beyond additive classifiers (Perronnin et al. 2010b; Sreekanth et al. 2010). Another line of research consists in computing BoV representations which are directly amenable to costless linear classification. Boureau et al. (2010), Wang et al. (2010) and Yang et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1492,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation. Maji and Berg (2009) and Wang et al. (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples. Vedaldi and Zisserman (2010) and Perronnin et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 147
                            }
                        ],
                        "text": "Several systems are based on the combination of multiple channels corresponding to many different features including (Bergamo and Torresani, 2012, Boiman et al, 2008, Gehler and Nowozin, 2009, VanGemert et al, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 84
                            }
                        ],
                        "text": "Second, the descriptor quantization is a lossy process as underlined in the work of Boiman et al. (2008). In this work, we propose an alternative patch aggregation mechanism based on the Fisher Kernel (FK) principle of Jaakkola and Haussler (1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 84
                            }
                        ],
                        "text": "Second, the descriptor quantization is a lossy process as underlined in the work of Boiman et al. (2008). In this work, we propose an alternative patch aggregation mechanism based on the Fisher Kernel (FK) principle of Jaakkola and Haussler (1998). The FK combines the benefits of generative and discriminative approaches to pattern classification by deriving a kernel from a generative model of the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1337,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation. Maji and Berg (2009) and Wang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1360,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation. Maji and Berg (2009) and Wang et al. (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 84
                            }
                        ],
                        "text": "Second, the descriptor quantization is a lossy process as underlined in the work of Boiman et al (2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1150,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1853,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation. Maji and Berg (2009) and Wang et al. (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples. Vedaldi and Zisserman (2010) and Perronnin et al. (2010b) subsequently generalized this principle to any additive classifier. Attempts have been made also to go beyond additive classifiers (Perronnin et al. 2010b; Sreekanth et al. 2010). Another line of research consists in computing BoV representations which are directly amenable to costless linear classification. Boureau et al. (2010), Wang et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1897,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation. Maji and Berg (2009) and Wang et al. (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples. Vedaldi and Zisserman (2010) and Perronnin et al. (2010b) subsequently generalized this principle to any additive classifier. Attempts have been made also to go beyond additive classifiers (Perronnin et al. 2010b; Sreekanth et al. 2010). Another line of research consists in computing BoV representations which are directly amenable to costless linear classification. Boureau et al. (2010), Wang et al. (2010) and Yang et al. (2009b) showed that replacing the average pooling stage in the BoV computation by a max-pooling yielded excellent results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1521,
                                "start": 24
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al. 2006). The focus in the image classification community was initially on developing classification systems which would yield the best possible accuracy fairly independently of their cost as examplified in the PASCAL VOC competitions (Everingham et al. 2010). The winners of the 2007 and 2008 competitions used a similar paradigm: many types of low-level local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and non-linear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al. 2010; Zhang et al. 2007). The use of many channels and non-linear SVMs\u2014whose training cost scales somewhere between quadratically and cubically in the number of training samples\u2014was made possible by the modest size of the available databases. In recent years only the computational cost has become a central issue in image classification and object detection. Maji et al. (2008) showed that the runtime cost of an intersection kernel (IK) SVM could be made independent of the number of support vectors with a negligible performance degradation. Maji and Berg (2009) and Wang et al. (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples. Vedaldi and Zisserman (2010) and Perronnin et al. (2010b) subsequently generalized this principle to any additive classifier."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In defense of nearestneighbor based image classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 20
                            }
                        ],
                        "text": "Le et al (2012) and Krizhevsky et al (2012) also report results on the same subset of 10K classes using deep architectures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 64
                            }
                        ],
                        "text": "Le\net al (2012) reports a top-1 per-image accuracy of 19.2% and Krizhevsky et al (2012) of 32.6%.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 23
                            }
                        ],
                        "text": "In a very recent work, Krizhevsky et al (2012) reported significantly better results using a deep learning network."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 132
                            }
                        ],
                        "text": "9 While it is standard practice to report per-class accuracy on this dataset (see Deng et al (2010), Sa\u0301nchez and Perronnin (2011)), Krizhevsky et al (2012), Le et al (2012) report a per-image accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 79
                            }
                        ],
                        "text": "This was clarified through a personal correspondence with the first authors of Krizhevsky et al (2012), Le et al (2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 3
                            }
                        ],
                        "text": "In (Krizhevsky et al. 2012) the network consists of six convolutional layers plus three fully connected layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 4
                            }
                        ],
                        "text": "In (Krizhevsky et al, 2012) the network consists of 6 convolutional layers plus three fully connected layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image classification with deep convolutional neural networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 9
                            }
                        ],
                        "text": "Finally, Guillaumin et al (2010) reports 66.7% but assuming that one has access to the image tags."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multimodal semisupervised learning for image classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 158
                            }
                        ],
                        "text": "We consider two types of patch descriptors in this work: the 128dim SIFT descriptors of Lowe (2004) and the 96-dim local color statistic (LCS) descriptors of Clinchant et al. (2007). In both cases, unless specified otherwise, they are reduced down to 64-dim using PCA, so as to better fit the diagonal covariance matrix assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 159
                            }
                        ],
                        "text": "We consider two types of patch descriptors in this work: the 128-dim SIFT descriptors of Lowe (2004) and the 96-dim Local Color Statistic (LCS) descriptors of Clinchant et al (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "In practice we use SIFT (Lowe, 2004) or Local Color Statistics (Clinchant et al, 2007) as descriptors computed on a dense multi-scale grid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 62
                            }
                        ],
                        "text": "In practice we use SIFT (Lowe 2004) or local color statistics (Clinchant et al. 2007) as descriptors computed on a dense multi-scale grid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XRCEs participation to imageval. In: ImageEval Workshop at CVIR"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143698811"
                        ],
                        "name": "A. Cohen",
                        "slug": "A.-Cohen",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125431157,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3ef90a62796c6c8c88439bd116ca7472e96254b7",
            "isKey": false,
            "numCitedBy": 670,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Finite-Mixture-Distributions-Cohen",
            "title": {
                "fragments": [],
                "text": "Finite Mixture Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409749316"
                        ],
                        "name": "S. Ben-David",
                        "slug": "S.-Ben-David",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Ben-David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ben-David"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 124552244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f00b80041d4c562529f4c06cb2de3070024ff06",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-Gradient-Descent-Shalev-Shwartz-Ben-David",
            "title": {
                "fragments": [],
                "text": "Stochastic Gradient Descent"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 127974963,
            "fieldsOfStudy": [],
            "id": "f95dc8050e55c4b303c62e0527415bccbd940064",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finite Mixture Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 172
                            }
                        ],
                        "text": "It was shown to be effective both for scene recognition (Lazebnik et al, 2006) and loosely structured object recognition as demonstrated during the PASCAL VOC evaluations (Everingham et al, 2007, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713807"
                        ],
                        "name": "Gunnar Evermann",
                        "slug": "Gunnar-Evermann",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Evermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar Evermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171861"
                        ],
                        "name": "Thomas Hain",
                        "slug": "Thomas-Hain",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066474202"
                        ],
                        "name": "Dan J. Kershaw",
                        "slug": "Dan-J.-Kershaw",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Kershaw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan J. Kershaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1938928"
                        ],
                        "name": "G. Moore",
                        "slug": "G.-Moore",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Moore",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2965187"
                        ],
                        "name": "D. Ollason",
                        "slug": "D.-Ollason",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ollason",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ollason"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69013545"
                        ],
                        "name": "Valtchev",
                        "slug": "Valtchev",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Valtchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valtchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60164858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "135328a4e2a33e17949b495ccd5fbdc87b2a7e3d",
            "isKey": false,
            "numCitedBy": 1072,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-HTK-book-version-3.4-Young-Evermann",
            "title": {
                "fragments": [],
                "text": "The HTK book version 3.4"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54566318,
            "fieldsOfStudy": [],
            "id": "9a3aba927b80c40e5006118f2fb763e28ee7f28f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient Additive Kernels via Explicit Feature Maps"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145930529"
                        ],
                        "name": "H. Nagaoka",
                        "slug": "H.-Nagaoka",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Nagaoka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagaoka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 41
                            }
                        ],
                        "text": "From the theory of information geometry (Amari and Nagaoka, 2000), a parametric family of distributions U = {u\u03bb ,\u03bb \u2208\u039b} can be regarded as a Riemanninan manifold M\u039b with a local metric given by the Fisher Information Matrix (FIM) F\u03bb \u2208 RM\u00d7M:\nF\u03bb = Ex\u223cu\u03bb [ Gx\u03bb G x \u03bb \u2032] ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 116976027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "617111ed3746c4304c87b188ba155b160e9f082e",
            "isKey": false,
            "numCitedBy": 2368,
            "numCiting": 201,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Methods-of-information-geometry-Amari-Nagaoka",
            "title": {
                "fragments": [],
                "text": "Methods of information geometry"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XRCEs participation to imageval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 41
                            }
                        ],
                        "text": "From the theory of information geometry (Amari and Nagaoka, 2000), a parametric family of distributions U = {u\u03bb ,\u03bb \u2208\u039b} can be regarded as a Riemanninan manifold M\u039b with a local metric given by the Fisher Information Matrix (FIM) F\u03bb \u2208 RM\u00d7M:\nF\u03bb = Ex\u223cu\u03bb [ Gx\u03bb G x \u03bb \u2032] ."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methods of Information Geometry, Translations of Mathematical monographs , vol 191"
            },
            "venue": {
                "fragments": [],
                "text": "Methods of Information Geometry, Translations of Mathematical monographs , vol 191"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Mensink Inteligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH, Amsterdam, The Netherlands E-mail: thomas.mensink@uva.nl\nJakob Verbeek LEAR Team, INRIA Grenoble, 655 Avenue de l\u2019Europe, 38330 Montbonnot, France E-mail: jakob.verbeek@inria.fr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 156
                            }
                        ],
                        "text": "In Section 3, we provide a first set of experimental results on three smalland medium-scale datasets \u2013 PASCAL VOC 2007 (Everingham et al, 2007), Caltech 256 (Griffin et al, 2007) and SUN 397 (Xiao et al, 2010) \u2013 showing that the FV outperforms significantly the BoV."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 16
                            }
                        ],
                        "text": "The baseline of Griffin et al (2007) is a reimplementation of the spatial pyramid BoV of Lazebnik et al (2006)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Caltech-256 object category dataset.. California Institute of Technology"
            },
            "venue": {
                "fragments": [],
                "text": "Caltech-256 object category dataset.. California Institute of Technology"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ImageNet10K"
            },
            "venue": {
                "fragments": [],
                "text": "ImageNet10K"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "23 4.3 SGD Learning with quantization"
            },
            "venue": {
                "fragments": [],
                "text": "23 4.3 SGD Learning with quantization"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Classification with the Fisher Vector: Theory and Practice 23"
            },
            "venue": {
                "fragments": [],
                "text": "Image Classification with the Fisher Vector: Theory and Practice 23"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 84
                            }
                        ],
                        "text": "For p = 2, as the dimensionality E grows, this distribution converges to a Gaussian (Spruill, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 270
                            }
                        ],
                        "text": "\u2026form solution for the marginals over the `p-normalized coordinates ui = ui/\u2016u\u2016p, is given in Song and Gupta (1997):\ngp,E(ui) = p\u0393 (E/p)\n2\u0393 (1/p)\u0393 ((E\u22121)/p) (1\u2212|ui|p)(E\u22121)/p\u22121 (28)\nwith ui \u2208 [\u22121,1]\nFor p = 2, as the dimensionality E grows, this distribution converges to a Gaussian (Spruill, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Asymptotic distribution of coordinates on"
            },
            "venue": {
                "fragments": [],
                "text": "American Mathematical Society,"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XRCEs participation to imageval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector quantization and product quantization"
            },
            "venue": {
                "fragments": [],
                "text": "Vector quantization and product quantization"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 139
                            }
                        ],
                        "text": "We note that more sophisticated models have been proposed to take into account the scene geometry in the FV framework (Krapac et al, 2011, Sa\u0301nchez et al, 2012) but we will not consider such extensions in this work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling the spatial lay"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Saint Ismier Cedex Publisher Inria Domaine de Voluceau -Rocquencourt BP 105 -78153 Le Chesnay Cedex inria"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 159
                            }
                        ],
                        "text": "We consider two types of patch descriptors in this work: the 128-dim SIFT descriptors of Lowe (2004) and the 96-dim Local Color Statistic (LCS) descriptors of Clinchant et al (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "In practice we use SIFT (Lowe, 2004) or Local Color Statistics (Clinchant et al, 2007) as descriptors computed on a dense multi-scale grid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XRCE\u2019s participation to imageval. In: ImageEval Workshop at CVIR"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 132
                            }
                        ],
                        "text": "There have been several extensions of this popular framework including the use of better coding techniques based on soft assignment (Farquhar et al. 2005; Perronnin et al. 2006; VanGemert et al. 2010; Winn et al. 2005) or sparse coding (Boureau et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 24
                            }
                        ],
                        "text": "Indeed, in the soft-BoV (Farquhar et al. 2005; Perronnin et al. 2006; VanGemert et al. 2010; Winn et al. 2005), the average number of assignments to Gaussian k can be computed as:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 181
                            }
                        ],
                        "text": "In the computer vision literature, a GMM which models the generation process of local descriptors in any image has been referred to as a universal (probabilistic) visual vocabulary (Perronnin et al. 2006; Winn et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object categorization by learned visual dictionary"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 25
                            }
                        ],
                        "text": "Maji and Berg (2009) and Wang et al (2009) then proposed efficient algorithms to learn IKSVMs in a time linear in the number of training samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 275
                            }
                        ],
                        "text": "For instance, as of today, ImageNet1 consists of more than 14M images of 22K concepts (Deng et al, 2009) and Flickr contains thousands of groups2 \u2013 some of which with hundreds of thousands of pictures \u2013 which can be exploited to learn object classifiers (Perronnin et al, 2010c, Wang et al, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning image similarity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 143
                            }
                        ],
                        "text": "In both cases, unless specified otherwise, they are reduced down to 64-dim using PCA, so as to better fit the diagonal covariance matrix assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 41
                            }
                        ],
                        "text": "From the theory of information geometry (Amari and Nagaoka, 2000), a parametric family of distributions U = {u\u03bb ,\u03bb \u2208\u039b} can be regarded as a Riemanninan manifold M\u039b with a local metric given by the Fisher Information Matrix (FIM) F\u03bb \u2208 RM\u00d7M:\nF\u03bb = Ex\u223cu\u03bb [ Gx\u03bb G x \u03bb \u2032] ."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methods of information geometry , translations of mathematical monographs"
            },
            "venue": {
                "fragments": [],
                "text": "Methods of information geometry , translations of mathematical monographs"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 250
                            }
                        ],
                        "text": "\u2026used a similar paradigm: many types of lowlevel local features are extracted (referred to as \u201cchannels\u201d), one BoV histogram is computed for each channel and nonlinear kernel classifiers such as \u03c72-kernel SVMs are used to perform classification (van de Sande et al, 2010, Zhang et al, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluating color descriptors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Boureau et al (2010), Wang et al (2010), Yang et al (2009b) showed that replacing the average pooling stage in the BoV computation by a max-pooling yielded excellent results."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 23
                            }
                        ],
                        "text": "2005) or sparse coding (Boureau et al. 2010; Wang et al. 2010; Yang et al. 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of the image (Lazebnik et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 131
                            }
                        ],
                        "text": "\u2026based on soft assignment (Farquhar et al, 2005, Perronnin et al, 2006, VanGemert et al, 2010, Winn et al, 2005) or sparse coding (Boureau et al, 2010, Wang et al, 2010, Yang et al, 2009b) and the use of spatial pyramids to take into account some aspects of the spatial layout of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning midlevel features for recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 55,
            "methodology": 54,
            "result": 13
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 111,
        "totalPages": 12
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-Classification-with-the-Fisher-Vector:-Theory-S\u00e1nchez-Perronnin/d4cede3acfd94fccc927519e04384a8debfec705?sort=total-citations"
}