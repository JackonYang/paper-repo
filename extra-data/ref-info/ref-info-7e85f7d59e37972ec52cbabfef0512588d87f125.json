{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 82
                            }
                        ],
                        "text": "Preliminary reports of this material appeared in Tenenbaum and Freeman (1997) and Freeman and Tenenbaum (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5258674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a6b10ab0dddcfbd10e16b4219086a875198b15c",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In many vision problems, we want to infer two (or more) hidden factors which interact to produce our observations. We may want to disentangle illuminant and object colors in color constancy; rendering conditions from surface shape in shape-from-shading; face identity and head pose in face recognition; or font and letter class in character recognition. We refer to these two factors generically as \"style\" and \"content\". Bilinear models offer a powerful framework for extracting the two-factor structure of a set of observations, and are familiar in computational vision from several well-known lines of research. This paper shows how bilinear models can be used to learn the style-content structure of a pattern analysis or synthesis problem, which can then be generalized to solve related tasks using different styles and/or content. We focus on three tasks: extrapolating the style of data to unseen content classes, classifying data with known content under a novel style, and translating data from novel content classes and style to a known style or content. We show examples from color constancy, face pose estimation, shape-from-shading, typography and speech."
            },
            "slug": "Learning-bilinear-models-for-two-factor-problems-in-Freeman-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Learning bilinear models for two-factor problems in vision"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper shows how bilinear models can be used to learn the style-content structure of a pattern analysis or synthesis problem, which can then be generalized to solve related tasks using different styles and/or content."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Preliminary reports of this material appeared in  Tenenbaum and Freeman (1997)  and Freeman and Tenenbaum (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 49
                            }
                        ],
                        "text": "Preliminary reports of this material appeared in Tenenbaum and Freeman (1997) and Freeman and Tenenbaum (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2209131,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa236a1ef29c6632fd3aebdfcbfdb04d945e48d7",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek to analyze and manipulate two factors, which we call style and content, underlying a set of observations. We fit training data with bilinear models which explicitly represent the two-factor structure. These models can adapt easily during testing to new styles or content, allowing us to solve three general tasks: extrapolation of a new style to unobserved content; classification of content observed in a new style; and translation of new content observed in a new style. For classification, we embed bilinear models in a probabilistic framework, Separable Mixture Models (SMMs), which generalizes earlier work on factorial mixture models [7, 3]. Significant performance improvement on a benchmark speech dataset shows the benefits of our approach."
            },
            "slug": "Separating-Style-and-Content-Tenenbaum-Freeman",
            "title": {
                "fragments": [],
                "text": "Separating Style and Content"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Blinear models are fitted with bilinear models which explicitly represent the two-factor structure, allowing them to solve three general tasks: extrapolation of a new style to unobserved content; classification of content observed in a newstyle; and translation of new content observation in anew style."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889729"
                        ],
                        "name": "T. Polk",
                        "slug": "T.-Polk",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Polk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Polk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704633"
                        ],
                        "name": "M. Farah",
                        "slug": "M.-Farah",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Farah",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Farah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 267
                            }
                        ],
                        "text": "\u2026and abstraction in typography have been restricted to artificial grid-based fonts, for which the grid elements provide a reasonable distributed representation (Hofstadter, 1995; Grebert et al., 1992), or even simpler \u201cgrandmother cell\u201d representations of each letter (Polk & Farah, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Previous models of extrapolation and abstraction in typography have been restricted to artificial grid-based fonts, for which the grid elements provide a reasonable distributed representation (Hofstadter, 1995; Grebert et al., 1992), or even simpler \u201cgrandmother cell\u201d representations of each letter ( Polk & Farah, 1997 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1369453,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bbcd352d939998067647bb0c861d2801310480d7",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "letter identities (ALIs) are an early representation in visual word recognition that are specific to written language. They do not reflect visual or phonological features, but rather encode the identities of letters independent of case, font, sound, and so forth. How could the visual system come to develop such a representation? We propose that because many letters look similar regardless of case, font, and other characteristics, these provide common contexts for visually dissimilar uppercase and lowercase forms of other letters (e.g., e between k and y in key and E in the visually similar context K-Y). Assuming that the distribution of words' relative frequencies is comparable in upper and lowercase (that just as key is more frequent than pew, KEY is more frequent than PEW), these common contexts will also be similarly distributed in the two cases. We show how this statistical regularity could lead Hebbian learning to produce ALIs in a competitive architecture. We present a self-organizing artificial neural network that illustrates this idea and produces ALIs when presented with the most frequent words from a beginning reading corpus, as well as with artificial input."
            },
            "slug": "A-Simple-Common-Contexts-Explanation-for-the-of-Polk-Farah",
            "title": {
                "fragments": [],
                "text": "A Simple Common Contexts Explanation for the Development of Abstract Letter Identities"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A self-organizing artificial neural network is presented that illustrates this idea and produces ALIs when presented with the most frequent words from a beginning reading corpus, as well as with artificial input."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145771244"
                        ],
                        "name": "Andrew D. Wilson",
                        "slug": "Andrew-D.-Wilson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Wilson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7469544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d838b7e02ecfafdd1ed81ac0f70d9996b4bdf20",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for the representation, recognition, and interpretation of parameterized gesture is presented. By parameterized gesture we mean gestures that exhibit a systematic spatial variation; one example is a point gesture where the relevant parameter is the two-dimensional direction. Our approach is to extend the standard hidden Markov model method of gesture recognition by including a global parametric variation in the output probabilities of the HMM states. Using a linear model of dependence, we formulate an expectation-maximization (EM) method for training the parametric HMM. During testing, a similar EM algorithm simultaneously maximizes the output likelihood of the PHMM for the given sequence and estimates the quantifying parameters. Using visually derived and directly measured three-dimensional hand position measurements as input, we present results that demonstrate the recognition superiority of the PHMM over standard HMM techniques, as well as greater robustness in parameter estimation with respect to noise in the input features. Finally, we extend the PHMM to handle arbitrary smooth (nonlinear) dependencies. The nonlinear formulation requires the use of a generalized expectation-maximization (GEM) algorithm for both training and the simultaneous recognition of the gesture and estimation of the value of the parameter. We present results on a pointing gesture, where the nonlinear approach permits the natural spherical coordinate parameterization of pointing direction."
            },
            "slug": "Parametric-Hidden-Markov-Models-for-Gesture-Wilson-Bobick",
            "title": {
                "fragments": [],
                "text": "Parametric Hidden Markov Models for Gesture Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The approach is to extend the standard hidden Markov model method of gesture recognition by including a global parametric variation in the output probabilities of the HMM states by forming an expectation-maximization (EM) method for training the parametric HMM."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Cambridge, MA 02139, U.S.A."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 63
                            }
                        ],
                        "text": "Note that the basis images for each pose look like eigenfaces (Turk & Pentland, 1991) in the appropriate style of each pose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "The original work on eigenfaces (Kirby & Sirovich, 1990; Turk & Pentland, 1991) showed that images of many different faces taken under fixed lighting and viewpoint conditions occupy a low-dimensional linear subspace of pixel space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "Here the basis vector interpretation of the wijk terms is most natural, by analogy to the well-known work on eigenfaces (Kirby & Sirovich, 1990; Turk & Pentland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 86
                            }
                        ],
                        "text": "A perceptual system observes a training set of data in multiple styles and content classes and is then presented with incomplete data in an unfamiliar style, missing either content labels (see Figure 1A) or whole observations (see Figure 1B) or both (see Figure 1C)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": true,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 19
                            }
                        ],
                        "text": "Subsequent work by Hallinan (1994) established the complementary result that images of a single face taken under many different lighting conditions also occupy a low-dimensional linear subspace."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46324024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "236c132eda073ad7e80fcc45a248ac2baea9a786",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "When recognizing a fixed object from a fixed viewpoint, the dominant source of variation in image intensity is lighting changes. We propose a low-dimensional model for human faces that can both synthesize a face image when given lighting conditions and can estimate lighting conditions when given a face image. The model can handle non-Lambertian and self-shadowing surfaces such as faces because it does not make any assumptions about either the surface geometry or bidirectional reflectance function. The model can be adapted to handle any arbitrary lighting condition, and is easily extendable to any other viewpoint or to any other object.<<ETX>>"
            },
            "slug": "A-low-dimensional-representation-of-human-faces-for-Hallinan",
            "title": {
                "fragments": [],
                "text": "A low-dimensional representation of human faces for arbitrary lighting conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A low-dimensional model for human faces is proposed that can both synthesize a face image when given lighting conditions and can estimate lighting conditions when given a face images."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 139
                            }
                        ],
                        "text": "\u2026by guest on 17 May 2021\nWhile the general problem of separating shape, texture, and illumination features in an image is underdetermined (Barrow & Tenenbaum, 1978), here the bilinear model learned during training provides sufficient constraint to approximately recover both face and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14892007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd580fad7a14f93d6d59765a5fe91974e2653281",
            "isKey": false,
            "numCitedBy": 922,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We suggest that an appropriate role of early visual processing is to describe a scene in terms of intrinsic (vertical) characteristics -- such as range, orientation, reflectance, and incident illumination -- of the surface element visible at each point in the image. Support for this idea comes from three sources: the obvious utility of intrinsic characteristics for higher-level scene analysis; the apparent ability of humans to determine these characteristics, regardless of viewing conditions or familiarity with the scene; and a theoretical argument that such a description is obtainable, by a noncognitive and nonpurposive process, at least, for simple scene domains. The central problem in recovering intrinsic scene characteristics is that the information is confounded in the original light-intensity image: a single intensity value encodes all the characteristics of the corresponding scene point. Recovery depends on exploiting constraints, derived from assumptions about the nature of the scene and the physics of the imaging process."
            },
            "slug": "RECOVERING-INTRINSIC-SCENE-CHARACTERISTICS-FROM-Barrow-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "RECOVERING INTRINSIC SCENE CHARACTERISTICS FROM IMAGES"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is suggested that an appropriate role of early visual processing is to describe a scene in terms of intrinsic (vertical) characteristics -- such as range, orientation, reflectance, and incident illumination -- of the surface element visible at each point in the image."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1701422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d7d0e8c4791700defd4b0df82a26b50055346e0",
            "isKey": false,
            "numCitedBy": 8758,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing."
            },
            "slug": "An-Information-Maximization-Approach-to-Blind-and-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "An Information-Maximization Approach to Blind Separation and Blind Deconvolution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that information maximization provides a unifying framework for problems in \"blind\" signal processing and dependencies of information transfer on time delays are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2385089"
                        ],
                        "name": "P. A. Griffin",
                        "slug": "P.-A.-Griffin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Griffin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. A. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144513847"
                        ],
                        "name": "A. Redlich",
                        "slug": "A.-Redlich",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Redlich",
                            "middleNames": [
                                "Norman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redlich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 33
                            }
                        ],
                        "text": "Our solution (as well as that of Atick et al., 1996) depends critically on the assumption that the new image, like the images in the training set, depicts an upright face under reasonable lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17146562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3d0aa18ce358c93f485cbe9264db515651ad483",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system is proficient in perceiving three-dimensional shape from the shading patterns in a two-dimensional image. How it does this is not well understood and continues to be a question of fundamental and practical interest. In this paper we present a new quantitative approach to shape-from-shading that may provide some answers. We suggest that the brain, through evolution or prior experience, has discovered that objects can be classified into lower-dimensional object-classes as to their shape. Extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low-dimensional space. We carry out this proposal for an important class of three-dimensional (3D) objects: human heads. From an ensemble of several hundred laser-scanned 3D heads, we use principal component analysis to derive a low-dimensional parameterization of head shape space. An algorithm for solving shape-from-shading using this representation is presented. It works well even on real images where it is able to recover the 3D surface for a given person, maintaining facial detail and identity, from a single 2D image of his face. This algorithm has applications in face recognition and animation."
            },
            "slug": "Statistical-Approach-to-Shape-from-Shading:-of-Face-Atick-Griffin",
            "title": {
                "fragments": [],
                "text": "Statistical Approach to Shape from Shading: Reconstruction of Three-Dimensional Face Surfaces from Single Two-Dimensional Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested that the brain, through evolution or prior experience, has discovered that objects can be classified into lower-dimensional object-classes as to their shape, and extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low-dimensional space."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085784343"
                        ],
                        "name": "ImagesJoseph",
                        "slug": "ImagesJoseph",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "ImagesJoseph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ImagesJoseph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090142166"
                        ],
                        "name": "Paul A. Gri",
                        "slug": "Paul-A.-Gri",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Gri",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Gri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068999015"
                        ],
                        "name": "A. Norman",
                        "slug": "A.-Norman",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Norman",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Norman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100318437"
                        ],
                        "name": "RedlichComputational",
                        "slug": "RedlichComputational",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "RedlichComputational",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "RedlichComputational"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 33
                            }
                        ],
                        "text": "Our solution (as well as that of Atick et al., 1996) depends critically on the assumption that the new image, like the images in the training set, depicts an upright face under reasonable lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2746005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "495235f014bd7aeda046ab475d2876d51f40f177",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system is proocient in perceiving three-dimensional shape from the shading patterns in a two-dimensional image. How it does this is not well understood and continues to be a question of fundamental and practical interest. In this paper we present a new quantitative approach to shape-from-shading that may provide some answers. We suggest that the brain, through evolution or prior experience, has discovered that objects can be classiied into lower-dimensional object-classes as to their shape. Extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low dimensional space. We carry out this proposal for an important class of 3D objects; human heads. From an ensemble of several hundred laser-scanned 3D heads, we use principal component analysis to derive a low-dimensional parameterization of head shape space. An algorithm for solving shape-from-shading using this representation is presented. It works well even on real images where it is able to recover the 3D surface for a given person, maintaining facial detail and identity, from a single 2D image of their face. This algorithm has applications in face recognition and animation."
            },
            "slug": "Statistical-Approach-to-Shape-from-Shading-:-of-3-D-ImagesJoseph-Atick",
            "title": {
                "fragments": [],
                "text": "Statistical Approach to Shape from Shading : Reconstruction of 3 D Face Surfaces from Single 2 D"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested that the brain, through evolution or prior experience, has discovered that objects can be classiied into lower-dimensional object-classes as to their shape, and extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low dimensional space."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 136
                            }
                        ],
                        "text": "In conventional supervised learning situations, the data are divided into complete training patterns and incomplete (e.g., unlabeled) test patterns, which are assumed to be sampled randomly from the same distribution (Bishop, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 77
                            }
                        ],
                        "text": "However, they do not provide a true orthogonal basis for any one pose, as in Moghaddam and Pentland (1997), where a distinct set of eigenfaces is computed for each of several poses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": false,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520178"
                        ],
                        "name": "D. V. Bergem",
                        "slug": "D.-V.-Bergem",
                        "structuredName": {
                            "firstName": "Dick",
                            "lastName": "Bergem",
                            "middleNames": [
                                "R.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. V. Bergem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52537416"
                        ],
                        "name": "L. Pols",
                        "slug": "L.-Pols",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Pols",
                            "middleNames": [
                                "C.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pols"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7862888"
                        ],
                        "name": "F. J. K. Beinum",
                        "slug": "F.-J.-K.-Beinum",
                        "structuredName": {
                            "firstName": "Florien",
                            "lastName": "Beinum",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. J. K. Beinum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6984161,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "52971c796a0797f4360f5c1cfca69ca385cd6387",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perceptual-normalization-of-the-vowels-of-a-man-and-Bergem-Pols",
            "title": {
                "fragments": [],
                "text": "Perceptual normalization of the vowels of a man and a child in various contexts"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46831169"
                        ],
                        "name": "G. Hinton",
                        "slug": "G.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 273
                            }
                        ],
                        "text": "\u20261979), independent component analysis (Bell & Sejnowski, 1995), and cooperative vector quantization (Hinton & Zemel, 1994; Ghahramani, 1995), and hierarchical factorial models, as used in the Helmholtz machine and its descendants (Hinton et al., 1995; Dayan et al., 1995; Hinton & Ghahramani, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ARTICLE Communicated by John Platt"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 149
                            }
                        ],
                        "text": "\u2026Bibby, 1979; Hinton & Zemel, 1994; Ghahramani, 1995; Bell & Sejnowski, 1995; Hinton, Dayan, Frey, & Neal, 1995; Dayan, Hinton, Neal, & Zemel, 1995; Hinton & Ghahramani, 1997) are either insufficiently rich to capture the complex interactions of perceptually meaningful factors such as phoneme and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17706343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e08b47eadfac97fab508485ed5fbef9dbbbd9a3",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a hierarchical, generative model that can be viewed as a nonlinear generalization of factor analysis and can be implemented in a neural network. The model uses bottom-up, top-down and lateral connections to perform Bayesian perceptual inference correctly. Once perceptual inference has been performed the connection strengths can be updated using a very simple learning rule that only requires locally available information. We demonstrate that the network learns to extract sparse, distributed, hierarchical representations."
            },
            "slug": "Generative-models-for-discovering-sparse-Hinton-Ghahramani",
            "title": {
                "fragments": [],
                "text": "Generative models for discovering sparse distributed representations."
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A hierarchical, generative model that can be viewed as a nonlinear generalization of factor analysis and can be implemented in a neural network that learns to extract sparse, distributed, hierarchical representations is described."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11382731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8314dda1ec43ce57ff877f8f02ed89acb68ca035",
            "isKey": false,
            "numCitedBy": 581,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory-based classification algorithms such as radial basis functions or K-nearest neighbors typically rely on simple distances (Euclidean, dot product...), which are not particularly meaningful on pattern vectors. More complex, better suited distance measures are often expensive and rather ad-hoc (elastic matching, deformable templates). We propose a new distance measure which (a) can be made locally invariant to any set of transformations of the input and (b) can be computed efficiently. We tested the method on large handwritten character databases provided by the Post Office and the NIST. Using invariances with respect to translation, rotation, scaling, shearing and line thickness, the method consistently outperformed all other systems tested on the same databases."
            },
            "slug": "Efficient-Pattern-Recognition-Using-a-New-Distance-Simard-LeCun",
            "title": {
                "fragments": [],
                "text": "Efficient Pattern Recognition Using a New Transformation Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new distance measure which can be made locally invariant to any set of transformations of the input and can be computed efficiently is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145780619"
                        ],
                        "name": "David J. Miller",
                        "slug": "David-J.-Miller",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145245719"
                        ],
                        "name": "Lian Yan",
                        "slug": "Lian-Yan",
                        "structuredName": {
                            "firstName": "Lian",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lian Yan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40796207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0259cd8e1a1f1185297b367ba1d8110fef0bde15",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop new rules for combining the estimates obtained from each classifier in an ensemble, in order to address problems involving multiple (>2) classes. A variety of techniques have been previously suggested, including averaging probability estimates from each classifier, as well as hard (0-1) voting schemes. In this work, we introduce the notion of a critic associated with each classifier, whose objective is to predict the classifier's errors. Since the critic only tackles a two class problem, its predictions are generally more reliable than those of the classifier and, thus, can be used as the basis for improved combination rules. Several such rules are suggested here. While previous techniques are only effective when the individual classifier error rate is p<0.5, the new approach is successful, as proved under an independence assumption, even when this condition is violated-in particular, so long as p+q<1, with q the critic's error rate. More generally, critic-driven combining is found to achieve significant performance gains over alternative methods on a number of benchmark data sets. We also propose a new analytical tool for modeling ensemble performance, based on dependence between experts. This approach is substantially more accurate than the analysis based on independence that is often used to justify ensemble methods."
            },
            "slug": "Critic-driven-ensemble-classification-Miller-Yan",
            "title": {
                "fragments": [],
                "text": "Critic-driven ensemble classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The notion of a critic associated with each classifier, whose objective is to predict the classifier's errors, is introduced and is found to achieve significant performance gains over alternative methods on a number of benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6453080"
                        ],
                        "name": "C. Moore",
                        "slug": "C.-Moore",
                        "structuredName": {
                            "firstName": "Cassandra",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144403711"
                        ],
                        "name": "P. Cavanagh",
                        "slug": "P.-Cavanagh",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Cavanagh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cavanagh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7152684,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "116ca2fba4aa3183b7e33aefec62b92e42db5449",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recovery-of-3D-volume-from-2-tone-images-of-novel-Moore-Cavanagh",
            "title": {
                "fragments": [],
                "text": "Recovery of 3D volume from 2-tone images of novel objects"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684073"
                        ],
                        "name": "A. Hurlbert",
                        "slug": "A.-Hurlbert",
                        "structuredName": {
                            "firstName": "Anya",
                            "lastName": "Hurlbert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hurlbert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "More generally, the ability to learn constrained solutions to a priori underconstrained inference problems may turn out to be essential for perception ( Poggio & Hurlbert, 1994;  Nayar & Poggio, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 152
                            }
                        ],
                        "text": "More generally, the ability to learn constrained solutions to a priori underconstrained inference problems may turn out to be essential for perception (Poggio & Hurlbert, 1994; Nayar & Poggio, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2441722,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "3ee07fc62801c8e76c8d31292c120580b03b2176",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper sketches a hypothetical cortical architecture for visual 3D object recognition based on a recent computational model. The view-centered scheme relies on modules for learning from examples, such as Hyperbf-like networks. Such models capture a class of explanations we call Memory-Based Models (MBM) that contains sparse population coding, memory-based recognition, and codebooks of prototypes. Unlike the sigmoidal units of some artificial neural networks, the units of MBMs are consistent with the description of cortical neurons. We describe how an example of MBM may be realized in terms of cortical circuitry and biophysical mechanisms, consistent with psychophysical and physiological data."
            },
            "slug": "Observations-on-Cortical-Mechanisms-for-Object-and-Poggio-Hurlbert",
            "title": {
                "fragments": [],
                "text": "Observations on Cortical Mechanisms for Object Recognition and Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper sketches a hypothetical cortical architecture for visual 3D object recognition based on a recent computational model that contains sparse population coding, memory-based recognition, and codebooks of prototypes that is consistent with the description of cortical neurons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864134"
                        ],
                        "name": "Igor Grebert",
                        "slug": "Igor-Grebert",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Grebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Igor Grebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2205164"
                        ],
                        "name": "R. Keesing",
                        "slug": "R.-Keesing",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Keesing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Keesing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060463653"
                        ],
                        "name": "Steve Mims",
                        "slug": "Steve-Mims",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Mims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Mims"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19314193,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "75b8b3eea3b67340970be70fb4e77babd28c694b",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors designed and trained a connectionist network so that it could generate letterforms in a new font given just a few exemplars from that font. During learning, the network constructed a distributed internal representation of different fonts and letters, even though each training instance had both font characteristics and letter characteristics. For successful generation of letterforms, it was found that it was necessary to have separate but interconnected hidden units for 'letter' and 'font' representations. The limitations of the network can be attributed, in part, to limited training data.<<ETX>>"
            },
            "slug": "Connectionist-generalization-for-production:-an-Grebert-Stork",
            "title": {
                "fragments": [],
                "text": "Connectionist generalization for production: an example from GridFont"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A connectionist network is designed for generalization of production in such a way-to generate letterforms in a new font given just a few exemplars from that font."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN-91-Seattle International Joint Conference on Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Beymer and Poggio (1996)  advocate a dense warp map for related problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Beymer and Poggio (1996) advocate a dense warp map for related problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62531491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models. Many of these techniques depend on a representation of images that induces a linear vector space structure and in principle requires dense feature correspondence. This image representation allows the use of learning techniques for the analysis of images (for computer vision) as well as for the synthesis of images (for computer graphics)."
            },
            "slug": "Image-Representations-for-Visual-Learning-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Image Representations for Visual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 201
                            }
                        ],
                        "text": "It has been suggested that SVD, the essential computational procedure for learning in our framework, can be implemented naturally in neural networks using Hebb-like learning rules (Sanger, 1989, 1994; Oja, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 269
                            }
                        ],
                        "text": "May these same kinds of circuits be co-opted to perform some of the tasks we study here? It has been suggested that SVD, the essential computational procedure for learning in our framework, can be implemented naturally in neural networks using Hebb-like learning rules (Sanger, 1989, 1994; Oja, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207107700,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0eddb03e19bcf7555042508145426451da1d5c7f",
            "isKey": false,
            "numCitedBy": 907,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A single neuron with Hebbian-type learning for the connection weights, and with nonlinear internal feedback, has been shown to extract the statistical principal components of its stationary input pattern sequence. A generalization of this model to a layer of neuron units is given, called the Subspace Network, which yields a multi-dimensional, principal component subspace. This can be used as an associative memory for the input vectors or as a module in nonsupervised learning of data clusters in the input space. It is also able to realize a powerful pattern classifier based on projections on class subspaces. Some classification results for natural textures are given."
            },
            "slug": "Neural-Networks,-Principal-Components,-and-Oja",
            "title": {
                "fragments": [],
                "text": "Neural Networks, Principal Components, and Subspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A single neuron with Hebbian-type learning for the connection weights, and with nonlinear internal feedback, has been shown to extract the statistical principal components of its stationary input pattern sequence, which yields a multi-dimensional, principal component subspace."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Neural Syst."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80317385"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Olshausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143718183"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392063491"
                        ],
                        "name": "D. van Essen",
                        "slug": "D.-van-Essen",
                        "structuredName": {
                            "firstName": "D. C.",
                            "lastName": "van Essen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. van Essen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 189
                            }
                        ],
                        "text": "\u2026& Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as modulating spatial attention (Andersen et al., 1985; Olshausen et al., 1993; Riesenhuber & Dayan, 1997; Salinas & Abbott, 1993) or estimating motion (Koch, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1118263,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "700bbcd3518ca8cb3dac50a89fc69cad3dc1a579",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 146,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world. The model relies on a set of control neurons to dynamically modify the synaptic strengths of intracortical connections so that information from a windowed region of primary visual cortex (V1) is selectively routed to higher cortical areas. Local spatial relationships (i.e., topography) within the attentional window are preserved as information is routed through the cortex. This enables attended objects to be represented in higher cortical areas within an object-centered reference frame that is position and scale invariant. We hypothesize that the pulvinar may provide the control signals for routing information through the cortex. The dynamics of the control neurons are governed by simple differential equations that could be realized by neurobiologically plausible circuits. In preattentive mode, the control neurons receive their input from a low-level \u201csaliency map\u201d representing potentially interesting regions of a scene. During the pattern recognition phase, control neurons are driven by the interaction between top-down (memory) and bottom-up (retinal input) sources. The model respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "slug": "A-neurobiological-model-of-visual-attention-and-on-Olshausen-Anderson",
            "title": {
                "fragments": [],
                "text": "A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world that respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3176387"
                        ],
                        "name": "L. Nygaard",
                        "slug": "L.-Nygaard",
                        "structuredName": {
                            "firstName": "Lynne",
                            "lastName": "Nygaard",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Nygaard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859196"
                        ],
                        "name": "D. Pisoni",
                        "slug": "D.-Pisoni",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pisoni",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pisoni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41217744,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "716f980be59a6ce6083c12e9c11cebc3aa5b1af8",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 153,
            "paperAbstract": {
                "fragments": [],
                "text": "The effects of perceptual learning of talker identity on the recognition of spoken words and sentences were investigated in three experiments. In each experiment, listeners were trained to learn a set of 10 talkers\u2019 voices and were then given an intelligibility test to assess the influence of learning the voices on the processing of the linguistic content of speech. In the first experiment, listeners learned voices from isolated words and were then tested with novel isolated words mixed in noise. The results showed that listeners who were given words produced by familiar talkers at test showed better identification performance than did listeners who were given words produced by unfamiliar talkers. In the second experiment, listeners learned novel voices from sentence-length utterances and were then presented with isolated words. The results showed that learning a talker\u2019s voice from sentences did not generalize well to identification of novel isolated words. In the third experiment, listeners learned voices from sentence-length utterances and were then given sentence-length utterances produced by familiar and unfamiliar talkers at test. We found that perceptual learning of novel voices from sentence-length utterances improved speech intelligibility for words in sentences. Generalization and transfer from voice learning to linguistic processing was found to be sensitive to the talker-specific information available during learning and test. These findings demonstrate that increased sensitivity to talker-specific information affects the perception of the linguistic properties of speech in isolated words and sentences."
            },
            "slug": "Talker-specific-learning-in-speech-perception-Nygaard-Pisoni",
            "title": {
                "fragments": [],
                "text": "Talker-specific learning in speech perception"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is found that perceptual learning of novel voices from sentence-length utterances improved speech intelligibility for words in sentences."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ARTICLE Communicated by John Platt"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2445072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dc3a0efe58eaf8564ca1965c0ffd23ec495b83f",
            "isKey": false,
            "numCitedBy": 958,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "An autoencoder network uses a set of recognition weights to convert an input vector into a code vector. It then uses a set of generative weights to convert the code vector into an approximate reconstruction of the input vector. We derive an objective function for training autoencoders based on the Minimum Description Length (MDL) principle. The aim is to minimize the information required to describe both the code vector and the reconstruction error. We show that this information is minimized by choosing code vectors stochastically according to a Boltzmann distribution, where the generative weights define the energy of each possible code vector given the input vector. Unfortunately, if the code vectors use distributed representations, it is exponentially expensive to compute this Boltzmann distribution because it involves all possible code vectors. We show that the recognition weights of an autoencoder can be used to compute an approximation to the Boltzmann distribution and that this approximation gives an upper bound on the description length. Even when this bound is poor, it can be used as a Lyapunov function for learning both the generative and the recognition weights. We demonstrate that this approach can be used to learn factorial codes."
            },
            "slug": "Autoencoders,-Minimum-Description-Length-and-Free-Hinton-Zemel",
            "title": {
                "fragments": [],
                "text": "Autoencoders, Minimum Description Length and Helmholtz Free Energy"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that the recognition weights of an autoencoder can be used to compute an approximation to the Boltzmann distribution and that this approximation gives an upper bound on the description length."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1890561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "605402e235bd62437baf3c9ebefe77fb4d92ee95",
            "isKey": false,
            "numCitedBy": 1173,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways."
            },
            "slug": "The-Helmholtz-Machine-Dayan-Hinton",
            "title": {
                "fragments": [],
                "text": "The Helmholtz Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations is described, viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106806851"
                        ],
                        "name": "SJ Nowlan",
                        "slug": "SJ-Nowlan",
                        "structuredName": {
                            "firstName": "SJ",
                            "lastName": "Nowlan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SJ Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67024781"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Sejnowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6624412,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "7b1269fc6d196d16c318a076b3f811f33de750f2",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A computational model for motion processing in area MT is presented that is based on the observed response properties of cortical neurons and is consistent with the visual perception of partially occluded and transparent moving stimuli. In contrast to models of motion processing that assume spatial continuity and fail to compute the correct velocity for these visual stimuli, our model produces a distributed segmentation of the image into disjoint patches that represent distinct objects moving with common velocities. A key element in the model is the selection of regions of the visual field where the velocity estimates are most reliable. The processing units in the motion model that perform the selection have nonclassical receptive fields similar to those observed in area MT (Allman et al., 1985). The psychophysical responses of the model to coherently moving random dots and transparent plaid gratings are similar to those observed in primates."
            },
            "slug": "A-selection-model-for-motion-processing-in-area-MT-Nowlan-Sejnowski",
            "title": {
                "fragments": [],
                "text": "A selection model for motion processing in area MT of primates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A computational model for motion processing in area MT is presented that is based on the observed response properties of cortical neurons and is consistent with the visual perception of partially occluded and transparent moving stimuli."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433345"
                        ],
                        "name": "D. Marimont",
                        "slug": "D.-Marimont",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Marimont",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marimont"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022202"
                        ],
                        "name": "B. Wandell",
                        "slug": "B.-Wandell",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Wandell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wandell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 141
                            }
                        ],
                        "text": "\u2026from motion under orthographic projection (Tomasi & Kanade, 1992) and color constancy under multiple illuminants (Brainard & Wandell, 1991; Marimont & Wandell, 1992; D\u2019Zmura, 1992) are solvable efficiently because they are fundamentally bilinear at the level of geometry or physics\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 128
                            }
                        ],
                        "text": "The algorithm we use was described for scalar observations by Magnus and Neudecker (1988) and adapted to vector observations by Marimont and Wandell (1992), in the context of characterizing color surface and illuminant spectra."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Again, if we assume that the training set consists of an equal number of observations in each style and content class, there are efficient matrix algorithms for minimizing E. The algorithm we use was described for scalar observations by Magnus and Neudecker (1988) and adapted to vector observations by  Marimont and Wandell (1992) , in the context of characterizing color surface and illuminant spectra."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "of structure from motion under orthographic projection (Tomasi & Kanade, 1992) and color constancy under multiple illuminants (Brainard & Wandell, 1991;  Marimont & Wandell, 1992;  D\u2019Zmura, 1992) are solvable efficiently because they are fundamentally bilinear at the level of geometry or physics (Koenderink & van Doorn, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Figure 5: Schematic illustration of the vector transpose (following  Marimont & Wandell, 1992 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15440792,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ec4e8013d3e22c7f55561ade91430f4f45662248",
            "isKey": true,
            "numCitedBy": 313,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe procedures for creating efficient spectral representations for color. The representations generalize conventional tristimulus representations, which are based on the peripheral encoding by the human eye. We use low-dimensional linear models to approximate the spectral properties of surfaces and illuminants with respect to a collection of sensing devices. We choose the linear-model basis functions by minimizing the error in approximating sensor responses for collections of surfaces and illuminants. These linear models offer some conceptual simplifications for applications such as printer calibration; they also perform substantially better than principal-components approximations for computer-graphics applications."
            },
            "slug": "Linear-models-of-surface-and-illuminant-spectra.-Marimont-Wandell",
            "title": {
                "fragments": [],
                "text": "Linear models of surface and illuminant spectra."
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Low-dimensional linear models used for creating efficient spectral representations for color offer some conceptual simplifications for applications such as printer calibration; they also perform substantially better than principal-components approximations for computer-graphics applications."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807117"
                        ],
                        "name": "T. Sanger",
                        "slug": "T.-Sanger",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Sanger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sanger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "May these same kinds of circuits be co-opted to perform some of the tasks we study here? It has been suggested that SVD, the essential computational procedure for learning in our framework, can be implemented naturally in neural networks using Hebb-like learning rules ( Sanger, 1989, 1994;  Oja, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "It has been suggested that SVD, the essential computational procedure for learning in our framework, can be implemented naturally in neural networks using Hebb-like learning rules (Sanger, 1989, 1994; Oja, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10138295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "709b4bfc5198336ba5d70da987889a157f695c1e",
            "isKey": false,
            "numCitedBy": 1524,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-unsupervised-learning-in-a-single-layer-Sanger",
            "title": {
                "fragments": [],
                "text": "Optimal unsupervised learning in a single-layer linear feedforward neural network"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3164225"
                        ],
                        "name": "T. Sanocki",
                        "slug": "T.-Sanocki",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Sanocki",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sanocki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143754744,
            "fieldsOfStudy": [
                "Psychology",
                "Physics"
            ],
            "id": "657790741146d390d2c5e6540b55fde3bb7896e8",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjects made speeded decisions as to whether strings contained all letters or a nonletter. Strings were 2 to 6 items long, and were initially drawn from one subset of letters and nonletters from one font. During the session, the stimuli were changed without warning to either new letters of the same font or new letters of a new font (Experiments 1 and 2), or to new instances of the same letters in a new font (Experiment 3). Changes to new instances of letters caused considerable cost, in the form of an increase in the reaction time slopes due to string length. The results are consistent with the idea that perceptual processing relies upon the retrieval of prior instances"
            },
            "slug": "Effects-of-font-and-letter-specific-experience-on-Sanocki",
            "title": {
                "fragments": [],
                "text": "Effects of font- and letter-specific experience on the perceptual processing of letters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50222622"
                        ],
                        "name": "D. Hofstadter",
                        "slug": "D.-Hofstadter",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Hofstadter",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hofstadter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "\u2026and abstraction in typography have been restricted to artificial grid-based fonts, for which the grid elements provide a reasonable distributed representation (Hofstadter, 1995; Grebert et al., 1992), or even simpler \u201cgrandmother cell\u201d representations of each letter (Polk & Farah, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 8
                            }
                        ],
                        "text": "Indeed, Hofstadter (1995) has argued that the question, \u201cWhat is the letter \u2018a\u2019?\u201d may be \u201cthe central problem of AI\u201d (p. 633)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 121
                            }
                        ],
                        "text": "The ability to draw analogies across observations in different contexts is a hallmark of human perception and cognition (Hofstadter, 1995; Holyoak & Barnden, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 184
                            }
                        ],
                        "text": "In particular, the ability to produce analogous content in a novel style\u2014and not just recognize it, as in the previous section\u2014has been taken as a severe test of perceptual abstraction (Hofstadter, 1995; Grebert, Stork, Keesing, & Mims, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Hofstadter (1995) has been critical of approaches to stylistic extrapolation that minimize the role of domain-specific knowledge and processing, in particular, the connectionist model of Grebert et al. (1992), arguing that models that \u201cdon\u2019t know anything about what they are doing\u201d (p. 408) cannot\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 142801505,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "90d60cb4ac901d19ba1eaf1b369bdef24e3c9861",
            "isKey": true,
            "numCitedBy": 378,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nSince 1977, Douglas R. Hofstadter and his graduate students at Indiana University and the University of Michigan have been developing computer models of discovery, creation, and analogical thought. What has emerged is a sophisticated and unorthodox vision of the mind in which perception, at an abstract level, is the key: perception of situations, of patterns, of patterns among patterns, even perception of one's perceptions. Fluid Concepts and Creative Analogies conveys this bold vision to a broad public as well as to cognitive scientists. Two ideas pervade the research. One is that the key question to answer is \"What is a concept?\" This means understanding how concepts overlap and trigger one another, how their fluid boundaries come about, how they give rise to generalizations and analogies, and so on. The second idea is that mental activity is fundamentally parallel, with many tiny agents independently carrying out small \"subcognitive\" acts and collectively building up coherent mental structures. Such agents lie far above the neural level, yet far below the conscious level; the hypothetical level of the brain at which they reside thus constitutes a largely uncharted substrate for thought. With these intuitions as guides, Hofstadter and the members of the Fluid Analogies Research Group have developed computer models that operate in small but extraordinarily challenging domains: playful anagram and number puzzles, analogy puzzles involving letter strings or tabletop objects, and fanciful alphabetic styles. These subtle ideas are spelled out with verve, charm, and clarity by Hofstadter and his co-workers in a series of chapters alternating with prefaces; the latter tie the projects together and give insight into their evolution. Readers of earlier works by Hofstadter will find this book a natural extension of his style and his ideas about creativity and analogy; in addition, psychologists, philosophers, and artificial-intelligence researchers will find in this el"
            },
            "slug": "Fluid-Concepts-and-Creative-Analogies:-Computer-of-Hofstadter",
            "title": {
                "fragments": [],
                "text": "Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought, Douglas Hofstadter. 1994. Basic Books, New York, NY. 512 pages. ISBN: 0-465-05154-5. $30.00"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2761918"
                        ],
                        "name": "P. Teo",
                        "slug": "P.-Teo",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Teo",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Teo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "First, successful classification requires only that the outputs of the bilinear model be close to the test data under the generic metric of mean squared error, while success in extrapolation is judged by the far more subtle metric of visual appearance ( Teo & Heeger, 1994 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 253
                            }
                        ],
                        "text": "First, successful classification requires only that the outputs of the bilinear model be close to the test data under the generic metric of mean squared error, while success in extrapolation is judged by the far more subtle metric of visual appearance (Teo & Heeger, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1370281,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "63c13deef4ecb94d69b6763f43311720e40a2f61",
            "isKey": false,
            "numCitedBy": 401,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a perceptual distortion measure that predicts image integrity far better than mean-squared error. This perceptual distortion measure is based an a model of human visual processing that fits empirical measurements of the psychophysics of spatial pattern detection. The model of human visual processing proposed involves two major components: a steerable pyramid transform and contrast normalization. We also illustrate the usefulness of the model in predicting perceptual distortion in real images.<<ETX>>"
            },
            "slug": "Perceptual-image-distortion-Teo-Heeger",
            "title": {
                "fragments": [],
                "text": "Perceptual image distortion"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A perceptual distortion measure that predicts image integrity far better than mean-squared error and the usefulness of the model in predicting perceptual distortion in real images is illustrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1st International Conference on Image Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16927,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 213
                            }
                        ],
                        "text": "\u2026& Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as modulating spatial attention (Andersen et al., 1985; Olshausen et al., 1993; Riesenhuber & Dayan, 1997; Salinas & Abbott, 1993) or estimating motion (Koch, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 140
                            }
                        ],
                        "text": "At the physiological level, multiplicative neuronal interactions (Andersen, Essick, & Siegel, 1985; Olshausen, Anderson, & van Essen, 1993; Riesenhuber & Dayan, 1997), arising from nonlinear synaptic (Koch, 1997) or populationlevel (Salinas & Abbott, 1993) mechanisms, have been proposed for visual\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3133616,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c183c6dc1d3187b1460b8b1c83dfe7605fd2780c",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a connectionist method for representing images that explicitly addresses their hierarchical nature. It blends data from neuroscience about whole-object viewpoint sensitive cells in inferotemporal cortex and attentional basis-field modulation in V4 with ideas about hierarchical descriptions based on microfeatures. The resulting model makes critical use of bottom-up and top-down pathways for analysis and synthesis. We illustrate the model with a simple example of representing information about faces."
            },
            "slug": "Neural-Models-for-Part-Whole-Hierarchies-Riesenhuber-Dayan",
            "title": {
                "fragments": [],
                "text": "Neural Models for Part-Whole Hierarchies"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A connectionist method for representing images that explicitly addresses their hierarchical nature is presented, combining data from neuroscience about whole-object viewpoint sensitive cells in inferotemporal cortex and attentional basis-field modulation in V4 with ideas about hierarchical descriptions based on microfeatures."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2354883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09370d132a1e238a778f5e39a7a096994dc25ec1",
            "isKey": false,
            "numCitedBy": 909,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Nearest neighbor classification expects the class conditional probabilities to be locally constant, and suffers from bias in high dimensions We propose a locally adaptive form of nearest neighbor classification to try to finesse this curse of dimensionality. We use a local linear discriminant analysis to estimate an effective metric for computing neighborhoods. We determine the local decision boundaries from centroid information, and then shrink neighborhoods in directions orthogonal to these local decision boundaries, and elongate them parallel to the boundaries. Thereafter, any neighborhood-based classifier can be employed, using the modified neighborhoods. The posterior probabilities tend to be more homogeneous in the modified neighborhoods. We also propose a method for global dimension reduction, that combines local dimension information. In a number of examples, the methods demonstrate the potential for substantial improvements over nearest neighbour classification."
            },
            "slug": "Discriminant-Adaptive-Nearest-Neighbor-Hastie-Tibshirani",
            "title": {
                "fragments": [],
                "text": "Discriminant Adaptive Nearest Neighbor Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A locally adaptive form of nearest neighbor classification is proposed to try to finesse this curse of dimensionality, and a method for global dimension reduction is proposed, that combines local dimension information."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 149
                            }
                        ],
                        "text": "\u2026analysis (Mardia et al., 1979), independent component analysis (Bell & Sejnowski, 1995), and cooperative vector quantization (Hinton & Zemel, 1994; Ghahramani, 1995), and hierarchical factorial models, as used in the Helmholtz machine and its descendants (Hinton et al., 1995; Dayan et al., 1995;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 75
                            }
                        ],
                        "text": "Existing factor models (Mardia, Kent, & Bibby, 1979; Hinton & Zemel, 1994; Ghahramani, 1995; Bell & Sejnowski, 1995; Hinton, Dayan, Frey, & Neal, 1995; Dayan, Hinton, Neal, & Zemel, 1995; Hinton & Ghahramani, 1997) are either insufficiently rich to capture the complex interactions of perceptually\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 8523597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0182096896504acf759110091a6bca3ca75e828",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real world learning problems are best characterized by an interaction of multiple independent causes or factors. Discovering such causal structure from the data is the focus of this paper. Based on Zemel and Hinton's cooperative vector quantizer (CVQ) architecture, an unsupervised learning algorithm is derived from the Expectation-Maximization (EM) framework. Due to the combinatorial nature of the data generation process, the exact E-step is computationally intractable. Two alternative methods for computing the E-step are proposed: Gibbs sampling and mean-field approximation, and some promising empirical results are presented."
            },
            "slug": "Factorial-Learning-and-the-EM-Algorithm-Ghahramani",
            "title": {
                "fragments": [],
                "text": "Factorial Learning and the EM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Based on Zemel and Hinton's cooperative vector quantizer (CVQ) architecture, an unsupervised learning algorithm is derived from the Expectation-Maximization (EM) framework, and some promising empirical results are presented."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2853,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833095"
                        ],
                        "name": "S. Kothari",
                        "slug": "S.-Kothari",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Kothari",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kothari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681982"
                        ],
                        "name": "H. Oh",
                        "slug": "H.-Oh",
                        "structuredName": {
                            "firstName": "Heekuck",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 218
                            }
                        ],
                        "text": "In conventional supervised learning situations, the data are divided into complete training patterns and incomplete (e.g., unlabeled) test patterns, which are assumed to be sampled randomly from the same distribution (Bishop, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 96
                            }
                        ],
                        "text": ", unlabeled) test patterns, which are assumed to be sampled randomly from the same distribution (Bishop, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 177751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbc0a468ab103ae29717703d4aa9f682f6a2b664",
            "isKey": false,
            "numCitedBy": 15339,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Pattern-Recognition-Kothari-Oh",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15208137,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "baf4491be1f4c1de7ecb03bf81325f6f09bda9c6",
            "isKey": false,
            "numCitedBy": 9488,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "IS B N 0-523108-5) C opright (C ) 19-1992 by C am bidge U nirsity P rss. P rogram s C opright (C ) 19-1992 by N um eical R eipes S ftw are. P rm ission is grnted or inrnet uers to m ke ne pper cpy or teir ow n peonal use. F uther repruction, or ny coying of m acineredable fles (inluding his one) to ny srver om pter, is sictly proibited. T o oder N um eical R eipes boks, disettes, or C D R O M s visit w esite hp://w w w .n.com or call 1-8072-7423 (N orth A m erica oly), or snd em il to trde@ cu.cam .ac.uk (otside N orth A m eca). Numerical Recipes in C"
            },
            "slug": "Numerical-recipes-in-C++:-the-art-of-scientific-2nd-Press",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C++: the art of scientific computing, 2nd Edition (C++ ed., print. is corrected to software version 2.10)"
            },
            "tldr": {
                "abstractSimilarityScore": 32,
                "text": "F uther repruction, or ny coying of m acineredable fles (inluding his one) to ny srver om pter, is sictly proibited."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608039"
                        ],
                        "name": "P. V. D. Laar",
                        "slug": "P.-V.-D.-Laar",
                        "structuredName": {
                            "firstName": "Pi\u00ebrre",
                            "lastName": "Laar",
                            "middleNames": [
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. V. D. Laar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2805324"
                        ],
                        "name": "S. Gielen",
                        "slug": "S.-Gielen",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Gielen",
                            "middleNames": [
                                "C.",
                                "A.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gielen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10917785,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Psychology"
            ],
            "id": "7814eb7b0978d21f5b0e403ca86f532cc0d6da39",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a biologically plausible neural model of selective covert visual attention. We show that this model is able to learn focussing on object-specific features. It has similar learning characteristics as humans in the learning and unlearning paradigm of Shiffrin and Schneider [8]."
            },
            "slug": "A-Neural-Model-of-Visual-Attention-Laar-Heskes",
            "title": {
                "fragments": [],
                "text": "A Neural Model of Visual Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A biologically plausible neural model of selective covert visual attention that is able to learn focussing on object-specific features and has similar learning characteristics as humans in the learning and unlearning paradigm of Shiffrin and Schneider is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "SNN Symposium on Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145437578"
                        ],
                        "name": "E. Salinas",
                        "slug": "E.-Salinas",
                        "structuredName": {
                            "firstName": "Emilio",
                            "lastName": "Salinas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Salinas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293717"
                        ],
                        "name": "L. Abbott",
                        "slug": "L.-Abbott",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Abbott",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Abbott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "At the physiological level, multiplicative neuronal interactions (Andersen, Essick, & Siegel, 1985; Olshausen, Anderson, & van Essen, 1993; Riesenhuber & Dayan, 1997), arising from nonlinear synaptic (Koch, 1997) or populationlevel ( Salinas & Abbott, 1993 ) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as modulating spatial attention (Andersen et al., ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 240
                            }
                        ],
                        "text": "\u2026& Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as modulating spatial attention (Andersen et al., 1985; Olshausen et al., 1993; Riesenhuber & Dayan, 1997; Salinas & Abbott, 1993) or estimating motion (Koch, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "... neuronal interactions (Andersen, Essick, & Siegel, 1985; Olshausen, Anderson, & van Essen, 1993; Riesenhuber & Dayan, 1997), arising from nonlinear synaptic (Koch, 1997) or populationlevel (Salinas & Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as modulating spatial attention (Andersen et al., 1985; Olshausen et al., 1993; Riesenhuber & Dayan, ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u2026& Siegel, 1985; Olshausen, Anderson, & van Essen, 1993; Riesenhuber & Dayan, 1997), arising from nonlinear synaptic (Koch, 1997) or populationlevel (Salinas & Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16049376,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1fd00cabd152d148f1b243f099f9ee9964bd008a",
            "isKey": true,
            "numCitedBy": 315,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual responses of neurons in parietal area 7a are modulated by a combined eye and head position signal in a multiplicative manner. Neurons with multiplicative responses can act as powerful computational elements in neural networks. In the case of parietal cortex, multiplicative gain modulation appears to play a crucial role in the transformation of object locations from retinal to body-centered coordinates. It has proven difficult to uncover single-neuron mechanisms that account for neuronal multiplication. Here we show that multiplicative responses can arise in a network model through population effects. Specifically, neurons in a recurrently connected network with excitatory connections between similarly tuned neurons and inhibitory connections between differently tuned neurons can perform a product operation on additive synaptic inputs. The results suggest that parietal responses may be based on this architecture."
            },
            "slug": "A-model-of-multiplicative-neural-responses-in-Salinas-Abbott",
            "title": {
                "fragments": [],
                "text": "A model of multiplicative neural responses in parietal cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that multiplicative responses can arise in a network model through population effects and suggest that parietal responses may be based on this architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808760"
                        ],
                        "name": "S. Omohundro",
                        "slug": "S.-Omohundro",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Omohundro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Omohundro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17817815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cae71762b6dd2f415576de3915a59c7dd7da0f9",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Family discovery\" is the task of learning the dimension and structure of a parameterized family of stochastic models. It is especially appropriate when the training examples are partitioned into \"episodes\" of samples drawn from a single parameter value. We present three family discovery algorithms based on surface learning and show that they significantly improve performance over two alternatives on a parameterized classification task."
            },
            "slug": "Family-Discovery-Omohundro",
            "title": {
                "fragments": [],
                "text": "Family Discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Three family discovery algorithms based on surface learning are presented and it is shown that they significantly improve performance over two alternatives on a parameterized classification task."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394815784"
                        ],
                        "name": "M. D'Zmura",
                        "slug": "M.-D'Zmura",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "D'Zmura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D'Zmura"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 126
                            }
                        ],
                        "text": "of structure from motion under orthographic projection (Tomasi & Kanade, 1992) and color constancy under multiple illuminants (Brainard & Wandell, 1991; Marimont & Wandell, 1992; D\u2019Zmura, 1992) are solvable efficiently because they are fundamentally bilinear at the level of geometry or physics (Koenderink & van Doorn, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "\u2026orthographic projection (Tomasi & Kanade, 1992) and color constancy under multiple illuminants (Brainard & Wandell, 1991; Marimont & Wandell, 1992; D\u2019Zmura, 1992) are solvable efficiently because they are fundamentally bilinear at the level of geometry or physics (Koenderink & van Doorn, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16908659,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "34ce5d56fbbad7e86f7b9d8a2aa0dbf2385c2d04",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Viewing the lights reflected by a set of three or more surfaces, a trichromatic visual system can recover three color-constant descriptors of reflectance per surface if the color of the surfaces\u2019 illuminant changes. This holds true for a broad range of models that relate photoreceptor, surface, and illuminant spectral properties. Changing illumination, which creates the problem of color constancy, affords its solution."
            },
            "slug": "Color-constancy-:-surface-color-from-changing-D'Zmura",
            "title": {
                "fragments": [],
                "text": "Color constancy : surface color from changing illumination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189155"
                        ],
                        "name": "R. Andersen",
                        "slug": "R.-Andersen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Andersen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5280173"
                        ],
                        "name": "G. Essick",
                        "slug": "G.-Essick",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Essick",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Essick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40025811"
                        ],
                        "name": "R. M. Siegel",
                        "slug": "R.-M.-Siegel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Siegel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. M. Siegel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8367973,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0f3c1ca738ad6ab8c5d5f642e1e81958b0c45cbd",
            "isKey": false,
            "numCitedBy": 1436,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The cortex of the inferior parietal lobule in primates is important for spatial perception and spatially oriented behavior. Recordings of single neurons in this area in behaving monkeys showed that the visual sensitivity of the retinotopic receptive fields changes systematically with the angle of gaze. The activity of many of the neurons can be largely described by the product of a gain factor that is a function of the eye position and the response profile of the visual receptive field. This operation produces an eye position-dependent tuning for locations in head-centered coordinate space."
            },
            "slug": "Encoding-of-spatial-location-by-posterior-parietal-Andersen-Essick",
            "title": {
                "fragments": [],
                "text": "Encoding of spatial location by posterior parietal neurons."
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The cortex of the inferior parietal lobule in primates is important for spatial perception and spatially oriented behavior and recordings of single neurons in this area in behaving monkeys showed that the visual sensitivity of the retinotopic receptive fields changes systematically with the angle of gaze."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172770680"
                        ],
                        "name": "N. L. Johnson",
                        "slug": "N.-L.-Johnson",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Johnson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. L. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "These include essentially additive factor models, as used in principal component analysis (Mardia et al., 1979), independent component analysis (Bell & Sejnowski, 1995), and cooperative vector quantization (Hinton & Zemel, 1994; Ghahramani, 1995), and hierarchical factorial models, as used in the Helmholtz machine and its descendants (Hinton et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 91
                            }
                        ],
                        "text": "These include essentially additive factor models, as used in principal component analysis (Mardia et al., 1979), independent component analysis (Bell & Sejnowski, 1995), and cooperative vector quantization (Hinton & Zemel, 1994; Ghahramani, 1995), and hierarchical factorial models, as used in the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4206943,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "182f77976b08d832b5cdc7debdaeacc300c8e723",
            "isKey": false,
            "numCitedBy": 5733,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An Introduction to Multivariate Statistical AnalysisBy Prof. T. W. Anderson. (Wiley Publications in Mathematical Statistics.) Pp. xii + 374. (New York: John Wiley and Sons, Inc.; London: Chapman and Hall, Ltd., 1958.) 100s. net.Some Aspects of Multivariate AnalysisBy Prof. S. N. Roy. (Indian Statistical Series, No. 1.) Pp. viii + 214. (New York: John Wiley and Sons, Inc.; Calcutta: Indian Statistical Institute; London: Chapman and Hall, Ltd., 1957.) 64s. net.The Analysis of Multiple Time-SeriesBy M. H. Quenouille. (Griffin's Statistical Monographs and Courses, No. 1.) Pp. 105. (London: Charles Griffin and Co., Ltd., 1957.) 24s."
            },
            "slug": "Multivariate-Analysis-Johnson",
            "title": {
                "fragments": [],
                "text": "Multivariate Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693738"
                        ],
                        "name": "David Tonnesen",
                        "slug": "David-Tonnesen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tonnesen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Tonnesen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Specifically, the need to represent shapes of different topologies in comparable forms motivates using a particle-based representation ( Szeliski & Tonnesen, 1992 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 136
                            }
                        ],
                        "text": "Specifically, the need to represent shapes of different topologies in comparable forms motivates using a particle-based representation (Szeliski & Tonnesen, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 431276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c89e50e8c6f6f70707ba150802803cc0a850b29",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Splines and deformable surface models are widely used in computer graphics to describe free-form surfaces. These methods require manual preprocessing to discretize the surface into patches and to specify their connectivity. We present a new model of elastic surfaces based on interacting particle systems, which, unlike previous techniques, can be used to sptiL join, or extend surfaces without the need for manual intervention. The particles we use have longrange attraction forces and short-range repulsion forces and follow Newtonian dynamics, much tiie recent computational models of fluids and solids. To enable our particles to model surface elements instead of point masses or volume elements, we add an orientation to each particle\u2019s state. We devise new interaction potentials for our oriented particles which favor locally planar or spherical arrangements. We atso develop techniques for adding new particles automatically, which enables our surfaces to stretch and grow. We demonstrate the application of our new particle system to modefing surfaces in 3-D and the interpolation of 3-D point sets."
            },
            "slug": "Surface-modeling-with-oriented-particle-systems-Szeliski-Tonnesen",
            "title": {
                "fragments": [],
                "text": "Surface modeling with oriented particle systems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new model of elastic surfaces based on interacting particle systems, which, unlike previous techniques, can be used to join, or extend surfaces without the need for manual intervention."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46831169"
                        ],
                        "name": "G. Hinton",
                        "slug": "G.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145572884"
                        ],
                        "name": "R. Neal",
                        "slug": "R.-Neal",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Neal",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 871473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dd01cd9c17d1491ead8c9f97597fbc61dead8ea",
            "isKey": false,
            "numCitedBy": 1001,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representation in the layer above. In the \"wake\" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the \"sleep\" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above."
            },
            "slug": "The-\"wake-sleep\"-algorithm-for-unsupervised-neural-Hinton-Dayan",
            "title": {
                "fragments": [],
                "text": "The \"wake-sleep\" algorithm for unsupervised neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described, where bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representations in the layer above."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50222622"
                        ],
                        "name": "D. Hofstadter",
                        "slug": "D.-Hofstadter",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Hofstadter",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hofstadter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "\u2026and abstraction in typography have been restricted to artificial grid-based fonts, for which the grid elements provide a reasonable distributed representation (Hofstadter, 1995; Grebert et al., 1992), or even simpler \u201cgrandmother cell\u201d representations of each letter (Polk & Farah, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 192
                            }
                        ],
                        "text": "Previous models of extrapolation and abstraction in typography have been restricted to artificial grid-based fonts, for which the grid elements provide a reasonable distributed representation (Hofstadter, 1995; Grebert et al., 1992), or even simpler \u201cgrandmother cell\u201d representations of each letter (Polk & Farah, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 8
                            }
                        ],
                        "text": "Indeed, Hofstadter (1995) has argued that the question, \u201cWhat is the letter \u2018a\u2019?\u201d may be \u201cthe central problem of AI\u201d (p. 633)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 121
                            }
                        ],
                        "text": "The ability to draw analogies across observations in different contexts is a hallmark of human perception and cognition (Hofstadter, 1995; Holyoak & Barnden, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 184
                            }
                        ],
                        "text": "In particular, the ability to produce analogous content in a novel style\u2014and not just recognize it, as in the previous section\u2014has been taken as a severe test of perceptual abstraction (Hofstadter, 1995; Grebert, Stork, Keesing, & Mims, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Hofstadter (1995) has been critical of approaches to stylistic extrapolation that minimize the role of domain-specific knowledge and processing, in particular, the connectionist model of Grebert et al. (1992), arguing that models that \u201cdon\u2019t know anything about what they are doing\u201d (p. 408) cannot\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 59760674,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "c6af5b3d2b6f2b891d5cc538d80ebe8d07d5bcd1",
            "isKey": true,
            "numCitedBy": 386,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognizing the exaggeration ways to acquire this books fluid concepts and creative analogies douglas r hofstadter is additionally useful. You have remained in right site to begin getting this info. acquire the fluid concepts and creative analogies douglas r hofstadter member that we pay for here and check out the link. You could purchase lead fluid concepts and creative analogies douglas r hofstadter or acquire it as soon as feasible. You could speedily download this fluid concepts and creative analogies douglas r hofstadter after getting deal. So, in the manner of you require the books swiftly, you can straight get it. It's therefore entirely easy and correspondingly fats, isn't it? You have to favor to in this express Page Url"
            },
            "slug": "Fluid-Concepts-and-Creative-Analogies-Hofstadter",
            "title": {
                "fragments": [],
                "text": "Fluid Concepts and Creative Analogies"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Recognizing the exaggeration ways to acquire this books fluid concepts and creative analogies douglas r hofstadter is additionally useful."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3239730"
                        ],
                        "name": "M. Landy",
                        "slug": "M.-Landy",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Landy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Landy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145707107"
                        ],
                        "name": "J. Movshon",
                        "slug": "J.-Movshon",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Movshon",
                            "middleNames": [
                                "Anthony"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Movshon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 46001464,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "edea2405826cb4966864e6a34e62779eeb17a0ab",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Reflectance and Illumination, Ambiguity, Discussion, Acknowledgments, References"
            },
            "slug": "A-Bilinear-Model-of-the-Illuminant's-Effect-on-Landy-Movshon",
            "title": {
                "fragments": [],
                "text": "A Bilinear Model of the Illuminant's Effect on Color Appearance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61769312,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ca2832d2c30287a9ee5b8584cc498d2b1cb14753",
            "isKey": false,
            "numCitedBy": 16689,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08"
            },
            "slug": "Numerical-recipes-in-C-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30124219"
                        ],
                        "name": "M. Brereton",
                        "slug": "M.-Brereton",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brereton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brereton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126071699,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "bcd087b2162e6b50d1f2fdd0347d643807bdc62e",
            "isKey": false,
            "numCitedBy": 2485,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "J D Jackson Chichester: J Wiley 1975 pp xxii + 848 price \u00a310.75 The present edition of this now classic text offers substantial refinements and improvements over the first edition and includes some new material. New topics on electromagnetism include an improved derivation of the macroscopic equations, monopoles, causality and dispersion relations, signal propagation in a dispersive media."
            },
            "slug": "Classical-Electrodynamics-(2nd-edn)-Brereton",
            "title": {
                "fragments": [],
                "text": "Classical Electrodynamics (2nd edn)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144403711"
                        ],
                        "name": "P. Cavanagh",
                        "slug": "P.-Cavanagh",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Cavanagh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cavanagh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3307862"
                        ],
                        "name": "A. Gorea",
                        "slug": "A.-Gorea",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Gorea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gorea"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 214
                            }
                        ],
                        "text": "In fact, there is evidence that the brain often does not solve the shape-from-shading problem in its most general form, but rather has learned (or evolved) solutions to important special cases such as face images (Cavanagh, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58806311,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "93f09bbb8d1f8041e082dc1b7d007967919a266e",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "What's-up-in-top-down-processing-Cavanagh-Gorea",
            "title": {
                "fragments": [],
                "text": "What's up in top-down processing?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 80
                            }
                        ],
                        "text": ", 1993; Riesenhuber & Dayan, 1997; Salinas & Abbott, 1993) or estimating motion (Koch, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 150
                            }
                        ],
                        "text": "\u2026interactions (Andersen, Essick, & Siegel, 1985; Olshausen, Anderson, & van Essen, 1993; Riesenhuber & Dayan, 1997), arising from nonlinear synaptic (Koch, 1997) or populationlevel (Salinas & Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 286
                            }
                        ],
                        "text": "\u2026& Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as modulating spatial attention (Andersen et al., 1985; Olshausen et al., 1993; Riesenhuber & Dayan, 1997; Salinas & Abbott, 1993) or estimating motion (Koch, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 200
                            }
                        ],
                        "text": "At the physiological level, multiplicative neuronal interactions (Andersen, Essick, & Siegel, 1985; Olshausen, Anderson, & van Essen, 1993; Riesenhuber & Dayan, 1997), arising from nonlinear synaptic (Koch, 1997) or populationlevel (Salinas & Abbott, 1993) mechanisms, have been proposed for visual computations that require the synergistic combination of two inputs, such as modulating spatial attention (Andersen et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4364990,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6794d696c8f5be2a9ac3ddcd9ffaa5158eb97abf",
            "isKey": true,
            "numCitedBy": 191,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Neurons and their networks underlie our perceptions, actions and memories. The latest work on information processing and storage at the single-cell level reveals previously unimagined complexity and dynamism."
            },
            "slug": "Computation-and-the-single-neuron-Koch",
            "title": {
                "fragments": [],
                "text": "Computation and the single neuron"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The latest work on information processing and storage at the single-cell level reveals previously unimagined complexity and dynamism."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40756601"
                        ],
                        "name": "D. A. Dunnett",
                        "slug": "D.-A.-Dunnett",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Dunnett",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Dunnett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 99
                            }
                        ],
                        "text": "The electrostatic forces used to find the correspondences are easily calculated from Coulomb\u2019s law (Jackson, 1975)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4268632,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "e4a81b32bdc0adbf599bb8e98e53ec1adfa91878",
            "isKey": false,
            "numCitedBy": 23190,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Electrodynamics of Particles and PlasmasBy P. C. Clemmow and J. P. Dougherty. (Addison-Wesley Series in Advanced Physics.) Pp. ix + 457. (Addison-Wesley London, September 1969.) 163s."
            },
            "slug": "Classical-Electrodynamics-Dunnett",
            "title": {
                "fragments": [],
                "text": "Classical Electrodynamics"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068005343"
                        ],
                        "name": "R. Iyer",
                        "slug": "R.-Iyer",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Iyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Iyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 205
                            }
                        ],
                        "text": "As in the two-factor case, we iteratively apply linear matrix techniques to solve for the parameters of each factor given parameter estimates for the other factors, until all parameter estimates converge (Magnus & Neudecker, 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 62
                            }
                        ],
                        "text": "The algorithm we use was described for scalar observations by Magnus and Neudecker (1988) and adapted to vector observations by Marimont and Wandell (1992), in the context of characterizing color surface and illuminant spectra."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 5
                            }
                        ],
                        "text": "(See Magnus & Neudecker, 1988, for a proof for the scalar case, K = 1, which can be extended to the vector case considered here.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 131
                            }
                        ],
                        "text": "The most obvious extension of our work is to observations and tasks with more than two underlying factors, via multilinear models (Magnus & Neudecker, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125362180,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e763e3c673392822a125133ac4467e05896fc08c",
            "isKey": true,
            "numCitedBy": 1957,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matrix-Differential-Calculus-with-Applications-in-Iyer",
            "title": {
                "fragments": [],
                "text": "Matrix Differential Calculus with Applications in Statistics and Econometrics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 87
                            }
                        ],
                        "text": "The first experiment with the speech data was the standard benchmark task described in Robinson (1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 28
                            }
                        ],
                        "text": "Of the many techniques that Robinson (1989) tested, 1-nearest neighbor (1-NN) performs the best, with 56.3% correct; chance is approximately 9% correct."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic error propagation networks"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished doctoral dissertation, Cambridge University."
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 87
                            }
                        ],
                        "text": "The first experiment with the speech data was the standard benchmark task described in Robinson (1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 28
                            }
                        ],
                        "text": "Of the many techniques that Robinson (1989) tested, 1-nearest neighbor (1-NN) performs the best, with 56.3% correct; chance is approximately 9% correct."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic error propagation networks. Unpublished doctoral dissertation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69424229"
                        ],
                        "name": "\u6ecb \u7be0\u672c",
                        "slug": "\u6ecb-\u7be0\u672c",
                        "structuredName": {
                            "firstName": "\u6ecb",
                            "lastName": "\u7be0\u672c",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u6ecb \u7be0\u672c"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 60310468,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6e365a6ef2f2118497ec188b03a3e13c99744a19",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computation-and-the-single-neuron-\u6ecb",
            "title": {
                "fragments": [],
                "text": "Computation and the single neuron"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 177
                            }
                        ],
                        "text": "More generally, the ability to learn constrained solutions to a priori underconstrained inference problems may turn out to be essential for perception (Poggio & Hurlbert, 1994; Nayar & Poggio, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 141482914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc7f89f8778f1154d59ae31299fca0aa5073a8da",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1: Shree Nayar & Tomaso Poggio: Early Visual Learning. 2: Jon Pauls, Emanuela Bricolo, & Nikos Logothetis: View Invariant Representations in Monkey Temporal Cortex: Position, Scale, and Rotational Invariance. 3: Tomaso Poggio & David Beymer: Regularization Networks for Visual Learning. 4: Arthur R. Pope & David G. Lowe: Learning Probabilistic Appearance Models for Object Recognition. 5: Baback Moghaddam & Alex Pentland: Probabilistic Visual Learning for Object Representation. 6: Shree K. Nayar, Hiroshi Murase, & Sameer A. Nene: Parametric Appearance Representation. 7: Dean Pomerieau: Neural Network Vision for Robot Driving. 8: John J. Weng: Cresceptron and SHOSLIF: Toward Comprehensive Visual Learning. 9: Randal C. Nelson: Memorization Learning for Object Recognition. 10: Usama M. Fayyad, Padhraic H. Smyth, Michael C. Burt, & Pietro Perona: Learning to Catalog Science Images. 11: Bir Bhanu, Xing Wu, & Sungkee Lee: Genetic Algorithms for Adaptive Image Segmentation. 12: Hayit Greenspan: Non-Parametric Texture Learning. 13: Marcos Salganicoff, Michele Rucci, & Ruzena Bajcsy: Unsupervised Visual-Tactile Learning for Control of Manipulation"
            },
            "slug": "Early-Visual-Learning-Nayar-Poggio",
            "title": {
                "fragments": [],
                "text": "Early Visual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a meta-modelling architecture that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually cataloging and annotating images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to Learn. Kluwer"
            },
            "venue": {
                "fragments": [],
                "text": "Learning to Learn. Kluwer"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fluid Concepts and Creative Analogies. Basic Books"
            },
            "venue": {
                "fragments": [],
                "text": "Fluid Concepts and Creative Analogies. Basic Books"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The generic bilinear calibrationnestimation problem"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 72
                            }
                        ],
                        "text": "Thus, our work is closest in spirit to the family discovery approach of Omohundro (1995), differing primarily in our focus on bilinear models to parameterize the style \u00d7 content interaction."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Family discovery Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Family discovery Advances in neural information processing systems"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classical electrodynamics (2nd ed.)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical approach to shape from shading: Reconstruction of 3d face surfaces from single 2d images"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 40
                            }
                        ],
                        "text": "perceptual observations remains elusive (Hofstadter, 1985)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 143
                            }
                        ],
                        "text": "Yet a general and tractable computational model of this ability to untangle the underlying factors of perceptual observations remains elusive (Hofstadter, 1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Metamagical themas"
            },
            "venue": {
                "fragments": [],
                "text": "New York: Basic Books."
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mind Sights. F reeman"
            },
            "venue": {
                "fragments": [],
                "text": "Mind Sights. F reeman"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two algorithms for iterative computation of the singular value decomposition from inputtoutput samples"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. in Neural Information Processing Systems"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical approach to shape from shading: Reconstruction of 3d face surfaces from single 2d images"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classical electrodynamics (2nd ed.). New York: Wiley. Downloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015349 by guest on"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "It has been suggested that SVD, the essential computational procedure for learning in our framework, can be implemented naturally in neural networks using Hebb-like learning rules (Sanger, 1989, 1994; Oja, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two algorithms for iterative computation of the singular value decomposition from input/output samples"
            },
            "venue": {
                "fragments": [],
                "text": "J. Cowan, G. Tesauro, &"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 49
                            }
                        ],
                        "text": "Preliminary reports of this material appeared in Tenenbaum and Freeman (1997) and Freeman and Tenenbaum (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Separating style and content Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Separating style and content Advances in neural information processing systems"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Received October"
            },
            "venue": {
                "fragments": [],
                "text": "Received October"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 139
                            }
                        ],
                        "text": "The ability to draw analogies across observations in different contexts is a hallmark of human perception and cognition (Hofstadter, 1995; Holyoak & Barnden, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Advances in connectionist and neural computation theory"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in connectionist and neural computation theory"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 143
                            }
                        ],
                        "text": "Our approach is also related to the \u201clearning-to-learn\u201d research program (Thrun & Pratt, 1998)\u2014also known as task transfer or multitask learning (Caruana, 1998)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multitask learning Learning to learn"
            },
            "venue": {
                "fragments": [],
                "text": "Multitask learning Learning to learn"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Advances in Connectionist and Neural Computation Theory. Ablex"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Connectionist and Neural Computation Theory. Ablex"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "It has been suggested that SVD, the essential computational procedure for learning in our framework, can be implemented naturally in neural networks using Hebb-like learning rules (Sanger, 1989, 1994; Oja, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two algorithms for iterative computation of the singular value decomposition from input/output samples Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Two algorithms for iterative computation of the singular value decomposition from input/output samples Advances in neural information processing systems"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "\u2026upright position, but cannot be discriminated from two-dimensional ink blotches when viewed upside down so that the shading conventions are atypical (Shepard, 1990), or when the underlying three-dimensional structure has been distorted away from a globally facelike shape (Moore & Cavanagh, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 329
                            }
                        ],
                        "text": "So-called Mooney faces\u2014brightness-thresholded face images in which shading is the only cue to shape\u2014can be easily recognized as images of three-dimensional surfaces when viewed in upright position, but cannot be discriminated from two-dimensional ink blotches when viewed upside down so that the shading conventions are atypical (Shepard, 1990), or when the underlying three-dimensional structure has been distorted away from a globally facelike shape (Moore & Cavanagh, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mind sights"
            },
            "venue": {
                "fragments": [],
                "text": "New York: Freeman."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Family discovery. I n A dv"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Information Processing Systems"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 30,
            "methodology": 16,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 78,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Separating-Style-and-Content-with-Bilinear-Models-Tenenbaum-Freeman/7e85f7d59e37972ec52cbabfef0512588d87f125?sort=total-citations"
}