{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149531"
                        ],
                        "name": "Arthur D. Szlam",
                        "slug": "Arthur-D.-Szlam",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Szlam",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur D. Szlam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "To avoid this problem, [2] proposed a hierarchical clustering of graph substructures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Neural networks on fixed graphs [2] introduce convolutional networks on graphs in the regime where the graph structure is fixed, and each training example differs only in having different features at the vertices of the same graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17682909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e925a9f1e20df61d1e860a7aa71894b35a1c186",
            "isKey": false,
            "numCitedBy": 2788,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures."
            },
            "slug": "Spectral-Networks-and-Locally-Connected-Networks-on-Bruna-Zaremba",
            "title": {
                "fragments": [],
                "text": "Spectral Networks and Locally Connected Networks on Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper considers possible generalizations of CNNs to signals defined on more general domains without the action of a translation group, and proposes two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260481"
                        ],
                        "name": "F. Scarselli",
                        "slug": "F.-Scarselli",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Scarselli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scarselli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784450"
                        ],
                        "name": "M. Hagenbuchner",
                        "slug": "M.-Hagenbuchner",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Hagenbuchner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hagenbuchner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3073217"
                        ],
                        "name": "G. Monfardini",
                        "slug": "G.-Monfardini",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Monfardini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Monfardini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Neural networks on input-dependent graphs [22] propose a neural network model for graphs having an interesting training procedure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "However, it may be fruitful to apply multiple layers of nonlinearities between each message-passing step (as in [22]), or to make information preservation easier by adapting the Long Short-Term Memory [10] architecture to pass information upwards."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206756462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3efd851140aa28e95221b55fcc5659eea97b172d",
            "isKey": false,
            "numCitedBy": 3206,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities."
            },
            "slug": "The-Graph-Neural-Network-Model-Scarselli-Gori",
            "title": {
                "fragments": [],
                "text": "The Graph Neural Network Model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains, and implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3318293"
                        ],
                        "name": "A. Lusci",
                        "slug": "A.-Lusci",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Lusci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lusci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2028880"
                        ],
                        "name": "G. Pollastri",
                        "slug": "G.-Pollastri",
                        "structuredName": {
                            "firstName": "Gianluca",
                            "lastName": "Pollastri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pollastri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Neural graph fingerprints The most closely related work is [15], who build a neural network having graph-valued inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6363483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3e025049142be3d97d559cca12b027f16c6349e",
            "isKey": false,
            "numCitedBy": 361,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Shallow machine learning methods have been applied to chemoinformatics problems with some success. As more data becomes available and more complex problems are tackled, deep machine learning methods may also become useful. Here, we present a brief overview of deep learning methods and show in particular how recursive neural network approaches can be applied to the problem of predicting molecular properties. However, molecules are typically described by undirected cyclic graphs, while recursive approaches typically use directed acyclic graphs. Thus, we develop methods to address this discrepancy, essentially by considering an ensemble of recursive neural networks associated with all possible vertex-centered acyclic orientations of the molecular graph. One advantage of this approach is that it relies only minimally on the identification of suitable molecular descriptors because suitable representations are learned automatically from the data. Several variants of this approach are applied to the problem of predicting aqueous solubility and tested on four benchmark data sets. Experimental results show that the performance of the deep learning methods matches or exceeds the performance of other state-of-the-art methods according to several evaluation metrics and expose the fundamental limitations arising from training sets that are too small or too noisy. A Web-based predictor, AquaSol, is available online through the ChemDB portal ( cdb.ics.uci.edu ) together with additional material."
            },
            "slug": "Deep-Architectures-and-Deep-Learning-in-The-of-for-Lusci-Pollastri",
            "title": {
                "fragments": [],
                "text": "Deep Architectures and Deep Learning in Chemoinformatics: The Prediction of Aqueous Solubility for Drug-Like Molecules"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A brief overview of deep learning methods is presented and in particular how recursive neural network approaches can be applied to the problem of predicting molecular properties, by considering an ensemble of recursive neural networks associated with all possible vertex-centered acyclic orientations of the molecular graph."
            },
            "venue": {
                "fragments": [],
                "text": "J. Chem. Inf. Model."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41231471"
                        ],
                        "name": "A. Micheli",
                        "slug": "A.-Micheli",
                        "structuredName": {
                            "firstName": "Alessio",
                            "lastName": "Micheli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Micheli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] also propose a neural network model for graphs with a learning scheme whose inner loop optimizes not the training loss, but rather the correlation between each newly-proposed vector and the training error residual."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17486263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec2b2569b3a0d70a5b45d48b041dec9060d85eb7",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach for learning in structured domains (SDs) using a constructive neural network for graphs (NN4G). The new model allows the extension of the input domain for supervised neural networks to a general class of graphs including both acyclic/cyclic, directed/undirected labeled graphs. In particular, the model can realize adaptive contextual transductions, learning the mapping from graphs for both classification and regression tasks. In contrast to previous neural networks for structures that had a recursive dynamics, NN4G is based on a constructive feedforward architecture with state variables that uses neurons with no feedback connections. The neurons are applied to the input graphs by a general traversal process that relaxes the constraints of previous approaches derived by the causality assumption over hierarchical input data. Moreover, the incremental approach eliminates the need to introduce cyclic dependencies in the definition of the system state variables. In the traversal process, the NN4G units exploit (local) contextual information of the graphs vertices. In spite of the simplicity of the approach, we show that, through the compositionality of the contextual information developed by the learning, the model can deal with contextual information that is incrementally extended according to the graphs topology. The effectiveness and the generality of the new approach are investigated by analyzing its theoretical properties and providing experimental results."
            },
            "slug": "Neural-Network-for-Graphs:-A-Contextual-Approach-Micheli",
            "title": {
                "fragments": [],
                "text": "Neural Network for Graphs: A Contextual Constructive Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The new model allows the extension of the input domain for supervised neural networks to a general class of graphs including both acyclic/cyclic, directed/undirected labeled graphs and can realize adaptive contextual transductions, learning the mapping from graphs for both classification and regression tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378027"
                        ],
                        "name": "Bharath Ramsundar",
                        "slug": "Bharath-Ramsundar",
                        "structuredName": {
                            "firstName": "Bharath",
                            "lastName": "Ramsundar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bharath Ramsundar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3157072"
                        ],
                        "name": "S. Kearnes",
                        "slug": "S.-Kearnes",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Kearnes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kearnes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119508204"
                        ],
                        "name": "Patrick F. Riley",
                        "slug": "Patrick-F.-Riley",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Riley",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick F. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47191829"
                        ],
                        "name": "D. Webster",
                        "slug": "D.-Webster",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Webster",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Webster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316826"
                        ],
                        "name": "D. Konerding",
                        "slug": "D.-Konerding",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Konerding",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Konerding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806271"
                        ],
                        "name": "V. Pande",
                        "slug": "V.-Pande",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Pande",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pande"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2127453,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72de1bfa528c9450a57394c900361acf1e85b8d0",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Massively multitask neural architectures provide a learning framework for drug discovery that synthesizes information from many distinct biological sources. To train these architectures at scale, we gather large amounts of data from public sources to create a dataset of nearly 40 million measurements across more than 200 biological targets. We investigate several aspects of the multitask framework by performing a series of empirical studies and obtain some interesting results: (1) massively multitask networks obtain predictive accuracies significantly better than single-task methods, (2) the predictive power of multitask networks improves as additional tasks and data are added, (3) the total amount of data and the total number of tasks both contribute significantly to multitask improvement, and (4) multitask networks afford limited transferability to tasks not in the training set. Our results underscore the need for greater data sharing and further algorithmic innovation to accelerate the drug discovery process."
            },
            "slug": "Massively-Multitask-Networks-for-Drug-Discovery-Ramsundar-Kearnes",
            "title": {
                "fragments": [],
                "text": "Massively Multitask Networks for Drug Discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results underscore the need for greater data sharing and further algorithmic innovation to accelerate the drug discovery process and investigate several aspects of the multitask framework."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583391"
                        ],
                        "name": "Nal Kalchbrenner",
                        "slug": "Nal-Kalchbrenner",
                        "structuredName": {
                            "firstName": "Nal",
                            "lastName": "Kalchbrenner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nal Kalchbrenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1864353"
                        ],
                        "name": "Edward Grefenstette",
                        "slug": "Edward-Grefenstette",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Grefenstette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685771"
                        ],
                        "name": "P. Blunsom",
                        "slug": "P.-Blunsom",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Blunsom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Blunsom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1306065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27725a2d2a8cee9bf9fffc6c2167017103aba0fa",
            "isKey": false,
            "numCitedBy": 2989,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline."
            },
            "slug": "A-Convolutional-Neural-Network-for-Modelling-Kalchbrenner-Grefenstette",
            "title": {
                "fragments": [],
                "text": "A Convolutional Neural Network for Modelling Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) is described that is adopted for the semantic modelling of sentences and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] used circular fingerprints as inputs to an ensemble of neural networks, Gaussian processes, and random forests."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14119565,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "455e630308f5a80bf3e33abff7b58c258d5ad837",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Although artificial neural networks have occasionally been used for Quantitative Structure-Activity/Property Relationship (QSAR/QSPR) studies in the past, the literature has of late been dominated by other machine learning techniques such as random forests. However, a variety of new neural net techniques along with successful applications in other domains have renewed interest in network approaches. In this work, inspired by the winning team's use of neural networks in a recent QSAR competition, we used an artificial neural network to learn a function that predicts activities of compounds for multiple assays at the same time. We conducted experiments leveraging recent methods for dealing with overfitting in neural networks as well as other tricks from the neural networks literature. We compared our methods to alternative methods reported to perform well on these tasks and found that our neural net methods provided superior performance."
            },
            "slug": "Multi-task-Neural-Networks-for-QSAR-Predictions-Dahl-Jaitly",
            "title": {
                "fragments": [],
                "text": "Multi-task Neural Networks for QSAR Predictions"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work used an artificial neural network to learn a function that predicts activities of compounds for multiple assays at the same time and compared its methods to alternative methods reported to perform well on these tasks and found that the neural net methods provided superior performance."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465270"
                        ],
                        "name": "Thomas Unterthiner",
                        "slug": "Thomas-Unterthiner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Unterthiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Unterthiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144831680"
                        ],
                        "name": "Andreas Mayr",
                        "slug": "Andreas-Mayr",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Mayr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Mayr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34833911"
                        ],
                        "name": "J. Wegner",
                        "slug": "J.-Wegner",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Wegner",
                            "middleNames": [
                                "Kurt"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wegner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "For example, [28] used a fingerprint vector of size 43,000, after having removed rarely-occurring features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38235267,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "95f7b2c0fe75f08e3ce0d2ac4315166f4239db5c",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep learning excels in vision and speech applications where it pushed the stateof-the-art to a new level. However its impact on other fields remains to be shown. The Merck Kaggle challenge on chemical compound activity was won by Hinton\u2019s group with deep networks. This indicates the high potential of deep learning in drug design and attracted the attention of big pharma. However, the unrealistically small scale of the Kaggle dataset does not allow to assess the value of deep learning in drug target prediction if applied to in-house data of pharmaceutical companies. Even a publicly available drug activity data base like ChEMBL is magnitudes larger than the Kaggle dataset. ChEMBL has 13 M compound descriptors, 1.3 M compounds, and 5 k drug targets, compared to the Kaggle dataset with 11 k descriptors, 164 k compounds, and 15 drug targets. On the ChEMBL database, we compared the performance of deep learning to seven target prediction methods, including two commercial predictors, three predictors deployed by pharma, and machine learning methods that we could scale to this dataset. Deep learning outperformed all other methods with respect to the area under ROC curve and was significantly better than all commercial products. Deep learning surpassed the threshold to make virtual compound screening possible and has the potential to become a standard tool in industrial drug design. \u2217These authors contributed equally to this work"
            },
            "slug": "Deep-Learning-as-an-Opportunity-in-Virtual-Unterthiner-Mayr",
            "title": {
                "fragments": [],
                "text": "Deep Learning as an Opportunity in Virtual Screening"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Deep learning surpassed the threshold to make virtual compound screening possible and has the potential to become a standard tool in industrial drug design and was significantly better than all commercial products."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054531802"
                        ],
                        "name": "D. Rogers",
                        "slug": "D.-Rogers",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rogers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rogers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32559603"
                        ],
                        "name": "M. Hahn",
                        "slug": "M.-Hahn",
                        "structuredName": {
                            "firstName": "Mathew",
                            "lastName": "Hahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hahn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "The state of the art in molecular fingerprints are extended-connectivity circular fingerprints (ECFP) [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "2 Circular fingerprints The state of the art in molecular fingerprints are extended-connectivity circular fingerprints (ECFP) [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "In our convolutional networks, the initial atom and bond features were chosen to be similar to those used by ECFP: Initial atom features concatenated a one-hot encoding of the atom\u2019s element, its degree, the number of attached hydrogen atoms, and the implicit valence, and an aromaticity indicator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "The line of points on the right of the plot shows that for some pairs of molecules, binary ECFP fingerprints have exactly zero overlap."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5132461,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d1b796ff0c1895426de11a1eaafc5443be29645d",
            "isKey": true,
            "numCitedBy": 3284,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "Extended-connectivity fingerprints (ECFPs) are a novel class of topological fingerprints for molecular characterization. Historically, topological fingerprints were developed for substructure and similarity searching. ECFPs were developed specifically for structure-activity modeling. ECFPs are circular fingerprints with a number of useful qualities: they can be very rapidly calculated; they are not predefined and can represent an essentially infinite number of different molecular features (including stereochemical information); their features represent the presence of particular substructures, allowing easier interpretation of analysis results; and the ECFP algorithm can be tailored to generate different types of circular fingerprints, optimized for different uses. While the use of ECFPs has been widely adopted and validated, a description of their implementation has not previously been presented in the literature."
            },
            "slug": "Extended-Connectivity-Fingerprints-Rogers-Hahn",
            "title": {
                "fragments": [],
                "text": "Extended-Connectivity Fingerprints"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A description of their implementation has not previously been presented in the literature, and ECFPs can be very rapidly calculated and can represent an essentially infinite number of different molecular features."
            },
            "venue": {
                "fragments": [],
                "text": "J. Chem. Inf. Model."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12352574"
                        ],
                        "name": "Robert C Glem",
                        "slug": "Robert-C-Glem",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Glem",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert C Glem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144917032"
                        ],
                        "name": "A. Bender",
                        "slug": "A.-Bender",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Bender",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bender"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3311000"
                        ],
                        "name": "C. H. Arnby",
                        "slug": "C.-H.-Arnby",
                        "structuredName": {
                            "firstName": "Catrin",
                            "lastName": "Arnby",
                            "middleNames": [
                                "Hasselgren"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Arnby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144743758"
                        ],
                        "name": "L. Carlsson",
                        "slug": "L.-Carlsson",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carlsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144396841"
                        ],
                        "name": "S. Boyer",
                        "slug": "S.-Boyer",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Boyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Boyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119124938"
                        ],
                        "name": "James Smith",
                        "slug": "James-Smith",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30264445,
            "fieldsOfStudy": [
                "Chemistry",
                "Biology"
            ],
            "id": "48424cd5c1099429d6cd92b3627a59e0a2aacb79",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Circular fingerprints -- the representation of molecular structures by atom neighborhoods -- have been applied to a wide range of applications, such as similarity searching and the prediction of absorption, distribution, metabolism, excretion and toxicity properties. In recent years there has been a surge in applications resulting from the superior performance of circular fingerprints in comparative studies. This feature examines the nature of circular fingerprints as well as their applications, including virtual screening, metabolism prediction and the estimation of pK((a)) constants."
            },
            "slug": "Circular-fingerprints:-flexible-molecular-with-from-Glem-Bender",
            "title": {
                "fragments": [],
                "text": "Circular fingerprints: flexible molecular descriptors with applications from physical chemistry to ADME."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The nature of circular fingerprints as well as their applications are examined, including virtual screening, metabolism prediction and the estimation of pK((a)) constants."
            },
            "venue": {
                "fragments": [],
                "text": "IDrugs : the investigational drugs journal"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2387467"
                        ],
                        "name": "J. Hershey",
                        "slug": "J.-Hershey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hershey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hershey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9332945"
                        ],
                        "name": "Jonathan Le Roux",
                        "slug": "Jonathan-Le-Roux",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Le Roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Le Roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740602"
                        ],
                        "name": "F. Weninger",
                        "slug": "F.-Weninger",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Weninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Weninger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Unrolled inference algorithms [9] and others have noted that iterative inference procedures sometimes resemble the feedforward computation of a recurrent neural network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17026226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e20f9de45d26950ecd11965989d2b15a5d0d86b",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Model-based methods and deep neural networks have both been tremendously successful paradigms in machine learning. In model-based methods, problem domain knowledge can be built into the constraints of the model, typically at the expense of difficulties during inference. In contrast, deterministic deep neural networks are constructed in such a way that inference is straightforward, but their architectures are generic and it is unclear how to incorporate knowledge. This work aims to obtain the advantages of both approaches. To do so, we start with a model-based approach and an associated inference algorithm, and \\emph{unfold} the inference iterations as layers in a deep network. Rather than optimizing the original model, we \\emph{untie} the model parameters across layers, in order to create a more powerful network. The resulting architecture can be trained discriminatively to perform accurate inference within a fixed network size. We show how this framework allows us to interpret conventional networks as mean-field inference in Markov random fields, and to obtain new architectures by instead using belief propagation as the inference algorithm. We then show its application to a non-negative matrix factorization model that incorporates the problem-domain knowledge that sound sources are additive. Deep unfolding of this model yields a new kind of non-negative deep neural network, that can be trained using a multiplicative backpropagation-style update algorithm. We present speech enhancement experiments showing that our approach is competitive with conventional neural networks despite using far fewer parameters."
            },
            "slug": "Deep-Unfolding:-Model-Based-Inspiration-of-Novel-Hershey-Roux",
            "title": {
                "fragments": [],
                "text": "Deep Unfolding: Model-Based Inspiration of Novel Deep Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work starts with a model-based approach and an associated inference algorithm, and folds the inference iterations as layers in a deep network, and shows how this framework allows to interpret conventional networks as mean-field inference in Markov random fields, and to obtain new architectures by instead using belief propagation as the inference algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465270"
                        ],
                        "name": "Thomas Unterthiner",
                        "slug": "Thomas-Unterthiner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Unterthiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Unterthiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144831680"
                        ],
                        "name": "Andreas Mayr",
                        "slug": "Andreas-Mayr",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Mayr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Mayr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1994964"
                        ],
                        "name": "G. Klambauer",
                        "slug": "G.-Klambauer",
                        "structuredName": {
                            "firstName": "G\u00fcnter",
                            "lastName": "Klambauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Klambauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[27] constructed similar visualizations, but in a semi-manual way: to determine which toxic fragments activated a given neuron, they searched over a hand-made list of toxic substructures and chose the one most correlated with a given neuron."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17772075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65c10300c2094d86c47928ddf70eeda7d083dec9",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Everyday we are exposed to various chemicals via food additives, cleaning and cosmetic products and medicines \u2014 and some of them might be toxic. However testing the toxicity of all existing compounds by biological experiments is neither financially nor logistically feasible. Therefore the government agencies NIH, EPA and FDA launched the Tox21 Data Challenge within the \u201cToxicology in the 21st Century\u201d (Tox21) initiative. The goal of this challenge was to assess the performance of computational methods in predicting the toxicity of chemical compounds. State of the art toxicity prediction methods build upon specifically-designed chemical descriptors developed over decades. Though Deep Learning is new to the field and was never applied to toxicity prediction before, it clearly outperformed all other participating methods. In this application paper we show that deep nets automatically learn features resembling well-established toxicophores. In total, our Deep Learning approach won both of the panel-challenges (nuclear receptors and stress response) as well as the overall Grand Challenge, and thereby sets a new standard in tox prediction."
            },
            "slug": "Toxicity-Prediction-using-Deep-Learning-Unterthiner-Mayr",
            "title": {
                "fragments": [],
                "text": "Toxicity Prediction using Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The Deep Learning approach won both of the panel-challenges (nuclear receptors and stress response) as well as the overall Grand Challenge, and thereby sets a new standard in tox prediction."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227028"
                        ],
                        "name": "Fr\u00e9d\u00e9ric Bastien",
                        "slug": "Fr\u00e9d\u00e9ric-Bastien",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Bastien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fr\u00e9d\u00e9ric Bastien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996134"
                        ],
                        "name": "Razvan Pascanu",
                        "slug": "Razvan-Pascanu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Pascanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan Pascanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47944877"
                        ],
                        "name": "Arnaud Bergeron",
                        "slug": "Arnaud-Bergeron",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Bergeron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnaud Bergeron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065828537"
                        ],
                        "name": "Nicolas Bouchard",
                        "slug": "Nicolas-Bouchard",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Bouchard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Bouchard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393680089"
                        ],
                        "name": "David Warde-Farley",
                        "slug": "David-Warde-Farley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warde-Farley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Warde-Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Software Automatic differentiation (AD) software packages such as Theano [1] significantly speed up development time by providing gradients automatically, but can only handle limited control structures and indexing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8180128,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "855d0f722d75cc56a66a00ede18ace96bafee6bd",
            "isKey": false,
            "numCitedBy": 1374,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks."
            },
            "slug": "Theano:-new-features-and-speed-improvements-Bastien-Lamblin",
            "title": {
                "fragments": [],
                "text": "Theano: new features and speed improvements"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "New features and efficiency improvements to Theano are presented, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8421815"
                        ],
                        "name": "Kai Sheng Tai",
                        "slug": "Kai-Sheng-Tai",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Tai",
                            "middleNames": [
                                "Sheng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Sheng Tai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Techniques from natural language processing [25] might be fruitfully adapted to this domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3033526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "isKey": false,
            "numCitedBy": 2501,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank)."
            },
            "slug": "Improved-Semantic-Representations-From-Long-Memory-Tai-Socher",
            "title": {
                "fragments": [],
                "text": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Tree-LSTM is introduced, a generalization of LSTMs to tree-structured network topologies that outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences and sentiment classification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053671127"
                        ],
                        "name": "Li Wan",
                        "slug": "Li-Wan",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33551113"
                        ],
                        "name": "Sixin Zhang",
                        "slug": "Sixin-Zhang",
                        "structuredName": {
                            "firstName": "Sixin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sixin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2936324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38f35dd624cd1cf827416e31ac5e0e0454028eca",
            "isKey": false,
            "numCitedBy": 2093,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models."
            },
            "slug": "Regularization-of-Neural-Networks-using-DropConnect-Wan-Zeiler",
            "title": {
                "fragments": [],
                "text": "Regularization of Neural Networks using DropConnect"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work introduces DropConnect, a generalization of Dropout, for regularizing large fully-connected layers within neural networks, and derives a bound on the generalization performance of both Dropout and DropConnect."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89504302"
                        ],
                        "name": "Greg Wayne",
                        "slug": "Greg-Wayne",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Wayne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Wayne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841008"
                        ],
                        "name": "Ivo Danihelka",
                        "slug": "Ivo-Danihelka",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Danihelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo Danihelka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15299054,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3823aacea60bc1f2cabb9283144690a3d015db5",
            "isKey": false,
            "numCitedBy": 1634,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples."
            },
            "slug": "Neural-Turing-Machines-Graves-Wayne",
            "title": {
                "fragments": [],
                "text": "Neural Turing Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Training and Architecture Training used batch normalization [11]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5808102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d376d6978dad0374edfa6709c9556b42d3594d3",
            "isKey": false,
            "numCitedBy": 29234,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."
            },
            "slug": "Batch-Normalization:-Accelerating-Deep-Network-by-Ioffe-Szegedy",
            "title": {
                "fragments": [],
                "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40150953"
                        ],
                        "name": "E. Huang",
                        "slug": "E.-Huang",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Huang",
                            "middleNames": [
                                "Hsin-Chun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "A recursive neural network [23, 24] is then run from the leaves to the root to produce a fixed-size representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3116311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfa2646776405d50533055ceb1b7f050e9014dcb",
            "isKey": false,
            "numCitedBy": 1244,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines."
            },
            "slug": "Semi-Supervised-Recursive-Autoencoders-for-Socher-Pennington",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions that outperform other state-of-the-art approaches on commonly used datasets, without using any pre-defined sentiment lexica or polarity shifting rules."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40150953"
                        ],
                        "name": "E. Huang",
                        "slug": "E.-Huang",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Huang",
                            "middleNames": [
                                "Hsin-Chun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "A recursive neural network [23, 24] is then run from the leaves to the root to produce a fixed-size representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6979578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae5e6c6f5513613a161b2c85563f9708bf2e9178",
            "isKey": false,
            "numCitedBy": 887,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Paraphrase detection is the task of examining two sentences and determining whether they have the same meaning. In order to obtain high accuracy on this task, thorough syntactic and semantic analysis of the two statements is needed. We introduce a method for paraphrase detection based on recursive autoencoders (RAE). Our unsupervised RAEs are based on a novel unfolding objective and learn feature vectors for phrases in syntactic trees. These features are used to measure the word- and phrase-wise similarity between two sentences. Since sentences may be of arbitrary length, the resulting matrix of similarity measures is of variable size. We introduce a novel dynamic pooling layer which computes a fixed-sized representation from the variable-sized matrices. The pooled representation is then used as input to a classifier. Our method outperforms other state-of-the-art approaches on the challenging MSRP paraphrase corpus."
            },
            "slug": "Dynamic-Pooling-and-Unfolding-Recursive-for-Socher-Huang",
            "title": {
                "fragments": [],
                "text": "Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces a method for paraphrase detection based on recursive autoencoders (RAE) and unsupervised RAEs based on a novel unfolding objective and learns feature vectors for phrases in syntactic trees to measure word- and phrase-wise similarity between two sentences."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "Each experiment optimized for 10000 minibatches of size 100 using the Adam algorithm [13], a variant of RMSprop that includes momentum."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90076,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35525979"
                        ],
                        "name": "T. Oliphant",
                        "slug": "T.-Oliphant",
                        "structuredName": {
                            "firstName": "Travis",
                            "lastName": "Oliphant",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Oliphant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "This package handles standard Numpy [18] code, and can differentiate code containing while loops, branches, and indexing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206457124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c647e8d93d85cdc6fb8c19deaf2eb9ec5c8d8941",
            "isKey": false,
            "numCitedBy": 2653,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Python is an excellent \"steering\" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions."
            },
            "slug": "Python-for-Scientific-Computing-Oliphant",
            "title": {
                "fragments": [],
                "text": "Python for Scientific Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Python is an excellent \"steering\" language for scientific codes written in other languages, but with additional basic tools, it transforms into a high-level language suited for scientific and engineering code that's often fastenough to be immediately useful but also flexible enough to be sped up with additional extensions."
            },
            "venue": {
                "fragments": [],
                "text": "Computing in Science & Engineering"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "However, it may be fruitful to apply multiple layers of nonlinearities between each message-passing step (as in [22]), or to make information preservation easier by adapting the Long Short-Term Memory [10] architecture to pass information upwards."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 51693,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339223"
                        ],
                        "name": "D. Weininger",
                        "slug": "D.-Weininger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Weininger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weininger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Experimental setup Our pipeline takes as input the SMILES [30] string encoding of each molecule, which is then converted into a graph using RDKit [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5445756,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "3f7983818b76a5f1b5daf9b605877ed401c8e73c",
            "isKey": false,
            "numCitedBy": 3454,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "(1) Klamer, A. D. \u201cSome Results Concerning Polyominoes\u201d. Fibonacci Q. 1965, 3(1), 9-20. (2) Golomb, S. W. Polyominoes\u00b7, Scribner, New York, 1965. (3) Harary, F.; Read, R. C. \u201cThe Enumeration of Tree-like Polyhexes\u201d. Proc. Edinburgh Math. Soc. 1970, 17, 1-14. (4) Lunnon, W. F. \u201cCounting Polyominoes\u201d in Computers in Number Theory\u00b7, Academic: London, 1971; pp 347-372. (5) Lunnon, W. F. \u201cCounting Hexagonal and Triangular Polyominoes\u201d. Graph Theory Comput. 1972, 87-100. (6) Brunvoll, J.; Cyvin, S. J.; Cyvin, B. N. \u201cEnumeration and Classification of Benzenoid Hydrocarbons\u201d. J. Comput. Chem. 1987, 8, 189-197. (7) Balaban, A. T., et al. \u201cEnumeration of Benzenoid and Coronoid Hydrocarbons\u201d. Z. Naturforsch., A: Phys., Phys. Chem., Kosmophys. 1987, 42A, 863-870. (8) Gutman, I. \u201cTopological Properties of Benzenoid Systems\u201d. Bull. Soc. Chim., Beograd 1982, 47, 453-471. (9) Gutman, I.; Polansky, O. E. Mathematical Concepts in Organic Chemistry\u00b7, Springer: Berlin, 1986. (10) To3i6, R.; Doroslovacki, R.; Gutman, I. \u201cTopological Properties of Benzenoid Systems\u2014The Boundary Code\u201d. MATCH 1986, No. 19, 219-228. (11) Doroslovacki, R.; ToSic, R. \u201cA Characterization of Hexagonal Systems\u201d. Rev. Res. Fac. Sci.-Univ. Novi Sad, Math. Ser. 1984,14(2) 201-209. (12) Knop, J. V.; Szymanski, K.; Trinajstic, N. \u201cComputer Enumeration of Substituted Polyhexes\u201d. Comput. Chem. 1984, 8(2), 107-115. (13) Stojmenovic, L; Tosi\u00f3, R.; Doroslova\u00f3ki, R. \u201cGenerating and Counting Hexagonal Systems\u201d. Proc. Yugosl. Semin. Graph Theory, 6th, Dubrovnik 1985; pp 189-198. (14) Doroslova\u00f3ki, R.; Stojmenovi\u00f3, I.; Tosi\u00f3, R. \u201cGenerating and Counting Triangular Systems\u201d. BIT 1987, 27, 18-24. (15) Knop, J. V.; Miller, W. R.; Szymanski, K.; Trinajstic, N. Computer Generation of Certain Classes of Molecules\u00b7, Association of Chemists and Technologists of Croatia: Zagreb, 1985."
            },
            "slug": "SMILES,-a-chemical-language-and-information-system.-Weininger",
            "title": {
                "fragments": [],
                "text": "SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This chapter discusses the construction of Benzenoid and Coronoid Hydrocarbons through the stages of enumeration, classification, and topological properties in a number of computers used for this purpose."
            },
            "venue": {
                "fragments": [],
                "text": "J. Chem. Inf. Comput. Sci."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34829192"
                        ],
                        "name": "J. Delaney",
                        "slug": "J.-Delaney",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Delaney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Delaney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "The fingerprint network was trained as inputs to a linear model predicting solubility, as measured in [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Fingerprints had length 2048, and were calculated on pairs of molecules from the solubility dataset [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "\u2022 Solubility: The aqueous solubility of 1144 molecules as measured by [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 130
                            }
                        ],
                        "text": "Datasets We compared the performance of standard circular fingerprints against neural graph fingerprints on a variety of domains:\n\u2022 Solubility: The aqueous solubility of 1144 molecules as measured by [4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Solubility features Figure 4 shows the fragments that maximally activate the most predictive features of a fingerprint."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Dataset Solubility [4] Drug efficacy [5] Photovoltaic efficiency [8] Units log Mol/L EC50 in nM percent Predict mean 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29799633,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "3646f61b3dc39749e6546449904d5f8d72308bdf",
            "isKey": true,
            "numCitedBy": 361,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a simple method for estimating the aqueous solubility (ESOL--Estimated SOLubility) of a compound directly from its structure. The model was derived from a set of 2874 measured solubilities using linear regression against nine molecular properties. The most significant parameter was calculated logP(octanol), followed by molecular weight, proportion of heavy atoms in aromatic systems, and number of rotatable bonds. The model performed consistently well across three validation sets, predicting solubilities within a factor of 5-8 of their measured values, and was competitive with the well-established \"General Solubility Equation\" for medicinal/agrochemical sized molecules."
            },
            "slug": "ESOL:-Estimating-Aqueous-Solubility-Directly-from-Delaney",
            "title": {
                "fragments": [],
                "text": "ESOL: Estimating Aqueous Solubility Directly from Molecular Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper describes a simple method for estimating the aqueous solubility (ESOL--Estimated SOLubility) of a compound directly from its structure, and was competitive with the well-established \"General Solubility Equation\" for medicinal/agrochemical sized molecules."
            },
            "venue": {
                "fragments": [],
                "text": "J. Chem. Inf. Model."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40519827"
                        ],
                        "name": "F. Gamo",
                        "slug": "F.-Gamo",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Gamo",
                            "middleNames": [
                                "Javier"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gamo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153791255"
                        ],
                        "name": "Laura M Sanz",
                        "slug": "Laura-M-Sanz",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Sanz",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura M Sanz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144205748"
                        ],
                        "name": "J. Vidal",
                        "slug": "J.-Vidal",
                        "structuredName": {
                            "firstName": "Jaume",
                            "lastName": "Vidal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vidal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93342152"
                        ],
                        "name": "C. Cozar",
                        "slug": "C.-Cozar",
                        "structuredName": {
                            "firstName": "Cristina",
                            "lastName": "Cozar",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cozar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056324475"
                        ],
                        "name": "E. Alvarez",
                        "slug": "E.-Alvarez",
                        "structuredName": {
                            "firstName": "Emilio",
                            "lastName": "Alvarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Alvarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3647318"
                        ],
                        "name": "J. Lavandera",
                        "slug": "J.-Lavandera",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Lavandera",
                            "middleNames": [
                                "Lu\u00eds"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lavandera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13658214"
                        ],
                        "name": "D. Vanderwall",
                        "slug": "D.-Vanderwall",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Vanderwall",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Vanderwall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144670441"
                        ],
                        "name": "D. Green",
                        "slug": "D.-Green",
                        "structuredName": {
                            "firstName": "Darren",
                            "lastName": "Green",
                            "middleNames": [
                                "V.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112233056"
                        ],
                        "name": "Vinod Kumar",
                        "slug": "Vinod-Kumar",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144796504"
                        ],
                        "name": "Samiul Hasan",
                        "slug": "Samiul-Hasan",
                        "structuredName": {
                            "firstName": "Samiul",
                            "lastName": "Hasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samiul Hasan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152787354"
                        ],
                        "name": "James R. Brown",
                        "slug": "James-R.-Brown",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Brown",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3437113"
                        ],
                        "name": "C. E. Peishoff",
                        "slug": "C.-E.-Peishoff",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Peishoff",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. E. Peishoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799276"
                        ],
                        "name": "L. Cardon",
                        "slug": "L.-Cardon",
                        "structuredName": {
                            "firstName": "Lon",
                            "lastName": "Cardon",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cardon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401338159"
                        ],
                        "name": "J. Garcia-Bustos",
                        "slug": "J.-Garcia-Bustos",
                        "structuredName": {
                            "firstName": "Jose",
                            "lastName": "Garcia-Bustos",
                            "middleNames": [
                                "F"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Garcia-Bustos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "falciparum, the parasite that causes malaria, as measured by [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Dataset Solubility [4] Drug efficacy [5] Photovoltaic efficiency [8] Units log Mol/L EC50 in nM percent Predict mean 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1143258,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3719c6fd859bf0f165dc3d948d9250fddc85ee31",
            "isKey": false,
            "numCitedBy": 861,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Malaria is a devastating infection caused by protozoa of the genus Plasmodium. Drug resistance is widespread, no new chemical class of antimalarials has been introduced into clinical practice since 1996 and there is a recent rise of parasite strains with reduced sensitivity to the newest drugs. We screened nearly 2\u2009million compounds in GlaxoSmithKline\u2019s chemical library for inhibitors of P. falciparum, of which 13,533 were confirmed to inhibit parasite growth by at least 80% at 2\u2009\u00b5M concentration. More than 8,000 also showed potent activity against the multidrug resistant strain Dd2. Most (82%) compounds originate from internal company projects and are new to the malaria community. Analyses using historic assay data suggest several novel mechanisms of antimalarial action, such as inhibition of protein kinases and host\u2013pathogen interaction related targets. Chemical structures and associated data are hereby made public to encourage additional drug lead identification efforts and further research into this disease."
            },
            "slug": "Thousands-of-chemical-starting-points-for-lead-Gamo-Sanz",
            "title": {
                "fragments": [],
                "text": "Thousands of chemical starting points for antimalarial lead identification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Chemical structures and associated data suggest several novel mechanisms of antimalarial action, such as inhibition of protein kinases and host\u2013pathogen interaction related targets."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40471981"
                        ],
                        "name": "J. Hachmann",
                        "slug": "J.-Hachmann",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Hachmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hachmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403757169"
                        ],
                        "name": "Roberto Olivares-Amaya",
                        "slug": "Roberto-Olivares-Amaya",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Olivares-Amaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Olivares-Amaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398176607"
                        ],
                        "name": "Sule Atahan-Evrenk",
                        "slug": "Sule-Atahan-Evrenk",
                        "structuredName": {
                            "firstName": "Sule",
                            "lastName": "Atahan-Evrenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sule Atahan-Evrenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404550532"
                        ],
                        "name": "C. Amador-Bedolla",
                        "slug": "C.-Amador-Bedolla",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Amador-Bedolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Amador-Bedolla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401005842"
                        ],
                        "name": "Roel S. S\u00e1nchez-Carrera",
                        "slug": "Roel-S.-S\u00e1nchez-Carrera",
                        "structuredName": {
                            "firstName": "Roel",
                            "lastName": "S\u00e1nchez-Carrera",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roel S. S\u00e1nchez-Carrera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398663888"
                        ],
                        "name": "Aryeh Gold-Parker",
                        "slug": "Aryeh-Gold-Parker",
                        "structuredName": {
                            "firstName": "Aryeh",
                            "lastName": "Gold-Parker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aryeh Gold-Parker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47024906"
                        ],
                        "name": "Leslie Vogt",
                        "slug": "Leslie-Vogt",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Vogt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leslie Vogt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92124471"
                        ],
                        "name": "Anna M. Brockway",
                        "slug": "Anna-M.-Brockway",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Brockway",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna M. Brockway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1380248954"
                        ],
                        "name": "Al\u00e1n Aspuru-Guzik",
                        "slug": "Al\u00e1n-Aspuru-Guzik",
                        "structuredName": {
                            "firstName": "Al\u00e1n",
                            "lastName": "Aspuru-Guzik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Al\u00e1n Aspuru-Guzik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54001464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62618ae02006058a196daf1ea27c21371772cf28",
            "isKey": false,
            "numCitedBy": 458,
            "numCiting": 347,
            "paperAbstract": {
                "fragments": [],
                "text": "This Perspective introduces the Harvard Clean Energy Project (CEP), a theory-driven search for the next generation of organic solar cell materials. We give a broad overview of its setup and infrastructure, present first results, and outline upcoming developments. CEP has established an automated, high-throughput, in silico framework to study potential candidate structures for organic photovoltaics. The current project phase is concerned with the characterization of millions of molecular motifs using first-principles quantum chemistry. The scale of this study requires a correspondingly large computational resource, which is provided by distributed volunteer computing on IBM\u2019s World Community Grid. The results are compiled and analyzed in a reference database and will be made available for public use. In addition to finding specific candidates with certain properties, it is the goal of CEP to illuminate and understand the structure\u2013property relations in the domain of organic electronics. Such insights can o..."
            },
            "slug": "The-Harvard-Clean-Energy-Project:-Large-Scale-and-Hachmann-Olivares-Amaya",
            "title": {
                "fragments": [],
                "text": "The Harvard Clean Energy Project: Large-Scale Computational Screening and Design of Organic Photovoltaics on the World Community Grid"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This Perspective introduces the Harvard Clean Energy Project (CEP), a theory-driven search for the next generation of organic solar cell materials, and gives a broad overview of its setup and infrastructure, present first results, and outline upcoming developments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40471981"
                        ],
                        "name": "J. Hachmann",
                        "slug": "J.-Hachmann",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Hachmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hachmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403757169"
                        ],
                        "name": "Roberto Olivares-Amaya",
                        "slug": "Roberto-Olivares-Amaya",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Olivares-Amaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Olivares-Amaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398176607"
                        ],
                        "name": "Sule Atahan-Evrenk",
                        "slug": "Sule-Atahan-Evrenk",
                        "structuredName": {
                            "firstName": "Sule",
                            "lastName": "Atahan-Evrenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sule Atahan-Evrenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404550532"
                        ],
                        "name": "C. Amador-Bedolla",
                        "slug": "C.-Amador-Bedolla",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Amador-Bedolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Amador-Bedolla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1380248954"
                        ],
                        "name": "Al\u00e1n Aspuru-Guzik",
                        "slug": "Al\u00e1n-Aspuru-Guzik",
                        "structuredName": {
                            "firstName": "Al\u00e1n",
                            "lastName": "Aspuru-Guzik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Al\u00e1n Aspuru-Guzik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 108525149,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "dddcbb18c3d2cfe885327ae4295aeb4ed2ccf205",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Harvard-Clean-Energy-Project.-Large-scale-and-Hachmann-Olivares-Amaya",
            "title": {
                "fragments": [],
                "text": "The Harvard Clean Energy Project. Large-scale computational screening and design of molecular motifs for organic photovoltaics on the World Community Grid"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70523593"
                        ],
                        "name": "H. L. Morgan",
                        "slug": "H.-L.-Morgan",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Morgan",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. L. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Circular fingerprints [6] are a refinement of the Morgan algorithm [17], designed to encode which substructures are present in a molecule in a way that is invariant to atom-relabeling."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62164893,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "69b316e545a7d7eefa9d9ce510cdd17601daaff0",
            "isKey": false,
            "numCitedBy": 788,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Generation-of-a-Unique-Machine-Description-for-Morgan",
            "title": {
                "fragments": [],
                "text": "The Generation of a Unique Machine Description for Chemical Structures-A Technique Developed at Chemical Abstracts Service."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Convolutional neural networks Convolutional neural networks have been used to model images, speech, and time series [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6916627,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "563e821bb5ea825efb56b77484f5287f08cf3753",
            "isKey": false,
            "numCitedBy": 4091,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convolutional-networks-for-images,-speech,-and-time-LeCun-Bengio",
            "title": {
                "fragments": [],
                "text": "Convolutional networks for images, speech, and time series"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dahl , Navdeep Jaitly , and Ruslan Salakhutdinov . Multitask neural networks for QSAR predictions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "RDKit: Open-source cheminformatics. www.rdkit.org"
            },
            "venue": {
                "fragments": [],
                "text": "RDKit: Open-source cheminformatics. www.rdkit.org"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] used circular fingerprints (of depth 2) as inputs to a multitask neural network, showing that multiple tasks helped performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Massively multitask networks for drug"
            },
            "venue": {
                "fragments": [],
                "text": "discovery. arXiv:1502.02072,"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "National center for advancing translational sciences. http://tripod. nih.gov/tox21/challenge"
            },
            "venue": {
                "fragments": [],
                "text": "National center for advancing translational sciences. http://tripod. nih.gov/tox21/challenge"
            },
            "year": 2014
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 33,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Convolutional-Networks-on-Graphs-for-Learning-Duvenaud-Maclaurin/5d1bfeed240709725c78bc72ea40e55410b373dc?sort=total-citations"
}