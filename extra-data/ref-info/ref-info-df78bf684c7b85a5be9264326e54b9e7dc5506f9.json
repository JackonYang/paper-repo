{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3070139"
                        ],
                        "name": "C. J. Hu",
                        "slug": "C.-J.-Hu",
                        "structuredName": {
                            "firstName": "Chialun",
                            "lastName": "Hu",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62768057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2010b081e653c82f8c34f51b2824bfab7d9fc925",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "As we published in the last five years, the supervised learning in a hard-limited perceptron system can be accomplished in a noniterative manner if the input-output mapping to be learned satisfies a certain positive-linear-independency (or PLI) condition. When this condition is satisfied (for most practical pattern recognition applications, this condition should be satisfied,) the connection matrix required to meet this mapping can be obtained noniteratively in one step. Generally, there exist infinitively many solutions for the connection matrix when the PLI condition is satisfied. We can then select an optimum solution such that the recognition of any untrained patterns will become optimally robust in the recognition mode. The learning speed is very fast and close to real-time because the learning process is noniterative and one-step. This paper reports the theoretical analysis and the design of a practical charter recognition system for recognizing hand-written alphabets. The experimental result is recorded in real-time on an unedited video tape for demonstration purposes. It is seen from this real-time movie that the recognition of the untrained hand-written alphabets is invariant to size, location, orientation, and writing sequence, even the training is done with standard size, standard orientation, central location and standard writing sequence."
            },
            "slug": "Ultrafast-learning-in-a-hard-limited-neural-network-Hu",
            "title": {
                "fragments": [],
                "text": "Ultrafast learning in a hard-limited neural network pattern recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The theoretical analysis and the design of a practical charter recognition system for recognizing hand-written alphabets is reported and it is seen from this real-time movie that the recognition of the untrained hand- written alphABets is invariant to size, location, orientation, and writing sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3070139"
                        ],
                        "name": "C. J. Hu",
                        "slug": "C.-J.-Hu",
                        "structuredName": {
                            "firstName": "Chialun",
                            "lastName": "Hu",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56686241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "009aebbeeadcc3bb2304d837b97d9b5d5f1faf65",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "If M given training patterns are not extremely similar, the analog N-vectors representing them are generally separable in the N-space. Then a one-layered binary perceptron containing P neurons (P equals >log2M) is generally sufficient to do the pattern recognition job. The connection matrix between the input (linear) layer and the neuron layer can be calculated in a noniterative manner. Real-time pattern recognition experiments implementing this theoretical result were reported in this and other national conferences last year. It is demonstrated in these experiments that the noniterative training is very fast, (can be done in real time), and the recognition of the untrained patterns is very robust and very accurate. The present paper concentrates at the theoretical foundation of this noniteratively trained perceptron. The theory starts from an N-dimension Euclidean-geometry approach. An optimally robust learning scheme is then derived. The robustness and the speed of this optimal learning scheme are to be compared with those of the conventional iterative learning schemes."
            },
            "slug": "Optimal-robustness-in-noniterative-learning-Hu",
            "title": {
                "fragments": [],
                "text": "Optimal robustness in noniterative learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated in these experiments that the noniterative training is very fast, (can be done in real time), and the recognition of the untrained patterns is very robust and very accurate."
            },
            "venue": {
                "fragments": [],
                "text": "SPIE Defense + Commercial Sensing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97811722"
                        ],
                        "name": "C.-L.J. Hu",
                        "slug": "C.-L.J.-Hu",
                        "structuredName": {
                            "firstName": "C.-L.J.",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C.-L.J. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61571235,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59bb5eb2e20b029cc4535b594b06c6d3ed59406c",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Whenever the input training patterns applied to a one layered, hard limited perceptron (OHP) satisfy a certain positive linear independency (PLI) condition, the learning of these standard patterns by the neural network can be done non iteratively in a few algebraic steps and the recognition of the untrained test patterns can reach an \"optimal robustness\" if a special learning scheme is adopted in the learning mode. We report the theoretical foundation, the analysis (design) of this pattern recognition system, and the experiments we carried out with this novel system. The experimental result shows that the learning of four digitized training patterns is close to real time, and the recognition of the untrained patterns is above 90% correct. The ultra fast learning speed we achieved here is due to the non iterative nature of the novel learning scheme. The high robustness in recognition here is due to the optimal robustness analysis (including a special feature extraction process) we used in the neural network design."
            },
            "slug": "Robust-pattern-recognition-using-non-iteratively-Hu",
            "title": {
                "fragments": [],
                "text": "Robust pattern recognition using non-iteratively learned perceptron"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The experimental result shows that the learning of four digitized training patterns is close to real time, and the recognition of the untrained patterns is above 90% correct."
            },
            "venue": {
                "fragments": [],
                "text": "1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3070139"
                        ],
                        "name": "C. J. Hu",
                        "slug": "C.-J.-Hu",
                        "structuredName": {
                            "firstName": "Chialun",
                            "lastName": "Hu",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121782466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd9d677c4fdf3d46d08a66c4608ed54dbed332a0",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "To continue the study we reported last year in this conference, we would like to present here the theoretical origin of our design of this super-fast learning, neural network pattern recognition system. As we published in the last few years, a one-layered, hard-limited perceptron can be used to classify analog pattern vectors if the latter satisfy the PLI condition. For most pattern recognition applications, this condition should be satisfied. When this condition is satisfied, then an automatic feature extraction scheme can be derived using some N-dimension Euclidean geometry theories. This automatic scheme will automatically extract the most distinguished parts of the N-vectors used in the training. It selects the feature vectors automatically according to the descending order of the volumes of the parallelepiped spanned by these sub-vectors. Theoretical derivation and numerical examples revealing the physical nature of this process and its effect in optimizing the robustness of this novel pattern recognition system will be reported in detail."
            },
            "slug": "N-dimension-geometrical-approach-to-the-design-of-a-Hu",
            "title": {
                "fragments": [],
                "text": "N-dimension geometrical approach to the design of an automatic feature extraction scheme in a noniterative neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The theoretical origin of this super-fast learning, neural network pattern recognition system, which uses a one-layered, hard-limited perceptron to classify analog pattern vectors if the latter satisfy the PLI condition, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Defense, Security, and Sensing"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3070139"
                        ],
                        "name": "C. J. Hu",
                        "slug": "C.-J.-Hu",
                        "structuredName": {
                            "firstName": "Chialun",
                            "lastName": "Hu",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58195446,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a8586ee208f1dddc51b2d17e6fe836503dc1a74",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "As we published in the last few years, when the given input- output training vector pairs satisfy a PLI (positive-linear- independency) condition, the training of a hard-limited neural network to recognize untrained patterns can be achieved noniteratively with very short training time and very robust recognition. The key feature in this novel pattern recognition system is the use of slack constants in solving the connection matrix when the PLI condition is satisfied. Generally there are infinitely many ways of selecting the slack constants for meeting the training- recognition goal, but there is only one way to select them if an optimal robustness is sought in the recognition of the untrained patterns. This particular way of selecting the slack constants carries some special physical properties of the system--the automatic feature extraction in the learning mode and the automatic feature competition in the recognition mode. Physical significance as well as mathematical analysis of these novel properties are to be explained in detail in this paper. Real-time experiments are to be presented in an unedited movie. It is seen that in the system, the training of 4 hand-written characters is close to real time (< 0.1 sec.) and the recognition of the untrained hand-written characters is > 90% accurate."
            },
            "slug": "Feature-competition-and-feature-extraction-in-a-Hu",
            "title": {
                "fragments": [],
                "text": "Feature competition and feature extraction in a novel neural network pattern recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Physical significance as well as mathematical analysis of these novel properties of the novel pattern recognition system carry some special physical properties--the automatic feature extraction in the learning mode and the automatic feature competition in the recognition mode."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3070139"
                        ],
                        "name": "C. J. Hu",
                        "slug": "C.-J.-Hu",
                        "structuredName": {
                            "firstName": "Chialun",
                            "lastName": "Hu",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 108519241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60b6e0cd90ca31034544608f51b264ff1d8bbf77",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "As we published in the last few years, when the pattern vectors used in the training of a novel neural network satisfy a generalized N-dimension convexity property (or the novel PLI condition we derived), the neural network can learn these patterns very fast in a NONITERATIVE manner. The recognition of any UNTRAINED patterns by using this learned neural network can then reach OPTIMUM ROBUSTNESS if an automatic feature extraction scheme derived from the N-dimension geometry is used in the recognition mode. The simplified physical picture of the high-robustness reached by this novel system is the automatic extraction of the most distinguished parts in all the M training pattern vectors in the N-space such that the volume of the M-dimension parallelepiped spanned by these parts of the vectors reaches a maximum."
            },
            "slug": "Automatic-feature-extraction-using-N-dimension-in-a-Hu",
            "title": {
                "fragments": [],
                "text": "Automatic feature extraction using N-dimension convexity concept in a novel neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The simplified physical picture of the high-robustness reached by this novel system is the automatic extraction of the most distinguished parts in all the M training pattern vectors in the N-space such that the volume of the M-dimension parallelepiped spanned by these parts of the vectors reaches a maximum."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rotation-Invariance in a Real-Time Neural Network Learning Scheme,\" invited paper (all expenses paid by NASA) presented at NASA Neural Network Symposium"
            },
            "venue": {
                "fragments": [],
                "text": "NASA Ames Research Center, Aug"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 35
                            }
                        ],
                        "text": "Casasent, Tien-Hsin Chao, Editors, 291 Proceedings of SPIE Vol. 4043 (2000) \u2022 0277-786X/00/$1 5."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A deterministic method of solving supervised learning problems,\" Intelligent Engineering Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Tthrough Artificial Neural Networks, ASME press,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A novel, one-step, geometrical supervised learning scheme,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1990 International Joint Conference on Neural Networks,"
            },
            "year": 1990
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 9,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Parallel-cascaded-noniterative-neural-network-for-Hu/df78bf684c7b85a5be9264326e54b9e7dc5506f9?sort=total-citations"
}