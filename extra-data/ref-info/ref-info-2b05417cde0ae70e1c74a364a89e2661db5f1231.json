{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658132"
                        ],
                        "name": "David Pinto",
                        "slug": "David-Pinto",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876441"
                        ],
                        "name": "Xing Wei",
                        "slug": "Xing-Wei",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1092004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6991606a1a9d5c285af385ee9159fd46cc14048e",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to find tables and extract information from them is a necessary component of data mining, question answering, and other information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efficiently indicate fields and records in two-dimensional form.Their rich combination of formatting and content present difficulties for traditional language modeling techniques, however. This paper presents the use of conditional random fields (CRFs) for table extraction, and compares them with hidden Markov models (HMMs). Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better. We show experimental results on plain-text government statistical reports in which tables are located with 92% F1, and their constituent lines are classified into 12 table-related categories with 94% accuracy. We also discuss future work on undirected graphical models for segmenting columns, finding cells, and classifying them as data cells or label cells."
            },
            "slug": "Table-extraction-using-conditional-random-fields-Pinto-McCallum",
            "title": {
                "fragments": [],
                "text": "Table extraction using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better, and are compared with hidden Markov models (HMMs)."
            },
            "venue": {
                "fragments": [],
                "text": "DG.O"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654778"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10717306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e17dbf643fdb7b38d36a5d7e59271a6de393e662",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "As the rapid growth of PDF documents, recognizing the document structure and components are useful for document storage, classification and retrieval. Table, a ubiquitous document component, becomes an important information source. Accurately detecting the table boundary plays a crucial role for many applications, e.g., the increasing demand on the table data search. Rather than converting PDFs to image or HTML and then processing with other techniques (e.g., OCR), extracting and analyzing texts from PDFs directly is easy and accurate. However, text extraction tools face a common problem: text sequence error. In this paper, we propose two algorithms to recover the sequence of extracted sparse lines, which improve the table content collection. The experimental results show the comparison of the performance of both algorithms, and demonstrate the effectiveness of text sequence recovering for the table boundary detection."
            },
            "slug": "Improving-the-Table-Boundary-Detection-in-PDFs-by-Liu-Bai",
            "title": {
                "fragments": [],
                "text": "Improving the Table Boundary Detection in PDFs by Fixing the Sequence Error of the Sparse Lines"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Two algorithms to recover the sequence of extracted sparse lines, which improve the table content collection are proposed and the experimental results show the comparison of the performance of both algorithms, and the effectiveness of text sequence recovering for the table boundary detection."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9393238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7673ba3e72a07d4bbfb6b03d806fc3d8f0283105",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme for describing relational information. Table understanding on the web has many potential applications including web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. Although in HTML documents tables are generally marked as ?table? elements, a ?table? element does not necessarily indicate the presence of a genuine relational table. Thus the important first step in table understanding in the web domain is the detection of the genuine tables. In our earlier work we designed a basic rule-based algorithm to detect genuine tables in major news and corporate home pages as part of a web content filtering system. In this paper we investigate a machine learning based approach that is trainable and thus can be automatically generalized to including any domain. Various features reflecting the layout as well as content characteristics of tables are explored. The system is tested on a large database which consists of 1, 393 HTML files collected from hundreds of different web sites from various domains and contains over 10,000 leaf ?table? elements. Experiments were conducted using the cross validation method. The machine learning based approach outperformed the rule-based system and achieved an F-measure of 95.88%."
            },
            "slug": "Detecting-Tables-in-HTML-Documents-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "Detecting Tables in HTML Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper investigates a machine learning based approach that is trainable and thus can be automatically generalized to including any domain and outperformed the rule-based system and achieved an F-measure of 95.88%."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "For the rule-based methods, the performance is al\u00adways heavily a.ected by the quality of the \nrules."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "The experimental results not only compare the performances between \nthe machine learning methods and the heuristical-based method, but also demonstrate the e.ectiveness \nof the sparse line analysis in the table boundary detection."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2061833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89945f77470b6a1dabd1f224f10b7d096fd9435",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme, especially for describing relational information. However, table understanding remains an open problem. In this paper, we consider the problem of table detection in web documents. Its potential applications include web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. We describe a machine learning based approach to classify each given table entity as either genuine or non-genuine. Various features reflecting the layout as well as content characteristics of tables are studied.In order to facilitate the training and evaluation of our table classifier, we designed a novel web document table ground truthing protocol and used it to build a large table ground truth database. The database consists of 1,393 HTML files collected from hundreds of different web sites and contains 11,477 leaf TABLE elements, out of which 1,740 are genuine tables. Experiments were conducted using the cross validation method and an F-measure of 95.89% was achieved."
            },
            "slug": "A-machine-learning-based-approach-for-table-on-the-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "A machine learning based approach for table detection on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A machine learning based approach to classify each given table entity as either genuine or non-genuine, and designed a novel web document table ground truthing protocol and used it to build a large table ground truth database."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206405589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "108030474840ce5e1086cc8ef598ff3e6c13693c",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient approach to identify tabular structures within either electronic or paper documents. The resulting T-Recs system takes word bounding box information as input, and outputs the corresponding logical text block units. Starting with an arbitrary word as block seed the algorithm recursively expands this block to all words that interleave with their vertical neighbors. Since even smallest gaps of table columns prevent their words from mutual interleaving, this initial segmentation is able to identify and isolate such columns. In order to deal with some inherent segmentation errors caused by isolated lines, overhanging words, or cells spawning more than one column, a series of postprocessing steps is added. These steps benefit form a very simple distinction between type 1 and type 2 blocks: type 1 blocks are those of at most one word per line, all others are of type 2. This distinction allows the selective application of heuristics to each group of blocks. The conjoint decomposition of column blocks into subsets of table cells leads to the final block segmentation of a homogeneous abstraction level. These segments serve the final layout analysis which identifies table environments and cells that are stretching over several rows and/or columns."
            },
            "slug": "Table-structure-recognition-based-on-robust-block-Kieninger",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on robust block segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An efficient approach to identify tabular structures within either electronic or paper documents by taking word bounding box information as input, and outputs the corresponding logical text block units through the T-Recs system."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654778"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "If the data reported in tables can be extracted and stored in a database, the data \ncan be queried and joined with other data using database management systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "Other researchers, for example, who are conducting the empirical studies in the same topic, can quickly \nobtain valuable insights via examining these tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2940120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "627ae41c9e345f002a766cdb777fdac91d5f5427",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are ubiquitous in digital libraries. In scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. However, current search engines do not support table search. The difficulty of automatic extracting tables from un-tagged documents, the lack of a universal table metadata specification, and the limitation of the existing ranking schemes make table search problem challenging. In this paper, we describe TableSeer, a search engine for tables. TableSeer crawls digital libraries, detects tables from documents, extracts tables metadata, indexes and ranks tables, and provides a user-friendly search interface. We propose an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information. In addition, we devise a novel page box-cutting method to improve the performance of the table detection. Given a query, TableSeer ranks the matched tables using an innovative ranking algorithm - TableRank. TableRank rates each \u20edquery, table\u2102 pair with a tailored vector space model and a specific term weighting scheme. Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables. We demonstrate the value of TableSeer with empirical studies on scientific documents."
            },
            "slug": "TableSeer:-automatic-table-metadata-extraction-and-Liu-Bai",
            "title": {
                "fragments": [],
                "text": "TableSeer: automatic table metadata extraction and searching in digital libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables, and proposes an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7205594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f52409df167cfe6bafdebac63dfcf8710a56c92",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the table understanding task and present a catalogue of particular issues that arise when the tables are those found on the web. In addition, we consider what happens when processes commonly associated with web pages are applied to those bearing tables. 1 Table Understanding and the Web The ubiquity of tables, and their ability to describe relational information in a compact and immediate manner make them attractive targets for automated understanding. Recent research into the automatic location, recognition and understanding of tables has demonstrated the viability of integrating automated table processing systems into larger knowledge management applications ([8]). However, table understanding is still a relatively novel research area, one whose definition and terminology are still not fixed. It is useful to break the task down into some subtasks, and to consider them in turn with respect to the understanding of tables delivered on the web. Generally, table processing can be conceptualized as consisting of table location; table recognition; functional and structural analysis; and finally interpretation the extraction of meaningful and unambiguously structured information ([4]). We concentrate on the first two tasks in the following. location table location is the processes of spotting tables in documents. Traditionally, this task comes in two basic forms document image sourced tables ([7], [3]) and electronic text sourced tables including HTML ([1]). The problem is extended to include the spotting of tables in other document encodings such as postscript, pdf, rtf, word, etc. In general, when considering tables on the web, the appropriate HTML tags are exploited (TABLE, TH, TD, etc.). However, this is where we come to the first two distinguishing points. the presence of the TABLE tag in an HTML document does not necessarily indicate the presence of a table ([1] suggest less than 30 % of HTML TABLEs are real tables in one particular domain). there are many other ways in which tables may be presented in web delivered documents plain text (PRE), images, mixtures of table specific tags (TABLE, etc.) and tags used within the table for their functionality in terms of placing text spatially (PRE, LI, etc.) see Figure 1 for an example of such complexities. The first point requires the creation of accurate classification technology. Given any TABLE node in the HTML, the classifier must accept or reject it. Such a classifier may be built either via hand crafted rules ([1]) or using a machine learning approach. Experiments suggest that a machine learning approach using a naive bayse classifier ([9]) based on a feature set describing the set of tags below the potential TABLE node in the document tree produces adequate results. Locating tables encoded in other formats requires technology from other areas. For example, images of tables may be processed by techniques from the document image field ([2]), pre-formatted tables (using the PRE) tag may be processed using plain text table methods ([5]). However, the classification problem extends to these cases and individual classifiers must be constructed to make decisions about document elements of each type. The remaining outstanding issues relate to the mixture of encoding types (e.g. tables built out of TABLE nodes and pre-formatted elements), as well as the mixture of encoding purposes (e.g. the use of the HTML TABLE to encode surrounding text as well as an embedded table). Figure 1. A web page using a mixture of HTML tables (on the left) and images of tables (on the right). recognition table recognition is the task of segmenting the original description of the table into a relative spatial description. In general this task is required when the input is low-level, such as a document image or an electronic text. Clearly, if such tables are found on a web page, the same process is required. Again, given certain assumptions, we can take the marked up tables in a web page to be the logical spatial table. However, there are certain issues that need to be understood in order to account for certain variations: internal cell structure though tags like TH and TD may be assumed to delimit a single cell in the table, there are cases where other non-table tags are used to provide internal structure in such a way as to associate the cell\u2019s contents with those of other cells. A solution would be required to apply a certain amount of recursive processing working into the structure and building a unified abstract table. split cells in order to gain more control over the distribution of the text in a cell, authors occasionally split the text and place it in two or more adjacent cells. This problem may be accommodated by exploiting linguistic process as described in [6] where the content of the cell can be used to indicate continuity, if any, to other cells. errors spanning errors occur when the COLSPAN or ROWSPAN values are not correctly calculated. There are two cases. In the first the cell spans beyond the border of the intended table giving the cell incorrect coordinates. In the second, the span of the cell does not communicate the correct meaning of the cell. For example, a cell that is intended to span three cells below it spans only one leading to ambiguity. The first type of problem may be repaired by some form of normalization, whereas the second requires intelligent processing in order to distinguish the following two cases:"
            },
            "slug": "Layout-and-Language:-Challenges-for-Table-on-the-Hurst",
            "title": {
                "fragments": [],
                "text": "Layout and Language: Challenges for Table Understanding on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The table understanding task is considered and a catalogue of particular issues that arise when the tables are those found on the web are presented and what happens when processes commonly associated with web pages are applied to those bearing tables is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206776168,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d25a61cc0cd816eba75864912fe2f6f44be3cecf",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables. T-Recs works on the output of commercial OCR systems that provide the word bounding box geometry together with the text itself (e.g. Xerox ScanWorX). While T-Recs performs well on a number of document categories, business letters still remained a challenging domain because the T-Recs location heuristics are mislead by their header or footer resulting in a low recognition precision. Business letters such as invoices are a very interesting domain for industrial applications due to the large amount of documents to be analyzed and the importance of the data carried within their tables. Hence, we developed a more restrictive approach which is implemented in the T-Recs++ prototype. This paper describes the ideas of the T-Recs++ location and also proposes a quality evaluation measure that reflects the bottom-up strategy of either T-Recs or T-Recs++. Finally, some results comparing both systems on a collection of business letters are given."
            },
            "slug": "Applying-the-T-Recs-table-recognition-system-to-the-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Applying the T-Recs table recognition system to the business letter domain"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables, and proposes a quality evaluation measure that reflects the bottom-up strategy of either T-recs or T- Recs++."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2456613"
                        ],
                        "name": "J. H. Shamilian",
                        "slug": "J.-H.-Shamilian",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shamilian",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Shamilian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394247998"
                        ],
                        "name": "T. Wood",
                        "slug": "T.-Wood",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Wood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206775234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ad7b7fe1c5e346b1cb9034af4fa18b5afe4d45e",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles. In these tables, textual data are presented in record lines made up of fixed-width fields. Tables often do not rely on line-art (ruled lines) to delimit fields, and in this way differ crucially from fixed forms. Our system performs these steps: copes with multiple tables per page; identifies records within tables; segments records into fields; and recognizes characters within fields, constrained by field-specific contextual knowledge. Obstacles to good performance on tables include small print, tight line-spacing, poor-quality text (such as photocopies), and line-art or background patterns that touch the text. Precise skew-correction and pitch-estimation, and high-performance OCR using neural nets proved crucial in overcoming these obstacles. The most significant technical advances in this work appear to be algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts. This GUI has been ergonomically designed to make efficient and intuitive use of exemplary images, so that the skill and manual effort required to retarget the system to new table layouts are held to a minimum. The system has been applied in this way to more than 400 distinct tabular layouts. During the last three years the system has read over fifty million records with high accuracy."
            },
            "slug": "A-retargetable-table-reader-Shamilian-Baird",
            "title": {
                "fragments": [],
                "text": "A retargetable table reader"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles, and algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 628973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd7e243fb7041c582a479116a11126904f2be010",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We first describe an automatic table ground truth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms. Then a novel background analysis-based, coarse-to-fine table identification algorithm and an X-Y cut table decomposition algorithm are described. We discuss an experimental protocol to evaluate the table detection algorithms. For a total of 1,125 document pages having 518 table entities and a total of 10,941 cell entities, our table detection algorithm takes line, word segmentation results as input and obtains around 90% cell correct detection rates."
            },
            "slug": "Automatic-table-ground-truth-generation-and-a-table-Wang-Haralick",
            "title": {
                "fragments": [],
                "text": "Automatic table ground truth generation and a background-analysis-based table structure extraction method"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An automatic table groundtruth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms and an X-Y cut table decomposition algorithm are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2632608"
                        ],
                        "name": "B. Yildiz",
                        "slug": "B.-Yildiz",
                        "structuredName": {
                            "firstName": "Burcu",
                            "lastName": "Yildiz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yildiz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804028"
                        ],
                        "name": "K. Kaiser",
                        "slug": "K.-Kaiser",
                        "structuredName": {
                            "firstName": "Katharina",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692521"
                        ],
                        "name": "S. Miksch",
                        "slug": "S.-Miksch",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Miksch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miksch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17242556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5dc08add84ef4070b00c2b43dac037bcfd6df460",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a common structuring element in many documents, such as PDF files. To reuse such tables, appropriate methods need to be develop, which capture the structure and the content information. We have developed several heuristics which together recognize and decompose tables in PDF files and store the extracted data in a structured data format (XML) for easier reuse. Additionally, we implemented a prototype, which gives the user the ability of making adjustments on the extracted data. Our work shows that purely heuristic-based approaches can achieve good results, especially for lucid tables."
            },
            "slug": "pdf2table:-A-Method-to-Extract-Table-Information-Yildiz-Kaiser",
            "title": {
                "fragments": [],
                "text": "pdf2table: A Method to Extract Table Information from PDF Files"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work developed several heuristics which together recognize and decompose tables in PDF files and store the extracted data in a structured data format (XML) for easier reuse and shows that purely heuristic-based approaches can achieve good results, especially for lucid tables."
            },
            "venue": {
                "fragments": [],
                "text": "IICAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153924342"
                        ],
                        "name": "Hsin-Hsi Chen",
                        "slug": "Hsin-Hsi-Chen",
                        "structuredName": {
                            "firstName": "Hsin-Hsi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Hsi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072526610"
                        ],
                        "name": "Shih-Chung Tsai",
                        "slug": "Shih-Chung-Tsai",
                        "structuredName": {
                            "firstName": "Shih-Chung",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chung Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949513"
                        ],
                        "name": "Jin-He Tsai",
                        "slug": "Jin-He-Tsai",
                        "structuredName": {
                            "firstName": "Jin-He",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-He Tsai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6844025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578c63514136ac5b9af0144bcfe06efcfdd3099c",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a very common presentation scheme, but few papers touch on table extraction in text data mining. This paper focuses on mining tables from large-scale HTML texts. Table filtering, recognition, interpretation, and presentation are discussed. Heuristic rules and cell similarities are employed to identify tables. The F-measure of table recognition is 86.50%. We also propose an algorithm to capture attribute-value relationships among table cells. Finally, more structured data is extracted and presented."
            },
            "slug": "Mining-Tables-from-Large-Scale-HTML-Texts-Chen-Tsai",
            "title": {
                "fragments": [],
                "text": "Mining Tables from Large Scale HTML Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper focuses on mining tables from large-scale HTML texts by using heuristic rules and cell similarities to identify tables and proposes an algorithm to capture attribute-value relationships among table cells."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216372"
                        ],
                        "name": "Chung Yong Lim",
                        "slug": "Chung-Yong-Lim",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Lim",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung Yong Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054350109"
                        ],
                        "name": "Jessica Li Teng Koo",
                        "slug": "Jessica-Li-Teng-Koo",
                        "structuredName": {
                            "firstName": "Jessica",
                            "lastName": "Koo",
                            "middleNames": [
                                "Li",
                                "Teng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jessica Li Teng Koo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16206198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d937270157cabb23288ce6a948275f4aeeaa827",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world texts contain tables. In order to process these texts correctly and extract the information contained within the tables, it is important to identify the presence and structure of tables. In this paper, we present a new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables. When tested on Wall Street Journal news documents, our learning approach outperforms a deterministic table recognition algorithm that identifies table recognition algorithm that identifies tables based on a fixed set of conditions. Our learning approach is also more flexible and easily adaptable to texts in different domains with different table characteristics."
            },
            "slug": "Learning-to-Recognize-Tables-in-Free-Text-Ng-Lim",
            "title": {
                "fragments": [],
                "text": "Learning to Recognize Tables in Free Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables, outperforms a deterministic table recognition algorithm that identifies tables based on a fixed set of conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995684"
                        ],
                        "name": "Jiwon Shin",
                        "slug": "Jiwon-Shin",
                        "structuredName": {
                            "firstName": "Jiwon",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiwon Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70322883"
                        ],
                        "name": "Nick Guerette",
                        "slug": "Nick-Guerette",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Guerette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nick Guerette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61480199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8daf6741c9ba82452edc04fb6480d8922d86a168",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm that recognizes tables in document images and extracts their structural information. We use region growing to locate bounding boxes around text, and cluster them into columns by examining spatial relationships between bounding boxes and their vertical neighbors. Once initial clustering is complete, a series of post-processing steps are applied to the clusters to find columns that line up horizontally and may form tables."
            },
            "slug": "Table-Recognition-and-Evaluation-Shin-Guerette",
            "title": {
                "fragments": [],
                "text": "Table Recognition and Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An algorithm is presented that recognizes tables in document images and extracts their structural information by using region growing to locate bounding boxes around text, and cluster them into columns by examining spatial relationships between bounding Boxes and their vertical neighbors."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738409"
                        ],
                        "name": "Bernhard Kr\u00fcpl",
                        "slug": "Bernhard-Kr\u00fcpl",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Kr\u00fcpl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Kr\u00fcpl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153481005"
                        ],
                        "name": "M. Herzog",
                        "slug": "M.-Herzog",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Herzog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Herzog"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000882"
                        ],
                        "name": "Wolfgang Gatterbauer",
                        "slug": "Wolfgang-Gatterbauer",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Gatterbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Gatterbauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6574692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38c3a2248eee100437388e4d9f881c5396208d8c",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method to extract tabular data from web pages. Rather than just analyzing the DOM tree, we also exploit visual cues in the rendered version of the document to extract data from tables which are not explicitly marked with an HTML table element. To detect tables, we rely on a variant of the well-known X-Y cut algorithm as used in the OCR community. We implemented the system by directly accessing Mozilla's box model that contains the positional data for all HTML elements of a given web page."
            },
            "slug": "Using-visual-cues-for-extraction-of-tabular-data-Kr\u00fcpl-Herzog",
            "title": {
                "fragments": [],
                "text": "Using visual cues for extraction of tabular data from arbitrary HTML documents"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A method to extract tabular data from web pages by exploiting visual cues in the rendered version of the document to extract data from tables which are not explicitly marked with an HTML table element is described."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143894263"
                        ],
                        "name": "Hui Chao",
                        "slug": "Hui-Chao",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Chao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Chao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962939"
                        ],
                        "name": "Jian Fan",
                        "slug": "Jian-Fan",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Fan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16993093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "358899712252e129c431a34a23d0a6bf754cebcf",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Portable document format (PDF) is a common output format for electronic documents. Most PDF documents are untagged and do not have basic high-level document logical structural information, which makes the reuse or modification of the documents difficult. We developed techniques that identified logical components on a PDF document page. The outlines, style attributes and the contents of the logical components were extracted and expressed in an XML format. These techniques could facilitate the reuse and modification of the layout and the content of a PDF document page."
            },
            "slug": "Layout-and-Content-Extraction-for-PDF-Documents-Chao-Fan",
            "title": {
                "fragments": [],
                "text": "Layout and Content Extraction for PDF Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Techniques that identified logical components on a PDF document page were developed and the outlines, style attributes and the contents of the logical components were extracted and expressed in an XML format."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40400230"
                        ],
                        "name": "Wei Li",
                        "slug": "Wei-Li",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11664683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d65ee7aa0a9dac3957093985e9179e1ccb9bd3b",
            "isKey": false,
            "numCitedBy": 1233,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Models for many natural language tasks benefit from the flexibility to use overlapping, non-independent features. For example, the need for labeled data can be drastically reduced by taking advantage of domain knowledge in the form of word lists, part-of-speech tags, character n-grams, and capitalization patterns. While it is difficult to capture such inter-dependent features with a generative probabilistic model, conditionally-trained models, such as conditional maximum entropy models, handle them well. There has been significant work with such models for greedy sequence modeling in NLP (Ratnaparkhi, 1996; Borthwick et al., 1998)."
            },
            "slug": "Early-results-for-Named-Entity-Recognition-with-and-McCallum-Li",
            "title": {
                "fragments": [],
                "text": "Early results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-Enhanced Lexicons"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work has shown that conditionally-trained models, such as conditional maximum entropy models, handle inter-dependent features of greedy sequence modeling in NLP well."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145329865"
                        ],
                        "name": "Minoru Yoshida",
                        "slug": "Minoru-Yoshida",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Yoshida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minoru Yoshida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768754"
                        ],
                        "name": "Kentaro Torisawa",
                        "slug": "Kentaro-Torisawa",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Torisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kentaro Torisawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737901"
                        ],
                        "name": "Junichi Tsujii",
                        "slug": "Junichi-Tsujii",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Tsujii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junichi Tsujii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15867784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2985934cf5161c1fb6cecc8728dbd155cb6d278a",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web (WWW) allows a person to access a great amount of data provided by a wide variety of entities. However, the content varies widely in expression. This makes it difficult to browse many pages effectively, even if the contents of the pages are quite similar. This study is the first step toward the reduction of such variety of WWW contents. The method proposed in this paper enables us to easily obtain information about similar objects scattered over the WWW. We focus on the tables contained in the WWW pages and propose a method to integrate them according to the category of objects presented in each table. The table integrated in a uniform format enables us to easily compare the objects of different locations and styles of expressions."
            },
            "slug": "A-method-to-integrate-tables-of-the-World-Wide-Web-Yoshida-Torisawa",
            "title": {
                "fragments": [],
                "text": "A method to integrate tables of the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study focuses on the tables contained in the WWW pages and proposes a method to integrate them according to the category of objects presented in each table, which enables us to easily compare the objects of different locations and styles of expressions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9966171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34dc22dcbdf1e09fb48691ee1fc6fe4bb8f834c3",
            "isKey": false,
            "numCitedBy": 475,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional Random Fields (CRFs) are undirected graphical models, a special case of which correspond to conditionally-trained finite state machines. A key advantage of CRFs is their great flexibility to include a wide variety of arbitrary, non-independent features of the input. Faced with this freedom, however, an important question remains: what features should be used? This paper presents an efficient feature induction method for CRFs. The method is founded on the principle of iteratively constructing feature conjunctions that would significantly increase conditional log-likelihood if added to the model. Automated feature induction enables not only improved accuracy and dramatic reduction in parameter count, but also the use of larger cliques, and more freedom to liberally hypothesize atomic input variables that may be relevant to a task. The method applies to linear-chain CRFs, as well as to more arbitrary CRF structures, such as Relational Markov Networks, where it corresponds to learning clique templates, and can also be understood as supervised structure learning. Experimental results on named entity extraction and noun phrase segmentation tasks are presented."
            },
            "slug": "Efficiently-Inducing-Features-of-Conditional-Random-McCallum",
            "title": {
                "fragments": [],
                "text": "Efficiently Inducing Features of Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents an efficient feature induction method for CRFs founded on the principle of iteratively constructing feature conjunctions that would significantly increase conditional log-likelihood if added to the model."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17179084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f03c5e7b1e66936544eaf329cbe38c57ccf5feb0",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A top-down page segmentation technique known as the recursive X-Y cut decomposes a document image recursively into a set of rectangular blocks. This paper proposes that the recursive X-Y cut be implemented using bounding boxes of connected components of black pixels instead of using image pixels. The advantage is that great improvement can be achieved in computation. In fact, once bounding boxes of connected components are obtained, the recursive X-Y cut is completed within an order of a second on Sparc-10 workstations for letter-sized document images scanned at 900 dpi resolution."
            },
            "slug": "Recursive-X-Y-cut-using-bounding-boxes-of-connected-Ha-Haralick",
            "title": {
                "fragments": [],
                "text": "Recursive X-Y cut using bounding boxes of connected components"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes that the recursive X-Y cut be implemented using bounding boxes of connected components of black pixels instead of using image pixels, so that great improvement can be achieved in computation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13409,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13936575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "897249c93f55ef1c0d2aa1e799eb67b414c6d4a6",
            "isKey": false,
            "numCitedBy": 1544,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional random fields for sequence labeling offer advantages over both generative models like HMMs and classifiers applied at each sequence position. Among sequence labeling tasks in language processing, shallow parsing has received much attention, with the development of standard evaluation datasets and extensive comparison among methods. We show here how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model. Improved training methods based on modern optimization algorithms were critical in achieving these results. We present extensive comparisons between models and training methods that confirm and strengthen previous results on shallow parsing and training methods for maximum-entropy models."
            },
            "slug": "Shallow-Parsing-with-Conditional-Random-Fields-Sha-Pereira",
            "title": {
                "fragments": [],
                "text": "Shallow Parsing with Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14319498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6e4c5aa32fd8180d336ce2b6ea8bf3194678636",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables, and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-Survey-of-Table-Recognition-:-Models-,-,-,-and-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A Survey of Table Recognition : Models , Observations , Transformations , and Inferences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49774164"
                        ],
                        "name": "Zijian Zheng",
                        "slug": "Zijian-Zheng",
                        "structuredName": {
                            "firstName": "Zijian",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zijian Zheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 45773571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "412cde368fb90ee33c51bb6dd02a054982c29d8f",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The naive Bayesian classifier provides a very simple yet surprisingly accurate technique for machine zijian@deakin.edu.au Some researchers have examined extensions to the naive Bayesian classifier that seek to further improve the accuracy. For example, a naive Bayesian tree approach generates a decision tree with one naive Bayesian classifier at each leaf. Another example is a constructive Bayesian classifier that eliminates attributes and constructs new attributes using Cartesian products of existing attributes. This paper proposes a simple, but effective approach for the same purpose. It generates a naive Bayesian classifier committee for a given classification task. Each member of the committee is a naive Bayesian classifier based on a subset of all the attributes available for the task. During the classification stage, the committee members vote to predict classes. Experiments across a wide variety of natural domains show that this method significantly increases the prediction accuracy of the naive Bayesian classifier on average. It performs better than the two approaches mentioned above in terms of higher prediction accuracy."
            },
            "slug": "Naive-Bayesian-Classifier-Committees-Zheng",
            "title": {
                "fragments": [],
                "text": "Naive Bayesian Classifier Committees"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experiments show that this method significantly increases the prediction accuracy of the naive Bayesian classifier on average and performs better than the two approaches mentioned above in terms of higher prediction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145047294"
                        ],
                        "name": "Gerald Penn",
                        "slug": "Gerald-Penn",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Penn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerald Penn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110416089"
                        ],
                        "name": "Hengbin Luo",
                        "slug": "Hengbin-Luo",
                        "structuredName": {
                            "firstName": "Hengbin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hengbin Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1214535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb72ee8307eeeafeb93031d8625440b9e6415159",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a set of baseline heuristics for identifying genuinely tabular information and news links in HTML documents. A prototype implementation of these heuristics is described for delivering content from news providers' home pages to a narrow-bandwidth device such as a portable digital assistant or cellular phone display. Its evaluation on 75 Web sites is provided, along with a discussion of topics for future research."
            },
            "slug": "Flexible-Web-document-analysis-for-delivery-to-Penn-Hu",
            "title": {
                "fragments": [],
                "text": "Flexible Web document analysis for delivery to narrow-bandwidth devices"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A prototype implementation of a set of baseline heuristics for identifying genuinely tabular information and news links in HTML documents for delivering content from news providers' home pages to a narrow-bandwidth device such as a portable digital assistant or cellular phone display is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721048"
                        ],
                        "name": "S. R. Safavian",
                        "slug": "S.-R.-Safavian",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Safavian",
                            "middleNames": [
                                "Rasoul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. R. Safavian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773449"
                        ],
                        "name": "D. Landgrebe",
                        "slug": "D.-Landgrebe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Landgrebe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Landgrebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6966739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df50278b090b306f210eea77c2496d3fc790e7ea",
            "isKey": false,
            "numCitedBy": 2702,
            "numCiting": 132,
            "paperAbstract": {
                "fragments": [],
                "text": "A survey is presented of current methods for decision tree classifier (DTC) designs and the various existing issues. After considering potential advantages of DTCs over single-state classifiers, the subjects of tree structure design, feature selection at each internal node, and decision and search strategies are discussed. The relation between decision trees and neutral networks (NN) is also discussed. >"
            },
            "slug": "A-survey-of-decision-tree-classifier-methodology-Safavian-Landgrebe",
            "title": {
                "fragments": [],
                "text": "A survey of decision tree classifier methodology"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The subjects of tree structure design, feature selection at each internal node, and decision and search strategies are discussed, and the relation between decision trees and neutral networks (NN) is also discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Svm light"
            },
            "venue": {
                "fragments": [],
                "text": "Svm light"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] proposed a set of rules for identifying genuinely tabular information and news links in HTML documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Flexible web document analy- sis for delivery to narrow-bandwidth"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 2,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Identifying-table-boundaries-in-digital-documents-Liu-Mitra/2b05417cde0ae70e1c74a364a89e2661db5f1231?sort=total-citations"
}