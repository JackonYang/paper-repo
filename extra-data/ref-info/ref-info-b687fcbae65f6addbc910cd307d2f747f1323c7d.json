{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823474"
                        ],
                        "name": "Mar\u00e7al Rusi\u00f1ol",
                        "slug": "Mar\u00e7al-Rusi\u00f1ol",
                        "structuredName": {
                            "firstName": "Mar\u00e7al",
                            "lastName": "Rusi\u00f1ol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mar\u00e7al Rusi\u00f1ol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763464"
                        ],
                        "name": "David Aldavert",
                        "slug": "David-Aldavert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Aldavert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Aldavert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144083430"
                        ],
                        "name": "R. Toledo",
                        "slug": "R.-Toledo",
                        "structuredName": {
                            "firstName": "Ricardo",
                            "lastName": "Toledo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Toledo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Although they are too slow to be used over the whole document page, they could be used to rerank the best regions returned by a sliding-window method such as ours."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "Then, a sliding window search is performed only over the salient regions of the documents using an expensive template-based matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Second, spotting methods can be improved in the learning of a more semantic space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "We evaluate our approach on two public datasets: The George Washington (GW) dataset [15, 16] and the Lord Byron (LB) [19]2 dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "In [19], this is achieved by learning, offline, a latent space through LSI, where the cosine similarity is an appropriate measure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "With this configuration, we obtain a 54.5% mAP on GW and a 85.5% mAP on LB, needing approximately 15ms per document."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "One important drawback of sliding-window based methods such as this or [9, 19] is the cost of recomputing the descriptors of every image with every new query."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "The work of [9] uses a descriptor based on the patch density, which is insufficient to capture all the fine-grained details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12403647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64f7506caf39d4fd997f7f5366067caf430e51bd",
            "isKey": true,
            "numCitedBy": 155,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a segmentation-free word spotting method that is able to deal with heterogeneous document image collections. We propose a patch-based framework where patches are represented by a bag-of-visual-words model powered by SIFT descriptors. A later refinement of the feature vectors is performed by applying the latent semantic indexing technique. The proposed method performs well on both handwritten and typewritten historical document images. We have also tested our method on documents written in non-Latin scripts."
            },
            "slug": "Browsing-Heterogeneous-Document-Collections-by-a-Rusi\u00f1ol-Aldavert",
            "title": {
                "fragments": [],
                "text": "Browsing Heterogeneous Document Collections by a Segmentation-Free Word Spotting Method"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A patch-based framework where patches are represented by a bag-of-visual-words model powered by SIFT descriptors that is able to deal with heterogeneous document image collections."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117020307"
                        ],
                        "name": "Jos\u00e9 A. Rodr\u00edguez",
                        "slug": "Jos\u00e9-A.-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Rodr\u00edguez",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. Rodr\u00edguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Then, the extracted candidates are represented as sequences of features [14, 17, 22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16977951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3c2ea5c04ded4644e7ac3c8c5405c229494816f",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we propose a local descriptor for an unconstrained handwritten word spotting task. The presented features are inspired by the SIFT keypoint descriptor, widely employed in computer vision and object recognition, but underexploited in the handwriting recognition field. In our approach, a sliding window moves from left to right over a word image. At each position, the window is subdivided into cells, and in each cell a histogram of orientations is accumulated. Experiments using two different word spotting systems hidden Markov models and dynamic time warping demonstrate a very significant improvement when using the proposed features with respect to the state-of-the-art ones."
            },
            "slug": "Local-gradient-histogram-features-for-word-spotting-Rodr\u00edguez-Perronnin",
            "title": {
                "fragments": [],
                "text": "Local gradient histogram features for word spotting in unconstrained handwritten documents"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A local descriptor for an unconstrained handwritten word spotting task inspired by the SIFT keypoint descriptor, widely employed in computer vision and object recognition, but underexploited in the handwriting recognition field is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Examples of this framework are the works of Rath and Manmatha [16] and Rodr\u00edguezSerrano and Perronnin [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "We evaluate our approach on two public datasets: The George Washington (GW) dataset [15, 16] and the Lord Byron (LB) [19]2 dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11418414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2032ca157296c50db62fafb90ba970b77262ed17",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Searching and indexing historical handwritten collections are a very challenging problem. We describe an approach called word spotting which involves grouping word images into clusters of similar words by using image matching to find similarity. By annotating \u201cinteresting\u201d clusters, an index that links words to the locations where they occur can be built automatically. Image similarities computed using a number of different techniques including dynamic time warping are compared. The word similarities are then used for clustering using both K-means and agglomerative clustering techniques. It is shown in a subset of the George Washington collection that such a word spotting technique can outperform a Hidden Markov Model word-based recognition technique in terms of word error rates."
            },
            "slug": "Word-spotting-for-historical-documents-Rath-Manmatha",
            "title": {
                "fragments": [],
                "text": "Word spotting for historical documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown in a subset of the George Washington collection that such a word spotting technique can outperform a Hidden Markov Model word-based recognition technique in terms of word error rates."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "One important drawback of sliding-window based methods such as this or [9, 19] is the cost of recomputing the descriptors of every image with every new query."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "Additionally, the line segmentation still has to be very precise to properly encode the lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14073277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd80fdc7d04e1c87a87f035278e251c3ea618629",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a new efficient word spotting methodology is presented that can be applied to historical printed documents without requiring any previous block or word segmentation step. Our aim is to address a methodology which is segmentation-free since in many cases of historical documents, the segmentation process does not produce meaningful results due to unconstraint layout, several degradations or typesetting imperfections. The proposed method is based on block-based document image descriptors that are used at a template matching process satisfying invariance in terms of translation, rotation and scaling. Improvement in terms of time expense is obtained by applying the matching process only on salient regions of the image. Experimental results on a database with representative historical printed documents prove the efficiency of the proposed approach."
            },
            "slug": "Segmentation-free-Word-Spotting-in-Historical-Gatos-Pratikakis",
            "title": {
                "fragments": [],
                "text": "Segmentation-free Word Spotting in Historical Printed Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new efficient word spotting methodology is presented that can be applied to historical printed documents without requiring any previous block or word segmentation step, based on block-based document image descriptors used at a template matching process satisfying invariance in terms of translation, rotation and scaling."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153745355"
                        ],
                        "name": "Andreas Fischer",
                        "slug": "Andreas-Fischer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052881224"
                        ],
                        "name": "Andreas Keller",
                        "slug": "Andreas-Keller",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Keller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Keller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688695"
                        ],
                        "name": "Volkmar Frinken",
                        "slug": "Volkmar-Frinken",
                        "structuredName": {
                            "firstName": "Volkmar",
                            "lastName": "Frinken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volkmar Frinken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Late works on word spotting have proposed methods that do not require a precise word segmentation, or, in some cases, no segmentation at all."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15576590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5ae30d5535cd1e349347200ca907e99b1784a9d",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwritten word spotting aims at making document images amenable to browsing and searching by keyword retrieval. In this paper, we present a word spotting system based on Hidden Markov Models (HMM) that uses trained subword models to spot keywords. With the proposed method, arbitrary keywords can be spotted that do not need to be present in the training set. Also, no text line segmentation is required. On the modern IAM off-line database and the historical George Washington database we show that the proposed system outperforms a standard template matching approach based on dynamic time warping (DTW)."
            },
            "slug": "HMM-based-Word-Spotting-in-Handwritten-Documents-Fischer-Keller",
            "title": {
                "fragments": [],
                "text": "HMM-based Word Spotting in Handwritten Documents Using Subword Models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A word spotting system based on Hidden Markov Models (HMM) that uses trained subword models to spot keywords that do not need to be present in the training set is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2010 20th International Conference on Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688695"
                        ],
                        "name": "Volkmar Frinken",
                        "slug": "Volkmar-Frinken",
                        "structuredName": {
                            "firstName": "Volkmar",
                            "lastName": "Frinken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volkmar Frinken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153745355"
                        ],
                        "name": "Andreas Fischer",
                        "slug": "Andreas-Fischer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "Late works on word spotting have proposed methods that do not require a precise word segmentation, or, in some cases, no segmentation at all."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14440997,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics",
                "Education"
            ],
            "id": "1bf93c700f2dfe6190497c027c510cddf170bdc1",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Keyword spotting refers to the process of retrieving all instances of a given keyword from a document. In the present paper, a novel keyword spotting method for handwritten documents is described. It is derived from a neural network-based system for unconstrained handwriting recognition. As such it performs template-free spotting, i.e., it is not necessary for a keyword to appear in the training set. The keyword spotting is done using a modification of the CTC Token Passing algorithm in conjunction with a recurrent neural network. We demonstrate that the proposed systems outperform not only a classical dynamic time warping-based approach but also a modern keyword spotting system, based on hidden Markov models. Furthermore, we analyze the performance of the underlying neural networks when using them in a recognition task followed by keyword spotting on the produced transcription. We point out the advantages of keyword spotting when compared to classic text line recognition."
            },
            "slug": "A-Novel-Word-Spotting-Method-Based-on-Recurrent-Frinken-Fischer",
            "title": {
                "fragments": [],
                "text": "A Novel Word Spotting Method Based on Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A novel keyword spotting method for handwritten documents is described, derived from a neural network-based system for unconstrained handwriting recognition, that performs template-free spotting, i.e., it is not necessary for a keyword to appear in the training set."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "Note however that these\nresults are not completely comparable since i) they use different partitions, and ii) they work on already segmented words, i.e., they are not segmentation-free."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "We evaluate our approach on two public datasets: The George Washington (GW) dataset [15, 16] and the Lord Byron (LB) [19]2 dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15554170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e20e64661424bee772c7f002d45c1ac79578fb03",
            "isKey": false,
            "numCitedBy": 658,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Libraries and other institutions are interested in providing access to scanned versions of their large collections of handwritten historical manuscripts on electronic media. Convenient access to a collection requires an index, which is manually created at great labor and expense. Since current handwriting recognizers do not perform well on historical documents, a technique called word spotting has been developed: clusters with occurrences of the same word in a collection are established using image matching. By annotating \"interesting\" clusters, an index can be built automatically. We present an algorithm for matching handwritten words in noisy historical documents. The segmented word images are preprocessed to create sets of 1-dimensional features, which are then compared using dynamic time warping. We present experimental results on two different data sets from the George Washington collection. Our experiments show that this algorithm performs better and is faster than competing matching techniques."
            },
            "slug": "Word-image-matching-using-dynamic-time-warping-Rath-Manmatha",
            "title": {
                "fragments": [],
                "text": "Word image matching using dynamic time warping"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents an algorithm for matching handwritten words in noisy historical documents that performs better and is faster than competing matching techniques and presents experimental results on two different data sets from the George Washington collection."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144565371"
                        ],
                        "name": "P. P\u00e9rez",
                        "slug": "P.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "This technique has shown excellent results on approximate nearest neighbor tasks [10, 12], maintaining a high accuracy while drastically reducing the size of the signatures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1912782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "400e09ceca374f0621335f84a4daf2049d5902be",
            "isKey": false,
            "numCitedBy": 2304,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of image search on a very large scale, where three constraints have to be considered jointly: the accuracy of the search, its efficiency, and the memory usage of the representation. We first propose a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation. We then show how to jointly optimize the dimension reduction and the indexing algorithm, so that it best preserves the quality of vector comparison. The evaluation shows that our approach significantly outperforms the state of the art: the search accuracy is comparable to the bag-of-features approach for an image representation that fits in 20 bytes. Searching a 10 million image dataset takes about 50ms."
            },
            "slug": "Aggregating-local-descriptors-into-a-compact-image-J\u00e9gou-Douze",
            "title": {
                "fragments": [],
                "text": "Aggregating local descriptors into a compact image representation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a simple yet efficient way of aggregating local image descriptors into a vector of limited dimension, which can be viewed as a simplification of the Fisher kernel representation, and shows how to jointly optimize the dimension reduction and the indexing algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399142941"
                        ],
                        "name": "Jos\u00e9 A. Rodr\u00edguez-Serrano",
                        "slug": "Jos\u00e9-A.-Rodr\u00edguez-Serrano",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Rodr\u00edguez-Serrano",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. Rodr\u00edguez-Serrano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Note however that these\nresults are not completely comparable since i) they use different partitions, and ii) they work on already segmented words, i.e., they are not segmentation-free."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "This is different from unsupervised methods that perform word segmentation such as that of [18]: even if they do not use labeled data, they have access to the bounding boxes of training words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Examples of this framework are the works of Rath and Manmatha [16] and Rodr\u00edguezSerrano and Perronnin [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "Moreover, [18] does not include the query as a positive sample, which we do to keep compatibility with [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6677464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e117b2a79a1c25f7894d1ee3787d2b70cd5fcf4d",
            "isKey": true,
            "numCitedBy": 100,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel similarity measure between vector sequences. We work in the framework of model-based approaches, where each sequence is first mapped to a Hidden Markov Model (HMM) and then a measure of similarity is computed between the HMMs. We propose to model sequences with semicontinuous HMMs (SC-HMMs). This is a particular type of HMM whose emission probabilities in each state are mixtures of shared Gaussians. This crucial constraint provides two major benefits. First, the a priori information contained in the common set of Gaussians leads to a more accurate estimate of the HMM parameters. Second, the computation of a similarity between two SC-HMMs can be simplified to a Dynamic Time Warping (DTW) between their mixture weight vectors, which significantly reduces the computational cost. Experiments are carried out on a handwritten word retrieval task in three different datasets-an in-house dataset of real handwritten letters, the George Washington dataset, and the IFN/ENIT dataset of Arabic handwritten words. These experiments show that the proposed similarity outperforms the traditional DTW between the original sequences, and the model-based approach which uses ordinary continuous HMMs. We also show that this increase in accuracy can be traded against a significant reduction of the computational cost."
            },
            "slug": "A-Model-Based-Sequence-Similarity-with-Application-Rodr\u00edguez-Serrano-Perronnin",
            "title": {
                "fragments": [],
                "text": "A Model-Based Sequence Similarity with Application to Handwritten Word Spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The proposed similarity outperforms the traditional DTW between the original sequences, and the model-based approach which uses ordinary continuous HMMs, and it is shown that this increase in accuracy can be traded against a significant reduction of the computational cost."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2576923"
                        ],
                        "name": "R. Tavenard",
                        "slug": "R.-Tavenard",
                        "structuredName": {
                            "firstName": "Romain",
                            "lastName": "Tavenard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tavenard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778357"
                        ],
                        "name": "L. Amsaleg",
                        "slug": "L.-Amsaleg",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Amsaleg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Amsaleg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "This technique has shown excellent results on approximate nearest neighbor tasks [10, 12], maintaining a high accuracy while drastically reducing the size of the signatures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10271065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03fc7bf4b4972a425c9508e71804b3c37eb57b09",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent indexing techniques inspired by source coding have been shown successful to index billions of high-dimensional vectors in memory. In this paper, we propose an approach that re-ranks the neighbor hypotheses obtained by these compressed-domain indexing methods. In contrast to the usual post-verification scheme, which performs exact distance calculation on the short-list of hypotheses, the estimated distances are refined based on short quantization codes, to avoid reading the full vectors from disk. We have released a new public dataset of one billion 128-dimensional vectors and proposed an experimental setup to evaluate high dimensional indexing algorithms on a realistic scale. Experiments show that our method accurately and efficiently re-ranks the neighbor hypotheses using little memory compared to the full vectors representation."
            },
            "slug": "Searching-in-one-billion-vectors:-Re-rank-with-J\u00e9gou-Tavenard",
            "title": {
                "fragments": [],
                "text": "Searching in one billion vectors: Re-rank with source coding"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper releases a new public dataset of one billion 128-dimensional vectors and proposed an experimental setup to evaluate high dimensional indexing algorithms on a realistic scale and accurately and efficiently re-ranks the neighbor hypotheses using little memory compared to the full vectors representation."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781242"
                        ],
                        "name": "Abhinav Shrivastava",
                        "slug": "Abhinav-Shrivastava",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Shrivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinav Shrivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Let us assume that we have access to a set P of regions that are relevant to the query."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Note that [13, 21] propose to use several iterations of hard negative mining."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Finally, as in [21], positive samples could also appear in this randomly chosen negatives set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "Last, we propose to compress the HOG descriptors by means of PQ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "For this task, we propose to use a similar approach to the Exemplar SVM framework of [13, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "In our case, we slightly shift the window around the query word to produce many almost identical, shifted positive samples (see Fig 1(c))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "For this reason, we propose to use HOG descriptors [4], which have been shown to obtain excellent results in the difficult tasks of object detection and image retrieval (see, e.g., [6] or [21])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13898083,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "39689bd427f5668a8fbb3113019c2b8393f0b1a7",
            "isKey": true,
            "numCitedBy": 247,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to find visually similar images even if they appear quite different at the raw pixel level. This task is particularly important for matching images across visual domains, such as photos taken over different seasons or lighting conditions, paintings, hand-drawn sketches, etc. We propose a surprisingly simple method that estimates the relative importance of different features in a query image based on the notion of \"data-driven uniqueness\". We employ standard tools from discriminative object detection in a novel way, yielding a generic approach that does not depend on a particular image representation or a specific visual domain. Our approach shows good performance on a number of difficult cross-domain visual tasks e.g., matching paintings or sketches to real photographs. The method also allows us to demonstrate novel applications such as Internet re-photography, and painting2gps. While at present the technique is too computationally intensive to be practical for interactive image retrieval, we hope that some of the ideas will eventually become applicable to that domain as well."
            },
            "slug": "Data-driven-visual-similarity-for-cross-domain-Shrivastava-Malisiewicz",
            "title": {
                "fragments": [],
                "text": "Data-driven visual similarity for cross-domain image matching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A surprisingly simple method that estimates the relative importance of different features in a query image based on the notion of \"data-driven uniqueness\" is proposed, yielding a generic approach that does not depend on a particular image representation or a specific visual domain."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719436"
                        ],
                        "name": "A. Vinciarelli",
                        "slug": "A.-Vinciarelli",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vinciarelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vinciarelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "Then, the extracted candidates are represented as sequences of features [14, 17, 22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8717387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc7b170fafcd44b4db939306c66a2799ae9b27b3",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts. The only assumption made about the data is that it is written in English. This allows the application of statistical language models in order to improve the performance of our system. Several experiments have been performed using both single and multiple writer data. Lexica of variable size (from 10,000 to 50,000 words) have been used. The use of language models is shown to improve the accuracy of the system (when the lexicon contains 50,000 words, the error rate is reduced by /spl sim/50 percent for single writer data and by /spl sim/25 percent for multiple writer data). Our approach is described in detail and compared with other methods presented in the literature to deal with the same problem. An experimental setup to correctly deal with unconstrained text recognition is proposed."
            },
            "slug": "Offline-recognition-of-unconstrained-handwritten-Vinciarelli-Bengio",
            "title": {
                "fragments": [],
                "text": "Offline recognition of unconstrained handwritten texts using HMMs and statistical language models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The use of language models is shown to improve the accuracy of the system and the approach is described in detail and compared with other methods presented in the literature to deal with the same problem."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "The recent [19] addresses the segmentation problem by representing regions with a fixedlength descriptor based on the well-known bag of visual words framework [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17606900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b91180d8853d00e8f2df7ee3532e07d3d0cce2af",
            "isKey": false,
            "numCitedBy": 5008,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "slug": "Visual-categorization-with-bags-of-keypoints-Csurka",
            "title": {
                "fragments": [],
                "text": "Visual categorization with bags of keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches and shows that it is simple, computationally efficient and intrinsically invariant."
            },
            "venue": {
                "fragments": [],
                "text": "eccv 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Similarly to [20], we decode the features and learn our classifier on the decoded data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16199577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eefcc7bcc05436dac9881acb4ff4e4a0b730e175",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We address image classification on a large-scale, i.e. when a large number of images and classes are involved. First, we study classification accuracy as a function of the image signature dimensionality and the training set size. We show experimentally that the larger the training set, the higher the impact of the dimensionality on the accuracy. In other words, high-dimensional signatures are important to obtain state-of-the-art results on large datasets. Second, we tackle the problem of data compression on very large signatures (on the order of 105 dimensions) using two lossy compression strategies: a dimensionality reduction technique known as the hash kernel and an encoding technique based on product quantizers. We explain how the gain in storage can be traded against a loss in accuracy and/or an increase in CPU cost. We report results on two large databases \u2014 ImageNet and a dataset of lM Flickr images \u2014 showing that we can reduce the storage of our signatures by a factor 64 to 128 with little loss in accuracy. Integrating the decompression in the classifier learning yields an efficient and scalable training algorithm. On ILSVRC2010 we report a 74.3% accuracy at top-5, which corresponds to a 2.5% absolute improvement with respect to the state-of-the-art. On a subset of 10K classes of ImageNet we report a top-1 accuracy of 16.7%, a relative improvement of 160% with respect to the state-of-the-art."
            },
            "slug": "High-dimensional-signature-compression-for-image-S\u00e1nchez-Perronnin",
            "title": {
                "fragments": [],
                "text": "High-dimensional signature compression for large-scale image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work reports results on two large databases \u2014 ImageNet and a dataset of lM Flickr images \u2014 showing that it can reduce the storage of the authors' signatures by a factor 64 to 128 with little loss in accuracy and integrating the decompression in the classifier learning yields an efficient and scalable training algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "As noted by the authors, the performance of the method is very dependent on the length of the query with respect to the fixed size of the window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "For this reason, we propose to use HOG descriptors [4], which have been shown to obtain excellent results in the difficult tasks of object detection and image retrieval (see, e.g., [6] or [21])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29258,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "First, we show that a sliding window approach on top of a HOG grid can be used to solve word spotting tasks in a very natural way."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "Unfortunately, using vector quantization is not possible if the dimensionality of the vectors is not trivially low: as noted in [11], to encode a descriptor of 128 dimensions using only 0.5 bits per dimension, we would need to compute 264 centroids, which is not feasible."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "In this section we propose to encode the HOG descriptors by means of Product Quantization (PQ) [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5850884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4748d22348e72e6e06c2476486afddbc76e5eca7",
            "isKey": true,
            "numCitedBy": 2049,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a product quantization-based approach for approximate nearest neighbor search. The idea is to decompose the space into a Cartesian product of low-dimensional subspaces and to quantize each subspace separately. A vector is represented by a short code composed of its subspace quantization indices. The euclidean distance between two vectors can be efficiently estimated from their codes. An asymmetric version increases precision, as it computes the approximate distance between a vector and a code. Experimental results show that our approach searches for nearest neighbors efficiently, in particular in combination with an inverted file system. Results for SIFT and GIST image descriptors show excellent search accuracy, outperforming three state-of-the-art approaches. The scalability of our approach is validated on a data set of two billion vectors."
            },
            "slug": "Product-Quantization-for-Nearest-Neighbor-Search-J\u00e9gou-Douze",
            "title": {
                "fragments": [],
                "text": "Product Quantization for Nearest Neighbor Search"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper introduces a product quantization-based approach for approximate nearest neighbor search to decompose the space into a Cartesian product of low-dimensional subspaces and to quantize each subspace separately."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37526757"
                        ],
                        "name": "Urs-Viktor Marti",
                        "slug": "Urs-Viktor-Marti",
                        "structuredName": {
                            "firstName": "Urs-Viktor",
                            "lastName": "Marti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs-Viktor Marti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Then, the extracted candidates are represented as sequences of features [14, 17, 22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10207300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e15725948c2ea8b190b825a0887e430dc4898428",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a system for the reading of totally unconstrained handwritten text is presented. The kernel of the system is a hidden Markov model (HMM) for handwriting recognition. The HMM is enhanced by a statistical language model. Thus linguistic knowledge beyond the lexicon level is incorporated in the recognition process. Another novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided. A number of experiments with various language models and large vocabularies have been conducted. The language models used in the system were also analytically compared based on their perplexity."
            },
            "slug": "Using-a-Statistical-Language-Model-to-Improve-the-Marti-Bunke",
            "title": {
                "fragments": [],
                "text": "Using a Statistical Language Model to Improve the Performance of an HMM-Based Cursive Handwriting Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided and linguistic knowledge beyond the lexicon level is incorporated in the recognition process."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Last, we propose to compress the HOG descriptors by means of PQ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "For this task, we propose to use a similar approach to the Exemplar SVM framework of [13, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Note that [13, 21] propose to use several iterations of hard negative mining."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Let us assume that we have access to a set P of regions that are relevant to the query."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14448882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d124f004fed2ee15860f624005b2215cfaeff276",
            "isKey": true,
            "numCitedBy": 891,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a conceptually simple but surprisingly powerful method which combines the effectiveness of a discriminative object detector with the explicit correspondence offered by a nearest-neighbor approach. The method is based on training a separate linear SVM classifier for every exemplar in the training set. Each of these Exemplar-SVMs is thus defined by a single positive instance and millions of negatives. While each detector is quite specific to its exemplar, we empirically observe that an ensemble of such Exemplar-SVMs offers surprisingly good generalization. Our performance on the PASCAL VOC detection task is on par with the much more complex latent part-based model of Felzenszwalb et al., at only a modest computational cost increase. But the central benefit of our approach is that it creates an explicit association between each detection and a single training exemplar. Because most detections show good alignment to their associated exemplar, it is possible to transfer any available exemplar meta-data (segmentation, geometric structure, 3D model, etc.) directly onto the detections, which can then be used as part of overall scene understanding."
            },
            "slug": "Ensemble-of-exemplar-SVMs-for-object-detection-and-Malisiewicz-Gupta",
            "title": {
                "fragments": [],
                "text": "Ensemble of exemplar-SVMs for object detection and beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper proposes a conceptually simple but surprisingly powerful method which combines the effectiveness of a discriminative object detector with the explicit correspondence offered by a nearest-neighbor approach."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "We follow [6] and use HOG histograms of 31 dimensions to represent each cell."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 181
                            }
                        ],
                        "text": "For this reason, we propose to use HOG descriptors [4], which have been shown to obtain excellent results in the difficult tasks of object detection and image retrieval (see, e.g., [6] or [21])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3198903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e79272fe3d65197100eae8be9fec6469107969ae",
            "isKey": false,
            "numCitedBy": 9371,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function."
            },
            "slug": "Object-Detection-with-Discriminatively-Trained-Part-Felzenszwalb-Girshick",
            "title": {
                "fragments": [],
                "text": "Object Detection with Discriminatively Trained Part Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An object detection system based on mixtures of multiscale deformable part models that is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849128"
                        ],
                        "name": "Rong-En Fan",
                        "slug": "Rong-En-Fan",
                        "structuredName": {
                            "firstName": "Rong-En",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong-En Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782886"
                        ],
                        "name": "Kai-Wei Chang",
                        "slug": "Kai-Wei-Chang",
                        "structuredName": {
                            "firstName": "Kai-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793529"
                        ],
                        "name": "Cho-Jui Hsieh",
                        "slug": "Cho-Jui-Hsieh",
                        "structuredName": {
                            "firstName": "Cho-Jui",
                            "lastName": "Hsieh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cho-Jui Hsieh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144799660"
                        ],
                        "name": "Xiang-Rui Wang",
                        "slug": "Xiang-Rui-Wang",
                        "structuredName": {
                            "firstName": "Xiang-Rui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang-Rui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "When learning the Exemplar SVM, we used the LIBLINEAR package [5] and fixed the C trade-off to 0.01."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3116168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "268a4f8da15a42f3e0e71691f760ff5edbf9cec8",
            "isKey": true,
            "numCitedBy": 7764,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets."
            },
            "slug": "LIBLINEAR:-A-Library-for-Large-Linear-Fan-Chang",
            "title": {
                "fragments": [],
                "text": "LIBLINEAR: A Library for Large Linear Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "LIBLINEAR is an open source library for large-scale linear classification that supports logistic regression and linear support vector machines and provides easy-to-use command-line tools and library calls for users and developers."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exemplar Word Spotting library"
            },
            "venue": {
                "fragments": [],
                "text": "Exemplar Word Spotting library"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Gradient Descent project"
            },
            "venue": {
                "fragments": [],
                "text": "Stochastic Gradient Descent project"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 15,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Efficient-Exemplar-Word-Spotting-Almaz\u00e1n-Gordo/b687fcbae65f6addbc910cd307d2f747f1323c7d?sort=total-citations"
}