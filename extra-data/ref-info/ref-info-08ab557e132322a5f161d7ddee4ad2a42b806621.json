{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3334581"
                        ],
                        "name": "Fattah Zirari",
                        "slug": "Fattah-Zirari",
                        "structuredName": {
                            "firstName": "Fattah",
                            "lastName": "Zirari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fattah Zirari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901589"
                        ],
                        "name": "A. Ennaji",
                        "slug": "A.-Ennaji",
                        "structuredName": {
                            "firstName": "Abdellatif",
                            "lastName": "Ennaji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ennaji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97014121"
                        ],
                        "name": "St\u00e9phane Nicolas",
                        "slug": "St\u00e9phane-Nicolas",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Nicolas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Nicolas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751527"
                        ],
                        "name": "D. Mammass",
                        "slug": "D.-Mammass",
                        "structuredName": {
                            "firstName": "Driss",
                            "lastName": "Mammass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mammass"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22226084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc6bcf219ef9dc20b2f12bb6aa5b950d72cfaf2d",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Page segmentation into text and non-text elements is an essential preprocessing step before optical character recognition (OCR) operation. In case of poor segmentation, an OCR classification engine produces garbage characters due to the presence of non-text elements. This paper presents a method to separate the textual and non textual components in document images using a graph-based modeling and structural analysis. This is a fast and efficient method to separate adequately the graphical and the textual parts of a document. We have evaluated our method on two well-known subsets: the UW-III dataset and the ICDAR 2009 page segmentation competition dataset. Comparisons are led with two methods of state-of-the-art, these results showing that our method proved better performances in this task."
            },
            "slug": "A-Document-Image-Segmentation-System-Using-Analysis-Zirari-Ennaji",
            "title": {
                "fragments": [],
                "text": "A Document Image Segmentation System Using Analysis of Connected Components"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents a method to separate the textual and non textual components in document images using a graph-based modeling and structural analysis, which is a fast and efficient way to separate adequately the graphical and the textual parts of a document."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715229"
                        ],
                        "name": "Markus Diem",
                        "slug": "Markus-Diem",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Diem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Diem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729636"
                        ],
                        "name": "Florian Kleber",
                        "slug": "Florian-Kleber",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Kleber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florian Kleber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706090"
                        ],
                        "name": "R. Sablatnig",
                        "slug": "R.-Sablatnig",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sablatnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sablatnig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 485,
                                "start": 480
                            }
                        ],
                        "text": "Table 1 \u2013 continued from previous page AlgorithmInput layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [109] Any No Color Yes Yes Regions Any Curved 49 3 2 [106] Any No Color Yes Yes Regions Any Curved 49 3 2 [114] Any No Color No Yes Text lines Any Curved 214 3 3 [116] Any No Color No Yes Text lines Horizontal Straight 1072 3 6 [100] Any No Gray Yes Yes Regions Any Curved 86 3 1 [102] Any No Gray Yes Yes Regions + text lines Any Curved 501 1 2"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 5
                            }
                        ],
                        "text": "Diem [102] tackles the challenge of segmenting document fragments."
                    },
                    "intents": []
                }
            ],
            "corpusId": 129669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44f20632b4e2f91f74d286d7b0ca7701ec809c84",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In general document image analysis methods are pre-processing steps for Optical Character Recognition (OCR) systems. In contrast, the proposed method aims at clustering document snippets, so that an automated clustering of documents can be performed. Therefore, words are classified according to printed text, manuscripts, and noise. Where, the third class corrects falsely segmented background elements. Having classified text elements, a layout analysis is carried out which groups words into text lines and paragraphs. A back propagation of the class weights - assigned to each word in the first step - enables correcting wrong class labels. The proposed method shows promising results on a dataset consisting of document snippets with varying shapes, content writing and layout. In addition, the system is compared to page segmentation methods of the ICDAR 2009 Page Segmentation Competition."
            },
            "slug": "Text-Classification-and-Document-Layout-Analysis-of-Diem-Kleber",
            "title": {
                "fragments": [],
                "text": "Text Classification and Document Layout Analysis of Paper Fragments"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The proposed method aims at clustering document snippets, so that an automated clustering of documents can be performed, and shows promising results on a dataset consisting of document snippets with varying shapes, content writing and layout."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31494111"
                        ],
                        "name": "F. C. Fernandez",
                        "slug": "F.-C.-Fernandez",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Fernandez",
                            "middleNames": [
                                "Cruz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. C. Fernandez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045937"
                        ],
                        "name": "O. R. Terrades",
                        "slug": "O.-R.-Terrades",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Terrades",
                            "middleNames": [
                                "Ramos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. R. Terrades"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11671554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b112a57ee2eef36ea67cbcbeaab4e1e0a0a5dfe",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we evaluate the use of Relative Location Features (RLF) on a historical document segmentation task, and compare the quality of the results obtained on structured and unstructured documents using RLF and not using them. We prove that using these features improve the final segmentation on documents with a strong structure, while their application on unstructured documents does not show significant improvement. Although this paper is not focused on segmenting unstructured documents, results obtained on a benchmark dataset are equal or even overcome previous results of similar works."
            },
            "slug": "Document-segmentation-using-Relative-Location-Fernandez-Terrades",
            "title": {
                "fragments": [],
                "text": "Document segmentation using Relative Location Features"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "It is proved that using Relative Location Features improve the final segmentation on documents with a strong structure, while their application on unstructured documents does not show significant improvement."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2455854"
                        ],
                        "name": "T. Bockholt",
                        "slug": "T.-Bockholt",
                        "structuredName": {
                            "firstName": "Tiago",
                            "lastName": "Bockholt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bockholt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805618"
                        ],
                        "name": "George D. C. Cavalcanti",
                        "slug": "George-D.-C.-Cavalcanti",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cavalcanti",
                            "middleNames": [
                                "D.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George D. C. Cavalcanti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846903"
                        ],
                        "name": "C. Mello",
                        "slug": "C.-Mello",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Mello",
                            "middleNames": [
                                "A.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mello"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8519228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b25092bf209b973b84ff07714c422900ea4802f",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital libraries need more than just a retrieval based on keywords, which can be inefficient for some applications. Thus, a document retrieval based on content of the digitized image version of the document can be a more appropriated approach. This paper discusses the retrieval of document images by means of identifying a variety of elements present in the document's image body. We propose a new strategy to identify and combine features extracted from a document image. We also consider the task of constructing an optimized feature set to improve the retrieval performance and to validate our experiments on an assorted database. Experimental results show that the proposed segmentation together with a wisely feature combination increase the overall retrieval performance. Moreover the retrieved images demonstrate the generality and effectiveness of our approach for an efficient segmentation and classification of document images."
            },
            "slug": "Document-image-retrieval-with-morphology-based-and-Bockholt-Cavalcanti",
            "title": {
                "fragments": [],
                "text": "Document image retrieval with morphology-based segmentation and features combination"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Experimental results show that the proposed segmentation together with a wisely feature combination increase the overall retrieval performance and the retrieved images demonstrate the generality and effectiveness of the approach for an efficient segmentation and classification of document images."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2764871"
                        ],
                        "name": "C. Clausner",
                        "slug": "C.-Clausner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Clausner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clausner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070747525"
                        ],
                        "name": "C. Papadopoulos",
                        "slug": "C.-Papadopoulos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206777025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eacf020f7eae7673a746eccdd5819a6a1be9e85",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an objective comparative evaluation of layout analysis methods for scanned historical documents. It describes the competition (modus operandi, dataset and evaluation methodology) held in the context of ICDAR2011 and the International Workshop on Historical Document Imaging and Processing (HIP2011), presenting the results of the evaluation of four submitted methods. A commercial state-of-the-art system is also evaluated for comparison. Two scenarios are reported in this paper, one evaluating the ability of methods to accurately segment regions and the other evaluating the whole pipeline of segmentation and region classification (with a text extraction goal). The results indicate that there is a convergence to a certain methodology with some variations in the approach. However, there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical documents."
            },
            "slug": "Historical-Document-Layout-Analysis-Competition-Antonacopoulos-Clausner",
            "title": {
                "fragments": [],
                "text": "Historical Document Layout Analysis Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An objective comparative evaluation of layout analysis methods for scanned historical documents shows that there is a convergence to a certain methodology with some variations in the approach, but there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical documents."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748667"
                        ],
                        "name": "N. Journet",
                        "slug": "N.-Journet",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Journet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Journet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682986"
                        ],
                        "name": "R. Mullot",
                        "slug": "R.-Mullot",
                        "structuredName": {
                            "firstName": "R\u00e9my",
                            "lastName": "Mullot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mullot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721326"
                        ],
                        "name": "V. Eglin",
                        "slug": "V.-Eglin",
                        "structuredName": {
                            "firstName": "V\u00e9ronique",
                            "lastName": "Eglin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eglin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[25] Any No Gray No No Regions Any Curved 400 1 2 [57] Any No Gray No No Regions Any Curved 25 1 1 [14] (MHS) Any No BW Yes No Regions Horizontal Straight 70 1 1"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "Texture only clustering Three algorithms use only texture features [25, 57, 58]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[25] use features at pixel level and tested them on both modern and historical documents."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15709769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eed7fde845f40d7e72af1d038ea47f3eda5bcfd9",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we propose a method of characterization of images of old documents based on a texture approach. This characterization is carried out with the help of a multi-resolution study of the textures contained in the images of the document. Thus, by extracting five features linked to the frequencies and to the orientations in the different areas of a page, it is possible to extract and compare elements of high semantic level without expressing any hypothesis about the physical or logical structure of the analyzed documents. Experimentation based on segmentation, data analysis and document image retrieval tools demonstrate the performance of our propositions and the advances that they represent in terms of characterization of content of a deeply heterogeneous corpus."
            },
            "slug": "Document-image-characterization-using-a-analysis-of-Journet-Ramel",
            "title": {
                "fragments": [],
                "text": "Document image characterization using a multiresolution analysis of the texture: application to old documents"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By extracting five features linked to the frequencies and to the orientations in the different areas of a page, it is possible to extract and compare elements of high semantic level without expressing any hypothesis about the physical or logical structure of the analyzed documents."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700033"
                        ],
                        "name": "N. Stamatopoulos",
                        "slug": "N.-Stamatopoulos",
                        "structuredName": {
                            "firstName": "Nikolaos",
                            "lastName": "Stamatopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Stamatopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2397702"
                        ],
                        "name": "S. Perantonis",
                        "slug": "S.-Perantonis",
                        "structuredName": {
                            "firstName": "Stavros",
                            "lastName": "Perantonis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Perantonis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8663191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "663e55b76e7a1544044ef8a3463d12363c6e37d9",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-method-for-combining-complementary-techniques-for-Stamatopoulos-Gatos",
            "title": {
                "fragments": [],
                "text": "A method for combining complementary techniques for document image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153322035"
                        ],
                        "name": "Takuma Yamaguchi",
                        "slug": "Takuma-Yamaguchi",
                        "structuredName": {
                            "firstName": "Takuma",
                            "lastName": "Yamaguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takuma Yamaguchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740697"
                        ],
                        "name": "M. Maruyama",
                        "slug": "M.-Maruyama",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Maruyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maruyama"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 27644575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efa4d68dbf5f80531bf26e1577ee80e387edcb23",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method for document image segmentation based on pLSA (probabilistic latent semantic analysis) model. The pLSA model is originally developed for topic discovery in text analysis using \"bag-of-words\" document representation. The model is useful for image analysis by \"bag-of-visual words\" image representation. The performance of the method depends on the visual vocabulary generated by feature extraction from the document image. We compare several feature extraction and description methods, and examine the relations to segmentation performance. Through the experiments, we show accurate content-based document segmentation is made possible by using pLSA-based method."
            },
            "slug": "Feature-Extraction-for-Document-Image-Segmentation-Yamaguchi-Maruyama",
            "title": {
                "fragments": [],
                "text": "Feature Extraction for Document Image Segmentation by pLSA Model"
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3097187"
                        ],
                        "name": "Mohamed Benjelil",
                        "slug": "Mohamed-Benjelil",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Benjelil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohamed Benjelil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144145492"
                        ],
                        "name": "S. Kanoun",
                        "slug": "S.-Kanoun",
                        "structuredName": {
                            "firstName": "Slim",
                            "lastName": "Kanoun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kanoun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682986"
                        ],
                        "name": "R. Mullot",
                        "slug": "R.-Mullot",
                        "structuredName": {
                            "firstName": "R\u00e9my",
                            "lastName": "Mullot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mullot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144000830"
                        ],
                        "name": "A. Alimi",
                        "slug": "A.-Alimi",
                        "structuredName": {
                            "firstName": "Adel",
                            "lastName": "Alimi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Alimi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41364035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17e8053901969cb1661016d3799f94c194d3632b",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Page segmentation and classification is very important in document layout analysis system before it is presented to an OCR system or for any other subsequent processing steps. In this paper, we propose an accurate and suitably designed system for complex documents segmentation. This system is based on steerable pyramid transform. The features extracted from pyramid sub-bands serve to locate and classify regions into text (either machine-printed or handwritten) and non-text (images, graphics, drawings or paintings) in some noise-infected, deformed, multilingual, multi-script document images. These documents contain tabular structures, logos, stamps, handwritten script blocks, photographs, etc. The encouraging and promising results obtained on 1,000 official complex document images data set are presented in this research paper. We compared our results with those from existing state-of-the-art methods. This comparison shows that the proposed method performs consistently well on large sets of complex document images."
            },
            "slug": "Complex-documents-images-segmentation-based-on-Benjelil-Kanoun",
            "title": {
                "fragments": [],
                "text": "Complex documents images segmentation based on steerable pyramid features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes an accurate and suitably designed system for complex documents segmentation based on steerable pyramid transform, which performs consistently well on large sets of complex document images."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145766704"
                        ],
                        "name": "Abedelkadir Asi",
                        "slug": "Abedelkadir-Asi",
                        "structuredName": {
                            "firstName": "Abedelkadir",
                            "lastName": "Asi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abedelkadir Asi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51037361"
                        ],
                        "name": "Rafi Cohen",
                        "slug": "Rafi-Cohen",
                        "structuredName": {
                            "firstName": "Rafi",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafi Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1939225"
                        ],
                        "name": "K. Kedem",
                        "slug": "K.-Kedem",
                        "structuredName": {
                            "firstName": "Klara",
                            "lastName": "Kedem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kedem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397974623"
                        ],
                        "name": "Jihad El-Sana",
                        "slug": "Jihad-El-Sana",
                        "structuredName": {
                            "firstName": "Jihad",
                            "lastName": "El-Sana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jihad El-Sana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26514936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a53eb30d8135ba22d14f6bc61663c76e88a464c",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Complex document layouts pose prominent challenges for document image understanding algorithms. These layouts impose irregularities on the location of text paragraphs which consequently induces difficulties in reading the text. In this paper we present a robust framework for analyzing historical manuscripts with complex layouts. This framework aims to provide a convenient reading experience for historians through topnotch algorithms for text localization, classification and dewarping. We segment text into spatially coherent regions and text-lines using texture-based filters and refine this segmentation by exploiting Markov Random Fields (MRFs). A principled technique is presented for dewarping curvy text regions using a non-linear geometric transformation. The framework has been validated using a subset of a publicly available dataset of historical documents and it provided promising results."
            },
            "slug": "Simplifying-the-reading-of-historical-manuscripts-Asi-Cohen",
            "title": {
                "fragments": [],
                "text": "Simplifying the reading of historical manuscripts"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A robust framework for analyzing historical manuscripts with complex layouts is presented and it aims to provide a convenient reading experience for historians through topnotch algorithms for text localization, classification and dewarping."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 301
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "This algorithm has been evaluated on 10 different scripts in [78]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31733,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a041d6f97e302ea1753641017300ff0efcb4b6c7",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Text-line extraction is the backbone of document image analysis. Since decades, a large number of text-line finding methods have been proposed, where these methods rely on certain assumptions about a target class of documents with respect to writing styles, digitization methods, intensity values, and scripts. There is no generic text-line finding method that can be robustly applied to a large variety of simple and complex document images. We introduced the ridge-based text-line finding method, and published its initial results for curled text-line detection on camera-captured document images. In this paper, we demonstrates our ridge-based method as a generic text-line finding approach that can be robustly applied on a diverse collection of simple and complex document images. The comprehensive performance evaluation of the ridge-based method and its comparison with several state-of-the-art methods is presented in the paper. For this purpose, diverse categories of publicly available and standard datasets have been selected: UWIII (scanned, printed English script), DFKI-I (camera-captured, printed English script), UMD (handwritten Chinese, Hindi, and Korean scripts), ICDAR2007 handwritten segmentation contest (handwritten English, French, German and Greek scripts), Arabic/Urdu (scanned, printed script), and Fraktur (scanned, calligraphic German script). Experiments on these datasets show that the ridge-based method achieves better text-line extraction results as those of the best performing, domain-specific text-line finding methods. Firstly, these results show that the ridge-based method is a generic text-line extraction method. Secondly, these results are also helpful for the community to assess the advantages of this method."
            },
            "slug": "Towards-Generic-Text-Line-Extraction-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Towards Generic Text-Line Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments on diverse categories of publicly available and standard datasets show that the ridge-based method achieves better text-line extraction results as those of the best performing, domain-specific text- line finding methods."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3290619"
                        ],
                        "name": "M. A. Azawi",
                        "slug": "M.-A.-Azawi",
                        "structuredName": {
                            "firstName": "Mayce",
                            "lastName": "Azawi",
                            "middleNames": [
                                "Ibrahim",
                                "Ali",
                                "Al"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Azawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Bukhari [92] focus on extracting text from documents that contain graphics illustrations such as circuit drawings."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10505962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86dc413ef69fb7e77608cca0683b558ab7fda7af",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of a document image into text and non-text regions is an important preprocessing step for a variety of document image analysis tasks, like improving OCR, document compression etc. Most of the state-of-the-art document image segmentation approaches perform segmentation using pixel-based or zone(block)-based classification. Pixel-based classification approaches are time consuming, whereas block-based methods heavily depend on the accuracy of block segmentation step. In contrast to the state-of-the-art document image segmentation approaches, our segmentation approach introduces connected component based classification, thereby not requiring a block segmentation beforehand. Here we train a self-tunable multi-layer perceptron (MLP) classifier for distinguishing between text and non-text connected components using shape and context information as a feature vector. Experimental results prove the effectiveness of our proposed algorithm. We have evaluated our method on subset of UW-III, ICDAR 2009 page segmentation competition test images and circuit diagrams datasets and compared its results with the state-of-the-art leptonica's page segmentation algorithm."
            },
            "slug": "Document-image-segmentation-using-discriminative-Bukhari-Azawi",
            "title": {
                "fragments": [],
                "text": "Document image segmentation using discriminative learning over connected components"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work trains a self-tunable multi-layer perceptron (MLP) classifier for distinguishing between text and non-text connected components using shape and context information as a feature vector to introduce connected component based classification."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152613893"
                        ],
                        "name": "Z. Liu",
                        "slug": "Z.-Liu",
                        "structuredName": {
                            "firstName": "Zongyi",
                            "lastName": "Liu",
                            "middleNames": [
                                "Joe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28190232"
                        ],
                        "name": "Hanning Zhou",
                        "slug": "Hanning-Zhou",
                        "structuredName": {
                            "firstName": "Hanning",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanning Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075332840"
                        ],
                        "name": "Ning Yang",
                        "slug": "Ning-Yang",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ning Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[38] use [41] to segment Manhattan layouts."
                    },
                    "intents": []
                }
            ],
            "corpusId": 39500171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d57f40e13ccb92c8562bc4a903024f1109b8372",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semi-supervised-learning-for-text-line-detection-Liu-Zhou",
            "title": {
                "fragments": [],
                "text": "Semi-supervised learning for text-line detection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131158"
                        ],
                        "name": "Maroua Mehri",
                        "slug": "Maroua-Mehri",
                        "structuredName": {
                            "firstName": "Maroua",
                            "lastName": "Mehri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maroua Mehri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399368454"
                        ],
                        "name": "Petra Gomez-Kr\u00e4mer",
                        "slug": "Petra-Gomez-Kr\u00e4mer",
                        "structuredName": {
                            "firstName": "Petra",
                            "lastName": "Gomez-Kr\u00e4mer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petra Gomez-Kr\u00e4mer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826457"
                        ],
                        "name": "P. H\u00e9roux",
                        "slug": "P.-H\u00e9roux",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "H\u00e9roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e9roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143858619"
                        ],
                        "name": "A. Boucher",
                        "slug": "A.-Boucher",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Boucher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Boucher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682986"
                        ],
                        "name": "R. Mullot",
                        "slug": "R.-Mullot",
                        "structuredName": {
                            "firstName": "R\u00e9my",
                            "lastName": "Mullot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mullot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16680421,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43421c6154b152a7081a175a225621bfa76925e2",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture feature analysis has undergone tremendous growth in recent years. It plays an important role for the analysis of many kinds of images. More recently, the use of texture analysis techniques for historical document image segmentation has become a logical and relevant choice in the conditions of significant document image degradation and in the context of lacking information on the document structure such as the document model and the typographical parameters. However, previous work in the use of texture analysis for segmentation of digitized historical document images has been limited to separately test one of the well-known texture-based approaches such as autocorrelation function, Grey Level Co-occurrence Matrix (GLCM), Gabor filters, gradient, wavelets, etc. In this paper we raise the question of which texture-based method could be better suited for discriminating on the one hand graphical regions from textual ones and on the other hand for separating textual regions with different sizes and fonts. The objective of this paper is to compare some of the well-known texture-based approaches: autocorrelation function, GLCM, and Gabor filters, used in a segmentation of digitized historical document images. Texture features are briefly described and quantitative results are obtained on simplified historical document images. The achieved results are very encouraging."
            },
            "slug": "Texture-feature-evaluation-for-segmentation-of-Mehri-Gomez-Kr\u00e4mer",
            "title": {
                "fragments": [],
                "text": "Texture feature evaluation for segmentation of historical document images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The question of which texture-based method could be better suited for discriminating on the one hand graphical regions from textual ones and on the other hand for separating textual regions with different sizes and fonts is raised."
            },
            "venue": {
                "fragments": [],
                "text": "HIP '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934864"
                        ],
                        "name": "A. Ouji",
                        "slug": "A.-Ouji",
                        "structuredName": {
                            "firstName": "Asma",
                            "lastName": "Ouji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ouji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3100171"
                        ],
                        "name": "Yann Leydier",
                        "slug": "Yann-Leydier",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Leydier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann Leydier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145573734"
                        ],
                        "name": "F. Lebourgeois",
                        "slug": "F.-Lebourgeois",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lebourgeois"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[72] have a versatile algorithm based on a"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "Algorithm Input layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [72] Any Yes Color Yes No Text lines Horizontal Straight 448 1 2 [104] Any Yes Color Yes Yes Regions Any Curved 87 1 2 [110] Any Yes Color Yes Yes Regions Any Curved 16 2 1 [51] Any Yes Color No No Regions Any Curved 2000 2 2 [74] Any Yes Color No No Text lines Any Curved 50 1 1 [84] Any Yes Color No Yes Text lines Any Straight 21 2 1 [54] Any Yes Gray Yes No Regions Horizontal Straight 65 2 1 [112] Any Yes BW Yes Yes Regions Horizontal Straight 1000 3 6 [89] Any No Color Yes Yes Regions Any Curved 100 1 1 Continued on next page"
                    },
                    "intents": []
                }
            ],
            "corpusId": 13085957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f032083184d073666098d92a24a01fb3e8da246a",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce a novel color segmentation approach robust against digitization noise and adapted to contemporary document images. This system is scalable, hierarchical, versatile and completely automated, i.e. user independent. It proposes an adaptive binarization/quantization without any penalizing information loss. This model may be used for many purposes. For instance, we rely on it to carry out the first steps leading to advertisement recognition in document images. Furthermore, the color segmentation output is used to localize text areas and enhance optical character recognition (OCR) performances. We held tests on a variety of magazine images to point up our contribution to the well-known OCR product Abby FinerReader. We also get promising results with our ad detection system on a large set of complex layout testing images."
            },
            "slug": "A-hierarchical-and-scalable-model-for-contemporary-Ouji-Leydier",
            "title": {
                "fragments": [],
                "text": "A hierarchical and scalable model for contemporary document image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A novel color segmentation approach robust against digitization noise and adapted to contemporary document images is introduced, which is scalable, hierarchical, versatile and completely automated, i.e. user independent."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Applications"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39796333"
                        ],
                        "name": "A. Winder",
                        "slug": "A.-Winder",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Winder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Winder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34774083"
                        ],
                        "name": "Timothy L. Andersen",
                        "slug": "Timothy-L.-Andersen",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Andersen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy L. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727768"
                        ],
                        "name": "E. B. Smith",
                        "slug": "E.-B.-Smith",
                        "structuredName": {
                            "firstName": "Elisa",
                            "lastName": "Smith",
                            "middleNames": [
                                "H.",
                                "Barney"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. B. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 17926754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "789a85c394794355cd6b34031657f50f26cf3369",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to add the capability to segment documents containing text, graphics, and pictures in the open source OCR engine OCRopus. To achieve this goal, OCRopus' RAST algorithm was improved to recognize non-text regions so that mixed content documents could be analyzed in addition to text-only documents. Also, a method for classifying text and non-text regions was developed and implemented for the Voronoi algorithm enabling users to perform OCR on documents processed by this method. Finally, both algorithms were modified to perform at a range of resolutions. Our testing showed an improvement of 15-40% for the RAST algorithm, giving it an average segmentation accuracy of about 80%. The Voronoi algorithm averaged around 70% accuracy on our test data. Depending on the particular layout and idiosyncracies of the documents to be digitized, however, either algorithm could be sufficiently accurate to be utilized."
            },
            "slug": "Extending-Page-Segmentation-Algorithms-for-Document-Winder-Andersen",
            "title": {
                "fragments": [],
                "text": "Extending Page Segmentation Algorithms for Mixed-Layout Document Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "OCRopus' RAST algorithm was improved to recognize non-text regions so that mixed content documents could be analyzed in addition to text-only documents and a method for classifying text and non- Text regions was developed and implemented for the Voronoi algorithm enabling users to perform OCR on documents processed by this method."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131158"
                        ],
                        "name": "Maroua Mehri",
                        "slug": "Maroua-Mehri",
                        "structuredName": {
                            "firstName": "Maroua",
                            "lastName": "Mehri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maroua Mehri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826457"
                        ],
                        "name": "P. H\u00e9roux",
                        "slug": "P.-H\u00e9roux",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "H\u00e9roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e9roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399368454"
                        ],
                        "name": "Petra Gomez-Kr\u00e4mer",
                        "slug": "Petra-Gomez-Kr\u00e4mer",
                        "structuredName": {
                            "firstName": "Petra",
                            "lastName": "Gomez-Kr\u00e4mer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petra Gomez-Kr\u00e4mer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143858619"
                        ],
                        "name": "A. Boucher",
                        "slug": "A.-Boucher",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Boucher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Boucher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682986"
                        ],
                        "name": "R. Mullot",
                        "slug": "R.-Mullot",
                        "structuredName": {
                            "firstName": "R\u00e9my",
                            "lastName": "Mullot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mullot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "Texture only clustering Three algorithms use only texture features [25, 57, 58]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9656136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddeb838ad644be06d0021685a740dac1b2f87493",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In the context of historical collection conservation and worldwide diffusion, this paper presents an automatic approach of historical book page layout segmentation. In this article, we propose to search the homogeneous regions from the content of historical digitized books with little a priori knowledge by extracting and analyzing texture features. The novelty of this work lies in the unsupervised clustering of the extracted texture descriptors to find homogeneous regions, i.e. graphic and textual regions, by performing the clustering approach on an entire book instead of processing each page individually. We propose firstly to characterize the content of an entire book by extracting the texture information of each page, as our goal is to compare and index the content of digitized books. The extraction of texture features, computed without any hypothesis on the document structure, is based on two non-parametric tools: the autocorrelation function and multiresolution analysis. Secondly, we perform an unsupervised clustering approach on the extracted features in order to classify automatically the homogeneous regions of book pages. The clustering results are assessed by internal and external accuracy measures. The overall results are quite satisfying. Such analysis would help to construct a computer-aided categorization tool of pages."
            },
            "slug": "A-Pixel-Labeling-Approach-for-Historical-Digitized-Mehri-H\u00e9roux",
            "title": {
                "fragments": [],
                "text": "A Pixel Labeling Approach for Historical Digitized Books"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The novelty of this work lies in the unsupervised clustering of the extracted texture descriptors to find homogeneous regions of book pages, i.e. graphic and textual regions, by performing the clustering approach on an entire book instead of processing each page individually."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144322499"
                        ],
                        "name": "D. Bridson",
                        "slug": "D.-Bridson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bridson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bridson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070747525"
                        ],
                        "name": "C. Papadopoulos",
                        "slug": "C.-Papadopoulos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33282851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b76f6734e87bcd7bf9f96c41156aa259e2429f7",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an objective comparative evalua-tion of layout analysis methods in realistic circumstances. It describes the Page Segmentation competition (modus operandi, dataset and evaluation methodology) held in the context of ICDAR2009 and presents the results of the evaluation of four submitted methods. Two state-of-the art methods are also compared as well as the three methods from the ICDA2007 Page Segmentation competition. The results indicate that although methods continue to mature, there is still a considerable need to develop robust methods that deal with everyday documents."
            },
            "slug": "ICDAR-2009-Page-Segmentation-Competition-Antonacopoulos-Pletschacher",
            "title": {
                "fragments": [],
                "text": "ICDAR 2009 Page Segmentation Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results indicate that although methods continue to mature, there is still a considerable need to develop robust methods that deal with everyday documents."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "Ferili et al. [47] replace the logical AND of RLSA by an OR."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "They benchmark their algorithm on 10000 envelopes and it outperforms RLSA and X-Y cut while providing a significant speedup."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "One of the first document image segmentation algorithms appeared in 1982 with the Run-Length Smoothing Algorithm (RLSA) [2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "15\nOne of the first document image segmentation algorithms appeared in 1982 with the Run-Length Smoothing Algorithm (RLSA) [2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Once they have obtained the class layers, they\ncreate regions by combining RLSA and white space analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "The algorithms that use filtering techniques to make the document regions appear\n[42\u201348]: They usually rely on RLSA, mathematical morphology or other filters."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15921038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abca302c74d2f5adfd323a28e26d40b019df2b5",
            "isKey": true,
            "numCitedBy": 594,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included."
            },
            "slug": "Document-Analysis-System-Wong-Casey",
            "title": {
                "fragments": [],
                "text": "Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing, are outlined and several critical functions have been investigated and the technical approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060306"
                        ],
                        "name": "I. Konya",
                        "slug": "I.-Konya",
                        "structuredName": {
                            "firstName": "Iuliu",
                            "lastName": "Konya",
                            "middleNames": [
                                "Vasile"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Konya"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "[42] Any No BW Yes No Regions Horizontal Straight 3742 2 1 [30] Any No BW Yes No Regions + text lines Horizontal Straight 185 2 2"
                    },
                    "intents": []
                }
            ],
            "corpusId": 45780713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9b3641b9d825d7032d3acdd1ac9942c6b90f8b8",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 293,
            "paperAbstract": {
                "fragments": [],
                "text": "A vast amount of digital document material is continuously being produced as part of major digitization efforts around the world. In this context, generic and efficient automatic solutions for document image understanding represent a stringent necessity. We propose a generic framework for document image understanding systems, usable for practically any document types available in digital form. Following the introduced workflow, we shift our attention to each of the following processing stages in turn: quality assurance, image enhancement, color reduction and binarization, skew and orientation detection, page segmentation and logical layout analysis. We review the state of the art in each area, identify current deficiencies, point out promising directions and give specific guidelines for future investigation. We address some of the identified issues by means of novel algorithmic solutions putting special focus on generality, computational efficiency and the exploitation of all available sources of information. More specifically, we introduce the following original methods: a fully automatic detection of color reference targets in digitized material, accurate foreground extraction from color historical documents, font enhancement for hot metal typesetted prints, a theoretically optimal solution for the document binarization problem from both computational complexityand threshold selection point of view, a layout-independent skew and orientation detection, a robust and versatile page segmentation method, a semi-automatic front page detection algorithm and a complete framework for article segmentation in periodical publications. The proposed methods are experimentally evaluated on large datasets consisting of real-life heterogeneous document scans. The obtained results show that a document understanding system combining these modules is able to robustly process a wide variety of documents with good overall accuracy."
            },
            "slug": "Adaptive-methods-for-robust-document-image-Konya",
            "title": {
                "fragments": [],
                "text": "Adaptive methods for robust document image unterstanding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a generic framework for document image understanding systems, usable for practically any document types available in digital form, and introduces the following original methods: a fully automatic detection of color reference targets in digitized material, accurate foreground extraction from color historical documents, font enhancement for hot metal typesetted prints."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[44] use Bloomberg\u2019s segmentation algorithm [118] which is based on mathematical morphology."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2551062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "680691b631baeecb70d31403fc6f9e2560e9f574",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Page segmentation into text and non-text elements is an essential preprocessing step before optical character recognition (OCR) operation. In case of poor segmentation, an OCR classification engine produces garbage characters due to the presence of non-text elements. This paper describes modifications to the text/non-text segmentation algorithm presented by Bloomberg,1 which is also available in his open-source Leptonica library.2The modifications result in significant improvements and achieved better segmentation accuracy than the original algorithm for UW-III, UNLV, ICDAR 2009 page segmentation competition test images and circuit diagram datasets."
            },
            "slug": "Improved-document-image-segmentation-algorithm-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Improved document image segmentation algorithm using multiresolution morphology"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Modifications to the text/non-text segmentation algorithm presented by Bloomberg are described which result in significant improvements and achieved better segmentation accuracy than the original algorithm for UW-III, UNLV, ICDAR 2009 page segmentation competition test images and circuit diagram datasets."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2764871"
                        ],
                        "name": "C. Clausner",
                        "slug": "C.-Clausner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Clausner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clausner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13273599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e137a9932a5cd732c3f03a353379a2fe1708a3b",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Large-scale digitisation of historical documents demands robust methods that cope with the presence of frequent distortions and noisy artefacts. This paper presents a hybrid text line segmentation method that uses a novel data structure and a rule base to combine the strengths of top-down and bottom-up approaches while minimising their weaknesses. The effectiveness of the proposed approach has been methodically evaluated in the context of large-scale digitisation using a standardised framework. Results on a diverse dataset show improved performance over top-down and bottom-up approaches as well as over a leading commercially available system."
            },
            "slug": "A-robust-hybrid-approach-for-text-line-segmentation-Clausner-Antonacopoulos",
            "title": {
                "fragments": [],
                "text": "A robust hybrid approach for text line segmentation in historical documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a hybrid text line segmentation method that uses a novel data structure and a rule base to combine the strengths of top-down and bottom-up approaches while minimising their weaknesses."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144858239"
                        ],
                        "name": "F. Cruz",
                        "slug": "F.-Cruz",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Cruz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cruz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045937"
                        ],
                        "name": "O. R. Terrades",
                        "slug": "O.-R.-Terrades",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Terrades",
                            "middleNames": [
                                "Ramos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. R. Terrades"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 93
                            }
                        ],
                        "text": "This improves slightly the state of the art on a large but not\nvery challenging data set.425\nCruz and Terrades [87] proposed a method based on Conditional Random Field (CRF) and location features similar to [29] (see section 5.3.2) but without any improvement over the state of the art."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Cruz and Terrades [87] proposed a method based on Conditional Random Field (CRF) and location features similar to [29] (see section 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 61
                            }
                        ],
                        "text": "Two algorithms make a probabilistic estimation of the layout [86, 87] but do not bring a significant improvement."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9017512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "486204f56d1ba9be67b04bd998752d7c6d0942da",
            "isKey": true,
            "numCitedBy": 9,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a method to perform layout analysis in structured documents. We proposed an EM-based algorithm to fit a set of Gaussian mixtures to the different regions according to the logical distribution along the page. After the convergence, we estimate the final shape of the regions according to the parameters computed for each component of the mixture. We evaluated our method in the task of record detection in a collection of historical structured documents and performed a comparison with other previous works in this task."
            },
            "slug": "EM-Based-Layout-Analysis-Method-for-Structured-Cruz-Terrades",
            "title": {
                "fragments": [],
                "text": "EM-Based Layout Analysis Method for Structured Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper proposed an EM-based algorithm to fit a set of Gaussian mixtures to the different regions according to the logical distribution along the page and evaluated its method in the task of record detection in a collection of historical structured documents."
            },
            "venue": {
                "fragments": [],
                "text": "2014 22nd International Conference on Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3148753"
                        ],
                        "name": "Elodie Carel",
                        "slug": "Elodie-Carel",
                        "structuredName": {
                            "firstName": "Elodie",
                            "lastName": "Carel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elodie Carel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690398"
                        ],
                        "name": "J. Burie",
                        "slug": "J.-Burie",
                        "structuredName": {
                            "firstName": "Jean-Christophe",
                            "lastName": "Burie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747906"
                        ],
                        "name": "V. Courboulay",
                        "slug": "V.-Courboulay",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Courboulay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Courboulay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695766"
                        ],
                        "name": "J. Ogier",
                        "slug": "J.-Ogier",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Ogier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401920887"
                        ],
                        "name": "V. P. d'Andecy",
                        "slug": "V.-P.-d'Andecy",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "d'Andecy",
                            "middleNames": [
                                "Poulain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. P. d'Andecy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30590868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4689420bd1f2d9b65fe035e130d668145955eff",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Administrative document images are usually processed in black and white what generates many problems due to the errors related to the binarization. Besides all semantic information provided by the color is lost. Document images have a rich and highly variable content. The presence of false colors and artefacts introduced by the scanning and the compression alter the segmentation of the regions. Problems arise when there is no correspondence between the point clouds which are detected in a color space and the real regions of an image. In order to help the segmentation, we propose the extraction of the main colors of an image as a set of binary layers. Due to the industrial context, our approach has to run unsupervised on a generic dataset of color administrative documents. The originality of this approach is the use of a multiresolution analysis to detect the number of colors automatically. At a low resolution, a set of local regions is obtained thanks to a SLIC-based approach which takes into account the structure of documents and which combines both colorimetric information and spatial information. Then, a merging stage is applied on each resolution separately based on the colors which have been extracted at a lower resolution. This contribution can both feed the traditional process and exploit colorimetric information."
            },
            "slug": "Multiresolution-approach-based-on-adaptive-for-into-Carel-Burie",
            "title": {
                "fragments": [],
                "text": "Multiresolution approach based on adaptive superpixels for administrative documents segmentation into color layers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes the extraction of the main colors of an image as a set of binary layers to help the segmentation and can both feed the traditional process and exploit colorimetric information."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054949003"
                        ],
                        "name": "Ritu Garg",
                        "slug": "Ritu-Garg",
                        "structuredName": {
                            "firstName": "Ritu",
                            "lastName": "Garg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ritu Garg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6620636"
                        ],
                        "name": "Ehtesham Hassan",
                        "slug": "Ehtesham-Hassan",
                        "structuredName": {
                            "firstName": "Ehtesham",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ehtesham Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144725842"
                        ],
                        "name": "S. Chaudhury",
                        "slug": "S.-Chaudhury",
                        "structuredName": {
                            "firstName": "Santanu",
                            "lastName": "Chaudhury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chaudhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153794844"
                        ],
                        "name": "M. Gopal",
                        "slug": "M.-Gopal",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Gopal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gopal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14907037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eacc07a7377fc8b6fa9ca4f4791ba9a4766aa95e",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel framework for segmentation of documents with complex layouts. The document segmentation is performed by combination of clustering and conditional random fields (CRF) based modeling. The bottom-up approach for segmentation assigns each pixel to a cluster plane based on color intensity. A CRF based discriminative model is learned to extract the local neighborhood information in different cluster/color planes. The final category assignment is done by a top-level CRF based on the semantic correlation learned across clusters. The proposed framework has been extensively tested on multi-colored document images with text overlapping graphics/image."
            },
            "slug": "A-CRF-Based-Scheme-for-Overlapping-Multi-colored-Garg-Hassan",
            "title": {
                "fragments": [],
                "text": "A CRF Based Scheme for Overlapping Multi-colored Text Graphics Separation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel framework for segmentation of documents with complex layouts performed by combination of clustering and conditional random fields (CRF) based modeling and has been extensively tested on multi-colored document images with text overlapping graphics/image."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1519030223"
                        ],
                        "name": "Yen-Lin Chen",
                        "slug": "Yen-Lin-Chen",
                        "structuredName": {
                            "firstName": "Yen-Lin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yen-Lin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15221777"
                        ],
                        "name": "Bing-fei Wu",
                        "slug": "Bing-fei-Wu",
                        "structuredName": {
                            "firstName": "Bing-fei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing-fei Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "The most outstanding one is that of Chen and Wu [54]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 503,
                                "start": 499
                            }
                        ],
                        "text": "Algorithm Input layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [72] Any Yes Color Yes No Text lines Horizontal Straight 448 1 2 [104] Any Yes Color Yes Yes Regions Any Curved 87 1 2 [110] Any Yes Color Yes Yes Regions Any Curved 16 2 1 [51] Any Yes Color No No Regions Any Curved 2000 2 2 [74] Any Yes Color No No Text lines Any Curved 50 1 1 [84] Any Yes Color No Yes Text lines Any Straight 21 2 1 [54] Any Yes Gray Yes No Regions Horizontal Straight 65 2 1 [112] Any Yes BW Yes Yes Regions Horizontal Straight 1000 3 6 [89] Any No Color Yes Yes Regions Any Curved 100 1 1 Continued on next page"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6077167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "535b533507563f57daa64cecead16b67f5b1b272",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-multi-plane-approach-for-text-segmentation-of-Chen-Wu",
            "title": {
                "fragments": [],
                "text": "A multi-plane approach for text segmentation of complex document images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144322499"
                        ],
                        "name": "D. Bridson",
                        "slug": "D.-Bridson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bridson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bridson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206776573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bec9abb1b4fd21f986c68866cd6a511c404ace9a",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "There is an established need for objective evaluation of layout analysis methods, in realistic circumstances. This paper describes the page segmentation competition (modus operandi, dataset and evaluation criteria) held in the context of ICDAR2005 and presents the results of the evaluation of four candidate methods. The main objective of the competition was to compare the performance of such methods using scanned documents from commonly-occurring publications. The results indicate that although methods seem to be maturing, there is still a considerable need to develop robust methods that deal with everyday documents."
            },
            "slug": "ICDAR2005-page-segmentation-competition-Antonacopoulos-Bridson",
            "title": {
                "fragments": [],
                "text": "ICDAR2005 page segmentation competition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results of the page segmentation competition held in the context of ICDAR2005 indicate that although methods seem to be maturing, there is still a considerable need to develop robust methods that deal with everyday documents."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3342880"
                        ],
                        "name": "J. V. Beusekom",
                        "slug": "J.-V.-Beusekom",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Beusekom",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Beusekom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027911"
                        ],
                        "name": "Daniel Keysers",
                        "slug": "Daniel-Keysers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keysers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Keysers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8135544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a3860eb11894cdb64f9868697152db51a2f0589",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric layout analysis plays an important role in document image understanding. Many algorithms known in literature work well on standard document images, achieving high text line segmentation accuracy on the UW-III dataset. These algorithms rely on certain assumptions about document layouts, and fail when their underlying assumptions are not met. Also, they do not provide confidence scores for their output. These two problems limit the usefulness of general purpose layout analysis methods in large scale applications. In this contribution, we propose a statistically motivated model-based trainable layout analysis system that allows assumption-free adaptation to different layout types and produces likelihood estimates of the correctness of the computed page segmentation. The performance of our approach is tested on a subset of the Google 1000 books dataset where it achieved a text line segmentation accuracy of 98.4% on layouts where other general-purpose algorithms failed to do a correct segmentation."
            },
            "slug": "Background-variability-modeling-for-statistical-Shafait-Beusekom",
            "title": {
                "fragments": [],
                "text": "Background variability modeling for statistical layout analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a statistically motivated model-based trainable layout analysis system that allows assumption-free adaptation to different layout types and produces likelihood estimates of the correctness of the computed page segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "2008 19th International Conference on Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3185334"
                        ],
                        "name": "A. Namboodiri",
                        "slug": "A.-Namboodiri",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Namboodiri",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Namboodiri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "If needed [6, 7] provide a very good introduction to them."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 82
                            }
                        ],
                        "text": "Document image segmentation algorithms are typically classified into three groups [5, 6]: top-down, bottom-up and hybrid algorithms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 58712706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42b2bc874b1b080cde919c2d9220f32a0023ac66",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A document image is composed of a variety of physical entities or regions such as text blocks, lines, words, figures, tables, and background. We could also assign functional or logical labels such as sentences, titles, captions, author names, and addresses to some of these regions. The process of document structure and layout analysis tries to decompose a given document image into its component regions and understand their functional roles and relationships. The processing is carried out in multiple steps, such as preprocessing, page decomposition, structure understanding, etc. We will look into each of these steps in detail in the following sections. Document images are often generated from physical documents by digitization using scanners or digital cameras. Many documents, such as newspapers, magazines and brochures, contain very complex layout due to the placement of figures, titles, and captions, complex backgrounds, artistic text formatting, etc. (see Figure 1). A human reader uses a variety of additional cues such as context, conventions and information about language/script, along with a complex reasoning process to decipher the contents of a document. Automatic analysis of an arbitrary document with complex layout is an extremely difficult task and is beyond the capabilities of the state-of-the-art document structure and layout analysis systems. This is interesting since documents are designed to be effective and clear to human interpretation unlike natural images."
            },
            "slug": "Document-Structure-and-Layout-Analysis-Namboodiri-Jain",
            "title": {
                "fragments": [],
                "text": "Document Structure and Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Automatic analysis of an arbitrary document with complex layout is an extremely difficult task and is beyond the capabilities of the state-of-the-art document structure and layout analysis systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684042"
                        ],
                        "name": "A. Clavelli",
                        "slug": "A.-Clavelli",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Clavelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Clavelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 152
                            }
                        ],
                        "text": "They outperform the state of the art on 448 challenging documents from magazine inside\npages to advertisements with text overlapping natural images.360\nClavelli and Karatzas [74] segment propaganda posters that have nearly uniform colors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Clavelli and Karatzas [74] segment propaganda posters that have nearly uniform colors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 392,
                                "start": 388
                            }
                        ],
                        "text": "Algorithm Input layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [72] Any Yes Color Yes No Text lines Horizontal Straight 448 1 2 [104] Any Yes Color Yes Yes Regions Any Curved 87 1 2 [110] Any Yes Color Yes Yes Regions Any Curved 16 2 1 [51] Any Yes Color No No Regions Any Curved 2000 2 2 [74] Any Yes Color No No Text lines Any Curved 50 1 1 [84] Any Yes Color No Yes Text lines Any Straight 21 2 1 [54] Any Yes Gray Yes No Regions Horizontal Straight 65 2 1 [112] Any Yes BW Yes Yes Regions Horizontal Straight 1000 3 6 [89] Any No Color Yes Yes Regions Any Curved 100 1 1 Continued on next page"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6623513,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "17438352afcac63e8ff48227b44dd4fd8b434d0c",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The extraction of textual content from colour documents of a graphical nature is a complicated task. The text can be rendered in any colour, size and orientation while the existence of complex background graphics with repetitive patterns can make its localization and segmentation extremely difficult. Here, we propose a new method for extracting textual content from such colour images that makes no assumption as to the size of the characters, their orientation or colour, while it is tolerant to characters that do not follow a straight baseline. We evaluate this method on a collection of documents with historical connotations: the Posters from the Spanish Civil War."
            },
            "slug": "Text-Segmentation-in-Colour-Posters-from-the-Civil-Clavelli-Karatzas",
            "title": {
                "fragments": [],
                "text": "Text Segmentation in Colour Posters from the Spanish Civil War Era"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A new method for extracting textual content from colour images that makes no assumption as to the size of the characters, their orientation or colour, while it is tolerant to characters that do not follow a straight baseline is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705780"
                        ],
                        "name": "M. Casey",
                        "slug": "M.-Casey",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Casey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Casey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2484576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e44d795bf5ff083dfc8795aa913167615edcf712",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The research goal of highly versatile document analysis systems, capable of performing useful functions on the great majority of document images, seems to be receding, even in the face of decades of research. One family of nearly universally applicable capabilities includes document image content extraction tools able to locate regions containing handwriting, machine-print text, graphics, line-art, logos, photographs, noise, etc. To solve this problem in its full generality requires coping with a vast diversity of document and image types. The severity of the methodological problems is suggested by the lack of agreement within the R&D community on even what is meant by a representative set of samples in this context. Even when this is agreed, it is often not clear how sufficiently large sets for training and testing can be collected and ground truthed. Perhaps this can be alleviated by discovering a principled way to amplify sample sets using synthetic variations. We will then need classification methodologies capable of learning automatically from these huge sample sets in spite of their poorly parameterized\u2014or unparameterizable\u2014distributions. Perhaps fast expected-time approximate k-nearest neighbors classifiers are a good solution, even if they tend to require enormous data structures: hashed k-d trees seem promising. We discuss these issues and report recent progress towards their resolution. \n \nKeyword: versatile document analysis systems, DAS methodology, document image content extraction, classification, k Nearest Neighbors, k-d trees, CART, spatial data structures, computational geometry, hashing"
            },
            "slug": "Towards-Versatile-Document-Analysis-Systems-Baird-Casey",
            "title": {
                "fragments": [],
                "text": "Towards Versatile Document Analysis Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Questions about how sufficiently large sets for training and testing can be collected and ground truthed, and how classification methodologies capable of learning automatically from these huge sample sets in spite of their poorly parameterized\u2014or unparameterizable\u2014distributions are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "It was followed in 1992 by the X-Y cut algorithm [3]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2530196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62a53caea5213ea177298d7b2aff292b1386c37a",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Gobbledoc, a system providing remote access to stored documents, which is based on syntactic document analysis and optical character recognition (OCR), is discussed. In Gobbledoc, image processing, document analysis, and OCR operations take place in batch mode when the documents are acquired. The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described. The process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools is also described. Syntactic analysis is used in Gobbledoc to divide each page into labeled rectangular blocks. Blocks labeled text are converted by OCR to obtain a secondary (ASCII) document representation. Since such symbolic files are better suited for computerized search than for human access to the document content and because too many visual layout clues are lost in the OCR process (including some special characters), Gobbledoc preserves the original block images for human browsing. Storage, networking, and display issues specific to document images are also discussed.<<ETX>>"
            },
            "slug": "A-prototype-document-image-analysis-system-for-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "A prototype document image analysis system for technical journals"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described, and the process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32179591"
                        ],
                        "name": "Philippine Barlas",
                        "slug": "Philippine-Barlas",
                        "structuredName": {
                            "firstName": "Philippine",
                            "lastName": "Barlas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philippine Barlas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143680806"
                        ],
                        "name": "S\u00e9bastien Adam",
                        "slug": "S\u00e9bastien-Adam",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712446"
                        ],
                        "name": "Cl\u00e9ment Chatelain",
                        "slug": "Cl\u00e9ment-Chatelain",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Chatelain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cl\u00e9ment Chatelain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690399"
                        ],
                        "name": "T. Paquet",
                        "slug": "T.-Paquet",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Paquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Paquet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[112] which can segment an extremely diverse and complex range of documents in several languages."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 564,
                                "start": 559
                            }
                        ],
                        "text": "Algorithm Input layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [72] Any Yes Color Yes No Text lines Horizontal Straight 448 1 2 [104] Any Yes Color Yes Yes Regions Any Curved 87 1 2 [110] Any Yes Color Yes Yes Regions Any Curved 16 2 1 [51] Any Yes Color No No Regions Any Curved 2000 2 2 [74] Any Yes Color No No Text lines Any Curved 50 1 1 [84] Any Yes Color No Yes Text lines Any Straight 21 2 1 [54] Any Yes Gray Yes No Regions Horizontal Straight 65 2 1 [112] Any Yes BW Yes Yes Regions Horizontal Straight 1000 3 6 [89] Any No Color Yes Yes Regions Any Curved 100 1 1 Continued on next page"
                    },
                    "intents": []
                }
            ],
            "corpusId": 22740431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e9ef730add7c34c0baac9249c4360b73c19bc4c",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a Document Image Analysis (DIA) system able to extract homogeneous typed and handwritten text regions from complex layout documents of various types. The method is based on two connected component classification stages that successively discriminate text/non text and typed/handwritten shapes, followed by an original block segmentation method based on white rectangles detection. We present the results obtained by the system during the first competition round of the MAURDOR campaign."
            },
            "slug": "A-Typed-and-Handwritten-Text-Block-Segmentation-for-Barlas-Adam",
            "title": {
                "fragments": [],
                "text": "A Typed and Handwritten Text Block Segmentation System for Heterogeneous and Complex Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A Document Image Analysis system able to extract homogeneous typed and handwritten text regions from complex layout documents of various types based on two connected component classification stages that successively discriminate text/non text and typed/handwritten shapes."
            },
            "venue": {
                "fragments": [],
                "text": "2014 11th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715229"
                        ],
                        "name": "Markus Diem",
                        "slug": "Markus-Diem",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Diem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Diem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729636"
                        ],
                        "name": "Florian Kleber",
                        "slug": "Florian-Kleber",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Kleber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florian Kleber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706090"
                        ],
                        "name": "R. Sablatnig",
                        "slug": "R.-Sablatnig",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sablatnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sablatnig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5934826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64ddbafca4730e327fe01a41d2483c0bfdbde096",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Text line detection is a pre-processing step for automated document analysis such as word spotting or OCR. It is additionally used for document structure analysis or layout analysis. Considering mixed layouts, degraded documents and handwritten documents, text line detection is still challenging. We present a novel approach that targets torn documents having varying layouts and writing. The proposed method is a bottom up approach that fuses words, to globally minimize their fusing distance. In order to improve processing time and further layout analysis, text lines are represented by oriented rectangles. Even though, the method was designed for modern handwritten and printed documents, tests on medieval manuscripts give promising results. Additionally, the text line detection was evaluated on the ICDAR 2009 and ICFHR 2010 Handwriting Segmentation Contest datasets."
            },
            "slug": "Text-Line-Detection-for-Heterogeneous-Documents-Diem-Kleber",
            "title": {
                "fragments": [],
                "text": "Text Line Detection for Heterogeneous Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed method is a bottom up approach that fuses words, to globally minimize their fusing distance and in order to improve processing time and further layout analysis, text lines are represented by oriented rectangles."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746772"
                        ],
                        "name": "G. Louloudis",
                        "slug": "G.-Louloudis",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Louloudis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Louloudis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759370"
                        ],
                        "name": "C. Halatsis",
                        "slug": "C.-Halatsis",
                        "structuredName": {
                            "firstName": "Constantin",
                            "lastName": "Halatsis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Halatsis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 124
                            }
                        ],
                        "text": "Segmentation based on straight line identification algorithms Three contributions are based on straight line identification [27, 49, 50]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[27] split the connected components horizontally into blocks based on the av280"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "The algorithms that try to identify straight lines [27, 49, 50]: This can be done"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1013,
                                "start": 1009
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 14196680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b96cb182b012a1687c653213b1bf82c0c6a8b4aa",
            "isKey": true,
            "numCitedBy": 249,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-line-and-word-segmentation-of-handwritten-Louloudis-Gatos",
            "title": {
                "fragments": [],
                "text": "Text line and word segmentation of handwritten documents"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996385488"
                        ],
                        "name": "Liuan Wang",
                        "slug": "Liuan-Wang",
                        "structuredName": {
                            "firstName": "Liuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153224842"
                        ],
                        "name": "Wei-liang Fan",
                        "slug": "Wei-liang-Fan",
                        "structuredName": {
                            "firstName": "Wei-liang",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-liang Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144291081"
                        ],
                        "name": "Jun Sun",
                        "slug": "Jun-Sun",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753831"
                        ],
                        "name": "S. Naoi",
                        "slug": "S.-Naoi",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Naoi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Naoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102777647"
                        ],
                        "name": "Tanaka Hiroshi",
                        "slug": "Tanaka-Hiroshi",
                        "structuredName": {
                            "firstName": "Tanaka",
                            "lastName": "Hiroshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanaka Hiroshi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 311,
                                "start": 306
                            }
                        ],
                        "text": "Table 1 \u2013 continued from previous page AlgorithmInput layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [109] Any No Color Yes Yes Regions Any Curved 49 3 2 [106] Any No Color Yes Yes Regions Any Curved 49 3 2 [114] Any No Color No Yes Text lines Any Curved 214 3 3 [116] Any No Color No Yes Text lines Horizontal Straight 1072 3 6 [100] Any No Gray Yes Yes Regions Any Curved 86 3 1 [102] Any No Gray Yes Yes Regions + text lines Any Curved 501 1 2"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[114] propose another algorithm for extracting text lines from complex documents with multi-oriented text in several languages."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23696620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa7ff41401eadaa1527c46f21e94b8ccafb4642a",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Text line extraction in document images is an important prerequisite for many content based image understanding applications. In this paper, we propose an accurate and robust method for generic text line extraction, which can be applied on large categories of document images, diverse languages, and text lines with different orientations. Firstly, the candidate connected components are extracted from document image using Maximal Stable Extremal Region (MSER) with the noises filtered by Adaboost and Convolution Neural Network (CNN). Then, the coarse text lines are generated from hierarchical edges reconstruction and cut by local linearity of text lines in the document spanning tree. Finally, for accurate text line extraction, the cut multi-components are re-connected based on text line energy minimization in terms of text line consistency and the fitting error. Experimental results on multilingual test dataset demonstrate the effectiveness and robust of the proposed method, which yields higher performance compared with state-of-the-art methods."
            },
            "slug": "Text-line-extraction-in-document-images-Wang-Fan",
            "title": {
                "fragments": [],
                "text": "Text line extraction in document images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper proposes an accurate and robust method for generic text line extraction, which can be applied on large categories of document images, diverse languages, and text lines with different orientations, and yields higher performance compared with state of the art methods."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308281"
                        ],
                        "name": "D. Bloomberg",
                        "slug": "D.-Bloomberg",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Bloomberg",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bloomberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 44
                            }
                        ],
                        "text": "[44] use Bloomberg\u2019s segmentation algorithm [118] which is based on mathematical morphology."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62269638,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "df7124a46d9eb276e6e653763fd7762949753f6e",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An image-based approach to document image analysis is presented. The methods are motivated by a merged view of shape and textural image properties at multiple scales. The principal binary image operations are morphological and multiresolution. The generalized opening is introduced for extraction of both shape and texture from an image. Threshold reduction operations are introduced for performing efficient and controllable shape and texture transformations between resolution levels. Some problems, such as halftone or dark area segmentation, can be in large part solved by a sequence of threshold reductions. Aspects of the approach are illustrated by the problem of identifying italic and bold words in text, using word-level extraction at lowered resolution. The computational costs of the basic operations are given, so that algorithm efficienc y can be estimated, and the importance of operating at the lowest feasable resolution is demonstrated. For example, word segmentation and halftone extraction proceed in excess of 1.5x10 image pixels/second on a Sun Sparcstation2 ."
            },
            "slug": "Multiresolution-Morphological-Approach-to-Document-Bloomberg",
            "title": {
                "fragments": [],
                "text": "Multiresolution Morphological Approach to Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An image-based approach to document image analysis is presented, motivated by a merged view of shape and textural image properties at multiple scales, and the computational costs of the basic operations are given, so that algorithm efficiencies can be estimated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801704"
                        ],
                        "name": "D. M. Oliveira",
                        "slug": "D.-M.-Oliveira",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Oliveira",
                            "middleNames": [
                                "Marques",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Oliveira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736950"
                        ],
                        "name": "R. Lins",
                        "slug": "R.-Lins",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Lins",
                            "middleNames": [
                                "Dueire"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791211"
                        ],
                        "name": "Gabriel Torre\u00e3o",
                        "slug": "Gabriel-Torre\u00e3o",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Torre\u00e3o",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriel Torre\u00e3o"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962939"
                        ],
                        "name": "Jian Fan",
                        "slug": "Jian-Fan",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797452"
                        ],
                        "name": "M. Thielo",
                        "slug": "M.-Thielo",
                        "structuredName": {
                            "firstName": "Marcelo",
                            "lastName": "Thielo",
                            "middleNames": [
                                "Resende"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Thielo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[67] improve their parallel line regression algorithm [66] by creating queues of horizontal and vertical neighbors of every connected component."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 953,
                                "start": 949
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 38337447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7af2ebbe2f8d29449e08aef9fd0ce3d9f6c8aed",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Warped text-lines often appear whenever one performs the digitalization of bound documents using flatbed scanners or digital cameras. Compensating such distortion is an important pre-processing step in document transcription via OCR, for instance. This paper presents an efficient algorithm for text-line segmentation for document images. A typographic study and parameter tuning are done yielding into high values for precision, recall and f-measure metrics. The method presented outperforms the competing algorithms using a public available dataset."
            },
            "slug": "An-Efficient-Algorithm-for-Segmenting-Warped-in-Oliveira-Lins",
            "title": {
                "fragments": [],
                "text": "An Efficient Algorithm for Segmenting Warped Text-Lines in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The method presented outperforms the competing algorithms using a public available dataset and yields high values for precision, recall and f-measure metrics."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708890"
                        ],
                        "name": "M. Baechler",
                        "slug": "M.-Baechler",
                        "structuredName": {
                            "firstName": "Micheal",
                            "lastName": "Baechler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baechler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33247622,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2406baedbacc20ba47bcdb3ce1d4fe88fce2e0de",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel text line extraction method for historical documents. The method works in two steps. In the first step, layout analysis is performed to recognize the physical structure of a given document using a classification technique, more precisely the pixels of a coloured document image are classified into five classes: text-block, core-text-line, decoration, background, and periphery. This layout recognition is achieved by a cascade of two Dynamic Multilayer Perceptron (DMLP) classifiers and works without binarisation. In the second step, an algorithm takes the layout recognition results as an input, extracts the text lines, and groups them into blocks using the connected components approach. Finally, the algorithm refines the boundaries of the text lines using the binary image and the layout recognition results. Our system is evaluated on three historical manuscripts with a test set of 49 pages. The best obtained hit rate for text lines is 96.3%."
            },
            "slug": "Text-Line-Extraction-Using-DMLP-Classifiers-for-Baechler-Liwicki",
            "title": {
                "fragments": [],
                "text": "Text Line Extraction Using DMLP Classifiers for Historical Manuscripts"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper proposes a novel text line extraction method for historical documents that takes the layout recognition results as an input, extracts the text lines, and groups them into blocks using the connected components approach."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697354"
                        ],
                        "name": "A. Garz",
                        "slug": "A.-Garz",
                        "structuredName": {
                            "firstName": "Angelika",
                            "lastName": "Garz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Garz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706090"
                        ],
                        "name": "R. Sablatnig",
                        "slug": "R.-Sablatnig",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sablatnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sablatnig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715229"
                        ],
                        "name": "Markus Diem",
                        "slug": "Markus-Diem",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Diem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Diem"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19147582,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "cb8a97802709a289ec1920d255e22d9e2f26d9ee",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a layout analysis method for historical manuscripts that relies on the part-based identification of layout entities. A layout entity -- such as letters of the text, initials or headings -- is composed of a set of characteristic segments or structures, which is dissimilar for distinct classes in the manuscripts under consideration. This fact is exploited in order to segment a manuscript page into homogeneous regions. Historical documents traditionally involve challenges such as uneven writing support and varying shapes of characters, fluctuating text lines, changing scripts and writing styles, and variance in the layout itself. Hence, a part-based detection of layout entities is proposed using a multi-stage algorithm for the localization of the entities, based on interest points. Results show that the proposed method is able to locate initials, headings and text areas in ancient manuscripts containing stains, tears and partially faded-out ink sufficiently well."
            },
            "slug": "Layout-Analysis-for-Historical-Manuscripts-Using-Garz-Sablatnig",
            "title": {
                "fragments": [],
                "text": "Layout Analysis for Historical Manuscripts Using Sift Features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results show that the proposed method is able to locate initials, headings and text areas in ancient manuscripts containing stains, tears and partially faded-out ink sufficiently well."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153819461"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820427"
                        ],
                        "name": "Fei Yin",
                        "slug": "Fei-Yin",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2685887,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dc56bfc594e9bc8e2e6a30b769daf71eac667b0a",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Page segmentation is still a challenging problem due to the large variety of document layouts. Methods examining both foreground and background regions are among the most effective to solve this problem. However, their performance is influenced by the implementation of two key steps: the extraction and selection of background regions, and the grouping of background regions into separators. This paper proposes an efficient hybrid method for page segmentation. The method extracts white space rectangles based on connected component analysis, and filters white space rectangles progressively incorporating foreground and background information such that the remaining rectangles are likely to form column separators. Experimental results on the ICDAR2009 page segmentation competition test set demonstrate the effectiveness and superiority of the proposed method."
            },
            "slug": "Hybrid-Page-Segmentation-with-Efficient-Whitespace-Chen-Yin",
            "title": {
                "fragments": [],
                "text": "Hybrid Page Segmentation with Efficient Whitespace Rectangles Extraction and Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An efficient hybrid method for page segmentation that extracts white space rectangles based on connected component analysis, and filters white space Rectangles progressively incorporating foreground and background information such that the remaining rectangles are likely to form column separators is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153819461"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109393868"
                        ],
                        "name": "Hao Wei",
                        "slug": "Hao-Wei",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722800"
                        ],
                        "name": "J. Hennebert",
                        "slug": "J.-Hennebert",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Hennebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 25082992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f04e041e82ebd8faf3a560a417d1059c67bfb31",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a novel text line segmentation method for historical manuscript images. We use a pyramidal approach where at the first level, pixels are classified into: text, background, decoration, and out of page, at the second level, text regions are split into text line and non text line. Color and texture features based on Local Binary Patterns and Gabor Dominant Orientation are used for classification. By applying a modified Fast Correlation-Based Filter feature selection algorithm, redundant and irrelevant features are removed. Finally, the text line segmentation results are refined by a smoothing post-processing procedure. Unlike other projection profile or connected components methods, the proposed algorithm does not use any script-specific knowledge and is applicable to color images. The proposed algorithm is evaluated on three historical manuscript image datasets of diverse nature and achieved an average precision of 91% and recall of 84%. Experiments also show that the proposed algorithm is robust with respect to changes of the writing style, page layout, and noise on the image."
            },
            "slug": "Robust-Text-Line-Segmentation-for-Historical-Images-Chen-Wei",
            "title": {
                "fragments": [],
                "text": "Robust Text Line Segmentation for Historical Manuscript Images Using Color and Texture"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A novel text line segmentation method for historical manuscript images that does not use any script-specific knowledge and is applicable to color images by applying a modified Fast Correlation-Based Filter feature selection algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "2014 22nd International Conference on Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12195028"
                        ],
                        "name": "V. Le",
                        "slug": "V.-Le",
                        "structuredName": {
                            "firstName": "Viet",
                            "lastName": "Le",
                            "middleNames": [
                                "Phuong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170742"
                        ],
                        "name": "Nibal Nayef",
                        "slug": "Nibal-Nayef",
                        "structuredName": {
                            "firstName": "Nibal",
                            "lastName": "Nayef",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nibal Nayef"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698969"
                        ],
                        "name": "M. Visani",
                        "slug": "M.-Visani",
                        "structuredName": {
                            "firstName": "Muriel",
                            "lastName": "Visani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Visani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695766"
                        ],
                        "name": "J. Ogier",
                        "slug": "J.-Ogier",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Ogier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2045917"
                        ],
                        "name": "D. Tran",
                        "slug": "D.-Tran",
                        "structuredName": {
                            "firstName": "De",
                            "lastName": "Tran",
                            "middleNames": [
                                "Cao"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19307603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99032c30c6609889391da4b023096594a0c11ca9",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image segmentation is crucial to OCR and other digitization processes. In this paper, we present a learning-based approach for text and non-text separation in document images. The training features are extracted at the level of connected components, a mid-level between the slow noise-sensitive pixel level, and the segmentation-dependent zone level. Given all types, shapes and sizes of connected components, we extract a powerful set of features based on size, shape, stroke width and position of each connected component. Adaboosting with Decision trees is used for labeling connected components. Finally, the classification of connected components into text and non-text is corrected based on classification probabilities and size as well as stroke width analysis of the nearest neighbors of a connected component. The performance of our approach has been evaluated on the two standard datasets: UW-III and ICDAR-2009 competition for document layout analysis. Our results demonstrate that the proposed approach achieves competitive performance for segmenting text and non-text in document images of variable content and degradation."
            },
            "slug": "Text-and-non-text-segmentation-based-on-connected-Le-Nayef",
            "title": {
                "fragments": [],
                "text": "Text and non-text segmentation based on connected component features"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper presents a learning-based approach for text and non-text separation in document images by extracting a powerful set of features based on size, shape, stroke width and position of each connected component."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7486545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "070018de05c0b154e8fede2e680c20f40c2c94ab",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of curled textlines from warped document images is one of the major issues in document image dewarping. Most of the curled textlines segmentation algorithms present in the literature today are sensitive to the degree of curl, direction of curl, and spacing between adjacent lines. We present a new algorithm for curled textline segmentation which is robust to above mentioned problems at the expense of high execution time. We will demonstrate this insensitivity in a performance evaluation section. Our approach is based on the state-of-the-art image segmentation technique: Active Contour Model (Snake) with the novel idea of several baby snakes and their convergence in a vertical direction only. Experiment on publically available CBDAR 2007 document image dewarping contest dataset shows our text line segmentation algorithm accuracy of 97.96%."
            },
            "slug": "Segmentation-of-Curled-Textlines-Using-Active-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Segmentation of Curled Textlines Using Active Contours"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work presents a new algorithm for curled textline segmentation which is robust to above mentioned problems at the expense of high execution time and insensitivity, and will demonstrate this insensitivity in a performance evaluation section."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33225210"
                        ],
                        "name": "Aur\u00e9lie Lemaitre",
                        "slug": "Aur\u00e9lie-Lemaitre",
                        "structuredName": {
                            "firstName": "Aur\u00e9lie",
                            "lastName": "Lemaitre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lie Lemaitre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28491075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "189d4f85f8a1ccfe98dbb45e4874c4dc184dc070",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method to address the problem of handwritten text segmentation into text lines and words. Thus, we propose a method based on the cooperation among points of view that enables the localization of the text lines in a low resolution image, and then to associate the pixels at a higher level of resolution. Thanks to the combination of levels of vision, we can detect overlapping characters and re-segment the connected components during the analysis. Then, we propose a segmentation of lines into words based on the cooperation among digital data and symbolic knowledge. The digital data are obtained from distances inside a Delaunay graph, which gives a precise distance between connected components, at the pixel level. We introduce structural rules in order to take into account some generic knowledge about the organization of a text page. This cooperation among information gives a bigger power of expression and ensures the global coherence of the recognition. We validate this work using the metrics and the database proposed for the segmentation contest of ICDAR 2009. Thus, we show that our method obtains very interesting results, compared to the other methods of the literature. More precisely, we are able to deal with slope and curvature, overlapping text lines and varied kinds of writings, which are the main difficulties met by the other methods."
            },
            "slug": "A-perceptive-method-for-handwritten-text-Lemaitre-Camillerapp",
            "title": {
                "fragments": [],
                "text": "A perceptive method for handwritten text segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A method based on the cooperation among points of view that enables the localization of the text lines in a low resolution image, and then to associate the pixels at a higher level of resolution, which is able to deal with slope and curvature, overlapping text lines and varied kinds of writings."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70378391"
                        ],
                        "name": "Xiaojun Du",
                        "slug": "Xiaojun-Du",
                        "structuredName": {
                            "firstName": "Xiaojun",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaojun Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681758"
                        ],
                        "name": "Wumo Pan",
                        "slug": "Wumo-Pan",
                        "structuredName": {
                            "firstName": "Wumo",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wumo Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144957197"
                        ],
                        "name": "T. Bui",
                        "slug": "T.-Bui",
                        "structuredName": {
                            "firstName": "Tien",
                            "lastName": "Bui",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bui"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17401851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23a0a76a3bdd2df4c148ce0b38e422440d978d1e",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-line-segmentation-in-handwritten-documents-Du-Pan",
            "title": {
                "fragments": [],
                "text": "Text line segmentation in handwritten documents using Mumford-Shah model"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027911"
                        ],
                        "name": "Daniel Keysers",
                        "slug": "Daniel-Keysers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keysers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Keysers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8746521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41d424d8b63e1f2a94f348d897bc19a817257894",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Informative benchmarks are crucial for optimizing the page segmentation step of an OCR system, frequently the performance limiting step for overall OCR system performance. We show that current evaluation scores are insufficient for diagnosing specific errors in page segmentation and fail to identify some classes of serious segmentation errors altogether. This paper introduces a vectorial score that is sensitive to, and identifies, the most important classes of segmentation errors (over, under, and mis-segmentation) and what page components (lines, blocks, etc.) are affected. Unlike previous schemes, our evaluation method has a canonical representation of ground-truth data and guarantees pixel-accurate evaluation results for arbitrary region shapes. We present the results of evaluating widely used segmentation algorithms (x-y cut, smearing, whitespace analysis, constrained text-line finding, docstrum, and Voronoi) on the UW-III database and demonstrate that the new evaluation scheme permits the identification of several specific flaws in individual segmentation methods."
            },
            "slug": "Performance-Evaluation-and-Benchmarking-of-Six-Page-Shafait-Keysers",
            "title": {
                "fragments": [],
                "text": "Performance Evaluation and Benchmarking of Six-Page Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A vectorial score that is sensitive to, and identifies, the most important classes of segmentation errors (over, under, and mis-segmentation) and what page components (lines, blocks, etc.) are affected."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14935721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d28efab837a6eac6e3345d0efbb1c3599a68b52",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Text-line extraction is a key task in document analysis. Methods based on an isotropic Gaussian filtering and ridge detection have shown good results. This paper describes performance improvements to these technique based on the use of a convolution of isotropic Gaussian filter with line filters. These new filter banks are motivated by a matched filter approach to text-lines and, in addition, require fewer operations to compute. We evaluate the performance of the new filter bank in combination with ridge detection on the public DFKI-I (CBDAR 2007 dewarping contest) dataset, which contains camera captured document images and demonstrate improvements in performance to previous state-of-the-art techniques."
            },
            "slug": "Text-Line-Extraction-Using-a-Convolution-of-Filter-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Text-Line Extraction Using a Convolution of Isotropic Gaussian Filter with a Set of Line Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Performance improvements to these technique based on the use of a convolution of isotropic Gaussian filter with line filters are described, which are motivated by a matched filter approach to text-lines and, in addition, require fewer operations to compute."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918919"
                        ],
                        "name": "V. Papavassiliou",
                        "slug": "V.-Papavassiliou",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Papavassiliou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Papavassiliou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799540"
                        ],
                        "name": "Themos Stafylakis",
                        "slug": "Themos-Stafylakis",
                        "structuredName": {
                            "firstName": "Themos",
                            "lastName": "Stafylakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Themos Stafylakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684430"
                        ],
                        "name": "V. Katsouros",
                        "slug": "V.-Katsouros",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Katsouros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Katsouros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143978280"
                        ],
                        "name": "G. Carayannis",
                        "slug": "G.-Carayannis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Carayannis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Carayannis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13396787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f0806351685bd999699399ea9553c91733ccb7d",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Handwritten-document-image-segmentation-into-text-Papavassiliou-Stafylakis",
            "title": {
                "fragments": [],
                "text": "Handwritten document image segmentation into text lines and words"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40078651"
                        ],
                        "name": "Mudit Agrawal",
                        "slug": "Mudit-Agrawal",
                        "structuredName": {
                            "firstName": "Mudit",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mudit Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Then they made a fuzzy version of it (with fuzzy edges) called CVS [56]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 7551995,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20ff55b3034bfb0f02a029d5f5a67e20308b9a42",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a dynamic approach to document page segmentation based on inter-component relationships, local patterns and context features. State-of-the art page segmentation algorithms segment zones based on local properties of neighboring connected components such as distance and orientation, and do not typically consider additional properties other than size. Our proposed approach uses a contextually aware and dynamically adaptive page segmentation scheme. The page is first over-segmented using a dynamically adaptive scheme of separation features based on [2] and adapted from [13]. A decision to form zones is then based on the context built from these local separation features and high-level content features. Zone-based evaluation was performed on sets of printed and handwritten documents in English and Arabic scripts with multiple font types, sizes and we achieved an increase of 15% over the accuracy reported in [2]."
            },
            "slug": "Context-aware-and-content-based-dynamic-Voronoi-Agrawal-Doermann",
            "title": {
                "fragments": [],
                "text": "Context-aware and content-based dynamic Voronoi page segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A dynamic approach to document page segmentation based on inter-component relationships, local patterns and context features is presented and an increase of 15% over the accuracy reported in [2] is achieved."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40813600"
                        ],
                        "name": "P. Roy",
                        "slug": "P.-Roy",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Roy",
                            "middleNames": [
                                "Pratim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 357655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "706a360fbab104383ecd43c2f61ba846edf73511",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In graphical documents (e.g., maps, engineering drawings), artistic documents etc., the text lines are annotated in multiple orientations or curvilinear way to illustrate different locations or symbols. For the optical character recognition of such documents, individual text lines from the documents need to be extracted. In this paper, we propose a novel method to segment such text lines and the method is based on the foreground and background information of the text components. To effectively utilize the background information, a water reservoir concept is used here. In the proposed scheme, at first, individual components are detected and grouped into character clusters in a hierarchical way using size and positional information. Next, the clusters are extended in two extreme sides to determine potential candidate regions. Finally, with the help of these candidate regions, individual lines are extracted. The experimental results are presented on different datasets of graphical documents, camera-based warped documents, noisy images containing seals, etc. The results demonstrate that our approach is robust and invariant to size and orientation of the text lines present in the document."
            },
            "slug": "Text-line-extraction-in-graphical-documents-using-Roy-Pal",
            "title": {
                "fragments": [],
                "text": "Text line extraction in graphical documents using background and foreground information"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel method to segment such text lines and the method is based on the foreground and background information of the text components, using a water reservoir concept to effectively utilize the background information."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40241827"
                        ],
                        "name": "Li Liu",
                        "slug": "Li-Liu",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409858950"
                        ],
                        "name": "Yue Lu",
                        "slug": "Yue-Lu",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [32] they consider several segmentations of a given document."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 364,
                                "start": 360
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 38784705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f95f409984e7b06181860ca32e757ba41629365",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Near-duplicate-document-image-matching:-A-graphical-Liu-Lu",
            "title": {
                "fragments": [],
                "text": "Near-duplicate document image matching: A graphical perspective"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33225210"
                        ],
                        "name": "Aur\u00e9lie Lemaitre",
                        "slug": "Aur\u00e9lie-Lemaitre",
                        "structuredName": {
                            "firstName": "Aur\u00e9lie",
                            "lastName": "Lemaitre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lie Lemaitre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11163262,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "954f2dc75804eea1d7ca7739d4485cd5d5820cfa",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a system to extract the logical structure of handwritten mail documents. It consists in two joined tasks: the segmentation of documents into blocks and the labeling of such blocks. The main considered label classes are: addressee details, sender details, date, subject, text body, signature. This work has to face with difficulties of unconstrained handwritten documents: variable structure and writing. We propose a method based on a geometric analysis of the arrangement of elements in the document. We give a description of the document using a two-dimension grammatical formalism, which makes it possible to easily introduce knowledge on mail into a generic parser. Our grammatical parser is LL(k), which means several combinations are tried before extracting the good one. The main interest of this approach is that we can deal with low structured documents. Moreover, as the segmentation into blocks often depends on the associated classes, our method is able to retry a different segmentation until labeling succeeds. We validated this method in the context of the French national project RIMES, which proposed a contest on a large base of documents. We obtain a recognition rate of 91.7% on 1150 images."
            },
            "slug": "A-generic-method-for-structure-recognition-of-mail-Lemaitre-Camillerapp",
            "title": {
                "fragments": [],
                "text": "A generic method for structure recognition of handwritten mail documents"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper presents a system to extract the logical structure of handwritten mail documents using a two-dimension grammatical formalism, which makes it possible to easily introduce knowledge on mail into a generic parser."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820427"
                        ],
                        "name": "Fei Yin",
                        "slug": "Fei-Yin",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 61
                            }
                        ],
                        "text": "Two algorithms make a probabilistic estimation of the layout [86, 87] but do not bring a significant improvement."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Yin and Liu [86] perform an estimation of the number of text lines with a blur filter and then use a variational Bayes approach to segment the image rescaled at 75 dpi."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Liu and al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Liu et al. [63] use a Gaussian Mixture model to classify connected component triplets as text or non text."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Liu et al. made two contributions in the perspective of near-duplicate document\nimage matching."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Yin and Liu [70] use metric learning based on geometric features to compute the330\nminimum spanning tree between the connected components of the binary image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 828,
                                "start": 824
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 542343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbdb497398b866e491e4feb49883f488c8a06a60",
            "isKey": true,
            "numCitedBy": 21,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Text line segmentation in unconstrained handwritten documents remains a challenge because handwritten text lines are multi-skewed and not obviously separated. This paper presents a new approach based on the variational Bayes (VB) framework for text line segmentation. Viewing the document image as a mixture density model, with each text line approximated by a Gaussian component, the VB method can automatically determine the number of components. We extend the VB method such that it can both eliminate and split components and control the orientation of text line lines. Experiments on Chinese handwritten documents demonstrated the effectiveness of the approach."
            },
            "slug": "A-Variational-Bayes-Method-for-Handwritten-Text-Yin-Liu",
            "title": {
                "fragments": [],
                "text": "A Variational Bayes Method for Handwritten Text Line Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new approach based on the variational Bayes (VB) framework for text line segmentation in unconstrained handwritten documents that can both eliminate and split components and control the orientation of text line lines is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095276889"
                        ],
                        "name": "N. Borse",
                        "slug": "N.-Borse",
                        "structuredName": {
                            "firstName": "Nikita",
                            "lastName": "Borse",
                            "middleNames": [
                                "Vijay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Borse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4551081"
                        ],
                        "name": "I. Shaikh",
                        "slug": "I.-Shaikh",
                        "structuredName": {
                            "firstName": "Imran",
                            "lastName": "Shaikh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shaikh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[82] which also won the ICDAR 2013 Competition for handwriting 405"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1075,
                                "start": 1071
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6253771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc631acd2f5a687a879c9daf1b06525f6cdb156d",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Text-line extraction in handwritten documents is an important step for document image understanding, and a number of algorithms have been proposed to address this problem. In order to overcome this limitation, we develop text-line extraction algorithm for cursive handwriting. Our method is based on connected components (CCs), however, unlike conventional methods, we analysed strokes and partition under-segmented CCs into normalized ones. Due to this normalization, the proposed method is able to estimate the states of CCs for a range of different languages and writing styles."
            },
            "slug": "Language-Independent-Text-Line-Extraction-Algorithm-Borse-Shaikh",
            "title": {
                "fragments": [],
                "text": "Language Independent Text-Line Extraction Algorithm for Handwritten Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The proposed text-line extraction algorithm for cursive handwriting is based on connected components, however, unlike conventional methods, it analysed strokes and partition under-segmented CCs into normalized ones, allowing for a range of different languages and writing styles."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892336"
                        ],
                        "name": "Nazih Ouwayed",
                        "slug": "Nazih-Ouwayed",
                        "structuredName": {
                            "firstName": "Nazih",
                            "lastName": "Ouwayed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nazih Ouwayed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16432038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "742681f227e4b5c26ad73f3e42ca6be1dac9e3c3",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "The multi-orientation occurs frequently in ancient handwritten documents, where the writers try to update a document by adding some annotations in the margins. Due to the margin narrowness, this gives rise to lines in different directions and orientations. Document recognition needs to find the lines everywhere they are written whatever their orientation. This is why we propose in this paper a new approach allowing us to extract the multi-oriented lines in scanned documents. Because of the multi-orientation of lines and their dispersion in the page, we use an image meshing allowing us to progressively and locally determine the lines. Once the meshing is established, the orientation is determined using the Wigner\u2013Ville distribution on the projection histogram profile. This local orientation is then enlarged to limit the orientation in the neighborhood. Afterward, the text lines are extracted locally in each zone basing on the follow-up of the orientation lines and the proximity of connected components. Finally, the connected components that overlap and touch in adjacent lines are separated. The morphology analysis of the terminal letters of Arabic words is here considered. The proposed approach has been experimented on 100 documents reaching an accuracy of about 98.6%."
            },
            "slug": "A-general-approach-for-multi-oriented-text-line-of-Ouwayed-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "A general approach for multi-oriented text line extraction of handwritten documents"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a new approach allowing to extract the multi-oriented lines in scanned documents using an image meshing allowing to progressively and locally determine the lines."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2557608"
                        ],
                        "name": "Sui-Yu Wang",
                        "slug": "Sui-Yu-Wang",
                        "structuredName": {
                            "firstName": "Sui-Yu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sui-Yu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144692946"
                        ],
                        "name": "Chang An",
                        "slug": "Chang-An",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "An",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang An"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[104] make a very interesting contribution by finding a way to automatically discover features to improve the performance of a 2-nearest neighbor classifier."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 227
                            }
                        ],
                        "text": "Algorithm Input layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [72] Any Yes Color Yes No Text lines Horizontal Straight 448 1 2 [104] Any Yes Color Yes Yes Regions Any Curved 87 1 2 [110] Any Yes Color Yes Yes Regions Any Curved 16 2 1 [51] Any Yes Color No No Regions Any Curved 2000 2 2 [74] Any Yes Color No No Text lines Any Curved 50 1 1 [84] Any Yes Color No Yes Text lines Any Straight 21 2 1 [54] Any Yes Gray Yes No Regions Horizontal Straight 65 2 1 [112] Any Yes BW Yes Yes Regions Horizontal Straight 1000 3 6 [89] Any No Color Yes Yes Regions Any Curved 100 1 1 Continued on next page"
                    },
                    "intents": []
                }
            ],
            "corpusId": 11055999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c2d97653b408f59505de9b1da5b9d6877cfeb8e",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We report an automatic feature discovery method that achieves results comparable to a manually chosen, larger feature set on a document image content extraction problem: the location and segmentation of regions containing handwriting and machine-printed text in documents images. This approach is a greedy forward selection algorithm that iteratively constructs one linear feature at a time. The algorithm finds error clusters in the current feature space, then projects one tight cluster into the null space of the feature mapping, where a new feature that helps to classify these errors can be discovered. We conducted experiments on 87 diverse test images. Four manually chosen linear features with an error rate of 16.2% were given to the algorithm; the algorithm then found an additional ten features; the composite 14 features achieve an error rate of 13.8%. This outperforms a feature set of size 14 chosen by Principal Component Analysis (PCA) with an error rate of 15.4%. It also nearly matches the error rate of 13.6% achieved by twice as many manually chosen features. Thus our algorithm appears to compete with both the widely used PCA method and tedious and expensive trial-and-error manual exploration."
            },
            "slug": "Document-Content-Extraction-Using-Automatically-Wang-Baird",
            "title": {
                "fragments": [],
                "text": "Document Content Extraction Using Automatically Discovered Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "An automatic feature discovery method that achieves results comparable to a manually chosen, larger feature set on a document image content extraction problem: the location and segmentation of regions containing handwriting and machine-printed text in documents images."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "Many other algorithms have been presented since then and surveys have been done in 2000 [4] and in 2003 [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 82
                            }
                        ],
                        "text": "Document image segmentation algorithms are typically classified into three groups [5, 6]: top-down, bottom-up and hybrid algorithms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6128200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "633fd1e2bd089c2c402244037876e879861d6739",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Document structure analysis can be regarded as a syntactic analysis problem. The order and containment relations among the physical or logical components of a document page can be described by an ordered tree structure and can be modeled by a tree grammar which describes the page at the component level in terms of regions or blocks. This paper provides a detailed survey of past work on document structure analysis algorithms and summarize the limitations of past approaches. In particular, we survey past work on document physical layout representations and algorithms, document logical structure representations and algorithms, and performance evaluation of document structure analysis algorithms. In the last section, we summarize this work and point out its limitations."
            },
            "slug": "Document-structure-analysis-algorithms:-a-survey-Mao-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Document structure analysis algorithms: a literature survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper provides a detailed survey of past work on document structure analysis algorithms and summarize the limitations of past approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153819461"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2700495"
                        ],
                        "name": "Mathias Seuret",
                        "slug": "Mathias-Seuret",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "Seuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathias Seuret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722800"
                        ],
                        "name": "J. Hennebert",
                        "slug": "J.-Hennebert",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Hennebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 200
                            }
                        ],
                        "text": "Table 1 \u2013 continued from previous page AlgorithmInput layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [109] Any No Color Yes Yes Regions Any Curved 49 3 2 [106] Any No Color Yes Yes Regions Any Curved 49 3 2 [114] Any No Color No Yes Text lines Any Curved 214 3 3 [116] Any No Color No Yes Text lines Horizontal Straight 1072 3 6 [100] Any No Gray Yes Yes Regions Any Curved 86 3 1 [102] Any No Gray Yes Yes Regions + text lines Any Curved 501 1 2"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[109] use convolutional autoencoders (a kind of neural network) to automatically discover distinctive features 510"
                    },
                    "intents": []
                }
            ],
            "corpusId": 9814021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b90411acf9a597f139651133d42bffce3df78044",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an unsupervised feature learning method for page segmentation of historical handwritten documents available as color images. We consider page segmentation as a pixel labeling problem, i.e., each pixel is classified as either periphery, background, text block, or decoration. Traditional methods in this area rely on carefully hand-crafted features or large amounts of prior knowledge. In contrast, we apply convolutional autoencoders to learn features directly from pixel intensity values. Then, using these features to train an SVM, we achieve high quality segmentation without any assumption of specific topologies and shapes. Experiments on three public datasets demonstrate the effectiveness and superiority of the proposed approach."
            },
            "slug": "Page-segmentation-of-historical-document-images-Chen-Seuret",
            "title": {
                "fragments": [],
                "text": "Page segmentation of historical document images with convolutional autoencoders"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper considers page segmentation as a pixel labeling problem, i.e., each pixel is classified as either periphery, background, text block, or decoration, and applies convolutional autoencoders to learn features directly from pixel intensity values."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153745355"
                        ],
                        "name": "Andreas Fischer",
                        "slug": "Andreas-Fischer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708890"
                        ],
                        "name": "M. Baechler",
                        "slug": "M.-Baechler",
                        "structuredName": {
                            "firstName": "Micheal",
                            "lastName": "Baechler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baechler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697354"
                        ],
                        "name": "A. Garz",
                        "slug": "A.-Garz",
                        "structuredName": {
                            "firstName": "Angelika",
                            "lastName": "Garz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Garz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26484429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b38f2fb8f00399439748e7225d9caeca6d672c72",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Automated reading of historical handwriting is needed to search and browse ancient manuscripts in digital libraries based on their textual content. In this paper, we present a combined system for text localization and transcription in page images. It includes flexible learning-based methods for layout analysis and handwriting recognition, which were developed in the context of the Swiss research project HisDoc. A comprehensive experimental evaluation is provided for the medieval Parzival database, demonstrating a promising word recognition accuracy of 93.0% with closed vocabulary. In order to harmonize the evaluation of the two document analysis tasks, we introduce a novel evaluation measure for text line extraction that takes substitution, deletion, as well as insertion errors into account."
            },
            "slug": "A-Combined-System-for-Text-Line-Extraction-and-in-Fischer-Baechler",
            "title": {
                "fragments": [],
                "text": "A Combined System for Text Line Extraction and Handwriting Recognition in Historical Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A combined system for text localization and transcription in page images is presented that includes flexible learning-based methods for layout analysis and handwriting recognition, which were developed in the context of the Swiss research project HisDoc."
            },
            "venue": {
                "fragments": [],
                "text": "2014 11th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2104187182"
                        ],
                        "name": "Vincent Malleron",
                        "slug": "Vincent-Malleron",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Malleron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Malleron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721326"
                        ],
                        "name": "V. Eglin",
                        "slug": "V.-Eglin",
                        "structuredName": {
                            "firstName": "V\u00e9ronique",
                            "lastName": "Eglin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eglin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093671870"
                        ],
                        "name": "St\u00e9phanie Dord-Crousl\u00e9",
                        "slug": "St\u00e9phanie-Dord-Crousl\u00e9",
                        "structuredName": {
                            "firstName": "St\u00e9phanie",
                            "lastName": "Dord-Crousl\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phanie Dord-Crousl\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796597"
                        ],
                        "name": "P. R\u00e9gnier",
                        "slug": "P.-R\u00e9gnier",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "R\u00e9gnier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R\u00e9gnier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 216050861,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d243ede4de1076ba659912b9abbbd775e04eae79",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a new approach to improve electronic editions of human science corpus, providing an efficient estimation of manuscripts pages structure. In any handwriting documents analysis process, the text line segmentation is an important stage. The presence of variable inter-line spaces, of inconstant base-line skews, overlapping and occlusions in unconstrained ancient 19th handwritten documents complexifies the text lines segmentation task. In this paper, we only use as prior knowledge of script the fact that text lines skews can be random and irregular.In that context, we model text line detection as an image segmentation problem by enhancing text line structure using Hough transform and a clustering of connected components so as to make text line boundaries appear. The proposed approach of snippets decomposition for page layout analysislies on a first step of content pages classification in five visual and genetic taxonomies, and a second step of text line extraction and snippets decomposition. Experiments show that the proposed method achieves high accuracy for detecting text lines in regular and semi-regular handwritten pages in the corpus of digitized Flaubert manuscripts (\u201dDossiers documentaires de Bouvard et P\u00e9cuchet\u201d, 1872-1880)."
            },
            "slug": "Text-Lines-and-Snippets-Extraction-for-19th-Century-Malleron-Eglin",
            "title": {
                "fragments": [],
                "text": "Text Lines and Snippets Extraction for 19th Century Handwriting Documents Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new approach to improve electronic editions of human science corpus, providing an efficient estimation of manuscripts pages structure by enhancing text line structure using Hough transform and a clustering of connected components so as to make text line boundaries appear."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915835"
                        ],
                        "name": "M. B. Jlaiel",
                        "slug": "M.-B.-Jlaiel",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Jlaiel",
                            "middleNames": [
                                "Ben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. B. Jlaiel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682986"
                        ],
                        "name": "R. Mullot",
                        "slug": "R.-Mullot",
                        "structuredName": {
                            "firstName": "R\u00e9my",
                            "lastName": "Mullot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mullot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144000830"
                        ],
                        "name": "A. Alimi",
                        "slug": "A.-Alimi",
                        "structuredName": {
                            "firstName": "Adel",
                            "lastName": "Alimi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Alimi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35217085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5713d11a1ec8c6e18bacad63c27d1c3dccd0b2b9",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an integrated system able to localize multi-oriented handwritten annotations in scanned documents. Unlike previous single methods which limit colors or types of annotations to be extracted, the proposed method attempts to extract annotations by fusing three feature extraction techniques based on internal and external shape analysis. Our method consists of two processes: 1) a coarse segmentation process which divides the scanned document into text and non-text regions. 2) A fine segmentation process which consists of three steps: a feature extraction process, a classification process and a majority voting process which identifies the segmented regions as machine-printed or handwritten annotations. We find that our adaptive method outperform all individual methods. Experimental results on a set of 301 annotated scanned documents are reported."
            },
            "slug": "Multi-oriented-Handwritten-Annotations-Extraction-Jlaiel-Mullot",
            "title": {
                "fragments": [],
                "text": "Multi-oriented Handwritten Annotations Extraction from Scanned Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "An integrated system able to localize multi-oriented handwritten annotations in scanned documents by fusing three feature extraction techniques based on internal and external shape analysis and finds that the adaptive method outperform all individual methods."
            },
            "venue": {
                "fragments": [],
                "text": "2014 11th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064863306"
                        ],
                        "name": "A. Sato",
                        "slug": "A.-Sato",
                        "structuredName": {
                            "firstName": "Akinori",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411993"
                        ],
                        "name": "M. Iwata",
                        "slug": "M.-Iwata",
                        "structuredName": {
                            "firstName": "Motoi",
                            "lastName": "Iwata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 61
                            }
                        ],
                        "text": "Agrawal and Doermann improved the original Voronoi algorithm [120] with Voronoi++ which adapts the Voronoi parameters to the local spatial context [55]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23399574,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "be80678c0eeedf754647a8b9adccd5d6d9be3e86",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0\u00b0~45\u00b0 as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "slug": "Segmentation-of-Page-Images-Using-the-Area-Voronoi-Kise-Sato",
            "title": {
                "fragments": [],
                "text": "Segmentation of Page Images Using the Area Voronoi Diagram"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is confirmed that the proposed method of page segmentation based on the approximated area Voronoi diagram is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145645182"
                        ],
                        "name": "N. Vincent",
                        "slug": "N.-Vincent",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12625121,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6737fb362f8b27d4bb0f2488e7fb786660f0fb11",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A page of a document is a set of small components which are grouped by a human reader into higher level components, such as lines and text blocs. Document image analysis is aimed at detecting these components in document images. We propose the encoding of local information by considering the properties that determine perceptual grouping. Each connected component is labelled according to the location of its nearest neighbour connected component. These labelled components constitute the input of a rule-based incremental process. Vertical and horizontal text lines are detected without prior assumption on their direction. Touching characters belonging to different lines are detected early and discarded from the grouping process to avoid line merging. The tolerance for grouping components increases in the course of the process until the final decision. After each step of the grouping process, conflict resolution rules are activated. This work was motivated by the automatic detection of Figure&Caption pairs in the documents of the historical collection of the BIUM digital library (Bibliotheque InterUniversitaire Medicale). The images that were used in this study belong to this collection."
            },
            "slug": "Simultaneous-detection-of-vertical-and-horizontal-Faure-Vincent",
            "title": {
                "fragments": [],
                "text": "Simultaneous detection of vertical and horizontal text lines based on perceptual organization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The encoding of local information is proposed by considering the properties that determine perceptual grouping by automatic detection of Figure&Caption pairs in the documents of the historical collection of the BIUM digital library (Bibliotheque InterUniversitaire Medicale)."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126187"
                        ],
                        "name": "Prateek Sarkar",
                        "slug": "Prateek-Sarkar",
                        "structuredName": {
                            "firstName": "Prateek",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prateek Sarkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763321"
                        ],
                        "name": "E. Saund",
                        "slug": "E.-Saund",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Saund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118746573"
                        ],
                        "name": "Jing Lin",
                        "slug": "Jing-Lin",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2045968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9de341009969a34507da143503b0d6bb06852716",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system that classifies pixels in a document image according to marking type such as machine print,handwriting, and noise. A segmenter module first splits an input image into fragments, sometimes breaking connected components. Each fragment is then classified by an automatically trained multi-stage classifier that is fast and considers features of the fragment, as well as its neighborhood.Features relevant for discrimination are picked out automatically from among hundreds of measurements. Our system is trainable from example images in which each foreground pixel has a \u201cground-truth\u201d label. The main distinction of our system is the level of accuracy achieved in classifying fragments at sub-connected component level, rather than larger aggregate groups such as words or text-lines.We have trained this system to detect handwriting, machine print text, machine print graphics, and noise."
            },
            "slug": "Classifying-Foreground-Pixels-in-Document-Images-Sarkar-Saund",
            "title": {
                "fragments": [],
                "text": "Classifying Foreground Pixels in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A system that classifies pixels in a document image according to marking type such as machine print, writing, and noise is presented, which is trainable from example images in which each foreground pixel has a \u201cground-truth\u201d label."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40474413"
                        ],
                        "name": "Michael Murdock",
                        "slug": "Michael-Murdock",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Murdock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Murdock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27437299"
                        ],
                        "name": "S. Reid",
                        "slug": "S.-Reid",
                        "structuredName": {
                            "firstName": "Shawn",
                            "lastName": "Reid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Reid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067534881"
                        ],
                        "name": "Blaine Hamilton",
                        "slug": "Blaine-Hamilton",
                        "structuredName": {
                            "firstName": "Blaine",
                            "lastName": "Hamilton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Blaine Hamilton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48163297"
                        ],
                        "name": "J. Reese",
                        "slug": "J.-Reese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Reese",
                            "middleNames": [
                                "Warren"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Reese"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "The A2iA1 in the text line segmentation competition [15] did not won it and it is similar to that of Moysset et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Projection profiles There are 7 algorithms of this type [37\u201341] and the two CASIA algorithms published in [15]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 30
                            }
                        ],
                        "text": "The neural network algorithms [15, 116] make use of artificial intelligence to automatically learn significant features and perform the required task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 73
                            }
                        ],
                        "text": "Segmentation based on neural networks Two algorithms use neural networks [15, 116]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "It was reused by A2iA in a competition [15] where it was ranked third out of 7 participants."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] is a very good addition as it comes from the industry and thus aims at addressing real case scenario issues."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "segmentation [121] and 2015 Competition on text line detection [15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19363314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfac7093dab0d9c444b0bb013fae1b9b0dd25b7c",
            "isKey": true,
            "numCitedBy": 27,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the ANDAR-TL competition (ANncestry Document Analysis and Recognition Text Lines) held at the 13th International Conference on Document Analysis and Recognition (ICDAR-2015). This competition uses the ANDAR-TL-1K dataset of 1300 images consisting of text-lines in paragraph form drawn from collections from the eighteenth and nineteenth century. These images are labeled with the coordinate location of the first character of the left-most word on each line (the origin point) and the objective of this competition is to use the training part of this dataset to develop and submit for evaluation a system that detects the locations of text-line origin points in the images from the validation set. Four teams submitted seven systems for scoring and evaluation. The results of this scoring are reported, along with brief descriptions of each system."
            },
            "slug": "ICDAR-2015-competition-on-text-line-detection-in-Murdock-Reid",
            "title": {
                "fragments": [],
                "text": "ICDAR 2015 competition on text line detection in historical documents"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The objective of this competition is to use the training part of this dataset to develop and submit for evaluation a system that detects the locations of text-line origin points in the images from the validation set."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3152399"
                        ],
                        "name": "Youbao Tang",
                        "slug": "Youbao-Tang",
                        "structuredName": {
                            "firstName": "Youbao",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Youbao Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47150160"
                        ],
                        "name": "Xiangqian Wu",
                        "slug": "Xiangqian-Wu",
                        "structuredName": {
                            "firstName": "Xiangqian",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangqian Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144830523"
                        ],
                        "name": "W. Bu",
                        "slug": "W.-Bu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Bu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6657237,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de4637ed2d973204c6d3f84bcf1acc9166127564",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel text line segmentation method based on matched filtering and top-down grouping for handwritten documents. The proposed method consists of three distinct steps. Firstly, the foreground pixel density (FPD) of handwritten document image (HDI) is estimated, then FPD is used to decide the size of the generated filter which is the convolution of a band-shape filter and an isotropic LoG filter. Secondly, the centers of the text lines (CTLs) are extracted by performing filtering, binarizing, thinning and top-down grouping operation on HDI. Finally, the overlapping connected-components (OCCs) which travel through multiple text lines are separated, and then all OCCs are assigned to a label of CTLs by the nearest neighbor principle. The proposed method is tested on two public databases, and the experimental results show that the proposed method outperforms the state-of-the-art text line segmentation approaches in both of these databases."
            },
            "slug": "Text-Line-Segmentation-Based-on-Matched-Filtering-Tang-Wu",
            "title": {
                "fragments": [],
                "text": "Text Line Segmentation Based on Matched Filtering and Top-Down Grouping for Handwritten Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed method is tested on two public databases, and the experimental results show that the proposed method outperforms the state-of-the-art text line segmentation approaches in both of these databases."
            },
            "venue": {
                "fragments": [],
                "text": "2014 11th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153476282"
                        ],
                        "name": "Christophe Rigaud",
                        "slug": "Christophe-Rigaud",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Rigaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Rigaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923932"
                        ],
                        "name": "Norbert Tsopz\u00e9",
                        "slug": "Norbert-Tsopz\u00e9",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Tsopz\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norbert Tsopz\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690398"
                        ],
                        "name": "J. Burie",
                        "slug": "J.-Burie",
                        "structuredName": {
                            "firstName": "Jean-Christophe",
                            "lastName": "Burie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695766"
                        ],
                        "name": "J. Ogier",
                        "slug": "J.-Ogier",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Ogier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 70
                            }
                        ],
                        "text": "A last addition could be documents similar to comics such as those in [50, 68] In section 2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 41510879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29953da60f470fc21dc484863e601bd5b4c6cb15",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Comic books constitute an important heritage in many countries. Nowadays, digitization allows to search directly from content instead of metadata only (e.g. album title or author name). Few studies have been done in this direction. Only frame and speech balloon extraction have been experimented in the case of simple page structure. In fact, the page structure depends on the author which is why many different structures and drawings exist. Despite the differences, drawings have a common characteristic because of design process: they are all surrounded by a black line. In this paper, we propose to rely on this particularity of comic books to automatically extract frame and text using a connected-component labeling analysis. The approach is compared with some existing methods found in the literature and results are presented."
            },
            "slug": "Robust-Frame-and-Text-Extraction-from-Comic-Books-Rigaud-Tsopz\u00e9",
            "title": {
                "fragments": [],
                "text": "Robust Frame and Text Extraction from Comic Books"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to rely on this particularity of comic books to automatically extract frame and text using a connected-component labeling analysis and compared with some existing methods found in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "Many other algorithms have been presented since then and surveys have been done in 2000 [4] and in 2003 [5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 620082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce3b569e18670f6c10e61aa9a8bda7c30fd37411",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "slug": "Twenty-Years-of-Document-Image-Analysis-in-PAMI-Nagy",
            "title": {
                "fragments": [],
                "text": "Twenty Years of Document Image Analysis in PAMI"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216188"
                        ],
                        "name": "Xiaolu Shen",
                        "slug": "Xiaolu-Shen",
                        "structuredName": {
                            "firstName": "Xiaolu",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaolu Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107903806"
                        ],
                        "name": "Changsong Liu",
                        "slug": "Changsong-Liu",
                        "structuredName": {
                            "firstName": "Changsong",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changsong Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145507765"
                        ],
                        "name": "X. Ding",
                        "slug": "X.-Ding",
                        "structuredName": {
                            "firstName": "Xiaoqing",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Ding"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[84] use both intra and interline metrics to build a segmentation cost function."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 446,
                                "start": 442
                            }
                        ],
                        "text": "Algorithm Input layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [72] Any Yes Color Yes No Text lines Horizontal Straight 448 1 2 [104] Any Yes Color Yes Yes Regions Any Curved 87 1 2 [110] Any Yes Color Yes Yes Regions Any Curved 16 2 1 [51] Any Yes Color No No Regions Any Curved 2000 2 2 [74] Any Yes Color No No Text lines Any Curved 50 1 1 [84] Any Yes Color No Yes Text lines Any Straight 21 2 1 [54] Any Yes Gray Yes No Regions Horizontal Straight 65 2 1 [112] Any Yes BW Yes Yes Regions Horizontal Straight 1000 3 6 [89] Any No Color Yes Yes Regions Any Curved 100 1 1 Continued on next page"
                    },
                    "intents": []
                }
            ],
            "corpusId": 21645784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cafae464cdea0c3647f1acc7c59566f2b1b25435",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses to text line extraction in free style document, such as business card, envelope, poster, etc. In free style document, global property such as character size, line direction can hardly be concluded, which reveals a grave limitation in traditional layout analysis. 'Line' is the most prominent and the highest structure in our bottom-up method. First, we apply a novel intensity function found on gradient information to locate text areas where gradient within a window have large magnitude and various directions, and split such areas into text pieces. We build a probability model of lines consist of text pieces via statistics on training data. For an input image, we group text pieces to lines using a simulated annealing algorithm with cost function based on the probability model."
            },
            "slug": "Text-line-extraction-in-free-style-document-Shen-Liu",
            "title": {
                "fragments": [],
                "text": "Text line extraction in free style document"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper addresses to text line extraction in free style document, such as business card, envelope, poster, etc, using a novel intensity function found on gradient information to locate text areas where gradient within a window have large magnitude and various directions."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801759"
                        ],
                        "name": "B. Lamiroy",
                        "slug": "B.-Lamiroy",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Lamiroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lamiroy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113205330"
                        ],
                        "name": "Tao Sun",
                        "slug": "Tao-Sun",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15038542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4dc8d25e43ac8a0ef2cb7e15df63195bd274dc3",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This contest aims to provide a metric giving indications on the influence of individual document analysis stages to overall end-to-end applications. Contestants are provided with a full, working pipeline which operates on a page image to extract useful information. The pipeline is built with clearly identified analysis stages (e.g. binarization, skew detection, layout analysis, OCR) that have a formalized input and output. Contestants are invited to contribute their own algorithms as an alternative to one or more of the initially provided stages. The evaluation measures the overall impact of the contributed algorithm on the final (end-of-pipeline) output."
            },
            "slug": "Document-Analysis-Algorithm-Contributions-in-Report-Lamiroy-Lopresti",
            "title": {
                "fragments": [],
                "text": "Document Analysis Algorithm Contributions in End-to-End Applications: Report on the ICDAR 2011 Contest"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This contest aims to provide a metric giving indications on the influence of individual document analysis stages to overall end-to-end applications."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801704"
                        ],
                        "name": "D. M. Oliveira",
                        "slug": "D.-M.-Oliveira",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Oliveira",
                            "middleNames": [
                                "Marques",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Oliveira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736950"
                        ],
                        "name": "R. Lins",
                        "slug": "R.-Lins",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Lins",
                            "middleNames": [
                                "Dueire"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791211"
                        ],
                        "name": "Gabriel Torre\u00e3o",
                        "slug": "Gabriel-Torre\u00e3o",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Torre\u00e3o",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriel Torre\u00e3o"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962939"
                        ],
                        "name": "Jian Fan",
                        "slug": "Jian-Fan",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797452"
                        ],
                        "name": "M. Thielo",
                        "slug": "M.-Thielo",
                        "structuredName": {
                            "firstName": "Marcelo",
                            "lastName": "Thielo",
                            "middleNames": [
                                "Resende"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Thielo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "[67] improve their parallel line regression algorithm [66] by creating queues of horizontal and vertical neighbors of every connected component."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15250343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcc82090e863e749ed54e2c6b2c30d9810fdb725",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Bound documents either scanned or captured with digital cameras often present a geometrical warp that makes text-lines curled. The identification of text-lines is one of the steps for document de-warping when only a single image is available. This paper presents a new method for text-line segmentation. It is based on a simple, but effective, skew detector proposed by Avila-Lins and simplifies the idea of coupled snakes introduced by Bukhari to a moving parallel line regression. The proposed method performed better than the best of the similar algorithms in the literature."
            },
            "slug": "A-New-Method-for-Text-Line-Segmentation-for-Warped-Oliveira-Lins",
            "title": {
                "fragments": [],
                "text": "A New Method for Text-Line Segmentation for Warped Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new method for text-line segmentation is presented based on a simple, but effective, skew detector proposed by Avila-Lins and simplifies the idea of coupled snakes introduced by Bukhari to a moving parallel line regression."
            },
            "venue": {
                "fragments": [],
                "text": "ICIAR"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33225210"
                        ],
                        "name": "Aur\u00e9lie Lemaitre",
                        "slug": "Aur\u00e9lie-Lemaitre",
                        "structuredName": {
                            "firstName": "Aur\u00e9lie",
                            "lastName": "Lemaitre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lie Lemaitre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 414,
                                "start": 410
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2076489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a47b70a9de4822c6dd01bd9e2f9775c2026b74f6",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows the interest of imitating the perceptive vision to improve the recognition of the structure of ancient, noisy and low structured documents. The perceptive vision, that is used by human eye, consists in focusing attention on interesting elements after having detecting their presence in a global vision process. We propose a generic method in order to apply this concept to various problems and kinds of documents. Thus, we introduce the concept of cooperation between multiresolution visions into a generic method. The originality of this work is that the cooperation between resolutions is totally led by the knowledge dedicated to each kind of document. In this paper, we present this method on three kinds of documents: handwritten low structured mail documents, naturalization decree register that are archive noisy documents from the 19th century and Bangla script that requires a precise vision. This work is validated on 86,291 documents."
            },
            "slug": "Multiresolution-cooperation-makes-easier-document-Lemaitre-Camillerapp",
            "title": {
                "fragments": [],
                "text": "Multiresolution cooperation makes easier document structure recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The concept of cooperation between multiresolution visions into a generic method is introduced and the originality of this work is that the cooperation between resolutions is totally led by the knowledge dedicated to each kind of document."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069634816"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145714522"
                        ],
                        "name": "Le Kang",
                        "slug": "Le-Kang",
                        "structuredName": {
                            "firstName": "Le",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Le Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404588675"
                        ],
                        "name": "W. Abd-Almageed",
                        "slug": "W.-Abd-Almageed",
                        "structuredName": {
                            "firstName": "Wael",
                            "lastName": "Abd-Almageed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Abd-Almageed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9763623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f5d6c1ae268505b84a1860c5af6522e5d57332",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an approach to text line extraction in handwritten document images which combines local and global techniques. We propose a graph-based technique to detect touching and proximity errors that are common with handwritten text lines. In a refinement step, we use Expectation-Maximization (EM) to iteratively split the error segments to obtain correct text-lines. We show improvement in accuracies using our correction method on datasets of Arabic document images. Results on a set of artificially generated proximity images show that the method is effective for handling touching errors in handwritten document images."
            },
            "slug": "Segmentation-of-Handwritten-Textlines-in-Presence-Kumar-Kang",
            "title": {
                "fragments": [],
                "text": "Segmentation of Handwritten Textlines in Presence of Touching Components"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An approach to text line extraction in handwritten document images which combines local and global techniques and uses Expectation-Maximization to iteratively split the error segments to obtain correct text-lines is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109393868"
                        ],
                        "name": "Hao Wei",
                        "slug": "Hao-Wei",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708890"
                        ],
                        "name": "M. Baechler",
                        "slug": "M.-Baechler",
                        "structuredName": {
                            "firstName": "Micheal",
                            "lastName": "Baechler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baechler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691805"
                        ],
                        "name": "Fouad Slimane",
                        "slug": "Fouad-Slimane",
                        "structuredName": {
                            "firstName": "Fouad",
                            "lastName": "Slimane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fouad Slimane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28832351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9050b13a07f94430631a7729652c6ad873789d0b",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a comparison between three classifiers based on Support Vector Machines, Multi-Layer Perceptrons and Gaussian Mixture Models respectively to detect physical structure of historical documents. Each classifier segments a scaled image of historical document into four classes, i.e., areas of periphery, background, text and decoration. We evaluate them on three data sets of historical documents. Depending on data sets, the best classification rates obtained vary from 90.35% to 97.47%."
            },
            "slug": "Evaluation-of-SVM,-MLP-and-GMM-Classifiers-for-of-Wei-Baechler",
            "title": {
                "fragments": [],
                "text": "Evaluation of SVM, MLP and GMM Classifiers for Layout Analysis of Historical Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a comparison between three classifiers based on Support Vector Machines, Multi-Layer Perceptrons and Gaussian Mixture Models respectively to detect physical structure of historical documents."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2463454"
                        ],
                        "name": "H. Koo",
                        "slug": "H.-Koo",
                        "structuredName": {
                            "firstName": "Hyung",
                            "lastName": "Koo",
                            "middleNames": [
                                "Il"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Koo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707645"
                        ],
                        "name": "N. Cho",
                        "slug": "N.-Cho",
                        "structuredName": {
                            "firstName": "Nam",
                            "lastName": "Cho",
                            "middleNames": [
                                "Ik"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7041863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50a97bdaaa6bf897c7490e7d61cc97e7145429e",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new approach to the estimation of document states such as interline spacing and text line orientation, which facilitates a number of tasks in document image processing. The proposed method can be applied to spatially varying states as well as invariant ones, so that general cases including images of complex layout, cameracaptured images, and handwritten ones can also be handled. Specifically, we find CCs (Connected Components) in a document image and assign a state to each of them. Then the states of CCs are estimated using an energy minimization framework, where the cost function is designed based on frequency domain analysis and minimized via graph-cuts. Using the estimated states, we also develop a new algorithm that performs text block identification and text line extraction. Roughly speaking, we can segment an image into text blocks by cutting the distant connections among the CCs (compared to the estimated interline spacing), and we can group the CCs into text lines using a bottom-up grouping along the estimated text line orientation. Experimental results on a variety of document images show that our method is efficient and provides promising results in several document image processing tasks."
            },
            "slug": "State-Estimation-in-a-Document-Image-and-Its-in-and-Koo-Cho",
            "title": {
                "fragments": [],
                "text": "State Estimation in a Document Image and Its Application in Text Block Identification and Text Line Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed method can be applied to spatially varying states as well as invariant ones, so that general cases including images of complex layout, cameracaptured images, and handwritten ones can also be handled."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15926594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db00cb120355dc5d72025452178b9b181e9ab257",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwritten document images contain textlines with multi orientations, touching and overlapping characters within consecutive textlines, and small inter-line spacing making textline segmentation a difficult task. In this paper we propose a novel, script-independent textline segmentation approach for handwritten documents, which is robust against above mentioned problems. We model textline extraction as a general image segmentation task. We compute the central line of parts of textlines using ridges over the smoothed image. Then we adapt the state-of-the-art active contours (snakes) over ridges, which results in textline segmentation. Unlike the ``Level Set'' and \"Mumford-Shah model'' based handwritten textline segmentation methods, our method use matched filter bank approach for smoothing and does not require heuristic post processing steps for merging or splitting segmented textlines. Experimental results prove the effectiveness of the proposed algorithm. We evaluated our algorithm on ICDAR 2007 handwritten segmentation contest dataset and obtained an accuracy of 96.3%."
            },
            "slug": "Script-Independent-Handwritten-Textlines-Using-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Script-Independent Handwritten Textlines Segmentation Using Active Contours"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel, script-independent textline segmentation approach for handwritten documents, which is robust against above mentioned problems, and uses matched filter bank approach for smoothing and does not require heuristic post processing steps for merging or splitting segmented textlines."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130389360"
                        ],
                        "name": "Minwoo Kim",
                        "slug": "Minwoo-Kim",
                        "structuredName": {
                            "firstName": "Minwoo",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minwoo Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40563148"
                        ],
                        "name": "Il-Seok Oh",
                        "slug": "Il-Seok-Oh",
                        "structuredName": {
                            "firstName": "Il-Seok",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Il-Seok Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10428753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2860181da01534aea1cd41c77c5d7e60ae49930",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a model-based text line segmentation algorithm for machine-printed document images. The model is based on geometric configuration which uses the interline spaces rather than the text lines. The paper proposes an objective function whose maximization leads to the optimal solution. The proposed interline space model provides the primary advantage of script-free nature. Additionally the model is versatile due to its abilities of processing both horizontally and vertically written documents and inferring the semantic of reading order. The experiments performed with various document images in Latin, Korean, Chinese, and Japanese scripts have proven the aforementioned advantages and have shown the noise tolerance."
            },
            "slug": "Script-Free-Text-Line-Segmentation-Using-Interline-Kim-Oh",
            "title": {
                "fragments": [],
                "text": "Script-Free Text Line Segmentation Using Interline Space Model for Printed Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This paper proposes a model-based text line segmentation algorithm for machine-printed document images based on geometric configuration which uses the interline spaces rather than the text lines, which provides the primary advantage of script-free nature."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8249814"
                        ],
                        "name": "Xujun Peng",
                        "slug": "Xujun-Peng",
                        "structuredName": {
                            "firstName": "Xujun",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xujun Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800513"
                        ],
                        "name": "S. Setlur",
                        "slug": "S.-Setlur",
                        "structuredName": {
                            "firstName": "Srirangaraj",
                            "lastName": "Setlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Setlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841171"
                        ],
                        "name": "R. Sitaram",
                        "slug": "R.-Sitaram",
                        "structuredName": {
                            "firstName": "Ramachandrula",
                            "lastName": "Sitaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sitaram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979909"
                        ],
                        "name": "K. Bhuvanagiri",
                        "slug": "K.-Bhuvanagiri",
                        "structuredName": {
                            "firstName": "Kiran",
                            "lastName": "Bhuvanagiri",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bhuvanagiri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5180945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6582769b92c6f67f02ddfc72051247e72e446357",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an approach to segment handwritten text, machine printed text and noise from annotated machine printed documents. Three categories of word level features are extracted. We use a modified K-Means clustering algorithm for classification followed by a relabeling procedure using Markov Random Field(MRF) based on a concept of neighboring patches and Belief Propagation(BP)rules. Experimental results on an imbalanced data set show that our approach achieves an overall recall of 96.33% ."
            },
            "slug": "Markov-Random-Field-Based-Text-Identification-from-Peng-Setlur",
            "title": {
                "fragments": [],
                "text": "Markov Random Field Based Text Identification from Annotated Machine Printed Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An approach to segment handwritten text, machine printed text and noise from annotated machine printed documents using a modified K-Means clustering algorithm followed by a relabeling procedure using Markov Random Field based on a concept of neighboring patches and Belief Propagation rules."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13171577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc0f545bc2f50be5fe4aa63f363ff824d8bacd6c",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Text-lines extraction and their reading order determination is an important step in optical character recognition (OCR) systems. Research in OCR of Arabic script documents has primarily focused on character recognition and therefore most of researchers use primitive methods like projection profile analysis for text-line extraction. Although projection methods achieve good accuracy on clean, skew corrected documents, their performance drops under challenging situations (border noise, skew, complex layouts). This paper presents a robust layout analysis system for extracting text-lines in reading order from scanned Arabic script document images written in different languages (Arabic, Urdu, Persian) and styles (Naskh, Nastaliq). The presented system is based on a suitable combination of different well established techniques for analyzing Latin script documents that have proven to be robust against different types of document image degradations. Evaluation of the presented system on Arabic and Urdu document image datasets consisting of a variety of complex single- and multi-column layouts achieves high accuracies for text and non-text segmentation, text-line extraction, and reading order determination."
            },
            "slug": "High-Performance-Layout-Analysis-of-Arabic-and-Urdu-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "High Performance Layout Analysis of Arabic and Urdu Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Evaluation of the presented system on Arabic and Urdu document image datasets consisting of a variety of complex single- and multi-column layouts achieves high accuracies for text and non-text segmentation, text-line extraction, and reading order determination."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3344452"
                        ],
                        "name": "Bastien Moysset",
                        "slug": "Bastien-Moysset",
                        "structuredName": {
                            "firstName": "Bastien",
                            "lastName": "Moysset",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bastien Moysset"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156685"
                        ],
                        "name": "Christopher Kermorvant",
                        "slug": "Christopher-Kermorvant",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Kermorvant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Kermorvant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899680"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373952"
                        ],
                        "name": "J. Louradour",
                        "slug": "J.-Louradour",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00f4me",
                            "lastName": "Louradour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Louradour"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 73
                            }
                        ],
                        "text": "Segmentation based on neural networks Two algorithms use neural networks [15, 116]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 367,
                                "start": 362
                            }
                        ],
                        "text": "Table 1 \u2013 continued from previous page AlgorithmInput layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [109] Any No Color Yes Yes Regions Any Curved 49 3 2 [106] Any No Color Yes Yes Regions Any Curved 49 3 2 [114] Any No Color No Yes Text lines Any Curved 214 3 3 [116] Any No Color No Yes Text lines Horizontal Straight 1072 3 6 [100] Any No Gray Yes Yes Regions Any Curved 86 3 1 [102] Any No Gray Yes Yes Regions + text lines Any Curved 501 1 2"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 30
                            }
                        ],
                        "text": "The neural network algorithms [15, 116] make use of artificial intelligence to automatically learn significant features and perform the required task."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1889158,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e0f262441dc609e2ad26da1ef23c8504c92209f",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The detection of text lines, as a first processing step, is critical in all text recognition systems. State-of-the-art methods to locate lines of text are based on handcrafted heuristics fine-tuned by the image processing community's experience. They succeed under certain constraints; for instance the background has to be roughly uniform. We propose to use more \u201cagnostic\u201d Machine Learning-based approaches to address text line location. The main motivation is to be able to process either damaged documents, or flows of documents with a high variety of layouts and other characteristics. A new method is presented in this work, inspired by the latest generation of optical models used for text recognition, namely Recurrent Neural Networks. As these models are sequential, a column of text lines in our application plays here the same role as a line of characters in more traditional text recognition settings. A key advantage of the proposed method over other data-driven approaches is that compiling a training dataset does not require labeling line boundaries: only the number of lines are required for each paragraph. Experimental results show that our approach gives similar or better results than traditional handcrafted approaches, with little engineering efforts and less hyper-parameter tuning."
            },
            "slug": "Paragraph-text-segmentation-into-lines-with-Neural-Moysset-Kermorvant",
            "title": {
                "fragments": [],
                "text": "Paragraph text segmentation into lines with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method to use more \u201cagnostic\u201d Machine Learning-based approaches to address text line location, inspired by the latest generation of optical models used for text recognition, namely Recurrent Neural Networks."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8249814"
                        ],
                        "name": "Xujun Peng",
                        "slug": "Xujun-Peng",
                        "structuredName": {
                            "firstName": "Xujun",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xujun Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800513"
                        ],
                        "name": "S. Setlur",
                        "slug": "S.-Setlur",
                        "structuredName": {
                            "firstName": "Srirangaraj",
                            "lastName": "Setlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Setlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841171"
                        ],
                        "name": "R. Sitaram",
                        "slug": "R.-Sitaram",
                        "structuredName": {
                            "firstName": "Ramachandrula",
                            "lastName": "Sitaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sitaram"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41443816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "602e2ba40e632d29ad8ffcb54f307c99a9632130",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-a-boosted-tree-classifier-for-text-in-Peng-Setlur",
            "title": {
                "fragments": [],
                "text": "Using a boosted tree classifier for text segmentation in hand-annotated documents"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820427"
                        ],
                        "name": "Fei Yin",
                        "slug": "Fei-Yin",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Yin and Liu [86] perform an estimation of the number of text lines with a blur filter and then use a variational Bayes approach to segment the image rescaled at 75 dpi."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Liu and al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Liu et al. [63] use a Gaussian Mixture model to classify connected component triplets as text or non text."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Yin and Liu [70] use metric learning based on geometric features to compute the 330"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Liu et al. made two contributions in the perspective of near-duplicate document\nimage matching."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Yin and Liu [70] use metric learning based on geometric features to compute the330\nminimum spanning tree between the connected components of the binary image."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4651364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "559d7f70d6bb0a5f81790b449e415d919acc2f28",
            "isKey": true,
            "numCitedBy": 151,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Handwritten-Chinese-text-line-segmentation-by-with-Yin-Liu",
            "title": {
                "fragments": [],
                "text": "Handwritten Chinese text line segmentation by clustering with distance metric learning"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725650"
                        ],
                        "name": "S. Ferilli",
                        "slug": "S.-Ferilli",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Ferilli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ferilli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704423"
                        ],
                        "name": "M. Biba",
                        "slug": "M.-Biba",
                        "structuredName": {
                            "firstName": "Marenglen",
                            "lastName": "Biba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Biba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700821"
                        ],
                        "name": "F. Esposito",
                        "slug": "F.-Esposito",
                        "structuredName": {
                            "firstName": "Floriana",
                            "lastName": "Esposito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Esposito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745663"
                        ],
                        "name": "T. Basile",
                        "slug": "T.-Basile",
                        "structuredName": {
                            "firstName": "Teresa",
                            "lastName": "Basile",
                            "middleNames": [
                                "Maria",
                                "Altomare"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Basile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[47] replace the logical AND of RLSA by an OR."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 10212356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65d46523fb8bbce0bc989e2d005c1e5e6d42737d",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Layout analysis is a fundamental step in automatic document processing. Many different techniques have been proposed to perform this task. Some follow a top-down approach: they start by identifying the high level components of the page structure and then recursively split them until basic blocks are found. On the other hand, bottom-up approaches start with the smallest elements (e.g., the pixels in case of digitized document) and then recursively merge them into higher level components. A first limitation of such methods is that most of them are designed to deal only with digitized documents and hence are not applicable to native digital documents which are nowadays pervasive. Furthermore, top-down and most of bottom-up methods are able to process Manhattan layout documents only. In this work, we propose a general bottom-up strategy to tackle the layout analysis of (possibly) non-Manhattan documents, and two specializations of it to handle both bitmap and PS/PDF sources. It was successfully embedded and tested in the DOMINUS document management system."
            },
            "slug": "A-Distance-Based-Technique-for-Non-Manhattan-Layout-Ferilli-Biba",
            "title": {
                "fragments": [],
                "text": "A Distance-Based Technique for Non-Manhattan Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A general bottom-up strategy to tackle the layout analysis of (possibly) non-Manhattan documents, and two specializations of it to handle both bitmap and PS/PDF sources are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 804476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0662f4d86d44b3094381b5e6c342598855fe3ac8",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "As compared to scanners, cameras offer fast, flexible and non-contact document imaging, but with distortions like uneven shading and warped shape. Therefore, camera-captured document images need preprocessing steps like binarization and textline detection for dewarping so that traditional document image processing steps can be applied on them. Previous approaches of binarization and curled textline detection are sensitive to distortions and loose some crucial image information during each step, which badly affects dewarping and further processing. Here we introduce a novel algorithm for curled textline region detection directly from a grayscale camera-captured document image, in which matched filter bank approach is used for enhancing textline structure and then ridges detection is applied for finding central line of curled textlines. The resulting ridges can be potentially used for binarization, dewarping or designing new techniques for camera-captured document image processing. Our approach is robust against bad shading and high degrees of curl. We have achieved around 91% detection accuracy on the dataset of CBDAR 2007 document image dewarping contest."
            },
            "slug": "Ridges-Based-Curled-Textline-Region-Detection-from-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Ridges Based Curled Textline Region Detection from Grayscale Camera-Captured Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel algorithm for curled textline region detection directly from a grayscale camera-captured document image, in which matched filter bank approach is used for enhancing textline structure and then ridges detection is applied for finding central line of curled textlines."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892336"
                        ],
                        "name": "Nazih Ouwayed",
                        "slug": "Nazih-Ouwayed",
                        "structuredName": {
                            "firstName": "Nazih",
                            "lastName": "Ouwayed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nazih Ouwayed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52805309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a394baa2dd7b7f225d45067e346557a0098d60a8",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel approach for the multi-oriented text line extraction from handwritten Arabic documents. After image pre-processing, the local orientations are determined in small windows obtained by image paving. The orientation of the text within each window is estimated using the projection profile technique considering several projection angles. Then, the windows which close angles are gathered into largest zones. We use the Wigner-Ville Distribution (WVD) to estimate the global orientation of each zone. The WVD is more precise than the classical projection profile technique. Afterwards, the text lines are extracted in each zone basing on the follow-up of the baselines and the proximity of connected components. The experimental results prove the efficiency of the proposed scheme. It has been evaluated on 50 documents reaching an accuracy of about 97.6%."
            },
            "slug": "Multi-oriented-Text-Line-Extraction-from-Arabic-Ouwayed-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "Multi-oriented Text Line Extraction from Handwritten Arabic Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A novel approach for the multi-oriented text line extraction from handwritten Arabic documents by using the Wigner-Ville Distribution (WVD) to estimate the global orientation of each zone."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2764871"
                        ],
                        "name": "C. Clausner",
                        "slug": "C.-Clausner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Clausner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clausner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070747525"
                        ],
                        "name": "C. Papadopoulos",
                        "slug": "C.-Papadopoulos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206777599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fbbd896dffc6577153454577114a9b0309c2fa7",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an objective comparative evaluation of page segmentation and region classification methods for documents with complex layouts. It describes the competition (modus operandi, dataset and evaluation methodology) held in the context of ICDAR2015, presenting the results of the evaluation of eight methods - four submitted, two state-of-the-art systems (one commercial and one open-source) and their two immediately previous versions. Three scenarios are reported in this paper, one evaluating the ability of methods to accurately segment regions and two evaluating both segmentation and region classification (one with emphasis on text and the other focusing only on text). The results indicate that an innovative approach has a clear advantage but there is still a considerable need to develop robust methods that deal with layout challenges, especially with the non-text content."
            },
            "slug": "ICDAR2015-competition-on-recognition-of-documents-Antonacopoulos-Clausner",
            "title": {
                "fragments": [],
                "text": "ICDAR2015 competition on recognition of documents with complex layouts - RDCL2015"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An objective comparative evaluation of page segmentation and region classification methods for documents with complex layouts indicates that an innovative approach has a clear advantage but there is still a considerable need to develop robust methods that deal with layout challenges, especially with the non-text content."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40078651"
                        ],
                        "name": "Mudit Agrawal",
                        "slug": "Mudit-Agrawal",
                        "structuredName": {
                            "firstName": "Mudit",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mudit Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Agrawal and Doermann improved the original Voronoi algorithm [120] with Voronoi++ which adapts the Voronoi parameters to the local spatial context [55]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3355513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dc458247092edc982718af4481c6400134b0852",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a dynamic approach to document page segmentation. Current page segmentation algorithms lack the ability to dynamically adapt local variations in the size, orientation and distance of components within a page. Our approach builds upon one of the best algorithms, Kise et. al. work based on Area Voronoi Diagrams, which adapts globally to page content to determine algorithm parameters. In our approach, local thresholds are determined dynamically based on parabolic relations between components, and Docstrum based angular and neighborhood features are integrated to improve accuracy. Zone-based evaluation was performed on four sets of printed and handwritten documents in English and Arabic scripts and an increase of 33% in accuracy is reported."
            },
            "slug": "Voronoi++:-A-Dynamic-Page-Segmentation-Approach-on-Agrawal-Doermann",
            "title": {
                "fragments": [],
                "text": "Voronoi++: A Dynamic Page Segmentation Approach Based on Voronoi and Docstrum Features"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "In this approach, local thresholds are determined dynamically based on parabolic relations between components, and Docstrum based angular and neighborhood features are integrated to improve accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708890"
                        ],
                        "name": "M. Baechler",
                        "slug": "M.-Baechler",
                        "structuredName": {
                            "firstName": "Micheal",
                            "lastName": "Baechler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baechler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 66
                            }
                        ],
                        "text": "Texture classification Three algorithms use only texture features [9, 88, 89]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 625,
                                "start": 621
                            }
                        ],
                        "text": "Algorithm Input layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [72] Any Yes Color Yes No Text lines Horizontal Straight 448 1 2 [104] Any Yes Color Yes Yes Regions Any Curved 87 1 2 [110] Any Yes Color Yes Yes Regions Any Curved 16 2 1 [51] Any Yes Color No No Regions Any Curved 2000 2 2 [74] Any Yes Color No No Text lines Any Curved 50 1 1 [84] Any Yes Color No Yes Text lines Any Straight 21 2 1 [54] Any Yes Gray Yes No Regions Horizontal Straight 65 2 1 [112] Any Yes BW Yes Yes Regions Horizontal Straight 1000 3 6 [89] Any No Color Yes Yes Regions Any Curved 100 1 1 Continued on next page"
                    },
                    "intents": []
                }
            ],
            "corpusId": 11273655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15b14acb4501964721da3c028c927c2ff048a98e",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a generic layout analysis system for historical documents. It presents the architecture of a pyramidal approach using three analysis levels. Each level consists of a classifier using machine learning techniques where the output of the upper level is used as a feature in the lower level. The current implementation uses a so called Dynamic Multi-Layer perceptron (DMLP), which is a natural extension of MLP classifiers. The system is evaluated on medieval documents for which a multi-layer model is used to discriminate among 10 classes organized hierarchically."
            },
            "slug": "Multi-Resolution-Layout-Analysis-of-Medieval-Using-Baechler-Ingold",
            "title": {
                "fragments": [],
                "text": "Multi Resolution Layout Analysis of Medieval Manuscripts Using Dynamic MLP"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a generic layout analysis system for historical documents using three analysis levels using a so called Dynamic Multi-Layer perceptron (DMLP), which is a natural extension of MLP classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892336"
                        ],
                        "name": "Nazih Ouwayed",
                        "slug": "Nazih-Ouwayed",
                        "structuredName": {
                            "firstName": "Nazih",
                            "lastName": "Ouwayed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nazih Ouwayed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100548599"
                        ],
                        "name": "F. Auger",
                        "slug": "F.-Auger",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Auger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Auger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17874736,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00c6a4215f63fc56cd05a06d1a81af126347d99c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for the multi-oriented text line extraction from historical handwritten Arabic documents. Because of the multi-orientation of lines and their dispersion in the page, we use an image paving algorithm that can progressively and locally determine the lines. The paving algorithm is initialized with a small window and then its size is corrected by extension until enough lines and connected components were found. We use the Snake for line extraction. Once the paving is established, the orientation is determined using the Wigner-Ville distribution on the histogram projection profile. This local orientation is then enlarged to limit the orientation in the neighborhood. Afterwards, the text lines are extracted locally in each zone basing on the follow-up of the baselines and the proximity of connected components. Finally, the connected components that overlap and touch in adjacent lines are separated. The morphology analysis of the terminal letters of Arabic words is here considered. The proposed approach has been experimented on 100 documents reaching an separation accuracy of about 98.6%."
            },
            "slug": "General-text-line-extraction-approach-based-on-Ouwayed-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "General text line extraction approach based on locally orientation estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper presents a novel approach for the multi-oriented text line extraction from historical handwritten Arabic documents using an image paving algorithm that can progressively and locally determine the lines."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14085340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec2f3cc86c334c3756f0bc06e4657c82f5b1215c",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Camera-captured, warped document images usually contain curled text-lines because of distortions caused by camera perspective view and page curl. Warped document images can be transformed into planar document images for improving optical character recognition accuracy and human readability using monocular dewarping techniques. Curled text-lines segmentation is a crucial initial step for most of the monocular dewarping techniques. Existing curled text-line segmentation approaches are sensitive to geometric and perspective distortions. In this paper, we introduce a novel curled text-line segmentation algorithm by adapting active contour (snake). Our algorithm performs text-line segmentation by estimating pairs of x-line and baseline. It estimates a local pair of x-line and baseline on each connected component by jointly tracing top and bottom points of neighboring connected components, and finally each group of overlapping pairs is considered as a segmented text-line. Our algorithm has achieved curled text-line segmentation accuracy of above 95% on the DFKI-I (CBDAR 2007 dewarping contest) dataset, which is significantly better than previously reported results on this dataset."
            },
            "slug": "Coupled-snakelets-for-curled-text-line-segmentation-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Coupled snakelets for curled text-line segmentation from warped document images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel curled text-line segmentation algorithm is introduced by adapting active contour (snake) by estimating pairs of x-line and baseline and achieving improved accuracy on the DFKI-I (CBDAR 2007 dewarping contest) dataset."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2764871"
                        ],
                        "name": "C. Clausner",
                        "slug": "C.-Clausner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Clausner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clausner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070747525"
                        ],
                        "name": "C. Papadopoulos",
                        "slug": "C.-Papadopoulos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12177952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43f0530c55a38db567e258a08ae9629aba5034e4",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an objective comparative evaluation of layout analysis methods for scanned historical newspapers. It describes the competition (modus operandi, dataset and evaluation methodology) held in the context of ICDAR2013 and the 2nd International Workshop on Historical Document Imaging and Processing (HIP2013), presenting the results of the evaluation of five submitted methods. Two state-of-the-art systems, one commercial and one open-source, are also evaluated for comparison. Two scenarios are reported in this paper, one evaluating the ability of methods to accurately segment regions and the other evaluating the whole pipeline of segmentation and region classification (with a text extraction goal). The results indicate that there is a convergence to a certain methodology with some variations in the approach. However, there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical newspapers."
            },
            "slug": "ICDAR-2013-Competition-on-Historical-Newspaper-Antonacopoulos-Clausner",
            "title": {
                "fragments": [],
                "text": "ICDAR 2013 Competition on Historical Newspaper Layout Analysis (HNLA 2013)"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An objective comparative evaluation of layout analysis methods for scanned historical newspapers indicates that there is a convergence to a certain methodology with some variations in the approach, but there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical newspapers."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49711577"
                        ],
                        "name": "Florent Montreuil",
                        "slug": "Florent-Montreuil",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Montreuil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Montreuil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3191442"
                        ],
                        "name": "E. Grosicki",
                        "slug": "E.-Grosicki",
                        "structuredName": {
                            "firstName": "Emmanu\u00e8le",
                            "lastName": "Grosicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Grosicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804638"
                        ],
                        "name": "L. Heutte",
                        "slug": "L.-Heutte",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Heutte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Heutte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97014121"
                        ],
                        "name": "St\u00e9phane Nicolas",
                        "slug": "St\u00e9phane-Nicolas",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Nicolas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Nicolas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2418672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adb54e63a9dadcbcd04b0ba9ec2cffd0491a9ef6",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a new approach using a Conditional Random Fields (CRFs) to extract physical and logical layouts in unconstrained handwritten letters such as those sent by individuals to companies. In this approach, the extraction of the layouts is considered as a labeling task consisting in assigning a label to each pixel of the document image. This label is chosen among a set of labels depicting the layout elements. The CRF-based method models two stochastic processes : the first one corresponds to the association between pixels and labels, the second one to the relationship of one label with respect to its neighboring labels. The CRF model gives access to the global conditional probability of a given labeling of the image according to image features and some prior knowledge about the structure of the document. This global probability is computed by means of local conditional probabilities at each pixel. To find the best label field, a key point of our model is the implementation of the optimal inference 2D Dynamic Programming method. Experiments have been performed on 1250 handwritten letters of the RIMES database. Good results have been reported showing the capacity of our approach to extract simultaneously the physical and logical layouts."
            },
            "slug": "Unconstrained-Handwritten-Document-Layout-Using-2D-Montreuil-Grosicki",
            "title": {
                "fragments": [],
                "text": "Unconstrained Handwritten Document Layout Extraction Using 2D Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A new approach using a Conditional Random Fields (CRFs) to extract physical and logical layouts in unconstrained handwritten letters such as those sent by individuals to companies, as well as the implementation of the optimal inference 2D Dynamic Programming method."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069634816"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404588675"
                        ],
                        "name": "W. Abd-Almageed",
                        "slug": "W.-Abd-Almageed",
                        "structuredName": {
                            "firstName": "Wael",
                            "lastName": "Abd-Almageed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Abd-Almageed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145714522"
                        ],
                        "name": "Le Kang",
                        "slug": "Le-Kang",
                        "structuredName": {
                            "firstName": "Le",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Le Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14628048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b31f762bad5bb44287d78a41e60ebd2264b03b4",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel graph-based method for extracting handwritten text lines in monochromatic Arabic document images. Our approach consists of two steps - Coarse text line estimation using primary components which define the line and assignment of diacritic components which are more difficult to associate with a given line. We first estimate local orientation at each primary component to build a sparse similarity graph. We then, use a shortest path algorithm to compute similarities between non-neighboring components. From this graph, we obtain coarse text lines using two estimates obtained from Affinity propagation and Breadth-first search. In the second step, we assign secondary components to each text line. The proposed method is very fast and robust to non-uniform skew and character size variations, normally present in handwritten text lines. We evaluate our method using a pixel-matching criteria, and report 96% accuracy on a dataset of 125 Arabic document images. We also present a proximity analysis on datasets generated by artificially decreasing the spacings between text lines to demonstrate the robustness of our approach."
            },
            "slug": "Handwritten-Arabic-text-line-segmentation-using-Kumar-Abd-Almageed",
            "title": {
                "fragments": [],
                "text": "Handwritten Arabic text line segmentation using affinity propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A novel graph-based method for extracting handwritten text lines in monochromatic Arabic document images using primary components which define the line and assignment of diacritic components which are more difficult to associate with a given line is presented."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700033"
                        ],
                        "name": "N. Stamatopoulos",
                        "slug": "N.-Stamatopoulos",
                        "structuredName": {
                            "firstName": "Nikolaos",
                            "lastName": "Stamatopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Stamatopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19984349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "175541a70dbd1a929d8fed35792851d2f50d9cb4",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of the handwriting segmentation contest that was organized in the context of ICDAR2007. The aim of this contest was to use well established evaluation practices and procedures in order to record recent advances in off-line handwriting segmentation. Two benchmarking datasets (one for text line and one for word segmentation) were used in a common evaluation platform in order to test and compare all submitted algorithms for handwritten document segmentation in realistic circumstances. The results of the evaluation of five algorithms submitted by participants as well as of two state-of-the-art algorithms are presented. The performance evaluation method is based on counting the number of matches between the text lines or words detected by the algorithms and the text line or words of the ground truth."
            },
            "slug": "Handwriting-Segmentation-Contest-Gatos-Antonacopoulos",
            "title": {
                "fragments": [],
                "text": "Handwriting Segmentation Contest"
            },
            "venue": {
                "fragments": [],
                "text": "ICDAR"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2394658"
                        ],
                        "name": "M. Ziaratban",
                        "slug": "M.-Ziaratban",
                        "structuredName": {
                            "firstName": "Majid",
                            "lastName": "Ziaratban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ziaratban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692435"
                        ],
                        "name": "K. Faez",
                        "slug": "K.-Faez",
                        "structuredName": {
                            "firstName": "Karim",
                            "lastName": "Faez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Faez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15060882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d57e8f3d243b5321ff8eb26b88a35bfce156a81",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a novel script-independent block-based text line extraction technique is proposed for multi-skewed document images. Three parameters are defined to adopt the method with various writings. Extensive experiments on different datasets demonstrate that the proposed algorithm outperforms previous methods"
            },
            "slug": "An-Adaptive-Script-Independent-Block-Based-Text-Ziaratban-Faez",
            "title": {
                "fragments": [],
                "text": "An Adaptive Script-Independent Block-Based Text Line Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A novel script-independent block-based text line extraction technique is proposed for multi-skewed document images that outperforms previous methods on different datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2010 20th International Conference on Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145851592"
                        ],
                        "name": "C\u00e9r\u00e8s Carton",
                        "slug": "C\u00e9r\u00e8s-Carton",
                        "structuredName": {
                            "firstName": "C\u00e9r\u00e8s",
                            "lastName": "Carton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9r\u00e8s Carton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33225210"
                        ],
                        "name": "Aur\u00e9lie Lemaitre",
                        "slug": "Aur\u00e9lie-Lemaitre",
                        "structuredName": {
                            "firstName": "Aur\u00e9lie",
                            "lastName": "Lemaitre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lie Lemaitre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[34] continued this work with an interactive training step capable of creating automatically an exhaustive set of models for a large data set."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19802053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef3158caed8619b5dde513d482cd79fa84de92ab",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Dealing with non annotated documents for the design of a document recognition system is not an easy task. In general, statistical methods cannot learn without an annotated ground truth, unlike syntactical methods. However their ability to deal with non annotated data comes from the fact that the description is manually made by a user. The adaptation to a new kind of document is then tedious as the whole manual process of extraction of knowledge has to be redone. In this paper, we propose a method to extract knowledge and generate rules without any ground truth. Using large volume of non annotated documents, it is possible to study redundancies of some extracted elements in the document images. The redundancy is exploited through an automatic clustering algorithm. An interaction with the user brings semantic to the detected clusters. In this work, the extracted elements are some keywords extracted with word spotting. This approach has been applied to old marriage record field detection on the FamilySearch HIP2013 competition database. The results demonstrate that we successfully automatically infer rules from non annotated documents using the redundancy of extracted elements of the documents."
            },
            "slug": "Automatic-and-interactive-rule-inference-without-Carton-Lemaitre",
            "title": {
                "fragments": [],
                "text": "Automatic and interactive rule inference without ground truth"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method to extract knowledge and generate rules from non annotated documents using the redundancy of extracted elements of the documents and has been applied to old marriage record field detection on the FamilySearch HIP2013 competition database."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712709"
                        ],
                        "name": "S. R. Vantaram",
                        "slug": "S.-R.-Vantaram",
                        "structuredName": {
                            "firstName": "Sreenath",
                            "lastName": "Vantaram",
                            "middleNames": [
                                "Rao"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. R. Vantaram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733172"
                        ],
                        "name": "E. Saber",
                        "slug": "E.-Saber",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Saber",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 120
                            }
                        ],
                        "text": "Our work was motivated by the outstanding and very exhaustive25\nreview of natural image segmentation algorithms done by Vantaram and Saber [16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 205
                            }
                        ],
                        "text": "Scientific scope of this survey Segmentation algorithms can be applied to document images but also to a set of document images (in order to segment a book into its chapters by instance), to natural images [16], to medical images [17] and even to 3D meshes [18]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "review of natural image segmentation algorithms done by Vantaram and Saber [16]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31980349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "101e8c988b1c088f84b42411e5d1e03e9957a821",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 244,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. In recent years, the acquisition of image and video information for processing, analysis, understanding, and exploitation of the underlying content in various applications, ranging from remote sensing to biomedical imaging, has grown at an unprecedented rate. Analysis by human observers is quite laborious, tiresome, and time consuming, if not infeasible, given the large and continuously rising volume of data. Hence the need for systems capable of automatically and effectively analyzing the aforementioned imagery for a variety of uses that span the spectrum from homeland security to elderly care. In order to achieve the above, tools such as image segmentation provide the appropriate foundation for expediting and improving the effectiveness of subsequent high-level tasks by providing a condensed and pertinent representation of image information. We provide a comprehensive survey of color image segmentation strategies adopted over the last decade, though notable contributions in the gray scale domain will also be discussed. Our taxonomy of segmentation techniques is sampled from a wide spectrum of spatially blind (or feature-based) approaches such as clustering and histogram thresholding as well as spatially guided (or spatial domain-based) methods such as region growing/splitting/merging, energy-driven parametric/geometric active contours, supervised/unsupervised graph cuts, and watersheds, to name a few. In addition, qualitative and quantitative results of prominent algorithms on several images from the Berkeley segmentation dataset are shown in order to furnish a fair indication of the current quality of the state of the art. Finally, we provide a brief discussion on our current perspective of the field as well as its associated future trends."
            },
            "slug": "Survey-of-contemporary-trends-in-color-image-Vantaram-Saber",
            "title": {
                "fragments": [],
                "text": "Survey of contemporary trends in color image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A comprehensive survey of color image segmentation strategies adopted over the last decade is provided, though notable contributions in the gray scale domain will also be discussed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3342880"
                        ],
                        "name": "J. V. Beusekom",
                        "slug": "J.-V.-Beusekom",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Beusekom",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Beusekom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027911"
                        ],
                        "name": "Daniel Keysers",
                        "slug": "Daniel-Keysers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keysers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Keysers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[35], proposed another grammar algorithm based on a probabilistic layout formulation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 536,
                                "start": 532
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 541167,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "7fa91b3fad9ac20c9b2bcbec1633b6235d21aa91",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A key limitation of current layout analysis methods is that they rely on many hard-coded assumptions about document layouts and can not adapt to new layouts for which the underlying assumptions are not satisfied. Another major drawback of these approaches is that they do not return confidence scores for their outputs. These problems pose major challenges in large scale digitization efforts where a large number of different layouts need to be handled and manual inspection of the results on each individual page is not feasible. This paper presents a novel statistical approach to layout analysis that aims at solving the above mentioned problems for Manhattan layouts. The presented approach models known page layouts as a structural mixture model. A probabilistic matching algorithm is presented that gives multiple interpretations of input layout with associated probabilities. First experiments on documents from the publicly available MARG dataset achieved below 5%error rate for geometric layout analysis."
            },
            "slug": "Structural-Mixtures-for-Statistical-Layout-Analysis-Shafait-Beusekom",
            "title": {
                "fragments": [],
                "text": "Structural Mixtures for Statistical Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A probabilistic matching algorithm is presented that gives multiple interpretations of input layout with associated probabilities that aims at solving the above mentioned problems for Manhattan layouts."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700033"
                        ],
                        "name": "N. Stamatopoulos",
                        "slug": "N.-Stamatopoulos",
                        "structuredName": {
                            "firstName": "Nikolaos",
                            "lastName": "Stamatopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Stamatopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746772"
                        ],
                        "name": "G. Louloudis",
                        "slug": "G.-Louloudis",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Louloudis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Louloudis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971318"
                        ],
                        "name": "Alireza Alaei",
                        "slug": "Alireza-Alaei",
                        "structuredName": {
                            "firstName": "Alireza",
                            "lastName": "Alaei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alireza Alaei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 13
                            }
                        ],
                        "text": "segmentation [121] and 2015 Competition on text line detection [15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17844687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5899ea0e6a1093c6287c1eec81169da16ba5b519",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of the Handwriting Segmentation Contest that was organized in the context of the ICDAR2013. The general objective of the contest was to use well established evaluation practices and procedures to record recent advances in off-line handwriting segmentation. Two benchmarking datasets, one for text line and one for word segmentation, were created in order to test and compare all submitted algorithms as well as some state-of-the-art methods for handwritten document image segmentation in realistic circumstances. Handwritten document images were produced by many writers in two Latin based languages (English and Greek) and in one Indian language (Bangla, the second most popular language in India). These images were manually annotated in order to produce the ground truth which corresponds to the correct text line and word segmentation results. The datasets of previously organized contests (ICDAR2007, ICDAR2009 and ICFHR2010 Handwriting Segmentation Contests) along with a dataset of Bangla document images were used as training dataset. Eleven methods are submitted in this competition. A brief description of the submitted algorithms, the evaluation criteria and the segmentation results obtained from the submitted methods are also provided in this manuscript."
            },
            "slug": "ICDAR-2013-Handwriting-Segmentation-Contest-Stamatopoulos-Gatos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2013 Handwriting Segmentation Contest"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This paper presents the results of the Handwriting Segmentation Contest that was organized in the context of the ICDAR2013 to use well established evaluation practices and procedures to record recent advances in off-line handwriting segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752239"
                        ],
                        "name": "Xiabi Liu",
                        "slug": "Xiabi-Liu",
                        "structuredName": {
                            "firstName": "Xiabi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiabi Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113504611"
                        ],
                        "name": "Hui Fu",
                        "slug": "Hui-Fu",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7415267"
                        ],
                        "name": "Yunde Jia",
                        "slug": "Yunde-Jia",
                        "structuredName": {
                            "firstName": "Yunde",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunde Jia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[63] use a Gaussian Mixture model to classify connected component triplets as text or non text."
                    },
                    "intents": []
                }
            ],
            "corpusId": 45832072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fb8de25351c543676c269421e05c0efc47f4c40",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Gaussian-mixture-modeling-and-learning-of-for-text-Liu-Fu",
            "title": {
                "fragments": [],
                "text": "Gaussian mixture modeling and learning of neighboring characters for multilingual text extraction in images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8249814"
                        ],
                        "name": "Xujun Peng",
                        "slug": "Xujun-Peng",
                        "structuredName": {
                            "firstName": "Xujun",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xujun Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800513"
                        ],
                        "name": "S. Setlur",
                        "slug": "S.-Setlur",
                        "structuredName": {
                            "firstName": "Srirangaraj",
                            "lastName": "Setlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Setlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841171"
                        ],
                        "name": "R. Sitaram",
                        "slug": "R.-Sitaram",
                        "structuredName": {
                            "firstName": "Ramachandrula",
                            "lastName": "Sitaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sitaram"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[99] work at connected component and patch level."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Peng [99] and Pinson [93] focus on extracting overlapping handwritten and typewritten text."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 716,
                                "start": 712
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 15655174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77a43603da317c85d1085713f9b6f8644f07e2fc",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "The convenience of search, both on the personal computer hard disk as well as on the web, is still limited mainly to machine printed text documents and images because of the poor accuracy of handwriting recognizers. The focus of research in this paper is the segmentation of handwritten text and machine printed text from annotated documents sometimes referred to as the task of \u201cink separation\u201d to advance the state-of-art in realizing search of hand-annotated documents. We propose a method which contains two main steps\u2014patch level separation and pixel level separation. In the patch level separation step, the entire document is modeled as a Markov Random Field (MRF). Three different classes (machine printed text, handwritten text and overlapped text) are initially identified using G-means based classification followed by a MRF based relabeling procedure. A MRF based classification approach is then used to separate overlapped text into machine printed text and handwritten text using pixel level features forming the second step of the method. Experimental results on a set of machine-printed documents which have been annotated by multiple writers in an office/collaborative environment show that our method is robust and provides good text separation performance."
            },
            "slug": "Handwritten-text-separation-from-annotated-machine-Peng-Setlur",
            "title": {
                "fragments": [],
                "text": "Handwritten text separation from annotated machine printed documents using Markov Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Experimental results on a set of machine-printed documents which have been annotated by multiple writers in an office/collaborative environment show that the proposed segmentation of handwritten text and machine printed text from annotated documents is robust and provides good text separation performance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111439"
                        ],
                        "name": "Djamel Gaceb",
                        "slug": "Djamel-Gaceb",
                        "structuredName": {
                            "firstName": "Djamel",
                            "lastName": "Gaceb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Djamel Gaceb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721326"
                        ],
                        "name": "V. Eglin",
                        "slug": "V.-Eglin",
                        "structuredName": {
                            "firstName": "V\u00e9ronique",
                            "lastName": "Eglin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eglin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145573734"
                        ],
                        "name": "F. Lebourgeois",
                        "slug": "F.-Lebourgeois",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lebourgeois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[61] use a custom binarization optimized for fast processing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 470,
                                "start": 466
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 108964,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "1bc1d93c9c02922a2aa061acb37e779c9c88b5d6",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Every-day, the postal sorting systems diffuse several tons of mails. It is noted that the principal origin of mail rejection is related to the failure of address-block localization task, particularly, of the physical layout segmentation stage. The bottom-up and top-down segmentation methods bring different knowledge that should not be ignored when we need to increase the robustness. Hybrid methods combine the two strategies in order to take advantages of one strategy to the detriment of other. Starting from these remarks, our proposal makes use of a hybrid segmentation strategy more adapted to the postal mails. The high level stages are based on the hierarchical graphs coloring. Today, no other work in this context has make use of the powerfulness of this tool. The performance evaluation of our approach was tested on a corpus of 10000 envelope images. The processing times and the rejection rate were considerably reduced."
            },
            "slug": "Application-of-graph-coloring-in-physical-layout-Gaceb-Eglin",
            "title": {
                "fragments": [],
                "text": "Application of graph coloring in physical layout segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This proposal makes use of a hybrid segmentation strategy more adapted to the postal mails based on the hierarchical graphs coloring that was tested on a corpus of 10000 envelope images and the processing times and the rejection rate were considerably reduced."
            },
            "venue": {
                "fragments": [],
                "text": "2008 19th International Conference on Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054986524"
                        ],
                        "name": "David Hebert",
                        "slug": "David-Hebert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690399"
                        ],
                        "name": "T. Paquet",
                        "slug": "T.-Paquet",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Paquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Paquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97014121"
                        ],
                        "name": "St\u00e9phane Nicolas",
                        "slug": "St\u00e9phane-Nicolas",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Nicolas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Nicolas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28374153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05deb3b69d15c145af0224c2712ec9db0d3b72c1",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce quantization feature functions to represent continuous or large range discrete data into the symbolic CRF data representation. We show that doing this convertion in a simple way allows the CRF to automaticaly select discriminative features to achieve best performance. This system is evaluated on a segmentation task of degraded newspapers archives. The results obtained show the ability of the CRF model to deal with numerical features similarly as for symbolic representation thanks to the use of quantization feature functions. The segmentation task is achieved by the definition of a horizontal CRF model dedicated to pixel labelling."
            },
            "slug": "Continuous-CRF-with-Multi-scale-Quantization-to-in-Hebert-Paquet",
            "title": {
                "fragments": [],
                "text": "Continuous CRF with Multi-scale Quantization Feature Functions Application to Structure Extraction in Old Newspaper"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "It is shown that doing quantization feature functions to represent continuous or large range discrete data into the symbolic CRF data representation in a simple way allows the CRF to automatically select discriminative features to achieve best performance."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2764871"
                        ],
                        "name": "C. Clausner",
                        "slug": "C.-Clausner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Clausner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clausner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070747525"
                        ],
                        "name": "C. Papadopoulos",
                        "slug": "C.-Papadopoulos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9857172,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cedd6fcd4a95d4b270d894f7fdacb87fded5412",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an objective comparative evaluation of layout analysis and recognition methods for scanned historical books. It describes the competition (modus operandi, dataset and evaluation methodology) held in the context of ICDAR2013 and the 2nd International Workshop on Historical Document Imaging and Processing (HIP2013), presenting the results of the evaluation of five methods - three submitted and two state-of-the-art systems (one commercial and one open-source). Three scenarios are reported in this paper, one evaluating the ability of methods to accurately segment regions, one evaluating segmentation and region classification (with a text extraction goal) and the other the whole pipeline including recognition. The results indicate that there is a convergence to a certain methodology, in terms of layout analysis, with some variations in the approach. However, there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical books, especially for OCR."
            },
            "slug": "ICDAR-2013-Competition-on-Historical-Book-(HBR-Antonacopoulos-Clausner",
            "title": {
                "fragments": [],
                "text": "ICDAR 2013 Competition on Historical Book Recognition (HBR 2013)"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results indicate that there is a convergence to a certain methodology, in terms of layout analysis, with some variations in the approach, but there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical books, especially for OCR."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40241827"
                        ],
                        "name": "Li Liu",
                        "slug": "Li-Liu",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409858950"
                        ],
                        "name": "Yue Lu",
                        "slug": "Yue-Lu",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24742344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05c248968101fe14127d2eded7f8bfab82032b9e",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A new near-duplicate document image matching approach is proposed. Globally, we model the spatial arrangements of objects in an image. Locally, the micro-patterns within each object are captured. To define a micro-pattern, the N-nary center-symmetric gray value differences in an image local neighborhood of a variable radius are exploited. A visual descriptor is proposed to characterize the appearance of the object based on micro-pattern distributions. By combining the global and local features, each document image is represented by a compact signature with a variable length. We employ Earth Mover's Distance for image dissimilarity computation, which stands out for its remarkable ability to tolerate the instability of object segmentation by allowing many-to-many correspondence among objects. Extensive experiments on two data sets demonstrate the effectiveness of the proposed approach."
            },
            "slug": "Novel-Global-and-Local-Features-for-Near-Duplicate-Liu-Lu",
            "title": {
                "fragments": [],
                "text": "Novel Global and Local Features for Near-Duplicate Document Image Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A new near-duplicate document image matching approach that employs Earth Mover's Distance for image dissimilarity computation, which stands out for its remarkable ability to tolerate the instability of object segmentation by allowing many-to-many correspondence among objects."
            },
            "venue": {
                "fragments": [],
                "text": "2014 22nd International Conference on Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24346804,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72b708230bb11b28682ad55587f960f3a892cfc6",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractWe will show in this paper one of the numerous interests of designing a generic recognition system, i.e. the possibility of producing either general or specific systems. We propose the Description and Modification of Segmentation (DMOS) method, which is made of a new grammatical language (Enhanced Position Formalism\u2014EPF) and an associated parser able to deal with noise. From an EPF description of a kind of document structure, a new recognition system is produced by compilation. This method has been successfully used to produce recognition systems on musical scores, mathematical formulae and even tennis courts in videos. This DMOS generic method separates knowledge from program. Therefore, for a same kind of document like table structures, it is possible to define with EPF, more or less specific descriptions to produce more or less specific recognition systems. For example, we have been able to produce a general recognition system of table structures. It can recognize the hierarchical organization \nof a table made with rulings, whatever the number/size of column/rows and the deep of the hierarchy contents in it, as soon as the document has a not too bad quality (no missing rulings for example). We will present the way the description is done using EPF to be general enough to recognize very different table organizations. With the same DMOS generic method, we have also been able to easily define a specific recognition system of the table structure of quite damaged military forms of the 19th century. This specific description was necessary to compensate some missing informations concerning the table structure of those military forms, due to a very bad quality or hidden part of the table. This system has been successfully validated on 88,745 images, showing that this DMOS generic method can be used at an industrial level."
            },
            "slug": "DMOS,-a-generic-document-recognition-method:-to-in-Co\u00fcasnon",
            "title": {
                "fragments": [],
                "text": "DMOS, a generic document recognition method: application to table structure analysis in a general and in a specific way"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Description and Modification of Segmentation (DMOS) method is proposed, which is made of a new grammatical language (Enhanced Position Formalism\u2014EPF) and an associated parser able to deal with noise, which has been successfully used to produce recognition systems on musical scores, mathematical formulae and even tennis courts in videos."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118542444"
                        ],
                        "name": "Raymond W. Smith",
                        "slug": "Raymond-W.-Smith",
                        "structuredName": {
                            "firstName": "Raymond W.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond W. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206776838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "faeb2be92d76d1d3fd1995e4c8021a3cc8b9748c",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new hybrid page layout analysis algorithm is proposed, which uses bottom-up methods to form an initial data-type hypothesis and locate the tab-stops that were used when the page was formatted. The detected tab-stops, are used to deduce the column layout of the page. The column layout is then applied in a top-down manner to impose structure and reading-order on the detected regions. The complete C++ source code implementation is available as part of the Tesseract open source OCR engine at http://code.google.com/p/tesseract-ocr."
            },
            "slug": "Hybrid-Page-Layout-Analysis-via-Tab-Stop-Detection-Smith",
            "title": {
                "fragments": [],
                "text": "Hybrid Page Layout Analysis via Tab-Stop Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new hybrid page layout analysis algorithm is proposed, which uses bottom-up methods to form an initial data-type hypothesis and locate the tab-stops that were used when the page was formatted."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708019"
                        ],
                        "name": "Zhixin Shi",
                        "slug": "Zhixin-Shi",
                        "structuredName": {
                            "firstName": "Zhixin",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhixin Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800513"
                        ],
                        "name": "S. Setlur",
                        "slug": "S.-Setlur",
                        "structuredName": {
                            "firstName": "Srirangaraj",
                            "lastName": "Setlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Setlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 649,
                                "start": 645
                            }
                        ],
                        "text": "[29] Any No BW Yes Yes Regions Any Curved 75 2 2 [56] Any No BW No No Regions Any Curved 350 2 3 [64] Any No BW No No Regions Any Curved 24339 2 2 [47] Any No BW No No Regions Any Straight 100 1 1 [60] Any No BW No No Text lines Any Straight 52 1 1 [83] Any No BW No No Text lines Any Straight 95 4 1 [78] Any No BW No No Text lines Horizontal Curved 649 10 2 [32] Any No BW No Yes Regions Any Curved 1425 2 3 [26] Structured No BW Yes No Regions Any Curved 100 2 2 [61] Structured No BW No No Regions Horizontal Straight 10000 1 1 [35] Structured No BW No Yes Regions Any Curved 260 1 1 [93] Text only Yes BW Yes Yes Regions Any Curved 500 1 1 [48] Text only No Gray No No Text lines Horizontal Straight 45 1 1 [99] Text only No BW Yes Yes Regions Any Curved 28 1 1 [41] Text only No BW No No Text lines Any Curved 100 1 1 [86] Text only No BW No No Text lines Any Straight 853 1 1 [115] Text only No BW No No Text lines Horizontal Straight 50 2 1 [67] Text only No BW No No Text lines Skewed Curved 202 1 2 [27] Text only No BW No No Text lines Skewed Straight 120 2 1 [82] Text only No BW No Yes Text lines Horizontal Straight 150 3 1"
                    },
                    "intents": []
                }
            ],
            "corpusId": 15257932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8034e92bbc697e7cbbd8256adb68f4f86db9071",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a new text line extraction method for handwritten Arabic documents. The proposed technique is based on a generalized adaptive local connectivity map (ALCM) using a steerable directional filter. The algorithm is designed to solve the particularly complex problems seen in handwritten documents such as fluctuating, touching or crossing text lines. The proposed algorithm consists of three steps. Firstly, a steerable filter is used to probe and determine foreground intensity along multiple directions at each pixel while generating the ALCM. The ALCM is then binarized using an adaptive thresholding algorithm to get a rough estimate of the location of the text lines. In the second step, connected component analysis is used to classify text and non text patterns in the generated ALCM to refine the location of the text lines. Finally, the text lines are separated by superimposing the text line patterns in the ALCM on the original document image and extracting the connected components covered by the pattern mask. Analysis of experimental results on the DARPA MADCAT Arabic handwritten document data indicate that the method is robust and is capable of correctly isolating handwritten text lines even on challenging document images."
            },
            "slug": "A-Steerable-Directional-Local-Profile-Technique-for-Shi-Setlur",
            "title": {
                "fragments": [],
                "text": "A Steerable Directional Local Profile Technique for Extraction of Handwritten Arabic Text Lines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Analysis of experimental results on the DARPA MADCAT Arabic handwritten document data indicate that the method is robust and is capable of correctly isolating handwritten text lines even on challenging document images."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18231200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b160881bdd0c995b1b0961365b6d21c0ecf577b",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Detection of curled textline is important for dewarping of hand-held camera-captured document images. Then baselines and the lines following the top of x-height of characters (x-lines) are estimated for dewarping. Existing curled textline segmentation approaches are sensitive to outlier points and perspective distortions. Furthermore these approaches use regression over top and bottom points of a segmented textline to estimate its x-line and baseline separately, which may results in inaccurate estimation. Here we propose a novel curled textline segmentation approach based on active contours (snakes) in which we perform segmentation by estimating the pairs of x-line and baseline; solving both problems together. Starting form a connected component we jointly trace a pair of x-line and baseline using coupled snakes and external energies of neighboring top-bottom points. We grow neighborhood region iteratively during tracing, which results in robustness to perspective distortions, and maintain a natural property of similar distance within the pair of x-line and baseline pair, which results in robustness to outlier points. We achieved 90.76% of one-to-one match-score recognition accuracy of curled textline segmentation on CBDAR 2007 Document Image Dewarping Contest dataset, with good estimation of pairs of x-line and baseline."
            },
            "slug": "Coupled-Snakelet-Model-for-Curled-Textline-of-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Coupled Snakelet Model for Curled Textline Segmentation of Camera-Captured Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a novel curled textline segmentation approach based on active contours (snakes) in which it performs segmentation by estimating the pairs of x-line and baseline using coupled snakes and external energies of neighboring top-bottom points."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "algorithms have been developed in the past [19] and in particular in paleography [20] but none was found during the time frame of this survey."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10854513,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "40b919bc2569979310a5e39d32b1a7dd542541e3",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of off-line handwritten character recognition has eluded a satisfactory solution for several decades. Researchers working in the area of on-line recognition have had greater success, but the possibility of extracting on-line information from static images has not been fully explored. The experience of forensic document examiners assures us that in many cases, such information can be successfully recovered.We outline the design of a system for the recovery of temporal information from static handwritten images. We provide a taxonomy of local, regional and global temporal clues which are often found in hand-written samples, and describe methods for recovering these clues from the image.We show how this system can benefit from obtaining a comprehensive understanding of the handwriting signal and a detailed analysis of stroke and sub-stroke properties. We suggest that the recovery task requires that we break away from traditional thresholding and thinning techniques, and we provide a framework for such analysis. We demonstrate how isolated temporal clues can reliably be extracted from this framework and propose a control structure for integrating the partial information.We show how many seemingly ambiguous situations can be resolved by the derived clues and our knowledge of the writing process, and provide several examples to illustrate our approach."
            },
            "slug": "Recovery-of-temporal-information-from-static-images-Doermann-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Recovery of temporal information from static images of handwriting"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how the temporal clues can reliably be extracted from this framework and how many of the seemingly ambiguous situations can be resolved by the derived clues and knowledge of the writing process."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2931211"
                        ],
                        "name": "G. Lazzara",
                        "slug": "G.-Lazzara",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Lazzara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lazzara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772796"
                        ],
                        "name": "Roland Levillain",
                        "slug": "Roland-Levillain",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Levillain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roland Levillain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788461"
                        ],
                        "name": "T. G\u00e9raud",
                        "slug": "T.-G\u00e9raud",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "G\u00e9raud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. G\u00e9raud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2211095"
                        ],
                        "name": "Y. Jacquelet",
                        "slug": "Y.-Jacquelet",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Jacquelet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Jacquelet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405807596"
                        ],
                        "name": "Julien Marquegnies",
                        "slug": "Julien-Marquegnies",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Marquegnies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julien Marquegnies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405807600"
                        ],
                        "name": "Arthur Crepin-Leblond",
                        "slug": "Arthur-Crepin-Leblond",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Crepin-Leblond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur Crepin-Leblond"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14455216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65dfbb12900a7ae9f8d0d32c31e56f17e9aebd88",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Electronic documents are being more and more usable thanks to better and more affordable network, storage and computational facilities. But in order to benefit from computer-aided document management, paper documents must be digitized and analyzed. This task may be challenging at several levels. Data may be of multiple types thus requiring different adapted processing chains. The tools to be developed should also take into account the needs and knowledge of users, ranging from a simple graphical application to a complete programming framework. Finally, the data sets to process may be large. In this paper, we expose a set of features that a Document Image Analysis framework should provide to handle the previous issues. In particular, a good strategy to address both flexibility and efficiency issues is the Generic Programming (GP) paradigm. These ideas are implemented as an open source module, SCRIBO, built on top of Olena, a generic and efficient image processing platform. Our solution features services such as preprocessing filters, text detection, page segmentation and document reconstruction (as XML, PDF or HTML documents). This framework, composed of reusable software components, can be used to create full-fledged graphical applications, small utilities, or processing chains to be integrated into third-party projects."
            },
            "slug": "The-SCRIBO-Module-of-the-Olena-Platform:-A-Free-for-Lazzara-Levillain",
            "title": {
                "fragments": [],
                "text": "The SCRIBO Module of the Olena Platform: A Free Software Framework for Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper exposes a set of features that a Document Image Analysis framework should provide to handle the previous issues, and implemented as an open source module, SCRIBO, built on top of Olena, a generic and efficient image processing platform."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421012"
                        ],
                        "name": "G. Zhong",
                        "slug": "G.-Zhong",
                        "structuredName": {
                            "firstName": "Guoqiang",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145541445"
                        ],
                        "name": "M. Cheriet",
                        "slug": "M.-Cheriet",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Cheriet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cheriet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12754882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cb07310020087fa678376188bed54eec6c5fdc3",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Tensor-representation-learning-based-image-patch-Zhong-Cheriet",
            "title": {
                "fragments": [],
                "text": "Tensor representation learning based image patch analysis for text identification and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118589"
                        ],
                        "name": "R. Achanta",
                        "slug": "R.-Achanta",
                        "structuredName": {
                            "firstName": "Radhakrishna",
                            "lastName": "Achanta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Achanta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2863792"
                        ],
                        "name": "Appu Shaji",
                        "slug": "Appu-Shaji",
                        "structuredName": {
                            "firstName": "Appu",
                            "lastName": "Shaji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Appu Shaji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548651"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40401747"
                        ],
                        "name": "Aur\u00e9lien Lucchi",
                        "slug": "Aur\u00e9lien-Lucchi",
                        "structuredName": {
                            "firstName": "Aur\u00e9lien",
                            "lastName": "Lucchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lien Lucchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735035"
                        ],
                        "name": "S. S\u00fcsstrunk",
                        "slug": "S.-S\u00fcsstrunk",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "S\u00fcsstrunk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S\u00fcsstrunk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1806278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3c785b99ec147049caa47f707f337b717705970",
            "isKey": false,
            "numCitedBy": 6554,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation."
            },
            "slug": "SLIC-Superpixels-Compared-to-State-of-the-Art-Achanta-Shaji",
            "title": {
                "fragments": [],
                "text": "SLIC Superpixels Compared to State-of-the-Art Superpixel Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new superpixel algorithm is introduced, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels and is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2393145"
                        ],
                        "name": "S. Katz",
                        "slug": "S.-Katz",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Katz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190047"
                        ],
                        "name": "G. Leifman",
                        "slug": "G.-Leifman",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Leifman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leifman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226509"
                        ],
                        "name": "A. Tal",
                        "slug": "A.-Tal",
                        "structuredName": {
                            "firstName": "Ayellet",
                            "lastName": "Tal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 256
                            }
                        ],
                        "text": "Scientific scope of this survey Segmentation algorithms can be applied to document images but also to a set of document images (in order to segment a book into its chapters by instance), to natural images [16], to medical images [17] and even to 3D meshes [18]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14495985,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b6722944cc4c9ab11a837273ce2732cacb4f38e",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Mesh segmentation has become a necessary ingredient in many applications in computer graphics. This paper proposes a novel hierarchical mesh segmentation algorithm, which is based on new methods for prominent feature point and core extraction. The algorithm has several benefits. First, it is invariant both to the pose of the model and to different proportions between the model\u2019s components. Second, it produces correct hierarchical segmentations of meshes, both in the coarse levels of the hierarchy and in the fine levels, where tiny segments are extracted. Finally, the boundaries between the segments go along the natural seams of the models."
            },
            "slug": "Mesh-segmentation-using-feature-point-and-core-Katz-Leifman",
            "title": {
                "fragments": [],
                "text": "Mesh segmentation using feature point and core extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A novel hierarchical mesh segmentation algorithm, which is based on new methods for prominent feature point and core extraction, which produces correct hierarchical segmentations of meshes, both in the coarse levels of the hierarchy and in the fine levels, where tiny segments are extracted."
            },
            "venue": {
                "fragments": [],
                "text": "The Visual Computer"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3191442"
                        ],
                        "name": "E. Grosicki",
                        "slug": "E.-Grosicki",
                        "structuredName": {
                            "firstName": "Emmanu\u00e8le",
                            "lastName": "Grosicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Grosicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801094"
                        ],
                        "name": "H. E. Abed",
                        "slug": "H.-E.-Abed",
                        "structuredName": {
                            "firstName": "Haikal",
                            "lastName": "Abed",
                            "middleNames": [
                                "El"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. E. Abed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 87
                            }
                        ],
                        "text": "RIMES is a data set of handwritten letters that has been used for several competitions [123, 124]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7536616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbcdab5afc0553b85325fe18cd346bdbf0fbb74c",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the handwriting recognition competitionheld at ICDAR 2009. This competition is based onthe RIMES-database, with French written text documents.These document are classified in three different categories,complete text pages, words, and isolated characters. Thisyear 10 systems were submitted for the handwritten recognitioncompetition on snippets of French words. The systemswere evaluated in three subtask depending of the sizes ofthe used dictionary. A comparison between different classificationand recognition systems show interesting results. Ashort description of the participating groups, their systems,and the results achieved are presented."
            },
            "slug": "ICDAR-2009-Handwriting-Recognition-Competition-Grosicki-Abed",
            "title": {
                "fragments": [],
                "text": "ICDAR 2009 Handwriting Recognition Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "This paper describes the handwriting recognition competition held at ICDAR 2009, based on the RIMES-database, with French written text documents, which shows interesting results."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47904794"
                        ],
                        "name": "Yongtao Wang",
                        "slug": "Yongtao-Wang",
                        "structuredName": {
                            "firstName": "Yongtao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongtao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49455255"
                        ],
                        "name": "Yafeng Zhou",
                        "slug": "Yafeng-Zhou",
                        "structuredName": {
                            "firstName": "Yafeng",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yafeng Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143830636"
                        ],
                        "name": "Zhi Tang",
                        "slug": "Zhi-Tang",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Tang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 124
                            }
                        ],
                        "text": "Segmentation based on straight line identification algorithms Three contributions are based on straight line identification [27, 49, 50]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[50] attempt to reconstruct the border of the frames in comic books 285"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "The algorithms that try to identify straight lines [27, 49, 50]: This can be done"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 70
                            }
                        ],
                        "text": "A last addition could be documents similar to comics such as those in [50, 68] In section 2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 37722943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de9bfb633f578c236413ac956179a24ca872a88f",
            "isKey": true,
            "numCitedBy": 12,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic comic frame extraction is the core technique for comic content adaptation. Typical algorithms segment a comic page into a set of frames using connected components or division lines, but they cannot produce frames without blank margins and there is still room for improvement for complex comic images. We present a method that identifies frame polygons via connected component labeling and line segments combination. We analyze lines within each component and preliminarily judge the frame type, and then we optimize an energy-like score function constrained by several rules to choose frames. Experimental results indicate an increase of both accuracy and F-score compared with previous methods."
            },
            "slug": "Comic-frame-extraction-via-line-segments-Wang-Zhou",
            "title": {
                "fragments": [],
                "text": "Comic frame extraction via line segments combination"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a method that identifies frame polygons via connected component labeling and line segments combination and optimize an energy-like score function constrained by several rules to choose frames."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828598"
                        ],
                        "name": "F. Paszkiewicz",
                        "slug": "F.-Paszkiewicz",
                        "structuredName": {
                            "firstName": "Filipe",
                            "lastName": "Paszkiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Paszkiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136076"
                        ],
                        "name": "A. Mar\u00e7al",
                        "slug": "A.-Mar\u00e7al",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Mar\u00e7al",
                            "middleNames": [
                                "R.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mar\u00e7al"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144453899"
                        ],
                        "name": "C. Guedes",
                        "slug": "C.-Guedes",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guedes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Guedes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "staff removal and direct recognition of music scores without any layout analysis [23]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12964479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46ec9789856ddab19e3d0011cadc08b419b533f3",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "For centuries, music has been shared and remembered by two traditions: aural transmission and in the form of written documents normally called musical scores. Many of these scores exist in the form of unpublished manuscripts and hence they are in danger of being lost through the normal ravages of time. To preserve the music some form of typesetting or, ideally, a computer system that can automatically decode the symbolic images and create new scores is required. Programs analogous to optical character recognition systems called optical music recognition (OMR) systems have been under intensive development for many years. However, the results to date are far from ideal. Each of the proposed methods emphasizes different properties and therefore makes it difficult to effectively evaluate its competitive advantages. This article provides an overview of the literature concerning the automatic analysis of images of printed and handwritten musical scores. For self-containment and for the benefit of the reader, an introduction to OMR processing systems precedes the literature overview. The following study presents a reference scheme for any researcher wanting to compare new OMR algorithms against well-known ones."
            },
            "slug": "Optical-music-recognition:-state-of-the-art-and-Rebelo-Fujinaga",
            "title": {
                "fragments": [],
                "text": "Optical music recognition: state-of-the-art and open issues"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An overview of the literature concerning the automatic analysis of images of printed and handwritten musical scores and a reference scheme for any researcher wanting to compare new OMR algorithms against well-known ones is presented."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Multimedia Information Retrieval"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "The overlapped text is separated at460\na pixel level with a third MRF and by using Shape Context Features (SCF) [122]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 73
                            }
                        ],
                        "text": "a pixel level with a third MRF and by using Shape Context Features (SCF) [122]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 129468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "faf8444bad76e8aa727c8b2df42fefe7b8242957",
            "isKey": false,
            "numCitedBy": 5812,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents my work on computing shape models that are computationally fast and invariant basic transformations like translation, scaling and rotation. In this paper, I propose shape detection using a feature called shape context. Shape context describes all boundary points of a shape with respect to any single boundary point. Thus it is descriptive of the shape of the object. Object recognition can be achieved by matching this feature with a priori knowledge of the shape context of the boundary points of the object. Experimental results are promising on handwritten digits, trademark images."
            },
            "slug": "Shape-matching-and-object-recognition-using-shape-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using shape contexts"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper presents work on computing shape models that are computationally fast and invariant basic transformations like translation, scaling and rotation, and proposes shape detection using a feature called shape context, which is descriptive of the shape of the object."
            },
            "venue": {
                "fragments": [],
                "text": "2010 3rd International Conference on Computer Science and Information Technology"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3191442"
                        ],
                        "name": "E. Grosicki",
                        "slug": "E.-Grosicki",
                        "structuredName": {
                            "firstName": "Emmanu\u00e8le",
                            "lastName": "Grosicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Grosicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801094"
                        ],
                        "name": "H. E. Abed",
                        "slug": "H.-E.-Abed",
                        "structuredName": {
                            "firstName": "Haikal",
                            "lastName": "Abed",
                            "middleNames": [
                                "El"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. E. Abed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 87
                            }
                        ],
                        "text": "RIMES is a data set of handwritten letters that has been used for several competitions [123, 124]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15685363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5abb3217c7dc19365abbfa35c98908dda9a9a5b4",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the French handwriting recognition competition held at ICDAR 2011. This competition is based on the RIMES-database composed of French written documents corresponding to letters sent by individuals to companies or administrations. Two tasks have been proposed this year : the first one consists in recognizing isolated snippets of words with the help of a given dictionary, the second one consists in recognizing blocks of words segmented into lines. This year 9 systems were submitted for the different competition subtasks. A comparison between different classification and recognition systems show interesting results. A short description of the participating groups, their systems, and the results achieved are presented."
            },
            "slug": "ICDAR-2011-French-Handwriting-Recognition-Grosicki-Abed",
            "title": {
                "fragments": [],
                "text": "ICDAR 2011 - French Handwriting Recognition Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This paper describes the French handwriting recognition competition held at ICDAR 2011, based on the RIMES-database composed of French written documents corresponding to letters sent by individuals to companies or administrations."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700931"
                        ],
                        "name": "David H. Douglas",
                        "slug": "David-H.-Douglas",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Douglas",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David H. Douglas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2531388"
                        ],
                        "name": "T. Peucker",
                        "slug": "T.-Peucker",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Peucker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Peucker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 73
                            }
                        ],
                        "text": "They separate the background then they use the Douglas-Peucker algorithm [119] to fit quadrangles onto the candidate frames."
                    },
                    "intents": []
                }
            ],
            "corpusId": 119823700,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e46ac802d7207e0e51b5333456a3f46519c2f92d",
            "isKey": false,
            "numCitedBy": 3705,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "All digitizing methods, as a general rule, record lines with far more data than is necessary for accurate graphic reproduction or for computer analysis. Two algorithms to reduce the number of points required to represent the line and, if desired, produce caricatures, are presented and compared with the most promising methods so far suggested. Line reduction will form a major part of automated generalization. Regle generale, les methodes numeriques enregistrent des lignes avec beaucoup plus de donnees qu'il n'est necessaire a la reproduction graphique precise ou a la recherche par ordinateur. L'auteur presente deux algorithmes pour reduire le nombre de points necessaires pour representer la ligne et produire des caricatures si desire, et les compare aux methodes les plus prometteuses suggerees jusqu'ici. La reduction de la ligne constituera une partie importante de la generalisation automatique."
            },
            "slug": "ALGORITHMS-FOR-THE-REDUCTION-OF-THE-NUMBER-OF-TO-A-Douglas-Peucker",
            "title": {
                "fragments": [],
                "text": "ALGORITHMS FOR THE REDUCTION OF THE NUMBER OF POINTS REQUIRED TO REPRESENT A DIGITIZED LINE OR ITS CARICATURE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105823197"
                        ],
                        "name": "Samuel J. Pinson",
                        "slug": "Samuel-J.-Pinson",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Pinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel J. Pinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055367"
                        ],
                        "name": "W. Barrett",
                        "slug": "W.-Barrett",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Barrett",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Barrett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12484875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91ba789fc7c21992e50db8ea12b870c14f0c6112",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We employ Eigenfaces to discriminate between handwritten and machine-printed text at the connected component (CC) level. Normalized images of machine print CCs are treated as points in a high-dimensional space. PCA yields a reduced-dimensional character space. Representative machine print CCs are projected into character space and a local distance threshold for each representative is automatically determined. CCs are classified as machine print if they are within the local distance threshold of their closest machine print representative. Otherwise, they are classified as handwriting. Recursive character segmentation using min graph cut is used to address the problem of touching characters. Validation over a large NIST handwriting and machine print database demonstrates precision of 93.98% and 89.1% for machine print and handwriting respectively."
            },
            "slug": "Connected-Component-Level-Discrimination-of-and-Pinson-Barrett",
            "title": {
                "fragments": [],
                "text": "Connected Component Level Discrimination of Handwritten and Machine-Printed Text Using Eigenfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Eigenfaces is employed to discriminate between handwritten and machine-printed text at the connected component (CC) level at the connection level to address the problem of touching characters."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739112"
                        ],
                        "name": "Jialin Peng",
                        "slug": "Jialin-Peng",
                        "structuredName": {
                            "firstName": "Jialin",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jialin Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109531996"
                        ],
                        "name": "Jinwei Wang",
                        "slug": "Jinwei-Wang",
                        "structuredName": {
                            "firstName": "Jinwei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinwei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35603119"
                        ],
                        "name": "D. Kong",
                        "slug": "D.-Kong",
                        "structuredName": {
                            "firstName": "Dexing",
                            "lastName": "Kong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "Scientific scope of this survey Segmentation algorithms can be applied to document images but also to a set of document images (in order to segment a book into its chapters by instance), to natural images [16], to medical images [17] and even to 3D meshes [18]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14360402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5bb950b443e65e98aa75d80470bfca1e3aa2cc9",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Due to intensity overlapping, blurred edges and complex backgrounds with clutter features, liver segmentation is still a challenging task. In this paper, we address it with a constrained convex variational model, which can definitely avoid leakage through anatomical knowledge from users. A novel heuristic intensity model is proposed to suppress irrelevant strong edges and constrain the segmentation. Both global and local region appearance information are integrated to model higher level features such as local context. As a result, weak liver boundaries and fine structures can be stably delineated according to the information from neighborhood and nearby layers. No precise prior segmentation is needed and few seeds without shape restriction, about three seeds, are adequate to capture fine structures. The initialization is also very easy. Moreover, an accelerated primal-dual algorithm is proposed to efficiently and globally optimize the model. Our method is validated on MICCAI dataset and produces a high score of 80.6. It can be used to segment other abdominal organs."
            },
            "slug": "A-new-convex-variational-model-for-liver-Peng-Wang",
            "title": {
                "fragments": [],
                "text": "A new convex variational model for liver segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper addresses liver segmentation with a constrained convex variational model, which can definitely avoid leakage through anatomical knowledge from users and an accelerated primal-dual algorithm is proposed to efficiently and globally optimize the model."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3662180"
                        ],
                        "name": "G. Gelade",
                        "slug": "G.-Gelade",
                        "structuredName": {
                            "firstName": "Garry",
                            "lastName": "Gelade",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gelade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "This paradigm is related to the associationist and Gestalt theories of vision [1]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 353246,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "76361a44e145732a39dbc68d9418871038c83be2",
            "isKey": false,
            "numCitedBy": 11415,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-feature-integration-theory-of-attention-Treisman-Gelade",
            "title": {
                "fragments": [],
                "text": "A feature-integration theory of attention"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66092662"
                        ],
                        "name": "P. Daniels",
                        "slug": "P.-Daniels",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Daniels",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Daniels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "algorithms have been developed in the past [19] and in particular in paleography [20] but none was found during the time frame of this survey."
                    },
                    "intents": []
                }
            ],
            "corpusId": 162246617,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "65acf5d2d1389abfcf6994cbba753241ce2f0873",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "SOME sixty-five years ago James Henry Breasted published a paper in this journal entitled \"The Physical Processes of Writing in the Early Orient and Their Relation to the Origin of the Alphabet.\"' Among his assertions is that the pen a scribe used on papyrus was almost as much a brush as a pen. \"It was only when incoming parchment offered a hard writing surface,\" he claimed, \"that our sharp-pointed split pen came into use.\"2 Breasted, writing at the beginning of the calligraphy revival instituted around the turn of the century by Edward Johnston, may be forgiven for not specifying this \"sharp-pointed pen\" as a broad-edge or chisel-tipped pen. There is, however, no justification for the statement about parchment; the Assur and Nimrud ostraca, centuries earlier than the earliest evidence of parchment, are incontrovertibly written with a broad-edge pen, as are numerous Egyptian papyri dating back into the third millennium.3"
            },
            "slug": "A-Calligraphic-Approach-to-Aramaic-Paleography-Daniels",
            "title": {
                "fragments": [],
                "text": "A Calligraphic Approach to Aramaic Paleography"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Near Eastern Studies"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127116590"
                        ],
                        "name": "Thomas de Quincey",
                        "slug": "Thomas-de-Quincey",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "de Quincey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas de Quincey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[42] Any No BW Yes No Regions Horizontal Straight 3742 2 1 [30] Any No BW Yes No Regions + text lines Horizontal Straight 185 2 2"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[42] use several combinations of erosion and dilation to efficiently identify successively the pictures, the graphics and the text."
                    },
                    "intents": []
                }
            ],
            "corpusId": 239491155,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "927881a5602f430ffd145d44b8c35cf7a07b464d",
            "isKey": false,
            "numCitedBy": 69792,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In supernova (SN) spectroscopy relatively little attention has been given to the properties of optically thick spectral lines in epochs following the photosphere\u2019s recession. Most treatments and analyses of post-photospheric optical spectra of SNe assume that forbidden-line emission comprises most if not all spectral features. However, evidence exists that suggests that some spectra exhibit line profiles formed via optically thick resonance-scattering even months or years after the SN explosion. To explore this possibility, we present a geometrical approach to SN spectrum formation based on the \u201cElementary Supernova\u201d model, wherein we investigate the characteristics of resonance-scattering in optically thick lines while replacing the photosphere with a transparent central core emitting non-blackbody continuum radiation, akin to the optical continuum provided by decaying 56Co formed during the explosion. We develop the mathematical framework necessary for solving the radiative transfer equation under these conditions and calculate spectra for both isolated and blended lines. Our comparisons with analogous results from the Elementary Supernova code SYNOW reveal several marked differences in line formation. Most notably, resonance lines in these conditions form P Cygni-like profiles, but the emission peaks and absorption troughs shift redward and blueward, respectively, from the line\u2019s rest wavelength by a significant amount, despite the spherically symmetric distribution of the line optical depth in the ejecta. These properties and others that we find in this work could lead to misidentification of lines or misattribution of properties of line-forming material at post-photospheric times in SN optical spectra."
            },
            "slug": "[C]-Quincey",
            "title": {
                "fragments": [],
                "text": "[C]"
            },
            "venue": {
                "fragments": [],
                "text": "The Works of Thomas De Quincey, Vol. 1: Writings, 1799\u20131820"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1619078806"
                        ],
                        "name": "A. ADoefaa",
                        "slug": "A.-ADoefaa",
                        "structuredName": {
                            "firstName": "A",
                            "lastName": "ADoefaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. ADoefaa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1619192001"
                        ],
                        "name": "H. P. Doetsch",
                        "slug": "H.-P.-Doetsch",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Doetsch",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. P. Doetsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1619263939"
                        ],
                        "name": "Draweng Table",
                        "slug": "Draweng-Table",
                        "structuredName": {
                            "firstName": "Draweng",
                            "lastName": "Table",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Draweng Table"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1619192001"
                        ],
                        "name": "H. P. Doetsch",
                        "slug": "H.-P.-Doetsch",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Doetsch",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. P. Doetsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 124
                            }
                        ],
                        "text": "Segmentation based on straight line identification algorithms Three contributions are based on straight line identification [27, 49, 50]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[49] analyze the white spaces to segment the document into text columns."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "The algorithms that try to identify straight lines [27, 49, 50]: This can be done"
                    },
                    "intents": []
                }
            ],
            "corpusId": 207877176,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d8daa2f46de22a0bf06ec5174d4fdbc650d4239b",
            "isKey": false,
            "numCitedBy": 143623,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "OF THE DISCLOSURE A gas Spring for a drawing table which has a cylinder, a piston in the cylinder, and a piston rod projecting from the piston through one end wall of the cylinder, the other end wall being imperforate. Gas under pressure fills the cylinder and may be released from the chamber adjacent the piston rod if the latter is almost fully expelled from the cylinder against a compression spring through a chan nel having orifices in the piston and in the piston rod. Additional gas is admitted to the cylinder of a modified Spring when the piston rod is almost fully retracted into the cylinder and the piston strikes a normally closed valve Separating the cylinder cavity from a storage chamber. SLSSSMSSSLSSSSTSSSTSS The present invention relates to a weight-compensating and equilibrium-maintaining device, and it is the principal object of this invention to provide a very simple and inexpensive device in the form of a so-called gas spring for compensating the weight or maintaining the equi librium of any device or apparatus which is adjustable to different levels or inclinations and for permitting such adjustments to be carried out with the least possible physi cal effort. Among the numerous types of devices and appa ratus to which the present invention may be applied may be mentioned especially: drawing tables, X-ray apparatus, hair driers, tilting doors and windows, covers for large freezer chests, and so forth. In connection with such devices or apparatus it is con ventionai to balance their weight or to maintain their equi librium by the provision of counterweights or coil springs. The employment of counterweights has the disadvantage that they require considerable space and also considerably increase the weight of the entire apparatus. The use of coil springs, on the other hand, has the disadvantage that the operations of compressing or expanding such springs require a considerable force and either require or result in considerable changes inforce which have to be compen sated by special mechanical means such as levers, cams, or other force-transmitting means which considerably in crease the cost of the respective apparatus. Another device which has previously been employed for the above-mentioned purposes is a so-called gas spring which consists of a pneumatic cylinder and piston unit in which the cylinder is filled with a pressure gas, for exam ple, compressed air. Although very successful when spe cially designed for a specific apparatus, these gas springs have the disadvantage that each of them has a very par ticular spring characteristic and that therefore a large number of different gas springs have to be produced and be held available for compensating the different forces of different devices or apparatus and even for compen sating differences in force which might be due to inac curacies of manufacture of an individual apparatus of a series thereof. When such gas springs are to be installed, for example, on a drawing table, it is evident that dif ferent gas springs would be required either for merely balancing the weight of the drawing board itself or for 0."
            },
            "slug": "F-ADoefaa-Doetsch",
            "title": {
                "fragments": [],
                "text": "F"
            },
            "venue": {
                "fragments": [],
                "text": "The Herodotus Encyclopedia"
            },
            "year": 1934
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "If needed [6, 7] provide a very good introduction to them."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Kise\u2019s survey in 2014 [7] - which is mostly and introduction to the field - only cites papers before 2007."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "From a different perspective, Kise [7] classifies first the algorithms according to\ntheir capability of segmenting documents with overlapping layouts such as a stamp on140\ntop of some text."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "From a different perspective, Kise [7] classifies first the algorithms according to their capability of segmenting documents with overlapping layouts such as a stamp on 140"
                    },
                    "intents": []
                }
            ],
            "corpusId": 44958840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc0640397925aacf48e325dd924e8bba00f56479",
            "isKey": true,
            "numCitedBy": 20,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Page-Segmentation-Techniques-in-Document-Analysis-Kise",
            "title": {
                "fragments": [],
                "text": "Page Segmentation Techniques in Document Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Document Image Processing and Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932720"
                        ],
                        "name": "G. Alagic",
                        "slug": "G.-Alagic",
                        "structuredName": {
                            "firstName": "Gorjan",
                            "lastName": "Alagic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Alagic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31441574"
                        ],
                        "name": "Catharine Lo",
                        "slug": "Catharine-Lo",
                        "structuredName": {
                            "firstName": "Catharine",
                            "lastName": "Lo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catharine Lo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "108074239"
                        ],
                        "name": "Phanuel Chuka Hakwendenda",
                        "slug": "Phanuel-Chuka-Hakwendenda",
                        "structuredName": {
                            "firstName": "Phanuel",
                            "lastName": "Hakwendenda",
                            "middleNames": [
                                "Chuka"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Phanuel Chuka Hakwendenda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "rithms [22] and found that they all have a very poor stability."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "evaluation of the stability of segmentation algorithms as done in [22]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "While natural image segmentation algorithms are not made for document images, that does not mean that they cannot perform this task as shown in a recent study [22]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 233455290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bc63a1a3c0a5bb66af7bb61c34e379658820f90",
            "isKey": true,
            "numCitedBy": 59401,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "#p-Alagic-Lo",
            "title": {
                "fragments": [],
                "text": "#p"
            },
            "venue": {
                "fragments": [],
                "text": "Quantum Inf. Comput."
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[106] compare the performance of SVM, MLP and GMM (Gaussian mixture model) classifiers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 253
                            }
                        ],
                        "text": "Table 1 \u2013 continued from previous page AlgorithmInput layout Multilayered Color depth Labels Training Type of output Text orientation Text alignment Data set test size Nb of languages Nb of doc types [109] Any No Color Yes Yes Regions Any Curved 49 3 2 [106] Any No Color Yes Yes Regions Any Curved 49 3 2 [114] Any No Color No Yes Text lines Any Curved 214 3 3 [116] Any No Color No Yes Text lines Horizontal Straight 1072 3 6 [100] Any No Gray Yes Yes Regions Any Curved 86 3 1 [102] Any No Gray Yes Yes Regions + text lines Any Curved 501 1 2"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of SVM"
            },
            "venue": {
                "fragments": [],
                "text": "MLP and GMM classifiers for layout analysis of historical documents, in: Proc. of 12th ICDAR, IEEE"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 40
                            }
                        ],
                        "text": "They were first published in 2006220\nby Cou\u0308asnon [117] and tested on a data set of 88745 documents which is an unrivaled data set size."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 12
                            }
                        ],
                        "text": "by Co\u00fcasnon [117] and tested on a data set of 88745 documents which is an unrivaled data set size."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DMOS"
            },
            "venue": {
                "fragments": [],
                "text": "a generic document recognition method: application to table structure analysis in a general and in a specific way, IJDAR 8 (2-3) "
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "Baird and Casey [125] denote this as evaluation based on \u201cconfidence before accuracy\u201d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 26
                            }
                        ],
                        "text": "Moreover, Baird and Casey [125] advocate for versatile algorithms."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards versatile DAS"
            },
            "venue": {
                "fragments": [],
                "text": "in: Proc. of DAS VII, Springer Berlin Heidelberg"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ridges based curled textline region detection from grayscale  935 camera-captured document"
            },
            "venue": {
                "fragments": [],
                "text": "in: Proc. of Computer Analysis of Images and Patterns (CAIP), Springer- Verlag"
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 133,
        "totalPages": 14
    },
    "page_url": "https://www.semanticscholar.org/paper/A-comprehensive-survey-of-mostly-textual-document-Eskenazi-Gomez-Kr\u00e4mer/08ab557e132322a5f161d7ddee4ad2a42b806621?sort=total-citations"
}