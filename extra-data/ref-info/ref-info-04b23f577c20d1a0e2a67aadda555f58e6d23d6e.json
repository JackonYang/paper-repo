{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9094007"
                        ],
                        "name": "Yuh-Jye Lee",
                        "slug": "Yuh-Jye-Lee",
                        "structuredName": {
                            "firstName": "Yuh-Jye",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuh-Jye Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11436439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7a7e37b5cfae27dcd9d99765a36ff6fd30e730b",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Smoothing methods, extensively used for solving important mathematical programming problems and applications, are applied here to generate and solve an unconstrained smooth reformulation of the support vector machine for pattern classification using a completely arbitrary kernel. We term such reformulation a smooth support vector machine (SSVM). A fast Newton\u2013Armijo algorithm for solving the SSVM converges globally and quadratically. Numerical results and comparisons are given to demonstrate the effectiveness and speed of the algorithm. On six publicly available datasets, tenfold cross validation correctness of SSVM was the highest compared with four other methods as well as the fastest. On larger problems, SSVM was comparable or faster than SVMlight (T. Joachims, in Advances in Kernel Methods\u2014Support Vector Learning, MIT Press: Cambridge, MA, 1999), SOR (O.L. Mangasarian and David R. Musicant, IEEE Transactions on Neural Networks, vol. 10, pp. 1032\u20131037, 1999) and SMO (J. Platt, in Advances in Kernel Methods\u2014Support Vector Learning, MIT Press: Cambridge, MA, 1999). SSVM can also generate a highly nonlinear separating surface such as a checkerboard."
            },
            "slug": "SSVM:-A-Smooth-Support-Vector-Machine-for-Lee-Mangasarian",
            "title": {
                "fragments": [],
                "text": "SSVM: A Smooth Support Vector Machine for Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Smoothing methods are applied here to generate and solve an unconstrained smooth reformulation of the support vector machine for pattern classification using a completely arbitrary kernel, which converges globally and quadratically."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Optim. Appl."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60502900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c4da62e9e89e65ac78ee271e424e8b498053e8c",
            "isKey": false,
            "numCitedBy": 5544,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al."
            },
            "slug": "Advances-in-kernel-methods:-support-vector-learning-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Advances in kernel methods: support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Support vector machines for dynamic reconstruction of a chaotic system, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050470845"
                        ],
                        "name": "H. Drucker",
                        "slug": "H.-Drucker",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Drucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116668597"
                        ],
                        "name": "Donghui Wu",
                        "slug": "Donghui-Wu",
                        "structuredName": {
                            "firstName": "Donghui",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donghui Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14895712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29fa9b903dbd8d19e39b0d7fb06efc6a1907dfdb",
            "isKey": false,
            "numCitedBy": 1429,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the use of support vector machines (SVM's) in classifying e-mail as spam or nonspam by comparing it to three other classification algorithms: Ripper, Rocchio, and boosting decision trees. These four algorithms were tested on two different data sets: one data set where the number of features were constrained to the 1000 best features and another data set where the dimensionality was over 7000. SVM's performed best when using binary features. For both data sets, boosting trees and SVM's had acceptable test performance in terms of accuracy and speed. However, SVM's had significantly less training time."
            },
            "slug": "Support-vector-machines-for-spam-categorization-Drucker-Wu",
            "title": {
                "fragments": [],
                "text": "Support vector machines for spam categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The use of support vector machines in classifying e-mail as spam or nonspam is studied by comparing it to three other classification algorithms: Ripper, Rocchio, and boosting decision trees, which found SVM's performed best when using binary features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "This is because an SVM can be seen as a linear algorithm in a high-dimensional space [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Similar to the pattern-recognition case, this can be written as a quadratic programming problem in terms of kernels [13] (see [6] for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2526394,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2773c7f8ff48d33b88f8e4c33bedcbe18074c73",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Bernhard Sch\u00f6lkopf, GMD First Is there anything worthwhile to learn about the new SVM algorithm, or does it fall into the category of \u201cyet-another-algorithm,\u201d in which case readers should stop here and save their time for something more useful? In this short overview, I will try to argue that studying support-vector learning is very useful in two respects. First, it is quite satisfying from a theoretical point of view: SV learning is based on some beautifully simple ideas and provides a clear intuition of what learning from examples is about. Second, it can lead to high performances in practical applications. In the following sense can the SV algorithm be considered as lying at the intersection of learning theory and practice: for certain simple types of algorithms, statistical learning theory can identify rather precisely the factors that need to be taken into account to learn successfully. Real-world applications, however, often mandate the use of more complex models and algorithms\u2014such as neural networks\u2014that are much harder to analyze theoretically. The SV algorithm achieves both. It constructs models that are complex enough: it contains a large class of neural nets, radial basis function (RBF) nets, and polynomial classifiers as special cases. Yet it is simple enough to be analyzed mathematically, because it can be shown to correspond to a linear method in a high-dimensional feature space nonlinearly related to input space. Moreover, even though we can think of it as a linear algorithm in a high-dimensional space, in practice, it does not involve any computations in that high-dimensional space. By the use of kernels, all necessary computations are performed directly in input space. This is the characteristic twist of SV methods\u2014we are dealing with complex algorithms for nonlinear pattern recognition, 1 regression, 2 or feature extraction,3 but for the sake of analysis and algorithmics, we can pretend that we are working with a simple linear algorithm. I will explain the gist of SV methods by describing their roots in learning theory, the optimal hyperplane algorithm, the kernel trick, and SV function estimation. For details and further references, see Vladimir Vapnik\u2019s authoritative treatment, 2 he collection my colleagues and I have put together, 4 and the SV Web page at http://svm. first.gmd.de."
            },
            "slug": "SVMs\u2014a-practical-consequence-of-learning-theory-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "SVMs\u2014a practical consequence of learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that studying support-vector learning is very useful in two respects: first, it is quite satisfying from a theoretical point of view: SV learning is based on some beautifully simple ideas and provides a clear intuition of what learning from examples is about and second, it can lead to high performances in practical applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145728220"
                        ],
                        "name": "K. Bennett",
                        "slug": "K.-Bennett",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Bennett",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116668597"
                        ],
                        "name": "Donghui Wu",
                        "slug": "Donghui-Wu",
                        "structuredName": {
                            "firstName": "Donghui",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donghui Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2894031"
                        ],
                        "name": "Leonardo Auslender",
                        "slug": "Leonardo-Auslender",
                        "structuredName": {
                            "firstName": "Leonardo",
                            "lastName": "Auslender",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leonardo Auslender"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15043488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a64fec49a357f1b206eeabdb3f79ec041eaed61",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a support vector decision tree method for customer targeting in the framework of large databases (database marketing). The goal is to provide a tool to identify the best customers based on historical data. This tool is then used to forecast the best potential customers among a pool of prospects. We begin by regressively constructing a decision tree. Each decision consists of a linear combination of independent attributes. A linear program motivated by the support vector machine method from Vapnik's statistical learning theory is used to construct each decision. This linear program automatically selects the relevant subset of attributes for each decision. Each customer is scored based on the decision tree. A gain chart table is used to verify the goodness-of-fit of the targeting, to determine the likely prospects and the expected utility or profit. Successful results are given for three industrial problems."
            },
            "slug": "On-support-vector-decision-trees-for-database-Bennett-Wu",
            "title": {
                "fragments": [],
                "text": "On support vector decision trees for database marketing"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A support vector decision tree method for customer targeting in the framework of large databases (database marketing) is introduced to provide a tool to identify the best customers based on historical data."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144379841"
                        ],
                        "name": "M. P. Brown",
                        "slug": "M.-P.-Brown",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Brown",
                            "middleNames": [
                                "P.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2361327"
                        ],
                        "name": "W. Grundy",
                        "slug": "W.-Grundy",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Grundy",
                            "middleNames": [
                                "Noble"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116443182"
                        ],
                        "name": "D. Lin",
                        "slug": "D.-Lin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lin",
                            "middleNames": [
                                "Yin-wei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070640"
                        ],
                        "name": "C. Sugnet",
                        "slug": "C.-Sugnet",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Sugnet",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sugnet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716986"
                        ],
                        "name": "T. Furey",
                        "slug": "T.-Furey",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Furey",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Furey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145729499"
                        ],
                        "name": "M. Ares",
                        "slug": "M.-Ares",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Ares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "These include text categorisation [7, 8], image classification [5, 10\u201312], biosequence analysis and biological data mining [3] and handwritten character recognition [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2698102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a86171e13f84fe32212dd7fb6a1c31a34a47155f",
            "isKey": false,
            "numCitedBy": 2328,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method of functionally classifying genes by using gene expression data from DNA microarray hybridization experiments. The method is based on the theory of support vector machines (SVMs). SVMs are considered a supervised computer learning method because they exploit prior knowledge of gene function to identify unknown genes of similar function from expression data. SVMs avoid several problems associated with unsupervised clustering methods, such as hierarchical clustering and self-organizing maps. SVMs have many mathematical features that make them attractive for gene expression analysis, including their flexibility in choosing a similarity function, sparseness of solution when dealing with large data sets, the ability to handle large feature spaces, and the ability to identify outliers. We test several SVMs that use different similarity metrics, as well as some other supervised learning methods, and find that the SVMs best identify sets of genes with a common function using expression data. Finally, we use SVMs to predict functional roles for uncharacterized yeast ORFs based on their expression data."
            },
            "slug": "Knowledge-based-analysis-of-microarray-gene-data-by-Brown-Grundy",
            "title": {
                "fragments": [],
                "text": "Knowledge-based analysis of microarray gene expression data by using support vector machines."
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A method of functionally classifying genes by using gene expression data from DNA microarray hybridization experiments, based on the theory of support vector machines (SVMs), to predict functional roles for uncharacterized yeast ORFs based on their expression data is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14591650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8",
            "isKey": false,
            "numCitedBy": 3047,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more."
            },
            "slug": "Transductive-Inference-for-Text-Classification-Joachims",
            "title": {
                "fragments": [],
                "text": "Transductive Inference for Text Classification using Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An analysis of why Transductive Support Vector Machines are well suited for text classi cation is presented, and an algorithm for training TSVMs, handling 10,000 examples and more is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675811"
                        ],
                        "name": "Sayan Mukherjee",
                        "slug": "Sayan-Mukherjee",
                        "structuredName": {
                            "firstName": "Sayan",
                            "lastName": "Mukherjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sayan Mukherjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16950792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d81512c6c2582fa91fe151efdaf80a867f66d12a",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel method for regression has been recently proposed by Vapnik et al. (1995, 1996). The technique, called support vector machine (SVM), is very well founded from the mathematical point of view and seems to provide a new insight in function approximation. We implemented the SVM and tested it on a database of chaotic time series previously used to compare the performances of different approximation techniques, including polynomial and rational approximation, local polynomial techniques, radial basis functions, and neural networks. The SVM performs better than the other approaches. We also study, for a particular time series, the variability in performance with respect to the few free parameters of SVM."
            },
            "slug": "Nonlinear-prediction-of-chaotic-time-series-using-Mukherjee-Osuna",
            "title": {
                "fragments": [],
                "text": "Nonlinear prediction of chaotic time series using support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The SVM is implemented and tested on a database of chaotic time series previously used to compare the performances of different approximation techniques, including polynomial and rational approximation, localPolynomial techniques, radial basis functions, and neural networks; the SVM performs better than the other approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing VII. Proceedings of the 1997 IEEE Signal Processing Society Workshop"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712063"
                        ],
                        "name": "C. Bahlmann",
                        "slug": "C.-Bahlmann",
                        "structuredName": {
                            "firstName": "Claus",
                            "lastName": "Bahlmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bahlmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2800929"
                        ],
                        "name": "B. Haasdonk",
                        "slug": "B.-Haasdonk",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Haasdonk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Haasdonk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36736177"
                        ],
                        "name": "H. Burkhardt",
                        "slug": "H.-Burkhardt",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Burkhardt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Burkhardt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6477991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f1cb9b92d9a4d3761027c650bc41409592afa78",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a novel classification approach for online handwriting recognition. The technique combines dynamic time warping (DTW) and support vector machines (SVMs) by establishing a new SVM kernel. We call this kernel Gaussian DTW (GDTW) kernel. This kernel approach has a main advantage over common HMM techniques. It does not assume a model for the generative class conditional densities. Instead, it directly addresses the problem of discrimination by creating class boundaries and thus is less sensitive to modeling assumptions. By incorporating DTW in the kernel function, general classification problems with variable-sized sequential data can be handled. In this respect the proposed method can be straightforwardly applied to all classification problems, where DTW gives a reasonable distance measure, e.g., speech recognition or genome processing. We show experiments with this kernel approach on the UNIPEN handwriting data, achieving results comparable to an HMM-based technique."
            },
            "slug": "Online-handwriting-recognition-with-support-vector-Bahlmann-Haasdonk",
            "title": {
                "fragments": [],
                "text": "Online handwriting recognition with support vector machines - a kernel approach"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel classification approach for online handwriting recognition is described that combines dynamic time warping (DTW) and support vector machines (SVMs) by establishing a new SVM kernel that is directly addresses the problem of discrimination by creating class boundaries and thus is less sensitive to modeling assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2703537"
                        ],
                        "name": "M. Rychetsky",
                        "slug": "M.-Rychetsky",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Rychetsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rychetsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21279206"
                        ],
                        "name": "S. Ortmann",
                        "slug": "S.-Ortmann",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Ortmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ortmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695280"
                        ],
                        "name": "M. Glesner",
                        "slug": "M.-Glesner",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Glesner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Glesner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 467,
                                "start": 434
                            }
                        ],
                        "text": "For instance the following examples,\n- Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 476,
                                "start": 468
                            }
                        ],
                        "text": "For instance the following examples, - Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28167647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b39d37f7cf450dbb50fa0884d1a2d76e5785c5c",
            "isKey": true,
            "numCitedBy": 50,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We show the application of large margin classifiers to the real world problem of engine knock detection. Large margin classifiers, like support vector machines (SVM) or the Adatron, promise a good generalization performance. Furthermore, the support vector approach has some bounds (e.g. for generalization error and learning convergence) which give this technique a more firm background than the neural network leaning algorithms. One drawback of the SVM, especially the Adatron, is that they tend to produce classification systems which need large computational effort for recall. This is caused by the fact that support vectors are normally sparse, but their number of calls is high. Therefore, we propose here a method which prunes (removes) support vectors that are less important. By an adjustment of the training data and remaining steps of the classifier a performance degradation is avoided."
            },
            "slug": "Support-vector-approaches-for-engine-knock-Rychetsky-Ortmann",
            "title": {
                "fragments": [],
                "text": "Support vector approaches for engine knock detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes here a method which prunes (removes) support vectors that are less important, by an adjustment of the training data and remaining steps of the classifier a performance degradation is avoided."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2427083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "isKey": false,
            "numCitedBy": 8601,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning."
            },
            "slug": "Text-Categorization-with-Support-Vector-Machines:-Joachims",
            "title": {
                "fragments": [],
                "text": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper explores the use of Support Vector Machines for learning text classifiers from examples and analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152597562"
                        ],
                        "name": "Gunnar R\u00e4tsch",
                        "slug": "Gunnar-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2633352"
                        ],
                        "name": "J. Kohlmorgen",
                        "slug": "J.-Kohlmorgen",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Kohlmorgen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kohlmorgen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5398743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f43840dc1638a18eb6178f1060dc5f41af1c5ac7",
            "isKey": false,
            "numCitedBy": 975,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Machines are used for time series prediction and compared to radial basis function networks. We make use of two different cost functions for Support Vectors: training with (i) an e insensitive loss and (ii) Huber's robust loss function and discuss how to choose the regularization parameters in these models. Two applications are considered: data from (a) a noisy (normal and uniform noise) Mackey Glass equation and (b) the Santa Fe competition (set D). In both cases Support Vector Machines show an excellent performance. In case (b) the Support Vector approach improves the best known result on the benchmark by a factor of 29%."
            },
            "slug": "Predicting-Time-Series-with-Support-Vector-Machines-M\u00fcller-Smola",
            "title": {
                "fragments": [],
                "text": "Predicting Time Series with Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two different cost functions for Support Vectors are made use: training with an e insensitive loss and Huber's robust loss function and how to choose the regularization parameters in these models are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102944324"
                        ],
                        "name": "Vapnik",
                        "slug": "Vapnik",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Vapnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17719593,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3473ce22ada00842b355883a5ddde5a8c7c76ba6",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that Support Vector Machines (SVM) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x,y) = e\u2212\u03c1 P i |x i \u2212y i | with a \u2264 1 and b \u2264 2 are evaluated on the classification of images extracted from the Corel Stock Photo Collection and shown to far outperform traditional polynomial or Gaussian RBF kernels. Moreover, we observed that a simple remapping of the input xi \u2192 x a i improves the performance of linear SVMs to such an extend that it makes them, for this problem, a valid alternative to RBF kernels. keywords: Support Vector Machines, Radial Basis Functions, Image Histogram, Image Classification, Corel."
            },
            "slug": "SVMs-for-Histogram-Based-Image-Classification-Chapelle-Haffner",
            "title": {
                "fragments": [],
                "text": "SVMs for Histogram Based Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper shows that Support Vector Machines (SVM) can generalize well on difficult image classification problems where the only features are high dimensional histograms and observes that a simple remapping of the input xi \u2192 x a i improves the performance of linear SVMs to such an extend that it makes them a valid alternative to RBF kernels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 100
                            }
                        ],
                        "text": "To deal with the non separable case an error tolerance can be introduced as described by Cortes and Vapnik, [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 165
                            }
                        ],
                        "text": "These include text categorisation [7, 8], image classification [5, 10\u201312], biosequence analysis and biological data mining [3] and handwritten character recognition [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 83
                            }
                        ],
                        "text": "For more details on the specific maths behind this and the full Lagrange proof see Vapnik\u2019s original work, [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 65
                            }
                        ],
                        "text": "The work of Boser et al, [8], was extended in 1995 by Cortes and Vapnik, [5], to include the handling of non-separable classes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 9
                            }
                        ],
                        "text": "Vladimir Vapnik argued that for a problem to be solved, it is necessary to avoid solving a more general problem as an intermediate step, i.e. when a division boundary between two classes has to be found, the computation of a probability density must be avoided."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Vapnik and Cortes, [5], show that to find the optimal set of weights,\nGiven, \u039bTo = (\u03b11, \u03b12 . . . , \u03b1l) (16)\nit is necessary to solve the following quadratic problem:\nW (\u039b) = \u039bT 1\u2212 1 2 \u039bT D\u039b (17)\nSubject to the following constraints\n\u039b \u2265 0, (18)\n\u039bT Y = 0, (19)\nwhere 1T = (1, 2, . . . , n) is an n-dimensional unit vector, Y T = (y1, y2, . . . , yn) is the n-dimensional vector of labels, and D is a symmetrical n \u2217nmatrix of dot product of the training vectors, multiplied by their labels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "Boser, Guyon and Vapnik [2], showed that a rather old trick [1]\u2014kernel functions\u2014can be used to accomplish the same result in a very simple and efficient way."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "Previously Vapnik had proposed a method of finding a hyperplane that optimally divided a search space, [39]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": true,
            "numCitedBy": 10840,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9094007"
                        ],
                        "name": "Yuh-Jye Lee",
                        "slug": "Yuh-Jye-Lee",
                        "structuredName": {
                            "firstName": "Yuh-Jye",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuh-Jye Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459584"
                        ],
                        "name": "W. Wolberg",
                        "slug": "W.-Wolberg",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Wolberg",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wolberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9427689,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "03d3d0d3b5409a116022b62499e409afd6747f84",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A linear support vector machine (SVM) is used to extract 6 features from a total of 31 features in a dataset of 253 breast cancer patients. Five features are nuclear features obtained during a non-invasive diagnostic procedure while one feature, tumor size, is obtained during surgery. The linear SVM selected the 6 features in the process of classifying the patients into node-positive (patients with some metastasized lymph nodes) and nodenegative (patients with no metastasized lymph nodes). Node-positive patients are typically those who undergo chemotherapy. The 6 features were then used in a Gaussian kernel nonlinear SVM to classify the patients into three prognostic groups: good (node-negative), intermediate (1 to 4 metastasized nodes) and poor (more than 4 metastasized nodes). Very well separated Kaplan-Meier survival curves were constructed for the three groups with pairwise p-value of less than 0.009 based on the logrank statistic. Patients in the good prognostic group had the highest survival, while patients in the poor prognostic group had the lowest. The majority (72.8%) of the good group did not receive chemotherapy, while the majority (87.5%) of the poor group received chemotherapy. Just over half (56.7%) of the intermediate group received chemotherapy. New patients can be assigned to one of these three prognostic groups with its associated survival curve, based only on 6 features obtained before and during surgery, but without the potentially risky procedure of removing lymph nodes to determine how many of them have metastasized."
            },
            "slug": "Breast-cancer-survival-and-chemotherapy:-A-support-Lee-Mangasarian",
            "title": {
                "fragments": [],
                "text": "Breast cancer survival and chemotherapy: A support vector machine analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "New patients can be assigned to one of these three prognostic groups with its associated survival curve, based only on 6 features obtained before and during surgery, but without the potentially risky procedure of removing lymph nodes to determine how many of them have metastasized."
            },
            "venue": {
                "fragments": [],
                "text": "Discrete Mathematical Problems with Medical Applications"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "The dot product can be replaced by a generalised dot product K(x, y) with any function which satisfies Mercer\u2019s theorem (see [5] for more details on Mercer\u2019s theorem)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "To deal with the non separable case an error tolerance can be introduced as described by Cortes and Vapnik, [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "The work of Boser et al, [8], was extended in 1995 by Cortes and Vapnik, [5], to include the handling of non-separable classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Vapnik and Cortes, [5], show that to find the optimal set of weights, Given, \u039bo = (\u03b11, \u03b12 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Vapnik and Cortes, [5], show that to find the optimal set of weights,\nGiven, \u039bTo = (\u03b11, \u03b12 . . . , \u03b1l) (16)\nit is necessary to solve the following quadratic problem:\nW (\u039b) = \u039bT 1\u2212 1 2 \u039bT D\u039b (17)\nSubject to the following constraints\n\u039b \u2265 0, (18)\n\u039bT Y = 0, (19)\nwhere 1T = (1, 2, . . . , n) is an n-dimensional unit vector, Y T = (y1, y2, . . . , yn) is the n-dimensional vector of labels, and D is a symmetrical n \u2217nmatrix of dot product of the training vectors, multiplied by their labels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "It can be shown [5], that, if the discrimination function is based on dot products, (equation 15), then there is no direct need to transform the input vectors to feature vectors before taking the dot product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52874011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52b7bf3ba59b31f362aa07f957f1543a29a4279e",
            "isKey": true,
            "numCitedBy": 33430,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "slug": "Support-Vector-Networks-Cortes-Vapnik",
            "title": {
                "fragments": [],
                "text": "Support-Vector Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated and the performance of the support- vector network is compared to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146325920"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "For further information on kernel methods relating to Support Vector Machines, see [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42131894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "506f516d8b60ba74e5ce811a458ec4fd72d714b2",
            "isKey": false,
            "numCitedBy": 916,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book is an introduction to support vector machines and related kernel methods in supervised learning, whose task is to estimate an input-output functional relationship from a training set of examples. A learning problem is referred to as classification if its output take discrete values in a set of possible categories and regression if it has continuous real-valued output."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Zhang",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This book is an introduction to support vector machines and related kernel methods in supervised learning, whose task is to estimate an input-output functional relationship from a training set of examples."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152318731"
                        ],
                        "name": "P. Vannerem",
                        "slug": "P.-Vannerem",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Vannerem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vannerem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087156364"
                        ],
                        "name": "K. Mueller",
                        "slug": "K.-Mueller",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Mueller",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mueller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30927799"
                        ],
                        "name": "B. Schoelkopf",
                        "slug": "B.-Schoelkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Schoelkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schoelkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116865041"
                        ],
                        "name": "A. Smola",
                        "slug": "A.-Smola",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388330985"
                        ],
                        "name": "S. Soldner-Rembold",
                        "slug": "S.-Soldner-Rembold",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Soldner-Rembold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soldner-Rembold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12051403,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "93e4f1677ff8689afee36c30d68bfedee27e3a7d",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have studied the application of different classification algorithms in the analysis of simulated high energy physics data. Whereas Neural Network algorithms have become a standard tool for data analysis, the performance of other classifiers such as Support Vector Machines has not yet been tested in this environment. We chose two different problems to compare the performance of a Support Vector Machine and a Neural Net trained with back-propagation: tagging events of the type e+e- -> ccbar and the identification of muons produced in multihadronic e+e- annihilation events."
            },
            "slug": "Classifying-LEP-data-with-support-vector-Vannerem-Mueller",
            "title": {
                "fragments": [],
                "text": "Classifying LEP data with support vector algorithms."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Two different problems are chosen to compare the performance of a Support Vector Machine and a Neural Net trained with back-propagation: tagging events of the type e+e- -> ccbar and the identification of muons produced in multihadronic e- annihilation events."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2562282"
                        ],
                        "name": "W. N. Street",
                        "slug": "W.-N.-Street",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Street",
                            "middleNames": [
                                "Nick"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. N. Street"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459584"
                        ],
                        "name": "W. Wolberg",
                        "slug": "W.-Wolberg",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Wolberg",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wolberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 231
                            }
                        ],
                        "text": "For instance the following examples,\n- Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 269
                            }
                        ],
                        "text": "For instance the following examples, - Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 583205,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "6a1b3266d2e68b67c398cce54cbafe83828053f8",
            "isKey": true,
            "numCitedBy": 803,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Two medical applications of linear programming are described in this paper. Specifically, linear programming-based machine learning techniques are used to increase the accuracy and objectivity of breast cancer diagnosis and prognosis. The first application to breast cancer diagnosis utilizes characteristics of individual cells, obtained from a minimally invasive fine needle aspirate, to discriminate benign from malignant breast lumps. This allows an accurate diagnosis without the need for a surgical biopsy. The diagnostic system in current operation at University of Wisconsin Hospitals was trained on samples from 569 patients and has had 100% chronological correctness in diagnosing 131 subsequent patients. The second application, recently put into clinical practice, is a method that constructs a surface that predicts when breast cancer is likely to recur in patients that have had their cancers excised. This gives the physician and the patient better information with which to plan treatment, and may eliminate the need for a prognostic surgical procedure. The novel feature of the predictive approach is the ability to handle cases for which cancer has not recurred (censored data) as well as cases for which cancer has recurred at a specific time. The prognostic system has an expected error of 13.9 to 18.3 months, which is better than prognosis correctness by other available techniques."
            },
            "slug": "Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-Mangasarian-Street",
            "title": {
                "fragments": [],
                "text": "Breast Cancer Diagnosis and Prognosis Via Linear Programming"
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934343"
                        ],
                        "name": "David Hecherman",
                        "slug": "David-Hecherman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hecherman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Hecherman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 34
                            }
                        ],
                        "text": "These include text categorisation [7, 8], image classification [5, 10\u201312], biosequence analysis and biological data mining [3] and handwritten character recognition [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 617436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02adea3455cd7b09e1dac9ddf2637a1e7ae84005",
            "isKey": false,
            "numCitedBy": 1291,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "1. ABSTRACT Text categorization \u2013 the assignment of natural language texts to one or more predefined categories based on their content \u2013 is an important component in many information organization and management tasks. We compare the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy. We also examine training set size, and alternative document representations. Very accurate text classifiers can be learned automatically from training examples. Linear Support Vector Machines (SVMs) are particularly promising because they are very accurate, quick to train, and quick to evaluate. 1.1"
            },
            "slug": "Inductive-learning-algorithms-and-representations-Dumais-Platt",
            "title": {
                "fragments": [],
                "text": "Inductive learning algorithms and representations for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A comparison of the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy is compared."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718382"
                        ],
                        "name": "S. Mukkamala",
                        "slug": "S.-Mukkamala",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Mukkamala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mukkamala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742050"
                        ],
                        "name": "A. Sung",
                        "slug": "A.-Sung",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Sung",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23224497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2e0189de61b11786bd84877590f3e08dc1ad814",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Due to increasing incidents of cyber attacks and heightened concerns for cyber terrorism, implementing effective intrusion detection systems (IDSs) is an essential task for protecting cyber security--as well as physical security because of the great dependence on networked computers for the operational control of various infrastructures. Building effective IDSs, unfortunately, has remained an elusive goal owing to the great technical challenges involved; and applied AI techniques are increasingly being utilized in attempts to overcome the difficulties. This paper presents a comparative study of using support vector machines (SVMs), artificial neural networks (ANNs), multivariate adaptive regression splines (MARS) and linear genetic programs (LGPs) for intrusion detection. We investigate and compare the performance of IDSs based on the mentioned techniques, with respect to a well-known set of intrusion evaluation data gathered by Lincoln Labs. Through a variety of experiments and analysis, it is found that, with appropriately chosen population size, program size, crossover rate and mutation rate, LGPs outperform other techniques in terms of detection accuracy at the expense of time. SVMs outperform MARS and ANNs in three critical aspects of intrusion detection: accuracy, training time, and testing time."
            },
            "slug": "A-comparative-study-of-techniques-for-intrusion-Mukkamala-Sung",
            "title": {
                "fragments": [],
                "text": "A comparative study of techniques for intrusion detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "SVMs outperform MARS and ANNs in three critical aspects of intrusion detection: accuracy, training time, and testing time; and, with appropriately chosen population size, program size, crossover rate and mutation rate, LGPs outperform other techniques in terms of detection accuracy at the expense of time."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 15th IEEE International Conference on Tools with Artificial Intelligence"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9094007"
                        ],
                        "name": "Yuh-Jye Lee",
                        "slug": "Yuh-Jye-Lee",
                        "structuredName": {
                            "firstName": "Yuh-Jye",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuh-Jye Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747026"
                        ],
                        "name": "O. Mangasarian",
                        "slug": "O.-Mangasarian",
                        "structuredName": {
                            "firstName": "Olvi",
                            "lastName": "Mangasarian",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mangasarian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459584"
                        ],
                        "name": "W. Wolberg",
                        "slug": "W.-Wolberg",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Wolberg",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wolberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6658702,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "b65e814077a0f8eac76580b6665ea08c0018acbf",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The identification of breast cancer patients for whom chemotherapy could prolong survival time is treated here as a data mining problem. This identification is achieved by clustering 253 breast cancer patients into three prognostic groups: Good, Poor and Intermediate. Each of the three groups has a significantly distinct Kaplan-Meier survival curve. Of particular significance is the Intermediate group, because patients with chemotherapy in this group do better than those without chemotherapy in the same group. This is the reverse case to that of the overall population of 253 patients for which patients undergoing chemotherapy have worse survival than those who do not. We also prescribe a procedure that utilizes three nonlinear smooth support vector machines (SSVMs) for classifying breast cancer patients into the three above prognostic groups. These results suggest that the patients in the Good group should not receive chemotherapy while those in the Intermediate group should receive chemotherapy based on our survival curve analysis. To our knowledge this is the first instance of a classifiable group of breast cancer patients for which chemotherapy can possibly enhance survival."
            },
            "slug": "Survival-Time-Classification-of-Breast-Cancer-Lee-Mangasarian",
            "title": {
                "fragments": [],
                "text": "Survival-Time Classification of Breast Cancer Patients"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is suggested that the patients in the Good group should not receive chemotherapy while those in the Intermediate group should receive chemotherapy based on the survival curve analysis, the first instance of a classifiable group of breast cancer patients for which chemotherapy can possibly enhance survival."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Optim. Appl."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118020225"
                        ],
                        "name": "Hyunsoo Kim",
                        "slug": "Hyunsoo-Kim",
                        "structuredName": {
                            "firstName": "Hyunsoo",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyunsoo Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685928"
                        ],
                        "name": "Haesun Park",
                        "slug": "Haesun-Park",
                        "structuredName": {
                            "firstName": "Haesun",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haesun Park"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 39
                            }
                        ],
                        "text": "For instance the following examples,\n- Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 68
                            }
                        ],
                        "text": "For instance the following examples, - Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5647130,
            "fieldsOfStudy": [
                "Computer Science",
                "Chemistry"
            ],
            "id": "b545effea74c974580e07babca03dd9e6d557d66",
            "isKey": true,
            "numCitedBy": 139,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "The prediction of protein relative solvent accessibility gives us helpful information for the prediction of tertiary structure of a protein. The SVMpsi method, which uses support vector machines (SVMs), and the position\u2010specific scoring matrix (PSSM) generated from PSI\u2010BLAST have been applied to achieve better prediction accuracy of the relative solvent accessibility. We have introduced a three\u2010dimensional local descriptor that contains information about the expected remote contacts by both the long\u2010range interaction matrix and neighbor sequences. Moreover, we applied feature weights to kernels in SVMs in order to consider the degree of significance that depends on the distance from the specific amino acid. Relative solvent accessibility based on a two state\u2010model, for 25%, 16%, 5%, and 0% accessibility are predicted at 78.7%, 80.7%, 82.4%, and 87.4% accuracy, respectively. Three\u2010state prediction results provide a 64.5% accuracy with 9%; 36% threshold. The support vector machine approach has successfully been applied for solvent accessibility prediction by considering long\u2010range interaction and handling unbalanced data. Proteins 2004;54:000\u2013000. \u00a9 2003 Wiley\u2010Liss, Inc."
            },
            "slug": "Prediction-of-protein-relative-solvent-with-support-Kim-Park",
            "title": {
                "fragments": [],
                "text": "Prediction of protein relative solvent accessibility with support vector machines and long\u2010range interaction 3D local descriptor"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The SVMpsi method, which uses support vector machines (SVMs), and the position\u2010specific scoring matrix (PSSM) generated from PSI\u2010BLAST have been applied to achieve better prediction accuracy of the relative solvent accessibility."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058177533"
                        ],
                        "name": "Simon Tong",
                        "slug": "Simon-Tong",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10743717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63861fbeb7ec41986b85965b9780b428d919919e",
            "isKey": false,
            "numCitedBy": 1510,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is often a critical component when designing image databases. With these databases it is difficult to specify queries directly and explicitly. Relevance feedback interactively determinines a user's desired output or query concept by asking the user whether certain proposed images are relevant or not. For a relevance feedback algorithm to be effective, it must grasp a user's query concept accurately and quickly, while also only asking the user to label a small number of images. We propose the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval. The algorithm selects the most informative images to query a user and quickly learns a boundary that separates the images that satisfy the user's query concept from the rest of the dataset. Experimental results show that our algorithm achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback."
            },
            "slug": "Support-vector-machine-active-learning-for-image-Tong-Chang",
            "title": {
                "fragments": [],
                "text": "Support vector machine active learning for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval and achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281542"
                        ],
                        "name": "A. Zien",
                        "slug": "A.-Zien",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Zien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459012"
                        ],
                        "name": "S. Mika",
                        "slug": "S.-Mika",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Mika",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mika"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21313583"
                        ],
                        "name": "C. Lemmen",
                        "slug": "C.-Lemmen",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lemmen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lemmen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49370597"
                        ],
                        "name": "Thomas Lengauer",
                        "slug": "Thomas-Lengauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Lengauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Lengauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2154417,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "bdb4a67b8e83de538965181f27bc070e68ced84c",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nIn order to extract protein sequences from nucleotide sequences, it is an important step to recognize points at which regions start that code for proteins. These points are called translation initiation sites (TIS).\n\n\nRESULTS\nThe task of finding TIS can be modeled as a classification problem. We demonstrate the applicability of support vector machines for this task, and show how to incorporate prior biological knowledge by engineering an appropriate kernel function. With the described techniques the recognition performance can be improved by 26% over leading existing approaches. We provide evidence that existing related methods (e.g. ESTScan) could profit from advanced TIS recognition."
            },
            "slug": "Engineering-Support-Vector-Machine-Kerneis-That-Zien-R\u00e4tsch",
            "title": {
                "fragments": [],
                "text": "Engineering Support Vector Machine Kerneis That Recognize Translation Initialion Sites"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "With the described techniques the recognition performance can be improved by 26% over leading existing approaches, and there is evidence that existing related methods could profit from advanced TIS recognition."
            },
            "venue": {
                "fragments": [],
                "text": "German Conference on Bioinformatics"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[36] showed that transforming not all training data, but only the support vectors, gives the same result, thereby avoiding a large increase of the size of the training set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9756494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55590f229e23a8e67af7d6d36f7456a595c251d1",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Developed only recently, support vector learning machines achieve high generalization ability by minimizing a bound on the expected test error; however, so far there existed no way of adding knowledge about invariances of a classification problem at hand. We present a method of incorporating prior knowledge about transformation invariances by applying transformations to support vectors, the training examples most critical for determining the classification boundary."
            },
            "slug": "Incorporating-Invariances-in-Support-Vector-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Incorporating Invariances in Support Vector Learning Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work presents a method of incorporating prior knowledge about transformation invariances by applying transformations to support vectors, the training examples most critical for determining the classification boundary."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1030170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e4ef37a4aeef7bf3747ae26875a1299e7091d4c",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Current systems for object detection in video sequences rely on explicit dynamical models like Kalman filters or hidden Markov models. There is significant overhead needed in the development of such systems as well as the a priori assumption that the object dynamics can be described with such a dynamical model. This paper describes a new pattern classification technique for object detection in video sequences that uses a rich, overcomplete dictionary of wavelet features to describe an object class. Unlike previous work where a small subset of features was selected from the dictionary, this system does no feature selection and learns the model in the full 1,326 dimensional feature space. Comparisons using different sized sets of several types of features are given. We extend this representation into the time domain without assuming any explicit model of dynamics. This data driven approach produces a model of the physical structure and short-time dynamical characteristics of people from a training set of examples; no assumptions are made about the motion of people, just that short sequences characterize their dynamics sufficiently for the purposes of detection. One of the main benefits of this approach is that transient false positives are reduced. This technique compares favorably with the static detection approach and could be applied to other object classes. We also present a real-time version of one of our static people detection systems."
            },
            "slug": "A-pattern-classification-approach-to-dynamical-Papageorgiou-Poggio",
            "title": {
                "fragments": [],
                "text": "A pattern classification approach to dynamical object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new pattern classification technique for object detection in video sequences that uses a rich, overcomplete dictionary of wavelet features to describe an object class and extends this representation into the time domain without assuming any explicit model of dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6476085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76f560991d56ad689ec32f9e9d13291e0193f4cf",
            "isKey": false,
            "numCitedBy": 1604,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general trainable framework for object detection in static images of cluttered scenes. The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances. By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as an input to a support vector machine classifier. This representation overcomes both the problem of in-class variability and provides a low false detection rate in unconstrained environments. We demonstrate the capabilities of the technique in two domains whose inherent information content differs significantly. The first system is face detection and the second is the domain of people which, in contrast to faces, vary greatly in color, texture, and patterns. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or motion-based segmentation. The paper also presents a motion-based extension to enhance the performance of the detection algorithm over video sequences. The results presented here suggest that this architecture may well be quite general."
            },
            "slug": "A-general-framework-for-object-detection-Papageorgiou-Oren",
            "title": {
                "fragments": [],
                "text": "A general framework for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A general trainable framework for object detection in static images of cluttered scenes based on a wavelet representation of an object class derived from a statistical analysis of the class instances and a motion-based extension to enhance the performance of the detection algorithm over video sequences is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716824"
                        ],
                        "name": "A. Verri",
                        "slug": "A.-Verri",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Verri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Verri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43548339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a885410fc374ee01704335647ed99ec2a0793c9e",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a method for 3-D object recognition based on Support Vector Machines (SVM) is proposed. Given a set of points which belong to either of two classes, a SVM finds the hyperplane that leaves the largest possible fraction of points of the same class on the same side, while maximizing the distance of the closest point. Recognition with SVMs does not require feature extraction and can be performed directly on images regarded as points of an N-dimensional object space. The potential of the proposed method is illustrated on a database of 7200 images of 100 different objects. The excellent recognition rates achieved in all the performed experiments indicate that the method is well-suited for aspect-based recognition."
            },
            "slug": "Direct-Aspect-Based-3D-Object-Recognition-Pontil-Verri",
            "title": {
                "fragments": [],
                "text": "Direct Aspect-Based 3D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The excellent recognition rates achieved in all the performed experiments indicate that the method is well-suited for aspect-based recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ICIAP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2671293"
                        ],
                        "name": "M. Diekhans",
                        "slug": "M.-Diekhans",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Diekhans",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Diekhans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2048632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e2dd064daaac3603581ec65b580b7b5385e2c2b",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily. The method is a variant of support vector machines using a new kernel function. The kernel function is derived from a generative statistical model for a protein family, in this case a hidden Markov model. This general approach of combining generative models like HMMs with discriminative methods such as support vector machines may have applications in other areas of biosequence analysis as well."
            },
            "slug": "A-Discriminative-Framework-for-Detecting-Remote-Jaakkola-Diekhans",
            "title": {
                "fragments": [],
                "text": "A Discriminative Framework for Detecting Remote Protein Homologies"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new method for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily using a new kernel function derived from a generative statistical model for a protein family, in this case a hidden Markov model."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Biol."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7967646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "slug": "Pedestrian-detection-using-wavelet-templates-Oren-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes and shows how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124866301"
                        ],
                        "name": "A. Mohan",
                        "slug": "A.-Mohan",
                        "structuredName": {
                            "firstName": "Anuj",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mohan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18545565,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d939b9b3e09b93bc9e034375b8185c23502c5d0b",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a component based person detection system that is capable of detecting frontal, rear and near side views of people, and partially occluded persons in cluttered scenes. The framework that is described here for people is easily applied to other objects as well. The motivation for developing a component based approach is two fold: first, to enhance the performance of person detection systems on frontal and rear views of people and second, to develop a framework that directly addresses the problem of detecting people who are partially occluded or whose body parts blend in with the background. The data classification is handled by several support vector machine classifiers arranged in two layers. This architecture is known as Adaptive Combination of Classifiers (ACC). The system performs very well and is capable of detecting people even when all components of a person are not found. The performance of the system is significantly better than a full body person detector designed along similar lines. This suggests that the improved performance is due to the components based approach and the ACC data classification structure."
            },
            "slug": "Object-Detection-in-Images-by-Components-Mohan",
            "title": {
                "fragments": [],
                "text": "Object Detection in Images by Components"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A component based person detection system that is capable of detecting frontal, rear and near side views of people, and partially occluded persons in cluttered scenes and is significantly better than a full body person detector designed along similar lines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3129654"
                        ],
                        "name": "S. Raudys",
                        "slug": "S.-Raudys",
                        "structuredName": {
                            "firstName": "Sarunas",
                            "lastName": "Raudys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Raudys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "This is a well-known boundary division problem, [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37044463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cf994cc7cec3c76f49f98aa6ded0824187e786d",
            "isKey": false,
            "numCitedBy": 1263,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The effects of sample size on feature selection and error estimation for several types of classifiers are discussed. The focus is on the two-class problem. Classifier design in the context of small design sample size is explored. The estimation of error rates under small test sample size is given. Sample size effects in feature selection are discussed. Recommendations for the choice of learning and test sample sizes are given. In addition to surveying prior work in this area, an emphasis is placed on giving practical advice to designers and users of statistical pattern recognition systems. >"
            },
            "slug": "Small-Sample-Size-Effects-in-Statistical-Pattern-Raudys-Jain",
            "title": {
                "fragments": [],
                "text": "Small Sample Size Effects in Statistical Pattern Recognition: Recommendations for Practitioners"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The effects of sample size on feature selection and error estimation for several types of classifiers are discussed and an emphasis is placed on giving practical advice to designers and users of statistical pattern recognition systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2667432"
                        ],
                        "name": "D. Roobaert",
                        "slug": "D.-Roobaert",
                        "structuredName": {
                            "firstName": "Danny",
                            "lastName": "Roobaert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roobaert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119793231"
                        ],
                        "name": "M. V. Van Hulle",
                        "slug": "M.-V.-Van-Hulle",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Van Hulle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. V. Van Hulle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62723522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff9da53833b421eeb514e92c734c3c06cf194ec",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines have demonstrated excellent results in pattern recognition tasks and 3D object recognition. We confirm some of the results in 3D object recognition and compare it to other object recognition systems. We use different pixel-level representations to perform the experiments, while we extend the setting to the more challenging and practical case when only a limited number of views of the object are presented during training. We report high correct classification of unseen views, especially considering that no domain knowledge is including into the proposed system. Finally, we suggest an active learning algorithm to reduce further the required number of training views."
            },
            "slug": "View-based-3D-object-recognition-with-support-Roobaert-Hulle",
            "title": {
                "fragments": [],
                "text": "View-based 3D object recognition with support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work reports high correct classification of unseen views, especially considering that no domain knowledge is including into the proposed system, and suggests an active learning algorithm to reduce further the required number of training views."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145884505"
                        ],
                        "name": "V. Cherkassky",
                        "slug": "V.-Cherkassky",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Cherkassky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cherkassky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Approfondimenti teorici sull\u2019argomento possono essere trovati in [1], [2], [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Con probabilit\u00e0 1 \u2212 \u03b7 vale la seguente disuguaglianza [2] R(\u03b1) \u2264 Remp(\u03b1) + \u221a\u221a\u221a\u221a ( h(log(2l/h) + 1)\u2212 log(\u03b7/4) l ) , (1)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 206755547,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "e64fecbaf4d75e0dd6711f8f335c8a53da9fd360",
            "isKey": false,
            "numCitedBy": 3182,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "If you really want to be smarter, reading can be one of the lots ways to evoke and realize. Many people who like reading will have more knowledge and experiences. Reading can be a way to gain information from economics, politics, science, fiction, literature, religion, and many others. As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book. Many people are absolutely searching for this book. It means that many love to read this kind of book."
            },
            "slug": "The-Nature-Of-Statistical-Learning-Theory-Cherkassky",
            "title": {
                "fragments": [],
                "text": "The Nature Of Statistical Learning Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69526161"
                        ],
                        "name": "\u7a42\u9df9 \u826f\u4ecb",
                        "slug": "\u7a42\u9df9-\u826f\u4ecb",
                        "structuredName": {
                            "firstName": "\u7a42\u9df9",
                            "lastName": "\u826f\u4ecb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u7a42\u9df9 \u826f\u4ecb"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "This approach was further extended by Kuhn and Tucker in 1951, [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "In 1951, Kuhn-Tucker extended Langrange mathematics to include inequalities, [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59644801,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "cdedd13cd6253bd08ca3d894b934c971ab84737c",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In a linear program, the constraints are linear in the decision variables, and so is the objective function. In a non linear program, the constraints and/or the objective function can also be non linear function of the decision variables. Example: Gasoline Blending: The qualities of a blend are determined by the qualities of the stocks used in the blend. An optimization is to determine the volume of each input stock in each blend so that the objective function is optimized subject to the output blends satisfying their quality specifications, stock availability constraints, and blend demand constraints. The decision variables are x ij denoting the amount of stock i in blend j. For the most part the constraints can be written as linear functions; but some of the quality constraints are non linear: Distillation Blending: D jk = b k + c k * ln [ \u03a3 i (S ik * VF ij) ] where D jk is the k th distillation point for blend j. S ik is the k th distillation point for stock i. VF ij is the volume fraction of stock i in blend j and is equal to x ij / (\u03a3 i x ij) and b k and c k are constants."
            },
            "slug": "Non-Linear-Programming-\u306e\u8a08\u7b97\u6cd5\u306b\u3064\u3044\u3066-\u7a42\u9df9",
            "title": {
                "fragments": [],
                "text": "Non-Linear Programming \u306e\u8a08\u7b97\u6cd5\u306b\u3064\u3044\u3066"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "In a linear program, the constraints are linear in the decision variables, and so is the objective function; but some of the quality constraints are non linear: Distillation Blending, for example."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122071124"
                        ],
                        "name": "K. Muller",
                        "slug": "K.-Muller",
                        "structuredName": {
                            "firstName": "K.-R.",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78088877"
                        ],
                        "name": "Alexander J. Smola",
                        "slug": "Alexander-J.-Smola",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Smola",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander J. Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2633352"
                        ],
                        "name": "J. Kohlmorgen",
                        "slug": "J.-Kohlmorgen",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Kohlmorgen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kohlmorgen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53879697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3bd61c3d78245d36ea073cc7399eb6b312b1f87",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-support-vector-machines-for-time-series-Muller-Smola",
            "title": {
                "fragments": [],
                "text": "Using support vector machines for time series prediction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117396721"
                        ],
                        "name": "Constantine Papgeorgiou",
                        "slug": "Constantine-Papgeorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papgeorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Constantine Papgeorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15099216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "193c7d756e030af8fc0a331857554247d8c75519",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In the near future, we can expect on-board automotive vision systems that inform or alert the driver about pedestrians, track surrounding vehicles, and read street signs. Object detection is fundamental to the success of this type of next-generation vision system. In this paper, w e present a trainable object detection system that automatically learns to detect objects of a certain class in unconstrained scenes. We apply our system to the task of pedestrian detection. Unlike previous approaches to pedestrian detection that rely heavily on hand-crafted models and motion information, our system learns the pedestrian model from examples and uses no motion cues. The system can easily be extended to include motion information. We review our previous system, describe a new system that exhibits significantly better performance, provide a comparison between using different combinations of feature sets with classifiers of varying complexity, and describe improvements that increase the system\u2019s processing speed by two orders of magnitude."
            },
            "slug": "A-TRAINABLE-PEDESTRIAN-DETECTION-SYSTEM-Papgeorgiou-Evgeniou",
            "title": {
                "fragments": [],
                "text": "A TRAINABLE PEDESTRIAN DETECTION SYSTEM"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A trainable object detection system that automatically learns to detect objects of a certain class in unconstrained scenes and learns the pedestrian model from examples and uses no motion cues."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794837"
                        ],
                        "name": "Siwei Lyu",
                        "slug": "Siwei-Lyu",
                        "structuredName": {
                            "firstName": "Siwei",
                            "lastName": "Lyu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siwei Lyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4153758"
                        ],
                        "name": "H. Farid",
                        "slug": "H.-Farid",
                        "structuredName": {
                            "firstName": "Hany",
                            "lastName": "Farid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Farid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14295442,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "637b0ba19f72f9eba326f07c8d46a6e26237e3be",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Techniques for information hiding have become increasingly more sophisticated and widespread. With high-resolution digital images as carriers, detecting hidden messages has become considerably more difficult. This paper describes an approach to detecting hidden messages in images that uses a wavelet-like decomposition to build higher-order statistical models of natural images. Support vector machines are then used to discriminate between untouched and adulterated images."
            },
            "slug": "Detecting-Hidden-Messages-Using-Higher-Order-and-Lyu-Farid",
            "title": {
                "fragments": [],
                "text": "Detecting Hidden Messages Using Higher-Order Statistics and Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An approach to detecting hidden messages in images that uses a wavelet-like decomposition to build higher-order statistical models of natural images and support vector machines are used to discriminate between untouched and adulterated images."
            },
            "venue": {
                "fragments": [],
                "text": "Information Hiding"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1613090964"
                        ],
                        "name": "\u30b7\u30e5\u3001\u30ea\u2212\u30af\u30a5\u30f3",
                        "slug": "\u30b7\u30e5\u3001\u30ea\u2212\u30af\u30a5\u30f3",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u30b7\u30e5\u3001\u30ea\u2212\u30af\u30a5\u30f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u30b7\u30e5\u3001\u30ea\u2212\u30af\u30a5\u30f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1613096492"
                        ],
                        "name": "\u30e9\u30f3\u30c0\u30d0\u30bd\u3001\u30db\u30bb\u2212\u30eb\u30a4\u30b9",
                        "slug": "\u30e9\u30f3\u30c0\u30d0\u30bd\u3001\u30db\u30bb\u2212\u30eb\u30a4\u30b9",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u30e9\u30f3\u30c0\u30d0\u30bd\u3001\u30db\u30bb\u2212\u30eb\u30a4\u30b9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u30e9\u30f3\u30c0\u30d0\u30bd\u3001\u30db\u30bb\u2212\u30eb\u30a4\u30b9"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 397,
                                "start": 365
                            }
                        ],
                        "text": "For instance the following examples,\n- Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 430,
                                "start": 398
                            }
                        ],
                        "text": "For instance the following examples, - Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 214813820,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "124fa44713b21566e3bc8d0d5dd5f48c1846db75",
            "isKey": true,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The present invention applies a segmentation operation to the input image to identify the foreground object of interest, and then applies a shadow removal operation to remove any shadows detected from the foreground segmentation. However, the shadow removal algorithm can leave holes and intersections in the segmentation map that will subsequently affect the object detection step performed using connected component analysis. To circumvent this problem, the present invention provides a conditional form for segmentation maps to \u201cgrow\u201d segmented blobs to fill holes and intersections without replaying shadow pixels with segmentation. Apply mathematical expansion operations. The result is an object detection method and system that is resistant to lighting changes that cause shadows and / or highlights. [Selection] Figure 2"
            },
            "slug": "Object-detection-in-images-\u30b7\u30e5\u3001\u30ea\u2212\u30af\u30a5\u30f3-\u30e9\u30f3\u30c0\u30d0\u30bd\u3001\u30db\u30bb\u2212\u30eb\u30a4\u30b9",
            "title": {
                "fragments": [],
                "text": "Object detection in images"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The present invention provides a conditional form for segmentation maps to \u201cgrow\u201d segmented blobs to fill holes and intersections without replaying shadow pixels with segmentation to create an object detection method and system that is resistant to lighting changes that cause shadows and / or highlights."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545803"
                        ],
                        "name": "M. Aizerman",
                        "slug": "M.-Aizerman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Aizerman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Aizerman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Boser, Guyon and Vapnik [2], showed that a rather old trick [1]\u2014kernel functions\u2014can be used to accomplish the same result in a very simple and efficient way."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60493317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3caf34c1c86633b6e80dca29e3cb2b6367a0f93",
            "isKey": false,
            "numCitedBy": 1692,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theoretical-Foundations-of-the-Potential-Function-Aizerman",
            "title": {
                "fragments": [],
                "text": "Theoretical Foundations of the Potential Function Method in Pattern Recognition Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "For more details on the specific maths behind this and the full Lagrange proof see Vapnik\u2019s original work, [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2703537"
                        ],
                        "name": "M. Rychetsky",
                        "slug": "M.-Rychetsky",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Rychetsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rychetsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21279206"
                        ],
                        "name": "S. Ortmann",
                        "slug": "S.-Ortmann",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Ortmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ortmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695280"
                        ],
                        "name": "M. Glesner",
                        "slug": "M.-Glesner",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Glesner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Glesner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 467,
                                "start": 434
                            }
                        ],
                        "text": "For instance the following examples,\n- Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 476,
                                "start": 468
                            }
                        ],
                        "text": "For instance the following examples, - Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59792027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0183708170c429a6e495e03e42f329285b674cca",
            "isKey": true,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Construction-of-a-support-vector-machine-with-local-Rychetsky-Ortmann",
            "title": {
                "fragments": [],
                "text": "Construction of a support vector machine with local experts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 39
                            }
                        ],
                        "text": "For instance the following examples,\n- Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 68
                            }
                        ],
                        "text": "For instance the following examples, - Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction by support vector machines and position-specific scoring"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143955418"
                        ],
                        "name": "M. S. Brown",
                        "slug": "M.-S.-Brown",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Brown",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2361327"
                        ],
                        "name": "W. Grundy",
                        "slug": "W.-Grundy",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Grundy",
                            "middleNames": [
                                "Noble"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116443182"
                        ],
                        "name": "D. Lin",
                        "slug": "D.-Lin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lin",
                            "middleNames": [
                                "Yin-wei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070640"
                        ],
                        "name": "C. Sugnet",
                        "slug": "C.-Sugnet",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Sugnet",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sugnet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145729499"
                        ],
                        "name": "M. Ares",
                        "slug": "M.-Ares",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Ares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 82894256,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b8d0c7bdbbb4015c572af7fba569b9f727c65701",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Support-Vector-Machine-Classification-of-Microarray-Brown-Grundy",
            "title": {
                "fragments": [],
                "text": "Support Vector Machine Classification of Microarray from Gene Expression Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Statistical learning theory or VC (Vapnik-Chervonenkis) theory [16], shows that it is imperative that we restrict the class of functions that our machine can learn, otherwise learning the underlying function is impossible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59752996,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "5451278e1a11cf3f1be28a05f38d36c8641e68f7",
            "isKey": false,
            "numCitedBy": 4580,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Nature-of-Statistical-Learning-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3267844"
                        ],
                        "name": "K. Schittkowski",
                        "slug": "K.-Schittkowski",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Schittkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schittkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2907488"
                        ],
                        "name": "Christian Zillober",
                        "slug": "Christian-Zillober",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Zillober",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Zillober"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 148
                            }
                        ],
                        "text": "Further details of the concepts behind Lagrange Mathematics are beyond the scope of this report but for further reading on optimisation theory see, [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44060508,
            "fieldsOfStudy": [],
            "id": "d4143c46910f249bedbdc37caf88e4c292124c08",
            "isKey": false,
            "numCitedBy": 6357,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "NONLINEAR-PROGRAMMING-Schittkowski-Zillober",
            "title": {
                "fragments": [],
                "text": "NONLINEAR PROGRAMMING"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Riferimenti bibliografici [1] Burges, C."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "Approfondimenti teorici sull\u2019argomento possono essere trovati in [1], [2], [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 34
                            }
                        ],
                        "text": "These include text categorisation [7, 8], image classification [5, 10\u201312], biosequence analysis and biological data mining [3] and handwritten character recognition [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text categorisation with support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of European Conference on Machine Learning (ECML),"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition with support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transaction on PAMI,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "Approfondimenti teorici sull\u2019argomento possono essere trovati in [1], [2], [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Learning Theory, Wiley, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 550,
                                "start": 546
                            }
                        ],
                        "text": "For instance the following examples, - Protein Structure Prediction [13, 14], - Land cover classification [29], - Network Intrusion Detection [26], - Handwriting Recognition [1], - Detecting Steganography in digital images [18], - Breast Cancer Diagnosis and Prognosis [17, 16, 15, 19], - Particle and Quark-Flavour Identification in High Energy Physics [38], - 3D Computer Vision Object Detection [31, 22, 30, 32, 28, 33, 41, 35], - Combustion Engine Knock Detection [23, 24], - Protein Sequence Transitions [42], - Detecting protein homologies [10], - Text Categorisation [11, 7, 6, 12], - Predicting time series data [20, 25, 21], - Microarray Gene Expression Classification [4], - Database Marketing [2], - Image Retrieval [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Haussler. A discriminative framework for detecting remote protein homologies"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Support vector classifiers for land cover classification"
            },
            "venue": {
                "fragments": [],
                "text": "Map India 2003 Image Processing and Interpretation"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic target recognition with support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS-98 Workshop on Large Margin Classifiers"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction by support vector machines and position-specific scoring matrices"
            },
            "venue": {
                "fragments": [],
                "text": "Protein secondary structure prediction by support vector machines and position-specific scoring matrices"
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 56,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Support-Vector-Machines-Steinwart-Christmann/04b23f577c20d1a0e2a67aadda555f58e6d23d6e?sort=total-citations"
}