{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32301760"
                        ],
                        "name": "Gabor Angeli",
                        "slug": "Gabor-Angeli",
                        "structuredName": {
                            "firstName": "Gabor",
                            "lastName": "Angeli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabor Angeli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14604520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f04df4e20a18358ea2f689b4c129781628ef7fc1",
            "isKey": false,
            "numCitedBy": 2518,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time."
            },
            "slug": "A-large-annotated-corpus-for-learning-natural-Bowman-Angeli",
            "title": {
                "fragments": [],
                "text": "A large annotated corpus for learning natural language inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Stanford Natural Language Inference corpus is introduced, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning, which allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480903"
                        ],
                        "name": "A. Conneau",
                        "slug": "A.-Conneau",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Conneau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Conneau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743722"
                        ],
                        "name": "Douwe Kiela",
                        "slug": "Douwe-Kiela",
                        "structuredName": {
                            "firstName": "Douwe",
                            "lastName": "Kiela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douwe Kiela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934336"
                        ],
                        "name": "Lo\u00efc Barrault",
                        "slug": "Lo\u00efc-Barrault",
                        "structuredName": {
                            "firstName": "Lo\u00efc",
                            "lastName": "Barrault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lo\u00efc Barrault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 138
                            }
                        ],
                        "text": "The MultiNLI corpus was first released in draft form in the first half of 2017, and in the time since its initial release, work by others (Conneau et al., 2017) has shown that NLI can also be an effective source task for pre-training and transfer learning in the context of sentence-to-vector models, with models trained on SNLI and MultiNLI substantially outperforming all prior models on a suite of established transfer learning benchmarks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28971531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c",
            "isKey": false,
            "numCitedBy": 1513,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available."
            },
            "slug": "Supervised-Learning-of-Universal-Sentence-from-Data-Conneau-Kiela",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34617501"
                        ],
                        "name": "C. Macleod",
                        "slug": "C.-Macleod",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Macleod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Macleod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882422"
                        ],
                        "name": "Nancy Ide",
                        "slug": "Nancy-Ide",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Ide",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy Ide"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "t to be maximally diverse and roughly represent the full range of American English. We selected nine sources from the second release of the Open American National Corpus (OANC; Fillmore et al., 1998; Macleod et al., 2000; Ide and Macleod, 2001; Ide and Suderman, 2006, downloaded 12/20161), balancing the volume of source text roughly evenly across genres, and avoiding genres with content that would be too dif\ufb01cult for"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 110
                            }
                        ],
                        "text": "Nine of these come from the second release of the Open American National Corpus (OANC; Fillmore et al., 1998; Macleod et al., 2000; Ide and Suderman, 2006, downloaded 12/2016):\n\u2022 FACE-TO-FACE: Transcriptions of two-sided conversations from the Charlotte, NC area; the Charlotte Narrative and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28495499,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4ad0ecff4b4912698c2a0800eacd6948fd090f30",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Linguistic research has become heavily reliant on text corpora over the past ten years. Such resources are becoming increasingly available through efforts such as the Linguistic Data Consortium (LDC) in the US and the European Language Resources Association (ELRA) in Europe. However, in the main the corpora that are gathered and distributed through these and other mechanisms consist of texts which can be easily acquired and are available for re-distribution without undue problems of copyright, etc. This practice has resulted in a vast over-representation among available corpora of certain genres, in particular newspaper samples, which comprise the greatest percentage of texts currently available from, for example, the LDC, and which also dominate the training data available for speech recognition purposes. Other available corpora typically consist of technical reports, transcriptions of parliamentary and other proceedings, short telephone conversations, and the like. The upshot of this is that corpusbased natural language processing has relied heavily on language samples representative of usage in a handful of limited and linguistically specialized domains."
            },
            "slug": "The-American-National-Corpus:-A-Standardized-for-Macleod-Ide",
            "title": {
                "fragments": [],
                "text": "The American National Corpus: A Standardized Resource for American English"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work has shown that corpusbased natural language processing has relied heavily on language samples representative of usage in a handful of limited and linguistically specialized domains."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257930"
                        ],
                        "name": "Bill MacCartney",
                        "slug": "Bill-MacCartney",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "MacCartney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill MacCartney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "nowledge about the world, and tend not to correspond closely with their premises in sentence structure. These syntactic differences suggest that alignment-based NLI models (like, for example, that of MacCartney, 2009) are unlikely to succeed. Hypotheses tend to be \ufb02uent and correctly spelled, consisting of full sentences, fragments, noun phrases, bare prepositional phrases, and verb phrases. Hypothesisinternal pun"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61771282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8314f8eef3b64054bfc00607507a92de92fb7c85",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference has been a central topic in artificial intelligence from the start, but while automatic methods for formal deduction have advanced tremendously, comparatively little progress has been made on the problem of natural language inference (NLI), that is, determining whether a natural language hypothesis h can justifiably be inferred from a natural language premise p. The challenges of NLI are quite different from those encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic knowledge, and variability of linguistic expression. \nThis dissertation explores a range of approaches to NLI, beginning with methods which are robust but approximate, and proceeding to progressively more precise approaches. \nWe first develop a baseline system based on overlap between bags of words. Despite its extreme simplicity, this model achieves surprisingly good results on a standard NLI evaluation, the PASCAL RTE Challenge. However, its effectiveness is limited by its failure to represent semantic structure. \nTo remedy this lack, we next introduce the Stanford RTE system, which uses typed dependency trees as a proxy for semantic structure, and seeks a low-cost alignment between trees for p and h, using a cost model which incorporates both lexical and structural matching costs. This system is typical of a category of approaches to NLI based on approximate graph matching. We argue, however, that such methods work best when the entailment decision is based, not merely on the degree of alignment, but also on global features of the aligned \u2329p, h\u232a pair motivated by semantic theory. \nSeeking still greater precision, we devote the largest part of the dissertation to developing an approach to NLI based on a model of natural logic. We greatly extend past work in natural logic, which has focused solely on semantic containment and monotonicity, to incorporate both semantic exclusion and implicativity. Our system decomposes an inference problem into a sequence of atomic edits which transforms p into h; predicts a lexical entailment relation for each edit using a statistical classifier; propagates these relations upward through a syntax tree according to semantic properties of intermediate nodes; and composes the resulting entailment relations across the edit sequence. \nFinally, we address the problem of alignment for NLI, by developing a model of phrase-based alignment inspired by analogous work in machine translation, including an alignment scoring function, inference algorithms for finding good alignments, and training algorithms for choosing feature weights."
            },
            "slug": "Natural-language-inference-Manning-MacCartney",
            "title": {
                "fragments": [],
                "text": "Natural language inference"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This dissertation explores a range of approaches to NLI, beginning with methods which are robust but approximate, and proceeding to progressively more precise approaches, and greatly extends past work in natural logic to incorporate both semantic exclusion and implicativity."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10666396"
                        ],
                        "name": "Nikita Nangia",
                        "slug": "Nikita-Nangia",
                        "structuredName": {
                            "firstName": "Nikita",
                            "lastName": "Nangia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikita Nangia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81840293"
                        ],
                        "name": "Adina Williams",
                        "slug": "Adina-Williams",
                        "structuredName": {
                            "firstName": "Adina",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adina Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672644"
                        ],
                        "name": "Angeliki Lazaridou",
                        "slug": "Angeliki-Lazaridou",
                        "structuredName": {
                            "firstName": "Angeliki",
                            "lastName": "Lazaridou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angeliki Lazaridou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "nd mismatched sets as competitions that will be open inde\ufb01nitely; Evaluations on a subset of the test set have previously been conducted with different leaderboards through the RepEval 2017 Workshop (Nangia et al., 2017). Thecorpusisavailable intwoformats\u2014tabseparated text and JSON Lines (jsonl), following SNLI. For each example, premise and hypothesis strings, unique identi\ufb01ers for the pair and prompt, and the follo"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30758763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83b83ee4f27388445bdebb199cd75e5bf546dd85",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of the RepEval 2017 Shared Task, which evaluated neural network sentence representation learning models on the Multi-Genre Natural Language Inference corpus (MultiNLI) recently introduced by Williams et al. (2017). All of the five participating teams beat the bidirectional LSTM (BiLSTM) and continuous bag of words baselines reported in Williams et al. The best single model used stacked BiLSTMs with residual connections to extract sentence features and reached 74.5% accuracy on the genre-matched test set. Surprisingly, the results of the competition were fairly consistent across the genre-matched and genre-mismatched test sets, and across subsets of the test data representing a variety of linguistic phenomena, suggesting that all of the submitted systems learned reasonably domain-independent representations for sentence meaning."
            },
            "slug": "The-RepEval-2017-Shared-Task:-Multi-Genre-Natural-Nangia-Williams",
            "title": {
                "fragments": [],
                "text": "The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference with Sentence Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The results of the RepEval 2017 Shared Task were fairly consistent across the genre-matched and genre-mismatched test sets, and across subsets of the test data representing a variety of linguistic phenomena, suggesting that all of the submitted systems learned reasonably domain-independent representations for sentence meaning."
            },
            "venue": {
                "fragments": [],
                "text": "RepEval@EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2992833"
                        ],
                        "name": "Shuohang Wang",
                        "slug": "Shuohang-Wang",
                        "structuredName": {
                            "firstName": "Shuohang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuohang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924150"
                        ],
                        "name": "Jing Jiang",
                        "slug": "Jing-Jiang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Jiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 198
                            }
                        ],
                        "text": ", 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11004224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "596c882de006e4bb4a93f1fa08a5dd467bee060a",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language inference (NLI) is a fundamentally important task in natural language processing that has many applications. The recently released Stanford Natural Language Inference (SNLI) corpus has made it possible to develop and evaluate learning-centered methods such as deep neural networks for natural language inference (NLI). In this paper, we propose a special long short-term memory (LSTM) architecture for NLI. Our model builds on top of a recently proposed neural attention model for NLI but is based on a significantly different idea. Instead of deriving sentence embeddings for the premise and the hypothesis to be used for classification, our solution uses a match-LSTM to perform word-by-word matching of the hypothesis with the premise. This LSTM is able to place more emphasis on important word-level matching results. In particular, we observe that this LSTM remembers important mismatches that are critical for predicting the contradiction or the neutral relationship label. On the SNLI corpus, our model achieves an accuracy of 86.1%, outperforming the state of the art."
            },
            "slug": "Learning-Natural-Language-Inference-with-LSTM-Wang-Jiang",
            "title": {
                "fragments": [],
                "text": "Learning Natural Language Inference with LSTM"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A special long short-term memory (LSTM) architecture for NLI that remembers important mismatches that are critical for predicting the contradiction or the neutral relationship label and achieves an accuracy of 86.1%, outperforming the state of the art."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47261124"
                        ],
                        "name": "Qian Chen",
                        "slug": "Qian-Chen",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854999"
                        ],
                        "name": "Xiao-Dan Zhu",
                        "slug": "Xiao-Dan-Zhu",
                        "structuredName": {
                            "firstName": "Xiao-Dan",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Dan Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749989"
                        ],
                        "name": "Zhenhua Ling",
                        "slug": "Zhenhua-Ling",
                        "structuredName": {
                            "firstName": "Zhenhua",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenhua Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572674"
                        ],
                        "name": "Si Wei",
                        "slug": "Si-Wei",
                        "structuredName": {
                            "firstName": "Si",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Si Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36357862"
                        ],
                        "name": "Hui Jiang",
                        "slug": "Hui-Jiang",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697366"
                        ],
                        "name": "D. Inkpen",
                        "slug": "D.-Inkpen",
                        "structuredName": {
                            "firstName": "Diana",
                            "lastName": "Inkpen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Inkpen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "Because of these two factors, SNLI is not sufficiently demanding to serve as an effective benchmark for NLU, with the best current model performance (Chen et al., 2017) falling within a few percentage points of human accuracy, and limited room left for finegrained comparisons between models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34032948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83e7654d545fbbaaf2328df365a781fb67b841b4",
            "isKey": false,
            "numCitedBy": 789,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is very challenging. With the availability of large annotated data (Bowman et al., 2015), it has recently become feasible to train neural network based inference models, which have shown to be very effective. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.6% on the Stanford Natural Language Inference Dataset. Unlike the previous top models that use very complicated network architectures, we first demonstrate that carefully designing sequential inference models based on chain LSTMs can outperform all previous models. Based on this, we further show that by explicitly considering recursive architectures in both local inference modeling and inference composition, we achieve additional improvement. Particularly, incorporating syntactic parsing information contributes to our best result\u2014it further improves the performance even when added to the already very strong model."
            },
            "slug": "Enhanced-LSTM-for-Natural-Language-Inference-Chen-Zhu",
            "title": {
                "fragments": [],
                "text": "Enhanced LSTM for Natural Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a new state-of-the-art result, achieving the accuracy of 88.6% on the Stanford Natural Language Inference Dataset, and demonstrates that carefully designing sequential inference models based on chain LSTMs can outperform all previous models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 72
                            }
                        ],
                        "text": "(PTB) marks that a tag is derived automatically from Penn Treebank tags (Marcus et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "First, we use the existing Penn Treebank (PTB Marcus et al., 1993) tag set to automatically isolate sentences containing difficult linguistic phenomena (e.g., pronouns, negation, existentials, modals, comparatives and superlatives, etc.)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8176,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3461596"
                        ],
                        "name": "Johan Bos",
                        "slug": "Johan-Bos",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Bos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Bos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686341"
                        ],
                        "name": "K. Markert",
                        "slug": "K.-Markert",
                        "structuredName": {
                            "firstName": "Katja",
                            "lastName": "Markert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Markert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 59
                            }
                        ],
                        "text": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10202504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea2563467c1c472a346d165b7f97c86317d63ca4",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We use logical inference techniques for recognising textual entailment. As the performance of theorem proving turns out to be highly dependent on not readily available background knowledge, we incorporate model building, a technique borrowed from automated reasoning, and show that it is a useful robust method to approximate entailment. Finally, we use machine learning to combine these deep semantic analysis techniques with simple shallow word overlap; the resulting hybrid model achieves high accuracy on the RTE testset, given the state of the art. Our results also show that the different techniques that we employ perform very differently on some of the subsets of the RTE corpus and as a result, it is useful to use the nature of the dataset as a feature."
            },
            "slug": "Recognising-Textual-Entailment-with-Logical-Bos-Markert",
            "title": {
                "fragments": [],
                "text": "Recognising Textual Entailment with Logical Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work incorporates model building, a technique borrowed from automated reasoning, and shows that it is a useful robust method to approximate entailment, and uses machine learning to combine these deep semantic analysis techniques with simple shallow word overlap."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644577"
                        ],
                        "name": "S. Menini",
                        "slug": "S.-Menini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Menini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Menini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 762228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c333778104f648c385b4631f7b4a859787e9d3d3",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Shared and internationally recognized benchmarks are fundamental for the development of any computational system. We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them. SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs. By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral). The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes."
            },
            "slug": "A-SICK-cure-for-the-evaluation-of-compositional-Marelli-Menini",
            "title": {
                "fragments": [],
                "text": "A SICK cure for the evaluation of compositional distributional semantic models"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work aims to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24339276"
                        ],
                        "name": "Jon Gauthier",
                        "slug": "Jon-Gauthier",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Gauthier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jon Gauthier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2188497"
                        ],
                        "name": "Abhinav Rastogi",
                        "slug": "Abhinav-Rastogi",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Rastogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinav Rastogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47495799"
                        ],
                        "name": "Raghav Gupta",
                        "slug": "Raghav-Gupta",
                        "structuredName": {
                            "firstName": "Raghav",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raghav Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14429450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36c097a225a95735271960e2b63a2cb9e98bff83",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Tree-structured neural networks exploit valuable syntactic parse information as they interpret the meanings of sentences. However, they suer from two key technical problems that make them slow and unwieldyforlarge-scaleNLPtasks: theyusually operate on parsed sentences and they do not directly support batched computation. We address these issues by introducingtheStack-augmentedParser-Interpreter NeuralNetwork(SPINN),whichcombines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shiftreduceparser. Ourmodelsupportsbatched computation for a speedup of up to 25\u25ca over other tree-structured models, and its integrated parser can operate on unparsed data with little loss in accuracy. We evaluate it on the Stanford NLI entailment task and show that it significantly outperforms other sentence-encoding models."
            },
            "slug": "A-Fast-Unified-Model-for-Parsing-and-Sentence-Bowman-Gauthier",
            "title": {
                "fragments": [],
                "text": "A Fast Unified Model for Parsing and Sentence Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The Stack-augmentedParser-Interpreter NeuralNetwork (SPINN) combines parsing and interpretation within a single tree-sequence hybrid model by integrating tree-structured sentence interpretation into the linear sequential structure of a shiftreduceparser."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227827"
                        ],
                        "name": "Tsendsuren Munkhdalai",
                        "slug": "Tsendsuren-Munkhdalai",
                        "structuredName": {
                            "firstName": "Tsendsuren",
                            "lastName": "Munkhdalai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsendsuren Munkhdalai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145174375"
                        ],
                        "name": "Hong Yu",
                        "slug": "Hong-Yu",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 229
                            }
                        ],
                        "text": ", 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11262376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cff79255a94b9b05a4ce893eb403a522e0923f04",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a memory augmented neural network for natural language understanding: Neural Semantic Encoders. NSE is equipped with a novel memory update rule and has a variable sized encoding memory that evolves over time and maintains the understanding of input sequences through read, compose and write operations. NSE can also access 1 multiple and shared memories. In this paper, we demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks: natural language inference, question answering, sentence classification, document sentiment analysis and machine translation where NSE achieved state-of-the-art performance when evaluated on publically available benchmarks. For example, our shared-memory model showed an encouraging result on neural machine translation, improving an attention-based baseline by approximately 1.0 BLEU."
            },
            "slug": "Neural-Semantic-Encoders-Munkhdalai-Yu",
            "title": {
                "fragments": [],
                "text": "Neural Semantic Encoders"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks: natural language inference, question answering, sentence classification, document sentiment analysis and machine translation where NSE achieved state-of-the-art performance when evaluated on publically available benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144729897"
                        ],
                        "name": "Ankur P. Parikh",
                        "slug": "Ankur-P.-Parikh",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Parikh",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ankur P. Parikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556289"
                        ],
                        "name": "Oscar T\u00e4ckstr\u00f6m",
                        "slug": "Oscar-T\u00e4ckstr\u00f6m",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "T\u00e4ckstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oscar T\u00e4ckstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143790066"
                        ],
                        "name": "Dipanjan Das",
                        "slug": "Dipanjan-Das",
                        "structuredName": {
                            "firstName": "Dipanjan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dipanjan Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 154
                            }
                        ],
                        "text": "jor benchmark for machine learning work on sentence understanding and spurring work on core representation learning techniques for NLU, such as attention (Wang and Jiang, 2016; Parikh et al., 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8495258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2cd8e8f510c89c7c18268e8ad51c061e459ad321",
            "isKey": false,
            "numCitedBy": 1060,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a simple neural architecture for natural language inference. Our approach uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable. On the Stanford Natural Language Inference (SNLI) dataset, we obtain state-of-the-art results with almost an order of magnitude fewer parameters than previous work and without relying on any word-order information. Adding intra-sentence attention that takes a minimum amount of order into account yields further improvements."
            },
            "slug": "A-Decomposable-Attention-Model-for-Natural-Language-Parikh-T\u00e4ckstr\u00f6m",
            "title": {
                "fragments": [],
                "text": "A Decomposable Attention Model for Natural Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work proposes a simple neural architecture for natural language inference that uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 149
                            }
                        ],
                        "text": "\u2026task, also known\nas recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60246043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02e5cae2cb6f7cd290de44ad144a55fcde12c2ec",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes the way in which a Preference Semantics system for natural language analysis and generation tackles a difficult class of anaphoric inference problems (finding the correct referent for an English pronoun in context): those requiring either analysis (conceptual) knowledge of a complex sort, or requiring weak inductive knowledge of the course of events in the real world. The method employed converts all available knowledge to a canonical template form and endeavors to create chains of non-deductive inferences from the unknowns to the possible referents. Its method of selecting among possible chains of inferences is consistent with the overall principle of \"semantic preference\" used to set up the original meaning representation, of which these anaphoric inference procedures are a manipulation."
            },
            "slug": "Natural-language-inference.-Wilks",
            "title": {
                "fragments": [],
                "text": "Natural language inference."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The paper describes the way in which a Preference Semantics system for natural language analysis and generation tackles a difficult class of anaphoric inference problems (finding the correct referent for an English pronoun in context)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644577"
                        ],
                        "name": "S. Menini",
                        "slug": "S.-Menini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Menini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Menini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 216
                            }
                        ],
                        "text": "Data Collection In data collection for NLI, different annotator decisions about the coreference between entities and events across the pair can lead to very different assignments of labels (de Marneffe et al., 2008; Marelli et al., 2014a; Bowman et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "The validation phase follows the procedure used in SICK (Marelli et al., 2014b) and SNLI (Bowman et al., 2015); workers are presented with pairs of sentences and asked to supply a single label (entailment, contradiction, neutral) for the pair."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16404002,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "11ec56898a9e7f401a2affe776b5297bd4e25025",
            "isKey": false,
            "numCitedBy": 360,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the task on the evaluation of Compositional Distributional Semantics Models on full sentences organized for the first time within SemEval2014. Participation was open to systems based on any approach. Systems were presented with pairs of sentences and were evaluated on their ability to predict human judgments on (i) semantic relatedness and (ii) entailment. The task attracted 21 teams, most of which participated in both subtasks. We received 17 submissions in the relatedness subtask (for a total of 66 runs) and 18 in the entailment subtask (65 runs)."
            },
            "slug": "SemEval-2014-Task-1:-Evaluation-of-Compositional-on-Marelli-Bentivogli",
            "title": {
                "fragments": [],
                "text": "SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper presents the task on the evaluation of Compositional Distributional Semantics Models on full sentences organized for the first time within SemEval2014, and attracted 21 teams, most of which participated in both subtasks."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644577"
                        ],
                        "name": "S. Menini",
                        "slug": "S.-Menini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Menini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Menini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 216
                            }
                        ],
                        "text": "Data Collection In data collection for NLI, different annotator decisions about the coreference between entities and events across the pair can lead to very different assignments of labels (de Marneffe et al., 2008; Marelli et al., 2014a; Bowman et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "The validation phase follows the procedure used in SICK (Marelli et al., 2014b) and SNLI (Bowman et al., 2015); workers are presented with pairs of sentences and asked to supply a single label (entailment, contradiction, neutral) for the pair."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8897969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb93bc031fede3d53ee01a1b66ca3b24fc8a10d7",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractThis paper is an extended description of SemEval-2014 Task 1, the task on the evaluation of Compositional Distributional Semantics Models on full sentences. Systems participating in the task were presented with pairs of sentences and were evaluated on their ability to predict human judgments on (1) semantic relatedness and (2) entailment.\n Training and testing data were subsets of the SICK (Sentences Involving Compositional Knowledge) data set. SICK was developed with the aim of providing a proper benchmark to evaluate compositional semantic systems, though task participation was open to systems based on any approach. Taking advantage of the SemEval experience, in this paper we analyze the SICK data set, in order to evaluate the extent to which it meets its design goal and to shed light on the linguistic phenomena that are still challenging for state-of-the-art computational semantic systems.\n Qualitative and quantitative error analyses show that many systems are quite sensitive to changes in the proportion of sentence pair types, and degrade in the presence of additional lexico-syntactic complexities which do not affect human judgements. More compositional systems seem to perform better when the task proportions are changed, but the effect needs further confirmation.\n"
            },
            "slug": "SICK-through-the-SemEval-glasses.-Lesson-learned-of-Bentivogli-Bernardi",
            "title": {
                "fragments": [],
                "text": "SICK through the SemEval glasses. Lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Qualitative and quantitative error analyses show that many systems are quite sensitive to changes in the proportion of sentence pair types, and degrade in the presence of additional lexico-syntactic complexities which do not affect human judgements, but the effect needs further confirmation."
            },
            "venue": {
                "fragments": [],
                "text": "Lang. Resour. Evaluation"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116927"
                        ],
                        "name": "John Blitzer",
                        "slug": "John-Blitzer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Blitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Blitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2007), including sequence and part-of-speech tagging (Blitzer et al., 2006; Peng and Dredze, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15978939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fa8d73e572c3ca824a04a5f551b602a17831bc5",
            "isKey": false,
            "numCitedBy": 1518,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative learning methods are widely used in natural language processing. These methods work best when their training and test data are drawn from the same distribution. For many NLP tasks, however, we are confronted with new domains in which labeled data is scarce or non-existent. In such cases, we seek to adapt existing models from a resource-rich source domain to a resource-poor target domain. We introduce structural correspondence learning to automatically induce correspondences among features from different domains. We test our technique on part of speech tagging and show performance gains for varying amounts of source and target training data, as well as improvements in target domain parsing accuracy using our improved tagger."
            },
            "slug": "Domain-Adaptation-with-Structural-Correspondence-Blitzer-McDonald",
            "title": {
                "fragments": [],
                "text": "Domain Adaptation with Structural Correspondence Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces structural correspondence learning to automatically induce correspondences among features from different domains in order to adapt existing models from a resource-rich source domain to aresource-poor target domain."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257930"
                        ],
                        "name": "Bill MacCartney",
                        "slug": "Bill-MacCartney",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "MacCartney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill MacCartney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 59
                            }
                        ],
                        "text": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6561519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5feb2c61b04532869e44d1ca4e48c7108aee5fd3",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a model of natural language inference which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation. We extend past work in natural logic, which has focused on semantic containment and monotonicity, by incorporating both semantic exclusion and implicativity. Our model decomposes an inference problem into a sequence of atomic edits linking premise to hypothesis; predicts a lexical semantic relation for each edit; propagates these relations upward through a semantic composition tree according to properties of intermediate nodes; and joins the resulting semantic relations across the edit sequence. A computational implementation of the model achieves 70% accuracy and 89% precision on the FraCaS test suite. Moreover, including this model as a component in an existing system yields significant performance gains on the Recognizing Textual Entailment challenge."
            },
            "slug": "An-extended-model-of-natural-logic-MacCartney-Manning",
            "title": {
                "fragments": [],
                "text": "An extended model of natural logic"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A model of natural language inference which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation is proposed, extending past work in natural logic by incorporating both semantic exclusion and implicativity."
            },
            "venue": {
                "fragments": [],
                "text": "IWCS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2241127"
                        ],
                        "name": "Marie-Catherine de Marneffe",
                        "slug": "Marie-Catherine-de-Marneffe",
                        "structuredName": {
                            "firstName": "Marie-Catherine",
                            "lastName": "Marneffe",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marie-Catherine de Marneffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1875900"
                        ],
                        "name": "Anna N. Rafferty",
                        "slug": "Anna-N.-Rafferty",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Rafferty",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna N. Rafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 190
                            }
                        ],
                        "text": "Data Collection In data collection for NLI, different annotator decisions about the coreference between entities and events across the pair can lead to very different assignments of labels (de Marneffe et al., 2008; Marelli et al., 2014a; Bowman et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5555594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "287d5571dbf255a7ccbdc2bcfe9211fd8f0b2a7c",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting conflicting statements is a foundational text understanding task with applications in information analysis. We propose an appropriate definition of contradiction for NLP tasks and develop available corpora, from which we construct a typology of contradictions. We demonstrate that a system for contradiction needs to make more fine-grained distinctions than the common systems for entailment. In particular, we argue for the centrality of event coreference and therefore incorporate such a component based on topicality. We present the first detailed breakdown of performance on this task. Detecting some types of contradiction requires deeper inferential paths than our system is capable of, but we achieve good performance on types arising from negation and antonymy."
            },
            "slug": "Finding-Contradictions-in-Text-Marneffe-Rafferty",
            "title": {
                "fragments": [],
                "text": "Finding Contradictions in Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated that a system for contradiction needs to make more fine-grained distinctions than the common systems for entailment, and is argued for the centrality of event coreference and therefore incorporate such a component based on topicality."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 88
                            }
                        ],
                        "text": "All three models are initialized with 300D reference GloVe vectors (840B token version; Pennington et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": false,
            "numCitedBy": 22539,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 136
                            }
                        ],
                        "text": "In this task, also known\nas recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 59
                            }
                        ],
                        "text": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8587959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de794d50713ea5f91a7c9da3d72041e2f5ef8452",
            "isKey": false,
            "numCitedBy": 1762,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges."
            },
            "slug": "The-PASCAL-Recognising-Textual-Entailment-Challenge-Dagan-Glickman",
            "title": {
                "fragments": [],
                "text": "The PASCAL Recognising Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38956216"
                        ],
                        "name": "Lili Mou",
                        "slug": "Lili-Mou",
                        "structuredName": {
                            "firstName": "Lili",
                            "lastName": "Mou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lili Mou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447639"
                        ],
                        "name": "Rui Men",
                        "slug": "Rui-Men",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Men",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Men"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410115257"
                        ],
                        "name": "Ge Li",
                        "slug": "Ge-Li",
                        "structuredName": {
                            "firstName": "Ge",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ge Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118039966"
                        ],
                        "name": "Yan Xu",
                        "slug": "Yan-Xu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156144568"
                        ],
                        "name": "Lu Zhang",
                        "slug": "Lu-Zhang",
                        "structuredName": {
                            "firstName": "Lu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055863231"
                        ],
                        "name": "Rui Yan",
                        "slug": "Rui-Yan",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700880"
                        ],
                        "name": "Zhi Jin",
                        "slug": "Zhi-Jin",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Jin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 327,
                                "start": 287
                            }
                        ],
                        "text": ", 2015) has enabled a good deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al., 2016b; Bowman et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 262
                            }
                        ],
                        "text": "\u2026deal of progress on NLU, serving as a standard benchmark for sentence understanding and spurring work on core representation learning techniques for NLU such as attention (Wang and Jiang, 2016), memory (Munkhdalai and Yu, 2017), and the use of parse structure (Mou et al., 2016b;\nar X\niv :1\n70 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 113
                            }
                        ],
                        "text": "To do this, they concatenate the two representations, their difference, and their elementwise product (following Mou et al., 2016b), and pass the result to a single tanh layer followed by a three-way softmax classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 144
                            }
                        ],
                        "text": "However, attempts to bring this kind of general purpose representation learning to NLU have seen only very limited successes (see, for example, Mou et al., 2016a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7454072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea407573bfcd39f9a478fe33cf6ce0ee1780a5f0",
            "isKey": true,
            "numCitedBy": 286,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose the TBCNN-pair model to recognize entailment and contradiction between two sentences. In our model, a tree-based convolutional neural network (TBCNN) captures sentence-level semantics; then heuristic matching layers like concatenation, element-wise product/difference combine the information in individual sentences. Experimental results show that our model outperforms existing sentence encoding-based approaches by a large margin."
            },
            "slug": "Natural-Language-Inference-by-Tree-Based-and-Mou-Men",
            "title": {
                "fragments": [],
                "text": "Natural Language Inference by Tree-Based Convolution and Heuristic Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This model, a tree-based convolutional neural network (TBCNN) captures sentence-level semantics; then heuristic matching layers like concatenation, element-wise product/difference combine the information in individual sentences."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2 (Klein and Manning, 2003)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11495042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a600850ac0120cb09a0b7de7da80bb6a7a76de06",
            "isKey": false,
            "numCitedBy": 3370,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize."
            },
            "slug": "Accurate-Unlexicalized-Parsing-Klein-Manning",
            "title": {
                "fragments": [],
                "text": "Accurate Unlexicalized Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is demonstrated that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882422"
                        ],
                        "name": "Nancy Ide",
                        "slug": "Nancy-Ide",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Ide",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy Ide"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34617501"
                        ],
                        "name": "C. Macleod",
                        "slug": "C.-Macleod",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Macleod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Macleod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 87
                            }
                        ],
                        "text": "Nine of these come from the second release of the Open American National Corpus (OANC; Fillmore et al., 1998; Macleod et al., 2000; Ide and Suderman, 2006, downloaded 12/2016):\n\u2022 FACE-TO-FACE: Transcriptions of two-sided conversations from the Charlotte, NC area; the Charlotte Narrative and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ources of freely available text, which are meant to cover a maximally broad range of genres of American English. Nine of these come from the second release of the Open American National Corpus (OANC; Fillmore et al., 1998; Macleod et al., 2000; Ide and Suderman, 2006, downloaded 12/2016): FACE-TO-FACE: Transcriptions of two-sided conversations from the Charlotte, NC area; the Charlotte Narrative and Conversation Coll"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63837396,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "46088860d7fc2e6ef8399b0d266be9508e1aba94",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes the development of an American National Corpus comparable to the British National Corpus. Corpus-analytic work has demonstrated that the use of the British National Corpus is inappropriate to study of American English, due to the numerous differences in the use of the language. We also propose that the corpus include a component of texts in other major North American languages, notably Spanish and French, and ideally a parallel component containing texts in these languages aligned to the English. The development of an ANC will demand a significant commitment from the funding agencies and the research community; such an effort would, however, significantly contribute to language and linguistic research as well as the U.S. National Digital Libraries Initiative and other large-scale projects."
            },
            "slug": "An-American-national-corpus:-a-proposal-Fillmore-Ide",
            "title": {
                "fragments": [],
                "text": "An American national corpus: a proposal"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The development of an ANC will demand a significant commitment from the funding agencies and the research community; such an effort would, however, significantly contribute to language and linguistic research as well as the U.S. National Digital Libraries Initiative and other large-scale projects."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14154185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47f5682448cdc0b650b54e7f59d22d72f4976c2d",
            "isKey": false,
            "numCitedBy": 840,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The most basic assumption used in statistical learning theory is that training data and test data are drawn from the same underlying distribution. Unfortunately, in many applications, the \"in-domain\" test data is drawn from a distribution that is related, but not identical, to the \"out-of-domain\" distribution of the training data. We consider the common case in which labeled out-of-domain data is plentiful, but labeled in-domain data is scarce. We introduce a statistical formulation of this problem in terms of a simple mixture model and present an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts. We present efficient inference algorithms for this special case based on the technique of conditional expectation maximization. Our experimental results show that our approach leads to improved performance on three real world tasks on four different data sets from the natural language processing domain."
            },
            "slug": "Domain-Adaptation-for-Statistical-Classifiers-Daum\u00e9-Marcu",
            "title": {
                "fragments": [],
                "text": "Domain Adaptation for Statistical Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces a statistical formulation of this problem in terms of a simple mixture model and presents an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts and leads to improved performance on three real world tasks on four different data sets from the natural language processing domain."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516953"
                        ],
                        "name": "C. Condoravdi",
                        "slug": "C.-Condoravdi",
                        "structuredName": {
                            "firstName": "Cleo",
                            "lastName": "Condoravdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Condoravdi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2953252"
                        ],
                        "name": "Dick Crouch",
                        "slug": "Dick-Crouch",
                        "structuredName": {
                            "firstName": "Dick",
                            "lastName": "Crouch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dick Crouch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143893075"
                        ],
                        "name": "Valeria C V de Paiva",
                        "slug": "Valeria-C-V-de-Paiva",
                        "structuredName": {
                            "firstName": "Valeria",
                            "lastName": "de Paiva",
                            "middleNames": [
                                "C",
                                "V"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valeria C V de Paiva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097032136"
                        ],
                        "name": "R. Stolle",
                        "slug": "R.-Stolle",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Stolle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stolle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753394"
                        ],
                        "name": "D. Bobrow",
                        "slug": "D.-Bobrow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bobrow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 88
                            }
                        ],
                        "text": "In this task, also known\nas recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 59
                            }
                        ],
                        "text": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5471801,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "5ffa3aea748533186b6638d97eafe80d86b208b2",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We argue that the detection of entailment and contradiction relations between texts is a minimal metric for the evaluation of text understanding systems. Intensionality, which is widespread in natural language, raises a number of detection issues that cannot be brushed aside. We describe a contexted clausal representation, derived from approaches in formal semantics, that permits an extended range of intensional entailments and contradictions to be tractably detected."
            },
            "slug": "Entailment,-intensionality-and-text-understanding-Condoravdi-Crouch",
            "title": {
                "fragments": [],
                "text": "Entailment, intensionality and text understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A contexted clausal representation is described, derived from approaches in formal semantics, that permits an extended range of intensional entailments and contradictions to be tractably detected."
            },
            "venue": {
                "fragments": [],
                "text": "HLT-NAACL 2003"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401829700"
                        ],
                        "name": "Shai Ben-David",
                        "slug": "Shai-Ben-David",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Ben-David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shai Ben-David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116927"
                        ],
                        "name": "John Blitzer",
                        "slug": "John-Blitzer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Blitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Blitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "forms well on test data from a target domain with a different distribution\u2014have resulted in gains across many tasks (Daume III and Marcu, 2006; Ben-David et al., 2007), including sequence and part-of-speech tagging (Blitzer et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10908021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96c6bc559b79d8fd518f431c707e8b44ce3bc4de",
            "isKey": false,
            "numCitedBy": 1387,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. In many situations, though, we have labeled training data for a source domain, and we wish to learn a classifier which performs well on a target domain with a different distribution. Under what conditions can we adapt a classifier trained on the source domain for use in the target domain? Intuitively, a good feature representation is a crucial factor in the success of domain adaptation. We formalize this intuition theoretically with a generalization bound for domain adaption. Our theory illustrates the tradeoffs inherent in designing a representation for domain adaptation and gives a new justification for a recently proposed model. It also points toward a promising new model for domain adaptation: one which explicitly minimizes the difference between the source and target domains, while at the same time maximizing the margin of the training set."
            },
            "slug": "Analysis-of-Representations-for-Domain-Adaptation-Ben-David-Blitzer",
            "title": {
                "fragments": [],
                "text": "Analysis of Representations for Domain Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The theory illustrates the tradeoffs inherent in designing a representation for domain adaptation and gives a new justification for a recently proposed model which explicitly minimizes the difference between the source and target domains, while at the same time maximizing the margin of the training set."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3157053"
                        ],
                        "name": "Nanyun Peng",
                        "slug": "Nanyun-Peng",
                        "structuredName": {
                            "firstName": "Nanyun",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nanyun Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782853"
                        ],
                        "name": "Mark Dredze",
                        "slug": "Mark-Dredze",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dredze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Dredze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2007), including sequence and part-of-speech tagging (Blitzer et al., 2006; Peng and Dredze, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7178598,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "0daf48d0ce4e4200a753c28519f5761b160944fb",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Many domain adaptation approaches rely on learning cross domain shared representations to transfer the knowledge learned in one domain to other domains. Traditional domain adaptation only considers adapting for one task. In this paper, we explore multi-task representation learning under the domain adaptation scenario. We propose a neural network framework that supports domain adaptation for multiple tasks simultaneously, and learns shared representations that better generalize for domain adaptation. We apply the proposed framework to domain adaptation for sequence tagging problems considering two tasks: Chinese word segmentation and named entity recognition. Experiments show that multi-task domain adaptation works better than disjoint domain adaptation for each task, and achieves the state-of-the-art results for both tasks in the social media domain."
            },
            "slug": "Multi-task-Domain-Adaptation-for-Sequence-Tagging-Peng-Dredze",
            "title": {
                "fragments": [],
                "text": "Multi-task Domain Adaptation for Sequence Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A neural network framework is proposed that supports domain adaptation for multiple tasks simultaneously, and learns shared representations that better generalize for domain adaptation."
            },
            "venue": {
                "fragments": [],
                "text": "Rep4NLP@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997146"
                        ],
                        "name": "Yaroslav Fyodorov",
                        "slug": "Yaroslav-Fyodorov",
                        "structuredName": {
                            "firstName": "Yaroslav",
                            "lastName": "Fyodorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaroslav Fyodorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2104936402"
                        ],
                        "name": "YoadWinter NissimFrancez",
                        "slug": "YoadWinter-NissimFrancez",
                        "structuredName": {
                            "firstName": "YoadWinter",
                            "lastName": "NissimFrancez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "YoadWinter NissimFrancez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 65
                            }
                        ],
                        "text": "In this task, also known\nas recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 59
                            }
                        ],
                        "text": "In this task, also known as recognizing textual entailment (RTE; Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009), a model is presented with a pair of sentences\u2014like one of those in Figure 1\u2014 and asked to judge the relationship between their"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18306353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a3f127ce3047295d9967ccff19fd006ebc8841",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops a version of Natural Logic \u2013 an inference system that works directly on natural language syntactic representations, with no int ermediate translation to logical formulae. Following work by S\u00e1nchez (1991), we develop a small fragment t ha computes semantic order relations between derivation trees in Categorial Grammar. Unlike pre vious works, the proposed system has the following new characteristics: (i) It uses orderings betwe en derivation trees as purely syntactic units, derivable by a formal calculus. (ii) The system is extended f or conjunctive phenomena like coordination and relative clauses. This allows a simple account of non -m otonic expressions that are reducible to conjunctions of monotonic ones. (iii) A preliminary proof s earch algorithm based on a tree generating regular system is developed for S\u00e1nchez\u2019 smaller fragment of Natural Logic."
            },
            "slug": "A-Natural-Logic-Inference-System-Fyodorov-NissimFrancez",
            "title": {
                "fragments": [],
                "text": "A Natural Logic Inference System"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A version of Natural Logic \u2013 an inference system that works directly on natural language syntactic representations, with no immediate translation to logical formulae is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38956216"
                        ],
                        "name": "Lili Mou",
                        "slug": "Lili-Mou",
                        "structuredName": {
                            "firstName": "Lili",
                            "lastName": "Mou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lili Mou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144861196"
                        ],
                        "name": "Zhao Meng",
                        "slug": "Zhao-Meng",
                        "structuredName": {
                            "firstName": "Zhao",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhao Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055863231"
                        ],
                        "name": "Rui Yan",
                        "slug": "Rui-Yan",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410115257"
                        ],
                        "name": "Ge Li",
                        "slug": "Ge-Li",
                        "structuredName": {
                            "firstName": "Ge",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ge Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48615144"
                        ],
                        "name": "Yan Xu",
                        "slug": "Yan-Xu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156144568"
                        ],
                        "name": "Lu Zhang",
                        "slug": "Lu-Zhang",
                        "structuredName": {
                            "firstName": "Lu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700880"
                        ],
                        "name": "Zhi Jin",
                        "slug": "Zhi-Jin",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Jin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11866664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f21b36a5cfba94bbc6ed5c3642e1e46057deccaf",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Transfer learning is aimed to make use of valuable knowledge in a source domain to help model performance in a target domain. It is particularly important to neural networks, which are very likely to be overfitting. In some fields like image processing, many studies have shown the effectiveness of neural network-based transfer learning. For neural NLP, however, existing studies have only casually applied transfer learning, and conclusions are inconsistent. In this paper, we conduct systematic case studies and provide an illuminating picture on the transferability of neural networks in NLP."
            },
            "slug": "How-Transferable-are-Neural-Networks-in-NLP-Mou-Meng",
            "title": {
                "fragments": [],
                "text": "How Transferable are Neural Networks in NLP Applications?"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "In this paper, systematic case studies are conducted and an illuminating picture is provided on the transferability of neural networks in NLP."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769407"
                        ],
                        "name": "M. Aloni",
                        "slug": "M.-Aloni",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Aloni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Aloni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113837390"
                        ],
                        "name": "P. Dekker",
                        "slug": "P.-Dekker",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Dekker",
                            "middleNames": [
                                "J.",
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dekker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 200
                            }
                        ],
                        "text": "\u2022 PRESUPPOSITION TRIGGERS: Single words that trigger presuppositions\u2014an assumption(s) that must be accepted in order for certain words to be appropriately used in a certain context (see Stalnaker 1974; Schlenker 2016)\u2014e.g. again, too, anymore.2\n\u2022 CONDITIONALS: The word if."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63247695,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "21a8639e793f6624dc3dea58cda60ac385f9838d",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Formal semantics \u2013 the scientific study of meaning in natural language \u2013 is one of the most fundamental and longest-established areas of linguistics. This handbook offers a comprehensive yet compact guide to the field, bringing together research from a wide range of world-leading experts. Chapters include coverage of the historical context and foundation of contemporary formal semantics, a survey of the variety of formal/logical approaches to linguistic meaning, and an overview of the major areas of research within current semantic theory, broadly conceived. The handbook also explores the interfaces between semantics and neighbouring disciplines, including research in cognition and computation. This work will be essential reading for students and researchers working in linguistics, philosophy, psychology, and computer science."
            },
            "slug": "The-Cambridge-Handbook-of-Formal-Semantics-Aloni-Dekker",
            "title": {
                "fragments": [],
                "text": "The Cambridge Handbook of Formal Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This handbook offers a comprehensive yet compact guide to the field, bringing together research from a wide range of world-leading experts, and explores the interfaces between semantics and neighbouring disciplines, including research in cognition and computation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 40
                            }
                        ],
                        "text": "For the CBOW and\nBiLSTM models, we tune Dropout on the SNLI development set and find that a drop rate of 0.1 works well."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 16
                            }
                        ],
                        "text": "We use Dropout (Srivastava et al., 2014) for regularization."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": true,
            "numCitedBy": 28158,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50196944"
                        ],
                        "name": "Judy Hoffman",
                        "slug": "Judy-Hoffman",
                        "structuredName": {
                            "firstName": "Judy",
                            "lastName": "Hoffman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judy Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152329702"
                        ],
                        "name": "Ning Zhang",
                        "slug": "Ning-Zhang",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ning Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368132"
                        ],
                        "name": "Eric Tzeng",
                        "slug": "Eric-Tzeng",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Tzeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Tzeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ossible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014). However, attempts to bring this kind of general purpose representation learning to NLU have seen only very limited successes (see, for example, Mou et al., 2016a). Nearly all successful applications"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 271
                            }
                        ],
                        "text": "\u2026areas outside NLU,\nartificial neural network techniques have made it possible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6161478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8de958fead0d8a9619b55c7299df3257c624a96",
            "isKey": false,
            "numCitedBy": 4237,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms."
            },
            "slug": "DeCAF:-A-Deep-Convolutional-Activation-Feature-for-Donahue-Jia",
            "title": {
                "fragments": [],
                "text": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "DeCAF, an open-source implementation of deep convolutional activation features, along with all associated network parameters, are released to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 70
                            }
                        ],
                        "text": "The second uses the average of the states of a bidirectional LSTM RNN (BiLSTM; Hochreiter and Schmidhuber, 1997) over the words to compute representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 51702,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9817314"
                        ],
                        "name": "I. Heim",
                        "slug": "I.-Heim",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Heim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Heim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2824542"
                        ],
                        "name": "A. Kratzer",
                        "slug": "A.-Kratzer",
                        "structuredName": {
                            "firstName": "Angelika",
                            "lastName": "Kratzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kratzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "hosen key words indicative of additional interesting phenomena. The hand-chosen tag set covers the following phenomena: QUANTIFIERS contains single words with quanti\ufb01cational force (see, for example, Heim and Kratzer, 1998; Szabolcsi, 2010, e.g., many, all, few, some); BELIEF VERBS contains sentence-embedding verbs denoting mental states (e.g., know, believe, think), including irregular past tense forms; TIME TERMS con"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57341324,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "0dc0d0cfebc2ea1f88c64a159a76d0cb8258bff9",
            "isKey": false,
            "numCitedBy": 2585,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Truth-conditional Semantics and the Fregean Program. 2. Executing the Fregean Program. 3. Semantics and Syntax. 4. More of English: Non-verbal Predicates, Modifiers, Definite Descriptions. 5. Relative Clauses, Variables, Variable Binding. 6. Quantifiers: Their Semantic Type. 7. Quantification and Grammar. 8. Syntactic and Semantic Constraints on Quantifier Movement. 9. Bound and Referential Pronouns and Ellipsis. 10. Syntactic and Semantic Binding. 11. E-Type Anaphora. 12. First Steps Towards an Intensional Semantics. Index."
            },
            "slug": "Semantics-in-generative-grammar-Heim-Kratzer",
            "title": {
                "fragments": [],
                "text": "Semantics in generative grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This chapter discusses truth-conditional Semantics and the Fregean Program, and first steps towards an Intensional Semantics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90091,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052690705"
                        ],
                        "name": "Peter Young",
                        "slug": "Peter-Young",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068187980"
                        ],
                        "name": "Alice Lai",
                        "slug": "Alice-Lai",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alice Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170746"
                        ],
                        "name": "M. Hodosh",
                        "slug": "M.-Hodosh",
                        "structuredName": {
                            "firstName": "Micah",
                            "lastName": "Hodosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hodosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 87
                            }
                        ],
                        "text": "SNLI consists only of sentences derived from image captions from the Flickr30k corpus (Young et al., 2014), and thus can be treated as a large additional CAPTIONS genre."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 86
                            }
                        ],
                        "text": "SNLI consists only of sentences derived from image captions from the Flickr30k corpus (Young et al., 2014), and thus can be treated as a large ad-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3104920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44040913380206991b1991daf1192942e038fe31",
            "isKey": false,
            "numCitedBy": 1324,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to use the visual denotations of linguistic expressions (i.e. the set of images they describe) to define novel denotational similarity metrics, which we show to be at least as beneficial as distributional similarities for two tasks that require semantic inference. To compute these denotational similarities, we construct a denotation graph, i.e. a subsumption hierarchy over constituents and their denotations, based on a large corpus of 30K images and 150K descriptive captions."
            },
            "slug": "From-image-descriptions-to-visual-denotations:-New-Young-Lai",
            "title": {
                "fragments": [],
                "text": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "This work proposes to use the visual denotations of linguistic expressions to define novel denotational similarity metrics, which are shown to be at least as beneficial as distributional similarities for two tasks that require semantic inference."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 200
                            }
                        ],
                        "text": "artificial neural network techniques have made it possible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 221
                            }
                        ],
                        "text": "\u2026areas outside NLU,\nartificial neural network techniques have made it possible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80959,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 200
                            }
                        ],
                        "text": "artificial neural network techniques have made it possible to train general-purpose feature extractors that, with no or minimal retraining, can extract useful features for a variety of styles of data (Krizhevsky et al., 2012; Zeiler and Fergus, 2014; Donahue et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3960646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a2a770d23b4a171fa81de62a78a3deb0588f238",
            "isKey": false,
            "numCitedBy": 11816,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets."
            },
            "slug": "Visualizing-and-Understanding-Convolutional-Zeiler-Fergus",
            "title": {
                "fragments": [],
                "text": "Visualizing and Understanding Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel visualization technique is introduced that gives insight into the function of intermediate feature layers and the operation of the classifier in large Convolutional Network models, used in a diagnostic role to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145707832"
                        ],
                        "name": "Henry Davis",
                        "slug": "Henry-Davis",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2743361"
                        ],
                        "name": "L. Matthewson",
                        "slug": "L.-Matthewson",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Matthewson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Matthewson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 240649088,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "7d3a1374a10488ed63cdf288e60fb726a63244c8",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The basic unit of truth functional logic was the statement. Out of statements, statement variables and truth functional connectives, we developed a statement calculus. The units with which we will now be dealing include predicates and the individuals to whom those predicates are applied. Upper case letters will be used as predicate constants. Lower case letters, \"a\" through \"v\" will be used as individual constants. Lower case letters, \"x\" through \"z\", will be used as individual variables. A limitation of traditional categorical logic was the lack of an easy and effective way of dealing with individuals. The statement, \"Socrates is mortal,\" was translated into standard form as \"All persons identical to Socrates are mortals.\" Using \"s\" as an individual constant abbreviating the proper name, \"Socrates,\" and \"Mx\" abbreviating the predicate \"x is mortal,\" we can express the statement \"Socrates is mortal\" as: Ms substituting the individual constant \"s\" for the \"x\". \"Socrates is a wise mortal\" can be symbolized as the truth functionally compound statement, Ws & Ms which we read as \"Socrates is wise and Socrates is mortal.\""
            },
            "slug": "Quantification-Davis-Matthewson",
            "title": {
                "fragments": [],
                "text": "Quantification"
            },
            "venue": {
                "fragments": [],
                "text": "The Routledge Handbook of North American Languages"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50419262"
                        ],
                        "name": "S. Pulman",
                        "slug": "S.-Pulman",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pulman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pulman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62490646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c50d5222ebeeeacb8663f2e369dd4acf0ce8015",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "It\u2019s shameless-plug time: the authors of this book are also the co-creators of the open-source Ajax framework Taconite. We admit this is a bit self-serving, but seriously, we think Taconite is pretty sweet. While originally built for Java Enterprise Edition\u2013based applications, we have refactored the core of Taconite into a client-side library that can easily be used with any server-side technology. Beyond that, it wouldn\u2019t be terribly hard to port the Taconite serverside components to other technologies such as .NET. What makes Taconite so special? Ajax is a fantastic step forward in the evolution of the Web application. However, we\u2019ve struggled over the years with the inconsistencies among browsers and the difficulty inherent in developing massive quantities of JavaScript. Since we\u2019re basically lazy, we decided to just \u201cbuild it once\u201d so we could easily reuse our hard work. (Besides, we can tell our bosses it\u2019ll take three weeks, get it done in one, and spend the rest of the time following the trials and tribulations of the Minnesota Vikings.) CHAPTER 8 n PUTTING IT ALL TOGETHER 226"
            },
            "slug": "Using-the-Framework-Pulman",
            "title": {
                "fragments": [],
                "text": "Using the Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "It\u2019s shameless-plug time: the authors of this book are also the co-creators of the open-source Ajax framework Taconite, which has been refactored into a client-side library that can be used with any server-side technology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055347517"
                        ],
                        "name": "P. Boyd",
                        "slug": "P.-Boyd",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Boyd",
                            "middleNames": [
                                "Larry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Boyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215478406,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "962290fc50c69ccbb4d812033f2572d4d6419a77",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Contributions to a recent conference of psychiatrists from 17 ) countries on the subject of the adolescent in his national setting are collected in this book. It outlines some details of his background ln sociological and cultural terms, and some of the foreground in terms normative and deviant behaviour, together with comments on treatI \"lent and treatment facilities. The size and style of the book J^ake for easy and pleasant reading, ?ut it is disappointing and unsatisfying precisely because it is so Str>al| and because individual conj1 tr'butors failed to follow the original ^andate given to them by the Editor. So the reader does not have a real opportunity to make comI Parisons within a comprehensive ,rarriework. As a book of reference it fails to"
            },
            "slug": "Youth-Boyd",
            "title": {
                "fragments": [],
                "text": "Youth"
            },
            "venue": {
                "fragments": [],
                "text": "Mental Health"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116536623"
                        ],
                        "name": "B. Abdullah",
                        "slug": "B.-Abdullah",
                        "structuredName": {
                            "firstName": "Bjj",
                            "lastName": "Abdullah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Abdullah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5618841"
                        ],
                        "name": "K. Ng",
                        "slug": "K.-Ng",
                        "structuredName": {
                            "firstName": "Kh",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10532517,
            "fieldsOfStudy": [
                "Medicine",
                "Political Science"
            ],
            "id": "aa9f17d355583203be11c519a87c52562c53b138",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Medical tourism involves travelling to other countries to avail medical, dental, or surgical care. A combination of various factors, such as exorbitant costs of healthcare in industrialised nations, the increased ease and affordability of international travel, favourable currency exchange rates in the global economy, rapidly improving medical technology and standards of care in many countries as well as the ubiquitous Internet, have led to the recent increase in its popularity. The medical tourism market is estimated to grow by USD 2.2 billion with a corresponding increase of USD 60 billion in the healthcare market [1]. Western Europeans and Canadians bypass the long wait periods that are part of their national health plans by getting medical care abroad. Ten per cent of EU patients seek treatment outside their own country and spend an estimated 12 billion Euro [2]. Medical tourism is a rapidly growing industry even in the so-called developing countries, with countries like Mexico, Brazil, Costa Rica, Dominican Republic, Hungary, India, Israel, Jordan, Lithuania, Malaysia, South Africa, Thailand and the Philippines actively promoting it [3]. According to a UN study, the cost differentials for medical services for a variety of procedures may be: \u2022 A heart-valve replacement that would cost USD 200,000 in the US is available for USD 10,000 in India inclusive of the round trip airfare and a vacation package. \u2022 A joint replacement in Thailand with eight days of physical therapy at a luxury resort costs less than USD 9,000. \u2022 Cosmetic-surgery savings are even greater: A full facelift that would cost USD 20,000 in the US is about USD 1,250 in South Africa [1]. \u2022 A PET/CT scan performed in Melbourne inclusive of airfare and accommodation in a 4-star hotel is cheaper than what it costs in Singapore, with some pocket money to spare."
            },
            "slug": "The-sky-is-falling-Abdullah-Ng",
            "title": {
                "fragments": [],
                "text": "The sky is falling"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Medical tourism is a rapidly growing industry even in the so-called developing countries, with countries like Mexico, Brazil, Costa Rica, Dominican Republic, Hungary, India, Israel, Jordan, Lithuania, Malaysia, South Africa, Thailand and the Philippines actively promoting it."
            },
            "venue": {
                "fragments": [],
                "text": "Biomedical imaging and intervention journal"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1411865852"
                        ],
                        "name": "B. Schmidt-nielsen",
                        "slug": "B.-Schmidt-nielsen",
                        "structuredName": {
                            "firstName": "Bodil",
                            "lastName": "Schmidt-nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schmidt-nielsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1411865852"
                        ],
                        "name": "B. Schmidt-nielsen",
                        "slug": "B.-Schmidt-nielsen",
                        "structuredName": {
                            "firstName": "Bodil",
                            "lastName": "Schmidt-nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schmidt-nielsen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15852134,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "46a0c1cb9fc6766b1565094986ec890b7f461f7a",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In 2005, The American Physiological Society initiated The Living History of Physiology Project to recognize senior members who have made extraordinary contributions during their career to the advancement of the discipline and profession of physiology. Each physiologist will be interviewed for archival purposes, and the video tape will be available from the American Physiological Society Headquarters. In addition, a biographical profile of the recipient will be published in Advances in Physiology Education."
            },
            "slug": "Living-History-Schmidt-nielsen-Schmidt-nielsen",
            "title": {
                "fragments": [],
                "text": "Living History"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "In 2005, The American Physiological Society initiated The Living History of Physiology Project to recognize senior members who have made extraordinary contributions during their career to the advancement of the discipline and profession of physiology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47395514"
                        ],
                        "name": "P. Unger",
                        "slug": "P.-Unger",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Unger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Unger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101797300"
                        ],
                        "name": "M. Munitz",
                        "slug": "M.-Munitz",
                        "structuredName": {
                            "firstName": "Milton",
                            "lastName": "Munitz",
                            "middleNames": [
                                "Karl"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Munitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61932975,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "eff0c00d9269c9b68f2392a09fe0b8cc91c3d426",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semantics-and-Philosophy-Unger-Munitz",
            "title": {
                "fragments": [],
                "text": "Semantics and Philosophy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Youth. Space Science Fiction Magazine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 184
                            }
                        ],
                        "text": "\u2022 PRESUPPOSITION TRIGGERS: Single words that trigger presuppositions\u2014an assumption(s) that must be accepted in order for certain words to be appropriately used in a certain context (see Stalnaker 1974; Schlenker 2016)\u2014e.g. again, too, anymore.2\n\u2022 CONDITIONALS: The word if."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantics and Philosophy, chapter Pragmatic Presupposition, pages 197\u2013213"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Integrating linguistic resources: The national corpus model"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. LREC."
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Secret Adversary"
            },
            "venue": {
                "fragments": [],
                "text": "Dodd, Mead."
            },
            "year": 1922
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantics in generative grammar . Blackwell Publishers . Sepp Hochreiter and J\u00fcrgen Schmidhuber . 1997 . Long short - term memory"
            },
            "venue": {
                "fragments": [],
                "text": "Neural computation"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A fast unified"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Living History. CreateSpace Independent Publishing Platform"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Captain Blood"
            },
            "venue": {
                "fragments": [],
                "text": "Houghton Mifflin Company."
            },
            "year": 1922
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This figure \"sentence_dist.png\" is available in \"png"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Seven Swords"
            },
            "venue": {
                "fragments": [],
                "text": "Published online."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A decomposable atten"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mysterious Affair at Styles"
            },
            "venue": {
                "fragments": [],
                "text": "The Bodley Head."
            },
            "year": 1921
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Password Incorrect. Published online. Author also known as Piotr Kowalczyk"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 184
                            }
                        ],
                        "text": "\u2022 PRESUPPOSITION TRIGGERS: Single words that trigger presuppositions\u2014an assumption(s) that must be accepted in order for certain words to be appropriately used in a certain context (see Stalnaker 1974; Schlenker 2016)\u2014e.g. again, too, anymore.2\n\u2022 CONDITIONALS: The word if."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantics and Philosophy, New York, NY: New York University Press, chapter Pragmatic Presupposition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Rebel Spurs. The World Publishing Company"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Murder In the Gun Room"
            },
            "venue": {
                "fragments": [],
                "text": "H.B. Piper, New York."
            },
            "year": 1953
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2016b. Natural language inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "seven_ swords.html, shared with the author's permission. 9 manybooks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Captain Blood. Houghton Mifflin Company"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1922
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mysterious Affair at Styles. The Bodley Head"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1921
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 184
                            }
                        ],
                        "text": "\u2022 PRESUPPOSITION TRIGGERS: Single words that trigger presuppositions\u2014an assumption(s) that must be accepted in order for certain words to be appropriately used in a certain context (see Stalnaker 1974; Schlenker 2016)\u2014e.g. again, too, anymore.2\n\u2022 CONDITIONALS: The word if."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantics and Philosophy, New York University Press, chapter Pragmatic Presupposition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2016a. How transferable are"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 30,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 67,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Broad-Coverage-Challenge-Corpus-for-Sentence-Williams-Nangia/5ded2b8c64491b4a67f6d39ce473d4b9347a672e?sort=total-citations"
}