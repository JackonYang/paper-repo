{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115432683"
                        ],
                        "name": "Ting Liu",
                        "slug": "Ting-Liu",
                        "structuredName": {
                            "firstName": "Ting",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ting Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760402"
                        ],
                        "name": "A. Moore",
                        "slug": "A.-Moore",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703070"
                        ],
                        "name": "Alexander G. Gray",
                        "slug": "Alexander-G.-Gray",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Gray",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander G. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143781496"
                        ],
                        "name": "Ke Yang",
                        "slug": "Ke-Yang",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 12
                            }
                        ],
                        "text": "Liu et al. (Liu et al., 2004) propose a new kind of metric tree that allows an overlap between the children of each node, called the spill-tree."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "(Liu et al., 2004) propose a new kind of metric tree that allows an overlap between the children of each node, called the spill-tree."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12565844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d394976d52f40bf14652de10b30fb9326c20f19",
            "isKey": false,
            "numCitedBy": 447,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper concerns approximate nearest neighbor searching algorithms, which have become increasingly important, especially in high dimensional perception areas such as computer vision, with dozens of publications in recent years. Much of this enthusiasm is due to a successful new approximate nearest neighbor approach called Locality Sensitive Hashing (LSH). In this paper we ask the question: can earlier spatial data structure approaches to exact nearest neighbor, such as metric trees, be altered to provide approximate answers to proximity queries and if so, how? We introduce a new kind of metric tree that allows overlap: certain datapoints may appear in both the children of a parent. We also introduce new approximate k-NN search algorithms on this structure. We show why these structures should be able to exploit the same random-projection-based approximations that LSH enjoys, but with a simpler algorithm and perhaps with greater efficiency. We then provide a detailed empirical evaluation on five large, high dimensional datasets which show up to 31-fold accelerations over LSH. This result holds true throughout the spectrum of approximation levels."
            },
            "slug": "An-Investigation-of-Practical-Approximate-Nearest-Liu-Moore",
            "title": {
                "fragments": [],
                "text": "An Investigation of Practical Approximate Nearest Neighbor Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper asks the question: can earlier spatial data structure approaches to exact nearest neighbor, such as metric trees, be altered to provide approximate answers to proximity queries and if so, how and why and introduces a new kind of metric tree that allows overlap."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116168"
                        ],
                        "name": "J. Beis",
                        "slug": "J.-Beis",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Beis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "Examples of such problems include finding the best matches for local image features in large datasets (Lowe, 2004; Philbin et al., 2007), clustering local features into visual words using the k-means or similar algorithms (Sivic and Zisserman, 2003), or performing normalized cross-correlation to compare image patches in large datasets (Torralba et al., 2008)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": "Beis and Lowe (Beis and Lowe, 1997) describe a similar kd-tree based algorithm, but use a stopping criterion based on examining a fixed number Emax of leaf nodes, which can give better performance than the \u03b5-approximate cutoff."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Beis and Lowe ( Beis and Lowe, 1997 ) describe a similar kd-tree based algorithm, but use a stopping criterion based on examining a fixed number Emax of leaf nodes, which can give better performance than the e-approximate cutoff."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 270664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef05b72c9e5b267811d4a069fb1d8038f0e36bbd",
            "isKey": false,
            "numCitedBy": 1093,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Shape indexing is a way of making rapid associations between features detected in an image and object models that could have produced them. When model databases are large, the use of high-dimensional features is critical, due to the improved level of discrimination they can provide. Unfortunately, finding the nearest neighbour to a query point rapidly becomes inefficient as the dimensionality of the feature space increases. Past indexing methods have used hash tables for hypothesis recovery, but only in low-dimensional situations. In this paper we show that a new variant of the k-d tree search algorithm makes indexing in higher-dimensional spaces practical. This Best Bin First, or BBF search is an approximate algorithm which finds the nearest neighbour for a large fraction of the queries, and a very close neighbour in the remaining cases. The technique has been integrated into a fully developed recognition system, which is able to detect complex objects in real, cluttered scenes in just a few seconds."
            },
            "slug": "Shape-indexing-using-approximate-nearest-neighbour-Beis-Lowe",
            "title": {
                "fragments": [],
                "text": "Shape indexing using approximate nearest-neighbour search in high-dimensional spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper shows that a new variant of the k-d tree search algorithm makes indexing in higher-dimensional spaces practical, and is integrated into a fully developed recognition system, which is able to detect complex objects in real, cluttered scenes in just a few seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786259"
                        ],
                        "name": "S. Brin",
                        "slug": "S.-Brin",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Brin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 94
                            }
                        ],
                        "text": "When using zero iterations in the k-means clustering we obtain the more general GNAT tree of (Brin, 1995), which assumes that the data lives in a generic metric space, not in a vector space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 6
                            }
                        ],
                        "text": "Brin (Brin, 1995) proposes a similar tree, called GNAT, Geometric Near-neighbor Access Tree, in which he uses some of the data points as the cluster centers instead of computing the cluster mean points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8041967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6438d00d2d916568eadd630617ed0a54f8b98b9a",
            "isKey": false,
            "numCitedBy": 630,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Given user data, one often wants to find approximate matches in a large database. A good example of such a task is finding images similar to a given image in a large collection of images. We focus on the important and technically diffcult case where each data element is high dimensional, or more generally, is represented by a point in a large metric spaceand distance calculations are computationally expensive. In this paper we introduce a data structure to solve this problem called a GNAT { Geometric Near-neighbor Access Tree. It is based on the philosophy that the data structure should act as a hierarchical geometrical model of the data as opposed to a simple decomposition of the data that does not use its intrinsic geometry. In experiments, we find that GNAT's outperform previous data structures in a number of applications. Keywords { near neighbor, metric space, approximate queries, data mining, Dirichlet domains, Voronoi regions"
            },
            "slug": "Near-Neighbor-Search-in-Large-Metric-Spaces-Brin",
            "title": {
                "fragments": [],
                "text": "Near Neighbor Search in Large Metric Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A data structure to solve the problem of finding approximate matches in a large database called a GNAT { Geometric Near-neighbor Access Tree} is introduced based on the philosophy that the data structure should act as a hierarchical geometrical model of the data as opposed to a simple decomposition of theData that does not use its intrinsic geometry."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738395"
                        ],
                        "name": "Alexandr Andoni",
                        "slug": "Alexandr-Andoni",
                        "structuredName": {
                            "firstName": "Alexandr",
                            "lastName": "Andoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandr Andoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "\u2026(the multiple randomized kd-trees and the hierarchical kmeans tree) with existing approaches, the ANN (Arya et al., 1998) and LSH algorithms (Andoni, 2006)3 on\n2http://www.vis.uky.edu/\u0303 stewe/ukbench/data/ 3We have used the publicly available implementations\nthe first dataset of 100,000\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 27
                            }
                        ],
                        "text": ", 1998) and LSH algorithms (Andoni, 2006) 3 on the first dataset of 100,000 SIFT features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6468963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf779b9ca68b915a8807ec6e99c084b4d6de549a",
            "isKey": false,
            "numCitedBy": 1495,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O(dn 1c2/+o(1)) and space O(dn + n1+1c2/+o(1)). This almost matches the lower bound for hashing-based algorithm recently obtained in (R. Motwani et al., 2006). We also obtain a space-efficient version of the algorithm, which uses dn+n logO(1) n space, with a query time of dnO(1/c2). Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders for the Leech lattice"
            },
            "slug": "Near-Optimal-Hashing-Algorithms-for-Approximate-in-Andoni-Indyk",
            "title": {
                "fragments": [],
                "text": "Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O(dn 1c2/+o(1)) and space O(DN + n1+1c2 + o(1) + 1/c2), which almost matches the lower bound for hashing-based algorithm recently obtained."
            },
            "venue": {
                "fragments": [],
                "text": "2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 12
                            }
                        ],
                        "text": "Similarly, (Mikolajczyk and Matas, 2007) evaluates the nearest neighbor matching performance for several tree structures, including the kd-tree, the hierarchical k-means tree, and the agglomerative tree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 34
                            }
                        ],
                        "text": "Similar results were reported in (Mikolajczyk and Matas, 2007)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8475287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "252dc222e485daa8180f7db9f2107efb1434a624",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose to transform an image descriptor so that nearest neighbor (NN) search for correspondences becomes the optimal matching strategy under the assumption that inter-image deviations of corresponding descriptors have Gaussian distribution. The Euclidean NN in the transformed domain corresponds to the NN according to a truncated Mahalanobis metric in the original descriptor space. We provide theoretical justification for the proposed approach and show experimentally that the transformation allows a significant dimensionality reduction and improves matching performance of a state-of-the art SIFT descriptor. We observe consistent improvement in precision-recall and speed of fast matching in tree structures at the expense of little overhead for projecting the descriptors into transformed space. In the context of SIFT vs. transformed M- SIFT comparison, tree search structures are evaluated according to different criteria and query types. All search tree experiments confirm that transformed M-SIFTperforms better than the original SIFT."
            },
            "slug": "Improving-Descriptors-for-Fast-Tree-Matching-by-Mikolajczyk-Matas",
            "title": {
                "fragments": [],
                "text": "Improving Descriptors for Fast Tree Matching by Optimal Linear Projection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown experimentally that the transformation allows a significant dimensionality reduction and improves matching performance of a state-of-the art SIFT descriptor and consistent improvement in precision-recall and speed of fast matching in tree structures at the expense of little overhead for projecting the descriptors into transformed space."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2031033"
                        ],
                        "name": "P. Narendra",
                        "slug": "P.-Narendra",
                        "structuredName": {
                            "firstName": "Patrenahalli",
                            "lastName": "Narendra",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Narendra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 184
                            }
                        ],
                        "text": "Similarly, (Mikolajczyk and Matas, 2007) evaluates the nearest neighbor matching performance for several tree structures, including the kd-tree, the hierarchical k-means tree, and the agglomerative tree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 23
                            }
                        ],
                        "text": "Fukunaga and Narendra (Fukunaga and Narendra, 1975) propose that nearest-neighbor matching be performed with a tree structure constructed by clustering the data points with the k-means algorithm into k disjoint groups and then recursively doing the same for each of the groups."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 136
                            }
                        ],
                        "text": "Their method is based on accessing a single leaf node of a hierarchi-\ncal k-means tree similar to that proposed by Fukunaga and Narendra (Fukunaga and Narendra, 1975)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5941649,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72713a8e1e0fe291b28513dee97596690f4e1376",
            "isKey": false,
            "numCitedBy": 700,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Computation of the k-nearest neighbors generally requires a large number of expensive distance computations. The method of branch and bound is implemented in the present algorithm to facilitate rapid calculation of the k-nearest neighbors, by eliminating the necesssity of calculating many distances. Experimental results demonstrate the efficiency of the algorithm. Typically, an average of only 61 distance computations were made to find the nearest neighbor of a test sample among 1000 design samples."
            },
            "slug": "A-Branch-and-Bound-Algorithm-for-Computing-Fukunaga-Narendra",
            "title": {
                "fragments": [],
                "text": "A Branch and Bound Algorithm for Computing k-Nearest Neighbors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The method of branch and bound is implemented in the present algorithm to facilitate rapid calculation of the k-nearest neighbors, by eliminating the necesssity of calculating many distances."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066819269"
                        ],
                        "name": "James Philbin",
                        "slug": "James-Philbin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Philbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Philbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12203312,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28e4b8ebbdb0e80f03b6f0578deeb38694af081e",
            "isKey": false,
            "numCitedBy": 2923,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a large-scale object retrieval system. The user supplies a query object by selecting a region of a query image, and the system returns a ranked list of images that contain the same object, retrieved from a large corpus. We demonstrate the scalability and performance of our system on a dataset of over 1 million images crawled from the photo-sharing site, Flickr [3], using Oxford landmarks as queries. Building an image-feature vocabulary is a major time and performance bottleneck, due to the size of our dataset. To address this problem we compare different scalable methods for building a vocabulary and introduce a novel quantization method based on randomized trees which we show outperforms the current state-of-the-art on an extensive ground-truth. Our experiments show that the quantization has a major effect on retrieval quality. To further improve query performance, we add an efficient spatial verification stage to re-rank the results returned from our bag-of-words model and show that this consistently improves search quality, though by less of a margin when the visual vocabulary is large. We view this work as a promising step towards much larger, \"web-scale \" image corpora."
            },
            "slug": "Object-retrieval-with-large-vocabularies-and-fast-Philbin-Chum",
            "title": {
                "fragments": [],
                "text": "Object retrieval with large vocabularies and fast spatial matching"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "To improve query performance, this work adds an efficient spatial verification stage to re-rank the results returned from the bag-of-words model and shows that this consistently improves search quality, though by less of a margin when the visual vocabulary is large."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696575"
                        ],
                        "name": "J. Bentley",
                        "slug": "J.-Bentley",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Bentley",
                            "middleNames": [
                                "Louis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bentley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236311"
                        ],
                        "name": "R. Finkel",
                        "slug": "R.-Finkel",
                        "structuredName": {
                            "firstName": "Raphael",
                            "lastName": "Finkel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Finkel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The most widely used algorithm for nearest-neighbor search is the kd-tree (Freidman et al., 1977), which works well for exact nearest neighbor search in lowdimensional data, but quickly loses its effectiveness as dimensionality increases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The classical kd-tree algorithm (Freidman et al., 1977) is efficient in low dimensions, but in high dimensions the performance rapidly degrades."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10811510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cab3c73f1b2140231b98944c720100b356d91b28",
            "isKey": false,
            "numCitedBy": 2964,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm and data structure are presented for searching a file containing N records, each described by k real valued keys, for the m closest matches or nearest neighbors to a given query record. The computation required to organize the file is proportional to kNlogN. The expected number of records examined in each search is independent of the file size. The expected computation to perform each search is proportional to logN. Empirical evidence suggests that except for very small files, this algorithm is considerably faster than other methods."
            },
            "slug": "An-Algorithm-for-Finding-Best-Matches-in-Expected-Friedman-Bentley",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Finding Best Matches in Logarithmic Expected Time"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An algorithm and data structure are presented for searching a file containing N records, each described by k real valued keys, for the m closest matches or nearest neighbors to a given query record."
            },
            "venue": {
                "fragments": [],
                "text": "TOMS"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 276
                            }
                        ],
                        "text": "\u2026local image features in large datasets (Lowe, 2004; Philbin et al., 2007), clustering local features into visual words using the k-means or similar algorithms (Sivic and Zisserman, 2003), or performing normalized cross-correlation to compare image patches in large datasets (Torralba et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7487588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54d2b5c64a67f65c5dd812b89e07973f97699552",
            "isKey": false,
            "numCitedBy": 1868,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors."
            },
            "slug": "80-Million-Tiny-Images:-A-Large-Data-Set-for-Object-Torralba-Fergus",
            "title": {
                "fragments": [],
                "text": "80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "For certain classes that are particularly prevalent in the dataset, such as people, this work is able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 103
                            }
                        ],
                        "text": "Examples of such problems include finding the best matches for local image features in large datasets (Lowe, 2004; Philbin et al., 2007), clustering local features into visual words using the k-means or similar algorithms (Sivic and Zisserman, 2003), or performing normalized cross-correlation to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Examples of such problems include finding the best matches for local image features in large datasets ( Lowe, 2004;  Philbin et al., 2007), clustering local features into visual words using the k-means or similar algorithms (Sivic and Zisserman, 2003), or performing normalized cross-correlation to compare image patches in large datasets (Torralba et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221242327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c04f169203f9e55056a6f7f956695babe622a38",
            "isKey": false,
            "numCitedBy": 12997,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene and can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404628011"
                        ],
                        "name": "Chanop Silpa-Anan",
                        "slug": "Chanop-Silpa-Anan",
                        "structuredName": {
                            "firstName": "Chanop",
                            "lastName": "Silpa-Anan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chanop Silpa-Anan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 24
                            }
                        ],
                        "text": "Silpa-Anan and Hartley (Silpa-Anan and Hartley, 2008) propose the use of multiple randomized kdtrees as a means to speed up approximate nearestneighbor search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 24
                            }
                        ],
                        "text": "Silpa-Anan and Hartley (Silpa-Anan and Hartley, 2008) have recently proposed an improved version of the kd-tree algorithm in which multiple randomized kd-trees are created."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 48
                            }
                        ],
                        "text": "This algorithm has only been proposed recently (Silpa-Anan and Hartley, 2004; SilpaAnan and Hartley, 2008) and has not been widely tested."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10191182,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09d947e7cd215abf5d45463b64859ddc0f7e1a8e",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we look at improving the KD-tree for a specific usage: indexing a large number of SIFT and other types of image descriptors. We have extended priority search, to priority search among multiple trees. By creating multiple KD-trees from the same data set and simultaneously searching among these trees, we have improved the KD-treepsilas search performance significantly.We have also exploited the structure in SIFT descriptors (or structure in any data set) to reduce the time spent in backtracking. By using Principal Component Analysis to align the principal axes of the data with the coordinate axes, we have further increased the KD-treepsilas search performance."
            },
            "slug": "Optimised-KD-trees-for-fast-image-descriptor-Silpa-Anan-Hartley",
            "title": {
                "fragments": [],
                "text": "Optimised KD-trees for fast image descriptor matching"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper has extended priority search, to priority search among multiple trees, by creating multiple KD-trees from the same data set and simultaneously searching among these trees, and improved the KD-treepsilas search performance significantly."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404628011"
                        ],
                        "name": "Chanop Silpa-Anan",
                        "slug": "Chanop-Silpa-Anan",
                        "structuredName": {
                            "firstName": "Chanop",
                            "lastName": "Silpa-Anan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chanop Silpa-Anan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 48
                            }
                        ],
                        "text": "This algorithm has only been proposed recently (Silpa-Anan and Hartley, 2004; SilpaAnan and Hartley, 2008) and has not been widely tested."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15521401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d4f1cd7d49f414ab80e11dfd1f2fa9a22d1b8cf",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper looks at the problem of building a visual map for later localisation using images from a typical digital camera. The main objective is an ability to query and match images in general position against a large image data set or an image-map. We have achieved a quick localisation in terms of finding a label of the map by finding similar images in the data set. We use affinely invariant Harris corners and sift descriptors to represent 2d images. A kd-tree is used for indexing, matching, and grouping the data set to form a visual map database. For this application, we have improved a voting technique for a 3d structure and a run-time efficiency of kd-tree to allow a quick finding of similar images and a quick localisation. The result can be applied to a more generic localisation (for mobile robotics) and may be integrated in a visual odometry system."
            },
            "slug": "Localisation-using-an-image-map-Silpa-Anan-Hartley",
            "title": {
                "fragments": [],
                "text": "Localisation using an image-map"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A voting technique for a 3d structure and a run-time efficiency of kd-tree are improved to allow a quick finding of similar images and a quick localisation of a visual map using images from a typical digital camera."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582852"
                        ],
                        "name": "Grant Schindler",
                        "slug": "Grant-Schindler",
                        "structuredName": {
                            "firstName": "Grant",
                            "lastName": "Schindler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Grant Schindler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735785"
                        ],
                        "name": "Matthew A. Brown",
                        "slug": "Matthew-A.-Brown",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brown",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew A. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The projections are constructed using the same technique as in ( Schindler et al., 2007 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14222017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbd2b4bbdf5b0b16e2f9db342bd902f3d851d094",
            "isKey": false,
            "numCitedBy": 660,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We look at the problem of location recognition in a large image dataset using a vocabulary tree. This entails finding the location of a query image in a large dataset containing 3times104 streetside images of a city. We investigate how the traditional invariant feature matching approach falls down as the size of the database grows. In particular we show that by carefully selecting the vocabulary using the most informative features, retrieval performance is significantly improved, allowing us to increase the number of database images by a factor of 10. We also introduce a generalization of the traditional vocabulary tree search algorithm which improves performance by effectively increasing the branching factor of a fixed vocabulary tree."
            },
            "slug": "City-Scale-Location-Recognition-Schindler-Brown",
            "title": {
                "fragments": [],
                "text": "City-Scale Location Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that by carefully selecting the vocabulary using the most informative features, retrieval performance is significantly improved, allowing us to increase the number of database images by a factor of 10."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 14
                            }
                        ],
                        "text": "We have used these experiments to guide our choice of algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 4
                            }
                        ],
                        "text": "In (Leibe et al., 2006) the authors propose an efficient method for clustering and matching features in large datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 266
                            }
                        ],
                        "text": "We have experimented with a number of variations, such as using the distance to the closest Voronoi border instead of the distance to the closest cluster center, using multiple randomized k-means trees, or using agglomerative clustering as proposed by Leibe et al. (Leibe et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 20
                            }
                        ],
                        "text": "However, these were found\nnot to give improved performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5143124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "463a59fe9e27004fbaac8700bb30a156d07e2f03",
            "isKey": true,
            "numCitedBy": 107,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of building object class representations\n based on local features and fast matching in a large database. We\n propose an efficient algorithm for hierarchical agglomerative clustering.\n We examine different agglomerative and partitional clustering strategies\n and compare the quality of obtained clusters. Our combination of\n partitional-agglomerative clustering gives significant improvement\n in terms of efficiency while maintaining the same quality of clusters.\n We also propose a method for building data structures for fast matching\n in high dimensional feature spaces. These improvements allow to\n deal with large sets of training data typically used in recognition\n of multiple object classes."
            },
            "slug": "Efficient-Clustering-and-Matching-for-Object-Class-Leibe-Mikolajczyk",
            "title": {
                "fragments": [],
                "text": "Efficient Clustering and Matching for Object Class Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes an efficient algorithm for hierarchical agglomerative clustering and proposes a method for building data structures for fast matching in high dimensional feature spaces."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3083483"
                        ],
                        "name": "D. Nist\u00e9r",
                        "slug": "D.-Nist\u00e9r",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nist\u00e9r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nist\u00e9r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3086037"
                        ],
                        "name": "Henrik Stew\u00e9nius",
                        "slug": "Henrik-Stew\u00e9nius",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Stew\u00e9nius",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henrik Stew\u00e9nius"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 22
                            }
                        ],
                        "text": "Nister and Stewenius (Nister and Stewenius, 2006) present a fast method for nearest-neighbor feature search in very large databases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 167
                            }
                        ],
                        "text": "We construct a 100K and 1 million SIFT features dataset by randomly sampling a dataset of over 5 million SIFT features extracted from a collection of CD cover images (Nister and Stewenius, 2006)2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1654266,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3e7d3e37e67af7f4546b46051063bea1b62dbae",
            "isKey": false,
            "numCitedBy": 3890,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD\u2019s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images."
            },
            "slug": "Scalable-Recognition-with-a-Vocabulary-Tree-Nist\u00e9r-Stew\u00e9nius",
            "title": {
                "fragments": [],
                "text": "Scalable Recognition with a Vocabulary Tree"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A recognition scheme that scales efficiently to a large number of objects and allows a larger and more discriminatory vocabulary to be used efficiently is presented, which it is shown experimentally leads to a dramatic improvement in retrieval quality."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724709"
                        ],
                        "name": "S. Arya",
                        "slug": "S.-Arya",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Arya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709509"
                        ],
                        "name": "D. Mount",
                        "slug": "D.-Mount",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mount",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mount"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712586"
                        ],
                        "name": "N. Netanyahu",
                        "slug": "N.-Netanyahu",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Netanyahu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Netanyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37746341"
                        ],
                        "name": "R. Silverman",
                        "slug": "R.-Silverman",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Silverman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736712"
                        ],
                        "name": "A. Wu",
                        "slug": "A.-Wu",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Wu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "The results for ANN are consistent with the experiment in figure 2, as ANN uses only a single kd-tree and does not benefit from the speedup due to using multiple randomized trees."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "\u2026at finding fast approximate nearest neighbors (the multiple randomized kd-trees and the hierarchical kmeans tree) with existing approaches, the ANN (Arya et al., 1998) and LSH algorithms (Andoni, 2006)3 on\n2http://www.vis.uky.edu/\u0303 stewe/ukbench/data/ 3We have used the publicly available\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Arya et al. ( Arya et al., 1998 ) modify the original kd-tree algorithm to use it for approximate matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "Arya et al. (Arya et al., 1998) modify the original kd-tree algorithm to use it for approximate matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "The figure shows that the two algo-\nof ANN (http://www.cs.umd.edu/\u0303 mount/ANN/) and LSH (http://www.mit.edu/\u0303 andoni/LSH/)\nrithms scale well with the increase in the dataset size, having the speedup over linear search increase with the dataset size."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 198
                            }
                        ],
                        "text": "We compare the two algorithms we found to be the best at finding fast approximate nearest neighbors (the multiple randomized kd-trees and the hierarchical kmeans tree) with existing approaches, the ANN (Arya et al., 1998) and LSH algorithms (Andoni, 2006)3 on\n2http://www.vis.uky.edu/\u0303 stewe/ukbench/data/ 3We have used the publicly available implementations\nthe first dataset of 100,000 SIFT features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Figure 6(a) shows that the hierarchical k-means algorithm outperforms both the ANN and LSH algorithms by about an order of magnitude."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We compare the two algorithms we found to be the best at finding fast approximate nearest neighbors (the multiple randomized kd-trees and the hierarchical kmeans tree) with existing approaches, the ANN ( Arya et al., 1998 ) and LSH algorithms (Andoni, 2006)3 on"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8193729,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "219101fe724232acc330ff0910152931538f85c7",
            "isKey": true,
            "numCitedBy": 2723,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider a set of <italic>S</italic> of <italic>n</italic> data points  in real <italic>d</italic>-dimensional space, R<supscrpt>d</supscrpt>, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess <italic>S</italic> into a data structure, so that given any query point <italic>q</italic><inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, is the closest point of S to <italic>q</italic> can be reported quickly. Given any positive real \u03b5, data point <italic>p</italic> is a (1 +\u03b5)-<italic>approximate nearest neighbor</italic> of <italic>q</italic> if its distance from <italic>q</italic> is within a factor of (1 + \u03b5) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of <italic>n</italic> points in     R<supscrpt>d</supscrpt> in <italic>O(dn</italic> log <italic>n</italic>) time and <italic>O(dn)</italic> space, so that given a query point <italic> q</italic> <inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, and \u03b5 > 0, a (1 + \u03b5)-approximate nearest neighbor of <italic>q</italic> can be computed in <italic>O</italic>(<italic>c</italic><subscrpt><italic>d</italic>, \u03b5</subscrpt> log <italic>n</italic>) time, where <italic>c<subscrpt>d,\u03b5</subscrpt></italic>\u2264<italic>d</italic> <inline-equation> <f><fen lp=\"ceil\">1 + 6d/<g>e</g><rp post=\"ceil\"></fen></f></inline-equation>;<supscrpt>d</supscrpt> is a factor depending only on dimension and \u03b5. In general, we show that given an integer <italic>k</italic> \u2265 1, (1 + \u03b5)-approximations  to the  <italic>k</italic> nearest neighbors of <italic>q</italic> can  be computed in additional <italic>O(kd</italic> log <italic>n</italic>) time."
            },
            "slug": "An-optimal-algorithm-for-approximate-nearest-fixed-Arya-Mount",
            "title": {
                "fragments": [],
                "text": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that it is possible to preprocess a set of data points in real D-dimensional space in O(kd) time and in additional space, so that given a query point q, the closest point of S to S to q can be reported quickly."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 161
                            }
                        ],
                        "text": "\u2026local image features in large datasets (Lowe, 2004; Philbin et al., 2007), clustering local features into visual words using the k-means or similar algorithms (Sivic and Zisserman, 2003), or performing normalized cross-correlation to compare image patches in large datasets (Torralba et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14457153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642e328cae81c5adb30069b680cf60ba6b475153",
            "isKey": false,
            "numCitedBy": 6760,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films."
            },
            "slug": "Video-Google:-a-text-retrieval-approach-to-object-Sivic-Zisserman",
            "title": {
                "fragments": [],
                "text": "Video Google: a text retrieval approach to object matching in videos"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video, represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "The results for ANN are consistent with the experiment in figure 2, as ANN uses only a single kd-tree and does not benefit from the speedup due to using multiple randomized trees."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "(Arya et al., 1998) modify the original kd-tree algorithm to use it for approximate matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "\u2026at finding fast approximate nearest neighbors (the multiple randomized kd-trees and the hierarchical kmeans tree) with existing approaches, the ANN (Arya et al., 1998) and LSH algorithms (Andoni, 2006)3 on\n2http://www.vis.uky.edu/\u0303 stewe/ukbench/data/ 3We have used the publicly available\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 202
                            }
                        ],
                        "text": "We compare the two algorithms we found to be the best at finding fast approximate nearest neighbors (the multiple randomized kd-trees and the hierarchical kmeans tree) with existing approaches, the ANN (Arya et al., 1998) and LSH algorithms (Andoni, 2006) 3 on the first dataset of 100,000 SIFT features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "Arya et al. (Arya et al., 1998) modify the original kd-tree algorithm to use it for approximate matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "The figure shows that the two algo-\nof ANN (http://www.cs.umd.edu/\u0303 mount/ANN/) and LSH (http://www.mit.edu/\u0303 andoni/LSH/)\nrithms scale well with the increase in the dataset size, having the speedup over linear search increase with the dataset size."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 198
                            }
                        ],
                        "text": "We compare the two algorithms we found to be the best at finding fast approximate nearest neighbors (the multiple randomized kd-trees and the hierarchical kmeans tree) with existing approaches, the ANN (Arya et al., 1998) and LSH algorithms (Andoni, 2006)3 on\n2http://www.vis.uky.edu/\u0303 stewe/ukbench/data/ 3We have used the publicly available implementations\nthe first dataset of 100,000 SIFT features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Figure 6(a) shows that the hierarchical k-means algorithm outperforms both the ANN and LSH algorithms by about an order of magnitude."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An optimal algorithm for approximate nearest neighbor searching in fixed dimensions.Journal of the ACM, 45:891\u2013923"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 13
                            }
                        ],
                        "text": "They compare several clustering methods: k-means clustering, agglomerative clustering, and a combined partitional-agglomerative algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cityscale location recognition"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 48
                            }
                        ],
                        "text": "This algorithm has only been proposed recently (Silpa-Anan and Hartley, 2004; SilpaAnan and Hartley, 2008) and has not been widely tested."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Localization using an imagemap"
            },
            "venue": {
                "fragments": [],
                "text": "Australasian Conference on Robotics and Automation"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 103
                            }
                        ],
                        "text": "Examples of such problems include finding the best matches for local image features in large datasets (Lowe, 2004; Philbin et al., 2007), clustering local features into visual words using the k-means or similar algorithms (Sivic and Zisserman, 2003), or performing normalized cross-correlation to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 102
                            }
                        ],
                        "text": "Examples of such problems include finding the best matches for local image features in large datasets (Lowe, 2004; Philbin et al., 2007), clustering local features into visual words using the k-means or similar algorithms (Sivic and Zisserman, 2003), or performing normalized cross-correlation to compare image patches in large datasets (Torralba et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distinctive image features from scaleinvariant keypoints.Int"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Computer Vision,"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 16
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Fast-Approximate-Nearest-Neighbors-with-Automatic-Muja-Lowe/35d81066cb1369acf4b6c5117fcbb862be2af350?sort=total-citations"
}