{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35229948"
                        ],
                        "name": "S. Katz",
                        "slug": "S.-Katz",
                        "structuredName": {
                            "firstName": "Slava",
                            "lastName": "Katz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6555412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0130277677e5b915d5cd86b3afafd77fd08eb2e",
            "isKey": false,
            "numCitedBy": 1908,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The description of a novel type of m-gram language model is given. The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data. This solution compares favorably to other proposed methods. While the method has been developed for and successfully implemented in the IBM Real Time Speech Recognizers, its generality makes it applicable in other areas where the problem of estimating probabilities from sparse data arises."
            },
            "slug": "Estimation-of-probabilities-from-sparse-data-for-of-Katz",
            "title": {
                "fragments": [],
                "text": "Estimation of probabilities from sparse data for the language model component of a speech recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data, and compares favorably to other proposed methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037240"
                        ],
                        "name": "U. Essen",
                        "slug": "U.-Essen",
                        "structuredName": {
                            "firstName": "Ute",
                            "lastName": "Essen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Essen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795942"
                        ],
                        "name": "Reinhard Kneser",
                        "slug": "Reinhard-Kneser",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Kneser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Kneser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206560877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3e53b9c0e3a7a60e7a5295e9b08af74d6fb3dbf",
            "isKey": false,
            "numCitedBy": 599,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this paper, we study the problem of stochastic language modelling from the viewpoint of introducing suitable structures into the conditional probability distributions. The task of these distributions is to predict the probability of a new word by looking at M or even all predecessor words. The conventional approach is to limit M to 1 or 2 and to interpolate the resulting bigram and trigram models with a unigram model in a linear fashion. However, there are many other structures that can be used to model the probabilistic dependences between the predecessor word and the word to be predicted. The structures considered in this paper are: nonlinear interpolation as an alternative to linear interpolation; equivalence classes for word histories and single words; cache memory and word associations. For the optimal estimation of nonlinear and linear interpolation parameters, the leaving-one-out method is systematically used. For the determination of word equivalence classes in a bigram model, an automatic clustering procedure has been adapted. To capture long-distance dependences, we consider various models for word-by-word dependences; the cache model may be viewed as a special type of self-association. Experimental results are presented for two text databases, a Germany database and an English database."
            },
            "slug": "On-structuring-probabilistic-dependences-in-Ney-Essen",
            "title": {
                "fragments": [],
                "text": "On structuring probabilistic dependences in stochastic language modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The problem of stochastic language modelling is studied from the viewpoint of introducing suitable structures into the conditional probability distributions, and nonlinear interpolation as an alternative to linear interpolation; equivalence classes for word histories and single words; cache memory and word associations are considered."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122690"
                        ],
                        "name": "X. Aubert",
                        "slug": "X.-Aubert",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Aubert",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Aubert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32703822"
                        ],
                        "name": "C. Dugast",
                        "slug": "C.-Dugast",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Dugast",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dugast"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3214660"
                        ],
                        "name": "Volker Steinbiss",
                        "slug": "Volker-Steinbiss",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Steinbiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Steinbiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2526767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11d74704fe3bb078f81e32e61857e082794c829d",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on recent developments of the Philips large vocabulary speech recognition system and on our experiments with the Wall Street Journal (WSJ) corpus. A two-pass decoding has been devised that allows an easy integration of more complex language models. First, a word lattice is produced using a time synchronous beam search with a bigram language model. Next, a higher-order language model is applied to the lattice at the phrase level. The conditions insuring the validity of this approach are explained and practical results for trigram demonstrate its usefulness. The main system development stages on WSJ data are presented and our final recognizers are evaluated on Nov. '92 and Nov. '93 test-data for both 5 K and 20 K vocabularies.<<ETX>>"
            },
            "slug": "Large-vocabulary-continuous-speech-recognition-of-Aubert-Dugast",
            "title": {
                "fragments": [],
                "text": "Large vocabulary continuous speech recognition of Wall Street Journal data"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A two-pass decoding has been devised that allows an easy integration of more complex language models and practical results for trigram demonstrate its usefulness."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICASSP '94. IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145631743"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Baker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2618014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8648dbfff9662fa9c62a95622712dd2951b5b3a3",
            "isKey": false,
            "numCitedBy": 1278,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The DARPA Spoken Language System (SLS) community has long taken a leadership position in designing, implementing, and globally distributing significant speech corpora widely used for advancing speech recognition research. The Wall Street Journal (WSJ) CSR Corpus described here is the newest addition to this valuable set of resources. In contrast to previous corpora, the WSJ corpus will provide DARPA its first general-purpose English, large vocabulary, natural language, high perplexity, corpus containing significant quantities of both speech data (400 hrs.) and text data (47M words), thereby providing a means to integrate speech recognition and natural language processing in application domains with high potential practical value. This paper presents the motivating goals, acoustic data design, text processing steps, lexicons, and testing paradigms incorporated into the multi-faceted WSJ CSR Corpus."
            },
            "slug": "The-Design-for-the-Wall-Street-Journal-based-CSR-Paul-Baker",
            "title": {
                "fragments": [],
                "text": "The Design for the Wall Street Journal-based CSR Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents the motivating goals, acoustic data design, text processing steps, lexicons, and testing paradigms incorporated into the multi-faceted WSJ CSR Corpus, a corpus containing significant quantities of both speech data and text data."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48892185"
                        ],
                        "name": "J. Teahan",
                        "slug": "J.-Teahan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Teahan",
                            "middleNames": [
                                "K"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Teahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752317"
                        ],
                        "name": "J. Cleary",
                        "slug": "J.-Cleary",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cleary",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cleary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6633939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d36910319d11359b995ff5413696aa9e9995e163",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "\\A new data structure for cumulative probability tables\". Soft-\\The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression\"."
            },
            "slug": "\\self-organized-Language-Modeling-for-Speech-In-Teahan-Cleary",
            "title": {
                "fragments": [],
                "text": "\\self-organized Language Modeling for Speech Recognition\". In"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression and a new data structure for cumulative probability tables are studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "Events that have been observed twice or more, on the other hand, still stay in the 'seen' branch."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11945361,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b2986b25f50babd536dd0ecf2237d9eabf5843c2",
            "isKey": false,
            "numCitedBy": 3274,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-POPULATION-FREQUENCIES-OF-SPECIES-AND-THE-OF-Good",
            "title": {
                "fragments": [],
                "text": "THE POPULATION FREQUENCIES OF SPECIES AND THE ESTIMATION OF POPULATION PARAMETERS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "In addition, recognition results were pro\u00ad duced for the Wall-Street-Journal task by applying the different models in the trigram rescoring step of our recognizer [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large Vocabulary Continuolls Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "onNall Street Journal Data\","
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Classification and Scene"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 9,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Improved-backing-off-for-M-gram-language-modeling-Kneser-Ney/9548ac30c113562a51e603dbbc8e9fa651cfd3ab?sort=total-citations"
}