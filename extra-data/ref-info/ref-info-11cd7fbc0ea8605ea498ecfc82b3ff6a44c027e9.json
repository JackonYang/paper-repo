{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 74294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4711ff01d8eff9b9d10deeb3b68f366f7944c208",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a polynomial-time algorithm for statistical machine translation. This algorithm can be used in place of the expensive, slow best-first search strategies in current statistical translation architectures. The approach employs the stochastic bracketing transduction grammar (SBTG) model we recently introduced to replace earlier word alignment channel models, while retaining a bigram language model. The new algorithm in our experience yields major speed improvement with no significant loss of accuracy."
            },
            "slug": "A-Polynomial-Time-Algorithm-for-Statistical-Machine-Wu",
            "title": {
                "fragments": [],
                "text": "A Polynomial-Time Algorithm for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A polynomial-time algorithm for statistical machine translation that employs the stochastic bracketing transduction grammar (SBTG) model to replace earlier word alignment channel models, while retaining a bigram language model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2925458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "297b0d80575ae36e3e26772ba7e70fa6b570c68d",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a decoding algorithm for a syntax-based translation model (Yamada and Knight, 2001). The model has been extended to incorporate phrasal translations as presented here. In contrast to a conventional word-to-word statistical model, a decoder for the syntax-based model builds up an English parse tree given a sentence in a foreign language. As the model size becomes huge in a practical setting, and the decoder considers multiple syntactic structures for each word alignment, several pruning techniques are necessary. We tested our decoder in a Chinese-to-English translation system, and obtained better results than IBM Model 4. We also discuss issues concerning the relation between this decoder and a language model."
            },
            "slug": "A-Decoder-for-Syntax-based-Statistical-MT-Yamada-Knight",
            "title": {
                "fragments": [],
                "text": "A Decoder for Syntax-based Statistical MT"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The model has been extended to incorporate phrasal translations as presented here, and the decoder obtained better results than IBM Model 4 in a Chinese-to-English translation system."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2581781"
                        ],
                        "name": "Nicola Ueffing",
                        "slug": "Nicola-Ueffing",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Ueffing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicola Ueffing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20054530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7181f7a664fbbf34c7c147c8a90f0343cdd1674c",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical machine translation systems usually compute the single sentence that has the highest probability according to the models that are trained on data. We describe a method for constructing a word graph to represent alternative hypotheses in an efficient way. The advantage is that these hypotheses can be rescored using a refined language or translation model. Results are presented on the German-English Verbmobil corpus."
            },
            "slug": "Generation-of-Word-Graphs-in-Statistical-Machine-Ueffing-Och",
            "title": {
                "fragments": [],
                "text": "Generation of Word Graphs in Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method for constructing a word graph to represent alternative hypotheses in an efficient way to ensure that these hypotheses can be rescored using a refined language or translation model."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070617284"
                        ],
                        "name": "Daniel Wong",
                        "slug": "Daniel-Wong",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Wong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1567400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a9ba4a76d1e9948c1cb980800ad117531753f8",
            "isKey": false,
            "numCitedBy": 525,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a joint probability model for statistical machine translation, which automatically learns word and phrase equivalents from bilingual corpora. Translations produced with parameters estimated using the joint model are more accurate than translations produced using IBM Model 4."
            },
            "slug": "A-Phrase-Based,-Joint-Probability-Model-for-Machine-Marcu-Wong",
            "title": {
                "fragments": [],
                "text": "A Phrase-Based, Joint Probability Model for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A joint probability model for statistical machine translation is presented, which automatically learns word and phrase equivalents from bilingual corpora, which is more accurate than translations produced using IBM Model 4."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767307"
                        ],
                        "name": "H. Alshawi",
                        "slug": "H.-Alshawi",
                        "structuredName": {
                            "firstName": "Hiyan",
                            "lastName": "Alshawi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alshawi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3265812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ce919d90ee41a8a6852677f7553e297de2b06a7",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents statistical language and translation models based on collections of small finite-state machines that we call \"head automata\". The models are intended to capture the lexical sensitivity of N-gram models and direct statistical translation models, while at the same time taking account of the hierarchical phrasal structure of language. Two types of head automata are defined: relational head automata, which are suitable for translation by the transfer of dependency trees, and head transducers, which are suitable for direct recursive lexical translation."
            },
            "slug": "Head-automata-for-speech-translation-Alshawi",
            "title": {
                "fragments": [],
                "text": "Head automata for speech translation"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "Presents statistical language and translation models based on collections of small finite-state machines that are intended to capture the lexical sensitivity of N-gram models and direct statistical translation models, while at the also taking account of the hierarchical phrasal structure of language."
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18153866,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7eb1d96fa4c7d3a36613139116e356364ea3edcd",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a set of algorithms that enable us to translate natural language sentences by exploiting both a translation memory and a statistical-based translation model. Our results show that an automatically derived translation memory can be used within a statistical framework to often find translations of higher probability than those found using solely a statistical model. The translations produced using both the translation memory and the statistical model are significantly better than translations produced by two commercial systems: our hybrid system translated perfectly 58% of the 505 sentences in a test collection, while the commercial systems translated perfectly only 40-42% of them."
            },
            "slug": "Towards-a-Unified-Approach-to-Memory-and-Machine-Marcu",
            "title": {
                "fragments": [],
                "text": "Towards a Unified Approach to Memory- and Statistical-Based Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The results show that an automatically derived translation memory can be used within a statistical framework to often find translations of higher probability than those found using solely a statistical model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324070"
                        ],
                        "name": "C. Tillmann",
                        "slug": "C.-Tillmann",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Tillmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tillmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 58
                            }
                        ],
                        "text": "Wang(1998)enhancedtheIBM modelsby introducing phrases,and Och et al. (1999) used templatesto capturephrasalsequencesin a sentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6665740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b0495331238da6c0e7be0bfdb9b5453b33c1f98",
            "isKey": false,
            "numCitedBy": 579,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe improved alignment models for statistical machine translation. The statistical translation approach uses two types of information: a translation model and a language model. The language model used is a bigram or general m-gram model. The translation model is decomposed into a lexical and an alignment model. We describe two different approaches for statistical translation and present experimental results. The first approach is based on dependencies between single words, the second approach explicitly takes shallow phrase structures into account, using two different alignment levels: a phrase level alignment between phrases and a word level alignment between single words. We present results using the Verbmobil task (German-English, 6000word vocabulary) which is a limited-domain spoken-language task. The experimental tests were performed on both the text transcription and the speech recognizer output. 1 S t a t i s t i c a l M a c h i n e T r a n s l a t i o n The goal of machine translation is the translation of a text given in some source language into a target language. We are given a source string f / = fl...fj...fJ, which is to be translated into a target string e{ = el...ei...ex. Among all possible target strings, we will choose the string with the highest probability: = argmax {Pr(ezIlflJ)}"
            },
            "slug": "Improved-Alignment-Models-for-Statistical-Machine-Och-Tillmann",
            "title": {
                "fragments": [],
                "text": "Improved Alignment Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Improved alignment models for statistical machine translation are described and experimental results are presented using the Verbmobil task (German-English, 6000word vocabulary) which is a limited-domain spoken-language task."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 99202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b8f0e60a648880ddeaed371c339714f66f24624",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical machine translation is a relatively new approach to the long-standing problem of translating human languages by computer. Current statistical techniques uncover translation rules from bilingual training texts and use those rules to translate new texts. The general architecture is the source-channel model: an English string is statistically generated (source), then statistically transformed into French (channel). In order to translate (or \"decode\") a French string, we look for the most likely English source. We show that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence. We trace this complexity to factors not present in other decoding problems."
            },
            "slug": "Decoding-Complexity-in-Word-Replacement-Translation-Knight",
            "title": {
                "fragments": [],
                "text": "Decoding Complexity in Word-Replacement Translation Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows that for the simplest form of statistical models, this problem is NP-complete, i.e., probably exponential in the length of the observed sentence, and traces this complexity to factors not present in other decoding problems."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5284722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9214ebe91454e6369720136ab7dd990d52a07d4",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present and compare various single-word based alignment models for statistical machine translation. We discuss the five IBM alignment models, the Hidden-Markov alignment model, smoothing techniques and various modifications. We present different methods to combine alignments. As evaluation criterion we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We show that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies."
            },
            "slug": "Improved-Statistical-Alignment-Models-Och-Ney",
            "title": {
                "fragments": [],
                "text": "Improved Statistical Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8031067,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "d18af6780f9242ec988c89ed0b67dc7d05a7785a",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present and compare various alignment models for statistical machine translation. We propose to measure the quality of an alignment model using the quality of the Viterbi alignment compared to a manually-produced alignment and describe a refined annotation scheme to produce suitable reference alignments. We also compare the impact of different alignment models on the translation quality of a statistical machine translation system."
            },
            "slug": "A-Comparison-of-Alignment-Models-for-Statistical-Och-Ney",
            "title": {
                "fragments": [],
                "text": "A Comparison of Alignment Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The quality of an alignment model is proposed to be measured using the quality of the Viterbi alignment compared to a manually-produced alignment and a refined annotation scheme to produce suitable reference alignments is described."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110694221"
                        ],
                        "name": "Taro Watanabe",
                        "slug": "Taro-Watanabe",
                        "structuredName": {
                            "firstName": "Taro",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taro Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3341861"
                        ],
                        "name": "K. Imamura",
                        "slug": "K.-Imamura",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Imamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Imamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698363"
                        ],
                        "name": "E. Sumita",
                        "slug": "E.-Sumita",
                        "structuredName": {
                            "firstName": "Eiichiro",
                            "lastName": "Sumita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sumita"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10441402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c242076eeb03bf5fb29ee602e1bb4cec4b7a3eca",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes statistical machine translation improved by applying hierarchical phrase alignment. The hierarchical phrase alignment is a method to align bilingual sentences phrase-by-phrase employing the partial parse results. Based on the hierarchical phrase alignment, a translation model is trained on a chunked corpus by converting hierarchically aligned phrases into a sequence of chunks. The second method transforms the bilingual correspondence of the phrase alignments into that of translation model. Both of our approaches yield better quality of the translaiton model."
            },
            "slug": "Statistical-machine-translation-based-on-phrase-Watanabe-Imamura",
            "title": {
                "fragments": [],
                "text": "Statistical machine translation based on hierarchical phrase alignment."
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper describes statistical machine translation improved by applying hierarchical phrase alignment, a method to align bilingual sentences phrase-by-phrase employing the partial parse results."
            },
            "venue": {
                "fragments": [],
                "text": "TMI"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324070"
                        ],
                        "name": "C. Tillmann",
                        "slug": "C.-Tillmann",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Tillmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tillmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247319"
                        ],
                        "name": "S. Vogel",
                        "slug": "S.-Vogel",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2805349"
                        ],
                        "name": "A. Zubiaga",
                        "slug": "A.-Zubiaga",
                        "structuredName": {
                            "firstName": "Arkaitz",
                            "lastName": "Zubiaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zubiaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 613292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a19ceb1281b84d96abba03e973ba7274a8f0f8b0",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a Dynamic Programming (DP) based search algorithm for statistical translation and present experimental results. The statistical translation uses two sources of information: a translation model and a language model. The language model used is a standard bigram model. For the translation model, the alignment probabilities are made dependent on the differences in the alignment positions rather than on the absolute positions. Thus, the approach amounts to a first-order Hidden Markov model (HMM) as they are used successfully in speech recognition for the time alignment problem. Under the assumption that the alignment is monotone with respect to the word order in both languages, an efficient search strategy for translation can be formulated. The details of the search algorithm are described. Experiments on the EuTrans corpus produced a word error rate of 5.1%."
            },
            "slug": "A-DP-based-Search-Using-Monotone-Alignments-in-Tillmann-Vogel",
            "title": {
                "fragments": [],
                "text": "A DP-based Search Using Monotone Alignments in Statistical Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A Dynamic Programming (DP) based search algorithm for statistical translation uses a first-order Hidden Markov model as they are used successfully in speech recognition for the time alignment problem."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35313721"
                        ],
                        "name": "S. Bangalore",
                        "slug": "S.-Bangalore",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Bangalore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bangalore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702447"
                        ],
                        "name": "Owen Rambow",
                        "slug": "Owen-Rambow",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Rambow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Rambow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1693203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e733d1c229cb010d6630bae29fb86cfbe09a2d0f",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous stochastic approaches to generation do not include a tree-based representation of syntax. While this may be adequate or even advantageous for some applications, other applications profit from using as much syntactic knowledge as is available, leaving to a stochastic model only those issues that are not determined by the grammar. We present initial results showing that a tree-based model derived from a tree-annotated corpus improves on a tree model derived from an unannotated corpus, and that a tree-based stochastic model with a hand-crafted grammar outperforms both."
            },
            "slug": "Exploiting-a-Probabilistic-Hierarchical-Model-for-Bangalore-Rambow",
            "title": {
                "fragments": [],
                "text": "Exploiting a Probabilistic Hierarchical Model for Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Initial results are presented showing that a tree-based model derived from aTree-annotated corpus improves on a tree modelderived from an unannotated Corpus, and that a Tree-based stochastic model with a hand-crafted grammar outperforms both."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 284436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37fadfb6d60e83e24c72d8a90da5644b39d6e8f0",
            "isKey": false,
            "numCitedBy": 1228,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case. All knowledge sources are treated as feature functions, which depend on the source language sentence, the target language sentence and possible hidden variables. This approach allows a baseline machine translation system to be extended easily by adding new feature functions. We show that a baseline statistical machine translation system is significantly improved using this approach."
            },
            "slug": "Discriminative-Training-and-Maximum-Entropy-Models-Och-Ney",
            "title": {
                "fragments": [],
                "text": "Discriminative Training and Maximum Entropy Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case and shows that a baseline statistical machinetranslation system is significantly improved using this approach."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13508959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db856853d93e104f6e7d2121450d6900dde068ed",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Selecting the right word translation among several options in the lexicon is a core problem for machine translation. We present a novel approach to this problem that can be trained using only unrelated monolingual corpora and a lexicon. By estimating word translation probabilities using the EM algorithm, we extend upon target language modeling. We construct a word translation model for 3830 German and 6147 English noun tokens, with very promising results."
            },
            "slug": "Estimating-Word-Translation-Probabilities-from-the-Koehn-Knight",
            "title": {
                "fragments": [],
                "text": "Estimating Word Translation Probabilities from Unrelated Monolingual Corpora Using the EM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel approach to word translation probabilities using the EM algorithm is presented, which extends upon target language modeling and constructs a word translation model for 3830 German and 6147 English noun tokens, with very promising results."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30844359"
                        ],
                        "name": "Ye-Yi Wang",
                        "slug": "Ye-Yi-Wang",
                        "structuredName": {
                            "firstName": "Ye-Yi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ye-Yi Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10282937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03b513b30b9d95e39285df1dc93be63e25f2744e",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Decoding algorithm is a crucial part in statistical machine translation. We describe a stack decoding algorithm in this paper. We present the hypothesis scoring method and the heuristics used in our algorithm. We report several techniques deployed to improve the performance of the decoder. We also introduce a simplified model to moderate the sparse data problem and to speed up the decoding process. We evaluate and compare these techniques/models in our statistical machine translation system."
            },
            "slug": "Decoding-Algorithm-in-Statistical-Machine-Wang-Waibel",
            "title": {
                "fragments": [],
                "text": "Decoding Algorithm in Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A stack decoding algorithm is described and the hypothesis scoring method and the heuristics used in the algorithm are presented, and a simplified model to moderate the sparse data problem and to speed up the decoding process is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30844359"
                        ],
                        "name": "Ye-Yi Wang",
                        "slug": "Ye-Yi-Wang",
                        "structuredName": {
                            "firstName": "Ye-Yi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ye-Yi Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 621484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb9f9d320ad39febc6246901d47fb40446f2344b",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "NLP researchers face a dilemma: on one side, it is unarguably accepted that languages have internal structure rather than strings of words. On the other side, they nd it very di cult and expensive to write grammars that have good coverage of language structures. Statistical machine translation tries to cope with this problem by ignoring language structures and using a statistical models to depict the translation process. Most of the translation models are word-based. While the approach has achieved surprisingly good performance comparable to the best commercial systems, many questions remain in the machine translation community. Can the statistical word-based translation still perform well on language pairs with radically di erent linguistic structures? How would it function with less training data or with spoken languages? The thesis work investigated these questions. In summary, word-based alignment model is a major cause of errors in German-English statistical spoken language translation. To account for this problem, a structure-based alignment model is introduced. This new model takes advantages of a bilingual grammar inference algorithm, which can automatically acquire shallow phrase structures used by the model. The structure-based model can directly depict the structure di erence between English and German spoken languages. It also results in focused learning of word alignment, therefore it can alleviate the sparse data problem. The structurebased model achieved 11 percent error reduction over the state-of-the-art statistical machine translation models."
            },
            "slug": "Grammar-Inference-and-Statistical-Machine-Wang",
            "title": {
                "fragments": [],
                "text": "Grammar Inference and Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A structure-based alignment model is introduced that can directly depict the structure between English and German spoken languages and results in focused learning of word alignment, therefore it can alleviate the sparse data problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145440721"
                        ],
                        "name": "Francis Bond",
                        "slug": "Francis-Bond",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francis Bond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34981957"
                        ],
                        "name": "S. Shirai",
                        "slug": "S.-Shirai",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Shirai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shirai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16974365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be2adf009f5f67ae8c51b529ba39dac5b8386630",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new example-based method of machine translation in which the examples need not be direct translations. The system will weed out strange examples during translation, allowing the use of currently available sentence-aligned corpora as data. Rule-based modules are used where appropriate. A prototype Japanese-to-English system has been implemented that allows multiple users to share corpora."
            },
            "slug": "A-Hybrid-Rule-and-Example-Based-Method-for-Machine-Bond-Shirai",
            "title": {
                "fragments": [],
                "text": "A Hybrid Rule and Example-Based Method for Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new example-based method of machine translation in which the examples need not be direct translations, allowing the use of currently available sentence-aligned corpora as data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706916"
                        ],
                        "name": "P. Langlais",
                        "slug": "P.-Langlais",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Langlais",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Langlais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2458308"
                        ],
                        "name": "George F. Foster",
                        "slug": "George-F.-Foster",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Foster",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George F. Foster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806207"
                        ],
                        "name": "G. Lapalme",
                        "slug": "G.-Lapalme",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Lapalme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lapalme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1568059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76a6d780805a8b05ff64afe7218b3b97d0a7a1ff",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the embedding of a statistical translation system within a text editor to produce TRANSTYPE, a system that watches over the user as he or she types a translation and repeatedly suggests completions for the text already entered. This innovative Embedded Machine Translation system is thus a specialized means of helping produce high quality translations."
            },
            "slug": "TransType:-a-Computer-Aided-Translation-Typing-Langlais-Foster",
            "title": {
                "fragments": [],
                "text": "TransType: a Computer-Aided Translation Typing System"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper describes the embedding of a statistical translation system within a text editor to produce TRANSTYPE, a system that watches over the user as he or she types a translation and repeatedly suggests completions for the text already entered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204549"
                        ],
                        "name": "S. Finch",
                        "slug": "S.-Finch",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Finch",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Finch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1103254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24e83b9202b4e2992fde4083a31fe16efb7c0644",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a model of statistical word-level mapping for comparable corpora. The approach is based on the assumption that if two terms have close distributional profiles, their corresponding translations' distributional profiles should be close in a comparable corpus. The proposed model is described. A preliminary investigation on intralanguage comparable corpora is laid out. The preliminary results are >92% accurate, suggesting the feasibility of the model. The model needs to undergo some improvements and should be tested cross linguistically before assessing its significance."
            },
            "slug": "A-statistical-word-level-translation-model-for-Diab-Finch",
            "title": {
                "fragments": [],
                "text": "A statistical word-level translation model for comparable corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The preliminary results are >92% accurate, suggesting the feasibility of the model, and some improvements are needed and the model needs to undergo some improvements and should be tested cross linguistically before assessing its significance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110568470"
                        ],
                        "name": "Kaoru Yamamoto",
                        "slug": "Kaoru-Yamamoto",
                        "structuredName": {
                            "firstName": "Kaoru",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaoru Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2885757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34c71b6177f2daf1d1d726dd05941a545a149928",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method to find phrase-level translation patterns from parallel corpora by applying dependency structure analysis. We use statistical dependency parsers to determine dependency relations between base phrases in a sentence. Our method is tested with a business expression corpus containing 10000 English-Japanese sentence pairs and achieved approximately 90% accuracy in extracting bilingual correspondences. The result shows that the use of dependency relation helps to acquire interesting translation patterns."
            },
            "slug": "Acquisition-of-Phrase-level-Bilingual-using-Yamamoto-Matsumoto",
            "title": {
                "fragments": [],
                "text": "Acquisition of Phrase-level Bilingual Correspondence using Dependency Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper uses statistical dependency parsers to determine dependency relations between base phrases in a sentence to find phrase-level translation patterns from parallel corpora by applying dependency structure analysis."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5458997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85b9eb556c211d954b31d9d58fed6891a07ab473",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a statistical technique for assigning senses to words. An instance of a word is assigned a sense by asking a question about the context in which the word appears. The question is constructed to have high mutual information with the translation of that instance in another language. When we incorporated this method of assigning senses into our statistical machine translation system, the error rate of the system decreased by thirteen percent."
            },
            "slug": "Word-Sense-Disambiguation-Using-Statistical-Methods-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Word-Sense Disambiguation Using Statistical Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A statistical technique for assigning senses to words is described, which incorporated into the statistical machine translation system the error rate of the system decreased by thirteen percent."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35313721"
                        ],
                        "name": "S. Bangalore",
                        "slug": "S.-Bangalore",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Bangalore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bangalore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702447"
                        ],
                        "name": "Owen Rambow",
                        "slug": "Owen-Rambow",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Rambow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Rambow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8854602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "322a66f2baa894d6e85f08d772a54660f967f964",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Choosing the best lexeme to realize a meaning in natural language generation is a hard task. We investigate different tree-based stochastic models for lexical choice. Because of the difficulty of obtaining a sense-tagged corpus, we generalize the notion of synonymy. We show that a tree-based model can achieve a word-bag based accuracy of 90%, representing an improvement over the baseline."
            },
            "slug": "Corpus-Based-Lexical-Choice-in-Natural-Language-Bangalore-Rambow",
            "title": {
                "fragments": [],
                "text": "Corpus-Based Lexical Choice in Natural Language Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that a tree-based model can achieve a word-bag based accuracy of 90%, representing an improvement over the baseline, and generalize the notion of synonymy."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038307"
                        ],
                        "name": "S. Nie\u00dfen",
                        "slug": "S.-Nie\u00dfen",
                        "structuredName": {
                            "firstName": "Sonja",
                            "lastName": "Nie\u00dfen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nie\u00dfen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9389310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc43ce300875906274ae9f40a1b437374703d0cf",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical machine translation, correspondences between the words in the source and the target language are learned from bilingual corpora on the basis of so called alignment models. Existing statistical systems for MT often treat different derivatives of the same lemma as if they were independent of each other. In this paper we argue that a better exploitation of the bilingual training data can be achieved by explicitly taking into account the interdependencies of the different derivatives. We do this along two directions: Usage of hierarchical lexicon models and the introduction of equivalence classes in order to ignore information not relevant for the translation task. The improvement of the translation results is demonstrated on a German-English corpus."
            },
            "slug": "Toward-hierarchical-models-for-statistical-machine-Nie\u00dfen-Ney",
            "title": {
                "fragments": [],
                "text": "Toward hierarchical models for statistical machine translation of inflected languages"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A better exploitation of the bilingual training data can be achieved by explicitly taking into account the interdependencies of the different derivatives of the same lemma, and usage of hierarchical lexicon models and the introduction of equivalence classes are argued."
            },
            "venue": {
                "fragments": [],
                "text": "DDMMT@ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736723"
                        ],
                        "name": "Ishwar Chander",
                        "slug": "Ishwar-Chander",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Chander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ishwar Chander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105813021"
                        ],
                        "name": "Matthew Haines",
                        "slug": "Matthew-Haines",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Haines",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Haines"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40502269"
                        ],
                        "name": "Masayo Iida",
                        "slug": "Masayo-Iida",
                        "structuredName": {
                            "firstName": "Masayo",
                            "lastName": "Iida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masayo Iida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076094546"
                        ],
                        "name": "Steve K. Luk",
                        "slug": "Steve-K.-Luk",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Luk",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve K. Luk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742723"
                        ],
                        "name": "Akitoshi Okumura",
                        "slug": "Akitoshi-Okumura",
                        "structuredName": {
                            "firstName": "Akitoshi",
                            "lastName": "Okumura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akitoshi Okumura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143660355"
                        ],
                        "name": "R. Whitney",
                        "slug": "R.-Whitney",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Whitney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Whitney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9969417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3125d995046ecf8cf43c2d9175630eafaa90ba9",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We summarize recent machine translation (MT) research at the Information Sciences Institute of USC, and we describe its application to the development of a Japanese-English newspaper MT system. Our work aims at scaling up grammar-based, knowledge-based MT techniques. This scale-up involves the use of statistical methods, both in acquiring effective knowledge resources and in making reasonable linguistic choices in the face of knowledge gaps."
            },
            "slug": "Integrating-Knowledge-Bases-and-Statistics-in-MT-Knight-Chander",
            "title": {
                "fragments": [],
                "text": "Integrating Knowledge Bases and Statistics in MT"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This work aims at scaling up grammar-based, knowledge-based MT techniques, both in acquiring effective knowledge resources and in making reasonable linguistic choices in the face of knowledge gaps."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390051006"
                        ],
                        "name": "I. Langkilde-Geary",
                        "slug": "I.-Langkilde-Geary",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Langkilde-Geary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Langkilde-Geary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2680971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0886bd3d1b4fd46928a295a36b5230c4352f699b",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe novel aspects of a new natural language generator called Nitrogen. This generator has a highly flexible input representation that allows a spectrum of input from syntactic to semantic depth, and shifts the burden of many linguistic decisions to the statistical post-processor. The generation algorithm is compositional, making it efficient, yet it also handles non-compositional aspects of language. Nitrogen's design makes it robust and scalable, operating with lexicons and knowledge bases of one hundred thousand entities."
            },
            "slug": "Generation-that-Exploits-Corpus-Based-Statistical-Langkilde-Geary-Knight",
            "title": {
                "fragments": [],
                "text": "Generation that Exploits Corpus-Based Statistical Knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "Novel aspects of a new natural language generator called Nitrogen are described, which has a highly flexible input representation that allows a spectrum of input from syntactic to semantic depth, and shifts the burden of many linguistic decisions to the statistical post-processor."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052717227"
                        ],
                        "name": "M. Epstein",
                        "slug": "M.-Epstein",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Epstein",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323275"
                        ],
                        "name": "Kishore Papineni",
                        "slug": "Kishore-Papineni",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Papineni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kishore Papineni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144582029"
                        ],
                        "name": "T. Ward",
                        "slug": "T.-Ward",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10687513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2136b1fc1b9430289ff5164663b1414605b157d1",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to natural language understanding (NLU) based on the source-channel paradigm, and apply it to ARPA's Air Travel Information Service (ATIS) domain. The model uses techniques similar to those used by IBM in statistical machine translation. The parameters are trained using the exact match algorithm; a hierarchy of models is used to facilitate the bootstrapping of more complex models from simpler models."
            },
            "slug": "Statistical-natural-language-understanding-using-Epstein-Papineni",
            "title": {
                "fragments": [],
                "text": "Statistical natural language understanding using hidden clumpings"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A new approach to natural language understanding (NLU) based on the source-channel paradigm is presented, and it is applied to ARPA's Air Travel Information Service (ATIS) domain."
            },
            "venue": {
                "fragments": [],
                "text": "1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737285"
                        ],
                        "name": "Radu Soricut",
                        "slug": "Radu-Soricut",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Soricut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radu Soricut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26634821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ab56fec13eb20efea55b2747f25588fc029e787",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The existence of a phrase in a large monolingual corpus is very useful information, and so is its frequency. We introduce an alternative approach to automatic translation of phrases/sentences that operationalizes this observation. We use a statistical machine translation system to produce alternative translations and a large monolingual corpus to (re)rank these translations. Our results show that this combination yields better translations, especially when translating out-of-domain phrases/sentences. Our approach can be also used to automatically construct parallel corpora from monolingual resources."
            },
            "slug": "Using-a-large-monolingual-corpus-to-improve-Soricut-Knight",
            "title": {
                "fragments": [],
                "text": "Using a large monolingual corpus to improve translation accuracy"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work uses a statistical machine translation system to produce alternative translations and a large monolingual corpus to (re)rank these translations, and shows that this combination yields better translations, especially when translating out-of-domain phrases/sentences."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247319"
                        ],
                        "name": "S. Vogel",
                        "slug": "S.-Vogel",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5443564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "085ee1aff80617d2b368bba6bc9584351c0e7cd1",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Translation memories are promising devices for automatic translation. Their main weakness, however, is poor coverage on unseen text. In this paper, the use of a hierarchical translation memory, consisting of a cascade of finite state transducers, is proposed. A number of transducers is applied to convert sentence pairs from a bilingual corpus into translation patterns, which are then used as a translation memory. Preliminary results on the German English VERBMOBIL corpus are given."
            },
            "slug": "Construction-of-a-Hierarchical-Translation-Memory-Vogel-Ney",
            "title": {
                "fragments": [],
                "text": "Construction of a Hierarchical Translation Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A hierarchical translation memory, consisting of a cascade of finite state transducers, is proposed, which is applied to convert sentence pairs from a bilingual corpus into translation patterns, which are then used as a translation memory."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33317048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e3e4c011f2dfe28a706cfb8d32571948192ab89",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The WWW is two orders of magnitude larger than the largest corpora. Although noisy, web text presents language as it is used, and statistics derived from the Web can have practical uses in many NLP applications. For this reason, the WWW should be seen and studied as any other computationally available linguistic resource. In this article, we illustrate this by showing that an Example-Based approach to lexical choice for machine translation can use the Web as an adequate and free resource."
            },
            "slug": "The-World-Wide-Web-as-a-Resource-for-Example-Based-Grefenstette",
            "title": {
                "fragments": [],
                "text": "The World Wide Web as a Resource for Example-Based Machine Translation Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This article illustrates this by showing that an Example-Based approach to lexical choice for machine translation can use the Web as an adequate and free resource."
            },
            "venue": {
                "fragments": [],
                "text": "TC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35313721"
                        ],
                        "name": "S. Bangalore",
                        "slug": "S.-Bangalore",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Bangalore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bangalore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702447"
                        ],
                        "name": "Owen Rambow",
                        "slug": "Owen-Rambow",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Rambow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Rambow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9108161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e7e73c8ff223782975f8fb8402a39b819b9c4fa",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Srinivas Bangalore et Owen Rambow AT &T Labs-Research, B233 180 Park Ave, PO Box 971 F1orham Park, NJ 07932-0971, USA srini, rambow@research.att.com 33 Previous stochastic approaches to sentence realization da not include a tree-based representation of syntax. While this may be adequate or even advantageous for some applications, other applications profitfrom using as much syntactic knowledge as is available, leaving to a stochastic model only those issues that are not determined by the grammar. In this paper, we present three results in the context of surface realization: a stochastic tree model derivedfrom a parsed corpus outperforms a tree model derivedfrom unannotated corpus; exploiting a hand-crafted grammar in conjunction with a tree model outpe1fonns a tree model without a grammar; and exploiting a tree model in conjunction with a linear language model outperforms just the tree model."
            },
            "slug": "Using-TAGs,-a-Tree-Model,-and-a-Language-Model-for-Bangalore-Rambow",
            "title": {
                "fragments": [],
                "text": "Using TAGs, a Tree Model, and a Language Model for Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "Three results in the context of surface realization are presented: a stochastic tree model derived from a parsed corpus outperforms a tree models derived from unannotated corpus and exploiting a hand-crafted grammar in conjunction with a tree model outpe1fonns aTree model without a grammar."
            },
            "venue": {
                "fragments": [],
                "text": "TAG+"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20866393"
                        ],
                        "name": "Heidi Fox",
                        "slug": "Heidi-Fox",
                        "structuredName": {
                            "firstName": "Heidi",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heidi Fox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17555617,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b5cd35709797ac02a69e930d97f7917f377107de",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been much interest in using phrasal movement to improve statistical machine translation. We explore how well phrases cohere across two languages, specifically English and French, and examine the particular conditions under which they do not. We demonstrate that while there are cases where coherence is poor, there are many regularities which can be exploited by a statistical machine translation system. We also compare three variant syntactic representations to determine which one has the best properties with respect to cohesion."
            },
            "slug": "Phrasal-Cohesion-and-Statistical-Machine-Fox",
            "title": {
                "fragments": [],
                "text": "Phrasal Cohesion and Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated that while there are cases where coherence is poor, there are many regularities which can be exploited by a statistical machine translation system."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143881680"
                        ],
                        "name": "Jes\u00fas Tom\u00e1s",
                        "slug": "Jes\u00fas-Tom\u00e1s",
                        "structuredName": {
                            "firstName": "Jes\u00fas",
                            "lastName": "Tom\u00e1s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jes\u00fas Tom\u00e1s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696761"
                        ],
                        "name": "F. Casacuberta",
                        "slug": "F.-Casacuberta",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Casacuberta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Casacuberta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 349588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d38ee9eb5f6b3529899886232855fd2f74f8c9c3",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical machine translation, there are many source words that can present different translations. The usual approach to disambiguating these words is to use a target language model. These models are based on local phenomena and in many cases are not capable of properly translating some of these words. To deal with this problem, a new approach is proposed that is based on the so-called naive Bayesian classifier. After a process of automatic selection of ambiguous words, an adequate binary feature set that maximizes the information gain is chosen. A Bayesian classifier can be used to choose the most adequate translation of a word, using this feature set. Experimental results on a parallel corpus (approximately 650,000 Spanish-Catalan sentence pairs) show the benefits that the proposed method can achieve."
            },
            "slug": "Binary-Feature-Classification-for-Word-in-Machine-Tom\u00e1s-Casacuberta",
            "title": {
                "fragments": [],
                "text": "Binary Feature Classification for Word Disambiguation in Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new approach is proposed that is based on the so-called naive Bayesian classifier, which can be used to choose the most adequate translation of a word, using this feature set."
            },
            "venue": {
                "fragments": [],
                "text": "PRIS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 206
                            }
                        ],
                        "text": "\u2026usedfor statisticalmachinetranslation(Bergeret al., 1996), word alignmentof a translationcorpus(Melamed,2000),multilingual documentretrieval (Franzet al., 1999),automaticdictionary construction(Resnik and Melamed,1997), and datapreparationfor word sensedisambiguation programs(Brown etal., 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3074496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b66fc3bbba9027fd1f0ebf6d1c5c849ef15ca695",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Many multilingual NLP applications need to translate words between different languages, but cannot afford the computational expenses of inducing or applying a full translation model. For theses applications, we have designed a fast algorithm for estimating a partial translation model, which accounts for translational equivalence only at the word level. The model's precision/recall trade-off can be directly controlled via one threshold parameter. This feature makes the model more suitable for applications that are not fully statistical. The model's hidden parameters can be easily conditioned on information extrinsic to the model, providing an easy way to integrate pre-existing knowledge such as part-of-speech, dictionaries, word order, etc., Our model can link word tokens in parallel texts as well as other translation models in the literature. Unlike other translation models, it can automatically produce dictionary-sized translation lexicons, and it can do so with over 99% accuracy."
            },
            "slug": "A-Word-to-Word-Model-of-Translational-Equivalence-Melamed",
            "title": {
                "fragments": [],
                "text": "A Word-to-Word Model of Translational Equivalence"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A fast algorithm for estimating a partial translation model, which accounts for translational equivalence only at the word level, that can automatically produce dictionary-sized translation lexicons and can do so with over 99% accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247319"
                        ],
                        "name": "S. Vogel",
                        "slug": "S.-Vogel",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13964295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a4a53ea2e895a2ac820b151bb040297241f1d46",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In the VERBMOBIL project several translation methods are used concurrently to improve the overall performance of the system. One of the translation modules is based on a statistical approach. In this paper, we give an overview of this approach and how it is embedded in the VERBMOBIL system. Results from a comparative evaluation are given to compare the statistical approach to the other translation methods."
            },
            "slug": "The-Statistical-Translation-Module-in-the-Verbmobil-Vogel-Och",
            "title": {
                "fragments": [],
                "text": "The Statistical Translation Module in the Verbmobil System"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An overview of the statistical approach to translation in the VERBMOBIL system is given and results from a comparative evaluation are given to compare this approach to the other translation methods."
            },
            "venue": {
                "fragments": [],
                "text": "KONVENS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": false,
            "numCitedBy": 7803,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12928205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8457e5ac4b519fbf9420ddcc67e32e272bba427c",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "STRAND (Resnik, 1998) is a language-independent system for automatic discovery of text in parallel translation on the World Wide Web. This paper extends the preliminary STRAND results by adding automatic language identification, scaling up by orders of magnitude, and formally evaluating performance. The most recent end-product is an automatically acquired parallel corpus comprising 2491 English-French document pairs, approximately 1.5 million words per language."
            },
            "slug": "Mining-the-Web-for-Bilingual-Text-Resnik",
            "title": {
                "fragments": [],
                "text": "Mining the Web for Bilingual Text"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The preliminary STRAND results are extended by adding automatic language identification, scaling up by orders of magnitude, and formally evaluating performance."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403907739"
                        ],
                        "name": "Y. Al-Onaizan",
                        "slug": "Y.-Al-Onaizan",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Al-Onaizan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Al-Onaizan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35799577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f3e90eae5d24f502603163aed4bdfc32203207c",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical models have recently been applied to machine translation with interesting results. Algorithms for processing these models have not received wide circulation, however. By contrast, general finite-state transduction algorithms have been applied in a variety of tasks. This paper gives a finite-state reconstruction of statistical translation and demonstrates the use of standard tools to compute statistically likely translations. Ours is the first translation algorithm for \u201cfertility/permutation\u201d statistical models to be described in replicable detail."
            },
            "slug": "Translation-with-finite-state-devices-Knight-Al-Onaizan",
            "title": {
                "fragments": [],
                "text": "Translation with finite-state devices"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The authors' is the first translation algorithm for \u201cfertility/permutation\u201d statistical models to be described in replicable detail and demonstrates the use of standard tools to compute statistically likely translations."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069902"
                        ],
                        "name": "P. Roossin",
                        "slug": "P.-Roossin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Roossin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roossin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14386564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1066659ec1afee9dce586f6f49b7d44527827e1",
            "isKey": false,
            "numCitedBy": 1940,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a statistical approach to machine translation. We describe the application of our approach to translation from French to English and give preliminary results."
            },
            "slug": "A-Statistical-Approach-to-Machine-Translation-Brown-Cocke",
            "title": {
                "fragments": [],
                "text": "A Statistical Approach to Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The application of the statistical approach to translation from French to English and preliminary results are described and the results are given."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 31
                            }
                        ],
                        "text": "To make thispapercomparableto (Brown et al., 1993),we useEnglish-Frenchnotationin this section."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 33
                            }
                        ],
                        "text": "To make this paper comparable to (Brown et al., 1993), we use English-French notation in this section."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "Notethisnotation is differentfrom (Brown et al., 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "Following (Brown et al., 1993) and the other literaturein TM, this paperonly focusesthe detailsof TM. Applicationsof ourTM, suchasmachinetranslationor dictionaryconstruction,will be describedin a separatepaper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Brown et al. (1993)assumesthat there is an invisible NULL word in the input sentence andit generatesoutputwordsthataredistributed into randompositions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 10
                            }
                        ],
                        "text": "Following (Brown et al., 1993) and the other literature in TM, this paper only focuses the details of TM."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 37
                            }
                        ],
                        "text": "Note this notation is different from (Brown et al., 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 44
                            }
                        ],
                        "text": "Mathematical details are fully described in (Brown et al., 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 41
                            }
                        ],
                        "text": "Mathematicaldetailsarefully describedin (Brown et al., 1993)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13259913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab7b5917515c460b90451e67852171a531671ab8",
            "isKey": true,
            "numCitedBy": 4745,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus."
            },
            "slug": "The-Mathematics-of-Statistical-Machine-Translation:-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Statistical Machine Translation: Parameter Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus, given a set of pairs of sentences that are translations of one another."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324070"
                        ],
                        "name": "C. Tillmann",
                        "slug": "C.-Tillmann",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Tillmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tillmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7829066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f630bbd08dc16e8e61deef8183eaf80d03590d28",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming (DP). The search algorithm uses the translation model presented in Brown et al. (1993). Starting from a DP-based solution to the traveling-salesman problem, we present a novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm. Word reordering restrictions especially useful for the translation direction German to English are presented. The restrictions are generalized, and a set of four parameters to control the word reordering is introduced, which then can easily be adopted to new translation directions. The beam search procedure has been successfully tested on the Verbmobil task (German to English, 8,000-word vocabulary) and on the Canadian Hansards task (French to English, 100,000-word vocabulary). For the medium-sized Verbmobil task, a sentence can be translated in a few seconds, only a small number of search errors occur, and there is no performance degradation as measured by the word error criterion used in this article."
            },
            "slug": "Word-Reordering-and-a-Dynamic-Programming-Beam-for-Tillmann-Ney",
            "title": {
                "fragments": [],
                "text": "Word Reordering and a Dynamic Programming Beam Search Algorithm for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm for statistical machine translation based on dynamic programming (DP)."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736723"
                        ],
                        "name": "Ishwar Chander",
                        "slug": "Ishwar-Chander",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Chander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ishwar Chander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105813021"
                        ],
                        "name": "Matthew Haines",
                        "slug": "Matthew-Haines",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Haines",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Haines"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40502269"
                        ],
                        "name": "Masayo Iida",
                        "slug": "Masayo-Iida",
                        "structuredName": {
                            "firstName": "Masayo",
                            "lastName": "Iida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masayo Iida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076094546"
                        ],
                        "name": "Steve K. Luk",
                        "slug": "Steve-K.-Luk",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Luk",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve K. Luk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143660355"
                        ],
                        "name": "R. Whitney",
                        "slug": "R.-Whitney",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Whitney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Whitney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2219982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4548589b8212b2b80d9bb706b44e369978683954",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge-based machine translation (KBMT) techniques yield high quabty in domuoH with detailed semantic models, limited vocabulary, and controlled input grammar Scaling up along these dimensions means acquiring large knowledge resources It also means behaving reasonably when definitive knowledge is not yet available This paper describes how we can fill various KBMT knowledge gap*, often using robust statistical techniques We describe quantitative and qualitative results from JAPANGLOSS, a broad-coverage Japanese-English MT system."
            },
            "slug": "Filling-Knowledge-Gaps-in-a-Broad-Coverage-Machine-Knight-Chander",
            "title": {
                "fragments": [],
                "text": "Filling Knowledge Gaps in a Broad-Coverage Machine Translation System"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "How to fill various KBMT knowledge gap*, often using robust statistical techniques is described, and quantitative and qualitative results from JAPANGLOSS, a broad-coverage Japanese-English MT system are described."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482936"
                        ],
                        "name": "Gideon S. Mann",
                        "slug": "Gideon-S.-Mann",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Mann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gideon S. Mann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 27299562,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "9abac1f26202dfb9ec49ef0f6c9400dbace044c9",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages. Bilingual lexicons within languages families are induced using probabilistic string edit distance models. Translation lexicons for arbitrary distant language pairs are then generated by a combination of these intra-family translation models and one or more cross-family on-line dictionaries. Up to 95% exact match accuracy is achieved on the target vocabulary (30-68% of inter-family test pairs). Thus substantial portions of translation lexicons can be generated accurately for languages where no bilingual dictionary or parallel corpora may exist."
            },
            "slug": "Multipath-Translation-Lexicon-Induction-via-Bridge-Mann-Yarowsky",
            "title": {
                "fragments": [],
                "text": "Multipath Translation Lexicon Induction via Bridge Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Substantial portions of translation lexicons can be generated accurately for languages where no bilingual dictionary or parallel corpora may exist, up to 95% exact match accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403907739"
                        ],
                        "name": "Y. Al-Onaizan",
                        "slug": "Y.-Al-Onaizan",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Al-Onaizan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Al-Onaizan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50655248"
                        ],
                        "name": "Ulrich Germann",
                        "slug": "Ulrich-Germann",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Germann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrich Germann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791311"
                        ],
                        "name": "U. Hermjakob",
                        "slug": "U.-Hermjakob",
                        "structuredName": {
                            "firstName": "Ulf",
                            "lastName": "Hermjakob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hermjakob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14387864,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "d2be77aeacf776d6a3234a30ada448a836948fe9",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Current corpus-based machine translation techniques do not work very well when given scarce linguistic resources. To examine the gap between human and machine translators, we created an experiment in which human beings were asked to translate an unknown language into English on the sole basis of a very small bilingual text. Participants performed quite well, and debrieflngs revealed a number of valuable strategies. We discuss these strategies and apply some of them to a statistical translation system."
            },
            "slug": "Translating-with-Scarce-Resources-Al-Onaizan-Germann",
            "title": {
                "fragments": [],
                "text": "Translating with Scarce Resources"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An experiment was created in which human beings were asked to translate an unknown language into English on the sole basis of a very small bilingual text, and participants performed quite well, and debriefs revealed a number of valuable strategies."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736744"
                        ],
                        "name": "A. Itai",
                        "slug": "A.-Itai",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Itai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Itai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1964654,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "67df61766618f54e3b136c18aa28694395b5fd6d",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach for resolving lexical ambiguities in one language using statistical data from a monolingual corpus of another language. This approach exploits the differences between mappings of words to senses in different languages. The paper concentrates on the problem of target word selection in machine translation, for which the approach is directly applicable. The presented algorithm identifies syntactic relations between words, using a source language parser, and maps the alternative interpretations of these relations to the target language, using a bilingual lexicon. The preferred senses are then selected according to statistics on lexical relations in the target language. The selection is based on a statistical model and on a constraint propagation algorithm, which simultaneously handles all ambiguities in the sentence. The method was evaluated using three sets of Hebrew and German examples and was found to be very useful for disambiguation. The paper includes a detailed comparative analysis of statistical sense disambiguation methods."
            },
            "slug": "Word-Sense-Disambiguation-Using-a-Second-Language-Dagan-Itai",
            "title": {
                "fragments": [],
                "text": "Word Sense Disambiguation Using a Second Language Monolingual Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents a new approach for resolving lexical ambiguities in one language using statistical data from a monolingual corpus of another language, which exploits the differences between mappings of words to senses in different languages."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 70
                            }
                        ],
                        "text": "Brill\u2019s part-of-speech (POS) tagger (Brill, 1995) and Collins\u2019 parser (Collins, 1999) were used to obtain parse trees for the English side of the corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7901127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fc44ff7f37ec5585310666c183c65e0a0bb2446",
            "isKey": false,
            "numCitedBy": 2062,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes three statistical models for natural language parsing. The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree. Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram lexical dependencies, wh-movement, and preferences for close attachment. All of these preferences are expressed by probabilities conditioned on lexical heads. The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature. To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of precision/recall results in recovering various types of dependencies. We analyze various characteristics of the models through experiments on parsing accuracy, by collecting frequencies of various structures in the treebank, and through linguistically motivated examples. Finally, we compare the models to others that have been applied to parsing the treebank, aiming to give some explanation of the difference in performance of the various models."
            },
            "slug": "Head-Driven-Statistical-Models-for-Natural-Language-Collins",
            "title": {
                "fragments": [],
                "text": "Head-Driven Statistical Models for Natural Language Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Three statistical models for natural language parsing are described, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152827470"
                        ],
                        "name": "Lei Zhang",
                        "slug": "Lei-Zhang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143849609"
                        ],
                        "name": "M. Zhou",
                        "slug": "M.-Zhou",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227579"
                        ],
                        "name": "C. Huang",
                        "slug": "C.-Huang",
                        "structuredName": {
                            "firstName": "Changning",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8809724,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee7e334a20c0268197bb87837fc92dfa2f9100ad",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider here the problem of Chinese named entity (NE) identification using statistical language model(LM). In this research, word segmentation and NE identification have been integrated into a unified framework that consists of several class-based language models. We also adopt a hierarchical structure for one of the LMs so that the nested entities in organization names can be identified. The evaluation on a large test set shows consistent improvements. Our experiments further demonstrate the improvement after seamlessly integrating with linguistic heuristic information, cache-based model and NE abbreviation identification."
            },
            "slug": "Chinese-Named-Entity-Identification-Using-Language-Sun-Gao",
            "title": {
                "fragments": [],
                "text": "Chinese Named Entity Identification Using Class-based Language Model"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "In this research, word segmentation and NE identification have been integrated into a unified framework that consists of several class-based language models and a hierarchical structure is adopted for one of the LMs so that the nested entities in organization names can be identified."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069902"
                        ],
                        "name": "P. Roossin",
                        "slug": "P.-Roossin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Roossin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roossin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5216540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2166fa493a8c6e40f7f8562d15712dd3c75f03df",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to automatic translation is outlined that utilizes techniques of statistical information extraction from large data bases. The method is based on the availability of pairs of large corresponding texts that are translations of each other. In our case, the texts are in English and French.Fundamental to the technique is a complex glossary of correspondence of fixed locutions. The steps of the proposed translation process are: (1) Partition the source text into a set of fixed locutions. (2) Use the glossary plus contextual information to select the corresponding set of fixed locutions into a sequence forming the target sentence. (3) Arrange the words of the target fixed locutions into a sequence forming the target sentence.We have developed statistical techniques facilitating both the automatic creation of the glossary, and the performance of the three translation steps, all on the basis of an alignment of corresponding sentences in the two texts.While we are not yet able to provide examples of French / English translation, we present some encouraging intermediate results concerning glossary creation and the arrangement of target word sequences."
            },
            "slug": "A-Statistical-Approach-to-Language-Translation-Brown-Cocke",
            "title": {
                "fragments": [],
                "text": "A Statistical Approach to Language Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An approach to automatic translation is outlined that utilizes techniques of statistical information extraction from large data bases based on the availability of pairs of large corresponding texts that are translations of each other in English and French."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 43
                            }
                        ],
                        "text": ", 1999), automatic dictionary construction (Resnik and Melamed, 1997), and data preparation for word sense disambiguation programs (Brown et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3264135,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "1931742167393426ef56523d0ecf53a6e92d0ed0",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the utility of an algorithm for translation lexicon acquisition (SABLE), used previously on a very large corpus to acquire general translation lexicons, when that algorithm is applied to a much smaller corpus to produce candidates for domain-specific translation lexicons."
            },
            "slug": "Semi-Automatic-Acquisition-of-Domain-Specific-Resnik-Melamed",
            "title": {
                "fragments": [],
                "text": "Semi-Automatic Acquisition of Domain-Specific Translation Lexicons"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The utility of an algorithm for translation lexicon acquisition (SABLE), used previously on a very large corpus to acquire general translation lexicons, when that algorithm is applied to a much smaller corpus to produce candidates for domain-specifictranslation lexicons is investigated."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50655248"
                        ],
                        "name": "Ulrich Germann",
                        "slug": "Ulrich-Germann",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Germann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrich Germann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3117946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1a7d7376340266d2c29b1c306c5a7d7fb52a043",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on our experience with building a statistical MT system from scratch, including the creation of a small parallel Tamil-English corpus, and the results of a task-based pilot evaluation of statistical MT systems trained on sets of ca. 1300 and ca. 5000 parallel sentences of Tamil and English data. Our results show that even with apparently incomprehensible system output, humans without any knowledge of Tamil can achieve performance rates as high as 86% accuracy for topic identification, 93% recall for document retrieval, and 64% recall on question answering (plus an additional 14% partially correct answers)."
            },
            "slug": "Building-a-Statistical-Machine-Translation-System-Germann",
            "title": {
                "fragments": [],
                "text": "Building a Statistical Machine Translation System from Scratch: How Much Bang for the Buck Can We Expect?"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results show that even with apparently incomprehensible system output, humans without any knowledge of Tamil can achieve performance rates as high as 86% accuracy for topic identification, 93% recall for document retrieval, and 64% recall on question answering."
            },
            "venue": {
                "fragments": [],
                "text": "DDMMT@ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121785394"
                        ],
                        "name": "Kuang-hua Chen",
                        "slug": "Kuang-hua-Chen",
                        "structuredName": {
                            "firstName": "Kuang-hua",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kuang-hua Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153924342"
                        ],
                        "name": "Hsin-Hsi Chen",
                        "slug": "Hsin-Hsi-Chen",
                        "structuredName": {
                            "firstName": "Hsin-Hsi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Hsi Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8721049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51facec91a5770f9267a4f4a711f3ab15fc969f2",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A pure statistics-based machine translation system is usually incapable of processing long sentences and is usually domain dependent. A pure rule-based machine translation system involves many costs in formulating rules. In addition, it is easy to introduce inconsistencies in a rule-based system, when the number of rules increases. Integrating both of approaches will get rid of these disadvantages. In this paper, a new model for machine translation system is proposed. A partial parsing method is adopted and the translation process is performed chunk by chunk. In synthesis module, the words are locally rearranged in chunks according to Markov model. Since the length of a chunk is much shorter than that of a sentence, the disadvantage of Markov model in dealing with long distance phenomena is greatly reduced. The structural transfer is fulfilled using a set of rules; in contrast, lexical transfer is resolved using bilingual constraints. The qualitative and quantitative knowledge is applied interleavingly and cooperatively, so that the advantages of both approaches are kept."
            },
            "slug": "Machine-Translation:-An-Integrated-Approach-Chen-Chen",
            "title": {
                "fragments": [],
                "text": "Machine Translation: An Integrated Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new model for machine translation system is proposed, where the length of a chunk is much shorter than that of a sentence, and the disadvantage of Markov model in dealing with long distance phenomena is greatly reduced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1060508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "925b40ae3aa7ed1bf642d78dc80fce1f573293e2",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Large-scale natural language generation requires the integration of vast amounts of knowledge: lexical, grammatical, and conceptual. A robust generator must be able to operate well even when pieces of knowledge are missing. It must also be robust against incomplete or inaccurate inputs. To attack these problems, we have built a hybrid generator, in which gaps in symbolic knowledge are filled by statistical methods. We describe algorithms and show experimental results. We also discuss how the hybrid generation model can be used to simplify current generators and enhance their portability, even when perfect knowledge is in principle obtainable."
            },
            "slug": "Two-Level,-Many-Paths-Generation-Knight-Hatzivassiloglou",
            "title": {
                "fragments": [],
                "text": "Two-Level, Many-Paths Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A hybrid generator is built, in which gaps in symbolic knowledge are filled by statistical methods, to attack problems of large-scale natural language generation and to simplify current generators and enhance their portability."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 176401,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "29574f0d891d4cc4577a0426aa675dce746a3ad1",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive the rhetorical structures of texts by means of two new, surface-form-based algorithms: one that identifies discourse usages of cue phrases and breaks sentences into clauses, and one that produces valid rhetorical structure trees for unrestricted natural language texts. The algorithms use information that was derived from a corpus analysis of cue phrases."
            },
            "slug": "The-Rhetorical-Parsing-of-Unrestricted-Natural-Marcu",
            "title": {
                "fragments": [],
                "text": "The Rhetorical Parsing of Unrestricted Natural Language Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Two new, surface-form-based algorithms are derived by means of one that identifies discourse usages of cue phrases and breaks sentences into clauses, and one that produces valid rhetorical structure trees for unrestricted natural language texts."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2176216"
                        ],
                        "name": "Douglas A. Jones",
                        "slug": "Douglas-A.-Jones",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Jones",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas A. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48030718"
                        ],
                        "name": "Rick Havrilla",
                        "slug": "Rick-Havrilla",
                        "structuredName": {
                            "firstName": "Rick",
                            "lastName": "Havrilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rick Havrilla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 81
                            }
                        ],
                        "text": "Our channel operations are also similar to the mechanism in Twisted Pair Grammar (Jones and Havrilla, 1998) used in their knowledge-based system."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": "Our channeloperationsare also similar to the mechanismin Twisted Pair Grammar(JonesandHavrilla, 1998)usedin their knowledge-basedsystem."
                    },
                    "intents": []
                }
            ],
            "corpusId": 43800528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07f8dc8ac06b0b3305ea96a62ea98145dc9620f4",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a streamlined knowledge acquisition method for semi-automatically constructing knowledge bases for a Knowledge Based Machine Translation (KBMT) system. This method forms the basis of a very simple Java-based user interface that enables a language expert to build lexical and syntactic transfer knowledge bases without extensive specialized training as an MT system builder. Following [Wu 1997], we assume that the permutation of binary-branching structures is a sufficient reordering mechanism for MT. Our syntactic knowledge is based on a novel, highly constrained grammar construction environment in which the only re-ordering mechanism is the permutation of binary-branching structures (Twisted Pair Grammar). We describe preliminary results for several fully implemented components of a Hindi/Urdu to English MT prototype being built with this interface."
            },
            "slug": "Twisted-pair-grammar:-support-for-rapid-development-Jones-Havrilla",
            "title": {
                "fragments": [],
                "text": "Twisted pair grammar: support for rapid development of machine translation for low density languages"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A streamlined knowledge acquisition method for semi-automatically constructing knowledge bases for a Knowledge Based Machine Translation (KBMT) system that enables a language expert to build lexical and syntactic transfer knowledge bases without extensive specialized training as an MT system builder."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 48
                            }
                        ],
                        "text": ", 1996), word alignment of a translation corpus (Melamed, 2000), multilingual document retrieval (Franz et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2420674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38224f0aa39e4d4b9a0060e0fe3941f9e6d1bee1",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallel texts (bitexts) have properties that distinguish them from other kinds of parallel data. First, most words translate to only one other word. Second, bitext correspondence is typically only partialmany words in each text have no clear equivalent in the other text. This article presents methods for biasing statistical translation models to reflect these properties. Evaluation with respect to independent human judgments has confirmed that translation models biased in this fashion are significantly more accurate than a baseline knowledge-free model. This article also shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs. Even the simplest kinds of language-specific knowledge, such as the distinction between content words and function words, are shown to reliably boost translation model performance on some tasks. Statistical models that reflect knowledge about the model domain combine the best of both the rationalist and empiricist paradigms."
            },
            "slug": "Models-of-translation-equivalence-among-words-Melamed",
            "title": {
                "fragments": [],
                "text": "Models of translation equivalence among words"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents methods for biasing statistical translation models to reflect bitext properties, and shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683412"
                        ],
                        "name": "Pascale Fung",
                        "slug": "Pascale-Fung",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "Fung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascale Fung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7822594,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "63a6f511fc9adb44da87ceccf9247d7fb5d42169",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel context heterogeneity similarity measure between words and their translations in helping to compile bilingual lexicon entries from a non-parallel English-Chinese corpus. Current algorithms for bilingual lexicon compilation rely on occurrence frequencies, length or positional statistics derived from parallel texts. There is little correlation between such statistics of a word and its translation in non-parallel corpora. On the other hand, we suggest that words with productive context in one language translate to words with productive context in another language, and words with rigid context translate into words With rigid context. Context heterogeneity measures how productive the context of a word is in a given domain, independent of its absolute occurrence frequency in the text. Based on this information, we derive statistics of bilingual word pairs from a non-parallel corpus. These statistics can be used to bootstrap a bilingual dictionary compilation algorithm."
            },
            "slug": "Compiling-Bilingual-Lexicon-Entries-From-a-Corpus-Fung",
            "title": {
                "fragments": [],
                "text": "Compiling Bilingual Lexicon Entries From a Non-Parallel English-Chinese Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel context heterogeneity similarity measure between words and their translations in helping to compile bilingual lexicon entries from a non-parallel English-Chinese corpus is proposed and it is suggested that words with productive context in one language translate to words withproductive context in another language."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32326549"
                        ],
                        "name": "J. Kupiec",
                        "slug": "J.-Kupiec",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Kupiec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kupiec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3031527,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b1bf3d314ad996c394949f88c4091a4832ce0c9b",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus. The taggers provide part-of-speech categories which are used by finite-state recognizers to extract simple noun phrases for both languages. Noun phrases are then mapped to each other using an iterative re-estimation algorithm that bears similarities to the Baum-Welch algorithm which is used for training the taggers. The algorithm provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated. Improvements to the basic algorithm are described, which enable context to be accounted for when constructing the noun phrase mappings."
            },
            "slug": "An-Algorithm-for-finding-Noun-Phrase-in-Bilingual-Kupiec",
            "title": {
                "fragments": [],
                "text": "An Algorithm for finding Noun Phrase Correspondences in Bilingual Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus and provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78659204"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683363"
                        ],
                        "name": "M. Nederhof",
                        "slug": "M.-Nederhof",
                        "structuredName": {
                            "firstName": "Mark-Jan",
                            "lastName": "Nederhof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nederhof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7393542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be1824ac017376a44c96a89d1262f243ca7033aa",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for approximating context-free languages with regular languages. The algorithm is based on a simple transformation that applies to any context-free grammar and guarantees that the result can be compiled into a finite automaton. The resulting grammar contains at most one new nonterminal for any nonterminal symbol of the input grammar. The result thus remains readable and if necessary modifiable. We extend the approximation algorithm to the case of weighted context-free grammars. We also report experiments with several grammars showing that the size of the minimal deterministic automata accepting the resulting approximations is of practical use for applications such as speech recognition."
            },
            "slug": "Regular-Approximation-of-Context-Free-Grammars-Mohri-Nederhof",
            "title": {
                "fragments": [],
                "text": "Regular Approximation of Context-Free Grammars through Transformation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The approximation algorithm is extended to the case of weighted context-free grammars and shows that the size of the minimal deterministic automata accepting the resulting approximations is of practical use for applications such as speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145978046"
                        ],
                        "name": "Lisa Ballesteros",
                        "slug": "Lisa-Ballesteros",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Ballesteros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lisa Ballesteros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2106176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79f150bf256c1682524e5722b115c8aec905df0a",
            "isKey": false,
            "numCitedBy": 400,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Dictionary methods for cross-language information retrieval give performance below that for mono-lingual retrieval. Failure to translate multi-term phrases has been shown to be one of the factors responsible for the errors associated with dictionary methods. First, we study the importance of phrasal translation for this approach. Second, we explore the role of phrases in query expansion via local context analysis and local feedback and show how they can be used to significantly reduce the error associated with automatic dictionary translation."
            },
            "slug": "Phrasal-translation-and-query-expansion-techniques-Ballesteros-Croft",
            "title": {
                "fragments": [],
                "text": "Phrasal translation and query expansion techniques for cross-language information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The role of phrases in query expansion via local context analysis and local feedback and how they can be used to significantly reduce the error associated with automatic dictionary translation are explored."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50655248"
                        ],
                        "name": "Ulrich Germann",
                        "slug": "Ulrich-Germann",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Germann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrich Germann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21755122"
                        ],
                        "name": "Michael E. Jahr",
                        "slug": "Michael-E.-Jahr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jahr",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael E. Jahr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 90111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd5514876b7e1c09b6d2f931d90bb34aa3501441",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A good decoding algorithm is critical to the success of any statistical machine translation system. The decoder's job is to find the translation that is most likely according to set of previously learned parameters (and a formula for combining them). Since the space of possible translations is extremely large, typical decoding algorithms are only able to examine a portion of it, thus risking to miss good solutions. In this paper, we compare the speed and output quality of a traditional stack-based decoding algorithm with two new decoders: a fast greedy decoder and a slow but optimal decoder that treats decoding as an integer-programming optimization problem."
            },
            "slug": "Fast-Decoding-and-Optimal-Decoding-for-Machine-Germann-Jahr",
            "title": {
                "fragments": [],
                "text": "Fast Decoding and Optimal Decoding for Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper compares the speed and output quality of a traditional stack-based decoding algorithm with two new decoders: a fast greedy decoder and a slow but optimal decoder that treats decoding as an integer-programming optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6830931"
                        ],
                        "name": "Kumiko Tanaka-Ishii",
                        "slug": "Kumiko-Tanaka-Ishii",
                        "structuredName": {
                            "firstName": "Kumiko",
                            "lastName": "Tanaka-Ishii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kumiko Tanaka-Ishii"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745636"
                        ],
                        "name": "H. Iwasaki",
                        "slug": "H.-Iwasaki",
                        "structuredName": {
                            "firstName": "Hideya",
                            "lastName": "Iwasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Iwasaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7077187,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2aedda5604b0faa36ea9e13b2f81db7909b0946",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for extracting lexical translations from non-aligned corpora is proposed to cope with the unavailability of large aligned corpus. The assumption that \"translations of two co-occurring words in a source language also co-occur in the target language\" is adopted and represented in the stochastic matrix formulation. The translation matrix provides the co-occurring information translated from the source into the target. This translated co-occurring information should resemble that of the original in the target when the ambiguity of the translational relation is resolved. An algorithm to obtain the best translation matrix is introduced. Some experiments were performed to evaluate the effectiveness of the ambiguity resolution and the refinement of the dictionary."
            },
            "slug": "Extraction-of-Lexical-Translations-from-Non-Aligned-Tanaka-Ishii-Iwasaki",
            "title": {
                "fragments": [],
                "text": "Extraction of Lexical Translations from Non-Aligned Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A method for extracting lexical translations from non-aligned corpora is proposed to cope with the unavailability of large aligned corpus and the effectiveness of the ambiguity resolution and the refinement of the dictionary."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 519954,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4fe2a45babab10c1bfae05d2464363f4e52bbaf9",
            "isKey": false,
            "numCitedBy": 1322,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in both machine translation (e.g., Brown et al. 1990) and bilingual lexicography (e.g., Klavans and Tzoukermann 1990) have recently become interested in studying bilingual corpora, bodies of text such as the Canadian Hansards (parliamentary proceedings), which are available in multiple languages (such as French and English). One useful step is to align the sentences, that is, to identify correspondences between sentences in one language and sentences in the other language.This paper will describe a method and a program (align) for aligning sentences based on a simple statistical model of character lengths. The program uses the fact that longer sentences in one language tend to be translated into longer sentences in the other language, and that shorter sentences tend to be translated into shorter sentences. A probabilistic score is assigned to each proposed correspondence of sentences, based on the scaled difference of lengths of the two sentences (in characters) and the variance of this difference. This probabilistic score is used in a dynamic programming framework to find the maximum likelihood alignment of sentences.It is remarkable that such a simple approach works as well as it does. An evaluation was performed based on a trilingual corpus of economic reports issued by the Union Bank of Switzerland (UBS) in English, French, and German. The method correctly aligned all but 4% of the sentences. Moreover, it is possible to extract a large subcorpus that has a much smaller error rate. By selecting the best-scoring 80% of the alignments, the error rate is reduced from 4% to 0.7%. There were more errors on the English-French subcorpus than on the English-German subcorpus, showing that error rates will depend on the corpus considered; however, both were small enough to hope that the method will be useful for many language pairs.To further research on bilingual corpora, a much larger sample of Canadian Hansards (approximately 90 million words, half in English and and half in French) has been aligned with the align program and will be available through the Data Collection Initiative of the Association for Computational Linguistics (ACL/DCI). In addition, in order to facilitate replication of the align program, an appendix is provided with detailed c-code of the more difficult core of the align program."
            },
            "slug": "A-Program-for-Aligning-Sentences-in-Bilingual-Gale-Church",
            "title": {
                "fragments": [],
                "text": "A Program for Aligning Sentences in Bilingual Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper will describe a method and a program for aligning sentences based on a simple statistical model of character lengths, which uses the fact that longer sentences in one language tend to be translated into longer sentence in the other language, and that shorter sentences tend to been translated into shorter sentences."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 299716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce2fb35b836b6180a8c59c15db8a33c72251872b",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine translation of human languages (for example, Japanese, English, Spanish) was one of the earliest goals of computer science research, and it remains an elusive one. Like many AI tasks, trans-lation requires an immense amount of knowledge about language and the world. Recent approaches to machine translation frequently make use of text-based learning algorithms to fully or partially automate the acquisition of knowledge. This article illustrates these approaches."
            },
            "slug": "Automating-Knowledge-Acquisition-for-Machine-Knight",
            "title": {
                "fragments": [],
                "text": "Automating Knowledge Acquisition for Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This article illustrates how recent approaches to machine translation frequently make use of text-based learning algorithms to fully or partially automate the acquisition of knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7965906"
                        ],
                        "name": "Sabine Schulte im Walde",
                        "slug": "Sabine-Schulte-im-Walde",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "Schulte im Walde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sabine Schulte im Walde"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11291545,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "7cff8af0471e965d897bdaf0258f84e3b5458d40",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a noun chunker for German which is based on a head-lexicalised probabilistic context-free grammar. A manually developed grammar was semi-automatically extended with robustness rules in order to allow parsing of unrestricted text. The model parameters were learned from unlabelled training data by a probabilistic context-free parser. For extracting noun chunks, the parser generates all possible noun chunk analyses, scores them with a novel algorithm which maximizes the best chunk sequence criterion, and chooses the most probable chunk sequence. An evaluation of the chunker on 2,140 hand-annotated noun chunks yielded 92% recall and 93% precision."
            },
            "slug": "Robust-German-Noun-Chunking-With-a-Probabilistic-Schmid-Walde",
            "title": {
                "fragments": [],
                "text": "Robust German Noun Chunking With a Probabilistic Context-Free Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A noun chunker for German which is based on a head-lexicalised probabilistic context-free grammar was presented, which yielded 92% recall and 93% precision."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110568470"
                        ],
                        "name": "Kaoru Yamamoto",
                        "slug": "Kaoru-Yamamoto",
                        "structuredName": {
                            "firstName": "Kaoru",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaoru Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2855749"
                        ],
                        "name": "Mihoko Kitamura",
                        "slug": "Mihoko-Kitamura",
                        "structuredName": {
                            "firstName": "Mihoko",
                            "lastName": "Kitamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mihoko Kitamura"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 168273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c566bb88cbdbcdf2a2869f7e0bdadeb86625b1af",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents on-going research on automatic extraction of bilingual lexicon from English-Japanese parallel corpora. The main objective of this paper is to examine various N-gram models of generating translation units for bilingual lexicon extraction. Three N-gram models, a baseline model (Bound-length N-gram) and two new models (Chunk-bound N-gram and Dependency-linked N-gram) are compared. An experiment with 10000 English-Japanese parallel sentences shows that Chunk-bound N-gram produces the best result in terms of accuracy (83%) as well as coverage (60%) and it improves approximately by 13% in accuracy and by 5-9% in coverage from the previously proposed baseline model."
            },
            "slug": "A-Comparative-Study-on-Translation-Units-for-Yamamoto-Matsumoto",
            "title": {
                "fragments": [],
                "text": "A Comparative Study on Translation Units for Bilingual Lexicon Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Chunk-bound N-gram produces the best result in terms of accuracy as well as coverage and it improves approximately by 13% in accuracy and by 5-9% in coverage from the previously proposed baseline model."
            },
            "venue": {
                "fragments": [],
                "text": "DDMMT@ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3223661"
                        ],
                        "name": "Jonathan Graehl",
                        "slug": "Jonathan-Graehl",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Graehl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Graehl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 751575,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "96aba9b1e93cb8d730086c178445af6cd9daa859",
            "isKey": false,
            "numCitedBy": 670,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "It is challenging to translate names and technical terms across languages with different alphabets and sound inventories. These items are commonly transliterated, i.e., replaced with approximate phonetic equivalents. For example, computer in English comes out as (konpyuutaa) in Japanese. Translating such items from Japanese back to English is even more challenging, and of practical interest, as transliterated items make up the bulk of text phrases not found in bilingual dictionaries. We describe and evaluate a method for performing backwards transliterations by machine. This method uses a generative model, incorporating several distinct stages in the transliteration process."
            },
            "slug": "Machine-Transliteration-Knight-Graehl",
            "title": {
                "fragments": [],
                "text": "Machine Transliteration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes and evaluates a method for performing backwards transliterations by machine that uses a generative model, incorporating several distinct stages in the transliteration process."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403907739"
                        ],
                        "name": "Y. Al-Onaizan",
                        "slug": "Y.-Al-Onaizan",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Al-Onaizan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Al-Onaizan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3164759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5137974c9fb4de7778f811120f1cbf52d0fa565",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere, and because many are domain specific, not to be found in bilingual dictionaries. We present a novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources. We report on the application and evaluation of this algorithm in translating Arabic named entities to English. We also compare our results with the results obtained from human translations and a commercial system for the same task."
            },
            "slug": "Translating-Named-Entities-Using-Monolingual-and-Al-Onaizan-Knight",
            "title": {
                "fragments": [],
                "text": "Translating Named Entities Using Monolingual and Bilingual Resources"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources is presented and evaluation of this algorithm in translating Arabic named entities to English is reported on."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e6d09530490561f1fc4dbfbd82fc4ff456f046c",
            "isKey": false,
            "numCitedBy": 663,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallel corpora have become an essential resource for work in multilingual natural language processing. In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web, first reviewing the original algorithm and results and then presenting a set of significant enhancements. These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new content-based measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale. Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair."
            },
            "slug": "The-Web-as-a-Parallel-Corpus-Resnik-Smith",
            "title": {
                "fragments": [],
                "text": "The Web as a Parallel Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The use of supervised learning based on structural features of documents to improve classification performance, a new content-based measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066017394"
                        ],
                        "name": "P. Clarkson",
                        "slug": "P.-Clarkson",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Clarkson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Clarkson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13988648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdf4aa623e4d5b5edaeb873ed8e8b1cef0b59c87",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The CMU Statistical Language Modeling toolkit was re leased in in order to facilitate the construction and testing of bigram and trigram language models It is currently in use in over academic government and industrial laboratories in over countries This paper presents a new version of the toolkit We outline the con ventional language modeling technology as implemented in the toolkit and describe the extra e ciency and func tionality that the new toolkit provides as compared to previous software for this task Finally we give an exam ple of the use of the toolkit in constructing and testing a simple language model"
            },
            "slug": "Statistical-language-modeling-using-the-toolkit-Clarkson-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Statistical language modeling using the CMU-cambridge toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The CMU Statistical Language Modeling toolkit was re leased in in order to facilitate the construction and testing of bigram and trigram language models and the technology as implemented in the toolkit is outlined."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767307"
                        ],
                        "name": "H. Alshawi",
                        "slug": "H.-Alshawi",
                        "structuredName": {
                            "firstName": "Hiyan",
                            "lastName": "Alshawi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alshawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35313721"
                        ],
                        "name": "S. Bangalore",
                        "slug": "S.-Bangalore",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Bangalore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bangalore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10461112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64455eb3fd378965589a69aa8472c39af6d332d2",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper defines weighted head transducers, finite-state machines that perform middle-out string transduction. These transducers are strictly more expressive than the special case of standard left-to-right finite-state transducers. Dependency transduction models are then defined as collections of weighted head transducers that are applied hierarchically. A dynamic programming search algorithm is described for finding the optimal transduction of an input string with respect to a dependency transduction model. A method for automatically training a dependency transduction model from a set of input-output example strings is presented. The method first searches for hierarchical alignments of the training examples guided by correlation statistics, and then constructs the transitions of head transducers that are consistent with these alignments. Experimental results are given for applying the training method to translation from English to Spanish and Japanese."
            },
            "slug": "Learning-Dependency-Translation-Models-as-of-Head-Alshawi-Bangalore",
            "title": {
                "fragments": [],
                "text": "Learning Dependency Translation Models as Collections of Finite-State Head Transducers"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A method for automatically training a dependency transduction model from a set of input-output example strings and a dynamic programming search algorithm for finding the optimal transduction of an input string with respect to a dependency Transduction model are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2281602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812c2ad5d26f474d1c499c2665ba1a9e4fd74436",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In this position paper, we make several observations about the state of the art in automatic word sense disambiguation. Motivated by these observations, we offer several specific proposals to the community regarding improved evaluation criteria, common training and testing resources, and the definition of sense inventories."
            },
            "slug": "A-Perspective-on-Word-Sense-Disambiguation-Methods-Resnik",
            "title": {
                "fragments": [],
                "text": "A Perspective on Word Sense Disambiguation Methods and Their Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This position paper makes several specific proposals to the community regarding improved evaluation criteria, common training and testing resources, and the definition of sense inventories about the state of the art in automatic word sense disambiguation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057503722"
                        ],
                        "name": "Jim Barnett",
                        "slug": "Jim-Barnett",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Barnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Barnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729172"
                        ],
                        "name": "I. Mani",
                        "slug": "I.-Mani",
                        "structuredName": {
                            "firstName": "Inderjeet",
                            "lastName": "Mani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Mani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3116626"
                        ],
                        "name": "E. Rich",
                        "slug": "E.-Rich",
                        "structuredName": {
                            "firstName": "Elaine",
                            "lastName": "Rich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6338334,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "e456401ea4e75a30087e1f15b5ef429568c4a28b",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "KBNL is a knowledge-based natural language processing system that is novel in several ways, including the clean separation it enforces between linguistic knowledge and world knowledge, and its use of knowledge to aid in lexical acquisition. Applications of KBNL include intelligent interfaces, text retrieval, and machine translation."
            },
            "slug": "Knowledge-and-natural-language-processing-Barnett-Knight",
            "title": {
                "fragments": [],
                "text": "Knowledge and natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "KBNL is a knowledge-based natural language processing system that is novel in several ways, including the clean separation it enforces between linguistic knowledge and world knowledge, and its use of knowledge to aid in lexical acquisition."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121084921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c79a9bb8f885050cad70b4c69e016b186ffa538",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms which are based on modeling speech as a finite\u2010state, hidden Markov process have been very successful in recent years. This paper presents a generalization of these algorithms to certain denumerable\u2010state, hidden Markov processes. This algorithm permits automatic training of the stochastic analog of an arbitrary context free grammar. In particular, in contrast to many grammatical inference methods, the new algorithm allows the grammar to have an arbitrary degree of ambiguity. Since natural language is often syntactically ambiguous, it is necessary for the grammatical inference algorithm to allow for this ambiguity. Furthermore, allowing ambiguity in the grammar allows errors in the recognition process to be explicitly modeled in the grammar rather than added as an extra component."
            },
            "slug": "Trainable-grammars-for-speech-recognition-Baker",
            "title": {
                "fragments": [],
                "text": "Trainable grammars for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper presents a generalization of these algorithms to certain denumerable\u2010state, hidden Markov processes that permits automatic training of the stochastic analog of an arbitrary context free grammar."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754680"
                        ],
                        "name": "Michael Elhadad",
                        "slug": "Michael-Elhadad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elhadad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elhadad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175167"
                        ],
                        "name": "J. Robin",
                        "slug": "J.-Robin",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Robin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Robin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8752262,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "80f18f3e91d9dcf52e43308a23c70451c2ecc493",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a short demo providing an overview of SURGE (Systemic Unification Realization Grammar of English) a syntactic realization front-end for natural language generation systems. Developed over the last seven years 1 it embeds one of the most comprehensive computational grammar of English for generation available to date. It has been successfully reused in eight generators, that have little in common in terms of architecture. It has also been used for teaching natural language generation at several academic institutions."
            },
            "slug": "An-Overview-of-SURGE:-a-Reusable-Comprehensive-Elhadad-Robin",
            "title": {
                "fragments": [],
                "text": "An Overview of SURGE: a Reusable Comprehensive Syntactic Realization Component"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper describes a short demo providing an overview of SURGE (Systemic Unification Realization Grammar of English) a syntactic realization front-end for natural language generation systems."
            },
            "venue": {
                "fragments": [],
                "text": "INLG"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 912349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13b6eeb28328252a35cdcbe3ab8d09d2a9caf99d",
            "isKey": false,
            "numCitedBy": 1000,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce (1) a novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and (2) the concept of bilingual parsing with a variety of parallel corpus analysis applications. Aside from the bilingual orientation, three major features distinguish the formalism from the finite-state transducers more traditionally found in computational linguistics: it skips directly to a context-free rather than finite-state base, it permits a minimal extra degree of ordering flexibility, and its probabilistic formulation admits an efficient maximum-likelihood bilingual parsing algorithm. A convenient normal form is shown to exist. Analysis of the formalism's expressiveness suggests that it is particularly well suited to modeling ordering shifts between languages, balancing needed flexibility against complexity constraints. We discuss a number of examples of how stochastic inversion transduction grammars bring bilingual constraints to bear upon problematic corpus analysis tasks such as segmentation, bracketing, phrasal alignment, and parsing."
            },
            "slug": "Stochastic-Inversion-Transduction-Grammars-and-of-Wu",
            "title": {
                "fragments": [],
                "text": "Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and the concept of bilingual parsing with a variety of parallel corpus analysis applications are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9635459,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "0222b108dd18431daccec3f4e1b038fac8f0cddb",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "With an increasing number of languages making their way to our desktops everyday via the Internet, researchers have come to realize the lack of linguistic knowledge resources for scarcely represented/studied languages. In an attempt to bootstrap some of the required linguistic resources for some of those languages, this paper presents an unsupervised method for automatic multilingual word sense tagging using parallel corpora. The method is evaluated on the English Brown corpus and its translation into three different languages: French, German and Spanish. A preliminary evaluation of the proposed method yielded results of up to 79% accuracy rate for the English data on 81.8% of the SemCor manually tagged data."
            },
            "slug": "An-Unsupervised-Method-for-Multilingual-Word-Sense-Diab",
            "title": {
                "fragments": [],
                "text": "An Unsupervised Method for Multilingual Word Sense Tagging Using Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "An unsupervised method for automatic multilingual word sense tagging using parallel corpora is presented in an attempt to bootstrap some of the required linguistic resources for scarcely represented/studied languages."
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153584694"
                        ],
                        "name": "R. Rapp",
                        "slug": "R.-Rapp",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Rapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rapp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12479653,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "bf6cefab34c62596d486a86a0187c427d38f0b29",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for the alignment of words in translated texts are well established. However, only recently new approaches have been proposed to identify word translations from non-parallel or even unrelated texts. This task is more difficult, because most statistical clues useful in the processing of parallel texts cannot be applied to non-parallel texts. Whereas for parallel texts in some studies up to 99% of the word alignments have been shown to be correct, the accuracy for non-parallel texts has been around 30% up to now. The current study, which is based on the assumption that there is a correlation between the patterns of word co-occurrences in corpora of different languages, makes a significant improvement to about 72% of word translations identified correctly."
            },
            "slug": "Automatic-Identification-of-Word-Translations-from-Rapp",
            "title": {
                "fragments": [],
                "text": "Automatic Identification of Word Translations from Unrelated English and German Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The current study, based on the assumption that there is a correlation between the patterns of word co-occurrences in corpora of different languages, makes a significant improvement to about 72% of word translations identified correctly."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403806833"
                        ],
                        "name": "Simon Corston-Oliver",
                        "slug": "Simon-Corston-Oliver",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Corston-Oliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Corston-Oliver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1450529,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "c94f966a5273c22918d15f804452c1fa6040c139",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "RASTA (Rhetorical Structure Theory Analyzer), a discourse analysis component within the Microsoft English Grammar, efficiently computes representations of the structure of written discourse using information available in syntactic and logical form analyses. RASTA heuristically scores the rhetorical relations that it hypothesizes, using those scores to guide it in producing more plausible discourse representations before less plausible ones. The heuristic scores also provide a genre-independent method for evaluating competing discourse analyses: the best discourse analyses are those constructed from the strongest hypotheses."
            },
            "slug": "Beyond-String-Matching-and-Cue-Phrases:-Improving-Corston-Oliver",
            "title": {
                "fragments": [],
                "text": "Beyond String Matching and Cue Phrases: Improving Efficiency and Coverage in Discourse Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145199941"
                        ],
                        "name": "H. Meng",
                        "slug": "H.-Meng",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Meng",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31726096"
                        ],
                        "name": "W. Lo",
                        "slug": "W.-Lo",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lo",
                            "middleNames": [
                                "Kit"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108381400"
                        ],
                        "name": "Berlin Chen",
                        "slug": "Berlin-Chen",
                        "structuredName": {
                            "firstName": "Berlin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berlin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055743514"
                        ],
                        "name": "K. Tang",
                        "slug": "K.-Tang",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8551944,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9f565066e6919fc43a4816689dd9d48028e1c8",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a technique for automatic transliteration of named entities for English-Chinese cross-language spoken document retrieval (CL-SDR). Our retrieval system integrates machine translation, speech recognition and information retrieval technologies. An English news story forms a textual query that is automatically translated into Chinese words, which are mapped into Mandarin syllables by pronunciation dictionary lookup. Mandarin radio news broadcasts form spoken documents that are indexed by word and syllable recognition. The information retrieval engine performs matching in both word and syllable scales. The English queries contain many named entities that tend to be out-of-vocabulary words for machine translation and speech recognition, and are omitted in retrieval. Names are often transliterated across languages and are generally important for retrieval. We present a technique that takes in a name spelling and automatically generates a phonetic cognate in terms of Chinese syllables to be used in retrieval. Experiments show consistent retrieval performance improvement by including the use of named entities in this way."
            },
            "slug": "Generating-phonetic-cognates-to-handle-named-in-Meng-Lo",
            "title": {
                "fragments": [],
                "text": "Generating phonetic cognates to handle named entities in English-Chinese cross-language spoken document retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A technique that takes in a name spelling and automatically generates a phonetic cognate in terms of Chinese syllables to be used in retrieval is presented, showing consistent retrieval performance improvement by including the use of named entities in this way."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Workshop on Automatic Speech Recognition and Understanding, 2001. ASRU '01."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144300985"
                        ],
                        "name": "Ferran Pl\u00e0",
                        "slug": "Ferran-Pl\u00e0",
                        "structuredName": {
                            "firstName": "Ferran",
                            "lastName": "Pl\u00e0",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ferran Pl\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145621529"
                        ],
                        "name": "Antonio Molina",
                        "slug": "Antonio-Molina",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145387377"
                        ],
                        "name": "N. Prieto",
                        "slug": "N.-Prieto",
                        "structuredName": {
                            "firstName": "Natividad",
                            "lastName": "Prieto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Prieto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1123574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d01a25a204e66b44ee2ab1380f86831d3dfaa9b",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an integrated system for tagging and chunking texts from a certain language. The approach is based on stochastic finite-state models that are learnt automatically. This includes biagram models or finite-state automata learnt using grammatical inference techniques. As the models involved in our system are learnt automatically, this is a very flexible and portable system.In order to show the viability of our approach we present results for tagging and chunking using bigram models on the Wall Street Journal corpus. We have achieved an accuracy rate for tagging of 96.8%, and a precision rate for NP chunks of 94.6% with a recall rate of 93.6%."
            },
            "slug": "Tagging-and-Chunking-with-Bigrams-Pl\u00e0-Molina",
            "title": {
                "fragments": [],
                "text": "Tagging and Chunking with Bigrams"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An integrated system for tagging and chunking texts from a certain language based on stochastic finite-state models that are learnt automatically, which is a very flexible and portable system."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390051006"
                        ],
                        "name": "I. Langkilde-Geary",
                        "slug": "I.-Langkilde-Geary",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Langkilde-Geary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Langkilde-Geary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14174813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "093b25b0ce5aaa65c9b7a5ddd1b2fcb8788ffc36",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine the practical s~'nergy between symbolic and statistical language processing in a generator called Nitrogen. The analysis provides insight into the kinds of linguistic decisions that bigram frequency statistics can make, and how it improves scalability.. We also discuss the limits of bigram statistical knowledge. We focus on specific examples of Nitrogen's output. 1 I n t r o d u c t i o n Langkilde and Knight (1998) introduced Nitrogen, a system that implements a new style of generation in which corpus-based ngram statistics are used in place of deep, extensive symbolic knowledge to provide Very large-scale generation (lexicons and knowledge bases on the order of 200,000 entities), and simultaneously simplify the input and improve robustness for sentence generation. Nitrogen's generation occurs in two stages, as shown in Figure 1. First the input is mapped tO a word lattice, a compact representation of multiple generation possibilities. Then, a statistical extractor selects the most fluent path through the lattice. The word lattice encodes alternative English expressions for the input when the symbolic knowledge is unavailable (whether from the input, or from the knowledge bases) for making realization decisions. The Nitrogen statistical extractor ranks these alternative s using bigram (adjacent word pairs) and unigram (single word) statistics Collected from two years of the Wall Street Journal. The extraction algorithm is presented in (Knight and Hatzivassiloglou, 1995). meaning symbolic generator \u2022 [ <--lexicon ~-gralnmar $ word lattice of possible renderings I statistical extractor [ 4 English string I--corpus Figure h Combining Symbolic and Statistical Knowledge in a Natural Language Generator (Knight and Hatzivassil0glou, 1995). In essence, Nitrogen uses ngram statistics to robustly make a wide variety of decisions, from tense to word choice\u2022 to syntactic subcategorization, that traditionally are handled either with defaults (e.g., assume present tense, use the alphabetically-first synonyms, use nominal arguments), explicit input specification, or by using deep, detailed knowledge bases. However, in scaling up a generator system, these methods become unsatisfactory. Defaults are too rigid and limit quality; detailed input specs are difficult or complex to construct, or m~' be unavailable; and"
            },
            "slug": "The-Practical-Value-of-N-Grams-Is-in-Generation-Langkilde-Geary-Knight",
            "title": {
                "fragments": [],
                "text": "The Practical Value of N-Grams Is in Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The practical s~'nergy between symbolic and statistical language processing in a generator called Nitrogen is examined, providing insight into the kinds of linguistic decisions that bigram frequency statistics can make, and how it improves scalability."
            },
            "venue": {
                "fragments": [],
                "text": "INLG"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486732"
                        ],
                        "name": "S. Miike",
                        "slug": "S.-Miike",
                        "structuredName": {
                            "firstName": "Seiji",
                            "lastName": "Miike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miike"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49467940"
                        ],
                        "name": "E. Itoh",
                        "slug": "E.-Itoh",
                        "structuredName": {
                            "firstName": "Etsuo",
                            "lastName": "Itoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Itoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072866665"
                        ],
                        "name": "Kenji Ono",
                        "slug": "Kenji-Ono",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Ono",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Ono"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145111101"
                        ],
                        "name": "Kazuo Sumita",
                        "slug": "Kazuo-Sumita",
                        "structuredName": {
                            "firstName": "Kazuo",
                            "lastName": "Sumita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuo Sumita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14130036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c413e7150a4eae1d720000817c29b439b9a9eca0",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a Japanese full-text retrieval system named BREVIDOC* that enables the user to specify an area within a text for abstraction and to control the volume of the abstract interactively. This system analyzes a document structure using linguistic knowledge only and thus is domain-independent. In its text structure analysis, the system determines relations among paragraphs and sentences, based on linguistic clues such as connectives, anaphoric expressions, and idiomatic expressions. The system analyzes and stores the text structure in advance so that it can generate an abstract in real time by selecting sentences according to relative importance of rhetorical relations among the sentences. The retrieval system works on an engineering workstation."
            },
            "slug": "A-full-text-retrieval-system-with-a-dynamic-Miike-Itoh",
            "title": {
                "fragments": [],
                "text": "A full-text retrieval system with a dynamic abstract generation function"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A Japanese full-text retrieval system named BREVIDOC* that enables the user to specify an area within a text for abstraction and to control the volume of the abstract interactively and is domain-independent."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61528973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be4b285117d2c41c3570eeb14d9e070805a6a3d7",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The translation of a text can be viewed as a detailed annotation of the text's meaning. From this point of view, texts that exist in two languages (bitexts) are the richest accessible source of linguistic knowledge. Such knowledge can be exploited in many ways, if it can be automatically acquired. The acquisition process is invariably based on automatic methods for inducing translational equivalence relations between the two halves of a bitext. At the word token level, these relations are called bitext maps; at the word type level, they are called translation models. This dissertation advances the state of the art in methods for determining both kinds of translational equivalence. It also shows how to integrate these methods to exploit a much wider variety of bitexts than was previously possible. \nThe dissertation begins by showing that the language-specific aspects of the bitext mapping problem can be encapsulated and modularized away, leaving only a problem of geometric pattern recognition. The best solution is then the one that maximizes the signal-to-noise ratio in the search space and employs the fastest and most accurate search algorithm. The dissertation presents new methods for maximizing the signal strength, for filtering noise, and for searching the resulting scatterplot in linear expected space and time. The unprecedented accuracy of this solution enables a new application of bitext maps--automatic detection of omissions in translations. \nThe second half of the dissertation makes a number of advances in statistical translation modeling. First, it proves the feasibility of modeling translational equivalence independently of word order. Second, the dissertation shows why and how translation models can benefit from an explicit noise model. Third, it shows how the noise model can be conditioned on almost any kind of pre-existing language-specific knowledge, and that even simple linguistic clues can significantly improve translation model accuracy. Fourth, the dissertation shows how to automatically determine the sense inventories of words in bitext and how to automatically discover word sequences that are translated as a unit. This information enables translation models that account for polysemy and for phrasal translations."
            },
            "slug": "Empirical-Methods-for-Exploiting-Parallel-Texts-Melamed-Marcus",
            "title": {
                "fragments": [],
                "text": "Empirical Methods for Exploiting Parallel Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This dissertation advances the state of the art in methods for determining both kinds of translational equivalence and shows how to integrate these methods to exploit a much wider variety of bitexts than was previously possible."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175167"
                        ],
                        "name": "J. Robin",
                        "slug": "J.-Robin",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Robin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Robin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19091184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b947f31028c542bbbc75f64773f5e8488977109",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically summarizing vast amounts of on-line quantitative data with a short natural language paragraph has a wide range of real-world applications. However, this specific task raises a number of difficult issues that are quite distinct from the generic task of language generation: conciseness, complex sentences, floating concepts, historical background, paraphrasing power and implicit content. \nIn this thesis, I address these specific issues by proposing a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit. This model requires a new type of linguistic knowledge: revision operations, which specifies the various ways a draft can be transformed in order to concisely accommodate a new piece of information. I present an in-depth corpus analysis of human-written sports summaries that resulted in an extensive set of such revision operations. I also present the implementation, based on functional unification grammars, of the system scSTREAK, which relies on these operations to incrementally generate complex sentences summarizing basketball games. This thesis also contains two quantitative evaluations. The first shows that the new revision-based generation model is far more robust than the one-pass model of previous generators. The second evaluation demonstrates that the revision operations acquired during the corpus analysis and implemented in scSTREAK are, for the most part, portable to at least one other quantitative domain (the stock market). \nscSTREAK is the first report generator that systematically places the facts which it summarizes in their historical perspective. It is more concise than previous systems thanks to its ability to generate more complex sentences and to opportunistically convey facts by adding a few words to carefully chosen draft constituents. The revision operations on which scSTREAK is based constitute the first set of corpus-based linguistic knowledge geared towards incremental generation. The evaluation presented in this thesis is also the first attempt to quantitatively assess the robustness of a new generation model and the portability of a new type of linguistic knowledge."
            },
            "slug": "Revision-based-generation-of-natural-language-and-Robin",
            "title": {
                "fragments": [],
                "text": "Revision-based generation of natural language summaries providing historical background: corpus-based analysis, design, implementation and evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This thesis presents a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390051006"
                        ],
                        "name": "I. Langkilde-Geary",
                        "slug": "I.-Langkilde-Geary",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Langkilde-Geary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Langkilde-Geary"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14381340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c878514565a57b82966640f21d21afdb3c82d2e",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a general-purpose sentence generation system that can achieve both broad scale coverage and high quality while aiming to be suitable for a variety of generation tasks. We measure the coverage and correctness empirically using a section of the Penn Treebank corpus as a test set. We also describe novel features that help make the generator flexible and easier to use for a variety of tasks. To our knowledge, this is the first empirical measurement of coverage reported in the literature, and the highest reported measurements of correctness."
            },
            "slug": "An-Empirical-Verification-of-Coverage-and-for-a-Langkilde-Geary",
            "title": {
                "fragments": [],
                "text": "An Empirical Verification of Coverage and Correctness for a General-Purpose Sentence Generator"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper describes a general-purpose sentence generation system that can achieve both broad scale coverage and high quality while aiming to be suitable for a variety of generation tasks, and reports the first empirical measurement of coverage reported in the literature, and the highest reported measurements of correctness."
            },
            "venue": {
                "fragments": [],
                "text": "INLG"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754680"
                        ],
                        "name": "Michael Elhadad",
                        "slug": "Michael-Elhadad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elhadad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elhadad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175167"
                        ],
                        "name": "J. Robin",
                        "slug": "J.-Robin",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Robin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Robin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 8242013,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "30d314aa866446c2c67d4e4dcdff6786ca6970c0",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard Functional Unification Grammars (FUGs) provide a structurally guided top-down control regime for sentence generation. When using FUGs to perform content realization as a whole, including lexical choice, this regime is no longer appropriate for two reasons: (1) the unification of non-lexicalized semantic input with an integrated lexico-grammar requires mapping \u201cfloating\u201d semantic elements which can trigger extensive backtracking and (2) lexical choice requires accessing external constraint sources on demand to preserve the modularity between conceptual and linguistic knowledge."
            },
            "slug": "Controlling-Content-Realization-with-Functional-Elhadad-Robin",
            "title": {
                "fragments": [],
                "text": "Controlling Content Realization with Functional Unification Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Standard Functional Unification Grammars provide a structurally guided top-down control regime for sentence generation but this regime is no longer appropriate for two reasons: the unification of non-lexicalized semantic input with an integrated lexico-grammar and lexical choice."
            },
            "venue": {
                "fragments": [],
                "text": "NLG"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029108"
                        ],
                        "name": "Yasuhiro Sobashima",
                        "slug": "Yasuhiro-Sobashima",
                        "structuredName": {
                            "firstName": "Yasuhiro",
                            "lastName": "Sobashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasuhiro Sobashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182416"
                        ],
                        "name": "O. Furuse",
                        "slug": "O.-Furuse",
                        "structuredName": {
                            "firstName": "Osamu",
                            "lastName": "Furuse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Furuse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743865"
                        ],
                        "name": "S. Akamine",
                        "slug": "S.-Akamine",
                        "structuredName": {
                            "firstName": "Susumu",
                            "lastName": "Akamine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Akamine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068665321"
                        ],
                        "name": "Jun Kawai",
                        "slug": "Jun-Kawai",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Kawai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Kawai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35555979"
                        ],
                        "name": "H. Iida",
                        "slug": "H.-Iida",
                        "structuredName": {
                            "firstName": "Hitoshi",
                            "lastName": "Iida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Iida"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8849060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75a07faf411500e51dd889b275dec44febac09c9",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a brief overview of the bidirectional (Japanese and English) Transfer-Driven Machine Translation system, currently being developed at ATR. The aim of this development is to achieve bidirectional spoken dialogue translation using a new translation technique, TDMT, in which an example-based framework is fully utilized to translate the whole sentence. Although the translation coverage is presently restricted to conference registration, the system meets requirements for spoken dialogue translation, such as two-way translation, high speed, and high accuracy with robust processing."
            },
            "slug": "A-Bidirectional,-Transfer-Driven-Machine-System-for-Sobashima-Furuse",
            "title": {
                "fragments": [],
                "text": "A Bidirectional, Transfer-Driven Machine Translation System for Spoken Dialogues"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The aim of this development is to achieve bidirectional spoken dialogue translation using a new translation technique, TDMT, in which an example-based framework is fully utilized to translate the whole sentence."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052557609"
                        ],
                        "name": "Bonnie Glover",
                        "slug": "Bonnie-Glover",
                        "structuredName": {
                            "firstName": "Bonnie",
                            "lastName": "Glover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bonnie Glover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7203709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf74e2924e5515be7d77b6c96e9d913ec13d271b",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "It is challenging to translate names and technical terms from English into Arabic. Translation is usually done phonetically: different alphabets and sound inventories force various compromises. For example, Peter Streams may come out as [Abstract contained text which could not be captured.] bytr strymz. This process is called transliteration. We address here the reverse problem: given a foreign name or loanword in Arabic text, we want to recover the original in Roman script. For example, an input like [Abstract contained text which could not be captured.] bytr strymz should yield an output like Peter Streams. Arabic presents special challenges due to unwritten vowels and phonetic-context effects. We present results and examples of use in an Arabic-to-English machine translator."
            },
            "slug": "Translating-Names-and-Technical-Terms-in-Arabic-Glover-Knight",
            "title": {
                "fragments": [],
                "text": "Translating Names and Technical Terms in Arabic Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work addresses the reverse problem: given a foreign name or loanword in Arabic text, the authors want to recover the original in Roman script, and presents results and examples of use in an Arabic-to-English machine translator."
            },
            "venue": {
                "fragments": [],
                "text": "SEMITIC@COLING"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076094546"
                        ],
                        "name": "Steve K. Luk",
                        "slug": "Steve-K.-Luk",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Luk",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve K. Luk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8023366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c27cb8364a7655b2e4e8aa799970a08f90dea61",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge-based machine translation (KBMT) systems have achieved excellent results in constrained domains, but have not yet scaled up to newspaper text. The reason is that knowledge resources (lexicons, grammar rules, world models) must be painstakingly handcrafted from scratch. One of the hypotheses being tested in the PAN-GLOSS machine translation project is whether or not these resources can be semi-automatically acquired on a very large scale. \n \nThis paper focuses on the construction of a large ontology (or knowledge base, or world model) for supporting KBMT. It contains representations for some 70,000 commonly encountered objects, processes, qualities, and relations. The ontology was constructed by merging various online dictionaries, semantic networks, and bilingual resources, through semi-automatic methods. Some of these methods (e.g., conceptual matching of semantic taxonomies) are broadly applicable to problems of importing/exporting knowledge from one KB to another. Other methods (e.g., bilingual matching) allow a knowledge engineer to build up an index to a KB in a second language, such as Spanish or Japanese."
            },
            "slug": "Building-a-Large-Scale-Knowledge-Base-for-Machine-Knight-Luk",
            "title": {
                "fragments": [],
                "text": "Building a Large-Scale Knowledge Base for Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper focuses on the construction of a large ontology (or knowledge base, or world model) for supporting KBMT, which contains representations for some 70,000 commonly encountered objects, processes, qualities, and relations."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143675545"
                        ],
                        "name": "J. Tiedemann",
                        "slug": "J.-Tiedemann",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Tiedemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tiedemann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17449548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a48deea31af98cc1003bc8976c27d5777947909",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "String similarity metrics are used for several purposes in text-processing. One task is the extraction of cognates from bilingual text. In this paper three approaches to the automatic generation of language dependent string matching functions are present"
            },
            "slug": "Automatic-Construction-of-Weighted-String-Measures-Tiedemann",
            "title": {
                "fragments": [],
                "text": "Automatic Construction of Weighted String Similarity Measures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Three approaches to the automatic generation of language dependent string matching functions are presented and it is shown that two of them are good candidates for bilingual text-processing."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323275"
                        ],
                        "name": "Kishore Papineni",
                        "slug": "Kishore-Papineni",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Papineni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kishore Papineni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144582029"
                        ],
                        "name": "T. Ward",
                        "slug": "T.-Ward",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2587983"
                        ],
                        "name": "Wei-Jing Zhu",
                        "slug": "Wei-Jing-Zhu",
                        "structuredName": {
                            "firstName": "Wei-Jing",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Jing Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11080756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7da009f457917aa381619facfa5ffae9329a6e9",
            "isKey": false,
            "numCitedBy": 16632,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations."
            },
            "slug": "Bleu:-a-Method-for-Automatic-Evaluation-of-Machine-Papineni-Roukos",
            "title": {
                "fragments": [],
                "text": "Bleu: a Method for Automatic Evaluation of Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61073455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d0340ed8cca75fb97a25b5e6fda425b807fa287",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 319,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis is an inquiry into the nature of the high-level, rhetorical structure of unrestricted natural language texts, computational means to enable its derivation, and two applications (in automatic summarization and natural language generation) that follow from the ability to build such structures automatically. \nThe thesis proposes a first-order formalization of the high-level, rhetorical structure of text. The formalization assumes that text can be sequenced into elementary units; that discourse relations hold between textual units of various sizes; that some textual units are more important to the writer's purpose than others; and that trees are a good approximation of the abstract structure of text. The formalization also introduces a linguistically motivated compositionality criterion, which is shown to hold for the text structures that are valid. \nThe thesis proposes, analyzes theoretically, and compares empirically four algorithms for determining the valid text structures of a sequence of units among which some rhetorical relations hold. Two algorithms apply model-theoretic techniques; the other two apply proof-theoretic techniques. \nThe formalization and the algorithms mentioned so far correspond to the theoretical facet of the thesis. An exploratory corpus analysis of cue phrases provides the means for applying the formalization to unrestricted natural language texts. A set of empirically motivated algorithms were designed in order to determine the elementary textual units of a text, to hypothesize rhetorical relations that hold among these units, and eventually, to derive the discourse structure of that text. The process that finds the discourse structure of unrestricted natural language texts is called rhetorical parsing. \nThe thesis explores two possible applications of the text theory that it proposes. The first application concerns a discourse-based summarization system, which is shown to significantly outperform both a baseline algorithm and a commercial system. An empirical psycholinguistic experiment not only provides an objective evaluation of the summarization system, but also confirms the adequacy of using the text theory proposed here in order to determine the most important units in a text. The second application concerns a set of text planning algorithms that can be used by natural language generation systems in order to construct text plans in the cases in which the high-level communicative goal is to map an entire knowledge pool into text."
            },
            "slug": "The-rhetorical-parsing,-summarization,-and-of-texts-Hirst-Marcu",
            "title": {
                "fragments": [],
                "text": "The rhetorical parsing, summarization, and generation of natural language texts"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This thesis is an inquiry into the nature of the high-level, rhetorical structure of unrestricted natural language texts, computational means to enable its derivation, and two applications (in automatic summarization and natural language generation) that follow from the ability to build such structures automatically."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754680"
                        ],
                        "name": "Michael Elhadad",
                        "slug": "Michael-Elhadad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elhadad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elhadad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 209072635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbf9adc8bdc2396e03c40bf9e8e0edca61836294",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This document is the user manual for FUF version 5.2, a natural language generator program that uses the technique of unification grammars. The program is composed of two main modules: a unifier and a linearizer. The unifier takes as input a semantic description of the text to be generated and a unification grammar, and produces as output a rich syntactic description of the text. The linearizer interprets this syntactic description and produces an English sentence. This manual includes a detailed presentation of the technique of unification grammars and a reference manual for the current implementation (FUF 5.2). Version 5.2 includes novel techniques in the unification allowing the specification of types and the expression of complete information. It also allows for procedural unification and supports sophisticated forms of control. Copyright \u00a9 1993 Michael Elhadad"
            },
            "slug": "FUF:-the-Universal-Unifier-User-Manual-Version-5.2-Elhadad",
            "title": {
                "fragments": [],
                "text": "FUF: the Universal Unifier User Manual Version 5.2"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This document is the user manual for FUF version 5.2, a natural language generator program that uses the technique of unification grammars, and includes novel techniques in the unification allowing the specification of types and the expression of complete information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754680"
                        ],
                        "name": "Michael Elhadad",
                        "slug": "Michael-Elhadad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elhadad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elhadad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175167"
                        ],
                        "name": "J. Robin",
                        "slug": "J.-Robin",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Robin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Robin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14860823,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5164fe539be0125609766582433d73a9d34a9efd",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 127,
            "paperAbstract": {
                "fragments": [],
                "text": "Lexical choice is a computationally complex task, requiring a generation system to consider a potentially large number of mappings between concepts and words. Constraints that aid in determining which word is best come from a wide variety of sources, including syntax, semantics, pragmatics, the lexicon, and the underlying domain. Furthermore, in some situations, different constraints come into play early on, while in others, they apply much later. This makes it difficult to determine a systematic ordering in which to apply constraints. In this paper, we present a general approach to lexical choice that can handle multiple, interacting constraints. We focus on the problem of floating constraints, semantic or pragmatic constraints that float, appearing at a variety of different syntactic ranks, often merged with other semantic constraints. This means that multiple content units can be realized by a single surface element, and conversely, that a single content unit can be realized by a variety of surface elements. Our approach uses the Functional Unification Formalism (FUF) to represent a generation lexicon, allowing for declarative and compositional representation of individual constraints."
            },
            "slug": "Floating-Constraints-in-Lexical-Choice-Elhadad-McKeown",
            "title": {
                "fragments": [],
                "text": "Floating Constraints in Lexical Choice"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a general approach to lexical choice that can handle multiple, interacting constraints, and focuses on the problem of floating constraints, semantic or pragmatic constraints that float, appearing at a variety of different syntactic ranks, often merged with other semantic constraints."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145421878"
                        ],
                        "name": "R. Sproat",
                        "slug": "R.-Sproat",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sproat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sproat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3265939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "110fd6d66c7380556b377ada84cfb5cd0b6bbaa0",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on a method for compiling decision trees into weighted finite-state transducers. The key assumptions are that the tree predictions specify how to rewrite symbols from an input string, and the decision at each tree node is stateable in terms of regular expressions on the input string. Each leaf node can then be treated as a separate rule where the left and right contexts are constructable from the decisions made traversing the tree from the root to the leaf. These rules are compiled into transducers using the weighted rewite-rule rule-compilation algorithm described in (Mohri and Sproat, 1996)."
            },
            "slug": "Compilation-of-Weighted-Finite-State-Transducers-Sproat-Riley",
            "title": {
                "fragments": [],
                "text": "Compilation of Weighted Finite-State Transducers from Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A method for compiling decision trees into weighted finite-state transducers using the weighted rewite-rule rule-compilation algorithm described in (Mohri and Sproat, 1996)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7752112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "824124343b305f1423e354f3a1cb66856b2efb6d",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that a process similar to Earley's algorithm can be generated by a simple top-down backtracking parser, when augmented by automatic memoization. The memoized parser has the same complexity as Earley's algorithm, but parses constituents in a different order. Techniques for deriving memo functions are described, with a complete implementation in Common Lisp, and an outline of a macro-based approach for other languages. 1. Memoization The term memoization was coined by Donald Michie (1968) to refer to the process by which a function is made to automatically remember the results of previous computations. The idea has become more popular in recent years with the rise of functional languages; Field and Harrison (1988) devote a whole chapter to it. The basic idea is just to keep a table of previously computed input/result pairs. In Common Lisp one could write: 1"
            },
            "slug": "Techniques-for-Automatic-Memoization-with-to-Norvig",
            "title": {
                "fragments": [],
                "text": "Techniques for Automatic Memoization with Applications to Context-Free Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that a process similar to Earley's algorithm can be generated by a simple top-down backtracking parser, when augmented by automatic memoization."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42fd4d469c53e4eedd7eb76e7859e3270367f795",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how to induce an N-best translation lexicon from a bilingual text corpus using statistical properties of the corpus together with four external knowledge sources. The knowledge sources are cast as filters, so that any subset of them can be cascaded in a uniform framework. A new objective evaluation measure is used to compare the quality of lexicons induced with different filter cascades. The best filter cascades improve lexicon quality by up to 137% over the plain vanilla statistical method, and approach human performance. Drastically reducing the size of the training corpus has a much smaller impact on lexicon quality when these knowledge sources are used. This makes it practical to train on small hand-built corpora for language pairs where large bilingual corpora are unavailable. Moreover, three of the four filters prove useful even when used with large training corpora."
            },
            "slug": "Automatic-Evaluation-and-Uniform-Filter-Cascades-Melamed",
            "title": {
                "fragments": [],
                "text": "Automatic Evaluation and Uniform Filter Cascades for Inducing N-Best Translation Lexicons"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper shows how to induce an N-best translation lexicon from a bilingual text corpus using statistical properties of the corpus together with four external knowledge sources, which improve lexicon quality by up to 137% over the plain vanilla statistical method, and approach human performance."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784037"
                        ],
                        "name": "T. Brants",
                        "slug": "T.-Brants",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Brants",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brants"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1452591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d560a8d279075a529e9cadb0d664b27957aac5a2",
            "isKey": false,
            "numCitedBy": 1905,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Trigrams'n'Tags (TnT) is an efficient statistical part-of-speech tagger. Contrary to claims found elsewhere in the literature, we argue that a tagger based on Markov models performs at least as well as other current approaches, including the Maximum Entropy framework. A recent comparison has even shown that TnT performs significantly better for the tested corpora. We describe the basic model of TnT, the techniques used for smoothing and for handling unknown words. Furthermore, we present evaluations on two corpora."
            },
            "slug": "TnT-A-Statistical-Part-of-Speech-Tagger-Brants",
            "title": {
                "fragments": [],
                "text": "TnT - A Statistical Part-of-Speech Tagger"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "Contrary to claims found elsewhere in the literature, it is argued that a tagger based on Markov models performs at least as well as other current approaches, including the Maximum Entropy framework."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35551590"
                        ],
                        "name": "Steven P. Abney",
                        "slug": "Steven-P.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven P. Abney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9716882,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "56d7826f3afaa374077f87ca3529709b1ca7e044",
            "isKey": false,
            "numCitedBy": 992,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "I begin with an intuition: when I read a sentence, I read it a chunk at a time. For example, the previous sentence breaks up something like this: \n \n(1) \n \n[I begin] [with an intuition]: [when I read] [a sentence], [I read it] [a chunk] [at a time] \n \n \n \n \n \n \nThese chunks correspond in some way to prosodic patterns. It appears, for instance, that the strongest stresses in the sentence fall one to a chunk, and pauses are most likely to fall between chunks. Chunks also represent a grammatical watershed of sorts. The typical chunk consists of a single content word surrounded by a constellation of function words, matching a fixed template. A simple context-free grammar is quite adequate to describe the structure of chunks. By contrast, the relationships between chunks are mediated more by lexical selection than by rigid templates. Co-occurrence of chunks is determined not just by their syntactic categories, but is sensitive to the precise words that head them; and the order in which chunks occur is much more flexible than the order of words within chunks."
            },
            "slug": "Parsing-By-Chunks-Abney",
            "title": {
                "fragments": [],
                "text": "Parsing By Chunks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The typical chunk consists of a single content word surrounded by a constellation of function words, matching a fixed template, and the relationships between chunks are mediated more by lexical selection than by rigid templates."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366409"
                        ],
                        "name": "F. Ren",
                        "slug": "F.-Ren",
                        "structuredName": {
                            "firstName": "Fuji",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2618596"
                        ],
                        "name": "H. Shi",
                        "slug": "H.-Shi",
                        "structuredName": {
                            "firstName": "Hongchi",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29561240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e5851d47f51891585fd81c226c5d67646fe0c0c",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallel machine translation (PMT) is a new machine translation paradigm that takes advantage of high-speed and large-memory computers and existing machine translation systems with different characteristics to solve the difficult machine translation problem. PMT is based on technologies of parallel computing, machine translation, and artificial intelligence. A PMT system consists of many machine translation procedures running in parallel, coordinated by a controller to dissolve various ambiguities in machine translation. We have designed and implemented a PMT system based on the above approach at a coarse parallel level. The system consists of four independent machine translation subsystems. Each subsystem is implemented using an existing machine translation technique and has its own characteristics. We present the principles and practice of PMT. We also present some results of experiments with our experimental PMT system and point out some future research on PMT."
            },
            "slug": "Parallel-machine-translation:-principles-and-Ren-Shi",
            "title": {
                "fragments": [],
                "text": "Parallel machine translation: principles and practice"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A PMT system that takes advantage of high-speed and large-memory computers and existing machine translation systems with different characteristics to solve the difficult machine translation problem is designed and implemented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Seventh IEEE International Conference on Engineering of Complex Computer Systems"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403907739"
                        ],
                        "name": "Y. Al-Onaizan",
                        "slug": "Y.-Al-Onaizan",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Al-Onaizan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Al-Onaizan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 62521945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ad2eee0a8e7d3c4a99603f00a2226abfe723263",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Named entity phrases are being introduced in news stories on a daily basis in the form of personal names, organizations, locations, temporal phrases, and monetary expressions. While the identification of named entities in text has received significant attention (e.g., [2] and [1]), translation of all named entities has not. This translation problem is especially challenging because new phrases can appear out of nowhere, and because many are domain specific, not to be found in bilingual dictionaries."
            },
            "slug": "Named-entity-translation:-extended-abstract-Al-Onaizan-Knight",
            "title": {
                "fragments": [],
                "text": "Named entity translation: extended abstract"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12106333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bb0b659a8241dcaa2b00d73a7a763bc488b72da",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose and evaluate computational techniques for deciphering unknown scripts. We focus on the case in which an unfamiliar script encodes a known language. The decipherment of a brief document or inscription is driven by data about the spoken language. We consider which scripts are easy or hard to decipher, how much data is required, and whether the techniques are robust against language change over time."
            },
            "slug": "A-Computational-Approach-to-Deciphering-Unknown-Knight-Yamada",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Deciphering Unknown Scripts"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work proposes and evaluates computational techniques for deciphering unknown scripts and considers which scripts are easy or hard to decipher, how much data is required, and whether the techniques are robust against language change over time."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741927"
                        ],
                        "name": "M. Covington",
                        "slug": "M.-Covington",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Covington",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Covington"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7641265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75c7dd1b26dc870150e072e2e7f1549003818b70",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The first step in applying the comparative method to a pair of words suspected of being cognate is to align the segments of each word that appear to correspond. Finding the right alignment may require searching. For example, Latin do 'I give' lines up with the middle do in Greek didomi, not the initial di.This paper presents an algorithm for finding probably correct alignments on the basis of phonetic similarity. The algorithm consists of an evaluation metric and a guided search procedure. The search algorithm can be extended to implement special handling of metathesis, assimilation, or other phenomena that require looking ahead in the string, and can return any number of alignments that meet some criterion of goodness, not just the one best. It can serve as a front end to computer implementations of the comparative method."
            },
            "slug": "An-Algorithm-to-Align-Words-for-Historical-Covington",
            "title": {
                "fragments": [],
                "text": "An Algorithm to Align Words for Historical Comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm for finding probably correct alignments on the basis of phonetic similarity, consisting of an evaluation metric and a guided search procedure, that can be extended to implement special handling of metathesis, assimilation, or other phenomena that require looking ahead in the string."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683412"
                        ],
                        "name": "Pascale Fung",
                        "slug": "Pascale-Fung",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "Fung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascale Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2936351"
                        ],
                        "name": "Y. Lo",
                        "slug": "Y.-Lo",
                        "structuredName": {
                            "firstName": "Yuen",
                            "lastName": "Lo",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2357627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd7edbb79b02e333145f645f897e55b9d387c29c",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, there is a phenomenal growth in the amount of online text material available from the greatest information repository known as the World Wide Web. Various traditional information retrieval(IR) techniques combined with natural language processing(NLP) techniques have been re-targeted to enable efficient access of the WWW--search engines, indexing, relevance feedback, query term and keyword weighting, document analysis, document classification, etc. Most of these techniques aim at efficient online search for information already on the Web. Meanwhile, the corpus linguistic community regards the WWW as a vast potential of corpus resources. It is now possible to download a large amount of texts with automatic tools when one needs to compute, for example, a list of synonyms; or download domain-specific monolingual texts by specifying a keyword to the search engine, and then use this text to extract domain-specific terms. It remains to be seen how we can also make use of the multilingual texts as NLP resources. In the years since the appearance of the first papers on using statistical models for bilingual lexicon compilation and machine translation(Brown et al., 1993; Brown et al., 1991; Gale and Church, 1993; Church, 1993; Simard et al., 1992), large amount of human effort and time has been invested in collecting parallel corpora of translated texts. Our goal is to alleviate this effort and enlarge the scope of corpus resources by looking into monolingual, comparable texts. This type of texts are known as nonparallel corpora. Such nonparallel, monolingual texts should be much more prevalent than parallel texts. However, previous attempts at using nonparallel corpora for terminology translation were constrained by the inadequate availability of same-domain, comparable texts in electronic form. The type of nonparallel texts obtained from the LDC or university libraries were often restricted, and were usually out-of-date as soon as they became available. For new word translation, the timeliness of corpus resources is a prerequisite, so is the continuous and automatic availability of nonparallel, comparable texts in electronic form. Data collection effort should not inhibit the actual translation effort. Fortunately, nowadays tile World Wide Web provides us with a daily increase of fresh, up-to-date multilingual material, together with the archived versions, all easily downloadable by software tools running in the background. It is possible to specify the URL of the online site of a newspaper, and the start and end dates, and automatically download all the daily newspaper materials between those dates. In this paper, we describe a new method which combines IR and NLP techniques to extract new word translation from automatically downloaded English-Chinese nonparallel newspaper texts."
            },
            "slug": "An-IR-Approach-for-Translating-New-Words-from-Texts-Fung-Lo",
            "title": {
                "fragments": [],
                "text": "An IR Approach for Translating New Words from Nonparallel, Comparable Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new method which combines IR and NLP techniques to extract new word translation from automatically downloaded English-Chinese nonparallel newspaper texts is described."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782178"
                        ],
                        "name": "S. Buchholz",
                        "slug": "S.-Buchholz",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "Buchholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Buchholz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8940645,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9e85832b04cc3700c2c26d6ba93fdeae39cac04a",
            "isKey": false,
            "numCitedBy": 872,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the CoNLL-2000 shared task: dividing text into syntactically related non-overlapping groups of words, so-called text chunking. We give background information on the data sets, present a general overview of the systems that have taken part in the shared task and briefly discuss their performance."
            },
            "slug": "Introduction-to-the-CoNLL-2000-Shared-Task-Chunking-Sang-Buchholz",
            "title": {
                "fragments": [],
                "text": "Introduction to the CoNLL-2000 Shared Task Chunking"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The CoNLL-2000 shared task: dividing text into syntactically related non-overlapping groups of words, so-called text chunking is described."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL/LLL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1487550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944cba683d10d8c1a902e05cd68e32a9f47b372e",
            "isKey": false,
            "numCitedBy": 2536,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints---that words tend to have one sense per discourse and one sense per collocation---exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%."
            },
            "slug": "Unsupervised-Word-Sense-Disambiguation-Rivaling-Yarowsky",
            "title": {
                "fragments": [],
                "text": "Unsupervised Word Sense Disambiguation Rivaling Supervised Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78659204"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10173315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa78148fd79b10962a15c5aa7ec95c573250c3f6",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an efficient algorithm for solving the n-best-strings problem in a weighted automaton. This problem arises commonly in speech recognition applications when a ranked list of unique recognizer hypotheses is desired. We believe this is the first n-best algorithm to remove redundant hypotheses before rather than after the n-best determination. We give a detailed description of the algorithm and demonstrate its correctness. We report experimental results showing its efficiency and practicality even for large n in a 40; 000-word vocabulary North American Business News (NAB) task. In particular, we show that 1000-best generation in this task requires negligible added time over recognizer lattice generation."
            },
            "slug": "An-efficient-algorithm-for-the-n-best-strings-Mohri-Riley",
            "title": {
                "fragments": [],
                "text": "An efficient algorithm for the n-best-strings problem"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This is the first n-best algorithm to remove redundant hypotheses before rather than after the n- best determination, and it is shown that 1000-best generation in this task requires negligible added time over recognizer lattice generation."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35551590"
                        ],
                        "name": "Steven P. Abney",
                        "slug": "Steven-P.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven P. Abney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5361885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61dffff2116f3543e71d536a18308fa4fc5e53c3",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic analogues of regular and context-free grammars are well known in computational linguistics, and currently the subject of intensive research. To date, however, no satisfactory probabilistic analogue of attribute-value grammars has been proposed: previous attempts have failed to define an adequate parameter-estimation algorithm.In the present paper, I define stochastic attribute-value grammars and give an algorithm for computing the maximum-likelihood estimate of their parameters. The estimation algorithm is adapted from Della Pietra, Della Pietra, and Lafferty (1995). To estimate model parameters, it is necessary to compute the expectations of certain functions under random fields. In the application discussed by Della Pietra, Della Pietra, and Lafferty (representing English orthographic constraints), Gibbs sampling can be used to estimate the needed expectations. The fact that attribute-value grammars generate constrained languages makes Gibbs sampling inapplicable, but I show that sampling can be done using the more general Metropolis-Hastings algorithm."
            },
            "slug": "Stochastic-Attribute-Value-Grammars-Abney",
            "title": {
                "fragments": [],
                "text": "Stochastic Attribute-Value Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Stochastic attribute-value grammars are defined and an algorithm for computing the maximum-likelihood estimate of their parameters is given and it is shown that sampling can be done using the more general Metropolis-Hastings algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784914"
                        ],
                        "name": "A. Lavie",
                        "slug": "A.-Lavie",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Lavie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lavie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686960"
                        ],
                        "name": "Lori S. Levin",
                        "slug": "Lori-S.-Levin",
                        "structuredName": {
                            "firstName": "Lori",
                            "lastName": "Levin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lori S. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2260563"
                        ],
                        "name": "Robert E. Frederking",
                        "slug": "Robert-E.-Frederking",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Frederking",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert E. Frederking"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760810"
                        ],
                        "name": "F. Pianesi",
                        "slug": "F.-Pianesi",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Pianesi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pianesi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4269349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2240a2c743e6560d54f20ca4434e9017e10a2617",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "NESPOLE! is a speech-to-speech machine translation research system designed to provide fully functional speech-to-speech capabilities within real-world settings of common users involved in e-commerce applications. The project is funded jointly by the European Commission and the US NSF. The NESPOLE! system uses a client-server architecture to allow a common user, who is browsing web-pages on the internet, to connect seamlessly in real-time to an agent of the service provider, using a video-conferencing channel and with speech-to-speech translation services mediating the conversation. Shared web pages and annotated images supported via a Whiteboard application are available to enhance the communication."
            },
            "slug": "The-NESPOLE!-speech-to-speech-translation-system-Lavie-Levin",
            "title": {
                "fragments": [],
                "text": "The NESPOLE! speech-to-speech translation system"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The NESPOLE! system uses a client-server architecture to allow a common user, who is browsing web-pages on the internet, to connect seamlessly in real-time to an agent of the service provider, using a video-conferencing channel and with speech-to-speech translation services mediating the conversation."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8754851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cd9fd8a36c8feb74bb20ae25817edb9c6a0518c",
            "isKey": false,
            "numCitedBy": 1401,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words."
            },
            "slug": "Automatic-Word-Sense-Discrimination-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Automatic Word Sense Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering that demonstrates good performance of context- group discrimination for a sample of natural and artificial ambiguous words."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 431099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2b5cb0285d593dde7c5a1b844ab0361aebfc85d",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context. The algorithms tested include statistical, neural-network, decision-tree, rule-based, and case-based classification techniques. The specific problem tested involves disambiguating six senses of the word ``line'' using the words in the current and proceeding sentence as context. The statistical and neural-network methods perform the best on this particular problem and we discuss a potential reason for this observed difference. We also discuss the role of bias in machine learning and its importance in explaining performance differences observed on specific problems."
            },
            "slug": "Comparative-Experiments-on-Disambiguating-Word-An-Mooney",
            "title": {
                "fragments": [],
                "text": "Comparative Experiments on Disambiguating Word Senses: An Illustration of the Role of Bias in Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context finds the statistical and neural-network methods perform the best on this particular problem."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776817"
                        ],
                        "name": "R. Grossi",
                        "slug": "R.-Grossi",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Grossi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grossi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688493"
                        ],
                        "name": "G. Italiano",
                        "slug": "G.-Italiano",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Italiano",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Italiano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17259717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "408b8ddd4340ff59aa802549c0c7b7c24927b350",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "The suffix tree is a compacted trie that stores all suffixes of a given text string. This data structure has been intensively employed in pattern matching on strings and trees, with a wide range of applications, such as molecular biology, data processing, text editing, term rewriting, interpreter design, information retrieval, abstract data types and many others. In this paper, we survey some applications of suffix trees and some algorithmic techniques for their construction. Special emphasis is given to the most recent developments in this area, such as parallel algorithms for suffix tree construction and generalizations of suffix trees to higher dimensions, which are important in multidimensional pattern matching. Work partially supported by the ESPRIT BRA ALCOM II under contract no. 7141 and by the Italian MURST Project \u201cAlgoritmi, Modelli di Calcolo e Strutture Informative\u201d. Part of this work was done while the author was visiting AT&T Bell Laboratories. Email: grossi@di.unipi.it Work supported in part by the Commission of the European Communities under ESPRIT LTR Project no. 20244 (ALCOM\u2013IT), by the Italian MURST Project \u201cEfficienza di Algoritmi e Progetto di Strutture Informative\u201d, and by a Research Grant from University of Venice \u201cCa\u2019 Foscari\u201d. Part of this work was done while at University of Salerno. Email: italiano@dsi.unive.it. URL: http://www.dsi.unive.it/\u223citaliano."
            },
            "slug": "Suffix-trees-and-their-applications-in-string-Grossi-Italiano",
            "title": {
                "fragments": [],
                "text": "Suffix trees and their applications in string algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Special emphasis is given to the most recent developments in this area, such as parallel algorithms for suffix tree construction and generalizations of suffix trees to higher dimensions, which are important in multidimensional pattern matching."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736723"
                        ],
                        "name": "Ishwar Chander",
                        "slug": "Ishwar-Chander",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Chander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ishwar Chander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6440613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a875de22ce33def6e0146be64e19491ef1a9861d",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Large amounts of low- to medium-quality English texts are now being produced by machine translation (MT) systems, optical character readers (OCR), and non-native speakers of English. Most of this text must be postedited by hand before it sees the light of day. Improving text quality is tedious work, but its automation has not received much research attention. \n \nAnyone who has postedited a technical report or thesis written by a non-native speaker of English knows the potential of an automated postediting system. For the case of MT-generated text, we argue for the construction of postediting modules that are portable across MT systems, as an alternative to hardcoding improvements inside any one system. As an example, we have built a complete self-contained postediting module for the task of article selection (a, an, the) for English noun phrases. This is a notoriously difficult problem for Japanese-English MT. Our system contains over 200,000 rules derived automatically from online text resources. We report on learning algorithms, accuracy, and comparisons with human performance."
            },
            "slug": "Automated-Postediting-of-Documents-Knight-Chander",
            "title": {
                "fragments": [],
                "text": "Automated Postediting of Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work argues for the construction of postediting modules that are portable across MT systems, as an alternative to hardcoding improvements inside any one system, and builds a complete self-contained postediting module for the task of article selection (a, an, the) for English noun phrases."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882422"
                        ],
                        "name": "Nancy Ide",
                        "slug": "Nancy-Ide",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Ide",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy Ide"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091214"
                        ],
                        "name": "J. V\u00e9ronis",
                        "slug": "J.-V\u00e9ronis",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "V\u00e9ronis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V\u00e9ronis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6478930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5c4aa82e5a35a8ecafb242fad400237dca0f686",
            "isKey": false,
            "numCitedBy": 1111,
            "numCiting": 560,
            "paperAbstract": {
                "fragments": [],
                "text": "ANIMATE, HUMAN, etc. and encode type restrictions on nouns and adjectives and on the arguments of verbs. Subject codes use another set of primitives to classify senses of words by subject (ECONOMICS, ENGINEERING, etc.). Guthrie et al. (1991) demonstrate a typical use of this information: in addition to using the Lesk-based method of counting overlaps between definitions and contexts, they impose a correspondence of subject codes in an iterative process. No quantitative evaluation of this method is available, but Cowie et al. (1992) improve the method using simulated annealing and report results of 47% for sense distinctions and 72% for homographs. The use of LDOCE box codes, however, is problematic: the codes are not systematic (see, for example, Fontenelle, 1990); in later work, Braden-Harder (1993) showed that simply matching box or subject codes is not sufficient for disambiguation. For example, in I tipped the driver, the codes for several senses of the words in the sentence satisfy the necessary constraints (e.g. tip-money + human object or tip-tilt + movable solid object). In many ways, the supplemen7 Note that the assumptions underlying this method are very similar to Quillian\u2019s: Thus one may think of a full concept analogically as consisting of all the information one would have if he looked up what will be called the \u201cpatriarch\u201d word in a dictionary, then looked up every word in each of its definitions, then looked up every word found in each of these, and so on, continually branching outward[...] (Quillian, 1968, p. 238). However, Quillian\u2019s network also keeps track of semantic relationships among the words encountered along the path between two words, which are encoded in his semantic network; the neural network avoids the overhead of creating the semantic network but loses this relational information. 13 tary information in the LDOCE, and in particular the subject codes, are similar to those in a thesaurus, which, however, are more systematically structured. Inconsistencies in dictionaries, noted earlier, are not the only and perhaps not the major source of their limitations for WSD. While dictionaries provide detailed information at the lexical level, they lack pragmatic information that enters into sense determination (see, e.g., Hobbs, 1987). For example, the link between ash and tobacco, cigarette or tray in a network such as Quillian\u2019s is very indirect, whereas in the Brown Corpus, the word ash co-occurs frequently with one of these words. It is therefore not surprising that corpora have become a primary source of information for WSD; this development is outlined below in section 2.3. 2.3.2 Thesauri. Thesauri provide information about relationships among words, most notably synonymy. Roget's International Thesaurus, which was put into machine-tractable form in the 1950's8 and has been used in a variety of applications including machine translation (Masterman, 1957), information retrieval (Sparck Jones, 1964, 1986), and content analysis (Sedelow and Sedelow, 1969; see also Sedelow and Sedelow, 1986, 1992), also supplies an explicit concept hierarchy consisting of up to eight increasingly refined levels. Typically, each occurrence of the same word under different categories of the thesaurus represent different senses of that word; i.e., the categories correspond roughly to word senses (Yarowsky, 1992). A set of words in the same category are semantically related. The earliest known use of Roget\u2019s for WSD is the work of Masterman (1957), described above in section 2.1. Several years later, Patrick (1985) used Roget\u2019s to discriminate among verb senses, by examining semantic clusters formed by \u201ce-chains\u201d derived from the thesaurus (Bryan, 1973, 1974; see also Sedelow and Sedelow, 1986). He uses \u201cword-strong neighborhoods,\u201d comprising word groups in low-level semicolon groups, which are the most closely related semantically in the thesaurus, and words connected to the group via chains. He is able to discriminate the correct sense of verbs such as inspire (to raise the spirits vs. to inhale, breathe in, sniff, etc.), question (to doubt vs. to ask a question) with \u201chigh reliability.\u201d Bryan's earlier work had already demonstrated that homographs can be distinguished by applying a metric based on relationships defined by his chains (Bryan, 1973, 1974). Similar work is described in Sedelow and Mooney (1988). Yarowsky (1992) derives classes of words by starting with words in common categories in Roget's (4th ed.). A 100-word context of each word in the category is extracted from a corpus (the 1991 electronic text of Grolier's Encyclopedia), and a mutual-information-like statistic is used to identify words most likely to co-occur with the category 8 The work of Masterman (1957) and Sparck Jones (1964) relied on a version of Roget\u2019s that was hand-punched onto cards in the 1950\u2019s; the Sedelow\u2019s (1969) work relied on a machine readable version of the 3rd Edition. Roget\u2019s is now widely available via anonymous ftp from various sites."
            },
            "slug": "Introduction-to-the-Special-Issue-on-Word-Sense-The-Ide-V\u00e9ronis",
            "title": {
                "fragments": [],
                "text": "Introduction to the Special Issue on Word Sense Disambiguation: The State of the Art"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Corva provide information about relationships among words, most notably synonymy, and have become a primary source of information for WSD; this development is outlined below."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3165062,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "75b2e2ce95a5ff349566025610a0213851dccefb",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "I use the distinction between the nuclei and the satellites that pertain to discourse relations to introduce a compositionality criterion for discourse trees. I provide a first-order formalization of rhetorical structure trees and, on its basis, I derive an algorithm that constructs all the valid rhetorical trees that can be associated with a given discourse."
            },
            "slug": "Building-Up-Rhetorical-Structure-Trees-Marcu",
            "title": {
                "fragments": [],
                "text": "Building Up Rhetorical Structure Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The distinction between the nuclei and the satellites that pertain to discourse relations is used to introduce a compositionality criterion for discourse trees and an algorithm is derived that constructs all the valid rhetorical trees that can be associated with a given discourse."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98884239"
                        ],
                        "name": "M. Arbabi",
                        "slug": "M.-Arbabi",
                        "structuredName": {
                            "firstName": "Mansur",
                            "lastName": "Arbabi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Arbabi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2907103"
                        ],
                        "name": "Scott M. Fischthal",
                        "slug": "Scott-M.-Fischthal",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Fischthal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott M. Fischthal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144932014"
                        ],
                        "name": "V. Cheng",
                        "slug": "V.-Cheng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Cheng",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073320070"
                        ],
                        "name": "Elizabeth Bart",
                        "slug": "Elizabeth-Bart",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Bart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Bart"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 885640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54bf6c494795efd680cdbb4ff5cbfb3511921b3c",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "An Arabic name can be written in English with many different spellings. For example, the name Sulayman is written only one way in Arabic. In English, this name is written in as many as forty different ways, such as Salayman, Seleiman, Solomon, Suleiman, and Sylayman. Currently, Arabic linguists manually transliterate these names\u2014a slow, laborious, error-prone, and time-consuming process. We present a hybrid algorithm which automates this process in real time using neural networks and a knowledge-based system to vowelize Arabic. A supervised neural network filters out unreliable names, passing the reliable names on to the knowledge-based system for romanization. This approach, developed at the IBM Federal Systems Company, is applicable to a wide variety of purposes, including visa processing and document processing by border patrols."
            },
            "slug": "Algorithms-for-Arabic-name-transliteration-Arbabi-Fischthal",
            "title": {
                "fragments": [],
                "text": "Algorithms for Arabic name transliteration"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This work presents a hybrid algorithm which automates this process in real time using neural networks and a knowledge-based system to vowelize Arabic, applicable to a wide variety of purposes, including visa processing and document processing by border patrols."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754680"
                        ],
                        "name": "Michael Elhadad",
                        "slug": "Michael-Elhadad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elhadad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elhadad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10256382,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e6c10634f50c1bd4ea2949385c62d9ebe1258319",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 155,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis presents new surface generation techniques that improve on both aspects of surface generation: (1) lexical choice, which consists of choosing words and their associated syntactic structures and (2) syntactic realization, which consists of combining these partial structures into grammatical sentences. The thesis investigates the impact of the pragmatic situation on surface generation. Because surface generation depends directly on many aspects of the situation, these new techniques allow a purely conceptual input to be expressed by a greater variety of linguistic forms and with more sensitivity to pragmatic factors than was previously possible. \nSpecifically, this research focuses on the impact on lexical choice of one part of the pragmatic situation: the speaker's argumentative intent, i.e., the goal of the speaker to convince the hearer of a certain conclusion. The argumentative intent can be realized by a variety of evaluative expressions appearing at various ranks in the syntactic structure. This thesis describes the selection of four classes of evaluative expressions: judgment determiners (i.e., many), scalar adjectives (i.e., difficult), connotative verbs (i.e., require, enjoy) and argumentative connectives (i.e., but, so). These four classes were not addressed in previous generators. \nThe scFUF formalism is introduced in this thesis to address the issue of complex constraint interaction arising when performing lexical choice under pragmatic constraints. scFUF is derived from Functional Unification Grammars (scFUGs), a formalism previously used for syntactic realization only. scFUF extends scFUGs by providing new mechanisms for control, for expressing hierarchical relations and for using modular knowledge sources. These extensions make scFUF capable of handling lexical choice. In addition, this thesis describes the use of scFUF to develop scSURGE, one of the largest and most widely used syntactic realization grammar available. \nFinally these new generation techniques are applied to the implementation of scADVISOR II, a question-answering system helping students to choose classes for a semester. In particular, scADVISOR II uses the increased expressive flexibility provided by these techniques to convince a student to choose different classes by presenting the same objective data, retrieved from an underlying knowledge base, in different linguistic forms using evaluative expressions."
            },
            "slug": "Using-argumentation-to-control-lexical-choice:-a-Elhadad",
            "title": {
                "fragments": [],
                "text": "Using argumentation to control lexical choice: a functional unification implementation"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "New surface generation techniques that improve on both aspects of surface generation are presented, which allow a purely conceptual input to be expressed by a greater variety of linguistic forms and with more sensitivity to pragmatic factors than was previously possible."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758035"
                        ],
                        "name": "Yue-Shi Lee",
                        "slug": "Yue-Shi-Lee",
                        "structuredName": {
                            "firstName": "Yue-Shi",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue-Shi Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62614996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9e2ef85bd9232767578e4bf6f979c679ec86d3f",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Contextual language processing plays an important role for the post-processing of speech recognition. The purpose of the contextual language processing is to find the most plausible candidate for each syllable with the maximum likelihood probability. Generally, the performance of the probabilistic model is affected by two major errors, i.e., modeling error and estimation error in training corpus. In this paper, we focus on the problem of estimation error in training corpus. An adaptive learning algorithm is proposed to decrease the influences of variant run-time context domain. It shows which objects are to be adjusted and how to adjust their probabilities by a neural network model. The resulting techniques are greatly simplified and robust. The experimental results demonstrate the effects of the learning algorithm from generic domain to specific domain. In general, these techniques can be easily extended to various language models and corpus-based applications."
            },
            "slug": "Neural-network-approach-to-adaptive-learning:-with-Lee",
            "title": {
                "fragments": [],
                "text": "Neural network approach to adaptive learning: with an application to Chinese homophone disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An adaptive learning algorithm is proposed to decrease the influences of variant run-time context domain and shows which objects are to be adjusted and how to adjust their probabilities by a neural network model."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725615"
                        ],
                        "name": "K. Nagao",
                        "slug": "K.-Nagao",
                        "structuredName": {
                            "firstName": "Katashi",
                            "lastName": "Nagao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nagao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2788856"
                        ],
                        "name": "Yoshinari Shirai",
                        "slug": "Yoshinari-Shirai",
                        "structuredName": {
                            "firstName": "Yoshinari",
                            "lastName": "Shirai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshinari Shirai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46740217"
                        ],
                        "name": "K. Squire",
                        "slug": "K.-Squire",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Squire",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Squire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18310974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "982774c10d42e38e9d69fdbf65dc18785dc774cb",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method for constructing superstructure on the Web using XML and external annotations to Web documents. We have three approaches for annotating documents: linguistic, commentary, and multimedia. The result is annotated documents that computers can understand and process more easily, allowing content to reach a wider audience with minimal overhead."
            },
            "slug": "Semantic-Annotation-and-Transcoding:-Making-Web-Nagao-Shirai",
            "title": {
                "fragments": [],
                "text": "Semantic Annotation and Transcoding: Making Web Content More Accessible"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A method for constructing superstructure on the Web using XML and external annotations to Web documents to create annotated documents that computers can understand and process more easily, allowing content to reach a wider audience with minimal overhead."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Multim."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058909188"
                        ],
                        "name": "Michael W. Fleming",
                        "slug": "Michael-W.-Fleming",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fleming",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael W. Fleming"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144860558"
                        ],
                        "name": "R. Cohen",
                        "slug": "R.-Cohen",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42020605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93a02e28be0aa21ba1250533b19dbcea42395265",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A mixed-initiative system is one which allows more interactivity between the system and user, as the system is reasoning. We present some observations on the task of translating Web pages for users and suggest that a more interactive approach to this problem may be desirable. The aim is to interact with the user who is requesting the translation and the challenge is to determine the circumstances under which the user should be able to take the initiative to direct the processing or the system should be able to take the initiative to solicit further input from the user. In fact, we envision a need to support interactive translation of Web pages as the World Wide Web becomes more accessible to people with varying needs and abilities throughout the world."
            },
            "slug": "Mixed-initiative-translation-of-Web-pages-Fleming-Cohen",
            "title": {
                "fragments": [],
                "text": "Mixed-initiative translation of Web pages"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A need to support interactive translation of Web pages as the World Wide Web becomes more accessible to people with varying needs and abilities throughout the world is envisioned."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9363872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25f51f4132626a645924b3c8b3edcbdcc35c48a3",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "When humans produce summaries of documents, they do not simply extract sentences and concatenate them. Rather, they create new sentences that are grammatical, that cohere with one another, and that capture the most salient pieces of information in the original document. Given that large collections of text/abstract pairs are available online, it is now possible to envision algorithms that are trained to mimic this process. In this paper, we focus on sentence compression, a simpler version of this larger challenge. We aim to achieve two goals simultaneously:our compressions should be grammatical, and they should retain the most important pieces of information. These two goals can conflict. We devise both noisy-channel and decision-tree approaches to the problem, and we evaluate results against manual compressions and a simple baseline."
            },
            "slug": "Statistics-Based-Summarization-Step-One:-Sentence-Knight-Marcu",
            "title": {
                "fragments": [],
                "text": "Statistics-Based Summarization - Step One: Sentence Compression"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper focuses on sentence compression, a simpler version of this larger challenge, and aims to achieve two goals simultaneously: the compressions should be grammatical, and they should retain the most important pieces of information."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50065230"
                        ],
                        "name": "J. Cohen",
                        "slug": "J.-Cohen",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Cohen",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39490797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8af06d013f303e81680a37a98df4a49ed9551eb5",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hardware-Assisted-Algorithm-for-Full-Text-String-Cohen",
            "title": {
                "fragments": [],
                "text": "Hardware-Assisted Algorithm for Full-Text Large-Dictionary String Matching using N-gram Hashing"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14619034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d20a039f2fec9a6439a3326c8e3b435a0d11e99",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 205,
            "paperAbstract": {
                "fragments": [],
                "text": "The unification problem and several variants are presented. Various algorithms and data structures are discussed. Research on unification arising in several areas of computer science is surveyed; these areas include theorem proving, logic programming, and natural language processing. Sections of the paper include examples that highlight particular uses of unification and the special problems encountered. Other topics covered are resolution, higher order logic, the occur check, infinite terms, feature structures, equational theories, inheritance, parallel algorithms, generalization, lattices, and other applications of unification. The paper is intended for readers with a general computer science background\u2014no specific knowledge of any of the above topics is assumed."
            },
            "slug": "Unification:-a-multidisciplinary-survey-Knight",
            "title": {
                "fragments": [],
                "text": "Unification: a multidisciplinary survey"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Topics covered are resolution, higher order logic, the occur check, infinite terms, feature structures, equational theories, inheritance, parallel algorithms, generalization, lattices, and other applications of unification."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 134248,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "2b2eb4a9bb146e3ffaa0b025fba0ed14240c683f",
            "isKey": false,
            "numCitedBy": 1821,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of injection molding wherein a pair of separable mold plates are initially urged together and fluid plastic is injected into a mold cavity formed between the mold plates to form an article. The injection pressure of the fluid plastic is utilized to generate forces sufficient to overcome the internal forces urging the mold plates apart and thus hold the mold plates together until the material being molded solidifies either by cooling, chemical reaction or phase change."
            },
            "slug": "Transformation-Based-Error-Driven-Learning-and-A-in-Brill",
            "title": {
                "fragments": [],
                "text": "Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Injection molding wherein a pair of separable mold plates are initially urged together and fluid plastic is injected into a mold cavity formed between the mold plates to form an article."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144987107"
                        ],
                        "name": "Jamie Callan",
                        "slug": "Jamie-Callan",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Callan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Callan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2533154"
                        ],
                        "name": "J. Broglio",
                        "slug": "J.-Broglio",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Broglio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Broglio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5779688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac1410ee22f8163cf0513b02a5d43054eb037424",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "TREC-and-Tipster-Experiments-with-Inquery-Callan-Croft",
            "title": {
                "fragments": [],
                "text": "TREC and Tipster Experiments with Inquery"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43609670,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "c97fecb8e3b14b4a46671a4b4ac5cbdce2931054",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-in-relevance-weighting-of-search-terms-Jones",
            "title": {
                "fragments": [],
                "text": "Experiments in relevance weighting of search terms"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847246"
                        ],
                        "name": "Andrei Mikheev",
                        "slug": "Andrei-Mikheev",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Mikheev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei Mikheev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085030"
                        ],
                        "name": "M. Moens",
                        "slug": "M.-Moens",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Moens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144003169"
                        ],
                        "name": "Claire Grover",
                        "slug": "Claire-Grover",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Grover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Grover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7332330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa8c4d7b07e1b03dfe214b247e62c27de33b63b6",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "It is often claimed that Named Entity recognition systems need extensive gazetteers---lists of names of people, organisations, locations, and other named entities. Indeed, the compilation of such gazetteers is sometimes mentioned as a bottleneck in the design of Named Entity recognition systems.We report on a Named Entity recognition system which combines rule-based grammars with statistical (maximum entropy) models. We report on the system's performance with gazetteers of different types and different sizes, using test material from the MUC-7 competition. We show that, for the text type and task of this competition, it is sufficient to use relatively small gazetteers of well-known names, rather than large gazetteers of low-frequency names. We conclude with observations about the domain independence of the competition and of our experiments."
            },
            "slug": "Named-Entity-Recognition-without-Gazetteers-Mikheev-Moens",
            "title": {
                "fragments": [],
                "text": "Named Entity Recognition without Gazetteers"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that, for the text type and task of this competition, it is sufficient to use relatively small gazetteers of well-known names, rather than large gazetters of low-frequency names."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21393511,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "744ff0ca51ac9170ea1fe5b7f40bc7027b8f4fac",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Interesse Zins Vorteil Wichtigkeit Bedeutung allotment lot proportion quota rate share interest advantage benefit vantage importance meaningfulness momentousness opportunity concern importance meaning prominence relevenacy significance weight acceptance denotation sense impact"
            },
            "slug": "Knowledge-Sources-for-Word-Level-Translation-Models-Koehn-Knight",
            "title": {
                "fragments": [],
                "text": "Knowledge Sources for Word-Level Translation Models"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Interesse Zins Vorteil Wichtigkeit Bedeutung allotment lot proportion quota rate share interest advantage benefit vantage importance meaningfulness momentousness opportunity concern importance meaning prominence relevenacy significance weight acceptance denotation sense impact."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62562997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae9443b39a5abfbf3cc9776173c1ae4f94732408",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a new sequential decoding algorithm is introduced that uses stack storage at the receiver. It is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp the rate below which the average number of decoding steps is bounded by a constant. Practical problems connected with implementing the stack algorithm are discussed and a scheme is described that facilitates satisfactory performance even with limited stack storage capacity. Preliminary simulation results estimating the decoding effort and the needed stack siazree presented."
            },
            "slug": "Fast-sequential-decoding-algorithm-using-a-stack-Jelinek",
            "title": {
                "fragments": [],
                "text": "Fast sequential decoding algorithm using a stack"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new sequential decoding algorithm is introduced that uses stack storage at the receiver that is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93671213"
                        ],
                        "name": "M. Carl",
                        "slug": "M.-Carl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Carl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Carl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14869687,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "1da9c5e6da6a9fc41ed4b3fb84bb3abd94c26968",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Constructivist cognitive theories conceptualize memory as a dynamic process which is directly linked to perception, memories and conclusion/induction (cf. [Sch91]). From this point of view, memory serves to establish structures that are relevant to the cognitive system in the present context of action. The function of memory is thus to participate in coherent behavior which makes survival of the acting cognitive system easier (or possible). Memories are similar to perceptions: they are perceptions without an object. Perception on the other hand is an activity (and not a passive process) that is driven by the memory."
            },
            "slug": "A-Constructivist-Approach-to-Machine-Translation-Carl",
            "title": {
                "fragments": [],
                "text": "A Constructivist Approach to Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Constructivist cognitive theories conceptualize memory as a dynamic process which is directly linked to perception, memories and conclusion/induction (cf. [Sch91])."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783611"
                        ],
                        "name": "Kiyotaka Uchimoto",
                        "slug": "Kiyotaka-Uchimoto",
                        "structuredName": {
                            "firstName": "Kiyotaka",
                            "lastName": "Uchimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kiyotaka Uchimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714612"
                        ],
                        "name": "S. Sekine",
                        "slug": "S.-Sekine",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Sekine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sekine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697381"
                        ],
                        "name": "M. Murata",
                        "slug": "M.-Murata",
                        "structuredName": {
                            "firstName": "Masaki",
                            "lastName": "Murata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Murata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714134"
                        ],
                        "name": "H. Isahara",
                        "slug": "H.-Isahara",
                        "structuredName": {
                            "firstName": "Hitoshi",
                            "lastName": "Isahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Isahara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61207064,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "297899c89d36663b7d1b35580b52e8efd883117e",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "\u672c\u8ad6\u6587\u3067\u306f, \u6a5f\u68b0\u7ffb\u8a33\u306b\u304a\u3051\u308b\u8a33\u8a9e\u9078\u629e\u306e\u624b\u6cd5\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b. \u6211\u3005\u306e\u30b7\u30b9\u30c6\u30e0\u306f, \u5165\u529b\u6587\u3068\u5bfe\u8c61\u5358\u8a9e\u304c\u4e0e\u3048\u3089\u308c\u305f\u3068\u304d, \u7ffb\u8a33\u30e1\u30e2\u30ea\u3068\u547c\u3070\u308c\u308b\u5bfe\u8a33\u7528\u4f8b\u96c6\u5408\u3068\u5165\u529b\u6587\u3068\u306e\u985e\u4f3c\u5ea6\u3092\u6c42\u3081, \u985e\u4f3c\u5ea6\u304c\u6700\u5927\u3068\u306a\u308b\u7528\u4f8b\u96c6\u5408\u3092\u7528\u3044\u3066\u5bfe\u8c61\u5358\u8a9e\u306e\u8a33\u8a9e\u9078\u629e\u3092\u884c\u306a\u3046. \u985e\u4f3c\u5ea6\u306f, \u7528\u4f8b\u306b\u57fa\u3065\u304f\u624b\u6cd5\u3068\u6a5f\u68b0\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u7528\u3044\u3066\u8a08\u7b97\u3055\u308c\u308b. \u985e\u4f3c\u5ea6\u306e\u8a08\u7b97\u306b\u306f, \u6587\u5b57\u5217\u306e\u985e\u4f3c\u6027\u3084\u5165\u529b\u6587\u306b\u304a\u3051\u308b\u5bfe\u8c61\u5358\u8a9e\u5468\u8fba\u306e\u5358\u8a9e, \u5165\u529b\u6587\u4e2d\u306e\u5185\u5bb9\u8a9e\u3068\u305d\u306e\u8a33\u8a9e\u5019\u88dc\u306e\u5bfe\u8a33\u30b3\u30fc\u30d1\u30b9\u304a\u3088\u3073\u65e5\u82f1\u306e\u5358\u8a00\u8a9e\u30b3\u30fc\u30d1\u30b9\u306b\u304a\u3051\u308b\u51fa\u73fe\u983b\u5ea6\u306a\u3069\u3092\u8003\u616e\u3059\u308b. \u5165\u529b\u6587\u3068\u5bfe\u8c61\u5358\u8a9e\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068, \u307e\u305a\u7528\u4f8b\u306b\u57fa\u3065\u304f\u624b\u6cd5\u3092\u9069\u7528\u3057, \u985e\u4f3c\u3057\u305f\u7528\u4f8b\u304c\u898b\u3064\u304b\u3089\u306a\u304b\u3063\u305f\u5834\u5408\u306b\u6a5f\u68b0\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u9069\u7528\u3059\u308b. \u6a5f\u68b0\u5b66\u7fd2\u30e2\u30c7\u30eb\u306f\u8907\u6570\u7528\u610f\u3057, \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306a\u3069\u306b\u3088\u308a\u5358\u8a9e\u6bce\u306b\u6700\u9069\u306a\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u9078\u629e\u3059\u308b. \u672c\u8ad6\u6587\u3067\u306f, 2001\u5e74\u306e\u6625\u306b\u958b\u50ac\u3055\u308c\u305f\u5358\u8a9e\u306e\u591a\u7fa9\u6027\u89e3\u6d88\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u7b2c2\u56deSENSEVAL\u3067\u306e\u7d50\u679c\u3092\u3082\u3068\u306b, \u63d0\u6848\u624b\u6cd5\u306e\u6709\u52b9\u6027\u3068, \u3069\u306e\u3088\u3046\u306a\u60c5\u5831\u304c\u7cbe\u5ea6\u5411\u4e0a\u306b\u6709\u52b9\u3067\u3042\u3063\u305f\u304b\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b."
            },
            "slug": "Word-Translation-by-Combining-an-Example-Based-and-Uchimoto-Sekine",
            "title": {
                "fragments": [],
                "text": "Word Translation by Combining an Example-Based Method and Machine Learning Models"
            },
            "tldr": {
                "abstractSimilarityScore": 0,
                "text": "It is claimed that the world's tallest building, the Eiffel Tower, is about to be demolished."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53142908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3524cdf7cf8344e7eb74886f71fcbb5c6732c337",
            "isKey": false,
            "numCitedBy": 26736,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence."
            },
            "slug": "Artificial-Intelligence:-A-Modern-Approach-Russell-Norvig",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence: A Modern Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685634"
                        ],
                        "name": "Kenji Imamura",
                        "slug": "Kenji-Imamura",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Imamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Imamura"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8413929,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "e147366677fcbf3bb82e3a8f5af87910e5c7ae5d",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "\u672c\u7a3f\u3067\u306f, \u6a5f\u68b0\u7ffb\u8a33\u77e5\u8b58\u306e\u81ea\u52d5\u7372\u5f97\u3092\u76ee\u7684\u3068\u3057\u305f, 2\u8a00\u8a9e\u306e\u5bfe\u8a33\u6587\u306e\u968e\u5c64\u7684\u53e5\u30a2\u30e9\u30a4\u30e1\u30f3\u30c8\u306b\u3064\u3044\u3066\u63d0\u6848\u3059\u308b. \u5f93\u6765\u63d0\u6848\u3055\u308c\u3066\u304d\u305f\u53e5\u30a2\u30e9\u30a4\u30e1\u30f3\u30c8\u65b9\u6cd5\u306f, \u3044\u305a\u308c\u3082\u69cb\u6587\u89e3\u6790\u7d50\u679c\u3092\u53d6\u5f97\u3057\u305f\u306e\u3061\u306b, \u90e8\u5206\u6728\u540c\u58eb\u306e\u5bfe\u5fdc\u3092\u3068\u308b\u3082\u306e\u3067\u3042\u3063\u305f. \u672c\u7a3f\u3067\u63d0\u6848\u3059\u308b\u65b9\u5f0f\u306f, \u69cb\u6587\u89e3\u6790\u5668\u304c\u6301\u3064\u90e8\u5206\u89e3\u6790\u7d50\u679c\u3092\u53e5\u5bfe\u5fdc\u30b9\u30b3\u30a2\u3068\u547c\u3076\u69cb\u9020\u985e\u4f3c\u6027\u8a55\u4fa1\u5c3a\u5ea6\u3067\u8a55\u4fa1\u3057, \u524d\u5411\u304dDP\u5f8c\u308d\u5411\u304dA\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u7528\u3044\u3066\u6700\u9069\u306a\u7d44\u307f\u5408\u308f\u305b\u3092\u63a2\u7d22\u3059\u308b. \u3053\u306e\u65b9\u5f0f\u3092\u7528\u3044\u308b\u3053\u3068\u306b\u3088\u308a, \u5b9f\u9a13\u3067\u306f\u5f93\u6765\u624b\u6cd5\u306b\u6bd4\u30792\u500d\u306e\u540c\u7b49\u53e5\u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d, \u305d\u306e\u3068\u304d\u306e\u7cbe\u5ea6\u306e\u4f4e\u4e0b\u306f\u307b\u3068\u3093\u3069\u306a\u3044\u3053\u3068\u304c\u89b3\u5bdf\u3055\u308c\u305f.\u307e\u305f, \u672c\u63d0\u6848\u65b9\u5f0f\u306f\u5358\u8a9e\u30a2\u30e9\u30a4\u30e1\u30f3\u30c8\u3092\u7528\u3044\u308b. \u3053\u306e\u5358\u8a9e\u30ec\u30d9\u30eb\u306e\u5bfe\u5fdc\u306f, \u5185\u5bb9\u8a9e\u306e\u307f\u3067\u306a\u304f, \u6a5f\u80fd\u8a9e\u9593\u5bfe\u5fdc\u3092\u542b\u3081\u305f\u65b9\u304c\u53e5\u30a2\u30e9\u30a4\u30e1\u30f3\u30c8\u7cbe\u5ea6\u304c\u5411\u4e0a\u3059\u308b. \u305d\u306e\u4e00\u822c\u5f62\u3068\u3057\u3066, \u672c\u65b9\u5f0f\u306b\u9069\u5408\u3057\u305f\u5358\u8a9e\u30a2\u30e9\u30a4\u30e1\u30f3\u30c8\u306f, \u518d\u73fe\u7387\u91cd\u8996\u306e\u3082\u306e\u304c\u671b\u307e\u3057\u3044\u3053\u3068\u3092\u4f75\u305b\u3066\u793a\u3059"
            },
            "slug": "Hierarchical-Phrase-Alignment-Harmonized-with-Imamura",
            "title": {
                "fragments": [],
                "text": "Hierarchical Phrase Alignment Harmonized with Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 0,
                "text": "Familiarity, ease of access, trust, and awareness of consequences will be important for the future."
            },
            "venue": {
                "fragments": [],
                "text": "NLPRS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35313721"
                        ],
                        "name": "S. Bangalore",
                        "slug": "S.-Bangalore",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Bangalore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bangalore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702447"
                        ],
                        "name": "Owen Rambow",
                        "slug": "Owen-Rambow",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Rambow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Rambow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143965889"
                        ],
                        "name": "S. Whittaker",
                        "slug": "S.-Whittaker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Whittaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Whittaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17640147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70f68fa66713f9c9f5c56f593fa2b3ab6460ba15",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Certain generation applications may profit from the use of stochastic methods. In developing stochastic methods, it is crucial to be able to quickly assess the relative merits of different approaches or models. In this paper, we present several types of intrinsic (system internal) metrics which we have used for baseline quantitative assessment. This quantitative assessment should then be augmented to a fuller evaluation that examines qualitative aspects. To this end, we describe an experiment that tests correlation between the quantitative metrics and human qualitative judgment. The experiment confirms that intrinsic metrics cannot replace human evaluation, but some correlate significantly with human judgments of quality and understandability and can be used for evaluation during development."
            },
            "slug": "Evaluation-Metrics-for-Generation-Bangalore-Rambow",
            "title": {
                "fragments": [],
                "text": "Evaluation Metrics for Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is confirmed that intrinsic metrics cannot replace human evaluation, but some correlate significantly with human judgments of quality and understandability and can be used for evaluation during development."
            },
            "venue": {
                "fragments": [],
                "text": "INLG"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36475526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb99bb04d1f0d5fecd22d8fb331eddeed2073adf",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In our quest to build intelligent machines, we have but one naturally occurring model: the human brain. It follows that one natural idea for artificial intelligence (AI) is to simulate the functioning of the brain directly on a computer. Indeed, the idea of building an intelligent machine out of artificial neurons has been around for quite some time. Some early results on brain-line mechanisms were achieved by [18], and other researchers pursued this notion through the next two decades, e.g., [1, 4, 19, 21, 24]. Research in neural networks came to a virtual halt in the 1970s, however, when the networks under study were shown to be very weak computationally. Recently, there has been a resurgence of interest in neural networks. There are several reasons for this, including the appearance of faster digital computers on which to simulate larger networks, interest in building massively parallel computers, and most importantly, the discovery of powerful network learning algorithms.\nThe new neural network architectures have been dubbed connectionist architectures. For the most part, these architectures are not meant to duplicate the operation of the human brain, but rather receive inspiration from known facts about how the brain works. They are characterized by\nLarge numbers of very simple neuron-like processing elements;\nLarge numbers of weighted connections between the elements\u2014the weights on the connections encode the knowledge of a network;\nHighly parallel, distributed control; and\nEmphasis on learning internal representations automatically.\nConnectionist researchers conjecture that thinking about computation in terms of the brain metaphor rather than the digital computer metaphor will lead to insights into the nature of intelligent behavior.\nComputers are capable of amazing feats. They can effortlessly store vast quantities of information. Their circuits operate in nanoseconds. They can perform extensive arithmetic calculations without error. Humans cannot approach these capabilities. On the other hand, humans routinely perform simple tasks such as walking, talking, and commonsense reasoning. Current AI systems cannot do any of these things better than humans. Why not? Perhaps the structure of the brain is somehow suited to these tasks, and not suited to tasks like high-speed arithmetic calculation. Working under constraints suggested by the brain may make traditional computation more difficult, but it may lead to solutions to AI problems that would otherwise be overlooked.\nWhat constraints, then, does the brain offer us? First of all, individual neurons are extremely slow devices when compared to their counterparts in digital computers. Neurons operate in the millisecond range, an eternity to a VLSI designer. Yet, humans can perform extremely complex tasks, like interpreting a visual scene or understanding a sentence, in just a tenth of a second. In other words, we do in about a hundred steps what current computers cannot do in ten million steps. How can this be possible? Unlike a conventional computer, the brain contains a huge number of processing elements that act in parallel. This suggests that in our search for solutions, we look for massively parallel algorithms that require no more than 100 processing steps [9].\nAlso, neurons are failure-prone devices. They are constantly dying (you have certainly lost a few since you began reading this article), and their firing patterns are irregular. Components in digital computers, on the other hand, must operate perfectly. Why? Such components store bits of information that are available nowhere else in the computer: the failure of one component means a loss of information. Suppose that we built AI programs that were not sensitive to the failure of a few components, perhaps by using redundancy and distributing information across a wide range of components? This would open the possibility of very large-scale implementations. With current technology, it is far easier to build a billion-component integrated circuit in which 95 percent of the components work correctly than it is to build a perfectly functioning million-component machine [8].\nAnother thing people seem to be able to do better than computers is handle fuzzy situations. We have very large memories of visual, auditory, and problem-solving episodes, and one key operation in solving new problems is finding closest matches to old situations. Inexact matching is something brain-style models seem to be good at, because of the diffuse and fluid way in which knowledge is represented.\nThe idea behind connectionism, then, is that we may see significant advances in AI if we approach problems from the point of view of brain-style computation rather than rule-based symbol manipulation. At the end of this article, we will look more closely at the relationship between connectionist and symbolic AI."
            },
            "slug": "Connectionist-ideas-and-algorithms-Knight",
            "title": {
                "fragments": [],
                "text": "Connectionist ideas and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Working under constraints suggested by the brain may make traditional computation more difficult, but it may lead to solutions to AI problems that would otherwise be overlooked."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744679"
                        ],
                        "name": "B. Selman",
                        "slug": "B.-Selman",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Selman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Selman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634377"
                        ],
                        "name": "H. Levesque",
                        "slug": "H.-Levesque",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Levesque",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Levesque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50066285"
                        ],
                        "name": "D. Mitchell",
                        "slug": "D.-Mitchell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8540521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f8729c0cfc09dae60170b83e6112c19bde7c625",
            "isKey": false,
            "numCitedBy": 1474,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a greedy local search procedure called GSAT for solving propositional satisfiability problems. Our experiments show that this procedure can be used to solve hard, randomly generated problems that are an order of magnitude larger than those that can be handled by more traditional approaches such as the Davis-Putnam procedure or resolution. We also show that GSAT can solve structured satisfiability problems quickly. In particular, we solve encodings of graph coloring problems, N-queens, and Boolean induction. General application strategies and limitations of the approach are also discussed. \n \nGSAT is best viewed as a model-finding procedure. Its good performance suggests that it may be advantageous to reformulate reasoning tasks that have traditionally been viewed as theorem-proving problems as model-finding tasks."
            },
            "slug": "A-New-Method-for-Solving-Hard-Satisfiability-Selman-Levesque",
            "title": {
                "fragments": [],
                "text": "A New Method for Solving Hard Satisfiability Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A greedy local search procedure called GSAT is introduced for solving propositional satisfiability problems and its good performance suggests that it may be advantageous to reformulate reasoning tasks that have traditionally been viewed as theorem-proving problems as model-finding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13879647"
                        ],
                        "name": "R. Monasson",
                        "slug": "R.-Monasson",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Monasson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monasson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719010"
                        ],
                        "name": "R. Zecchina",
                        "slug": "R.-Zecchina",
                        "structuredName": {
                            "firstName": "Riccardo",
                            "lastName": "Zecchina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zecchina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145847131"
                        ],
                        "name": "S. Kirkpatrick",
                        "slug": "S.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744679"
                        ],
                        "name": "B. Selman",
                        "slug": "B.-Selman",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Selman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Selman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3100429"
                        ],
                        "name": "L. Troyansky",
                        "slug": "L.-Troyansky",
                        "structuredName": {
                            "firstName": "Lidror",
                            "lastName": "Troyansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Troyansky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4385052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aae865c7780aa6d2dbfb54dddba63f3972cdd9e6",
            "isKey": false,
            "numCitedBy": 705,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Non-deterministic polynomial time (commonly termed \u2018NP-complete\u2019) problems are relevant to many computational tasks of practical interest\u2014such as the \u2018travelling salesman problem\u2019\u2014but are difficult to solve: the computing time grows exponentially with problem size in the worst case. It has recently been shown that these problems exhibit \u2018phase boundaries\u2019, across which dramatic changes occur in the computational difficulty and solution character\u2014the problems become easier to solve away from the boundary. Here we report an analytic solution and experimental investigation of the phase transition in K -satisfiability, an archetypal NP-complete problem. Depending on the input parameters, the computing time may grow exponentially or polynomially with problem size; in the former case, we observe a discontinuous transition, whereas in the latter case a continuous (second-order) transition is found. The nature of these transitions may explain the differing computational costs, and suggests directions for improving the efficiency of search algorithms. Similar types of transition should occur in other combinatorial problems and in glassy or granular materials, thereby strengthening the link between computational models and properties of physical systems."
            },
            "slug": "Determining-computational-complexity-from-\u2018phase-Monasson-Zecchina",
            "title": {
                "fragments": [],
                "text": "Determining computational complexity from characteristic \u2018phase transitions\u2019"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An analytic solution and experimental investigation of the phase transition in K -satisfiability, an archetypal NP-complete problem, is reported and the nature of these transitions may explain the differing computational costs, and suggests directions for improving the efficiency of search algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35422789"
                        ],
                        "name": "P. Richard",
                        "slug": "P.-Richard",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Richard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Richard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150208480"
                        ],
                        "name": "M. Falcon Chang",
                        "slug": "M.-Falcon-Chang",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Falcon Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Falcon Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742610"
                        ],
                        "name": "N. Monmarch\u00e9",
                        "slug": "N.-Monmarch\u00e9",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Monmarch\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Monmarch\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37432938"
                        ],
                        "name": "C. Proust",
                        "slug": "C.-Proust",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Proust",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Proust"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109708563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a31e03f1b6101b711501337bca3d00741fab6808",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a Petri net approach to the traveling salesman problem (TSP) in order to solve a planning problem in the glass industry. To a Petri net model can be associated, automatically, an integer linear program. That approach is useful to control the underlying graph structure of linear programs. For that reason, we found an acyclic Petri net, with a totally unimodular matrix, which leads to a polynomial version of the traveling salesman problem when the number of cities is less than 6."
            },
            "slug": "Visiting-the-traveling-salesman-problem-with-Petri-Richard-Chang",
            "title": {
                "fragments": [],
                "text": "Visiting the traveling salesman problem with Petri nets and application in the glass industry"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An acyclic Petri net is found, with a totally unimodular matrix, which leads to a polynomial version of the traveling salesman problem when the number of cities is less than 6."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1996 IEEE Conference on Emerging Technologies and Factory Automation. ETFA '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108679815"
                        ],
                        "name": "Ratnesh Kumar",
                        "slug": "Ratnesh-Kumar",
                        "structuredName": {
                            "firstName": "Ratnesh",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ratnesh Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051634892"
                        ],
                        "name": "Haomin Li",
                        "slug": "Haomin-Li",
                        "structuredName": {
                            "firstName": "Haomin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haomin Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16361158,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "8e58a58c405bf8699bf7cc6056e1107b0fc85715",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A printed circuit board (PCB) assembly task requires that a set of components be picked from their respective pickup locations and then be placed at their respective placement locations on the card being assembled. A pick-and-place robot is used for automated assembly of PCB's. The overall assembly time depends on two different decision variables: (i) the pickup locations of the components (in general there are several alternative pickup locations available, whereas the placement location of components is fixed and is determined by the card being assembled), and (ii) the sequence in which the pickup and placement of components is performed. In this paper, we develop a technique based on integer programming to determine both an optimal assignment of pickup locations as well as an optimal sequence of pickup and placements of the components. We demonstrate that the overall optimization problem is an instance of linear integer programming, and hence it is computationally intractable. We obtain near optimal solutions-that are computationally tractable-using the techniques of (i) minimum weight matching for determining an optimal assignment of pickup locations, and (ii) traveling salesman problem for determining an optimum sequence of pickups and placements. Near optimal solutions provide an upper bound for the optimal assembly time; we consider a linear programming relaxation of the problem to obtain a lower bound for the optimal assembly time. The gap between the upper bound and the lower bound provides a measure of closeness of near optimal solutions to an optimal one. Finally, we use simulations to compare the saving in overall assembly time using the techniques developed here and some of the techniques that are currently in use in industrial settings. >"
            },
            "slug": "Integer-programming-approach-to-printed-circuit-Kumar-Li",
            "title": {
                "fragments": [],
                "text": "Integer programming approach to printed circuit board assembly time optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 58
                            }
                        ],
                        "text": "To estimate the model parameters, we use the EM algorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 31
                            }
                        ],
                        "text": "To make thispapercomparableto (Brown et al., 1993),we useEnglish-Frenchnotationin this section."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "Notethisnotation is differentfrom (Brown et al., 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "Following (Brown et al., 1993) and the other literaturein TM, this paperonly focusesthe detailsof TM. Applicationsof ourTM, suchasmachinetranslationor dictionaryconstruction,will be describedin a separatepaper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 10
                            }
                        ],
                        "text": "Following (Brown et al., 1993) and the other literaturein TM, this paperonly focusesthe detailsof TM."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Brown et al. (1993)assumesthat there is an invisible NULL word in the input sentence andit generatesoutputwordsthataredistributed into randompositions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 41
                            }
                        ],
                        "text": "Mathematicaldetailsarefully describedin (Brown et al., 1993)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Themathematicsof statisticalmachine translation:Parameterestimation"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics,"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60804212,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "539036ab9e8f038c8a948596e77cc0dfcfa91fb3",
            "isKey": false,
            "numCitedBy": 1785,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-inequality-and-associated-maximization-technique-Baum",
            "title": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60618317,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ecb37a4e32d6faef4ac99b45d9ab9b2d92693985",
            "isKey": false,
            "numCitedBy": 1169,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Max-imum-Likelihood-from-Incomplete-Data-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Max-imum Likelihood from Incomplete Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145111101"
                        ],
                        "name": "Kazuo Sumita",
                        "slug": "Kazuo-Sumita",
                        "structuredName": {
                            "firstName": "Kazuo",
                            "lastName": "Sumita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuo Sumita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072866665"
                        ],
                        "name": "Kenji Ono",
                        "slug": "Kenji-Ono",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Ono",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Ono"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16758069"
                        ],
                        "name": "Tetsuro Chino",
                        "slug": "Tetsuro-Chino",
                        "structuredName": {
                            "firstName": "Tetsuro",
                            "lastName": "Chino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tetsuro Chino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37450012"
                        ],
                        "name": "T. Ukita",
                        "slug": "T.-Ukita",
                        "structuredName": {
                            "firstName": "Teruhiko",
                            "lastName": "Ukita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ukita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1896204"
                        ],
                        "name": "Shin'ya Amano",
                        "slug": "Shin'ya-Amano",
                        "structuredName": {
                            "firstName": "Shin'ya",
                            "lastName": "Amano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shin'ya Amano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20110478,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "e89aa7a37bcc6e8915e9aa505d51d447be3e8d77",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Discourse-Structure-Analyzer-for-Japanese-Text-Sumita-Ono",
            "title": {
                "fragments": [],
                "text": "A Discourse Structure Analyzer for Japanese Text"
            },
            "venue": {
                "fragments": [],
                "text": "FGCS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39038065"
                        ],
                        "name": "M. Franz",
                        "slug": "M.-Franz",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Franz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Franz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40454673"
                        ],
                        "name": "J. Scott McCarley",
                        "slug": "J.-Scott-McCarley",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "McCarley",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Scott McCarley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144582029"
                        ],
                        "name": "T. Ward",
                        "slug": "T.-Ward",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ward"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13890625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6466ae96db27c2635ec8cc1bdc5bbed09f8f6552",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Ad-hoc,-Cross-language-and-Spoken-Document-at-IBM-Franz-McCarley",
            "title": {
                "fragments": [],
                "text": "Ad hoc, Cross-language and Spoken Document Information Retrieval at IBM"
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582677"
                        ],
                        "name": "Michael Witbrock",
                        "slug": "Michael-Witbrock",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Witbrock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Witbrock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751139"
                        ],
                        "name": "V. Mittal",
                        "slug": "V.-Mittal",
                        "structuredName": {
                            "firstName": "Vibhu",
                            "lastName": "Mittal",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Mittal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208926737,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "cc7371cb1fe7c020aa13610d384cf869062700d6",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A game machine which can be played by two or more players includes an elongated box-like housing in which a game ball can be inserted, the housing including elongated side members with transparent windows therein and opposed end members with openings in their upper portions through which the game ball can be projected, the housing also including two projector elements in respective opposite ends thereof which are capable of utilization by competing players to project the game ball towards the opposite end member, and at least two activator elements in the housing between the two projector elements which are capable of utilization by competing players to contact and move a game ball in the desired fashion. A flooring structure inside the housing forms a contoured playing deck surface above the bottom of the housing and provides multiple, uniform and equally spaced-apart spaces which extend from one end member of the housing to the other. The projector elements and the activator elements include portions which can move within these spaces from a positioning below the playing deck surface to varying positionings above the playing deck surface so as to cause suitable manipulations of the game ball, including dribbling, when contacted by the noted projector element and activator element portions."
            },
            "slug": "Ultra-Summarization:-A-Statistical-Approach-to-Witbrock-Mittal",
            "title": {
                "fragments": [],
                "text": "Ultra-Summarization: A Statistical Approach to Generating Highly Condensed Non-Extractive Summaries (poster abstract)."
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A game machine which can be played by two or more players includes an elongated box-like housing in which a game ball can be inserted and portions which can move within these spaces so as to cause suitable manipulations of the game ball, including dribbling, when contacted by the noted projector element and activator element portions."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR 1999"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52082513"
                        ],
                        "name": "Irene Langkilde",
                        "slug": "Irene-Langkilde",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Langkilde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irene Langkilde"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60599281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df7eb9f3099747579b609a0072d390aa33c3f17f",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach to statistical sentence generation in which alternative phrases are represented as packed sets of trees, or forests, and then ranked statistically to choose the best one. This representation offers advantages in compactness and in the ability to represent syntactic information. It also facilitates more efficient statistical ranking than a previous approach to statistical generation. An efficient ranking algorithm is described, together with experimental results showing significant improvements over simple enumeration or a lattice-based approach."
            },
            "slug": "Forest-Based-Statistical-Sentence-Generation-Langkilde",
            "title": {
                "fragments": [],
                "text": "Forest-Based Statistical Sentence Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A new approach to statistical sentence generation is presented in which alternative phrases are represented as packed sets of trees, or forests, and then ranked statistically to choose the best one, and an efficient ranking algorithm is described."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 110
                            }
                        ],
                        "text": "TMs have been usedfor statisticalmachinetranslation(Bergeret al., 1996), word alignmentof a translationcorpus(Melamed,2000),multilingual documentretrieval (Franzet al., 1999),automaticdictionary construction(Resnik and Melamed,1997), and datapreparationfor word sensedisambiguation programs(Brown\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 48
                            }
                        ],
                        "text": ", 1996), word alignment of a translation corpus (Melamed, 2000), multilingual document retrieval (Franz et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Models of translational equivalence among words.Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochasticinversion transduction grammarsandbilingualparsingof parallelcorpora"
            },
            "venue": {
                "fragments": [],
                "text": "ComputationalLinguistics, 23(3)."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "andP. Roossin.1991.Word-sensedisambiguation usingstatisticalmethods.In ACL-91"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 58
                            }
                        ],
                        "text": "Researchersat IBM first describedsucha statistical TM in (Brown et al., 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 58
                            }
                        ],
                        "text": "Researchers at IBM first describedsucha statistical TM in (Brown et al., 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "andP. Roossin.1988.A statisticalapproachto languagetranslation.In COLING-88"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ta6[(z]\u00da\u00dc\u00db?\u00da\u00ddp \u00de \u00df\u00e0z w m`| \u00da\u00dc\u00e1 \u00da\u00e2\u00de\u009em \\$\u0084`\u0086\u00b6\u00de\u00e2e yqfcZ [k^ [T\u0084 j$f6Z\u00b6b$h u m`y\u0083e \u0084`\u03bcP[k\\$\u0084\u00b6\u00e31\u0084`j$^ e ycZ \u00b1 b a6\u0086?\u03bcT\\ \u0084X\u007f(\\ fl\u03bc6Z\u00b6\\(\u00e4\u00a2\u00e5\u009e\u00e6 \u0327\u00e6\u009a~ a6[T\u0084`\u03bc6Z \u00b1 b$al\u0086\u00a4"
            },
            "venue": {
                "fragments": [],
                "text": "Formulaefor alpha-betaprobabilities,andthecountderivation M. Collins"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incompletedatavia the em algorithm.RoyalStatisticalSocietySeriesB"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 58
                            }
                        ],
                        "text": "Wang(1998)enhancedtheIBM modelsby introducing phrases,and Och et al. (1999) used templatesto capturephrasalsequencesin a sentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved alignmentmodels for statisticalmachinetranslation"
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP-99."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Language TranslationApparatus andMethodUsingContext-BasedTranslationModels. U.S.Patent5,510,981"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Twistedpair grammar: Support for rapid developmentof machine translationfor low densitylanguages"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Models of translationalequivalenceamongwords"
            },
            "venue": {
                "fragments": [],
                "text": "ComputationalLinguistics, 26(2)."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "GrammarInferenceand Statistical MachineTranslation"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D.thesis,Carnegie Mellon University."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-automaticacquisitionof domain-specifictranslationlexicons"
            },
            "venue": {
                "fragments": [],
                "text": "In ANLP-97"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 58
                            }
                        ],
                        "text": "To estimate the model parameters, we use the EM algorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the em algorithm.Royal Statistical Society Series B"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 55
                            }
                        ],
                        "text": "TMs have been used for statistical machine translation (Berger et al., 1996), word alignment of a translation corpus (Melamed, 2000), multilingual document retrieval (Franz et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Language Translation Apparatus and Method Using Context-Based Translation Models"
            },
            "venue": {
                "fragments": [],
                "text": "U.S. Patent 5,510,981."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 36
                            }
                        ],
                        "text": "Brill\u2019 s part-of-speech(POS) tagger (Brill, 1995) and Collins\u2019 parser(Collins, 1999) were usedto obtainparsetreesfor theEnglishsideof the corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Transformation-basederror-driven learningand naturallanguageprocessing:A case studyin partof specchtagging.Computational"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 168
                            }
                        ],
                        "text": "Wedefineanalphaprobabilityandabetaprobability for eachmajor-node,in analogywith the measuresused in the inside-outsidealgorithm for probabilistic context free grammars(Baker, 1979)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 181
                            }
                        ],
                        "text": "We define an alpha probability and a beta probability for each major-node, in analogy with the measures used in the inside-outside algorithm for probabilistic context free grammars (Baker, 1979)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Trainable grammars for speech recognition. In Speech Communication Papers for the 97th Meeting of the Acoustical Sciety of America"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics,"
            },
            "year": 1979
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 10,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 163,
        "totalPages": 17
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Syntax-based-Statistical-Translation-Model-Yamada-Knight/11cd7fbc0ea8605ea498ecfc82b3ff6a44c027e9?sort=total-citations"
}