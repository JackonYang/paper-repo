{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697855"
                        ],
                        "name": "M. Ringuette",
                        "slug": "M.-Ringuette",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Ringuette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ringuette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 147
                            }
                        ],
                        "text": "If the recall and precision of a classifier can be tuned to have an equal value, then this value is called thebreak-even point (BEP) of the system (Lewis and Ringuette 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 146
                            }
                        ],
                        "text": "\u20261994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 149
                            }
                        ],
                        "text": "\u2026categorization systems whose results on the various versions of the Reuters corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 122
                            }
                        ],
                        "text": "Pcut is an abbreviation ofproportional assignment, a method which has been used in previous text categorization research (Lewis and Ringuette 1994, Wiener et al. 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 61
                            }
                        ],
                        "text": "Evaluation results of NaiveBayes on Reuters were reported by Lewis and Ringuette (1994) and Moulinier (1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 146
                            }
                        ],
                        "text": "Evaluation result of DTree algorithms on the Reuters text categorization collection were reported by Lewis and Ringuette (using the IND package) (Lewis and Ringuette 1994) and Moulinier (using C4.5) (Moulinier 1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 66
                            }
                        ],
                        "text": "Reuters version 2 (also called Reuters-21450), prepared by Lewis (Lewis and Ringuette 1994), contains all of the documents in the original corpus (version 1) except the 723 test documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 145
                            }
                        ],
                        "text": "Evaluation result of DTree algorithms on the Reuters text categorization collection were reported by Lewis and Ringuette (using the IND package) (Lewis and Ringuette 1994) and Moulinier (using C4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 141
                            }
                        ],
                        "text": "Apte et al. (1994) compared the results of SWAP-1 on Reuters version 3 to the results of NaiveBayes and DTree by Lewis on Reuters version 2 (Lewis and Ringuette 1994), and concluded from its significantly better performance that rule-learning methods were superior to decision trees for text\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 147
                            }
                        ],
                        "text": "If the recall and precision of a classifier can be tuned to have an equal value, then this value is called thebreak-even point(BEP) of the system (Lewis and Ringuette 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 146
                            }
                        ],
                        "text": "\u2026Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 128
                            }
                        ],
                        "text": "(1994) compared the results of SWAP-1 on Reuters version 3 to the results of NaiveBayes and DTree by Lewis on Reuters version 2 (Lewis and Ringuette 1994), and concluded from its significantly better performance that rule-learning methods were superior to decision trees for text categorization."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 16894634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9fd1a7ae0322d417ab2d32017e373dd50efc063",
            "isKey": true,
            "numCitedBy": 745,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the use of inductive learning to categorize natural language documents into predeened content categories. Categorization of text is of increasing importance in information retrieval and natural language processing systems. Previous research on automated text categorization has mixed machine learning and knowledge engineering methods, making it diicult to draw conclusions about the performance of particular methods. In this paper we present empirical results on the performance of a Bayesian classiier and a decision tree learning algorithm on two text categorization data sets. We nd that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives. The stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization. However, even this algorithm is aided by an initial preeltering of features, connrming the results found by Almuallim and Dietterich on artiicial data sets. We also demonstrate the impact of the time-varying nature of category deenitions."
            },
            "slug": "A-comparison-of-two-learning-algorithms-for-text-Lewis-Ringuette",
            "title": {
                "fragments": [],
                "text": "A comparison of two learning algorithms for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives, and the stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792682"
                        ],
                        "name": "C. Chute",
                        "slug": "C.-Chute",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Chute",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chute"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 147
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 127
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 26], nearest neighbor classi ers[4, 22], Bayesian probabilistic classi ers [19, 10, 12], decision trees[5, 10, 12], inductive rule learning algorithms[1, 3, 13], neural networks[21, 14] and on-line learning approaches[3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16063479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f926a0022e794485ec469124894aaaf29b087d70",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A unified model for text categorization and text retrieval is introduced. We use a training set of manually categorized documents to learn word-category associations, and use these associations to predict the categories of arbitrary documents. Similarly, we use a training set of queries and their related documents to obtain empirical associations between query words and indexing terms of documents, and use these associations to predict the related documents of arbitrary queries. A Linear Least Squares Fit (LLSF) technique is employed to estimate the likelihood of these associations. Document collections from the MEDLINE database and Mayo patient records are used for studies on the effectiveness of our approach, and on how much the effectiveness depends on the choices of training data, indexing language, word-weighting scheme, and morphological canonicalization. Alternative methods are also tested on these data collections for comparison. It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language. Such a semantic mapping lead to a significant improvement in categorization and retrieval, compared to alternative approaches."
            },
            "slug": "An-example-based-mapping-method-for-text-and-Yang-Chute",
            "title": {
                "fragments": [],
                "text": "An example-based mapping method for text categorization and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145272844"
                        ],
                        "name": "C. Apt\u00e9",
                        "slug": "C.-Apt\u00e9",
                        "structuredName": {
                            "firstName": "Chidanand",
                            "lastName": "Apt\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Apt\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68982679"
                        ],
                        "name": "Fred J. Damerau",
                        "slug": "Fred-J.-Damerau",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Damerau",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred J. Damerau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "DNF rules are of equal power to DTrees in machine learning theory (Mitchell 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Of the classifiers listed above, CONSTRUE, DTree, NaiveBayes, DNF, NNet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "Empirical results for the comparison between DNF and DTree approaches, however, are rarely available in text categorization, except in an indirect comparison by Apte et al. (1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Inductive rule learning in Disjunctive Normal Form (DNF) was tested in the WASP-1, RIPPER and CHARADE systems (Apte et al. 1994, Moulinier et al. 1996, Cohen and Singer 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "SVVAP-1, an inductive learning algorithm for classification using rules in Disjunctive Normal Form (DNF)[1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 775418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248380e4b3cc91a87bfb11d29fb95125496dd2c9",
            "isKey": true,
            "numCitedBy": 205,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the results of extensive machine learning experiments on large collections of Reuters\u2019 English and German newswires. The goal of these experiments was to automatically discover classification patterns that can be used for assignment of topics to the individual newswires. Our results with the English newswire collection show a very large gain in performance as compared to published benchmarks, while our initial results with the German newswires appear very promising. We present our methodology, which seems to be insensitive to the language of the document collections, and discuss issues related to the differences in results that we have obtained for the two collections."
            },
            "slug": "Towards-language-independent-automated-learning-of-Apt\u00e9-Damerau",
            "title": {
                "fragments": [],
                "text": "Towards language independent automated learning of text categorization models"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The results of extensive machine learning experiments on large collections of Reuters\u2019 English and German newswires are described, and the methodology, which seems to be insensitive to the language of the document collections, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 192
                            }
                        ],
                        "text": "\u2026on suitable choices of these parameter values were reported in previous papers where the main observations were that the performance of kNN is relatively stable for a large range ofk values (Yang 1994), and that satisfactory performance of LLSF depends on whetherp is sufficiently large (Yang 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 163
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 26], nearest neighbor classi ers[4, 22], Bayesian probabilistic classi ers [19, 10, 12], decision trees[5, 10, 12], inductive rule learning algorithms[1, 3, 13], neural networks[21, 14] and on-line learning approaches[3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 150
                            }
                        ],
                        "text": "\u2026this problem in recent years, including regression models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 214
                            }
                        ],
                        "text": "Thorough investigations on suitable choices of these parameter values were reported in previous papers where the main observations were that the performance of kNN is relatively stable for a large range of k values[22], and that satisfactory performance of LLSF depends on whether p is su ciently large[23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 87
                            }
                        ],
                        "text": "Using the inverted-file indexing of training documents, the time complexity isO(ln/m) (Yang 1994) wherel is the number of unique words in the document,n is the number of training documents, andm is the number of unique terms in the training collection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16041292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc8e59e4c7c2cbb6695ee5488aa569780449b212",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Expert Network (ExpNet) is our new approach to automatic categorization and retrieval of natural language texts. We use a training set of texts with expert-assigned categories to construct a network which approximately reflects the conditional probabilities of categories given a text. The input nodes of the network are words in the training texts, the nodes on the intermediate level are the training texts, and the output nodes are categories. The links between nodes are computed based on statistics of the word distribution and the category distribution over the training set. ExpNet is used for relevance ranking of candidate categories of an arbitrary text in the case of text categorization, and for relevance ranking of documents via categories in the case of text retrieval. We have evaluated ExpNet in categorization and retrieval on a document collection of the MEDLINE database, and observed a performance in recall and precision comparable to the Linear Least Squares Fit (LLSF) mapping method, and significantly better than other methods tested. Computationally, ExpNet has an O(N 1og N) time complexity which is much more efficient than the cubic complexity of the LLSF method. The simplicity of the model, the high recall-precision rates, and the efficient computation together make ExpNet preferable as a practical solution for real-world applications."
            },
            "slug": "Expert-network:-effective-and-efficient-learning-in-Yang",
            "title": {
                "fragments": [],
                "text": "Expert network: effective and efficient learning from human decisions in text categorization and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The simplicity of the model, the high recall-precision rates, and the efficient computation together make ExpNet preferable as a practical solution for real-world applications."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 183
                            }
                        ],
                        "text": "\u2026corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 231
                            }
                        ],
                        "text": "\u2026ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al. 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5083193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3ebcef26c22a373b6f26a67934213eb0582804e",
            "isKey": false,
            "numCitedBy": 5555,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a comparative study of feature selection methods in statistical learning of text categorization The focus is on aggres sive dimensionality reduction Five meth ods were evaluated including term selection based on document frequency DF informa tion gain IG mutual information MI a test CHI and term strength TS We found IG and CHI most e ective in our ex periments Using IG thresholding with a k nearest neighbor classi er on the Reuters cor pus removal of up to removal of unique terms actually yielded an improved classi cation accuracy measured by average preci sion DF thresholding performed similarly Indeed we found strong correlations between the DF IG and CHI values of a term This suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive TS compares favorably with the other methods with up to vocabulary reduction but is not competitive at higher vo cabulary reduction levels In contrast MI had relatively poor performance due to its bias towards favoring rare terms and its sen sitivity to probability estimation errors"
            },
            "slug": "A-Comparative-Study-on-Feature-Selection-in-Text-Yang-Pedersen",
            "title": {
                "fragments": [],
                "text": "A Comparative Study on Feature Selection in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper finds strong correlations between the DF IG and CHI values of a term and suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399346520"
                        ],
                        "name": "Wei Boon Goh",
                        "slug": "Wei-Boon-Goh",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Goh",
                            "middleNames": [
                                "Boon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Boon Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400215485"
                        ],
                        "name": "Kok Leong Low",
                        "slug": "Kok-Leong-Low",
                        "structuredName": {
                            "firstName": "Kok",
                            "lastName": "Low",
                            "middleNames": [
                                "Leong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kok Leong Low"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 207
                            }
                        ],
                        "text": "\u2026trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer 1996, Lewis et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 110
                            }
                        ],
                        "text": "Neural network (NNet) approaches to text categorization were evaluated on Reuters by Wiener et al. (1995) and Ng et al. (1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 316,
                                "start": 308
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 26], nearest neighbor classi ers[4, 22], Bayesian probabilistic classi ers [19, 10, 12], decision trees[5, 10, 12], inductive rule learning algorithms[1, 3, 13], neural networks[21, 14] and on-line learning approaches[3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 207
                            }
                        ],
                        "text": "\u2026corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 153
                            }
                        ],
                        "text": "Classifiers We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature[6, 10, 1, 21, 13, 3, 27, 14] 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3366452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c97e8fcd80d9a3779826f2930724c9d789faa05",
            "isKey": true,
            "numCitedBy": 552,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an automated learning approach to text categorization based on perception learning and a new feature selection metric, called correlation coefficient. Our approach has been teated on the standard Reuters text categorization collection. Empirical results indicate that our approach outperforms the best published results on this % uters collection. In particular, our new feature selection method yields comiderable improvement. We also investigate the usability of our automated hxu-n~ approach by actually developing a system that categorizes texts into a treeof categories. We compare tbe accuracy of our learning approach to a rrddmsed, expert system ap preach that uses a text categorization shell built by Cams gie Group. Although our automated learning approach still gives a lower accuracy, by appropriately inmrporating a set of manually chosen worda to use as f~ures, the combined, semi-automated approach yields accuracy close to the * baaed approach."
            },
            "slug": "Feature-selection,-perceptron-learning,-and-a-case-Ng-Goh",
            "title": {
                "fragments": [],
                "text": "Feature selection, perceptron learning, and a usability case study for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "An automated learning approach to text categorization based on perception learning and a new feature selection metric, called correlation coefficient, is described and empirical results indicate that this approach outperforms the best published results on this % uters collection."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "RIPPER and CHARADE systems (Apte et al. 1994, Moulinier et al. 1996,  Cohen and Singer 1996 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 256
                            }
                        ],
                        "text": "\u2026trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer 1996, Lewis et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 24
                            }
                        ],
                        "text": "Similarly, the claim by Cohen and Singer (1996) about the advantage of the context-sensitive classifiers (RIPPER and EXPERTS) over linear classifiers is not necessarily supported by the empirical results here."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 138
                            }
                        ],
                        "text": "This method is easy to implement and efficient in computation, and has been used as a baseline in several evaluations (Lewis et al. 1996, Cohen and Singer 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, the claim by  Cohen and Singer (1996)  about the advantage of the context-sensitive classifiers (RIPPER and EXPERTS) over linear classifiers is not necessarily supported by the empirical results here."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 160
                            }
                        ],
                        "text": "\u2026corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996,  Cohen and Singer 1996,  Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Cohen concluded that EXPERTS was the best performer ever on the Reuters version 2 collection ( Cohen and Singer 1996 ), and Table 6 agrees with this."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "8. Sleeping Experts (EXPERTS) are on-line learning algorithms recently applied to text categorization ( Cohen and Singer 1996 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 100
                            }
                        ],
                        "text": "Sleeping Experts (EXPERTS) are on-line learning algorithms recently applied to text categorization (Cohen and Singer 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 152
                            }
                        ],
                        "text": "Inductive rule learning in Disjunctive Normal Form (DNF) was tested in the WASP-1, RIPPER and CHARADE systems (Apte et al. 1994, Moulinier et al. 1996, Cohen and Singer 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This method is easy to implement and efficient in computation, and has been used as a baseline in several evaluations (Lewis et al. 1996,  Cohen and Singer 1996 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 94
                            }
                        ],
                        "text": "Cohen concluded that EXPERTS was the best performer ever on the Reuters version 2 collection (Cohen and Singer 1996), and Table 6 agrees with this."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5327274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce2d6de9cec4a6d135c32bb8d2d02bba09928b33",
            "isKey": true,
            "numCitedBy": 572,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "Two recently implemented machine-learning algorithms, RIPPER and sleeping-experts for phrases, are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the \u201ccontext\u201d of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences, both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "slug": "Context-sensitive-learning-methods-for-text-Cohen-Singer",
            "title": {
                "fragments": [],
                "text": "Context-sensitive learning methods for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods and are viewed as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46286298"
                        ],
                        "name": "Y. Yang",
                        "slug": "Y.-Yang",
                        "structuredName": {
                            "firstName": "Y",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "The OHSUMED collection has been used with the full range of categories (14,321 MeSH categories actually occurred) in some experiments[17], or with a subset of categories in the heart disease sub-domain (HD, 119 categories) in other experiments[8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1236261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef3b165b88accf9af1961014db7de7516f8feedd",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Whether or not high accuracy classification methods can be scaled to large applications is crucial for the ultimate usefulness of such methods in text categorization. This paper applies two statistical learning algorithms, the Linear Least Squares Fit (LLSF) mapping and a Nearest Neighbor classifier named ExpNet, to a large collection of MEDLINE documents. With the use of suitable dimensionality reduction techniques and efficient algorithms, both LLSF and ExpNet successfully scaled to this very large problem with a result significantly outperforming word-matching and other automatic learning methods applied to the same corpus."
            },
            "slug": "An-evaluation-of-statistical-approaches-to-MEDLINE-Yang",
            "title": {
                "fragments": [],
                "text": "An evaluation of statistical approaches to MEDLINE indexing."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper applies two statistical learning algorithms, the Linear Least Squares Fit (LLSF) mapping and a Nearest Neighbor classifier named ExpNet, to a large collection of MEDLINE documents, and both LLSF and ExpNet successfully scaled to this very large problem."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings : a conference of the American Medical Informatics Association. AMIA Fall Symposium"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 324,
                                "start": 313
                            }
                        ],
                        "text": "Thorough investigations on suitable choices of these parameter values were reported in previous papers where the main observations were that the performance of kNN is relatively stable for a large range of k values (Yang 1994), and that satisfactory performance of LLSF depends on whether p is sufficiently large (Yang 1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 148
                            }
                        ],
                        "text": "The training phase has a quadratic time complexity,O(pn\u2032) wherep is the number of singular vectors used for computing an approximated LLSF solution (Yang 1995), and n\u2032 = max{m, n} is the larger number betweenn, the number of training documents, and m, the number of unique terms in the training\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 289
                            }
                        ],
                        "text": "\u2026on suitable choices of these parameter values were reported in previous papers where the main observations were that the performance of kNN is relatively stable for a large range ofk values (Yang 1994), and that satisfactory performance of LLSF depends on whetherp is sufficiently large (Yang 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 149
                            }
                        ],
                        "text": "The training phase has a quadratic time complexity, O(pn\u2032) wherep is the number of singular vectors used for computing an approximated LLSF solution (Yang 1995), and n\u2032 = max{m, n} is the larger number between n, the number of training documents, and m, the number of unique terms in the training documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2237198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d81d19d270106805389d22b8d54b1f755797d440",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies noise reduction for computational efficiency improvements in a statistical learning method for text categorization, the Linear Least Squares Fit (LLSF) mapping. Multiple noise reduction strategies are proposedand evaluated, including: an aggressive removal of \u201cnon-informative words\u201d from texts before training; the use of a truncated singular value decomposition to cut off noisy \u201clatent semantic structures\u201d during training; the elimination of non-influential components in the LLSF solution (a word-concept association matrix) after training. Text collections in different domains were used for evaluation. Significant improvements in computational efficiency without losing categorization accuracy were evident in the testing results."
            },
            "slug": "Noise-reduction-in-a-statistical-approach-to-text-Yang",
            "title": {
                "fragments": [],
                "text": "Noise reduction in a statistical approach to text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Noise reduction strategies are proposed and evaluated, including an aggressive removal of \u201cnon-informative words\u201d from texts before training; the use of a truncated singular value decomposition to cut off noisy \u201clatent semantic structures\u201d during training."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 256
                            }
                        ],
                        "text": "It would be ideal if a universal test collection were shared by all the text categorization researchers, or if a controlled evaluation of a wide range of categorization methods were conducted, similar to the Text Retrieval Conference for document retrieval[4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1208194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d49df3eb2daf21fc508d82b1d96e3fdb1d29a75",
            "isKey": false,
            "numCitedBy": 305,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In November of 1992 the first Text REtrieval Conference (TREC-1) was held at NIST [Harman 1993]. The conference, co-sponsored by ARPA and NIST, brought together information retrieval researchers to discuss their system results on a new large test collection (the TIPSTER collection). This conference became the first in a series of ongoing conferences dedicated to encouraging research in retrieval from large-scale test collections, and to encouraging increased interaction among research groups in industry and academia. From the beginning there has been an almost equal number of universities and companies participating, with an emphasis on exploring many different types of approaches to the text retrieval problem."
            },
            "slug": "Overview-of-the-Third-Text-REtrieval-Conference-Harman",
            "title": {
                "fragments": [],
                "text": "Overview of the Third Text REtrieval Conference (TREC-3)"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This conference became the first in a series of ongoing conferences dedicated to encouraging research in retrieval from large-scale test collections, and to encouraging increased interaction among research groups in industry and academia."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144702"
                        ],
                        "name": "Makoto Iwayama",
                        "slug": "Makoto-Iwayama",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Iwayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Makoto Iwayama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37090109"
                        ],
                        "name": "T. Tokunaga",
                        "slug": "T.-Tokunaga",
                        "structuredName": {
                            "firstName": "Takenobu",
                            "lastName": "Tokunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tokunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 283
                            }
                        ],
                        "text": "In more general terms, the scaling problem in kNN can be reduced to the scaling problem in on-line document ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 177
                            }
                        ],
                        "text": "\u2026ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al. 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2229104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aae3851aca403fe4ea9953ec2b312ceb21bfb36",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Text categorization can be viewed asaprocessof catego~ search, in which one or more categories for a testdocument are searchedfor by using given training documents with known categories. In this paper a cluster-based search with a probabilistic clustering algorithm is proposed and evaluated on two data sets. The \u201cefficiency, effectiveness, and noise tolerance of this search strategy were confirmed to be better than those of a full search, a category-based search, and a cluster-based search with nonprobabilistic clustering."
            },
            "slug": "Cluster-based-text-categorization:-a-comparison-of-Iwayama-Tokunaga",
            "title": {
                "fragments": [],
                "text": "Cluster-based text categorization: a comparison of category search strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The \u201cefficiency, effectiveness, and noise tolerance of this search strategy were confirmed to be better than those of a full search, a category-based search, and a cluster- based search with nonprobabilistic clustering."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792682"
                        ],
                        "name": "C. Chute",
                        "slug": "C.-Chute",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Chute",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chute"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 80
                            }
                        ],
                        "text": "LLSF stands for Linear Least Squares Fit, a mapping approach developed by Yang (Yang and Chute 1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14473522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33536f0bf7925517ead9f44419617edfb24922d2",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a unique method for mapping natural language texts to canonical terms that identify the contents of the texts. This method learns empirical associations between free-form texts and canonical terms from human-assigned matches and determines a Linear Least Squares Fit (LLSF) mapping function which represents weighted connections between words in the texts and the canonical terms. The mapping function enables us to project an arbitrary text to the canonical term space where the \"transformed\" text is compared with the terms, and similarity scores are obtained which quantify the relevance between the the text and the terms. This approach has superior power to discover synonyms or related terms and to preserve the context sensitivity of the mapping. We achieved a rate of 84% in both the recall and the precision with a testing set of 6,913 texts, outperforming other techniques including string matching (15%), morphological parsing (17%) and statistical weighting (21%)."
            },
            "slug": "A-Linear-Least-Squares-Fit-Mapping-Method-for-From-Yang-Chute",
            "title": {
                "fragments": [],
                "text": "A Linear Least Squares Fit Mapping Method for Information Retrieval From Natural Language Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This method learns empirical associations between free-form texts and canonical terms from human-assigned matches and determines a Linear Least Squares Fit (LLSF) mapping function which represents weighted connections between words in the texts and the canonical terms."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428001"
                        ],
                        "name": "P. Hayes",
                        "slug": "P.-Hayes",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hayes",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053034118"
                        ],
                        "name": "S. P. Weinstein",
                        "slug": "S.-P.-Weinstein",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Weinstein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Weinstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature ( Hayes and Weinstein 1990,  Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 119
                            }
                        ],
                        "text": "CONSTRUE is an expert system developed at the Carnegie Group, and the earliest system evaluated on the Reuters corpus (Hayes and Weinstein 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(CGI) and used to evaluate their CONSTRUE system in 1990 ( Hayes and Weinstein 1990 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 143
                            }
                        ],
                        "text": "We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 135
                            }
                        ],
                        "text": "The original corpus (Reuters-22173) was provided by the Carnegie Group, Inc. (CGI) and used to evaluate their CONSTRUE system in 1990 (Hayes and Weinstein 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1. CONSTRUE is an expert system developed at the Carnegie Group, and the earliest system evaluated on the Reuters corpus ( Hayes and Weinstein 1990 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18312939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01d6d53fce6fac2a33d92ddf096290d6b99c2d13",
            "isKey": true,
            "numCitedBy": 230,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The Construe news story categorization system assigns indexing terms to news stories according to their content using knowledge-based techniques. An initial deployment of Construe in Reuters Ltd. topic identification system (TIS) has replaced human indexing for Reuters Country Reports, an online information service based on news stories indexed by country and type of news. TIS indexing is comparable to human indexing in overall accuracy but costs much less, is more consistent, and is available much more rapidly. TIS can be justified in terms of cost savings alone, but Reuters also expects the speed and consistency of TIS to provide significant competitive advantage and, hence, an increased market share for Country Reports and other products from Reuters Historical Information Products Division."
            },
            "slug": "CONSTRUE/TIS:-A-System-for-Content-Based-Indexing-a-Hayes-Weinstein",
            "title": {
                "fragments": [],
                "text": "CONSTRUE/TIS: A System for Content-Based Indexing of a Database of News Stories"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The Construe news story categorization system assigns indexing terms to news stories according to their content using knowledge-based techniques and Reuters expects the speed and consistency of TIS to provide significant competitive advantage and, hence, an increased market share for Country Reports and other products from Reuters Historical Information Products Division."
            },
            "venue": {
                "fragments": [],
                "text": "IAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688124"
                        ],
                        "name": "W. Hersh",
                        "slug": "W.-Hersh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Hersh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hersh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089238953"
                        ],
                        "name": "T. J. Leone",
                        "slug": "T.-J.-Leone",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Leone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. J. Leone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760869"
                        ],
                        "name": "D. Hickam",
                        "slug": "D.-Hickam",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hickam",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hickam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This problem is further illustrated by the OHSUMED collection ( Hersh et al. 1994 ), which is another corpus commonly used in text categorization research."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "This problem is further illustrated by the OHSUMED collection (Hersh et al. 1994), which is another corpus commonly used in text categorization research."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15094383,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "e91fc6cba8b23688d02b0dc3ead69ed05210bf33",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users. Using a commercial MEDLINE product based on the vector space model, these physicians searched just as effectively as more experienced searchers using Boolean searching. The results of this experiment were subsequently used to create a new large medical test collection, which was used in experiments with the SMART retrieval system to obtain baseline performance data as well as compare SMART with the other searchers."
            },
            "slug": "OHSUMED:-an-interactive-retrieval-evaluation-and-Hersh-Buckley",
            "title": {
                "fragments": [],
                "text": "OHSUMED: an interactive retrieval evaluation and new large test collection for research"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users using a commercial MEDLINE product based on the vector space model, finding that these physicians searched just as effectively as more experienced searchers using Boolean searching."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "Decision tree (DTree) is a well-known machine learning approach to automatic induction of classification trees based on training data (Quinlan 1986, Mitchell 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 67
                            }
                        ],
                        "text": "DNF rules are of equal power to DTrees in machine learning theory (Mitchell 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "Naive Bayes (NaiveBayes) probabilistic classi ers are also commonlyused in text categorization[11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 132
                            }
                        ],
                        "text": "Decision Tree (DTree) is a well-known machine learning approach to automatic induction of classi cation trees based on training data[16, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "DNF rules are of equal power to DTrees in machine learning theory[11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 98
                            }
                        ],
                        "text": "Naive Bayes (NaiveBayes) probabilistic classifiers are also commonly-used in text categorization (Mitchell 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6134427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aab43c9c33af00b718cf2ae374b861d49862a563",
            "isKey": true,
            "numCitedBy": 15727,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine Learning is the study of methods for programming computers to learn. Computers are applied to a wide range of tasks, and for most of these it is relatively easy for programmers to design and implement the necessary software. However, there are many tasks for which this is difficult or impossible. These can be divided into four general categories. First, there are problems for which there exist no human experts. For example, in modern automated manufacturing facilities, there is a need to predict machine failures before they occur by analyzing sensor readings. Because the machines are new, there are no human experts who can be interviewed by a programmer to provide the knowledge necessary to build a computer system. A machine learning system can study recorded data and subsequent machine failures and learn prediction rules. Second, there are problems where human experts exist, but where they are unable to explain their expertise. This is the case in many perceptual tasks, such as speech recognition, hand-writing recognition, and natural language understanding. Virtually all humans exhibit expert-level abilities on these tasks, but none of them can describe the detailed steps that they follow as they perform them. Fortunately, humans can provide machines with examples of the inputs and correct outputs for these tasks, so machine learning algorithms can learn to map the inputs to the outputs. Third, there are problems where phenomena are changing rapidly. In finance, for example, people would like to predict the future behavior of the stock market, of consumer purchases, or of exchange rates. These behaviors change frequently, so that even if a programmer could construct a good predictive computer program, it would need to be rewritten frequently. A learning program can relieve the programmer of this burden by constantly modifying and tuning a set of learned prediction rules. Fourth, there are applications that need to be customized for each computer user separately. Consider, for example, a program to filter unwanted electronic mail messages. Different users will need different filters. It is unreasonable to expect each user to program his or her own rules, and it is infeasible to provide every user with a software engineer to keep the rules up-to-date. A machine learning system can learn which mail messages the user rejects and maintain the filtering rules automatically. Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis. Statistics focuses on understanding the phenomena that have generated the data, often with the goal of testing different hypotheses about those phenomena. Data mining seeks to find patterns in the data that are understandable by people. Psychological studies of human learning aspire to understand the mechanisms underlying the various learning behaviors exhibited by people (concept learning, skill acquisition, strategy change, etc.)."
            },
            "slug": "Machine-learning-Dietterich",
            "title": {
                "fragments": [],
                "text": "Machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144987107"
                        ],
                        "name": "Jamie Callan",
                        "slug": "Jamie-Callan",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Callan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Callan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47394834"
                        ],
                        "name": "R. Papka",
                        "slug": "R.-Papka",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Papka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Papka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 22
                            }
                        ],
                        "text": "Another common measure[12, 8, 2] is called the F -measure, de ned to be: F (r; p) = ( 2 + 1)pr 2p+ r where is the parameter allowing di erential weighting of p and r."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 319
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 18], nearest neighbor classi ers[3, 19], Bayes belief networks [14, 9], decision trees[5, 9, 11], rule learning algorithms[1, 15, 12], neural networks[15] and inductive learning techniques[2, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 279
                            }
                        ],
                        "text": "\u2026trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer 1996, Lewis et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 119
                            }
                        ],
                        "text": "This method is easy to implement and efficient in computation, and has been used as a baseline in several evaluations (Lewis et al. 1996, Cohen and Singer 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "An exponentiated gradient (EG) inductive learning algorithm which approximates a least squares t [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 269
                            }
                        ],
                        "text": "Rocchio, a vector space model for classi cation where a training set of documents are used to construct a prototype vector for each category, and category ranking given a document is based on a similarity comparison between the document vector and the category vectors [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "The Widrow-Ho (WH) inductive learning algorithm which approximates a least squares t[8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 243
                            }
                        ],
                        "text": "The OHSUMED collection has been used with the full range of categories (14,321 MeSH categories actually occurred) in some experiments[17], or with a subset of categories in the heart disease sub-domain (HD, 119 categories) in other experiments[8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1650587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dc36b8d0c08613fb213ad419973d379a2264765",
            "isKey": true,
            "numCitedBy": 620,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Systems for text retrieval, routing, categorization and other IR tasks rely heavily on linear classifiers. We propose that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers. In contrast to most IR methods, theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms. Experimental data is presented showing Widrow-Hoff and EG to be more effective than the widely used Rocchio algorithm on several categorization and routing tasks."
            },
            "slug": "Training-algorithms-for-linear-text-classifiers-Lewis-Schapire",
            "title": {
                "fragments": [],
                "text": "Training algorithms for linear text classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work proposes that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers for IR tasks, and theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912499"
                        ],
                        "name": "Michael Persin",
                        "slug": "Michael-Persin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Persin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Persin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Clearly, a carefully conducted comparative study across methods and experiments is useful, at least for observation on significant performance variations due to different choices in approaches, parameter settings, domains and tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "\u2026problem in on-line document ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9620478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ab90fadbcc3b5e09c2af41b93bf2f9c576012b2",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Ranking techniques are effective for finding answers in document collections but the cost of evaluation of ranked queries can be unacceptably high. We propose an evaluation technique that reduces both main memory usage and query evaluation time. based on early recognition of which documents are likely to be highly ranked. Our experiments show that, for our test data, the proposed technique evaluates queries in 20% of the time and 2% of the memory taken by the standard inverted file implementation, without degradation in retrieval effectiveness."
            },
            "slug": "Document-filtering-for-fast-ranking-Persin",
            "title": {
                "fragments": [],
                "text": "Document filtering for fast ranking"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The experiments show that the proposed evaluation technique reduces both main memory usage and query evaluation time, based on early recognition of which documents are likely to be highly ranked, without degradation in retrieval effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103447"
                        ],
                        "name": "S. Hartmann",
                        "slug": "S.-Hartmann",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Hartmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hartmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084356644"
                        ],
                        "name": "G. Lustig",
                        "slug": "G.-Lustig",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Lustig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lustig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1959019"
                        ],
                        "name": "M. Schwantner",
                        "slug": "M.-Schwantner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schwantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schwantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334474"
                        ],
                        "name": "Kostas Tzeras",
                        "slug": "Kostas-Tzeras",
                        "structuredName": {
                            "firstName": "Kostas",
                            "lastName": "Tzeras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kostas Tzeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084310078"
                        ],
                        "name": "Gerhard Knorz",
                        "slug": "Gerhard-Knorz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Knorz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerhard Knorz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 129
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 146
                            }
                        ],
                        "text": "\u2026et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 127
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 18], nearest neighbor classi ers[3, 19], Bayes belief networks [14, 9], decision trees[5, 9, 11], rule learning algorithms[1, 15, 12], neural networks[15] and inductive learning techniques[2, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15004699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f61812ea95500993fada9f12c23577d2ba670d33",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "AIR/X is a rule-based system for indexing with terms (descriptors) from a prescribed vocabulary. For this task, an indexing dictionary with rules for mapping terms from the text onto descriptors is required, which can be derived automatically from a set of manually indexed documents. Based on the Darmstadt Indexing Approach, the indexing task is divided into a description step and a decision step. First, terms (single words or phrases) are identiied in the document text. With term-descriptor rules from the dictionary, descriptor indications are formed. The set of all indications from a document leading to the same descriptor is called a relevance description. A probabilistic classiication procedure computes indexing weights for each relevance description. Since the whole system is rule-based, it can be adapted to diierent subject elds by appropriate modiications of the rule bases. A major application of AIR/X is the AIR/PHYS system developed for a large physics database. This application is described in more detail along with experimental results."
            },
            "slug": "AIR/X-A-rule-based-multistage-indexing-system-for-Fuhr-Hartmann",
            "title": {
                "fragments": [],
                "text": "AIR/X - A rule-based multistage indexing system for Iarge subject fields"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A rule-based system for indexing with terms (descriptors) from a prescribed vocabulary, AIR/X is the AIR/PHYS system developed for a large physics database and can be adapted to diierent subject elds by appropriate modiications of the rule bases."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889602"
                        ],
                        "name": "Erik D. Wiener",
                        "slug": "Erik-D.-Wiener",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Wiener",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik D. Wiener"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024710"
                        ],
                        "name": "A. Weigend",
                        "slug": "A.-Weigend",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Weigend",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weigend"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 187
                            }
                        ],
                        "text": "\u2026trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer 1996, Lewis et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "Neural network (NNet) approaches to text categorization were evaluated on Reuters by Wiener et al. (1995) and Ng et al. (1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "Pcut is an abbreviation ofproportional assignment, a method which has been used in previous text categorization research (Lewis and Ringuette 1994, Wiener et al. 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 140
                            }
                        ],
                        "text": "Reuters version 4 was constructed by the research group at Xerox PARC, and was used for their evaluation of their neural network approaches (Wiener et al. 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 275
                            }
                        ],
                        "text": "\u2026from the training and test sets and restricting the categories to have a training-set frequency of at least two (Apte et al. 1994).3\nReuters version 4 was constructed by the research group at Xerox PARC, and was used for their evaluation of their neural network approaches (Wiener et al. 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 149
                            }
                        ],
                        "text": "\u2026various versions of the Reuters corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17503448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abbe40b7503f51971c92f9f9b20ebea6c0b36d77",
            "isKey": true,
            "numCitedBy": 459,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an application of nonlinear neural networks to topic spotting. Neural networks allow us to model higher-order interaction between document terms and to simultaneously predict multiple topics using shared hidden features. In the context of this model, we compare two approaches to dimensionality reduction in representation: one based on term selection and another based on Latent Semantic Indexing (LSI). Two diierent methods are proposed for improving LSI representations for the topic spotting task. We nd that term selection and our modiied LSI representations lead to similar topic spotting performance, and that this performance is equal to or better than other published results on the same corpus."
            },
            "slug": "A-neural-network-approach-to-topic-spotting-Wiener-Pedersen",
            "title": {
                "fragments": [],
                "text": "A neural network approach to topic spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that term selection and the modiied LSI representations lead to similar topic spotting performance, and that this performance is equal to or better than other published results on the same corpus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334474"
                        ],
                        "name": "Kostas Tzeras",
                        "slug": "Kostas-Tzeras",
                        "structuredName": {
                            "firstName": "Kostas",
                            "lastName": "Tzeras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kostas Tzeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103447"
                        ],
                        "name": "S. Hartmann",
                        "slug": "S.-Hartmann",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Hartmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hartmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "\u2026models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 206
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 26], nearest neighbor classi ers[4, 22], Bayesian probabilistic classi ers [19, 10, 12], decision trees[5, 10, 12], inductive rule learning algorithms[1, 3, 13], neural networks[21, 14] and on-line learning approaches[3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2861704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a283fb395343cd26984425306ca24c85b09ccdb",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a Bayesian inference network model for automatic indexing with index terms (descriptors) from a prescribed vocabulary is presented. It requires an indexing dictionary with rules mapping terms of the respective subject field onto descriptors and inverted lists for terms occuring in a set of documents of the subject field and descriptors manually assigned to these documents. The indexing dictionary can be derived automatically from a set of manually indexed documents. An application of the network model is described, followed by an indexing example and some experimental results about the indexing performance of the network model."
            },
            "slug": "Automatic-indexing-based-on-Bayesian-inference-Tzeras-Hartmann",
            "title": {
                "fragments": [],
                "text": "Automatic indexing based on Bayesian inference networks"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A Bayesian inference network model for automatic indexing with index terms (descriptors) from a prescribed vocabulary is presented, followed by an indexing example and some experimental results about the indexing performance of the network model."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 135
                            }
                        ],
                        "text": "Decision tree (DTree) is a well-known machine learning approach to automatic induction of classification trees based on training data (Quinlan 1986, Mitchell 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 132
                            }
                        ],
                        "text": "Decision Tree (DTree) is a well-known machine learning approach to automatic induction of classi cation trees based on training data[16, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13252401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcee7c85d237b79491a773ef51e746bbbcf48e35",
            "isKey": false,
            "numCitedBy": 13490,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions."
            },
            "slug": "Induction-of-Decision-Trees-Quinlan",
            "title": {
                "fragments": [],
                "text": "Induction of Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail, which is described in detail."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 160
                            }
                        ],
                        "text": "For the global evaluation of a classifier on a collection of test documents, we adapt the procedure for the conventionalinterpolated11-point average precision (Salton and McGill 1983), as described below:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 159
                            }
                        ],
                        "text": "For the global evaluation of a classifier on a collection of test documents, we adapt the procedure for the conventionalinterpolated11-point average precision (Salton and McGill 1983), as described below:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43685115,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "49af3e80343eb80c61e727ae0c27541628c7c5e2",
            "isKey": false,
            "numCitedBy": 12605,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here."
            },
            "slug": "Introduction-to-Modern-Information-Retrieval-Salton-McGill",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Reading is a need and a hobby at once and this condition is the on that will make you feel that you must read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40199624"
                        ],
                        "name": "R. Creecy",
                        "slug": "R.-Creecy",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Creecy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Creecy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127759"
                        ],
                        "name": "B. Masand",
                        "slug": "B.-Masand",
                        "structuredName": {
                            "firstName": "Brij",
                            "lastName": "Masand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Masand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111051178"
                        ],
                        "name": "Stephen J. Smith",
                        "slug": "Stephen-J.-Smith",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smith",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen J. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 279
                            }
                        ],
                        "text": "\u2026ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al. 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 146
                            }
                        ],
                        "text": "\u2026been applied to this problem in recent years, including regression models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18744432,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "7403fa3e56cee44e0f48185bb4a79d935eb9b01c",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "mission to profile and economy of ~e Census Bureau ~dustry and occupation data for individuals in the labor force. For the 1990 Decennial Census, each of an estimated 22 million natural language responses to questions on the census long form had to be classified into one of 232 industry categories and 504 occupation categories. If done fully by hand the cost of this task would be on the order of $15 million."
            },
            "slug": "Trading-MIPS-and-memory-for-knowledge-engineering-Creecy-Masand",
            "title": {
                "fragments": [],
                "text": "Trading MIPS and memory for knowledge engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "mission to profile and economy of ~e Census Bureau ~dustry and occupation data for individuals in the labor force, for the 1990 Decennial Census, which had to be classified into one of 232 industry categories and 504 occupation categories."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066731516"
                        ],
                        "name": "Timothy A. H. Bell",
                        "slug": "Timothy-A.-H.-Bell",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Bell",
                            "middleNames": [
                                "A.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy A. H. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144448479"
                        ],
                        "name": "Alistair Moffat",
                        "slug": "Alistair-Moffat",
                        "structuredName": {
                            "firstName": "Alistair",
                            "lastName": "Moffat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alistair Moffat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026on-line document ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Clearly, a carefully conducted comparative study across methods and experiments is useful, at least for observation on significant performance variations due to different choices in approaches, parameter settings, domains and tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11806907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3463043bd42fc61fd462c4afa139d849896d2d3b",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A high performance information filtering system has three mainrequirements: it must be effective in supplying users with usefulinformation, it must do so in a timely fashion, and it must be ableto handle a large throughput of information and a large number ofuser profiles efficiently. These three requirements pose adifficult problem, and to our knowledge no existing system iscapable of meeting all three. In this paper we describe a systemwhich combines a number of techniques from other informationretrieval and filtering systems, and is capable of providing highperformance on a typical workstation platform. We provide estimatesof computing resource usage, and show that our system is alsoscalable."
            },
            "slug": "The-design-of-a-high-performance-information-system-Bell-Moffat",
            "title": {
                "fragments": [],
                "text": "The design of a high performance information filtering system"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A system which combines a number of techniques from other information retrieval and filtering systems, and is capable of providing high performance on a typical workstation platform is described."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085813334"
                        ],
                        "name": "Isabelle Moulinier",
                        "slug": "Isabelle-Moulinier",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Moulinier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isabelle Moulinier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 108
                            }
                        ],
                        "text": "A naive Bayes model (NaiveBayes) for classi cation where word independence is assumed in category prediction[9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 169861341,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "124d181e21d24887e208923bd1f848d6107a5e72",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "L'objectif principal des travaux presentes dans cette these est de determiner si la classification automatique, en particulier au moyen de l'apprentissage symbolique supervise, peut etre appliquee a la categorisation de documents, tache qui permet d'affecter des categories semantiques a des documents en fonction de leur contenu. Le memoire s'articule autour de deux axes complementaires. L'axe principal consiste a determiner si les techniques d'apprentissage apportent des solutions aux preoccupations de la recherche documentaire, en particulier le filtrage de documents. Dans cette optique, il est necessaire de prendre en compte les caracteristiques des collections textuelles, en particulier celles liees aux dimensions des donnees textuelles (plusieurs milliers d'exemples et des dizaines de milliers d'attributs), qui sortent du cadre classique des applications de l'apprentissage. Ce probleme constitue le second axe de notre travail. Pour des raisons de complexite, notre demarche est d'introduire une etape prealable de selection d'attributs avant tout apprentissage. Ceci nous conduit a proposer une methode originale de reduction, appelee scar, qui tire parti des caracteristiques des donnees textuelles. Nous comparons scar a deux methodes classiques pour la reduction de dimension. Nous evaluons ces methodes sur la collection reuters-22 173, dont la taille est consequente. Nous nous interessons ensuite aux liens entre le presuppose d'apprentissage (nature de l'apprentissage) et les donnees textuelles, dans l'optique d'une application au filtrage. Nos resultats montrent que, malgre la relative equivalence observee en moyenne en comparant les differents algorithmes proposes, on peut distinguer une reelle influence du presuppose d'apprentissage sur la performance de l'algorithme, lorsque celui est applique a certaines classes de problemes que nous avons identifie."
            },
            "slug": "Une-approche-de-la-categorisation-de-textes-par-Moulinier",
            "title": {
                "fragments": [],
                "text": "Une approche de la categorisation de textes par l'apprentissage symbolique"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 127
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 18], nearest neighbor classi ers[3, 19], Bayes belief networks [14, 9], decision trees[5, 9, 11], rule learning algorithms[1, 15, 12], neural networks[15] and inductive learning techniques[2, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": "Thorough investigations on suitable choices of these parameter values were reported in previous papers where the main observations were that the performance of kNN is relatively stable for a large range ofk values (Yang 1994), and that satisfactory performance of LLSF depends on whetherp is sufficiently large (Yang 1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "A formatted version of this collection was prepared by Yang and colleagues, and is currently available at Carnegie Mellon University\u2019s web site through http://moscow.mt.cs.cmu.edu:8081/reuters21450/apte."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 342,
                                "start": 338
                            }
                        ],
                        "text": "In more general terms, the scaling problem in kNN can be reduced to the scaling problem in on-line document ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al. 1992)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer 1996, Lewis et al. 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "The training phase has a quadratic time complexity,O(pn\u2032) wherep is the number of singular vectors used for computing an approximated LLSF solution (Yang 1995), and n\u2032 = max{m, n} is the larger number betweenn, the number of training documents, and m, the number of unique terms in the training documents."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 279
                            }
                        ],
                        "text": "We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three systems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 233
                            }
                        ],
                        "text": "In the further scaling test of kNN on OHSUMED, we observed 11.5 CPU minutes for the indexing of 183,229 training documents, and an on-line response of 1.0 CPU second per test document on average, with a micro-averageF1 value of .49 (Yang 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 80
                            }
                        ],
                        "text": "LLSF stands for Linear Least Squares Fit, a mapping approach developed by Yang (Yang and Chute 1992)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "A formatted version of this collection was prepared by Yang and colleagues, and is electronically available at http://moscow.mt.cs.cmu.edu:8081/reuters21450/parc/."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Using the inverted-file indexing of training documents, the time complexity isO(ln/m) (Yang 1994) wherel is the number of unique words in the document,n is the number of training documents, andm is the number of unique terms in the training collection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "LLSF, a linear least squares t (LLSF) approach to classi cation [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 242
                            }
                        ],
                        "text": "Five feature selection criteria were tested with kNN and LLSF, including information gain, mutual exclusion, a\u03c72 statistic, document frequency and term strength; a thorough evaluation of these feature selection methods was reported elsewhere (Yang and Pederson 1997)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A linear least squares t mapping method for information retrieval from natural  language texts"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the 14th International Conference on Computational Linguistics (COLING"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 25
                            }
                        ],
                        "text": "Even more interestingly, Moulinier recently reported the result of a DTree algorithm as 0.79 inF1, which is close to SWAP-1\u2019s score in BEP on Reuters 3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 100
                            }
                        ],
                        "text": "I would like to thank Jan Pedersen at Infoseek, David Lewis and William Cohen at AT&T, and Isabelle Moulinier at University of Paris VI for providing information on their experiments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 92
                            }
                        ],
                        "text": "Evaluation results of NaiveBayes on Reuters were reported by Lewis and Ringuette (1994) and Moulinier (1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Evaluation results of NaiveBayes on Reuters were reported by Lewis & Ringuette[10] and Moulinier[12], respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 327,
                                "start": 318
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer 1996, Lewis et al. 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 206
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 26], nearest neighbor classi ers[4, 22], Bayesian probabilistic classi ers [19, 10, 12], decision trees[5, 10, 12], inductive rule learning algorithms[1, 3, 13], neural networks[21, 14] and on-line learning approaches[3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "\u2026nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 200
                            }
                        ],
                        "text": "Evaluation result of DTree algorithms on the Reuters text categorization collection were reported by Lewis and Ringuette (using the IND package) (Lewis and Ringuette 1994) and Moulinier (using C4.5) (Moulinier 1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 233
                            }
                        ],
                        "text": "We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three systems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 129
                            }
                        ],
                        "text": "Inductive rule learning in Disjunctive Normal Form (DNF) was tested in the WASP-1, RIPPER and CHARADE systems (Apte et al. 1994, Moulinier et al. 1996, Cohen and Singer 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 142
                            }
                        ],
                        "text": "\u2026classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is learning bias an issue on the text categorization problem? In Technical report, LAFORIA-LIP6"
            },
            "venue": {
                "fragments": [],
                "text": "Universite  Paris VI,"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 34
                            }
                        ],
                        "text": "A phrasing option is available in SMART but has not been used in these experiments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 170
                            }
                        ],
                        "text": "I would also like to thank Jaime Carbonell at Carnegie Mellon University for suggesting an improvement in binary decision making, Chris Buckley at Cornell for making the SMART system available, and Tom Ault for many valuable suggestions for improving the writing of this paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "The conventional 11-point average precision[13] was used to measure the goodness of category ranking."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 154
                            }
                        ],
                        "text": "The conventional vector space model is used for representing documents and category names (each name is treated as a bag of words), and the SMART system (Salton 1989) is used as the search engine."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 82
                            }
                        ],
                        "text": "Feature selection is the next step after stop words are removed from documents by SMART."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "The conventional Vector Space Model is used for representing documents and category names (each name is treated as a bag of words), and the SMART system [13] is used as the search engine."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "The conventional 11-point average precision is used to measure the performance of a classi er on a collection of documents[13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 43
                            }
                        ],
                        "text": "The bench-marking retrieval system, SMART (Salton 1989), is used as a unified preprocessor for the kNN, LLSF and WORD systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 85
                            }
                        ],
                        "text": "Several typical term-weighting options were tested, including \u201cltc\u201d, \u201catc\u201d, \u201cntc\u201d, etc. in SMART\u2019s notation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 34382228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f2f6772d96d972e3b2da5aaa8a0f2feefdf827f",
            "isKey": true,
            "numCitedBy": 3884,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-Text-Processing:-The-Transformation,-and-Salton",
            "title": {
                "fragments": [],
                "text": "Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 109
                            }
                        ],
                        "text": "Inductive rule learning in Disjunctive Normal Form (DNF) was tested in the WASP-1, RIPPER and CHARADE systems[1, 13, 3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "\u2026trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al. 1995, Ng et al. 1997) and on-line learning approaches (Cohen and Singer 1996, Lewis et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 281
                            }
                        ],
                        "text": "A growing number of statistical learning methods have been applied to this problem in recent years, including regression models[5, 26], nearest neighbor classi ers[4, 22], Bayesian probabilistic classi ers [19, 10, 12], decision trees[5, 10, 12], inductive rule learning algorithms[1, 3, 13], neural networks[21, 14] and on-line learning approaches[3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026the Reuters corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 129
                            }
                        ],
                        "text": "Inductive rule learning in Disjunctive Normal Form (DNF) was tested in the WASP-1, RIPPER and CHARADE systems (Apte et al. 1994, Moulinier et al. 1996, Cohen and Singer 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 153
                            }
                        ],
                        "text": "Classifiers We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature[6, 10, 1, 21, 13, 3, 27, 14] 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text categorization: A symbolic approach"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth Annual Symposium on Document Analysis and Information Retrieval"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 149
                            }
                        ],
                        "text": "\u2026learning methods have been applied to this problem in recent years, including regression models (Fuhr et al. 1991, Yang and Chute 1994), nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 233
                            }
                        ],
                        "text": "In the further scaling test of kNN on OHSUMED, we observed 11.5 CPU minutes for the indexing of 183,229 training documents, and an on-line response of 1.0 CPU second per test document on average, with a micro-averageF1 value of .49 (Yang 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An evaluation of statistical approach to text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report CMU-CS-97-127,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 92
                            }
                        ],
                        "text": "Evaluation results of NaiveBayes on Reuters were reported by Lewis and Ringuette (1994) and Moulinier (1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: text categorization, statistical learning algorithms, comparative study, evaluation"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "\u2026nearest neighbor classifiers (Creecy et al. 1992, Yang 1994), Bayesian probabilistic classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 200
                            }
                        ],
                        "text": "Evaluation result of DTree algorithms on the Reuters text categorization collection were reported by Lewis and Ringuette (using the IND package) (Lewis and Ringuette 1994) and Moulinier (using C4.5) (Moulinier 1997), respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 142
                            }
                        ],
                        "text": "\u2026classifiers (Tzeras and Hartman 1993, Lewis and Ringuette 1994, Moulinier 1997), decision trees (Fuhr et al. 1991, Lewis and Ringuette 1994, Moulinier 1997), inductive rule learning algorithms (Apte et al. 1994, Cohen and Singer 1996, Moulinier et al. 1996), neural networks (Wiener et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is learning bias an issue on the text categorization problem"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 183
                            }
                        ],
                        "text": "\u2026corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 231
                            }
                        ],
                        "text": "\u2026ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al. 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 241
                            }
                        ],
                        "text": "Five feature selection criteria were tested with kNN and LLSF, including information gain, mutual exclusion, a 2 statistic, document frequency and term strength; a thorough evaluation of these feature selection methods was reported elsewhere[27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 153
                            }
                        ],
                        "text": "Classifiers We consider the text categorization systems whose results on the various versions of the Reuters corpus have been published in the literature[6, 10, 1, 21, 13, 3, 27, 14] 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature selection in statistical learning of text cat egorization"
            },
            "venue": {
                "fragments": [],
                "text": "In The Fourteenth International Conference on Machine Learning,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Overview of the Third T ext REtrieval Conference (TREC-3). U S G o vernment Printing OOce"
            },
            "venue": {
                "fragments": [],
                "text": "Overview of the Third T ext REtrieval Conference (TREC-3). U S G o vernment Printing OOce"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A formatted version of this collection was prepared by Yang and colleagues, and is electronically available at http"
            },
            "venue": {
                "fragments": [],
                "text": "A formatted version of this collection was prepared by Yang and colleagues, and is electronically available at http"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is learning bias an issue on the text categorization problem ?"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparison of two learning algorithms for text categorization Une approche de la cat \u0013 egorisation de textes par l \u0013 apprentissage symbolique"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 361,
                                "start": 337
                            }
                        ],
                        "text": "In more general terms, the scaling problem in kNN can be reduced to the scaling problem in on-line document ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 183
                            }
                        ],
                        "text": "\u2026corpus have been published in the literature (Hayes and Weinstein 1990, Lewis and Ringuette 1994, Apte et al. 1994, Wiener et al. 1995, Moulinier et al. 1996, Cohen and Singer 1996, Yang and Pedersen 1997, Ng et al. 1997).1 In addition to these results, we present new results of three systems."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 231
                            }
                        ],
                        "text": "\u2026ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel computing (Creecy et al. 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature selection in statistical learning of text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "In: 14th International Conference on Machine Learning,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A personal contact in the Carnegie Group confirmed that Reuters does not always categorize all of their news stories"
            },
            "venue": {
                "fragments": [],
                "text": "A personal contact in the Carnegie Group confirmed that Reuters does not always categorize all of their news stories"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cohen and Yoram Singer . Context - sensitive learning metods for text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR ' 96 : Proceedings of the 19 th Annual International ACM SIGIR Conference on Research and Development inInformation Retrieval"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The design of a high performance information ltering system"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 19th Ann Int ACM SIGIR Conference o n R esearch and Development in Information Retrieval (SIGIR'96), pages 12{20"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Eval of Stat Appr to TC"
            },
            "venue": {
                "fragments": [],
                "text": "An Eval of Stat Appr to TC"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "\u2026problem in on-line document ranking, for which a number of techniques have been studied in the literature, including partial indexing and ranking (Persin 1994, Bell and Moffat 1996), document clustering (Iwayama and Tokunaga 1995), dimensionality reduction (Yang and Pedersen 1997) and parallel\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document ltering for fast ranking"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th Ann Int ACM SIGIR Conference o n Research and Development in Information Retrieval (SIGIR'94), pages 341{348"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A formatted version of this collection was prepared by Yang and colleagues, and is currently available at Carnegie Mellon University's web site through http"
            },
            "venue": {
                "fragments": [],
                "text": "A formatted version of this collection was prepared by Yang and colleagues, and is currently available at Carnegie Mellon University's web site through http"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 160
                            }
                        ],
                        "text": "For the global evaluation of a classifier on a collection of test documents, we adapt the procedure for the conventionalinterpolated11-point average precision (Salton and McGill 1983), as described below:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval. M c G r a w-Hill Computer Science Series"
            },
            "venue": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval. M c G r a w-Hill Computer Science Series"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "Decision tree (DTree) is a well-known machine learning approach to automatic induction of classification trees based on training data (Quinlan 1986, Mitchell 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 98
                            }
                        ],
                        "text": "Naive Bayes (NaiveBayes) probabilistic classifiers are also commonly-used in text categorization (Mitchell 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 67
                            }
                        ],
                        "text": "DNF rules are of equal power to DTrees in machine learning theory (Mitchell 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine Learning. McCraw Hill"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning. McCraw Hill"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 27
                            }
                        ],
                        "text": "The F1 measure, defined by van Rijsbergen (1979), is another common choice for a single-numbered performance measure:\nF1 = 2rp/(r + p)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 31
                            }
                        ],
                        "text": "The F1 measure, defined by van Rijsbergen (1979), is another common choice for a single-numbered performance measure:\nF1 = 2rp/(r + p)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths, London"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 160
                            }
                        ],
                        "text": "For the global evaluation of a classifier on a collection of test documents, we adapt the procedure for the conventionalinterpolated11-point average precision (Salton and McGill 1983), as described below:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "For the global evaluation of a classi er on a collection of test documents, we adapt the procedure for the conventional interpolated 11-point average precision[18], as described below: 4 A formatted version of this collection was prepared by Y."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval.  McGraw-Hill Computer Science Series"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Une approche de la cat egorisation de textes par ll apprentissage symbolique"
            },
            "venue": {
                "fragments": [],
                "text": "Une approche de la cat egorisation de textes par ll apprentissage symbolique"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cohen and Yoram Singer . Context - sensitive learning metods fortext categorization"
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR ' 96 : Proceedings of the 19 th Annual International ACM SIGIR Conference on Research and Development in InformationRetrieval"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 36,
            "result": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 50,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/An-Evaluation-of-Statistical-Approaches-to-Text-Yang/890c16ca29a781a7b793c603822ffd57aee9f57f?sort=total-citations"
}