{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47137139"
                        ],
                        "name": "Yael Karov",
                        "slug": "Yael-Karov",
                        "structuredName": {
                            "firstName": "Yael",
                            "lastName": "Karov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yael Karov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 277
                            }
                        ],
                        "text": "\u2026require sense-labels like\n\u2013 correct translation of ambiguous words \u2013 correct pronunciation of ambiguous words\n\u2022 some don\u2019t\n\u2013 Information Retrieval (selection of sense cluster in the result)\nJens Illig 2011-05-09 page 5\nVectorspace Model\nregular first-order co-occurrence (NOT used):\n... Bla | bla."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5094637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3aaab199ee6baaa15f09c1f01ccf3d4b56212ed",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for automatic word sense disambiguation using a text corpus and a machine-readable dictionary (MRD). The method is based on word similarity and context similarity measures. Words are considered similar if they appear in similar contexts; contexts are similar if they contain similar words. The circularity of this definition is resolved by an iterative, converging process, in which the system learns from the corpus a set of typical usages for each of the senses of the polysemous word listed in the MRD. A new instance of a polysemous word is assigned the sense associated with the typical usage most similar to its context. Experiments show that this method performs well, and can learn even from very sparse training data."
            },
            "slug": "Learning-Similarity-based-Word-Sense-Disambiguation-Karov-Edelman",
            "title": {
                "fragments": [],
                "text": "Learning Similarity-based Word Sense Disambiguation from Sparse Data"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A method for automatic word sense disambiguation using a text corpus and a machine-readable dictionary (MRD) based on word similarity and context similarity measures that performs well, and can learn even from very sparse training data."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@COLING"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 58
                            }
                        ],
                        "text": "... Venus and Mars are fellow planets of the Earth ...\nJens Illig 2011-05-09 page 8\nWord Vectors\nroom\nthings\nastronaut\nbla\nroom\n... Bla | bla."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14842061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ff0a2bf7bfc077ddea9f91552d8b59e1d386116",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes an algorithm for word sense disambiguation based on a vector representation of word similarity derived from lexical co-occurrence. It diiers from standard approaches by allowing for as ne grained distinctions as is warranted by the information at hand, rather than supposing a xed number of senses per word, and by allowing for more than one sense to be assigned to a given word occurrence. The algorithm is applied to the standard vector-space information retrieval model and an evaluation is performed over the Category B TREC-1 corpus (WSJ subcollection). Results show that this sense disambiguation algorithm improves performance by between 7% and 14% on average ."
            },
            "slug": "Information-Retrieval-Based-on-Word-Senses-Pedersen",
            "title": {
                "fragments": [],
                "text": "Information Retrieval Based on Word Senses"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An algorithm for word sense disambiguation based on a vector representation of word similarity derived from lexical co-occurrence is proposed and an evaluation is performed over the Category B TREC-1 corpus (WSJ subcollection)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2001885"
                        ],
                        "name": "Ted Pedersen",
                        "slug": "Ted-Pedersen",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Pedersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2614094"
                        ],
                        "name": "Rebecca F. Bruce",
                        "slug": "Rebecca-F.-Bruce",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bruce",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca F. Bruce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50547416475df1716769f569e0c6f6f99293f77",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an experimental comparison of three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text. The methods described in this paper, McQuitty's similarity analysis, Ward's minimum-variance method, and the EM algorithm, assign each instance of an ambiguous word to a known sense definition based solely on the values of automatically identifiable features in text. These methods and feature sets are found to be more successful in disambiguating nouns rather than adjectives or verbs. Overall, the most accurate of these procedures is McQuitty's similarity analysis in combination with a high dimensional feature set. 1 I n t r o d u c t i o n Statistical methods for natural language processing are often dependent on the availability of costly knowledge sources such as manually annotated text or semantic networks. This limits the applicability of such approaches to domains where this hard to acquire knowledge is already available. This paper presents three unsupervised learning algorithms that are able to distinguish among the known senses (i.e., as defined in some dictionary) of a word, based only on features that can be automatically extracted from untagged text. The object of unsupervised learning is to determine the class membership of each observation (i.e. each object to be classified), in a sample without using training examples of correct classifications. We discuss three algorithms, McQuitty's similarity analysis (McQuitty, 1966), Ward's minimum-variance method (Ward, 1963) and the EM algorithm (Dempster, Laird, and Rubin, 1977), that can be used to distinguish among the known senses of an ambiguous word without the aid of disambiguated examples. The EM algorithm produces maximum likelihood estimates of the parameters of a probabilistic model, where that model has been specified in advance. Both Ward's and McQuitty's methods are agglomerative clustering algorithms that form classes of unlabeled observations that minimize their respective distance measures between class members. The rest of this paper is organized as follows. First, we present introductions to Ward's and McQuitty 's methods (Section 2) and the EM algorithm (Section 3). We discuss the thirteen words (Section 4) and the three feature sets (Section 5) used in our experiments. We present our experimental results (Section 6) and close with a discussion of related work (Section 7). 2 Agglomerat ive Clustering In general, clustering methods rely on the assumption that classes occupy distinct regions in the feature space. The distance between two points in a multi-dimensional space can be measured using any of a wide variety of metrics (see, e.g. (Devijver and Kittler, 1982)). Observations are grouped in the manner that minimizes the distance between the members of each class. Ward's and McQuitty's method are agglomerative clustering algorithms that differ primarily in how they compute the distance between clusters. All such algorithms begin by placing each observation in a unique cluster, i.e. a cluster of one. The two closest clusters are merged to form a new cluster that replaces the two merged clusters. Merging of the two closest clusters continues until only some specified number of clusters remain. However, our data does not immediately lend itself to a distance-based interpretation. Our features represent part-of-speech (POS) tags, morphological characteristics, and word co-occurrence; such features are nominal and their values do not have scale. Given a POS feature, for example, we could choose noun = 1, verb = 2, adjective = 3, and adverb = 4. That adverb is represented by a larger number than noun is purely coincidental and implies nothing about the relationship between nouns and adverbs. Thus, before we employ either clustering algo-"
            },
            "slug": "Distinguishing-Word-Senses-in-Untagged-Text-Pedersen-Bruce",
            "title": {
                "fragments": [],
                "text": "Distinguishing Word Senses in Untagged Text"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An experimental comparison of three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text using McQuitty's similarity analysis, Ward's minimum-variance method, and the EM algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226331"
                        ],
                        "name": "C. Leacock",
                        "slug": "C.-Leacock",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Leacock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leacock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804836"
                        ],
                        "name": "G. Towell",
                        "slug": "G.-Towell",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Towell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Towell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2946526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b53b6b7ffd1435c2c6a1b6684f9975b73648d131",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The three corpus-based statistical sense resolution methods studied here attempt to infer the correct sense of a polysemous word by using knowledge about patterns of word cooccurrences. The techniques were based on Bayesian decision theory, neural, networks, and content vectors as used in information retrieval. To understand these methods better, we posed a very specific problem: given a set of contexts, each containing the noun line in a known sense, construct a classifier that selects the correct sense of line for new contexts. To see how the degree of polysemy affects performance, results from three- and six-sense tasks are compared.The results demonstrate that each of the techniques is able to distinguish six senses of line with an accuracy greater than 70%. Furthermore, the response patterns of the classifiers are, for the most part, statistically indistinguishable from one another. Comparison of the two tasks suggests that the degree of difficulty involved in resolving individual senses is a greater performance factor than the degree of polysemy."
            },
            "slug": "Corpus-Based-Statistical-Sense-Resolution-Leacock-Towell",
            "title": {
                "fragments": [],
                "text": "Corpus-Based Statistical Sense Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "Three corpus-based statistical sense resolution methods studied here attempt to infer the correct sense of a polysemous word by using knowledge about patterns of word cooccurrences, based on Bayesian decision theory, neural, networks, and content vectors."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 350665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59407446503d49a8cf5f5643b17502835b62f139",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an automatic indexing procedure that uses the \u201cIS-A\u201d relations contained within WordNet and the set of nouns contained in a text to select a sense for each plysemous noun in the text. The result of the indexing procedure is a vector in which some of the terms represent word senses instead of word stems. Retrieval experiments comparing the effectivenss of these sense-based vectors vs. stem-based vectors show the stem-based vectors to be superior overall, although the sense-based vectors do improve the performance of some queries. The overall degradation is due in large part to the difficulty of disambiguating senses in short query statements. An analysis of these results suggests two conclusions: the IS-A links define a generalization/specialization hierarchy that is not sufficient to reliably select the correct sense of a noun from the set of fine sense distinctions in WordNet; and missing correct matches because of incorrect sense resolution has a much more deleterious effect on retrieval performance than does making spurious matches."
            },
            "slug": "Using-WordNet-to-disambiguate-word-senses-for-text-Voorhees",
            "title": {
                "fragments": [],
                "text": "Using WordNet to disambiguate word senses for text retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The IS-A links define a generalization/specialization hierarchy that is not sufficient to reliably select the correct sense of a noun from the set of fine sense distinctions in WordNet; and missing correct matches because of incorrect sense resolution has a much more deleterious effect on retrieval performance than does making spurious matches."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872595"
                        ],
                        "name": "Robert Krovetz",
                        "slug": "Robert-Krovetz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Krovetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Krovetz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16748828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a548eb2f55fd5a5ccdf5db66bef001d014568f72",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Most approaches to full-text information retrieval currently index documents based on the words they contain, and retrieve them based on the word\u2019s frequency of occurrence. This can cause many irrelevant documents to be retrieved because words are often ambiguous. We propose an approach in which documents are indexed by word aenaea, and in which these senses are taken from a machine-readable dictionary. We review some of the work on machine-readable dictionaries and the approaches that have been taken to word sense disambiguation. We then discuss our own approach to the problem based on the use of multiple sources of evidence. We conclude with the results of some experiments that indicate the degree to which lexical ambiguity is a factor in current systems."
            },
            "slug": "Word-sense-disambiguation-using-machine-readable-Krovetz-Croft",
            "title": {
                "fragments": [],
                "text": "Word sense disambiguation using machine-readable dictionaries"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An approach is proposed in which documents are indexed by word aenaea, and in which these senses are taken from a machine-readable dictionary, which indicates the degree to which lexical ambiguity is a factor in current systems."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '89"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 13
                            }
                        ],
                        "text": "A tiny room has no space for thousands of unnecessary things."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1693468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d922631a6bf8361d7602e12cafb9e15d421c827",
            "isKey": false,
            "numCitedBy": 836,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a program that disambiguates English word senses in unrestricted text using statistical models of the major Roget's Thesaurus categories. Roget's categories serve as approximations of conceptual classes. The categories listed for a word in Roget's index tend to correspond to sense distinctions; thus selecting the most likely category provides a useful level of sense disambiguation. The selection of categories is accomplished by identifying and weighting words that are indicative of each category when seen in context, using a Bayesian theoretical framework.Other statistical approaches have required special corpora or hand-labeled training examples for much of the lexicon. Our use of class models overcomes this knowledge acquisition bottleneck, enabling training on unrestricted monolingual text without human intervention. Applied to the 10 million word Grolier's Encyclopedia, the system correctly disambiguated 92% of the instances of 12 polysemous words that have been previously studied in the literature."
            },
            "slug": "Word-Sense-Disambiguation-Using-Statistical-Models-Yarowsky",
            "title": {
                "fragments": [],
                "text": "Word-Sense Disambiguation Using Statistical Models of Roget\u2019s Categories Trained on Large Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A program that disambiguates English word senses in unrestricted text using statistical models of the major Roget's Thesaurus categories, enabling training on unrestricted monolingual text without human intervention."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2614094"
                        ],
                        "name": "Rebecca F. Bruce",
                        "slug": "Rebecca-F.-Bruce",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bruce",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca F. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 61
                            }
                        ],
                        "text": "Bla | bla blub ...\ncontext 1\ncontext 2\nastronaut\nbla\nroom\nhere context radius = 6 words (Sch\u00fctze uses 25)\nJens Illig 2011-05-09 page 6\nVectorspace Model\nregular first-order co-occurrence (NOT used):\n... Bla | bla."
                    },
                    "intents": []
                }
            ],
            "corpusId": 942975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98c5a252475fce36934e6c3d4710af1aa08a382b",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Most probabilistic classifiers used for word-sense disambiguation have either been based on only one contextual feature or have used a model that is simply assumed to characterize the interdependencies among multiple contextual features. In this paper, a different approach to formulating a probabilistic model is presented along with a case study of the performance of models produced in this manner for the disambiguation of the noun interest. We describe a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation, without requiring untested assumptions regarding the form of the model. Using this approach, the joint distribution of all variables is described by only the most systematic variable interactions, thereby limiting the number of parameters to be estimated, supporting computational efficiency, and providing an understanding of the data."
            },
            "slug": "Word-Sense-Disambiguation-Using-Decomposable-Models-Bruce-Wiebe",
            "title": {
                "fragments": [],
                "text": "Word-Sense Disambiguation Using Decomposable Models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a method for formulating probabilistic models that use multiple contextual features for word-sense disambiguation, without requiring untested assumptions regarding the form of the model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226331"
                        ],
                        "name": "C. Leacock",
                        "slug": "C.-Leacock",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Leacock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leacock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804836"
                        ],
                        "name": "G. Towell",
                        "slug": "G.-Towell",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Towell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Towell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 61
                            }
                        ],
                        "text": "| An astronaut on a mission in space sends pictures back to Earth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6830876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6520da982493225779ef2cac3411d10de50f5a7",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A b s t r a c t Automatic corpus-based sense resolution, or sense dlsambiguation, techniques tend to focus either on very local context or on topical context. Both components axe needed for word sense resolution. A contextual representation of a word sense consists of topical context and local context. Our goal is to construct contextual representations by automatically extracting topical and local information from textual corpora. We review an experiment evaluating three statistical classifiers that automatically extract topical context. An experiment designed to examine human subject performance with similar input is described. Finally, we investigate a method for automatically extracting local context from a corpus. Preliminary results show improved perfor-"
            },
            "slug": "Towards-Building-Contextual-Representations-of-Word-Leacock-Towell",
            "title": {
                "fragments": [],
                "text": "Towards Building Contextual Representations of Word Senses Using Statistical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The goal is to construct contextual representations by automatically extracting topical and local information from textual corpora by investigating a method for automatically extracting local context from a corpus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889692"
                        ],
                        "name": "S. I. Gallant",
                        "slug": "S.-I.-Gallant",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gallant",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. I. Gallant"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19596937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eac60aeb9a17517a3e92fda4b4ba71051959b85f",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Representing and manipulating context information is one of the hardest problems in natural language processing. This paper proposes a method for representing some context information so that the correct meaning for a word in a sentence can be selected. The approach is primarily based on work by Waltz and Pollack (1985, 1984), who emphasized neutrally plausible systems. By contrast this paper focuses on computationally feasible methods applicable to full-scale natural language processing systems. There are two key elements: a collection of context vectors defined for every word used by a natural language processing system, and a context algorithm that computes a dynamic context vector at any position in a body of text. Once the dynamic context vector has been computed it is easy to choose among competing meanings for a word. This choice of definitions is essentially a neural network computation, and neural network learning algorithms should be able to improve such choices. Although context vectors do not represent all context information, their use should improve those full-scale systems that have avoided context as being too difficult to deal with. Good candidates for full-scale context vector implementations are machine translation systems and Japanese word processors. A main goal of this paper is to encourage such large-scale implementations and tests of context vector approaches. A variety of interesting directions for research in natural language processing and machine learning will be possible once a full set of context vectors has been created. In particular the development of more powerful context algorithms will be an important topic for future research."
            },
            "slug": "A-Practical-Approach-for-Representing-Context-and-Gallant",
            "title": {
                "fragments": [],
                "text": "A Practical Approach for Representing Context and for Performing Word Sense Disambiguation Using Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A method for representing some context information so that the correct meaning for a word in a sentence can be selected and the development of more powerful context algorithms will be an important topic for future research."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144795591"
                        ],
                        "name": "J. A. Guthrie",
                        "slug": "J.-A.-Guthrie",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Guthrie",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Guthrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144850246"
                        ],
                        "name": "Louise Guthrie",
                        "slug": "Louise-Guthrie",
                        "structuredName": {
                            "firstName": "Louise",
                            "lastName": "Guthrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Louise Guthrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2873584"
                        ],
                        "name": "Homa Aidinejad",
                        "slug": "Homa-Aidinejad",
                        "structuredName": {
                            "firstName": "Homa",
                            "lastName": "Aidinejad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Homa Aidinejad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 135
                            }
                        ],
                        "text": "Bla | bla blub ...\ncontext 1\ncontext 2\nastronaut\nbla\nroom\nhere context radius = 6 words (Sch\u00fctze uses 25)\nJens Illig 2011-05-09 page 6\nVectorspace Model\nregular first-order co-occurrence (NOT used):\n... Bla | bla."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 257
                            }
                        ],
                        "text": "Jens Illig 2011-05-09 page 4\nApplications\n\u2022 some require sense-labels like\n\u2013 correct translation of ambiguous words \u2013 correct pronunciation of ambiguous words\n\u2022 some don\u2019t\n\u2013 Information Retrieval (selection of sense cluster in the result)\nJens Illig 2011-05-09 page 5\nVectorspace Model\nregular first-order co-occurrence (NOT used):\n... Bla | bla."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 121
                            }
                        ],
                        "text": "Term weighting by idf factor log( nr of documents nr of documents containing word )\nJens Illig 2011-05-09 page 9\nContext Vectors\nroom\nastronaut\nbla\nroom things\n... Bla | bla."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 89
                            }
                        ],
                        "text": "... Venus and Mars are fellow planets of the Earth ...\nJens Illig 2011-05-09 page 8\nWord Vectors\nroom\nthings\nastronaut\nbla\nroom\n... Bla | bla."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 225
                            }
                        ],
                        "text": "\u2026require sense-labels like\n\u2013 correct translation of ambiguous words \u2013 correct pronunciation of ambiguous words\n\u2022 some don\u2019t\n\u2013 Information Retrieval (selection of sense cluster in the result)\nJens Illig 2011-05-09 page 5\nVectorspace Model\nregular first-order co-occurrence (NOT used):\n... Bla | bla."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 36
                            }
                        ],
                        "text": "Jens Illig 2011-05-09 page 10\nSense Vectors\nastronaut\nbla\nroom context 1\ncontext 2\ncontext 3\ncontext 4 sense A\nsense B\nContext vectors in training data are clustered."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16452774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8f17ad0913c44923b704ca226f665e9c53fcf60",
            "isKey": true,
            "numCitedBy": 119,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for obtaining subject-dependent word sets relative to some (subject) domain. Using the subject classifications given in the machine-redable version of Longman's Dictionary of Contemporary English, we established subject-dependent co-occurrence links between words of the defining vocabulary to construct these \"neighborhoods\". Here, we describe the application of these neighborhoods to information retrieval, and present a method of word sense disambiguation based on these co-occurrences, an extension of previous work."
            },
            "slug": "Subject-Dependent-Co-Occurence-and-Word-Sense-Guthrie-Guthrie",
            "title": {
                "fragments": [],
                "text": "Subject-Dependent Co-Occurence and Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Using the subject classifications given in the machine-redable version of Longman's Dictionary of Contemporary English, subject-dependent co-occurrence links between words of the defining vocabulary are established to construct \"neighborhoods\" and the application of these neighborhoods to information retrieval is described."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872595"
                        ],
                        "name": "Robert Krovetz",
                        "slug": "Robert-Krovetz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Krovetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Krovetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1107502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "843ede8176f63ecc671bf21d41bf5936df3a2a23",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses research on distinguishing word meanings in the context of information retrieval systems. We conducted experiments with three sources of evidence for making these distinctions: morphology, part-of-speech, and phrases. We have focused on the distinction between homonymy and polysemy (unrelated vs. related meanings). Our results support the need to distinguish homonymy and polysemy. We found: 1) grouping morphological variants makes a significant improvement in retrieval performance, 2) that more than half of all words in a dictionary that differ in part-of-speech are related in meaning, and 3) that it is crucial to assign credit to the component words of a phrase. These experiments provide better understanding of word-based methods, and suggest where natural language processing can provide further improvements in retrieval performance."
            },
            "slug": "Homonymy-and-Polysemy-in-Information-Retrieval-Krovetz",
            "title": {
                "fragments": [],
                "text": "Homonymy and Polysemy in Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results support the need to distinguish homonymy and polysemy and suggest where natural language processing can provide further improvements in retrieval performance."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746503"
                        ],
                        "name": "A. Kilgarriff",
                        "slug": "A.-Kilgarriff",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Kilgarriff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kilgarriff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141355355,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "cb2577675cb3c46af3a3d226cd8b697c5fdec661",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The word senses in a published dictionary are a valuable resource for natural language processing and textual criticism alike. In order that they can be further exploited, their nature must be better understood. Lexicographers have always had to decide where to say a word has one sense, where two. The two studies described here look into their grounds for making distinctions. The first develops a classification scheme to describe the commonly occurring distinction types. The second examines the task of matching the usages of a word from a corpus with the senses a dictionary provides. Finally, a view of the ontological status of dictionary word senses is presented."
            },
            "slug": "Dictionary-word-sense-distinctions:-An-enquiry-into-Kilgarriff",
            "title": {
                "fragments": [],
                "text": "Dictionary word sense distinctions: An enquiry into their nature"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The two studies described here look into their grounds for making distinctions, developing a classification scheme to describe the commonly occurring distinction types and a view of the ontological status of dictionary word senses."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1487550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944cba683d10d8c1a902e05cd68e32a9f47b372e",
            "isKey": false,
            "numCitedBy": 2536,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints---that words tend to have one sense per discourse and one sense per collocation---exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%."
            },
            "slug": "Unsupervised-Word-Sense-Disambiguation-Rivaling-Yarowsky",
            "title": {
                "fragments": [],
                "text": "Unsupervised Word Sense Disambiguation Rivaling Supervised Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 48
                            }
                        ],
                        "text": "| An astronaut on a mission in space sends pictures back to Earth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8112529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f041c48820535bfaf374b162cfc6acfc52ff87d",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an accurate, relatively inexpensive method for the disambiguation of noun homographs using large text corpora. The algorithm checks the context surrounding the target noun against that of previously observed instances and chooses the sense for which the most evidence is found, where evidence consists of a set of orthographic, syntactic, and lexical features. Because the sense distinctions made are coarse, the disambiguation can be accomplished without the expense of knowledge bases or inference mechanisms. An implementation of the algorithm is described which, starting with a small set of hand-labeled instances, improves its results automatically via unsupervised training. The approach is compared to other attempts at homograph disambiguation using both machine readable dictionaries and unrestricted text and the use of training instances is determined to be a crucial di erence."
            },
            "slug": "Noun-Homograph-Disambiguation-Using-Local-Context-Hearst",
            "title": {
                "fragments": [],
                "text": "Noun Homograph Disambiguation Using Local Context in Large Text Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An accurate, relatively inexpensive method for the disambiguation of noun homographs using large text corpora using both machine readable dictionaries and unrestricted text and the use of training instances is determined to be a crucial di erence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6922975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cb09327e68400bf05e6f373e046a3a08e82510e",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In many applications of natural language processing it is necessary to determine the likelihood of a given word combination. For example, a speech recognizer may need to determine which of the two word combinations \"eat a peach\" and \"eat a beach\" is more likely. Statistical NLP methods determine the likelihood of a word combination according to its frequency in a training corpus. However, the nature of language is such that many word combinations are infrequent and do not occur in a given corpus. In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on \"most similar\" words.We describe a probabilistic word association model based on distributional word similarity, and apply it to improving probability estimates for unseen word bigrams in a variant of Katz's back-off model. The similarity-based method yields a 20% perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech-recognition error."
            },
            "slug": "Similarity-Based-Estimation-of-Word-Cooccurrence-Dagan-Pereira",
            "title": {
                "fragments": [],
                "text": "Similarity-Based Estimation of Word Cooccurrence Probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A probabilistic word association model based on distributional word similarity is described, and it is applied to improving probability estimates for unseen word bigrams in a variant of Katz's back-off model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872595"
                        ],
                        "name": "Robert Krovetz",
                        "slug": "Robert-Krovetz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Krovetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Krovetz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5889361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f3fce7cecdd9d83421ecb87788393474aaac7dc",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Lexical ambiguity is a pervasive problem in natural language processing. However, little quantitative information is available about the extent of the problem or about the impact that it has on information retrieval systems. We report on an analysis of lexical ambiguity in information retrieval test collections and on experiments to determine the utility of word meanings for separating relevant from nonrelevant documents. The experiments show that there is considerable ambiguity even in a specialized database. Word senses provide a significant separation between relevant and nonrelevant documents, but several factors contribute to determining whether disambiguation will make an improvement in performance. For example, resolving lexical ambiguity was found to have little impact on retrieval effectiveness for documents that have many words in common with the query. Other uses of word sense disambiguation in an information retrieval context are discussed."
            },
            "slug": "Lexical-ambiguity-and-information-retrieval-Krovetz-Croft",
            "title": {
                "fragments": [],
                "text": "Lexical ambiguity and information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An analysis of lexical ambiguity in information retrieval test collections and experiments to determine the utility of word meanings for separating relevant from nonrelevant documents show that there is considerable ambiguity even in a specialized database."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119515866"
                        ],
                        "name": "G. Ruge",
                        "slug": "G.-Ruge",
                        "structuredName": {
                            "firstName": "Gerd",
                            "lastName": "Ruge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ruge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5517932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4966f2d75734b4abd4ad105b85eff675cb781b5d",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-on-Linguistically-Based-Term-Ruge",
            "title": {
                "fragments": [],
                "text": "Experiments on Linguistically-Based Term Associations"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16105777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36c4c51917b1f53ee85c459f2597e115df53eb05",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "One aspect of world knowledge essential to information retrieval is knowing when two words are related. Knowing word relatedness allows a system given a user's query terms to retrieve relevant documents not containing those exact terms. Two words can be said to be related if they appear in the same contexts Document co-occurrence gives a measure of word relatedness that has proved to be too rough to be useful. The relatively recent apparition of on-line dictionaries and robust and rapid parsers permits the extraction of finer word contexts from large corpora. In this paper, we will describe such an extraction technique that uses only coarse syntactic analysis and no domain knowledge. This technique produces lists of words related to any work appearing in a corpus. When the closest related terms were used in query expansion of a standard information retrieval testbed, the results were much better than that given by document co-occurence techniques, and slightly better than using unexpanded queries, supporting the contention that semantically similar words were indeed extracted by this technique."
            },
            "slug": "Use-of-syntactic-context-to-produce-term-lists-for-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Use of syntactic context to produce term association lists for text retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "When the closest related terms were used in query expansion of a standard information retrieval testbed, the results were much better than that given by document co-occurence techniques, and slightly better than using unexpanded queries, supporting the contention that semantically similar words were indeed extracted by this technique."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142223"
                        ],
                        "name": "M. Lesk",
                        "slug": "M.-Lesk",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lesk",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lesk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11892605,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "76e4e034c20bea86edcc6e71bbaddb47fafeecbc",
            "isKey": false,
            "numCitedBy": 2124,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The meaning of an English word can vary widely depending on which sense is intended. Does a fireman feed fires or put them out? It depends on whether or not he is on a steam locomotive. I am trying to decide automatically which sense of a word is intended (in written English) by using machine readable dictionaries, and looking for words in the sense definitions that overlap words in the definition of nearby words. The problem of deciding which sense of a word was intended by the writer is an important problem in information retrieval systems. At present most retrieval systems rely on manual indexing; if this is to be replaced with automatic text processing, it would be very desirable to recognize the correct sense of each word as often as possible. Previous work has generally either suggested (a) detailed frames describing the particular word senses,t*\u2019 or (b) global statistics about the word occurrences.3 The first has not yet been made available in any real application, and the second may give the wrong answer in specific local instances. This procedure uses available dictionaries, so that it will process any text; and uses solely the immediate context. To consider the example in the title, look at the definition of pine in the Oxford Advanced Learner\u2019s Dictionary of Current English: there are, of course, two major senses. \u201ckind of evergreen tree with needle-shaped leaves.. .\u201d and \u201cwaste away through sorrow or illness...\u201d And cone has three separate definitions: \u201csolid body which narrows to a\u2019 point . . . . *\u2019 \u201csomething of this shape w-hether solid or hollow...,\u201d and \u201cfruit of certain evergreen trees...\u201d Note that both evergreen and tree are common to two of the sense definitions: thus a program could guess that if the two words pine cone appear together, the likely senses are those of the tree and its fruit"
            },
            "slug": "Automatic-sense-disambiguation-using-machine-how-to-Lesk",
            "title": {
                "fragments": [],
                "text": "Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This procedure uses available dictionaries, so that it will process any text; and uses solely the immediate context to decide which sense of a word is intended (in written English)."
            },
            "venue": {
                "fragments": [],
                "text": "SIGDOC '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721996"
                        ],
                        "name": "M. Sanderson",
                        "slug": "M.-Sanderson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sanderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sanderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6680175,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "df3fd99704ab829157062bb44fb4929f9cba9217",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 123,
            "paperAbstract": {
                "fragments": [],
                "text": "It has often been thought that word sense ambiguity is a cause of poor performance in Information Retrieval (IR) systems. The belief is that if ambiguous words can be correctly disambiguated, IR performance will increase. However, recent research into the application of a word sense disambiguator to an IR system failed to show any performance increase. From these results it has become clear that more basic research is needed to investigate the relationship between sense ambiguity, disambiguation, and IR."
            },
            "slug": "Word-sense-disambiguation-and-information-retrieval-Sanderson",
            "title": {
                "fragments": [],
                "text": "Word sense disambiguation and information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "From these results it has become clear that more basic research is needed to investigate the relationship between sense ambiguity, disambiguation, and IR."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142223"
                        ],
                        "name": "M. Lesk",
                        "slug": "M.-Lesk",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lesk",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lesk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5481961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1452a5689b6c220fd286c079cc81efd7aedc7bb9",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The SMART automatic document retrieval system is used to study association procedures for automatic content analysis. The effect of word frequency and other parameters on the association process is investigated through examination of related pairs and through retrieval experiments. Associated pairs of words usually reflect localized word meanings, and true synonyms cannot readily be found from first or second order relationships in our document collections. There is little overlap between word relationships found through associations and those used in thesaurus construction, and the effects of word associations and a thesaurus in retrieval are independent. The use of associations in retrieval experiments improves not only recall, by permitting new matches between requests and documents, but also precision, by reinforcing existing matches. In our experiments, the precision effect is responsible for most of the improvement possible with associations. A properly constructed thesaurus, however, offers better performance than statistical association methods."
            },
            "slug": "Word-word-associations-in-document-retrieval-Lesk",
            "title": {
                "fragments": [],
                "text": "Word-word associations in document retrieval systems"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The SMART automatic document retrieval system is used to study association procedures for automatic content analysis, and the effect of word frequency and other parameters on the association process is investigated through examination of related pairs and through retrieval experiments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055976119"
                        ],
                        "name": "S. Marcus",
                        "slug": "S.-Marcus",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Marcus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2309269"
                        ],
                        "name": "Shaul Markovitch",
                        "slug": "Shaul-Markovitch",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Markovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaul Markovitch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 62690935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a74739f6c71a80d81a0ba5655c07fba05fcb44a",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years there is much interest in word cooccurrence relations, such as n-grams, verb-object combinations, or cooccurrence within a limited context. This paper discusses how to estimate the probability of cooccurrences that do not occur in the training data. We present a method that makes local analogies between each specific unobserved cooccurrence and other cooccurrences that contain similar words, as determined by an appropriate word similarity metric. Our evaluation suggests that this method performs better than existing smoothing methods, and may provide an alternative to class based models."
            },
            "slug": "Contextual-Word-Similarity-and-Estimation-from-Data-Dagan-Marcus",
            "title": {
                "fragments": [],
                "text": "Contextual Word Similarity and Estimation from Sparse Data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method is presented that makes local analogies between each specific unobserved cooccurrence and other cooccurrences that contain similar words, as determined by an appropriate word similarity metric, and may provide an alternative to class based models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 15
                            }
                        ],
                        "text": "Bla | bla bla ... ... Bla bla bla."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5458997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85b9eb556c211d954b31d9d58fed6891a07ab473",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a statistical technique for assigning senses to words. An instance of a word is assigned a sense by asking a question about the context in which the word appears. The question is constructed to have high mutual information with the translation of that instance in another language. When we incorporated this method of assigning senses into our statistical machine translation system, the error rate of the system decreased by thirteen percent."
            },
            "slug": "Word-Sense-Disambiguation-Using-Statistical-Methods-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Word-Sense Disambiguation Using Statistical Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A statistical technique for assigning senses to words is described, which incorporated into the statistical machine translation system the error rate of the system decreased by thirteen percent."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14558325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fed3002240ebfcfbad4ff472748f46191e17e4e0",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "As large on-line corpora become more prevalent, a number of attempts have been made to automatically extract thesaurus-like relations directly from text using knowledge poor methods. In the absence of any specific application, comparing the results of these attempts is difficult. Here we propose an evaluation method using gold standards, i.e., pre-existing hand-compiled resources, as a means of comparing extraction techniques. Using this evaluation method, we compare two semantic extraction techniques which produce similar word lists, one using syntactic context of words , and the other using windows of heuristically tagged words. The two techniques are very similar except that in one case selective natural language processing, a partial syntactic analysis, is performed. On a 4 megabyte corpus, syntactic contexts produce significantly better results against the gold standards for the most characteristk: words in the corpus, while windows produce better results for rare words."
            },
            "slug": "Evaluation-Techniques-for-Automatic-Semantic-and-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Evaluation Techniques for Automatic Semantic Extraction: Comparing Syntactic and Window Based Approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An evaluation method using gold standards, i.e., pre-existing hand-compiled resources, is proposed as a means of comparing extraction techniques, which compare two semantic extraction techniques which produce similar word lists."
            },
            "venue": {
                "fragments": [],
                "text": "Workshop On The Acquisition Of Lexical Knowledge From Text"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72537573"
                        ],
                        "name": "Gregory Grefenstetti",
                        "slug": "Gregory-Grefenstetti",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstetti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Grefenstetti"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61937302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ded8f7265b7208d4fbca21c1fdaf2fc01ac3c512",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "As large on-line corpora become more prevalent, a number of attempts have been made to automatically extract thesaurus-like relations directly from text using knowledge poor methods. In the absence of any specific application, comparing the results of these attempts is difficult. Here we propose an evaluation method using gold standards, i.e., pre-existing hand-compiled resources, as a means of comparing extraction techniques. Using this evaluation method, we compare two semantic extraction techniques which produce similar word lists, one using syntactic context of words , and the other using windows of heuristically tagged words. The two techniques are very similar except that in one case selective natural language processing, a partial syntactic analysis, is performed. On a 4 megabyte corpus, syntactic contexts produce significantly better results against the gold standards for the most characteristk: words in the corpus, while windows produce better results for rare words."
            },
            "slug": "Evaluation-techniques-for-automatic-semantic-and-Grefenstetti",
            "title": {
                "fragments": [],
                "text": "Evaluation techniques for automatic semantic extraction: comparing syntactic and window based approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An evaluation method using gold standards, i.e., pre-existing hand-compiled resources, is proposed as a means of comparing extraction techniques, which compare two semantic extraction techniques which produce similar word lists."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34729490"
                        ],
                        "name": "W. Charles",
                        "slug": "W.-Charles",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Charles",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Charles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145580646,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "402627e4eb8c95e4aae3026fd921aa08cd792006",
            "isKey": false,
            "numCitedBy": 1678,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The relationship between semantic and contextual similarity is investigated for pairs of nouns that vary from high to low semantic similarity. Semantic similarity is estimated by subjective ratings; contextual similarity is estimated by the method of sorting sentential contexts. The results show an inverse linear relationship between similarity of meaning and the discriminability of contexts. This relation, is obtained for two separate corpora of sentence contexts. It is concluded that, on average, for words in the same language drawn from the same syntactic and semantic categories, the more often two words can be substituted into the same contexts the more similar in meaning they are judged to be."
            },
            "slug": "Contextual-correlates-of-semantic-similarity-Miller-Charles",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of semantic similarity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11091754,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "596b7b01ca8011b6c2c5bac21a5450f92e1747aa",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of corpus-based extraction techniques have been successfully implemented which derive lists of similar words, based on some definition of the context in which they are found, from a corpus. We present here the results of affining such a list in order to extract semantic axes expressing nuances of a word's meaning. These semantic axes represent corpus-based meaning distinctions that are based on the word's usage in the corpus."
            },
            "slug": "Corpus-Derived-First,-Second-and-Third-Order-Word-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Corpus-Derived First, Second and Third-Order Word Affinities"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results of affining such a list in order to extract semantic axes expressing nuances of a word's meaning, which represent corpus-based meaning distinctions that are based on the word's usage in the corpus are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736744"
                        ],
                        "name": "A. Itai",
                        "slug": "A.-Itai",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Itai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Itai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1955588"
                        ],
                        "name": "Ulrike Schwall",
                        "slug": "Ulrike-Schwall",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Schwall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrike Schwall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 247
                            }
                        ],
                        "text": "\u2026require sense-labels like\n\u2013 correct translation of ambiguous words \u2013 correct pronunciation of ambiguous words\n\u2022 some don\u2019t\n\u2013 Information Retrieval (selection of sense cluster in the result)\nJens Illig 2011-05-09 page 5\nVectorspace Model\nregular first-order co-occurrence (NOT used):\n... Bla | bla."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13591927,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "2de1202303b1cf5972fb9837b083fd1bd17a1d56",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach for resolving lexical ambiguities in one language using statistical data on lexical relations in another language. This approach exploits the differences between mappings of words to senses in different languages. We concentrate on the problem of target word selection in machine translation, for which the approach is directly applicable, and employ a statistical model for the selection mechanism. The model was evaluated using two sets of Hebrew and German examples and was found to be very useful for disambiguation."
            },
            "slug": "Two-Languages-Are-More-Informative-Than-One-Dagan-Itai",
            "title": {
                "fragments": [],
                "text": "Two Languages Are More Informative Than One"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A new approach for resolving lexical ambiguities in one language using statistical data on lexical relations in another language using a statistical model for the selection mechanism is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15829786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e569d99f3a0fcfa038631dda2b44c73a6e8e97b8",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The representation of documents and queries as vectors in a high-dimensional space is well-established in information retrieval. The author proposes that the semantics of words and contexts in a text be represented as vectors. The dimensions of the space are words and the initial vectors are determined by the words occurring close to the entity to be represented, which implies that the space has several thousand dimensions (words). This makes the vector representations (which are dense) too cumbersome to use directly. Therefore, dimensionality reduction by means of a singular value decomposition is employed. The author analyzes the structure of the vector representations and applies them to word sense disambiguation and thesaurus induction. >"
            },
            "slug": "Dimensions-of-meaning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Dimensions of meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author analyzes the structure of the vector representations and applies them to word sense disambiguation and thesaurus induction and finds that dimensionality reduction by means of a singular value decomposition is employed."
            },
            "venue": {
                "fragments": [],
                "text": "Supercomputing '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15216944,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6140f6549be97a3cfc39a4bd41a7bc1de19cbcf7",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 151,
            "paperAbstract": {
                "fragments": [],
                "text": "The title of Cottrell's book mentions only two concepts: connectionism and lexical disambiguation. That's misleading, because the book has much more to offer than just that. Among the topics addressed are parsing, agrammatism, connectionist inheritance hierarchies, and structural ambiguity, and it is the integration of this wide-ranging set of topics that is one of the strengths of the work. The book appears four years after the 1985 University of Rochester dissertation upon which it is based. Thus the flavor of connectionism that Cottrell uses is the coarsegrained localist representations used at Rochester in the early 1980s, in which each node in the network represents a concept. This is in contrast to the distributed representations (\"PDP\") that became popular in the latter part of the decade, in which many nodes may contribute to the representation of a concept (Rumelhart and McClelland 1986). Cottrell has taken advantage of the delay in publication to restructure the work substantially and to add discussions of the later research. He seems to suggest (p. 7) that distributed representations are generally preferable because they can learn, whereas localist networks like his own need to be individually hand designed. Nevertheless, this research shows that there is considerable appeal in hand-designed, localist networks. Cottrell takes work in psycholinguistics as the starting point for his model of lexical access and disambiguation. In the early 1980s, it was discovered that in many circumstances, people subconsciously consider all meanings of an ambiguous word, even if the preceding context makes one alternative preferable a priori. For example, the floral sense of the word rose is activated even when one hears The congregation rose. Within a few hundred milliseconds all senses but the one chosen as correct become deactivated again. (While subsequent research has qualified these resuits somewhat--see Gorfein 1989--the basic principle has proven to be robust.) The usual explanation for these results is in terms of priming and spreading activation in a semantic network, so a localist model is very natural. The input to Cottrelrs networks is a string of words forming a syntactically simple sentence, such as Bob threw a ball to the dog. This is done by activating the nodes corresponding to the words. The activation of a node causes the activation of those other nodes in the network to which it is connected by excitory links and the deactivation of those to which it is connected by inhibitory links. A node can receive activation and inhibition at the same time; for example, an ambiguous word will send activation to all its senses, but the senses will be mutally inhibitory. Thus the network may be unstable for some time until it settles down into a pattern of activation that represents its \"output\"; the nodes representing the relevant concepts are activated and other nodes aren't. In the case of an ambiguous word, the correct meaning in context will presumably receive activation from more sources, or be pre-activated by the preceding context, and thus be able eventually to force its competitors into inhibition. This final pattern of activation may be construed as the interpretation of the sentence. After the word-sense selection network, there are two more networks, running in parallel with one another: one for determining case roles and one for syntactic analysis. The case role network uses an \"exploded\" notion of cases; that is, rather than having one node representing, say, the agent role, Cottrell has one node for the agent of a propel action, one for the agent of a vomit action, and so on. (The topic area of Cottrell's example sentences ranges from baseball to emesis.) This seems counter-intuitive, or unparsimonious at the very least; but I must admit that, modern linguistic theory notwithstanding, I know of no particular psycholinguistic evidence for the reality of a single concept of, say, agency that is activated for any and every sentence that involves an agent. A feature of the parsing network is that it need not be constructed by hand; rather, it is automatically generated from a grammar and lexicon by a Lisp program. It parses only the very simple one-clause sentences needed to test the other parts of the system. Unlike the other parts of the system, the parser has no special claim to psychological reality. However, the minimal-attachment strategy of structural ambiguity resolution (namely, to attach a new constituent in the way that creates the fewest new nodes) \"falls out\" as a natural consequence of the design. Cottrell includes an interesting discussion of his system's predictions for aphasia. If the system has some psychological reality, then one would expect that \"damage\" to the network would result in behavior similar to that of aphasic patients. For example, if the connection between the case"
            },
            "slug": "A-connectionist-approach-to-word-sense-Cottrell",
            "title": {
                "fragments": [],
                "text": "A connectionist approach to word sense disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This research shows that there is considerable appeal in hand-designed, localist networks, and Cottrell takes work in psycholinguistics as the starting point for his model of lexical access and disambiguation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2325236"
                        ],
                        "name": "Y. Niwa",
                        "slug": "Y.-Niwa",
                        "structuredName": {
                            "firstName": "Yoshiki",
                            "lastName": "Niwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Niwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806193"
                        ],
                        "name": "Y. Nitta",
                        "slug": "Y.-Nitta",
                        "structuredName": {
                            "firstName": "Yoshihiko",
                            "lastName": "Nitta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nitta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2646329,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c989e8aa08b24345419e4528198fe5ea17cc0160",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A comparison was made of vectors derived by using ordinary co-occurrence statistics from large text corpora and of vectors derived by measuring the interword distances in dictionary definitions. The precision of word sense disambiguation by using co-occurrence vectors from the 1987 Wall Street Journal (20M total words) was higher than that by using distance vectors from the Collins English Dictionary (60K head words + 1.6M definition words). However, other experimental results suggest that distance vectors contain some different semantic information from co-occurrence vectors."
            },
            "slug": "Co-Occurrence-Vectors-From-Corpora-vs.-Distance-Niwa-Nitta",
            "title": {
                "fragments": [],
                "text": "Co-Occurrence Vectors From Corpora vs. Distance Vectors From Dictionaries"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results suggest that distance vectors contain some different semantic information from co-occurrence vectors, compared with other experimental results, which suggest that word sense disambiguation is affected by distance vectors."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50611682"
                        ],
                        "name": "C. Burgess",
                        "slug": "C.-Burgess",
                        "structuredName": {
                            "firstName": "Curt",
                            "lastName": "Burgess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burgess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40591835"
                        ],
                        "name": "K. Lund",
                        "slug": "K.-Lund",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lund"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62167489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bfe2ca67c84724c12f6c94b4896721b9fdf0b70",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Deriving representations of meaning has been a long-standing problem in cognitive psychology and psycholinguistics. The lack of a m odel for representing semantic and grammatical knowledge has been a handicap in attempting to model the effects of semantic constraints in hum an syntactic processing. A computational model of high-dim ensional context space, the Hyperspace A nalogue to Language (H AL), is presented with a series of simulations modelling a variety of human empirical results. HAL learns its representations from the unsupervised processing of 300 million words of conversational text. W e propose that HAL's high-dim ensional context space can be used to (1) provide a basic categorisation of semantic and grammatical concepts, (2) model certain aspects of morphological ambiguity in verbs, and (3) provide an account of semantic context effects in syntactic processing. W e propose that the distributed and contextually derived representations that HAL acquires provide a basis for the subconceptual kn..."
            },
            "slug": "Modelling-Parsing-Constraints-with-High-dimensional-Burgess-Lund",
            "title": {
                "fragments": [],
                "text": "Modelling Parsing Constraints with High-dimensional Context Space"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is proposed that HAL's high-dim ensional context space can be used to provide a basic categorisation of semantic and grammatical concepts, model certain aspects of morphological ambiguity in verbs, and provide an account of semantic context effects in syntactic processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29249810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "244ac8d99def8e6238f318e5a4cdcec8023970e1",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Cooccurrence-Based-Thesaurus-and-Two-Applications-Sch\u00fctze-Pedersen",
            "title": {
                "fragments": [],
                "text": "A Cooccurrence-Based Thesaurus and Two Applications to Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18817171,
            "fieldsOfStudy": [
                "Law"
            ],
            "id": "54859dd7fcfd9112e01eded68a29cd26611d66e8",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Table 1: Sample Concordances of duty (split into two senses) Sense Examples (from Canadian Hansards) tax fewer cases of companies paying duty and then claiming a refund and impose a countervailing duty of 29,1 per cent on candian exports of the united states imposed a duty on canadian salttish last year obligation it is my honour and duty to present a petition duly approved working well beyond the call of duty ? SENT i know what time they start in addition, it is my duty to present the government\u2019s comments"
            },
            "slug": "Work-on-Statistical-Methods-for-Word-Sense-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Work on Statistical Methods for Word Sense Disambiguation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10986188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de5d40b60742e3dfa86b19e7f660962298492af",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."
            },
            "slug": "Class-Based-n-gram-Models-of-Natural-Language-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Class-Based n-gram Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work addresses the problem of predicting a word from previous words in a sample of text and discusses n-gram models based on classes of words, finding that these models are able to extract classes that have the flavor of either syntactically based groupings or semanticallybased groupings, depending on the nature of the underlying statistics."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9035985,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "184bcc835a7ae0cb3753ed675d743498e25da8e1",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This informal note was prompted by discussions and questions at the 1990 AAAI Spring Symposium on Text-Based Intelligent Systems (cf Jacobs 1990). There is a growing interest in access to, and the use of, large scale full-text databases for a variety of purposes, and in the application of classification methods to organise the mass of data involved (see e.g. Church and Hanks 1990). A good deal of work has been done in this field in the past, but it is little known, and some of the early research literature is not very accessible. Classification is an area in which it is easy to make plausible but mistaken assumptions, and as this certainly holds for classification in retrieval, there is a good deal that can be usefully learnt from past experience, most of which was hard won from careful thought and grinding experiment. This paper is intended as an introduction to this initial work on automatic classification, to help those now becoming interested in classification to avoid unnecessarily repeating heavy effort or, more especially, reinventing square wheels. It should also be noted that automatic classification and related (e.g. seriation) methods have been extensively developed for biological applications in particular, but have been more variously applied, and that much of this work may be relevant in the broad area of machine learning.It must be emphasised that as this paper is focussed on early work on automatic classification, particularly for information retrieval, and is designed primarily to lead into this research and its literature, it does not attempt a critical evaluation of the overall results established by now, or of the current state of the art. However it should be pointed out that in the retrieval context in general, as opposed to the wider one of classification as a whole, there has been comparatively little work since the seventies, largely for the reasons indicated in the paper. More recent work in any case refers heavily to earlier research, so this note can be taken as an entry point to the research of the last decade for which some references are given at the end of the note."
            },
            "slug": "Notes-and-references-on-early-automatic-work-Jones",
            "title": {
                "fragments": [],
                "text": "Notes and references on early automatic classification work"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper is intended as an introduction to this initial work on automatic classification, particularly for information retrieval, and is designed primarily to lead into this research and its literature, and does not attempt a critical evaluation of the overall results established by now, or of the current state of the art."
            },
            "venue": {
                "fragments": [],
                "text": "SIGF"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204549"
                        ],
                        "name": "S. Finch",
                        "slug": "S.-Finch",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Finch",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Finch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59663035,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "cfc0b24738f3611f50bad6d56ee4d48610321af1",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Since the Chomskian revolution, it has become apparent that natural language is richly struc\u00ac tured, being naturally represented hierarchically, and requiring complex context sensitive rules to define regularities over these representations. It is widely assumed that the richness of the posited structure has strong nativist implications for mechanisms which might learn natural language, since it seemed unlikely that such structures could be derived directly from the ob\u00ac servation of linguistic data (Chomsky 1965). This thesis investigates the hypothesis that simple statistics of a large, noisy, unlabelled corpus of natural language can be exploited to discover some of the structure which exists in natural language automatically. The strategy is to initially assume no knowledge of the structures present in natural language, save that they might be found by analysing statistical regularities which pertain between a word and the words which typically surround it in the corpus. To achieve this, various statistical methods are applied to define similarity between statistical distributions, and to infer a structure for a domain given knowledge of the similarities which pertain within it. Using these tools, it is shown that it is possible to form a hierarchical classi\u00ac fication of many domains, including words in natural language. When this is done, it is shown that all the major syntactic categories can be obtained, and the classification is both relati\u00ac vely complete, and very much in accord with a standard linguistic conception of how words are classified in natural language. Once this has been done, the categorisation derived is used as the basis of a similar classification of short sequences of words. If these are analysed in a similar way, then several syntactic categories can be derived. These include simple noun phrases, various tensed forms of verbs, and simple prepositional phrases. Once this has been done, the same technique can be applied one level higher, and at this level simple sentences and verb phrases, as well as more complicated noun phrases and prepositional phrases, are shown to be derivable."
            },
            "slug": "Finding-structure-in-language-Finch",
            "title": {
                "fragments": [],
                "text": "Finding structure in language"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This thesis investigates the hypothesis that simple statistics of a large, noisy, unlabelled corpus of natural language can be exploited to discover some of the structure which exists in natural language automatically."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302203"
                        ],
                        "name": "C. Plaunt",
                        "slug": "C.-Plaunt",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Plaunt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Plaunt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 54
                            }
                        ],
                        "text": "| An astronaut on a mission in space sends pictures back to Earth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5390627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74ade10f9ce9247c2cc853e2b29775a400eb0c6c",
            "isKey": false,
            "numCitedBy": 428,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We argue that the advent of large volumes of full-length text, as opposed to short texts like abstracts and newswire, should be accompanied by corresponding new approaches to information access. Toward this end, we discuss the merits of imposing structure on full-length text documents; that is, a partition of the text into coherent multi-paragraph units that represent the pattern of subtopics that comprise the text. Using this structure, we can make a distinction between the main topics, which occur throughout the length of the text, and the subtopics, which are of only limited extent. We discuss why recognition of subtopic structure is important and how, to some degree of accuracy, it can be found. We describe a new way of specifying queries on full-length documents and then describe an experiment in which making use of the recognition of local structure achieves better results on a typical information retrieval task than does a standard IR measure."
            },
            "slug": "Subtopic-structuring-for-full-length-document-Hearst-Plaunt",
            "title": {
                "fragments": [],
                "text": "Subtopic structuring for full-length document access"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "It is argued that the advent of large volumes of full-length text, as opposed to short texts like abstracts and newswire, should be accompanied by corresponding new approaches to information access and a partition of the text into coherent multi-paragraph units that represent the pattern of subtopics that comprise the text."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144610645"
                        ],
                        "name": "P. Willett",
                        "slug": "P.-Willett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Willett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Willett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17113895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fb58b6de34ae18174a111a9f32efaf79bbb0bbe",
            "isKey": false,
            "numCitedBy": 877,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-trends-in-hierarchic-document-clustering:-A-Willett",
            "title": {
                "fragments": [],
                "text": "Recent trends in hierarchic document clustering: A critical review"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82323309"
                        ],
                        "name": "Karen Sparck Jones",
                        "slug": "Karen-Sparck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sparck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sparck Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5207282,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "be5406dcea7c9c734cdb1f6797712b71fcf71b79",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "356,302. Golf bags. DENT, L. M. E., 2, Porchester Gardens, Bayswater, and MACKENZIE, A., 38A, Northside, Clapham Common, both in London. June 10, 1930, No. 17844. [Class 132 (ii).] The reinforcing ring at the mouth of a golfclub bag is made in two or more parts so interconnected that they may be moved relatively to expand or contract the compass of the mouth. As shown in the Figure, the ring is composed of two bars 12, 13 h n ed together at their right-hand ends and pivoted at their other ends to links 17, 18 hinged together at 19. By pressing the links 17, 18 downwards the ends 12, 13 of the bars may be brought together and the links may be retained in this position by a catch. A rigid reinforcing ring may be provided at the base of the bag or a collapsable one similar to that at the mouth may be used. The bag is provided with flexible stiffeners 21, 22, carrying straps 26, 27, hood 25, dividing strap 24, and umbrella strap 31 and support 32."
            },
            "slug": "Synonymy-and-semantic-classification-Jones",
            "title": {
                "fragments": [],
                "text": "Synonymy and semantic classification"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "The reinforcing ring at the mouth of a golfclub bag is made in two or more parts so interconnected that they may be moved relatively to expand or contract the compass of the mouth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2863534"
                        ],
                        "name": "Yonggang Qiu",
                        "slug": "Yonggang-Qiu",
                        "structuredName": {
                            "firstName": "Yonggang",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonggang Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20839449"
                        ],
                        "name": "H. Frei",
                        "slug": "H.-Frei",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Frei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Frei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11711278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "356f5f4224ee090a11e83a7e3cc130b2fdb0e612",
            "isKey": false,
            "numCitedBy": 542,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Query expansion methods have been studied for a long time - with debatable success in many instances. In this paper we present a probabilistic query expansion model based on a similarity thesaurus which was constructed automatically. A similarity thesaurus reflects domain knowledge about the particular collection from which it is constructed. We address the two important issues with query expansion: the selection and the weighting of additional search terms. In contrast to earlier methods, our queries are expanded by adding those terms that are most similar to the concept of the query, rather than selecting terms that are similar to the query terms. Our experiments show that this kind of query expansion results in a notable improvement in the retrieval effectiveness when measured using both recall-precision and usefulness."
            },
            "slug": "Concept-based-query-expansion-Qiu-Frei",
            "title": {
                "fragments": [],
                "text": "Concept based query expansion"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This paper presents a probabilistic query expansion model based on a similarity thesaurus which was constructed automatically and results in a notable improvement in the retrieval effectiveness when measured using both recall-precision and usefulness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3133664"
                        ],
                        "name": "D. Cutting",
                        "slug": "D.-Cutting",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Cutting",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cutting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066217332"
                        ],
                        "name": "Per Christian Halvorsen",
                        "slug": "Per-Christian-Halvorsen",
                        "structuredName": {
                            "firstName": "Per",
                            "lastName": "Halvorsen",
                            "middleNames": [
                                "Christian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Per Christian Halvorsen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0558d4b776eedb9956b0ec5c14b23f4f81870533",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "For almost all aspects of information access systems it is still the case that their optimal composition and functionality is hotly debated. Moreover, diierent application scenarios put diierent demands on individual components. It is therefore of the essence to be able to quickly build systems that permit exploration of diierent designs and implementation strategies. This paper presents a software implementation architecture for text retrieval systems that facilitates (a) functional modularization (b) mix-and-match combination of module implementations and (c) deenition of inter-module protocols. We show how an object-oriented approach easily accommodates this type of architecture. The design principles are exempliied by code examples in Common Lisp. Taken together these code examples constitute an operational retrieval system. The design principles and protocols implemented have also been instantiated in a large scale retrieval prototype in our research laboratory."
            },
            "slug": "An-object-oriented-architecture-for-text-retrieval-Cutting-Pedersen",
            "title": {
                "fragments": [],
                "text": "An object-oriented architecture for text retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A software implementation architecture for text retrieval systems that facilitates functional modularization, a mix-and-match combination of module implementations and a deenition of inter-module protocols is presented."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 22052389,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "944dd4cce541c856a5e2ea5fb22962e760d015d2",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Introduction 2. Semantic interpretation 3. The Absity semantic interpreter 4. Lexical disambiguation 5. Polaroid words 6. Structural disambiguation 7. The semantic enquiry desk 8. Conclusion 9. Speculations, partially baked ideas, and exercises for the reader References Index of names Index of subjects."
            },
            "slug": "Semantic-Interpretation-and-the-Resolution-of-Hirst",
            "title": {
                "fragments": [],
                "text": "Semantic Interpretation and the Resolution of Ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The Absity semantic interpreter helps clarify the role of language in semantic interpretation and provides a basis for future semantic interpreters to address language-based problems."
            },
            "venue": {
                "fragments": [],
                "text": "Studies in natural language processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59167516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4471e3117cdac2fae74d305d54b237bb3addd749",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Introduction. 2. Semantic Extraction. 3. Sextant. 4. Evaluation. 5. Applications. 6. Conclusion. 1: Preprocesors. 2. Webster Stopword List. 3: Similarity List. 4: Semantic Clustering. 5: Automatic Thesaurus Generation. 6. Corpora Treated. Index."
            },
            "slug": "Explorations-in-automatic-thesaurus-discovery-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Explorations in automatic thesaurus discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The aim of this monograph is to provide a catalog of words and phrases used in ThesaurusGeneration, as well as some examples of other writers' work, which have been used in similar contexts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43685115,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "49af3e80343eb80c61e727ae0c27541628c7c5e2",
            "isKey": false,
            "numCitedBy": 12605,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here."
            },
            "slug": "Introduction-to-Modern-Information-Retrieval-Salton-McGill",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Reading is a need and a hobby at once and this condition is the on that will make you feel that you must read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3133664"
                        ],
                        "name": "D. Cutting",
                        "slug": "D.-Cutting",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Cutting",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cutting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743286"
                        ],
                        "name": "D. Karger",
                        "slug": "D.-Karger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Karger",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Karger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a5b8e81de1a5750359f471e73e7c7d5f06090c5",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The Scatter/Gather document browsing method uses fast document clustering to produce table-of-contents-like outlines of large document collections. Previous work [1] developed linear-time document clustering algorithms to establish the feasibility of this method over moderately large collections. However, even linear-time algorithms are too slow to support interactive browsing of very large collections such as Tipster, the DARPA standard text retrieval evaluation collection. We present a scheme that supports constant interaction-time Scatter/Gather of arbitrarily large collections after near-linear time preprocessing. This involves the construction of a cluster hierarchy. A modification of Scatter/Gather employing this scheme, and an example of its use over the Tipster collection are presented."
            },
            "slug": "Constant-interaction-time-scatter/gather-browsing-Cutting-Karger",
            "title": {
                "fragments": [],
                "text": "Constant interaction-time scatter/gather browsing of very large document collections"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents a scheme that supports constant interaction-time Scatter/Gather of arbitrarily large collections after near-linear time preprocessing, and involves the construction of a cluster hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17637032,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2ebb3dd597bbd7028d8c68bcf509e5bb09ea1e78",
            "isKey": false,
            "numCitedBy": 1442,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is an automatic process, introduced over 20 years ago, designed to produce query formulations following an initial retrieval operation. The principal relevance feedback methods described over the years are examined briefly, and evaluation data are included to demonstrate the effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback."
            },
            "slug": "Improving-retrieval-performance-by-relevance-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Improving retrieval performance by relevance feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback, and evaluation data are included to demonstrate the effectiveness of the various methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37416850"
                        ],
                        "name": "R. L. Ott",
                        "slug": "R.-L.-Ott",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Ott",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Ott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123347451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "efae12722062d47301ceeb4c6fca47bb23970e74",
            "isKey": false,
            "numCitedBy": 5697,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "PART I: INTRODUCTION 1. WHAT IS STATISTICS? Introduction / Why Study Statistics? / Some Current Applications of Statistics / What Do Statisticians Do? / Quality and Process Improvement / A Note to the Student / Summary / Supplementary Exercises PART II: COLLECTING THE DATA 2. USING SURVEYS AND SCIENTIFIC STUDIES TO COLLECT DATA Introduction / Surveys / Scientific Studies / Observational Studies / Data Management: Preparing Data for Summarization and Analysis / Summary PART III: SUMMARIZING DATA 3. DATA DESCRIPTION Introduction / Describing Data on a Single Variable: Graphical Methods / Describing Data on a Single Variable: Measures of Central Tendency / Describing Data on a Single Variable: Measures of Variability / The Box Plot / Summarizing Data from More Than One Variable / Calculators, Computers, and Software Systems / Summary / Key Formulas / Supplementary Exercises PART IV: TOOLS AND CONCEPTS 4. PROBABILITY AND PROBABILITY DISTRIBUTIONS How Probability Can Be Used in Making Inferences / Finding the Probability of an Event / Basic Event Relations and Probability Laws / Conditional Probability and Independence / Bayes's Formula / Variables: Discrete and Continuous / Probability Distributions for Discrete Random Variables / A Useful Discrete Random Variable: The Binomial / Probability Distributions for Continuous Random Variables / A Useful Continuous Random Variable: The Normal Distribution / Random Sampling / Sampling Distributions / Normal Approximation to the Binomial / Summary / Key Formulas / Supplementary Exercises PART V: ANALYZING DATA: CENTRAL VALUES, VARIANCES, AND PROPORTIONS 5. INFERENCES ON A POPULATION CENTRAL VALUE Introduction and Case Study / Estimation of / Choosing the Sample Size for Estimating / A Statistical Test for / Choosing the Sample Size for Testing / The Level of Significance of a Statistical Test / Inferences about for Normal Population, s Unknown / Inferences about the Population Median / Summary / Key Formulas / Supplementary Exercises 6. COMPARING TWO POPULATION CENTRAL VALUES Introduction and Case Study / Inferences about 1 - 2: Independent Samples / A Nonparametric Alternative: The Wilcoxon Rank Sum Test / Inferences about 1 - 2: Paired Data / A Nonparametric Alternative: The Wilcoxon Signed-Rank Test / Choosing Sample Sizes for Inferences about 1 - 2 / Summary / Key Formulas / Supplementary Exercises 7. INFERENCES ABOUT POPULATION VARIANCES Introduction and Case Study / Estimation and Tests for a Population Variance / Estimation and Tests for Comparing Two Population Variances / Tests for Comparing k > 2 Population Variances / Summary / Key Formulas / Supplementary Exercises 8. INFERENCES ABOUT POPULATION CENTRAL VALUES Introduction and Case Study / A Statistical Test About More Than Two Population Variances / Checking on the Assumptions / Alternative When Assumptions are Violated: Transformations / A Nonparametric Alternative: The Kruskal-Wallis Test / Summary / Key Formulas / Supplementary Exercises 9. MULTIPLE COMPARISONS Introduction and Case Study / Planned Comparisons Among Treatments: Linear Contrasts / Which Error Rate Is Controlled / Multiple Comparisons with the Best Treatment / Comparison of Treatments to a Control / Pairwise Comparison on All Treatments / Summary / Key Formulas / Supplementary Exercises 10. CATEGORICAL DATA Introduction and Case Study / Inferences about a Population Proportion p / Comparing Two Population Proportions p1 - p2 / Probability Distributions for Discrete Random Variables / The Multinomial Experiment and Chi-Square Goodness-of-Fit Test / The Chi-Square Test of Homogeneity of Proportions / The Chi-Square Test of Independence of Two Nominal Level Variables / Fisher's Exact Test, a Permutation Test / Measures of Association / Combining Sets of Contingency Tables / Summary / Key Formulas / Supplementary Exercises PART VI: ANALYZING DATA: REGRESSION METHODS, MODEL BUILDING 11. SIMPLE LINEAR REGRESSION AND CORRELATION Linear Regression and the Method of Least Squares / Transformations to Linearize Data / Correlation / A Look Ahead: Multiple Regression / Summary of Key Formulas. Supplementary Exercises. 12. INFERENCES RELATED TO LINEAR REGRESSION AND CORRELATION Introduction and Case Study / Diagnostics for Detecting Violations of Model Conditions / Inferences about the Intercept and Slope of the Regression Line / Inferences about the Population Mean for a Specified Value of the Explanatory Variable / Predictions and Prediction Intervals / Examining Lack of Fit in the Model / The Inverse Regression Problem (Calibration): Predicting Values for x for a Specified Value of y / Summary / Key Formulas / Supplementary Exercises 13. MULTIPLE REGRESSION AND THE GENERAL LINEAR MODEL Introduction and Case Study / The General Linear Model / Least Squares Estimates of Parameters in the General Linear Model / Inferences about the Parameters in the General Linear Model / Inferences about the Population Mean and Predictions from the General Linear Model / Comparing the Slope of Several Regression Lines / Logistic Regression / Matrix Formulation of the General Linear Model / Summary / Key Formulas / Supplementary Exercises 14. BUILDING REGRESSION MODELS WITH DIAGNOSTICS Introduction and Case Study / Selecting the Variables (Step 1) / Model Formulation (Step 2) / Checking Model Conditions (Step 3) / Summary / Key Formulas / Supplementary Exercises PART VII: ANALYZING DATA: DESIGN OF EXPERIMENTS AND ANOVA 15. DESIGN CONCEPTS FOR EXPERIMENTS AND STUDIES Experiments, Treatments, Experimental Units, Blocking, Randomization, and Measurement Units / How Many Replications? / Studies for Comparing Means versus Studies for Comparing Variances / Summary / Key Formulas / Supplementary Exercises 16. ANALYSIS OF VARIANCE FOR STANDARD DESIGNS Introduction and Case Study / Completely Randomized Design with Single Factor / Randomized Block Design / Latin Square Design / Factorial Experiments in a Completely Randomized Design / The Estimation of Treatment Differences and Planned Comparisons in the Treatment Means / Checking Model Conditions / Alternative Analyses: Transformation and Friedman's Rank-Based Test / Summary / Key Formulas / Supplementary Exercises 17. ANALYSIS OF COVARIANCE Introduction and Case Study / A Completely Randomized Design with One Covariate / The Extrapolation Problem / Multiple Covariates and More Complicated Designs / Summary / Key Formulas / Supplementary Exercises 18. ANALYSIS OF VARIANCE FOR SOME UNBALANCED DESIGNS Introduction and Case Study / A Randomized Block Design with One or More Missing Observations / A Latin Square Design with Missing Data / Incomplete Block Designs / Summary / Key Formulas / Supplementary Exercises 19. ANALYSIS OF VARIANCE FOR SOME FIXED EFFECTS, RANDOM EFFECTS, AND MIXED EFFECTS MODELS Introduction and Case Study / A One-Factor Experiment with Random Treatment Effects / Extensions of Random-Effects Models / A Mixed Model: Experiments with Both Fixed and Random Treatment Effects / Models with Nested Factors / Rules for Obtaining Expected Mean Squares / Summary / Key Formulas / Supplementary Exercises 20. SPLIT-PLOT DESIGNS AND EXPERIMENTS WITH REPEATED MEASURES Introduction and Case Study / Split-Plot Designs / Single-Factor Experiments with Repeated Measures / Two-Factor Experiments with Repeated Measures on One of the Factors / Crossover Design / Summary / Key Formulas / Supplementary Exercises PART VIII: COMMUNICATING AND DOCUMENTING THE RESULTS OF A STUDY OR EXPERIMENT 21. COMMUNICATING AND DOCUMENTING THE RESULTS OF A STUDY OR EXPERIMENT Introduction / The Difficulty of Good Communication / Communication Hurdles: Graphical Distortions / Communication Hurdles: Biased Samples / Communication Hurdles: Sample Size / The Statistical Report / Documentation and Storage of Results / Summary / Supplementary Exercises"
            },
            "slug": "An-introduction-to-statistical-methods-and-data-Ott",
            "title": {
                "fragments": [],
                "text": "An introduction to statistical methods and data analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This book discusses statistics and its applications in the context of population studies, and discusses the role of statistics in the development ofinformed decision-making."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8882719,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "56182e7eafe008200b5163dbd0e6f681db74d148",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes density estimation as a feasible approach to the wide class of learning problems where traditional function approximation methods fail. These problems generally involve learning the inverse of causal systems, speciically when the inverse is a non-convex mapping. We demonstrate the approach through three case studies: the inverse kinematics of a three-joint planar arm, the acoustics of a four-tube articulatory model, and the localization of multiple objects from sensor data. The learning algorithm presented diiers from regression-based algorithms in that no distinction is made between input and output variables; the joint density is estimated via the EM algorithm and can be used to represent any input/output map by forming the conditional density of the output given the input. Causality in physical systems induces directionality in the relations between variables measured from them. Thus, one can generally deene a forward and an inverse direction of mapping. The forward direction is the causal direction, for example, from the forces applied to an object to the motion outcome, from the joint angles of an arm to the Cartesian coordinate of the nger, or from the connguration of a vocal tract to the sound frequencies produced. Similarly, the inverse direction is the non-causal direction. If the goal is to control the physical system the the inverse direction of mapping is particularly relevant. Returning to the above examples, this is the mapping from desired motion of an object to the forces required, from desired Cartesian nger coordinates to required joint angles, or from desired sound frequencies to required vocal tract connguration. In general the forward direction will be a function, whereas the inverse direction may be one-to-many and therefore not a function. One-to-many relations are often diicult to learn with function approximation methods. This diiculty arises from the fact that if the image of an input is a non-convex region in the output, then the least-squares solution may fall outside this region (for further discussion of non-convexity see 12]). This paper proposes density estimation as a feasible approach to the wide class of non-convex learning problems where function approximation and non-linear regression methods fail. The learning algorithm presented here diiers from regression-based algorithms in that no distinction is made between input and output variables; the joint density is estimated and this estimate can then be used to form any input/output map. Thus, to estimate the vector function y = f(x) the joint density \u2026"
            },
            "slug": "Solving-inverse-problems-using-an-EM-approach-to-Ghahramani",
            "title": {
                "fragments": [],
                "text": "Solving inverse problems using an EM approach to density estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The proposed density estimation approach is demonstrated through three case studies: the inverse kinematics of a three-joint planar arm, the acoustics of a four-tube articulatory model, and the localization of multiple objects from sensor data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271549"
                        ],
                        "name": "M. Berry",
                        "slug": "M.-Berry",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Berry",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Berry"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119721307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eebdd4761f5db209944a933d1124812c998039b",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present four numerical methods for computing the singular value decomposition (SVD) of large sparse matrices on a multiprocessor architecture. We emphasize Lanczos and subspace iteration-based methods for determining several of the largest singular triplets (singular values and corresponding left- and right-singular vectors) for sparse matrices arising from two practical applications: information retrieval and seismic reflection tomography. The target architectures for our implementations are the CRAY-2S/4\u2013128 and Alliant FX/80. The sparse SVD problem is well motivated by recent information-retrieval techniques in which dominant singular values and their corresponding singular vectors of large sparse term-document matrices are desired, and by nonlinear inverse problems from seismic tomography applications which require approximate pseudo-inverses of large sparse Jacobian matrices. This research may help advance the development of future out-of-core sparse SVD methods, which can be used, for example, to handle extremely large sparse matrices 0 \u00d7 (106) rows or columns associated with extremely large databases in query-based information-retrieval applications."
            },
            "slug": "Large-Scale-Sparse-Singular-Value-Computations-Berry",
            "title": {
                "fragments": [],
                "text": "Large-Scale Sparse Singular Value Computations"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Four numerical methods for computing the singular value decomposition (SVD) of large sparse matrices on a multiprocessor architecture are presented and may help advance the development of future out-of-core sparse SVD methods, which can be used to handle extremely large sparsematrices associated with extremely large databases in query-based information-retrieval applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60186948,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "6bbb7e6e7836af5996722db76ae78c89f7cae337",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "... viii"
            },
            "slug": "The-First-Text-REtrieval-Conference-(TREC-1)-Harman",
            "title": {
                "fragments": [],
                "text": "The First Text REtrieval Conference (TREC-1)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16928311"
                        ],
                        "name": "L. A. Marascuilo",
                        "slug": "L.-A.-Marascuilo",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Marascuilo",
                            "middleNames": [
                                "Anthony"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. Marascuilo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32462152"
                        ],
                        "name": "B. J. Winer",
                        "slug": "B.-J.-Winer",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Winer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. J. Winer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124517730,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a2080c899fedbf2d748ffd130e14f500f498b7d2",
            "isKey": false,
            "numCitedBy": 1811,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Principles-in-Experimental-Design,-2nd-Marascuilo-Winer",
            "title": {
                "fragments": [],
                "text": "Statistical Principles in Experimental Design, 2nd Edition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35096171"
                        ],
                        "name": "E. Kelly",
                        "slug": "E.-Kelly",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Kelly",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14664289"
                        ],
                        "name": "P. Stone",
                        "slug": "P.-Stone",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61812228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c59c1f2720b5fda6c70a3c78f3d63b7c523d6fa",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-recognition-of-English-word-senses-Kelly-Stone",
            "title": {
                "fragments": [],
                "text": "Computer recognition of English word senses"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 227293486,
            "fieldsOfStudy": [],
            "id": "e1e6fffa73f959286b30c50e6b77fde971ec6222",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Providing machine tractable dictionary tools"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60611449,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "8409ac798efbb2730d8185509f86ca6d8087c73a",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Ambiguity-resolution-in-language-learning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Ambiguity resolution in language learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6699526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e154ccb2619019c85c9b8aebc7318ec1c6a75463",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-in-Automatic-Thesaurus-Construction-for-Salton",
            "title": {
                "fragments": [],
                "text": "Experiments in Automatic Thesaurus Construction for Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "IFIP Congress"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29535089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa4bddbd10eafd8e1b54338517eedfee408f03ae",
            "isKey": false,
            "numCitedBy": 10559,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-Clustering-Data-Jain-Dubes",
            "title": {
                "fragments": [],
                "text": "Algorithms for Clustering Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861222864"
                        ],
                        "name": "Miss A.O. Penney",
                        "slug": "Miss-A.O.-Penney",
                        "structuredName": {
                            "firstName": "Miss",
                            "lastName": "Penney",
                            "middleNames": [
                                "A.O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miss A.O. Penney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221039574,
            "fieldsOfStudy": [],
            "id": "45fd483402290ad4cae059a4e20cd586c019c3da",
            "isKey": false,
            "numCitedBy": 151816,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "(b)-Penney",
            "title": {
                "fragments": [],
                "text": "(b)"
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Synonymy and Semantic ClassiJicationPublication of Ph.D. thesis, University of Cambridge, 1964.) Sparck-Jones, Karen. 1991. Notes and references on early classification work Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Edinburgh. ACM SIGIR Forum van Rijsbergen, C. J"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 213
                            }
                        ],
                        "text": "\u2026require sense-labels like\n\u2013 correct translation of ambiguous words \u2013 correct pronunciation of ambiguous words\n\u2022 some don\u2019t\n\u2013 Information Retrieval (selection of sense cluster in the result)\nJens Illig 2011-05-09 page 5\nVectorspace Model\nregular first-order co-occurrence (NOT used):\n... Bla | bla."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic sense disambiguation: How to tell a pine cone from an ice cream cone"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1986 SIGDOC Conference"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "| An astronaut on a mission in space sends pictures back to Earth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Poisson mixtures Concordances for parallel text"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh Annual Conference of the UW Centre for the New OED and Text Research"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gallant, Stephen I. 1991. A practical approach for representing context and for performing word sense disambiguation using neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Working Notes of the AAAI Fall Symposium on Probabilistic Approaches to Natural Language"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Notes and references on early classiication work"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGIR Forum Information Retrieval. Butterworths"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The use of machine - readable dictionaries in sublanguage analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Analyzing Language in Restricted Domains : Sublanguage Description and Processing"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 32
                            }
                        ],
                        "text": "A tiny room has no space for thousands of unnecessary things."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The use of machine-readable dictionaries in sublanguage analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Analyzing language in restricted domains: sublanguage description and processing. L. Erlbaum Associates, Hillsdale NJ"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic sense disambiguation: How to tell a pine cone from an ice cream cone"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1986 SIGDOC Conference"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Notes and references on early classification work"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGIR Forum"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 71,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatic-Word-Sense-Discrimination-Sch\u00fctze/3cd9fd8a36c8feb74bb20ae25817edb9c6a0518c?sort=total-citations"
}