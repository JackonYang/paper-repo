{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 50
                            }
                        ],
                        "text": "We obtain the word alignments using the method of Koehn et al. (2003), which is based on that of Och and Ney (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 131
                            }
                        ],
                        "text": "Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al., 2003), or not at all (Zens and Ney, 2004; Kumar et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 45
                            }
                        ],
                        "text": "\u2022 the lexical weightsPw(\u03b3 | \u03b1) and Pw(\u03b1 | \u03b3) (Koehn et al., 2003), which estimate how well the words in\u03b1 translate the words in \u03b3;2"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 151
                            }
                        ],
                        "text": "Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al., 2003), or not at all (Zens and Ney, 2004; Kumar et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 62
                            }
                        ],
                        "text": "tial phrasepairs using the same criterion as previous systems (Och and Ney, 2004; Koehn et al., 2003):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "But Koehn et al. (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 81
                            }
                        ],
                        "text": "We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al., 2003; Koehn, 2004a), against our system."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Koehn et al. (2003) mention German \u3008es gibt, there is\u3009 as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 43
                            }
                        ],
                        "text": "When we run a phrase-based system, Pharaoh (Koehn et al., 2003; Koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 150
                            }
                        ],
                        "text": "\u2026is not found in the noisy-channel model, but has been previously found to be a helpful feature (Och and Ney, 2002);\n\u2022 the lexical weightsPw(\u03b3 | \u03b1) and Pw(\u03b1 | \u03b3) (Koehn et al., 2003), which estimate how well the words in\u03b1 translate the words in\u03b3;2\n\u2022 a phrase penalty exp(1), which allows the model\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 44
                            }
                        ],
                        "text": "When we run a phrase-based system, Pharaoh (Koehn et al., 2003; Koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations:\n(4) [Aozhou] [shi] [yu] [Bei Han] [you] [bangjiao]1 [de shaoshu guojia zhiyi]\n[Australia] [is] [dipl. rels.]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "The baseline system we used for comparison was Pharaoh (Koehn et al., 2003; Koehn, 2004a), as publicly distributed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 114
                            }
                        ],
                        "text": "To do this, we first identifyinitial phrasepairs using the same criterion as previous systems (Och and Ney, 2004; Koehn et al., 2003):\nDefinition 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8884845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4b828609b60b06e61bea7a4029cc9e1cad5df87",
            "isKey": true,
            "numCitedBy": 3754,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models. Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models out-perform word-based models. Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations. Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance. Learning only syntactically motivated phrases degrades the performance of our systems."
            },
            "slug": "Statistical-Phrase-Based-Translation-Koehn-Och",
            "title": {
                "fragments": [],
                "text": "Statistical Phrase-Based Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The empirical results suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translation."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983801"
                        ],
                        "name": "R. Zens",
                        "slug": "R.-Zens",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "5We used Zhang\u2019s significance tester (Zhang et al., 2004), which uses bootstrap resampling (Koehn, 2004b); it was modified to conform to NIST\u2019s current definition of the BLEU brevity penalty."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1435098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ceebe893cfb2dbf83d872523d9ddd140aa1649c",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical machine translation, the currently best performing systems are based in some way on phrases or word groups. We describe the baseline phrase-based translation system and various refinements. We describe a highly efficient monotone search algorithm with a complexity linear in the input sentence length. We present translation results for three tasks: Verbmobil, Xerox and the Canadian Hansards. For the Xerox task, it takes less than 7 seconds to translate the whole test set consisting of more than 10K words. The translation results for the Xerox and Canadian Hansards task are very promising. The system even outperforms the alignment template system."
            },
            "slug": "Improvements-in-Phrase-Based-Statistical-Machine-Zens-Ney",
            "title": {
                "fragments": [],
                "text": "Improvements in Phrase-Based Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A highly efficient monotone search algorithm with a complexity linear in the input sentence length is described and translated results for three tasks: Verbmobil, Xerox and the Canadian Hansards are presented."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 455928,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11cd7fbc0ea8605ea498ecfc82b3ff6a44c027e9",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 163,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a syntax-based statistical translation model. Our model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node. These operations capture linguistic differences such as word order and case marking. Model parameters are estimated in polynomial time using an EM algorithm. The model produces word alignments that are better than those produced by IBM Model 5."
            },
            "slug": "A-Syntax-based-Statistical-Translation-Model-Yamada-Knight",
            "title": {
                "fragments": [],
                "text": "A Syntax-based Statistical Translation Model"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node, and produces word alignments that are better than those produced by IBM Model 5."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 a phrase penalty exp(1), which allows the model to learn a preference for longer or shorter derivations, analogous to Koehn\u2019s phrase penalty (Koehn, 2003)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59670585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e4681ece0316438b9984097894fab3ef56d3b7a",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We define noun phrase translation as a subtask of statistical machine translation. This enables us to build a dedicated noun phrase translation subsystem that improves over the currently best general statistical machine translation methods by incorporating special modeling and special features. \nWe integrate such a system into a state-of-the-art statistical machine translation system with novel methods and show overall improvement in translation quality. We also carry out empirical linguistic studies on noun phrase translatability and the sources of translation errors."
            },
            "slug": "Noun-phrase-translation-Knight-Koehn",
            "title": {
                "fragments": [],
                "text": "Noun phrase translation"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A dedicated noun phrase translation subsystem is built that improves over the currently best general statistical machine translation methods by incorporating special modeling and special features and shows overall improvement in translation quality."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070617284"
                        ],
                        "name": "Daniel Wong",
                        "slug": "Daniel-Wong",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Wong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 65
                            }
                        ],
                        "text": "Other phrase-based models model the joint distribution P(e, f ) (Marcu and Wong, 2002) or madeP(e) andP( f | e) into features of a log-linear model (Och and Ney, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1567400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a9ba4a76d1e9948c1cb980800ad117531753f8",
            "isKey": false,
            "numCitedBy": 525,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a joint probability model for statistical machine translation, which automatically learns word and phrase equivalents from bilingual corpora. Translations produced with parameters estimated using the joint model are more accurate than translations produced using IBM Model 4."
            },
            "slug": "A-Phrase-Based,-Joint-Probability-Model-for-Machine-Marcu-Wong",
            "title": {
                "fragments": [],
                "text": "A Phrase-Based, Joint Probability Model for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A joint probability model for statistical machine translation is presented, which automatically learns word and phrase equivalents from bilingual corpora, which is more accurate than translations produced using IBM Model 4."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983801"
                        ],
                        "name": "R. Zens",
                        "slug": "R.-Zens",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110694221"
                        ],
                        "name": "Taro Watanabe",
                        "slug": "Taro-Watanabe",
                        "structuredName": {
                            "firstName": "Taro",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taro Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698363"
                        ],
                        "name": "E. Sumita",
                        "slug": "E.-Sumita",
                        "structuredName": {
                            "firstName": "Eiichiro",
                            "lastName": "Sumita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sumita"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3151217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "baa4de120a631c719928c2466681e322c9da7848",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical machine translation, the generation of a translation hypothesis is computationally expensive. If arbitrary reorderings are permitted, the search problem is NP-hard. On the other hand, if we restrict the possible reorderings in an appropriate way, we obtain a polynomial-time search algorithm. We investigate different reordering constraints for phrase-based statistical machine translation, namely the IBM constraints and the ITG constraints. We present efficient dynamic programming algorithms for both constraints. We evaluate the constraints with respect to translation quality on two Japanese-English tasks. We show that the reordering constraints improve translation quality compared to an unconstrained search that permits arbitrary phrase reorderings. The ITG constraints preform best on both tasks and yield statistically significant improvements compared to the unconstrained search."
            },
            "slug": "Reordering-Constraints-for-Phrase-Based-Statistical-Zens-Ney",
            "title": {
                "fragments": [],
                "text": "Reordering Constraints for Phrase-Based Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work investigates different reordering constraints for phrase-based statistical machine translation, namely the IBM constraints and the ITG constraints and presents efficient dynamic programming algorithms for both constraints."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 286
                            }
                        ],
                        "text": "\u2026CFG the elementary structures are rewrite rules with aligned pairs of right-hand sides:\n(9) X\u2192 \u3008\u03b3, \u03b1,\u223c\u3009\nwhereX is a nonterminal,\u03b3 and\u03b1 are both strings of terminals and nonterminals, and\u223c is a one-to-one correspondence between nonterminal occurrences in \u03b3 and nonterminal occurrences in\u03b1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5284722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9214ebe91454e6369720136ab7dd990d52a07d4",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present and compare various single-word based alignment models for statistical machine translation. We discuss the five IBM alignment models, the Hidden-Markov alignment model, smoothing techniques and various modifications. We present different methods to combine alignments. As evaluation criterion we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We show that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies."
            },
            "slug": "Improved-Statistical-Alignment-Models-Och-Ney",
            "title": {
                "fragments": [],
                "text": "Improved Statistical Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In our experiments using BLEU as a metric, the hierarchical phrasebased model achieves a relative improvement of 7.5% over Pharaoh, a state-of-the-art phrase-based system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 123
                            }
                        ],
                        "text": "But Koehn et al. (2003) find that phrases longer than three words improve performance little, suggesting that data sparseness takes over for longer phrases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 284436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37fadfb6d60e83e24c72d8a90da5644b39d6e8f0",
            "isKey": true,
            "numCitedBy": 1228,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case. All knowledge sources are treated as feature functions, which depend on the source language sentence, the target language sentence and possible hidden variables. This approach allows a baseline machine translation system to be extended easily by adding new feature functions. We show that a baseline statistical machine translation system is significantly improved using this approach."
            },
            "slug": "Discriminative-Training-and-Maximum-Entropy-Models-Och-Ney",
            "title": {
                "fragments": [],
                "text": "Discriminative Training and Maximum Entropy Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case and shows that a baseline statistical machinetranslation system is significantly improved using this approach."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In our experiments using BLEU as a metric, the hierarchical phrasebased model achieves a relative improvement of 7.5% over Pharaoh, a state-of-the-art phrase-based system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 260
                            }
                        ],
                        "text": "\u2026the hierarchical phrase pairs from our above example could be formalized in a synchronous CFG as:\nX \u2192 \u3008yu X 1 you X 2 ,have X2 with X 1 \u3009(10) X \u2192 \u3008X 1 de X 2 , the X 2 that X 1 \u3009(11) X \u2192 \u3008X 1 zhiyi,one of X1 \u3009(12)\nwhere we have used boxed indices to indicate which occurrences of X are linked by\u223c."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 50
                            }
                        ],
                        "text": "Proceedings of the 43rd Annual Meeting of the ACL, pages 263\u2013270, Ann Arbor, June 2005.c\u00a92005 Association for Computational Linguistics\nWe present a statistical phrase-based translation model that useshierarchical phrases\u2014 phrases that contain subphrases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1272090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6a83c4fcc99ba6753109301949c5b7cfa978079",
            "isKey": true,
            "numCitedBy": 1044,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "A phrase-based statistical machine translation approach the alignment template approach is described. This translation approach allows for general many-to-many relations between words. Thereby, the context of words is taken into account in the translation model, and local changes in word order from source to target language can be learned explicitly. The model is described using a log-linear modeling approach, which is a generalization of the often used source-channel approach. Thereby, the model is easier to extend than classical statistical machine translation systems. We describe in detail the process for learning phrasal translations, the feature functions used, and the search algorithm. The evaluation of this approach is performed on three different tasks. For the German-English speech Verbmobil task, we analyze the effect of various system components. On the French-English Canadian Hansards task, the alignment template system obtains significantly better results than a single-word-based translation model. In the Chinese-English 2002 National Institute of Standards and Technology (NIST) machine translation evaluation it yields statistically significantly better NIST scores than all competing research and commercial translation systems."
            },
            "slug": "The-Alignment-Template-Approach-to-Statistical-Och-Ney",
            "title": {
                "fragments": [],
                "text": "The Alignment Template Approach to Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A phrase-based statistical machine translation approach the alignment template approach is described, which allows for general many-to-many relations between words and is easier to extend than classical statistical machinetranslation systems."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 80
                            }
                        ],
                        "text": "We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al., 2003; Koehn, 2004a), against our system."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 55
                            }
                        ],
                        "text": "The baseline system we used for comparison was Pharaoh (Koehn et al., 2003; Koehn, 2004a), as publicly distributed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 43
                            }
                        ],
                        "text": "When we run a phrase-based system, Pharaoh (Koehn et al., 2003; Koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29758373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50b8e8d48f4973cdeefa835807b4e1a8ca65ced3",
            "isKey": false,
            "numCitedBy": 748,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe Pharaoh, a freely available decoder for phrase-based statistical machine translation models. The decoder is the implement at ion of an efficient dynamic programming search algorithm with lattice generation and XML markup for external components."
            },
            "slug": "Pharaoh:-A-Beam-Search-Decoder-for-Phrase-Based-Koehn",
            "title": {
                "fragments": [],
                "text": "Pharaoh: A Beam Search Decoder for Phrase-Based Statistical Machine Translation Models"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Pharaoh, a freely available decoder for phrase-based statistical machine translation models is described, which is the implement at ion of an efficient dynamic programming search algorithm with lattice generation and XML markup for external components."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023469"
                        ],
                        "name": "D. Bikel",
                        "slug": "D.-Bikel",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bikel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bikel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145287425"
                        ],
                        "name": "David Chiang",
                        "slug": "David-Chiang",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Chiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1219991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5b0ab2d445a393341d292b26c8a9a6d01c62051",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the first-ever results of applying statistical parsing models to the newly-available Chinese Treebank. We have employed two models, one extracted and adapted from BBN's SIFT System (Miller et al., 1998) and a TAG-based parsing model, adapted from (Chiang, 2000). On sentences with \u226440 words, the former model performs at 69% precision, 75% recall, and the latter at 77% precision and 78% recall."
            },
            "slug": "Two-Statistical-Parsing-Models-Applied-to-the-Bikel-Chiang",
            "title": {
                "fragments": [],
                "text": "Two Statistical Parsing Models Applied to the Chinese Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The first-ever results of applying statistical parsing models to the newly-available Chinese Treebank are presented, with the former performing at 69% precision, 75% recall, and the latter at 77% precision and 78% recall."
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799403021"
                        ],
                        "name": "H. Block",
                        "slug": "H.-Block",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Block",
                            "middleNames": [
                                "Ulrich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Block"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "cally the same as that of Block (2000), except we allow more than one nonterminal symbol in a rule, and use a more sophisticated probability model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60661987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffc1b0032e704185658ff36d0cfa5f7cfa5df362",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes a new approach to example based incremental translation for automatic interpretation systems developed in Verbmobil. The translation module is completely learned from a bilingual corpus. The training phase combines statistical word alignment with precomputation of translation \u201cchunks\u201d and contextual clustering of syntactic equivalence classes (word classes). The system gives incremental output for every piece of input being it words or sequences of words. It thus tries to mimic the behaviour of a human synchronous interpreter. If a larger context leads to the need for reformulation the system utters a correction marker like I mean, and restarts the output from the starting position of the reformulation. The system is currently effective for German \u21d4 English. German \u21d4 Chinese and German a Japanese are under construction. In the Verbmobil evaluation, this approach reached 79% of approximately correct translations on speech recognition output."
            },
            "slug": "Example-Based-Incremental-Synchronous-Block",
            "title": {
                "fragments": [],
                "text": "Example-Based Incremental Synchronous Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This article describes a new approach to example based incremental translation for automatic interpretation systems developed in Verbmobil that reached 79% of approximately correct translations on speech recognition output."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102020342"
                        ],
                        "name": "S. H. A N K A R K U M A R",
                        "slug": "S.-H.-A-N-K-A-R-K-U-M-A-R",
                        "structuredName": {
                            "firstName": "S",
                            "lastName": "A N K A R K U M A R",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. H. A N K A R K U M A R"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2104657619"
                        ],
                        "name": "Y. O N G G A N G D E N G And W I L L I A M B Y R N E",
                        "slug": "Y.-O-N-G-G-A-N-G-D-E-N-G-And-W-I-L-L-I-A-M-B-Y-R-N",
                        "structuredName": {
                            "firstName": "Y",
                            "lastName": "O N G G A N G D E N G And W I L L I A M B Y R N E",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. O N G G A N G D E N G And W I L L I A M B Y R N E"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In our experiments using BLEU as a metric, the hierarchical phrasebased model achieves a relative improvement of 7.5% over Pharaoh, a state-of-the-art phrase-based system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 207
                            }
                        ],
                        "text": "Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al., 2003), or not at all (Zens and Ney, 2004; Kumar et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6396125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd90aa78de07004f6eb40405462d77f27e0e79e0",
            "isKey": true,
            "numCitedBy": 67,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a Weighted Finite State Transducer Translation Template Model for statistical machine translation. This is a source-channel model of translation inspired by the Alignment Template translation model. The model attempts to overcome the deficiencies of word-toword translation models by considering phrases rather than words as units of translation. The approach we describe allows us to implement each constituent distribution of the model as a weighted finite state transducer or acceptor. We show that bitext word alignment and translation under the model can be performed with standard finite state machine operations involving these transducers. One of the benefits of using this framework is that it avoids the need to develop specialized search procedures, even for the generation of lattices or N-Best lists of bitext word alignments and translation hypotheses. We report and analyze bitext word alignment and translation performance on the Hansards French-English task and the FBIS Chinese-English task under the Alignment Error Rate, BLEU, NIST and Word Error-Rate metrics. These experiments identify the contribution of each of the model components to different aspects of alignment and translation performance. We finally discuss translation performance with large bitext training sets on the NIST 2004 Chinese-English and Arabic-English MT tasks."
            },
            "slug": "A-weighted-finite-state-transducer-translation-for-S.H.ANKARKUMA-Y.ONGGANGDENGAndWILLIAMBYRN",
            "title": {
                "fragments": [],
                "text": "A weighted finite state transducer translation template model for statistical machine translation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that bitext word alignment and translation under the model can be performed with standard finite state machine operations involving these transducers, and the contribution of each of the model components to different aspects of alignment andtranslation performance is identified."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 139
                            }
                        ],
                        "text": "We ran the trainer with its default settings (maximum phrase length 7), and then used Koehn\u2019s implementation of minimumerror-rate training (Och, 2003) to tune the feature weights to maximize the system\u2019s BLEU score on our development set, yielding the values shown in Table 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5474833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f12451245667a85d0ee225a80880fc93c71cc8b",
            "isKey": false,
            "numCitedBy": 3304,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Often, the training procedure for statistical machine translation models is based on maximum likelihood or related criteria. A general problem of this approach is that there is only a loose relation to the final translation quality on unseen text. In this paper, we analyze various training criteria which directly optimize translation quality. These training criteria make use of recently proposed automatic evaluation metrics. We describe a new algorithm for efficient training an unsmoothed error count. We show that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure."
            },
            "slug": "Minimum-Error-Rate-Training-in-Statistical-Machine-Och",
            "title": {
                "fragments": [],
                "text": "Minimum Error Rate Training in Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 75
                            }
                        ],
                        "text": "The basic phrase-based model is an instance of the noisy-channel approach (Brown et al., 1993),1 in which the translation of a French sentencef into an\n1Throughout this paper, we follow the convention of Brown et al. of designating the source and target languages as \u201cFrench\u201d and \u201cEnglish,\u201d\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The basic phrase-based model is an instance of the noisy-channel approach (Brown et al., 1993),1 in which the translation of a French sentence f into an"
                    },
                    "intents": []
                }
            ],
            "corpusId": 13259913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab7b5917515c460b90451e67852171a531671ab8",
            "isKey": false,
            "numCitedBy": 4745,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus."
            },
            "slug": "The-Mathematics-of-Statistical-Machine-Translation:-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Statistical Machine Translation: Parameter Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus, given a set of pairs of sentences that are translations of one another."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 129
                            }
                        ],
                        "text": "For all three systems we trained the translation model on the FBIS corpus (7.2M+9.2M words); for the language model, we used the SRI Language Modeling Toolkit to train a trigram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998) on 155M words of English newswire text, mostly from the Xinhua portion of the Gigaword corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "The decoder is implemented in Python, an interpreted language, with C ++ code from the SRI Language Modeling Toolkit (Stolcke, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 86
                            }
                        ],
                        "text": "The decoder is implemented in Python, an interpreted language, with C++ code from the SRI Language Modeling Toolkit (Stolcke, 2002)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1988103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399da68d3b97218b6c80262df7963baa89dcc71b",
            "isKey": true,
            "numCitedBy": 4998,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "slug": "SRILM-an-extensible-language-modeling-toolkit-Stolcke",
            "title": {
                "fragments": [],
                "text": "SRILM - an extensible language modeling toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The functionality of the SRILM toolkit is summarized and its design and implementation is discussed, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 41
                            }
                        ],
                        "text": ", 2004), which uses bootstrap resampling (Koehn, 2004b); it was modified to conform to NIST\u2019s current definition of the BLEU brevity penalty."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15119437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb826a3899752b796f14df1c50378c64954a6b0a",
            "isKey": false,
            "numCitedBy": 1524,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "If two translation systems differ differ in performance on a test set, can we trust that this indicates a difference in true system quality? To answer this question, we describe bootstrap resampling methods to compute statistical significance of test results, and validate them on the concrete example of the BLEU score. Even for small test sizes of only 300 sentences, our methods may give us assurances that test result differences are real."
            },
            "slug": "Statistical-Significance-Tests-for-Machine-Koehn",
            "title": {
                "fragments": [],
                "text": "Statistical Significance Tests for Machine Translation Evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 20
                            }
                        ],
                        "text": "bilingual bracketer (Wu, 1997), but ours uses a different extraction method that allows more than one lexical item in a rule, in keeping with the phrasebased philosophy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 54
                            }
                        ],
                        "text": "In this respect it resembles Wu\u2019s\nbilingual bracketer (Wu, 1997), but ours uses a different extraction method that allows more than one lexical item in a rule, in keeping with the phrasebased philosophy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 912349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13b6eeb28328252a35cdcbe3ab8d09d2a9caf99d",
            "isKey": false,
            "numCitedBy": 1000,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce (1) a novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and (2) the concept of bilingual parsing with a variety of parallel corpus analysis applications. Aside from the bilingual orientation, three major features distinguish the formalism from the finite-state transducers more traditionally found in computational linguistics: it skips directly to a context-free rather than finite-state base, it permits a minimal extra degree of ordering flexibility, and its probabilistic formulation admits an efficient maximum-likelihood bilingual parsing algorithm. A convenient normal form is shown to exist. Analysis of the formalism's expressiveness suggests that it is particularly well suited to modeling ordering shifts between languages, balancing needed flexibility against complexity constraints. We discuss a number of examples of how stochastic inversion transduction grammars bring bilingual constraints to bear upon problematic corpus analysis tasks such as segmentation, bracketing, phrasal alignment, and parsing."
            },
            "slug": "Stochastic-Inversion-Transduction-Grammars-and-of-Wu",
            "title": {
                "fragments": [],
                "text": "Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and the concept of bilingual parsing with a variety of parallel corpus analysis applications are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980198"
                        ],
                        "name": "W. Wahlster",
                        "slug": "W.-Wahlster",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Wahlster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wahlster"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "Our extraction method is basically the same as that of Block (2000), except we allow more than one nonterminal symbol in a rule, and use a more sophisticated probability model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30807920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f593c10ab7496d949526119499d39d766c832a2",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Mobile Speech-to-Speech Translation of Spontaneous Dialogs: An Overview of the Final Verbmobil System.- Facts and Figures about the Verbmobil Project.- Multilingual Speech Recognition.- Robust Recognition of Spontaneous Speech.- Fast Search for Large Vocabulary Speech Recognition.- Capturing Long Range Correlations Using Log-Linear Language Models.- Data Driven Generation of Pronunciation Dictionaries.- The Prosody Module.- The Recognition of Emotion.- Processing Self-Corrections in a Speech-to-Speech System.- Integrated Shallow Linguistic Processing.- Probabilistic LR-Parsing with Symbolic Postprocessing.- Robust Chunk Parsing for Spontaneous Speech.- Verbmobil Interface Terms (VITs).- Semantic Construction.- Deep Linguistic Analysis with HPSG.- HPSG Analysis of German.- HPSG Analysis of English.- HPSG Analysis of Japanese.- Efficient and Robust Parsing of Word Hypotheses Graphs.- Speech Lexica and Consistent Multilingual Vocabularies.- Combining Analyses from Various Parsers.- Robust Semantic Processing of Spoken Language.- Discourse and Dialog Semantics for Translation.- Multilingual Semantic Databases.- Semantic-Based Transfer.- Statistical Methods for Machine Translation.- Adapting a Large Scale MT System for Spoken Language.- Example-Based Incremental Synchronous Interpretation.- Example-Based Machine Translation with Templates.- Robust Content Extraction for Translation and Dialog Processing.- Modeling Negotiation Dialogs.- Dialog Processing.- Contextual Disambiguation.- The Verbmobil Generation Component VM-GECO.- The Application of HPSG-to-TAG Compilation Techniques.- Generating Multilingual Dialog Summaries and Minutes.- Speech Synthesis Using Multilevel Selection and Concatenation of Units from Large Speech Corpora.- Verbmobil Data Collection and Annotation.- The Tubingen Treebanks for Spoken German, English, and Japanese.- Multilingual Verbmobil-Dialogs: Experiments, Data Collection and Data Analysis.- Speech Recognition Performance Assessment.- Speech Synthesis Quality Assessment.- From Off-line Evaluation to On-line Selection.- Functional Validation of a Machine Interpretation System: Verbmobil.- Verbmobil From a Software Engineering Point of View: System Design and Software Integration.- From a Stationary Prototype to Telephone Translation Services.- List of Contributors."
            },
            "slug": "Verbmobil:-Foundations-of-Speech-to-Speech-Wahlster",
            "title": {
                "fragments": [],
                "text": "Verbmobil: Foundations of Speech-to-Speech Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "Mobile Speech-to-Speech Translation of Spontaneous Dialogs and Verbmobil From a Software Engineering Point of View: System Design and Software Integration."
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323275"
                        ],
                        "name": "Kishore Papineni",
                        "slug": "Kishore-Papineni",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Papineni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kishore Papineni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144582029"
                        ],
                        "name": "T. Ward",
                        "slug": "T.-Ward",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2587983"
                        ],
                        "name": "Wei-Jing Zhu",
                        "slug": "Wei-Jing-Zhu",
                        "structuredName": {
                            "firstName": "Wei-Jing",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Jing Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "In our experiments using BLEU as a metric, the hierarchical phrasebased model achieves a relative improvement of 7.5% over Pharaoh, a state-of-the-art phrase-based system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 32
                            }
                        ],
                        "text": "Our evaluation metric was BLEU (Pap-\nineni et al., 2002), as calculated by the NIST script\n(version 11a) with its default settings, which is to perform case-insensitive matching ofn-grams up to n = 4, and to use the shortest (as opposed to nearest) reference sentence for the brevity penalty."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "We ran the trainer with its default settings (maximum phrase length 7), and then used Koehn\u2019s implementation of minimumerror-rate training (Och, 2003) to tune the feature weights to maximize the system\u2019s BLEU score on our development set, yielding the values shown in Table 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "5We used Zhang\u2019s significance tester (Zhang et al., 2004), which uses bootstrap resampling (Koehn, 2004b); it was modified to conform to NIST\u2019s current definition of the BLEU brevity penalty."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11080756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7da009f457917aa381619facfa5ffae9329a6e9",
            "isKey": true,
            "numCitedBy": 16632,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations."
            },
            "slug": "Bleu:-a-Method-for-Automatic-Evaluation-of-Machine-Papineni-Roukos",
            "title": {
                "fragments": [],
                "text": "Bleu: a Method for Automatic Evaluation of Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48379623"
                        ],
                        "name": "Y. Zhang",
                        "slug": "Y.-Zhang",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247319"
                        ],
                        "name": "S. Vogel",
                        "slug": "S.-Vogel",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "5We used Zhang\u2019s significance tester (Zhang et al., 2004), which uses bootstrap resampling (Koehn, 2004b); it was modified to conform to NIST\u2019s current definition of the BLEU brevity penalty."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8080832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b78d00a50745c1833e513b8c188d372a35a5a184",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic evaluation metrics for Machine Translation (MT) systems, such as BLEU and the related NIST metric, are becoming increasingly important in MT. Yet, their behaviors are not fully understood. In this paper, we analyze some flaws in the BLEU/NIST metrics. With a better understanding of these problems, we can better interpret the reported BLEU/NIST scores. In addition, this paper reports a novel method of calculating the confidence intervals for BLEU/NIST scores using bootstrapping. With this method, we can determine whether two MT systems are significantly different from each other."
            },
            "slug": "Interpreting-BLEU/NIST-Scores:-How-Much-Improvement-Zhang-Vogel",
            "title": {
                "fragments": [],
                "text": "Interpreting BLEU/NIST Scores: How Much Improvement do We Need to Have a Better System?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A novel method of calculating the confidence intervals for BLEU/NIST scores using bootstrapping is reported, which can determine whether two MT systems are significantly different from each other."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715952"
                        ],
                        "name": "A. Aho",
                        "slug": "A.-Aho",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Aho",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 205894705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa5b410d52c1c292cd1a0c984f88b6a0ac9eb448",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Syntax-Directed-Translations-and-the-Pushdown-Aho-Ullman",
            "title": {
                "fragments": [],
                "text": "Syntax Directed Translations and the Pushdown Assembler"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643845523"
                        ],
                        "name": "F. ChenStanley",
                        "slug": "F.-ChenStanley",
                        "structuredName": {
                            "firstName": "F",
                            "lastName": "ChenStanley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. ChenStanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643789739"
                        ],
                        "name": "GoodmanJoshua",
                        "slug": "GoodmanJoshua",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "GoodmanJoshua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "GoodmanJoshua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 137
                            }
                        ],
                        "text": "2M words); for the language model, we used the SRI Language Modeling Toolkit to train a trigram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998) on 155M words of English newswire text, mostly from the Xinhua portion of the Gigaword corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215842252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4e8bed3b50a035e1eabad614fe4218a34b3b178",
            "isKey": false,
            "numCitedBy": 2861,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "We survey the most widely-used algorithms for smoothing models for language n -gram modeling. We then present an extensive empirical comparison of several of these smoothing techniques, including t..."
            },
            "slug": "An-empirical-study-of-smoothing-techniques-for-ChenStanley-GoodmanJoshua",
            "title": {
                "fragments": [],
                "text": "An empirical study of smoothing techniques for language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A survey of the most widely-used algorithms for smoothing models for language n -gram modeling and an extensive empirical comparison of several of these smoothing techniques are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2805094"
                        ],
                        "name": "I. Thayer",
                        "slug": "I.-Thayer",
                        "structuredName": {
                            "firstName": "Ignacio",
                            "lastName": "Thayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Thayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542900"
                        ],
                        "name": "D. Munteanu",
                        "slug": "D.-Munteanu",
                        "structuredName": {
                            "firstName": "Dragos",
                            "lastName": "Munteanu",
                            "middleNames": [
                                "Stefan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Munteanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1938286"
                        ],
                        "name": "Quamrul Tipu",
                        "slug": "Quamrul-Tipu",
                        "structuredName": {
                            "firstName": "Quamrul",
                            "lastName": "Tipu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quamrul Tipu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1947267"
                        ],
                        "name": "Michel Galley",
                        "slug": "Michel-Galley",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Galley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Galley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066428796"
                        ],
                        "name": "Mark Los Angeles Hopkins",
                        "slug": "Mark-Los-Angeles-Hopkins",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Hopkins",
                            "middleNames": [
                                "Los",
                                "Angeles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Los Angeles Hopkins"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 71
                            }
                        ],
                        "text": "A lexicalized phrase-reordering model like that in use in ISI\u2019s system (Och et al., 2004) might be able to learn a better reordering, but simpler distortion models will probably not."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59701728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95cd4ff6b4b14677cc8857521a71495fed5364ee",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Arabic-and-Chinese-MT-at-USC/ISI-Och-Thayer",
            "title": {
                "fragments": [],
                "text": "Arabic and Chinese MT at USC/ISI"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 64
                            }
                        ],
                        "text": "Other phrase-based models model the joint distribution P(e, f ) (Marcu and Wong, 2002) or made P(e) andP( f | e) into features of a log-linear model (Och and Ney, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A phrasebased, joint probability model for statistical machine translation"
            },
            "venue": {
                "fragments": [],
                "text": "InProceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 133\u2013139."
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 265
                            }
                        ],
                        "text": "\u20262002);\n\u2022 the lexical weightsPw(\u03b3 | \u03b1) and Pw(\u03b1 | \u03b3) (Koehn et al., 2003), which estimate how well the words in\u03b1 translate the words in\u03b3;2\n\u2022 a phrase penalty exp(1), which allows the model to learn a preference for longer or shorter derivations, analogous to Koehn\u2019s phrase penalty (Koehn, 2003)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 143
                            }
                        ],
                        "text": "\u2022 a phrase penalty exp(1), which allows the model to learn a preference for longer or shorter derivations, analogous to Koehn\u2019s phrase penalty (Koehn, 2003)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2003.Noun Phrase Translation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 18,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Hierarchical-Phrase-Based-Model-for-Statistical-Chiang/ad3d2f463916784d0c14a19936c1544309a0a440?sort=total-citations"
}