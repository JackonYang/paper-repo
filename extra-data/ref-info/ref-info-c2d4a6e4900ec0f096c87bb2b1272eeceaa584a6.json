{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735767"
                        ],
                        "name": "Margaret M. Fleck",
                        "slug": "Margaret-M.-Fleck",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Fleck",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margaret M. Fleck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Since computer vision techniques for this purpose are not highly accurate [ 9 ], content filters usually analyze the text inside web pages to determine whether they should be blocked."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1979750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ccda575c3c3e96bb99522c5a8ab158474a9f2f3",
            "isKey": false,
            "numCitedBy": 552,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a content-based retrieval strategy that can tell whether there are naked people present in an image. No manual intervention is required. The approach combines color and texture properties to obtain an effective mask for skin regions. The skin mask is shown to be effective for a wide range of shades and colors of skin. These skin regions are then fed to a specialized grouper, which attempts to group a human figure using geometric constraints on human structure. This approach introduces a new view of object recognition, where an object model is an organized collection of grouping hints obtained from a combination of constraints on geometric properties such as the structure of individual parts, and the relationships between parts, and constraints on color and texture. The system is demonstrated to have 60% precision and 52% recall on a test set of 138 uncontrolled images of naked people, mostly obtained from the internet, and 1401 assorted control images, drawn from a wide collection of sources."
            },
            "slug": "Finding-Naked-People-Fleck-Forsyth",
            "title": {
                "fragments": [],
                "text": "Finding Naked People"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A content-based retrieval strategy that can tell whether there are naked people present in an image and an effective mask for skin regions is demonstrated, which introduces a new view of object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2754399"
                        ],
                        "name": "R. Lempel",
                        "slug": "R.-Lempel",
                        "structuredName": {
                            "firstName": "Ronny",
                            "lastName": "Lempel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lempel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696998"
                        ],
                        "name": "A. Soffer",
                        "slug": "A.-Soffer",
                        "structuredName": {
                            "firstName": "Aya",
                            "lastName": "Soffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Soffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9547261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f12d572a00ac10983877cacfa6c829307fe69782",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe PicASHOW, a fully automated WWW image retrieval system that is based on several link-structure analyzing algorithms. Our basic premise is that a page p displays (or links to) an image when the author of p considers the image to be of value to the viewers of the page. We thus extend some well known link-based WWW page retrieval schemes to the context of image retrieval.PicASHOW's analysis of the link structure enables it to retrieve relevant images even when those are stored in files with meaningless names. The same analysis also allows it to identify image containers and image hubs. We define these as Web pages that are rich in relevant images, or from which many images are readily accessible.PicASHOW requires no image analysis whatsoever and no creation of taxonomies for preclassification of the Web's images. It can be implemented by standard WWW search engines with reasonable overhead, in terms of both computations and storage, and with no change to user query formats. It can thus be used to easily add image retrieving capabilities to standard search engines.Our results demonstrate that PicASHOW, while relying almost exclusively on link analysis, compares well with dedicated WWW image retrieval systems. We conclude that link analysis, a proven effective technique for Web page search, can improve the performance of Web image retrieval, as well as extend its definition to include the retrieval of image hubs and containers."
            },
            "slug": "PicASHOW:-pictorial-authority-search-by-hyperlinks-Lempel-Soffer",
            "title": {
                "fragments": [],
                "text": "PicASHOW: pictorial authority search by hyperlinks on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is concluded that link analysis, a proven effective technique for Web page search, can improve the performance of Web image retrieval, as well as extend its definition to include the retrieval of image hubs and containers."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Methods such as [2,3] d annotations to produce a and words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 86544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df70db146b07ce173476be3877a5a3ae3ca06aa5",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend a recently developed method (K. Barnard and D. Forsyth, 2001) for learning the semantics of image databases using text and pictures. We incorporate statistical natural language processing in order to deal with free text. We demonstrate the current system on a difficult dataset, namely 10000 images of work from the Fine Arts Museum of San Francisco. The images include line drawings, paintings, and pictures of sculpture and ceramics. Many of the images have associated free text which varies greatly from physical description to interpretation and mood. We use WordNet to provide semantic grouping information and to help disambiguate word senses, as well as emphasize the hierarchical nature of semantic relationships. This allows us to impose a natural structure on the image collection that reflects semantics to a considerable degree. Our method produces a joint probability distribution for words and picture elements. We demonstrate that this distribution can be used: (a) to provide illustrations for given captions, and (b) to generate words for images outside the training set. Results from this annotation process yield a quantitative study of our method. Finally, the annotation process can be seen as a form of object recognizer that has been learned through a partially supervised process."
            },
            "slug": "Clustering-art-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Clustering art"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work extends a recently developed method for learning the semantics of image databases using text and pictures and uses WordNet to provide semantic grouping information and to help disambiguate word senses, as well as emphasize the hierarchical nature of semantic relationships."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Methods such as [2,3] d annotations to produce a and words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13121800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e36d141e2964817c3d926c380793e404a3a3367",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a statistical model for organizing image collections which integrates semantic information provided by associate text and visual information provided by image features. The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features. Furthermore, since the model learns relationships between text and image features, it can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "slug": "Learning-the-semantics-of-words-and-pictures-Barnard-Forsyth",
            "title": {
                "fragments": [],
                "text": "Learning the semantics of words and pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features, and can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059257793"
                        ],
                        "name": "Jo\u00e3o Freitas",
                        "slug": "Jo\u00e3o-Freitas",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Freitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "For example, the work described in [7] only gave reasonable results for 80 out of their 371 vocabulary words (their evaluation consisted of searching for images using the vocabulary words, and only 80 of the words resulted in reasonable images)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "Other methods attempt to combine large semantic text models with annotated image structures [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12561212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d9f55b445f36578802e7eef4393cfa914b11620",
            "isKey": false,
            "numCitedBy": 1765,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model of object recognition as machine translation. In this model, recognition is a process of annotating image regions with words. Firstly, images are segmented into regions, which are classified into region types using a variety of features. A mapping between region types and keywords supplied with the images, is then learned, using a method based around EM. This process is analogous with learning a lexicon from an aligned bitext. For the implementation we describe, these words are nouns taken from a large vocabulary. On a large test set, the method can predict numerous words with high accuracy. Simple methods identify words that cannot be predicted well. We show how to cluster words that individually are difficult to predict into clusters that can be predicted well -- for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. The method is trained on a substantial collection of images. Extensive experimental results illustrate the strengths and weaknesses of the approach."
            },
            "slug": "Object-Recognition-as-Machine-Translation:-Learning-Sahin-Barnard",
            "title": {
                "fragments": [],
                "text": "Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows how to cluster words that individually are difficult to predict into clusters that can be predicted well, and cannot predict the distinction between train and locomotive using the current set of features, but can predict the underlying concept."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17], for instance, int human faces in still photograp typically accurate, but have not range of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14133530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36cd88ed2c17a596001e9c7d89533ac46c28dec0",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a trainable object detector and its instantiations for detecting faces and cars at any size, location, and pose. To cope with variation in object orientation, the detector uses multiple classifiers, each spanning a different range of orientation. Each of these classifiers determines whether the object is present at a specified size within a fixed-size image window. To find the object at any location and size, these classifiers scan the image exhaustively.Each classifier is based on the statistics of localized parts. Each part is a transform from a subset of wavelet coefficients to a discrete set of values. Such parts are designed to capture various combinations of locality in space, frequency, and orientation. In building each classifier, we gathered the class-conditional statistics of these part values from representative samples of object and non-object images. We trained each classifier to minimize classification error on the training set by using Adaboost with Confidence-Weighted Predictions (Shapire and Singer, 1999). In detection, each classifier computes the part values within the image window and looks up their associated class-conditional probabilities. The classifier then makes a decision by applying a likelihood ratio test. For efficiency, the classifier evaluates this likelihood ratio in stages. At each stage, the classifier compares the partial likelihood ratio to a threshold and makes a decision about whether to cease evaluation\u2014labeling the input as non-object\u2014or to continue further evaluation. The detector orders these stages of evaluation from a low-resolution to a high-resolution search of the image. Our trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation."
            },
            "slug": "Object-Detection-Using-the-Statistics-of-Parts-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "Object Detection Using the Statistics of Parts"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40643698"
                        ],
                        "name": "Chuck P. Lam",
                        "slug": "Chuck-P.-Lam",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Lam",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck P. Lam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 2
                            }
                        ],
                        "text": ", [18,19]), a worldwide effort to develop \u201cintelligent\u201d software."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17152089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ea4ed2098aa3e9b2040b40a28530a026d67f951",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the Open Mind Initiative, a framework for building intelligent systems collaboratively over the internet, and focus on one of its simpler component projects, Open Mind Animals. The Initiative extends traditional open source development methods by allowing non-expert netizens to contribute informal data over the internet. Such data is used to train classifiers or guide automatic inference systems, and thus it is important that only data of high accuracy and consistency be accepted. We identify a number of possible sources of poor data in Animals \u2014 several of which are generic and applicable to a range of open data collection projects \u2014 and implement a system of software modules for automatically and semi-automatically preventing poor data from being accepted. Our system, tested in a controlled laboratory intranet, filters faulty data through a variety of mechanisms and leads to accurate decision tree classifiers. Our reusable modules can be employed in our planned large-scale internet deployment of Animals and other Open Mind projects."
            },
            "slug": "Open-Mind-Animals-:-Insuring-the-quality-of-data-Stork-Lam",
            "title": {
                "fragments": [],
                "text": "Open Mind Animals : Insuring the quality of data openly contributed over the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system of software modules for automatically and semi-automatically preventing poor data from being accepted in Animals is implemented, which filters faulty data through a variety of mechanisms and leads to accurate decision tree classifiers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70186985"
                        ],
                        "name": "R. E. Milliman",
                        "slug": "R.-E.-Milliman",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Milliman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Milliman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 166574436,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "8ecb4d1fbd201abb20615626f58a669acc1f738b",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "DESIGNING WEBSITES FOR MAXIMUM MARKET PENETRATION Introduction and Problem Among website designers, the issue of website accessibility has become a very controversial topic. Because of poor design, it is estimated that up to 40% of the potential market is not able to fully access most websites, taking into consideration various disabilities and wireless devices that have limited web browsing capabilities. While the needs of wireless devices are being addressed quite rapidly, in sharp contrast, designers are accused of continuing to ignore the needs of various disabilities. It is estimated that there are up to 54 million people in the United States (with a disposable income of approximately $1 trillion), and another 750 million persons world-wide, (NCD #01-326, May 18, 2001, http://www.ncd.gov) with various disabilities whose full access to the web is limited because of poor, non-compliant web design; for example, a person who is blind needs an alternative to visual access in order to be able to fully access a website. As our population ages, the number of persons encountering such challenges is getting larger. In addition, various Federal laws and Regulations (e.g., Section 508) have placed considerable pressure on web designers of all government entities and firms seeking to do business with the Federal government to make their websites fully accessible. To minimize the possibility of being sued, all web designers for firms, large and small, private or public, for-profit or not-for-profit must deal with this issue of web accessibility. This paper seeks to answer the question: after the initiation of Federal Regulation Section 508 on June 21, 2001, does the problem of poor website design still exist in the private sector, resulting in inaccessibility to persons with various disabilities? If so, to what extent? Can disabled stakeholders tolerate continued disenfranchisement? THE PRESENT STUDY Questions to Be Answered This study attempts to answer the following key questions: 1. What proportion of firms, excluding government entities, has accessible web sites? 2. Of those firms that have inaccessible websites, what reasons are given for their inaccessibility? 3. What would it take to encourage firms that have inaccessible websites to make their websites accessible? Research Design This research was executed as an empirical field study. It was intended to be primarily a descriptive, as opposed to an inferential, type study. An e-mailed multiple-item questionnaire was used to collect the data. The sampled firms were divided into large compared to small which were further sub-divided into Business-to-Business (B2B) and Business-to-Consumer (B2C) types; profit-seeking firms were compared to not-for-profit types. Each organization that returned the questionnaire was given a free CD that covered the issue of website accessibility and the related law, and a detailed \"Website Compliance Analysis.\" Sample The questionnaire was sent by e-mail to the web master or web designer designated for the websites of a sample of 1080 organizations taken from each of the categories mentioned. A major \"opt-in\" e-mailing list broker provided the e-mailing list. RESULTS Of the 1080 organizations contacted, a total of 453 participated by returning the completed e-mailed questionnaire for an overall response rate of 41.94% (see Exhibits 1a & b). What proportion of firms has fully accessible websites? All of the websites of the firms selected in the initial sample of 1080 were tested using \"Bobby,\" a tool that assists website authors in identifying the changes needed to make their pages usable by persons with disabilities. Of the 1080 firms, only 19 or 1.76% had accessible websites, meaning 1061 or 98.24% failed the Bobby test. Among the profit-seeking compared to the not-for-profit firms, 2 (out of 63) and 5 (out of 89) were accessible according to Bobby (see Exhibit 2a & b). \u2026"
            },
            "slug": "Website-Accessibility-and-the-Private-Sector:-2-Milliman",
            "title": {
                "fragments": [],
                "text": "Website Accessibility and the Private Sector: Disability Stakeholders Cannot Tolerate 2% Access!"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394256448"
                        ],
                        "name": "Brian C. O'Connor",
                        "slug": "Brian-C.-O'Connor",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "O'Connor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian C. O'Connor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401687824"
                        ],
                        "name": "Mary K. O'Connor",
                        "slug": "Mary-K.-O'Connor",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "O'Connor",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary K. O'Connor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "that an individual indexer would have assigned [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62207903,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "373147fc837a5f0e3ef10f5f2fe27c268b3db1d4",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Categories,-Photographs-&-Predicaments:-Exploratory-O'Connor-O'Connor",
            "title": {
                "fragments": [],
                "text": "Categories, Photographs & Predicaments: Exploratory Research on Representing Pictures for Access"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144925016"
                        ],
                        "name": "T. K. Rengarajan",
                        "slug": "T.-K.-Rengarajan",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Rengarajan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. K. Rengarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47356984"
                        ],
                        "name": "Lucien A. Dimino",
                        "slug": "Lucien-A.-Dimino",
                        "structuredName": {
                            "firstName": "Lucien",
                            "lastName": "Dimino",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucien A. Dimino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382042801"
                        ],
                        "name": "Dwayne Chung",
                        "slug": "Dwayne-Chung",
                        "structuredName": {
                            "firstName": "Dwayne",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dwayne Chung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Text adjacent to the images is often scarce, and can be misleading or hard to process [ 4 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is insufficient because the text adjacent to the images is often scarce, and can be misleading or hard to process [ 4 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 204107704,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "970bdd76eadba122c3474012a7f628af02e261a2",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Storage-and-Retrieval-of-Feature-Data-for-a-Very-Rengarajan-Dimino",
            "title": {
                "fragments": [],
                "text": "Storage and Retrieval of Feature Data for a Very Large Online Image Collection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9302780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d1fde071222c92812a192ce3346c734ffcfc9f9",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "IEEE-conference-on-computer-vision-and-pattern",
            "title": {
                "fragments": [],
                "text": "IEEE conference on computer vision and pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260570"
                        ],
                        "name": "Virginia E. Ogle",
                        "slug": "Virginia-E.-Ogle",
                        "structuredName": {
                            "firstName": "Virginia",
                            "lastName": "Ogle",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Virginia E. Ogle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "This is insufficient because the text adjacent to the images is often scarce, and can be misleading or hard to process [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "Text adjacent to the images is often scarce, and can be misleading or hard to process [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8188014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1613abd9402dbd7461d652d74071cb91ef7a21b7",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Object-relational database systems are now being deployed for real use by customers. Researchers and industry users have begun to explore the performance issues that these systems raise. In this paper, we examine some of those performance issues, and evaluate them for object-relational systems in general and for INFORMIX-Universal Server in particular. We describe object-relational query processing techniques and make some predictions about how they will evolve over the next several years."
            },
            "slug": "Storage-and-Retrieval-of-Feature-Data-for-a-Very-Carson-Ogle",
            "title": {
                "fragments": [],
                "text": "Storage and Retrieval of Feature Data for a Very Large Online Image Collection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper examines some of the performance issues for object-relational systems in general and for INFORMIX-Universal Server in particular, and describes object- Relational query processing techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Data Eng. Bull."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Altavista Search Home"
            },
            "venue": {
                "fragments": [],
                "text": "Altavista Search Home"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Language Change. Routledge"
            },
            "venue": {
                "fragments": [],
                "text": "Language Change. Routledge"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stock Photography and Pictures"
            },
            "venue": {
                "fragments": [],
                "text": "Stock Photography and Pictures"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "C. Finding Naked People. ECCV"
            },
            "venue": {
                "fragments": [],
                "text": "C. Finding Naked People. ECCV"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Microsoft Corporation. MSN Gaming Zone"
            },
            "venue": {
                "fragments": [],
                "text": "Microsoft Corporation. MSN Gaming Zone"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Accessibility And The Private Sector"
            },
            "venue": {
                "fragments": [],
                "text": "Photographs & Predicaments: Exploratory Research on Representing Pictures for Access"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Electronic Arts"
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Arts"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Altavista Search Home. http://www.altavista.com/ 2"
            },
            "venue": {
                "fragments": [],
                "text": "Clustering Art. IEEE conference on Computer Vision and Pattern Recognition"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Google Web Search"
            },
            "venue": {
                "fragments": [],
                "text": "Google Web Search"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stock Photography and Pictures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random Bounce Me Website"
            },
            "venue": {
                "fragments": [],
                "text": "Bulletin of the American Society for Information Science"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "http://games.yahoo.com CHI"
            },
            "venue": {
                "fragments": [],
                "text": "http://games.yahoo.com CHI"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MSN Gaming Zone"
            },
            "venue": {
                "fragments": [],
                "text": "Website Accessibility And The Private Sector"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 2
                            }
                        ],
                        "text": ", [18,19]), a worldwide effort to develop \u201cintelligent\u201d software."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Open Mind Initiative"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Systems & Their Applications"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "webSEEK. www.ctr.columbia.edu/webseek/ 6. Corbis. Stock Photography and Pictures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MSN Gaming Zone"
            },
            "venue": {
                "fragments": [],
                "text": "PicASHOW : Pictorial Authority Search by Hyperlinks on the Web"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Google Web Search"
            },
            "venue": {
                "fragments": [],
                "text": "Finding Naked People . ECCV"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random Bounce Me Website"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Altavista Search Home"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Labeling-images-with-a-computer-game-Ahn-Dabbish/c2d4a6e4900ec0f096c87bb2b1272eeceaa584a6?sort=total-citations"
}