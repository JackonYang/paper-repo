{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3288675"
                        ],
                        "name": "F. Agakov",
                        "slug": "F.-Agakov",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Agakov",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Agakov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 101
                            }
                        ],
                        "text": "Theoretical analysis shows that CD can fail but does not give conditions which guarantee convergence [3,4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14004203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9b93a69f2ff9d1e5243a4a0cbc71813f8ea1d02",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The Boltzmann machine (BM) learning rule for random field models with latent variables can be problematic to use in practice. These problems have (at least partially) been attributed to the negative phase in BM learning where a Gibbs sampling chain should be run to equilibrium. Hinton (1999, 2000) has introduced an alternative called contrastive divergence (CD) learning where the chain is run for only 1 step. In this paper we analyse the mean and variance of the parameter update obtained after steps of Gibbs sampling for a simple Gaussian BM. For this model our analysis shows that CD learning produces (as expected) a biased estimate of the true parameter update. We also show that the variance does usually increase with and quantify this behaviour."
            },
            "slug": "An-analysis-of-contrastive-divergence-learning-in-Williams-Agakov",
            "title": {
                "fragments": [],
                "text": "An analysis of contrastive divergence learning in gaussian boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper analyses the mean and variance of the parameter update obtained after steps of Gibbs sampling for a simple Gaussian BM and shows that CD learning produces (as expected) a biased estimate of the true parameter update."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109302670"
                        ],
                        "name": "Xiuwen Liu",
                        "slug": "Xiuwen-Liu",
                        "structuredName": {
                            "firstName": "Xiuwen",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiuwen Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 133
                            }
                        ],
                        "text": "These algorithms are reviewed in [7] and have been used, for example, to learn probability distributions for modelling image texture [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 304863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf73e4c670f0295e07a1b538958f98fbebe9a0f9",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Gibbsian fields or Markov random fields are widely used in Bayesian image analysis, but learning Gibbs models is computationally expensive. The computational complexity is pronounced by the recent minimax entropy (FRAME) models which use large neighborhoods and hundreds of parameters. In this paper, we present a common framework for learning Gibbs models. We identify two key factors that determine the accuracy and speed of learning Gibbs models: The efficiency of likelihood functions and the variance in approximating partition functions using Monte Carlo integration. We propose three new algorithms. In particular, we are interested in a maximum satellite likelihood estimator, which makes use of a set of precomputed Gibbs models called \"satellites\" to approximate likelihood functions. This algorithm can approximately estimate the minimax entropy model for textures in seconds in a HP workstation. The performances of various learning algorithms are compared in our experiments."
            },
            "slug": "Learning-in-Gibbsian-Fields:-How-Accurate-and-How-Zhu-Liu",
            "title": {
                "fragments": [],
                "text": "Learning in Gibbsian Fields: How Accurate and How Fast Can It Be?"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A unified framework for learning Gibbs models from training images is presented and three new learning algorithms under the unified framework are proposed that can speed up the minimax entropy algorithm by about 2D times without losing much accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 44
                            }
                        ],
                        "text": "But adapting his mathematical techniques to Contrastive Divergence is beyond the scope of this paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 24
                            }
                        ],
                        "text": "This paper analyses the Contrastive Divergence algorithm for learning statistical parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "Finally, the analysis in this paper does not seem to capture many of the intuitions behind Contrastive Divergence [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 41
                            }
                        ],
                        "text": "The goal of this paper was to relate the Contrastive Divergence (CD) algorithm to the stochastic approximation literature."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Recently Hinton proposed a new algorithm called contrastive divergences (CD) [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": true,
            "numCitedBy": 4571,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 101
                            }
                        ],
                        "text": "Theoretical analysis shows that CD can fail but does not give conditions which guarantee convergence [3,4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6951034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6069ec0d0387b3f3516ae83ff108a581f10a76e4",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The Hinton network (Hinton, 2001, personal communication) is a deterministic mapping from an observable space x to an energy function E(x; w), parameterized by parameters w. The energy deflnes a probability P(xjw) = exp(iE(x; w))=Z(w). A maximum likelihood learning algorithm for this density model takes steps \u00a2w/ihgi 0 + hgi 1 where hgi 0 is the average of the gradient g = @E=@w evaluated at points x drawn from the data density, and hgi 1 is the average gradient for points x drawn from P(xjw). If T is a Markov chain in x-space that has P(xjw) as its unique invariant density then we can approximate hgi 1 by taking the data points x and hitting each of them I times with T, where I is a large integer. In the one-step learning algorithm of Hinton (2001), we set I to 1. In this paper I give examples of models E(x; w) and Markov chains T for which the true likelihood is unimodal in the parameters, but the one-step algorithm does not necessarily converge to the maximum likelihood parameters. It is hoped that these negative examples will help pin down the conditions for the one-step algorithm to be a correctly convergent algorithm. The Hinton network (Hinton, 2001, personal communication) is a deterministic mapping from anobservablespace xofdimension Dtoanenergyfunction E(x;w),parameterizedbyparameters w. The energy deflnesa probability"
            },
            "slug": "Failures-of-the-One-Step-Learning-Algorithm-Mackay",
            "title": {
                "fragments": [],
                "text": "Failures of the One-Step Learning Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Examples of models E(x; w) and Markov chains T for which the true likelihood is unimodal in the parameters are given, but the one-step algorithm does not necessarily converge to the maximum likelihood parameters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721284"
                        ],
                        "name": "L. Younes",
                        "slug": "L.-Younes",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Younes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Younes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 141
                            }
                        ],
                        "text": "The theorem is chosen because of the simplicity of its proof and we point out that a large variety of alternative results are available, see [6,7,9] and the references they cite."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "In particular, Younes [7] gives convergence results when the gradient of the energy \u2202E(x;\u03c9)/\u2202\u03c9 is bounded by a term that is linear in \u03c9 (and hence unbounded)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 142
                            }
                        ],
                        "text": "This stochastic approximation algorithm, and its many variants, have been extensively studied and convergence results have been obtained (see [7])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "These algorithms are reviewed in [7] and have been used, for example, to learn probability distributions for modelling image texture [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 88
                            }
                        ],
                        "text": "powerful results can be obtained by adapting the convergence theorems in the literature [6,7,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "We conjecture that far stronger results can be obtained by applying more advanced techniques such as those described by Younes [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 204
                            }
                        ],
                        "text": "We conjecture that weaker conditions, such as requiring only that the gradient ofE(x;\u03c9) be bounded by a function linear in \u03c9, can be obtained using the more sophisticated martingale analysis described in [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 15
                            }
                        ],
                        "text": "In particular, Younes [7] gives convergence results when the gradient of the energy \u2202E(x;\u03c9)/\u2202\u03c9 is bounded by a term that is linear in\u03c9 (and hence unbounded)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15419929,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "ca9b21e84ffc7e193d1b3bb45fb7c4e48226b59e",
            "isKey": true,
            "numCitedBy": 153,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyse the convergence of stochastic algorithms with Markovian noise when the ergodicity of the Markov chain governing the noise rapidly decreases as the control parameter tends to infinity. In such a case, there may be a positive probability of divergence of the algorithm in the classic Robbins-Monro form. We provide sufficient condition which ensure convergence. Moreover, we analyse the asymptotic behaviour of these algorithms and state a diffusion approximation theorem"
            },
            "slug": "On-the-convergence-of-markovian-stochastic-with-Younes",
            "title": {
                "fragments": [],
                "text": "On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This work analyses the convergence of stochastic algorithms with Markovian noise when the ergodicity of the Markov chain governing the noise rapidly decreases as the control parameter tends to infinity and provides sufficient condition which ensure convergence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3085659"
                        ],
                        "name": "H. Kushner",
                        "slug": "H.-Kushner",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Kushner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kushner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "In particular, Kushner [9] has proven convergence to global optima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 88
                            }
                        ],
                        "text": "powerful results can be obtained by adapting the convergence theorems in the literature [6,7,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 141
                            }
                        ],
                        "text": "The theorem is chosen because of the simplicity of its proof and we point out that a large variety of alternative results are available, see [6,7,9] and the references they cite."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119339305,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f5081943e0bdc65dc4af7da55a073a5118afe77f",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The asymptotic behavior of the systems $X_{n + 1} = X_n + a_n b( {X_n ,\\xi _n } ) + a_n \\sigma ( X_n )\\psi_n $ and $dy = \\bar b( y )dt + \\sqrt {a( t )} \\sigma ( y )dw$ is studied, where $\\{ {\\psi _n } \\}$ is i.i.d. Gaussian, $\\{ \\xi _n \\}$ is a (correlated) bounded sequence of random variables and $a_n \\approx A_0/\\log (A_1 + n )$. Without $\\{ \\xi _n \\}$, such algorithms are versions of the \u201csimulated annealing\u201d method for global optimization. When the objective function values can only be sampled via Monte Carlo, the discrete algorithm is a combination of stochastic approximation and simulated annealing. Our forms are appropriate. The $\\{ \\psi _n \\}$ are the \u201cannealing\u201d variables, and $\\{ \\xi _n \\}$ is the sampling noise. For large $A_0 $, a full asymptotic analysis is presented, via the theory of large deviations: Mean escape time (after arbitrary time n) from neighborhoods of stable sets of the algorithm, mean transition times (after arbitrary time n) from a neighborhood of one stable set to another, a..."
            },
            "slug": "Asymptotic-global-behavior-for-stochastic-and-with-Kushner",
            "title": {
                "fragments": [],
                "text": "Asymptotic global behavior for stochastic approximation and diffusions with slowly decreasing noise effects: Global minimization via Monte Carlo"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34782608"
                        ],
                        "name": "G. Orr",
                        "slug": "G.-Orr",
                        "structuredName": {
                            "firstName": "Genevieve",
                            "lastName": "Orr",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3222903"
                        ],
                        "name": "T. Leen",
                        "slug": "T.-Leen",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Leen",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Within the NIPS community, Orr and Leen [10] have studied the ability of these algorithms to escape from local minima by basin hopping."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6011585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce6ff7eb1a5b88988c33470f5c2050355458e3ec",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In stochastic learning, weights are random variables whose time evolution is governed by a Markov process. At each time-step, n, the weights can be described by a probability density function P(w, n). We summarize the theory of the time evolution of P, and give graphical examples of the time evolution that contrast the behavior of stochastic learning with true gradient descent (batch learning). Finally, we use the formalism to obtain predictions of the time required for noise-induced hopping between basins of different optima. We compare the theoretical predictions with simulations of large ensembles of networks for simple problems in supervised and unsupervised learning."
            },
            "slug": "Weight-Space-Probability-Densities-in-Stochastic-Orr-Leen",
            "title": {
                "fragments": [],
                "text": "Weight Space Probability Densities in Stochastic Learning: II. Transients and Basin Hopping Times"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Theoretical predictions of the time required for noise-induced hopping between basins of different optima are compared with simulations of large ensembles of networks for simple problems in supervised and unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "This includes the (known) special case when there exists\u03c9\u2217 such thatP (x|\u03c9\u2217) = P0(x) (see [2])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "Computer simulations show that this algorithm tends to converge, and to converge rapidly, although not always to the correct solution [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52865368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b95799a25def71b100bd12e7ebb32cbcee6590bf",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new way of extending independent components analysis (ICA) to overcomplete representations. In contrast to the causal generative extensions of ICA which maintain marginal independence of sources, we define features as deterministic (linear) functions of the inputs. This assumption results in marginal dependencies among the features, but conditional independence of the features given the inputs. By assigning energies to the features a probability distribution over the input states is defined through the Boltzmann distribution. Free parameters of this model are trained using the contrastive divergence objective (Hinton, 2002). When the number of features is equal to the number of input dimensions this energy-based model reduces to noiseless ICA and we show experimentally that the proposed learning algorithm is able to perform blind source separation on speech data. In additional experiments we train overcomplete energy-based models to extract features from various standard data-sets containing speech, natural images, hand-written digits and faces."
            },
            "slug": "Energy-Based-Models-for-Sparse-Overcomplete-Teh-Welling",
            "title": {
                "fragments": [],
                "text": "Energy-Based Models for Sparse Overcomplete Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A new way of extending independent components analysis (ICA) to overcomplete representations that defines features as deterministic (linear) functions of the inputs and assigns energies to the features through the Boltzmann distribution."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398249180"
                        ],
                        "name": "John Odentrantz",
                        "slug": "John-Odentrantz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Odentrantz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Odentrantz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "But we must first introduce some background material from Markov Chain theory [12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 205458983,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "86639d68fccf9509d050ada1113adc5287507e8a",
            "isKey": false,
            "numCitedBy": 1567,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface * 1 Probability Review * 2 Discrete Time Markov Models * 3 Recurrence and Ergodicity * 4 Long Run Behavior * 5 Lyapunov Functions and Martingales * 6 Eigenvalues and Nonhomogeneous Markov Chains * 7 Gibbs Fields and Monte Carlo Simulation * 8 Continuous-Time Markov Models 9 Poisson Calculus and Queues * Appendix * Bibliography * Author Index * Subject Index"
            },
            "slug": "Markov-Chains:-Gibbs-Fields,-Monte-Carlo-and-Queues-Odentrantz",
            "title": {
                "fragments": [],
                "text": "Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This book describes the development of Markov models for discrete-time Carlo simulation and some of the models used in this study had problems with regard to consistency and Ergodicity."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145045641"
                        ],
                        "name": "J. ffitch",
                        "slug": "J.-ffitch",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "ffitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. ffitch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14670560,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "7fd60f655c0a2c506a3071db86999444821b698d",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new multiplication algorithm for the implementation of elliptic curve cryptography (ECC) over the finite extension fields where is a prime number greater than . In the context of ECC we can assume that is a -to-bit number, and easily find values for which satisfy: , and for security reasons ! \" # $ % '&( )* ,+ . All the computations are performed within an alternate polynomial representation of the field elements which is directly obtained from the inputs. No conversion step is needed. We describe our algorithm in terms of matrix operations and point out some properties of the matrices that can be used to improve the design. The proposed algorithm is highly parallelizable and seems well adapted to hardware implementation of elliptic curve cryptosystems."
            },
            "slug": "Course-notes-ffitch",
            "title": {
                "fragments": [],
                "text": "Course notes"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Algebraic manipulation covers branches of software, particularly list processing, mathematics, notably logic and number theory, and applications largely in physics, and the lectures will deal with all of these to varying extent."
            },
            "venue": {
                "fragments": [],
                "text": "SIGSAM Bull."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47966942"
                        ],
                        "name": "G. Grimmett",
                        "slug": "G.-Grimmett",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Grimmett",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grimmett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70059285"
                        ],
                        "name": "D. Stirzaker",
                        "slug": "D.-Stirzaker",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stirzaker",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stirzaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "We now state the theorem and briefly sketch the proof which is based on martingale theory (for an introduction, see [11])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "The proof [12] is a consequence of the supermartingale convergence theorem [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120474741,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a746ef7f4060f9417bc8f13e5ce7e79b862f1ec0",
            "isKey": false,
            "numCitedBy": 2588,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Events and their probabilities random variables and their distributions discrete random variables continuous random variables generating functions and their applications Markov chains convergence of random variables random processes stationary processes renewals queues Martingales diffusion processes. Appendices: Foundations and notations history and varieties of probability John Arburthnot's preface to \"Of the Laws of Chance\" (1692)."
            },
            "slug": "Probability-and-random-processes-Grimmett-Stirzaker",
            "title": {
                "fragments": [],
                "text": "Probability and random processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144538666"
                        ],
                        "name": "J. Fitch",
                        "slug": "J.-Fitch",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Fitch",
                            "middleNames": [
                                "P"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fitch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195926166,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b79c016dc49659ca9a9ccec7020654ac1fbb9101",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Algebraic manipulation covers branches of software, particularly list processing, mathematics, notably logic and number theory, and applications largely in physics. The lectures will deal with all of these to a varying extent. The mathematical content will be kept to a minimum."
            },
            "slug": "Course-notes-Fitch",
            "title": {
                "fragments": [],
                "text": "Course notes"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Algebraic manipulation covers branches of software, particularly list processing, mathematics, notably logic and number theory, and applications largely in physics, and the lectures will deal with all of these to varying extent."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 65
                            }
                        ],
                        "text": "This paper relates CD to the stochastic approximation literature [5,6] and hence derives elementary conditions which ensure convergence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 116
                            }
                        ],
                        "text": "We conjecture that far more powerful results can be obtained by adapting the convergence theorems in the literature [6,7,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 75
                            }
                        ],
                        "text": "Van Roy, Stanford) and a large variety of other results are available, see [6,7,9] and the references they cite."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "The convergence results are based on stochastic approximation theorems [6] whose history starts with the analysis of the Robbins-Monro algorithm [5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Approximation for Constrained and Unconstrained Systems"
            },
            "venue": {
                "fragments": [],
                "text": "New York. Springer-Verlag"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 65
                            }
                        ],
                        "text": "This paper relates CD to the stochastic approximation literature [5,6] and hence derives elementary conditions which ensure convergence (with probability 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 88
                            }
                        ],
                        "text": "powerful results can be obtained by adapting the convergence theorems in the literature [6,7,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 141
                            }
                        ],
                        "text": "The theorem is chosen because of the simplicity of its proof and we point out that a large variety of alternative results are available, see [6,7,9] and the references they cite."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "The convergence results are based on stochastic approximation theorems [6] whose history starts with the analysis of the Robbins-Monro algorithm [5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Approximation for Constrained and Unconstrained Systems.New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92175817"
                        ],
                        "name": "V. Nollau",
                        "slug": "V.-Nollau",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Nollau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Nollau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121799979,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "46692b79455631f27ab7b26b0bcea91d2679b079",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Kushner,-H.-J./Clark,-D.-S.,-Stochastic-Methods-for-Nollau",
            "title": {
                "fragments": [],
                "text": "Kushner, H. J./Clark, D. S., Stochastic Approximation Methods for Constrained and Unconstrained Systems. (Applied Mathematical Sciences 26). Berlin\u2010Heidelberg\u2010New York, Springer\u2010Verlag 1978. X, 261 S., 4 Abb., DM 26,40. US $ 13.20"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "But we must first introduce some background material from Markov Chain theory [13]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bremaud. Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues.Springer"
            },
            "venue": {
                "fragments": [],
                "text": "New York"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 16,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Convergence-of-Contrastive-Divergences-Yuille/883b8a189fe1bb97b9ad2a382e057ba7e2a2e56f?sort=total-citations"
}