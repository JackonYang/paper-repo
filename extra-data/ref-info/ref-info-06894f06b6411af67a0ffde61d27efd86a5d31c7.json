{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718590"
                        ],
                        "name": "R. Gaizauskas",
                        "slug": "R.-Gaizauskas",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gaizauskas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gaizauskas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6456136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98dccde28a5f7ec0549598933c72b4e99b9dd0ff",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 150,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we give a synoptic view of the growth of the text processing technology of information extraction (IE) whose function is to extract information about a pre\u2010specified set of entities, relations or events from natural language texts and to record this information in structured representations called templates. Here we describe the nature of the IE task, review the history of the area from its origins in AI work in the 1960s and 70s till the present, discuss the techniques being used to carry out the task, describe application areas where IE systems are or are about to be at work, and conclude with a discussion of the challenges facing the area. What emerges is a picture of an exciting new text processing technology with a host of new applications, both on its own and in conjunction with other technologies, such as information retrieval, machine translation and data mining."
            },
            "slug": "Information-Extraction:-Beyond-Document-Retrieval-Gaizauskas-Wilks",
            "title": {
                "fragments": [],
                "text": "Information Extraction: Beyond Document Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A synoptic view of the growth of the text processing technology of information extraction whose function is to extract information about a pre\u2010specified set of entities, relations or events from natural language texts and to record this information in structured representations called templates is given."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Comput. Linguistics Chin. Lang. Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48949093"
                        ],
                        "name": "R. Basili",
                        "slug": "R.-Basili",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Basili",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basili"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3051418"
                        ],
                        "name": "R. Catizone",
                        "slug": "R.-Catizone",
                        "structuredName": {
                            "firstName": "Roberta",
                            "lastName": "Catizone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Catizone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802339"
                        ],
                        "name": "M. Pazienza",
                        "slug": "M.-Pazienza",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Pazienza",
                            "middleNames": [
                                "Teresa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazienza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144795097"
                        ],
                        "name": "Mark Stevenson",
                        "slug": "Mark-Stevenson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Stevenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Stevenson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782522"
                        ],
                        "name": "P. Velardi",
                        "slug": "P.-Velardi",
                        "structuredName": {
                            "firstName": "Paola",
                            "lastName": "Velardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Velardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3245573"
                        ],
                        "name": "Michele Vindigni",
                        "slug": "Michele-Vindigni",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Vindigni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Vindigni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3843042,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5a9ae629c462bbb3418e1d2f0d1c31fc35ab7dcc",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "NLP systems crucially depend on the knowledge structures devoted to describing and representing word senses. Although automatic Word Sense Disambiguation (WSD) is now an established task within empirically-based computational approaches to NLP, the suitability of the available set (and granularity) of senses is still a problem. Application domains exhibit speci c behaviors that cannot be fully predicted in advance. Suitable adaptation mechanisms have to be made available to NLP systems to tune existing large scale sense repositories to the practical needs of the target application, such as information extraction or machine translation. In this paper we describe a model of \"lexical tuning\" {the systematic adaptation of a lexicon to a corpus|that specializes the set of verb senses required for an NLP application, and builds inductively the corresponding lexical descriptions for those senses. 1 Word Sense Disambiguation and Lexical Tuning It is a commonplace observation (and the basis of much research e.g. [Rilo and Lehnert1993] that lexicons must be tuned or adapted to new domain corpora. This aspect, now often called Lexical Tuning, can take a number of forms, including: (a) adding a new sense to the lexical entry for a word (b) adding an entry for a word not already in the lexicon (c) adding a subcategorization or preference pattern etc. to any existing sense entry The system we describe is an original architecture for the overall task of corpus-based lexical tuning. This task is of general theoretical interest, but one that it is di cult to test directly, as a distinct NLP task, largely because of the di culty of incorporating the phenomenon into the standard markup-modeland-test paradigm of current empirical linguistics. A central issue in any application of empirical methods to computational linguistics is the evaluation procedure used, which is normally taken to consist in some form of experiment using premarked-up text divided into training and (unseen) test portions. Apart from the wellknown problem of the di erence between sense-sets in di erent lexicons, there are problems concerned with subjects having di culty assigning a word occurrence to one and only one sense during this markup phase. Kilgarri [Kilgarri 1993] has described such problems, though his gures suggest the di culties are probably not as serious as he claims [Wilks1997]. However,we have to ask what it means to evaluate the process of Lexical Tuning: this seems to require annotating in advance a new sense in a corpus that does not occur in the reference lexicon, when developing gold standard data for testing basic WSD. The clear answer is that, on the description given above, the sense extension (task (a) above: tuning to a new sense) CANNOT be pre-tagged and so no success rate for WSD can possibly exceed 100% MINUS the percentage of extended sense occurrences. One issue about lexical tuning that is not often discussed is: what the percentage of senses needing tuning IS in normal text? One anecdotal fact sometimes used is that, in any randomly chosen newspaper paragraph, each sentence will be likely to have an extended sense of at least one word, usually a verb, in the sense of a use that breaks conventional preferences and which might be considered extended or metaphorical use, and quite likely not in a standard lexicon. This is a claim that can be easily tested by anyone with a newspaper and a standard dictionary. The assumption under test in our project is that lexical tuning will assist the adaptation of a NLP task (e.g. Information Extraction) to a new domain and can therefore best be tested indirectly by its augmentation of the target system performances. There is already substantial evidence that some form of word sense disambiguation (WSD) assists any NL task, when applied as a separate module, and lexical tuning can be seen as a more advanced form of WSD. A second assumption not addressed in literature is that a tuned lexicon can signi cantly help the task of automatic pattern acquisition for template lling in an IE system. Currently, this task is largely performed by hand, with the help of more or less sophisticated interfaces [R. Yangarber1997]. The key idea adopted here is that an established initial lexicon can be tuned or adapted for verb senses in a given application domain. First verb occurrences in a corpus are distributed over a classi er that clusters their subcategorization patterns. This distribution allows a judgment of when a new pattern in the corpus, and not in the initial lexicon, should be assigned to an existing sense of the target dictionary, or established as a new sense to be added to it. 2 A general architecture for lexical tuning The proposed Lexical Tuning system rst processes a corpus with a tagger [Brill1992] and shallow parser 1. The structures so derived (essentially the subcategorization patterns (hereafter subcat) of individual verb occurrences in the corpus) are the distributed over a lattice structure, called a Galois Lattice (hereafter RGL), by an inductive method described in [Basili et al.1997], and brie y summarized in the next section. This is a device by which each occurring set of syntactic properties, for a given verb, is assigned to one node on the lattice, in an appropriate position for partial orderings with respect to all other subcat distributions. It is thus a sorting frame, with set inclusion relations, for the contexts of each appearance of the verb in the corpus."
            },
            "slug": "An-empirical-approach-to-Lexical-Tuning-Basili-Catizone",
            "title": {
                "fragments": [],
                "text": "An empirical approach to Lexical Tuning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A model of \"lexical tuning\" {the systematic adaptation of a lexicon to a corpus| that specializes the set of verb senses required for an NLP application, and builds inductively the corresponding lexical descriptions for those senses are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786957"
                        ],
                        "name": "David S. Day",
                        "slug": "David-S.-Day",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Day",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Day"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2757028"
                        ],
                        "name": "J. Aberdeen",
                        "slug": "J.-Aberdeen",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Aberdeen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aberdeen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2683445"
                        ],
                        "name": "Robyn Kozierok",
                        "slug": "Robyn-Kozierok",
                        "structuredName": {
                            "firstName": "Robyn",
                            "lastName": "Kozierok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robyn Kozierok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066645774"
                        ],
                        "name": "Patricia Robinson",
                        "slug": "Patricia-Robinson",
                        "structuredName": {
                            "firstName": "Patricia",
                            "lastName": "Robinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patricia Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2200382"
                        ],
                        "name": "M. Vilain",
                        "slug": "M.-Vilain",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Vilain",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vilain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16299418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ec06723d92e3b5775a9b6337d50d0c26ac503af",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Historically, tailoring language processing systems to specific domains and languages for which they were not originally built has required a great deal of effort. Recent advances in corpus-based manual and automatic training methods have shown promise in reducing the time and cost of this porting process. These developments have focused even greater attention on the bottleneck of acquiring reliable, manually tagged training data. This paper describes a new set of integrated tools, collectively called the Alembic Workbench, that uses a mixed-initiative approach to \"bootstrapping\" the manual tagging process, with the goal of reducing the overhead associated with corpus development. Initial empirical studies using the Alembic Workbench to annotate \"named entities\" demonstrates that this approach can approximately double the production rate. As an added benefit, the combined efforts of machine and user produce domain specific annotation rules that can be used to annotate similar texts automatically through the Alembic-NLP system. The ultimate goal of this project is to enable end users to generate a practical domain-specific information extraction system within a single session."
            },
            "slug": "Mixed-Initiative-Development-of-Language-Processing-Day-Aberdeen",
            "title": {
                "fragments": [],
                "text": "Mixed-Initiative Development of Language Processing Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new set of integrated tools, collectively called the Alembic Workbench, that uses a mixed-initiative approach to \"bootstrapping\" the manual tagging process, with the goal of reducing the overhead associated with corpus development."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069371110"
                        ],
                        "name": "Karen Jensen",
                        "slug": "Karen-Jensen",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2488519"
                        ],
                        "name": "G. Heidorn",
                        "slug": "G.-Heidorn",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Heidorn",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Heidorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3278929"
                        ],
                        "name": "Stephen D. Richardson",
                        "slug": "Stephen-D.-Richardson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Richardson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen D. Richardson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60827403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f80818f671774ef5078bacb69fca44ea0519120b",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language is easy for people and hard for machines. For two generations, the tantalizing goal has been to get computers to handle human languages in ways that will be compelling and useful to people. Obstacles are many and legendary. Natural Language Processing: The PLNLP Approach describes one group's decade of research in pursuit of that goal. A very broad coverage NLP system, including a programming language (PLNLP) development tools, and analysis and synthesis components, was developed and incorporated into a variety of well-known practical applications, ranging from text critiquing (CRITIQUE) to machine translation (e.g. SHALT). This books represents the first published collection of papers describing the system and how it has been used. Twenty-six authors from nine countries contributed to this volume. Natural language analysis, in the PLNLP approach, is done is six stages that move smoothly from syntax through semantics into discourse. The initial syntactic sketch is provided by an Augmented Phrase Structure Grammar (APSG) that uses exclusively binary rules and aims to produce some reasonable analysis for any input string. Its `approximate' analysis passes to the reassignment component, which takes the default syntactic attachments and adjusts them, using semantic information obtained by parsing definitions and example sentences from machine-readable dictionaries. This technique is an example of one facet of the PLNLP approach: the use of natural language itself as a knowledge representation language -- an innovation that permits a wide variety of online text materials to be exploited as sources of semantic information. The next stage computes the intrasential argument structure and resolves all references, both NP- and VP-anaphora, that can be treated at this point in the processing. Subsequently, additional components, currently not so well developed as the earlier ones, handle the further disambiguation of word senses, the normalization of paraphrases, and the construction of a paragraph (discourse) model by joining sentential semantic graphs. Natural Language Processing: The PLNLP Approach acquaints the reader with the theory and application of a working, real-world, domain-free NLP system, and attempts to bridge the gap between computational and theoretical models of linguistic structure. It provides a valuable resource for students, teachers, and researchers in the areas of computational linguistics, natural processing, artificial intelligence, and information science."
            },
            "slug": "Natural-Language-Processing:-The-PLNLP-Approach-Jensen-Heidorn",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing: The PLNLP Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The reader is presented with the theory and application of a working, real-world, domain-free NLP system, and attempts to bridge the gap between computational and theoretical models of linguistic structure."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48949093"
                        ],
                        "name": "R. Basili",
                        "slug": "R.-Basili",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Basili",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basili"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802339"
                        ],
                        "name": "M. Pazienza",
                        "slug": "M.-Pazienza",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Pazienza",
                            "middleNames": [
                                "Teresa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazienza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206642991,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "83d27ef7bcef7d97c3e33089766482cbbeb76620",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "The estimation of probabilistic preference for prepositional disambiguation as well as other acquisition modules (e.g. the Lexicon Acquisition module) crucially depend on naive semantic types . However, semantic ambiguity still exists even if high level tags (e.g. In s t rumen t or Human E n t i t y ) are used. An average of 2.8 classes per noun has been evaluated in a 1.300.000 words corpus of financial news ([5]). In the architecture of Fig. (2) a specific module (i.e. \"Semantic Tuning and Classification\") is foreseen for acquisition of semantic classification rules in a domain. An unsupervised method for (1) tuning an existing taxonomy (i.e. Wordnet) by means of an application corpus and (2) local word sense disambiguation has been described in [13, 12]. Collective contexts as hints for sense assignment (in the narrow meaning of semantic classification) are used in a way similar to [79]. However, as opposed to this approach, a method to bias the probabilistic model of semantic classes (i.e. conditional probabilities of typical contexts) to the corpus is proposed: representative nouns/verbs in each semantic class are first selected according to the corpus and Wordnet. Only representative candidates in each class are thus used during the learning phase (see [12] for details). Performance evaluation on samples of verbs and nouns in"
            },
            "slug": "Lexical-Acquisition-and-Information-Extraction-Basili-Pazienza",
            "title": {
                "fragments": [],
                "text": "Lexical Acquisition and Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A method to bias the probabilistic model of semantic classes (i.e. conditional probabilities of typical contexts) to the corpus is proposed: representative nouns/verbs in each semantic class are first selected according to the Corpus and Wordnet."
            },
            "venue": {
                "fragments": [],
                "text": "SCIE"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691929"
                        ],
                        "name": "D. Hiemstra",
                        "slug": "D.-Hiemstra",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Hiemstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hiemstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097974"
                        ],
                        "name": "F. D. Jong",
                        "slug": "F.-D.-Jong",
                        "structuredName": {
                            "firstName": "Franciska",
                            "lastName": "Jong",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Jong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57184145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a334679b6fd7a556e4829bcf0fe627c69fbeed8",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an overview of the tools and methods for Cross-Language Information Retrieval (CLIR) that were developed within the Twenty-One project. The tools and methods are evaluated with the TREC CLIR task document collection using Dutch queries on the English document base. The main issue addressed here is an evaluation of two approaches to disambiguation. The underlying question is whether a lot of effort should be put in finding the correct translation for each query term before searching, or whether searching with more than one possible translation leads to better results? The experimental study suggests that in terms of average precision, searching with ambiguities leads to better retrieval performance than searching with disambiguated queries."
            },
            "slug": "Cross-language-retrieval-in-Twenty-One:-using-one,-Hiemstra-Jong",
            "title": {
                "fragments": [],
                "text": "Cross-language retrieval in Twenty-One: using one, some or all possible translations?"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The experimental study suggests that in terms of average precision, searching with ambiguities leads to better retrieval performance than searching with disambiguated queries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081631974"
                        ],
                        "name": "D. Bourigault",
                        "slug": "D.-Bourigault",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Bourigault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bourigault"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 156905,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "249447f2408dfc7b38b1ce5e6b6ab9769d54c4fa",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a method for structural noun phrase disambiguation which mainly relies on the examination of the text corpus under analysis and doesn't need to integrate any domain-dependent lexico- or syntactico-semantic information. This method is implemented in the Terminology Extraction Sottware LEXTER. We first explain why the integration of LEXTER in the LEXTER-K project, which aims at building a tool for knowledge extraction from large technical text corpora, requires improving the quality of the terminolgy extracted by LEXTER. Then we briefly describe the way LEXTER works and show what kind of disambiguation it has to perform when parsing \"maximal-length\" noun phrases. We introduce a method of disambiguation which relies on a very simple idea: whenever LEXTER has to choose among several competing noun sub-groups in order to disambiguate a maximal-length noun phrase, it checks each of these sub-groups if it occurs anywhere else in the corpus in a non-ambiguous situation, and then it makes a choice. The half-a-million words corpus analysis resulted in an efficient strategy of disambiguation. The average rates are:27% no disambiguation70% correct disambiguation3% wrong disambiguation"
            },
            "slug": "An-Endogeneous-Corpus-Based-Method-for-Structural-Bourigault",
            "title": {
                "fragments": [],
                "text": "An Endogeneous Corpus-Based Method for Structural Noun Phrase Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A method for structural noun phrase disambiguation which mainly relies on the examination of the text corpus under analysis and doesn't need to integrate any domain-dependent lexico- or syntactico-semantic information."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753394"
                        ],
                        "name": "D. Bobrow",
                        "slug": "D.-Bobrow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699245"
                        ],
                        "name": "T. Winograd",
                        "slug": "T.-Winograd",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7965074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "033ecd544c4e71b14a7d3ee0611a300a20b91232",
            "isKey": false,
            "numCitedBy": 950,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes KRL, a Knowledge Representation Language designed for use in understander systems. It outlines both the general concepts which underlie our research and the details of KRL-0, an experimental implementation of some of these concepts. KRL is an attempt to integrate procedural knowledge with a broad base of declarative forms. These forms provide a variety of ways to express the logical structure of the knowledge, in order to give flexibility in associating procedures (for memory and reasoning) with specific pieces of knowledge, and to control the relative accessibility of different facts and descriptions. The formalism for declarative knowledge is based on structured conceptual objects with associated descriptions. These objects form a network of memory units with several different sorts of linkages, each having well-specified implications for the retrieval process. Procedures can be associated directly with the internal structure of a conceptual object. This procedural attachment allows the steps for a particular operation to be determined by characteristics of the specific entities involved. The control structure of KRL is based on the belief that the next generation of intelligent programs will integrate data-directed and goal-directed processing by using multi-processing. It provides for a priority-ordered multi-process agenda with explicit (user-provided) strategies for scheduling and resource allocation. It provides procedure directories which operate along with process frameworks to allow procedural parameterization of the fundamental system processes for building, comparing, and retrieving memory structures. Future development of KRL will include integrating procedure definition with the descriptive formalism."
            },
            "slug": "On-Overview-of-KRL,-a-Knowledge-Representation-Bobrow-Winograd",
            "title": {
                "fragments": [],
                "text": "On Overview of KRL, a Knowledge Representation Language"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "KRL is an attempt to integrate procedural knowledge with a broad base of declarative forms to give flexibility in associating procedures with specific pieces of knowledge, and to control the relative accessibility of different facts and descriptions."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2614094"
                        ],
                        "name": "Rebecca F. Bruce",
                        "slug": "Rebecca-F.-Bruce",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bruce",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca F. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144850246"
                        ],
                        "name": "Louise Guthrie",
                        "slug": "Louise-Guthrie",
                        "structuredName": {
                            "firstName": "Louise",
                            "lastName": "Guthrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Louise Guthrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13089612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4ea3e2e980010703ff12466cd7413ee78d59f5e",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The automatic construction of an IS_A taxonomy of noun senses from a machine readable dictionary (MRD) has long been sought, but achieved with only limited success. The task requires the solution to two problems: 1) To define an algorithm to automatically identify the genus or hypernym of a noun definition, and 2) to define an algorithm for lexical disambiguation of the genus term. In the last few years, effective methods for solving the first problem have been developed, but the problem of creating an algorithm for lexical disambiguation of the genus terms is one that has proven to be very difficult. In COLING 90 we described our initial work on the automatic creation of a taxonomy of noun senses from Longman's Dictionary of Contemporary English (LDOCE). The algorithm for lexical disambiguation of the genus term was accurate about 80% of the time and made use of the semantic categories, the subject area markings and the frequency of use information in LDOCE. In this paper we report a series of experiments which weight the three factors in various ways, and describe our improvements to the algorithm (to about 90% accuracy)."
            },
            "slug": "Genus-Disambiguation:-A-Study-in-Weighted-Bruce-Guthrie",
            "title": {
                "fragments": [],
                "text": "Genus Disambiguation: A Study in Weighted Preference"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A series of experiments are reported which weight the three factors in various ways, and improvements to the algorithm are described, to about 90% accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50063237"
                        ],
                        "name": "R. Evans",
                        "slug": "R.-Evans",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Evans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Evans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701400"
                        ],
                        "name": "G. Gazdar",
                        "slug": "G.-Gazdar",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Gazdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gazdar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 314957,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "289c92b685c50f0bfc34c040bfc8a2727ef07823",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "Much recent research on the design of natural language lexicons has made use of nonmonotonic inheritance networks as originally developed for general knowledge representation purposes in Artificial Intelligence. DATR is a simple, spartan language for defining nonmonotonic inheritance networks with path/value equations, one that has been designed specifically for lexical knowledge representation. In keeping with its intendedly minimalist character, it lacks many of the constructs embodied either in general-purpose knowledge representation languages or in contemporary grammar formalisms. The present paper shows that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of linguistic analysis. The paper provides an informal example-based introduction to DATR and to techniques for its use, including finite-state transduction, the encoding of DAGs and lexical rules, and the representation of ambiguity and alternation. Sample analysis of phenomena such as inflectional syncretism and verbal subcategorization are given that show how the language can be used to squeeze out redundancy from lexical descriptions."
            },
            "slug": "DATR:-A-Language-for-Lexical-Knowledge-Evans-Gazdar",
            "title": {
                "fragments": [],
                "text": "DATR: A Language for Lexical Knowledge Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The paper provides an informal example-based introduction to DATR and to techniques for its use, including finite-state transduction, the encoding of DAGs and lexical rules, and the representation of ambiguity and alternation."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097974"
                        ],
                        "name": "F. D. Jong",
                        "slug": "F.-D.-Jong",
                        "structuredName": {
                            "firstName": "Franciska",
                            "lastName": "Jong",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Jong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14462368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d224ec16a7e8d706bac60c33138dcb67fa46e6c",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we will give a short overview of the \nideas underpinning the demonstrator developed \nwithin the EU-funded project Twenty-One; this \nsystem provides for the disclosure of information in a \nheterogeneous document environment that includes \ndocuments of different types and languages. As part \nof the off-line document processing that has been \nintegrated in the system noun phrases are extracted \nto build a phrase-based index. They are the starting \npoint for the generation of both a fuzzy phrase index \nand a translation step that is needed for the \nrealisation of cross-language retrieval functionality."
            },
            "slug": "Twenty-One:-a-baseline-for-multilingual-multimedia-Jong",
            "title": {
                "fragments": [],
                "text": "Twenty-One: a baseline for multilingual multimedia retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "An overview of the ideas underpinning the demonstrator developed within the EU-funded project Twenty-One, which provides for the disclosure of information in a heterogeneous document environment that includes documents of different types and languages."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2008687"
                        ],
                        "name": "U. Heid",
                        "slug": "U.-Heid",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Heid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Heid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144327932"
                        ],
                        "name": "B. M. Schulze",
                        "slug": "B.-M.-Schulze",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Schulze",
                            "middleNames": [
                                "Maximilian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M. Schulze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841438"
                        ],
                        "name": "T. Fontenelle",
                        "slug": "T.-Fontenelle",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Fontenelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Fontenelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83955772"
                        ],
                        "name": "C. Gera",
                        "slug": "C.-Gera",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Gera",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gera"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52997806,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "eb5b9a5da090e520d071fedb09422a4bb30c74df",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the problems facing the user of a bilingual dictionary is producing multiword expressions and phrases in the target language when the explicit phrasal translation does not appear in the dictionary. Defining collocations as the preferred choice of words for expressing the desired concept, the DECIDE project has been exploring how collocational information from monoand bilingual dictionaries and raw text corpora can be discovered, extracted and stored online. During the project, we have developed tools for identifying potential collocations from raw text; for marking up English, French and German text for use in an interactive corpus query tool; for accessing lexical and grammatical patterns over such a corpus via this corpus query tool; for accessing collocations derived from online bilingual dictionaries; and for documenting such collocations using available text corpora. Finally, we have produced a common interface to these textual, corpus and dictionary tools, and used this interface to create a multilingual lexicon of the collocational choices of support verbs for nominalizations of speech act verbs. This paper presents an overview of this European Union sponsored project, its objectives, its methodology, and its results."
            },
            "slug": "The-DECIDE-Project:-Multilingual-Collocation-Grefenstette-Heid",
            "title": {
                "fragments": [],
                "text": "The DECIDE Project: Multilingual Collocation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The DECIDE project has developed tools for identifying potential collocations from raw text, and produced a common interface to create a multilingual lexicon of the collocational choices of support verbs for nominalizations of speech act verbs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691929"
                        ],
                        "name": "D. Hiemstra",
                        "slug": "D.-Hiemstra",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Hiemstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hiemstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5242820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7eb4731df814c5e7dc40dbeec2a549e3737dcd7c",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new probabilistic model of information retrieval. The most important modeling assumption made is that documents and queries are defined by an ordered sequence of single terms. This assumption is not made in well known existing models of information retrieval, but is essential in the field of statistical natural language processing. Advances already made in statistical natural language processing will be used in this paper to formulate a probabilistic justification for using tf\u00d7idf term weighting. The paper shows that the new probabilistic interpretation of tf\u00d7idf term weighting might lead to better understanding of statistical ranking mechanisms, for example by explaining how they relate to coordination level ranking. A pilot experiment on the Cranfield test collection indicates that the presented model outperforms the vector space model with classical tf\u00d7idf and cosine length normalisation."
            },
            "slug": "A-Linguistically-Motivated-Probabilistic-Model-of-Hiemstra",
            "title": {
                "fragments": [],
                "text": "A Linguistically Motivated Probabilistic Model of Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The paper shows that the new probabilistic interpretation of tf\u00d7idf term weighting might lead to better understanding of statistical ranking mechanisms, for example by explaining how they relate to coordination level ranking."
            },
            "venue": {
                "fragments": [],
                "text": "ECDL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403810460"
                        ],
                        "name": "Salah Ait-Mokhtar",
                        "slug": "Salah-Ait-Mokhtar",
                        "structuredName": {
                            "firstName": "Salah",
                            "lastName": "Ait-Mokhtar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salah Ait-Mokhtar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736675"
                        ],
                        "name": "J. Chanod",
                        "slug": "J.-Chanod",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Chanod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chanod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2711126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9aefe46d2f658b1905f18d490ac109f37cdbb52f",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate an approach for fast automatic recognition and extraction of subject and object dependency relations from large French corpora, using a sequence of finite-state transducers. The extraction is performed in two major steps: incremental finite-state parsing and extraction of subject/verb and object/verb relations. Our incremental and cautious approach during the first phase allows the system to deal successfully with complex phenomena such as embeddings, coordination of VPs and NPs or non-standard word order. The extraction requires no subcategorisation information. It relies on POS information only. After describing the two steps, we give the results of an evaluation on various types of unrestricted corpora. Precision is around 90-97% for subjects (84-88% for objects) and recall around 86-92% for subjects (80-90% for objects). We also provide some error analysis; in particular, we evaluate the impact of POS tagging errors on subject/object dependency extraction."
            },
            "slug": "Subject-and-Object-Dependency-Extraction-Using-Ait-Mokhtar-Chanod",
            "title": {
                "fragments": [],
                "text": "Subject and Object Dependency Extraction Using Finite-State Transducers"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An approach for fast automatic recognition and extraction of subject and object dependency relations from large French corpora, using a sequence of finite-state transducers, and the impact of POS tagging errors on subject/object dependency extraction is evaluated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748501"
                        ],
                        "name": "Claire Cardie",
                        "slug": "Claire-Cardie",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Cardie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Cardie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11708947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6df333b6e4dc95a19fb5dcfa49dbd3ac11db967b",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This article surveys the use of empirical, machine-learning methods for a particular natural language-understanding task-information extraction. The author presents a generic architecture for information-extraction systems and then surveys the learning algorithms that have been developed to address the problems of accuracy, portability, and knowledge acquisition for each component of the architecture."
            },
            "slug": "Empirical-Methods-in-Information-Extraction-Cardie",
            "title": {
                "fragments": [],
                "text": "Empirical Methods in Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The author presents a generic architecture for information-extraction systems and then surveys the learning algorithms that have been developed to address the problems of accuracy, portability, and knowledge acquisition for each component of the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79064988"
                        ],
                        "name": "Saliha Azzam",
                        "slug": "Saliha-Azzam",
                        "structuredName": {
                            "firstName": "Saliha",
                            "lastName": "Azzam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saliha Azzam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2133902"
                        ],
                        "name": "K. Humphreys",
                        "slug": "K.-Humphreys",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Humphreys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Humphreys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718590"
                        ],
                        "name": "R. Gaizauskas",
                        "slug": "R.-Gaizauskas",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gaizauskas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gaizauskas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5607967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c4829ed93043415e3c7a8be88f6cd93563ed95",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the use of coreference chains for the production of text summaries, using a variety of criteria to select a 'best' chain to represent the main topic of a text. The approach has been implemented within an existing MUC coreference system, which constructs a full discourse model of texts, including information about changes of focus, which can be used in the selection of chains. Some preliminary experiments on the automatic evaluation of summaries are also described, using existing tools to attempt to replicate some of the recent SUMMAC manual evaluations."
            },
            "slug": "Using-Coreference-Chains-for-Text-Summarization-Azzam-Humphreys",
            "title": {
                "fragments": [],
                "text": "Using Coreference Chains for Text Summarization"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The use of coreference chains for the production of text summaries is described, using a variety of criteria to select a 'best' chain to represent the main topic of a text."
            },
            "venue": {
                "fragments": [],
                "text": "COREF@ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12309040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "733234e097dceb9011baa8914930861996eb0b5e",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Most recent research in trainable part of speech taggers has explored stochastic tagging. While these taggers obtain high accuracy, linguistic information is captured indirectly, typically in tens of thousands of lexical and contextual probabilities. In (Brill 1992), a trainable rule-based tagger was described that obtained performance comparable to that of stochastic taggers, but captured relevant linguistic information in a small number of simple non-stochastic rules. In this paper, we describe a number of extensions to this rule-based tagger. First, we describe a method for expressing lexical relations in tagging that stochastic taggers are currently unable to express. Next, we show a rule-based approach to tagging unknown words. Finally, we show how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "slug": "Some-Advances-in-Transformation-Based-Part-of-Brill",
            "title": {
                "fragments": [],
                "text": "Some Advances in Transformation-Based Part of Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method for expressing lexical relations in tagging that stochastic taggers are currently unable to express is described and how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35551590"
                        ],
                        "name": "Steven P. Abney",
                        "slug": "Steven-P.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven P. Abney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9716882,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "56d7826f3afaa374077f87ca3529709b1ca7e044",
            "isKey": false,
            "numCitedBy": 992,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "I begin with an intuition: when I read a sentence, I read it a chunk at a time. For example, the previous sentence breaks up something like this: \n \n(1) \n \n[I begin] [with an intuition]: [when I read] [a sentence], [I read it] [a chunk] [at a time] \n \n \n \n \n \n \nThese chunks correspond in some way to prosodic patterns. It appears, for instance, that the strongest stresses in the sentence fall one to a chunk, and pauses are most likely to fall between chunks. Chunks also represent a grammatical watershed of sorts. The typical chunk consists of a single content word surrounded by a constellation of function words, matching a fixed template. A simple context-free grammar is quite adequate to describe the structure of chunks. By contrast, the relationships between chunks are mediated more by lexical selection than by rigid templates. Co-occurrence of chunks is determined not just by their syntactic categories, but is sensitive to the precise words that head them; and the order in which chunks occur is much more flexible than the order of words within chunks."
            },
            "slug": "Parsing-By-Chunks-Abney",
            "title": {
                "fragments": [],
                "text": "Parsing By Chunks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The typical chunk consists of a single content word surrounded by a constellation of function words, matching a fixed template, and the relationships between chunks are mediated more by lexical selection than by rigid templates."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3338131"
                        ],
                        "name": "P. Buitelaar",
                        "slug": "P.-Buitelaar",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Buitelaar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Buitelaar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14008742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d06669b8b13ad35a6cdadcb981c6c0f70a6fa26",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper defends the notion that semantic tagging should be viewed as more than disambiguation between senses. Instead, semantic tagging should be a first step in the interpretation process by assigning each lexical item a representation of all of its systematically related senses, from which further semantic processing steps can derive discourse dependent interpretations. This leads to a new type of semantic lexicon (CoreLex) that supports underspecified semantic tagging through a design based on systematic polysemous classes and a class-based acquisition of lexical knowledge for specific domains."
            },
            "slug": "A-Lexicon-for-Underspecified-Semantic-Tagging-Buitelaar",
            "title": {
                "fragments": [],
                "text": "A Lexicon for Underspecified Semantic Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The paper defends the notion that semantic tagging should be viewed as more than disambiguation between senses and develops a new type of semantic lexicon that supports underspecified semantic tagging through a design based on systematic polysemous classes and a class-based acquisition of lexical knowledge for specific domains."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2757028"
                        ],
                        "name": "J. Aberdeen",
                        "slug": "J.-Aberdeen",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Aberdeen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aberdeen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5416402"
                        ],
                        "name": "J. Burger",
                        "slug": "J.-Burger",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786957"
                        ],
                        "name": "David S. Day",
                        "slug": "David-S.-Day",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Day",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Day"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066645774"
                        ],
                        "name": "Patricia Robinson",
                        "slug": "Patricia-Robinson",
                        "structuredName": {
                            "firstName": "Patricia",
                            "lastName": "Robinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patricia Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2200382"
                        ],
                        "name": "M. Vilain",
                        "slug": "M.-Vilain",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Vilain",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vilain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12788399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14fee4e396303e9eb00beff50ee018ca9f7aff1a",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "As with several other veteran MUC participants, MITRE's Alembic system has undergone a major transformation in the past two years. The genesis of this transformation occurred during a dinner conversation at the last MUC conference, MUC-5. At that time, several of us reluctantly admitted that our major impediment towards improved performance was reliance on then-standard linguistic models of syntax. We knew we would need an alternative to traditional linguistic grammars, even to the somewhat non-traditional categorial pseudo-parser we had in place at the time. The problem was, which alternative?"
            },
            "slug": "MITRE:-description-of-the-Alembic-system-used-for-Aberdeen-Burger",
            "title": {
                "fragments": [],
                "text": "MITRE: description of the Alembic system used for MUC-6"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "As with several other veteran MUC participants, MITRE's Alembic system has undergone a major transformation in the past two years."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49778875"
                        ],
                        "name": "Mark Lauer",
                        "slug": "Mark-Lauer",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Lauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Lauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795294"
                        ],
                        "name": "M. Dras",
                        "slug": "M.-Dras",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17644828,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "b22b62cad8f8b2a7c26d89e6b98f1fc0d5393dac",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Compound nouns such as example noun compound are becoming more common in natural language and pose a number of difficult problems for NLP systems, notably increasing the complexity of parsing. In this paper we develop a probabilistic model for syntactically analysing such compounds. The model predicts compound noun structures based on knowledge of affinities between nouns, which can be acquired from a corpus. Problems inherent in this corpus-based approach are addressed: data sparseness is overcome by the use of semantically motivated word classes and sense ambiguity is explicitly handled in the model. An implementation based on this model is described in Lauer (1994) and correctly parses 77% of the test set."
            },
            "slug": "A-Probabilistic-Model-of-Compound-Nouns-Lauer-Dras",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Model of Compound Nouns"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A probabilistic model for syntactically analysing compound noun structures based on knowledge of affinities between nouns, which can be acquired from a corpus is developed."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740640"
                        ],
                        "name": "Wessel Kraaij",
                        "slug": "Wessel-Kraaij",
                        "structuredName": {
                            "firstName": "Wessel",
                            "lastName": "Kraaij",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wessel Kraaij"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12378070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3901bc25d9b14a4bb7db70f418d0db6f26e3c336",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "TwentyOne is a EU funded project which aims at developing advanced indexing and retrieval techniques for multimedia document bases. The document base consists of documents in four languages: Dutch, English, French and German. This paper focusses on the multilingual aspects of the project: cross-language retrieval, partial document translation techniques and automatic hyperlinking between sour ce text and translations."
            },
            "slug": "Multilingual-functionality-in-the-TwentyOne-project-Kraaij",
            "title": {
                "fragments": [],
                "text": "Multilingual functionality in the TwentyOne project"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper focusses on the multilingual aspects of the TwentyOne project: cross-language retrieval, partial document translation techniques and automatic hyperlinking between sour ce text and translations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2466657"
                        ],
                        "name": "K. Koskenniemi",
                        "slug": "K.-Koskenniemi",
                        "structuredName": {
                            "firstName": "Kimmo",
                            "lastName": "Koskenniemi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koskenniemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12819449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e11ce10eff56df1729626bda3ef6109566f779c9",
            "isKey": false,
            "numCitedBy": 579,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A language independent model for recognition and production of word forms is presented. This \"two-level model\" is based on a new way of describing morphological alternations. All rules describing the morphophonological variations are parallel and relatively independent of each other. Individual rules are implemented as finite state automata, as in an earlier model due to Martin Kay and Ron Kaplan. The two-level model has been implemented as an operational computer programs in several places. A number of operational two-level descriptions have been written or are in progress (Finnish, English, Japanese, Rumanian, French, Swedish, Old Church Slavonic, Greek, Lappish, Arabic, Icelandic). The model is bidirectional and it is capable of both analyzing and synthesizing word-forms."
            },
            "slug": "A-General-Computational-Model-for-Word-Form-and-Koskenniemi",
            "title": {
                "fragments": [],
                "text": "A General Computational Model For Word-Form Recognition And Production"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A language independent model for recognition and production of word forms is presented, based on a new way of describing morphological alternations that is capable of both analyzing and synthesizing word-forms."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701400"
                        ],
                        "name": "G. Gazdar",
                        "slug": "G.-Gazdar",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Gazdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gazdar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801917"
                        ],
                        "name": "C. Mellish",
                        "slug": "C.-Mellish",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Mellish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mellish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5454734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe32895baaea4b3759dd161fa4d879d64c60baa5",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapter Objectives Natural language processing representations were presented Semantic relationships Conceptual graphs Verb-based case frames Prolog was used to build a series of parsers Context free parsers Deterministic Probabilistic Parsers Probabilistic measures for sentence structures and words Lexicalized probabilistic parsers capture word combination plausibility Context sensitive parsers Deterministic Recursive descent semantic net parsers Enforce word-based case frame constraints Because of its declarative semantics, built-in search, and pattern matching, Prolog provides an important tool for programs that process natural language. Indeed, natural language understanding was one of Prolog's earliest applications. As we will see with many examples in this chapter, we can write natural language grammars directly in Prolog, for example, context-free, context-sensitive, recursive descent semantic network, as well as stochastic parsers. Semantic representations are also easy to create in Prolog, as we see for conceptual graphs and case frames in Section 8.2. Semantic relationships may be captured either using the first-order predicate calculus or by a meta-interpreter for another representation, as suggested by semantic networks (Section 2.4.1) or frames (Sections 2.4.2 and 8.1). This not only simplifies programming, but also keeps a close connection between theories and their implementation. In Section 8.3 we present a context-free parser and later add context sensitivity to the parse Section 8.5. We accomplish many of the same justifications for context sensitivity in parsing, e.g., noun-verb agreement, with the various probabilistic parsers of Section 8.4. Finally, semantic"
            },
            "slug": "Natural-Language-Processing-in-PROLOG-Gazdar-Mellish",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing in PROLOG"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This chapter presents a context-free parser and later adds context sensitivity to the parse, and accomplishes many of the same justifications for context sensitivity in parsing with the various probabilistic parsers of Section 8.4.5."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403810460"
                        ],
                        "name": "Salah Ait-Mokhtar",
                        "slug": "Salah-Ait-Mokhtar",
                        "structuredName": {
                            "firstName": "Salah",
                            "lastName": "Ait-Mokhtar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salah Ait-Mokhtar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736675"
                        ],
                        "name": "J. Chanod",
                        "slug": "J.-Chanod",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Chanod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chanod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2067055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea599b04fced33b0a38646c2df1dbf93f0fa7163",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new finite-state shallow parser. It merges constructive and reductionist approaches within a highly modular architecture. Syntactic information is added at the sentence level in an incremental way, depending on the contextual information available at a given stage. This approach overcomes the inefficiency of previous fully reductionist constraint-based systems, while maintaining broad coverage and linguistic granularity. The implementation relies on a sequence of networks built with the replace operator. Given the high level of modularity, the core grammar is easily augmented with corpus-specific sub-grammars. The current system is implemented for French and is being expanded to new languages."
            },
            "slug": "Incremental-Finite-State-Parsing-Ait-Mokhtar-Chanod",
            "title": {
                "fragments": [],
                "text": "Incremental Finite-State Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper describes a new finite-state shallow parser that overcomes the inefficiency of previous fully reductionist constraint-based systems, while maintaining broad coverage and linguistic granularity."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867844"
                        ],
                        "name": "Nancy A. Chinchor",
                        "slug": "Nancy-A.-Chinchor",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Chinchor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy A. Chinchor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16857799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "facef9d98129c394beb5de4e0a6a144e602b492d",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes and analyzes the results of the Third Message Understanding Conference (MUC-3). It reviews the purpose, history, and methodology of the conference, summarizes the participating systems, discusses issues of measuring system effectiveness, describes the linguistic phenomena tests, and provides a critical look at the evaluation in terms of the lessons learned. One of the common problems with evaluations is that the statistical significance of the results is unknown. In the discussion of system performance, the statistical significance of the evaluation results is reported and the use of approximate randomization to calculate the statistical significance of the results of MUC-3 is described."
            },
            "slug": "Evaluating-Message-Understanding-Systems:-An-of-the-Chinchor-Hirschman",
            "title": {
                "fragments": [],
                "text": "Evaluating Message Understanding Systems: An Analysis of the Third Message Understanding Conference (MUC-3)"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "The purpose, history, and methodology of the conference are reviewed, the participating systems are summarized, issues of measuring system effectiveness are discussed, the linguistic phenomena tests are described, and a critical look at the evaluation in terms of the lessons learned is provided."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52018505"
                        ],
                        "name": "T. Giv\u00f3n",
                        "slug": "T.-Giv\u00f3n",
                        "structuredName": {
                            "firstName": "Talmy",
                            "lastName": "Giv\u00f3n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Giv\u00f3n"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57508517,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "5dc6ba9718067ae946c5ed32646fa45e52a98a9f",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The shifting of the grammatical category of lexical items (nouns, verbs, adjectives) without overt morphological affixation was studied and compared with derivational morphology and nonaffixal sense development. The semantic processes underlying all these operations were found to be identical. They were described by two steps: the first, deletion on the surface of the utterance; the second, semantic reinterpretation of the remaining lexical material. It was found that the process of sense development or coinage of new vocabulary items always involves increasing the complexity of semantic structure, the counterpart of which is decreasing the complexity of surface phonological structure. The net result is that the semantics of lexical items seems to grow progressively more complex, in time. The semantic structure of both nouns and verbs seems to build up compositionally, in ways shown to be formally distinct. Underlying every verb sense is a verb phrase comprised of at least a main verb. Underlying every noun sense is a noun phrase comprised of at least a head noun plus any number of restrictive relative clauses. It is strongly suggested that these main verbs and head nouns are involved in the system of semantic classification of nouns and verbs. It is further suggested that they also underly or determine the overt syntactic behaviors of nouns and verbs, and that 'syntactic' phenomena are the reflection of semantic structure. (Author)"
            },
            "slug": "TRANSFORMATIONS-OF-ELLIPSIS,-SENSE-DEVELOPMENT-AND-Giv\u00f3n",
            "title": {
                "fragments": [],
                "text": "TRANSFORMATIONS OF ELLIPSIS, SENSE DEVELOPMENT AND RULES OF LEXICAL DERIVATION,"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The shifting of the grammatical category of lexical items without overt morphological affixation was studied and compared with derivational morphology and nonaffixal sense development, and it was found that the process of sense development or coinage of new vocabulary items always involves increasing the complexity of semantic structure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2425578"
                        ],
                        "name": "L. Karttunen",
                        "slug": "L.-Karttunen",
                        "structuredName": {
                            "firstName": "Lauri",
                            "lastName": "Karttunen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Karttunen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2444688,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "cfa202e2ac9efe6ac485da26d3caf81d499d7f38",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A lexical transducer, first discussed in Karttunen, Kaplan and Zaenen 1992, is a specialised finite-state automaton that maps inflected surface forms to lexical forms, and vice versa. The lexical form consists of a canonical representation of the word and a sequence of tags that show the morphological characteristics of the form in question and its syntactic category. For example, a lexical transducer for French might relate the surface form veut to the lexical form vouloir+IndPr+SG+P3. In order to map between these two forms, the transducer may contain a path like the one shown in Fig. 1."
            },
            "slug": "Constructing-Lexical-Transducers-Karttunen",
            "title": {
                "fragments": [],
                "text": "Constructing Lexical Transducers"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A lexical transducer, first discussed in Karttunen, Kaplan and Zaenen 1992, is a specialised finite-state automaton that maps inflected surface forms to lexical forms, and vice versa."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "108510257"
                        ],
                        "name": "D. F. Jong",
                        "slug": "D.-F.-Jong",
                        "structuredName": {
                            "firstName": "de",
                            "lastName": "Jong",
                            "middleNames": [
                                "Franciska"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. F. Jong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685010"
                        ],
                        "name": "J. Gauvain",
                        "slug": "J.-Gauvain",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Gauvain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gauvain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404415974"
                        ],
                        "name": "den Jurgen Hartog",
                        "slug": "den-Jurgen-Hartog",
                        "structuredName": {
                            "firstName": "den",
                            "lastName": "Hartog",
                            "middleNames": [
                                "Jurgen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "den Jurgen Hartog"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087277477"
                        ],
                        "name": "K. Netter",
                        "slug": "K.-Netter",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Netter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Netter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54141826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ef2109081f36b463df512b5c4d0e6f4712c43ee",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the Olive project which aims to support automated indexing of video material by use of human language technologies. Olive is making use of speech recognition to automatically derive transcriptions of the sound tracks, generating time-coded linguistic elements which serve as the basis for text-based retrieval functionality. The retrieval demonstrator builds on and extends the architecture from the Pop-Eye project, a system applying human language technology on subtitles for the disclosure of video fragments."
            },
            "slug": "OLIVE:-Speech-Based-Video-Retrieval-Jong-Gauvain",
            "title": {
                "fragments": [],
                "text": "OLIVE: Speech-Based Video Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The Olive project, a system applying human language technology on subtitles for the disclosure of video fragments, is making use of speech recognition to automatically derive transcriptions of the sound tracks, generating time-coded linguistic elements which serve as the basis for text-based retrieval functionality."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643814930"
                        ],
                        "name": "BrillEric",
                        "slug": "BrillEric",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "BrillEric",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "BrillEric"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215979972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afa13fa294b63c00ce03771b81416bdd4bd49837",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, there has been a rebirth of empiricism in the field of natural language processing. Manual encoding of linguistic information is being challenged by automated corpus-based learning as a m..."
            },
            "slug": "Transformation-based-error-driven-learning-and-BrillEric",
            "title": {
                "fragments": [],
                "text": "Transformation-based error-driven learning and natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "There has been a rebirth of empiricism in the field of natural language processing and manual encoding of linguistic information is being challenged by automated corpus-based learning as a challenge to manual encoding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086230401"
                        ],
                        "name": "James R. Cowie",
                        "slug": "James-R.-Cowie",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cowie",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Cowie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072992399"
                        ],
                        "name": "Louise Guthrie",
                        "slug": "Louise-Guthrie",
                        "structuredName": {
                            "firstName": "Louise",
                            "lastName": "Guthrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Louise Guthrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112344206"
                        ],
                        "name": "Wang Jin",
                        "slug": "Wang-Jin",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076189715"
                        ],
                        "name": "William C. Ogden",
                        "slug": "William-C.-Ogden",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Ogden",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William C. Ogden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057687016"
                        ],
                        "name": "James Pustejovsky",
                        "slug": "James-Pustejovsky",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pustejovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Pustejovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155889645"
                        ],
                        "name": "Rong Wang",
                        "slug": "Rong-Wang",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093354007"
                        ],
                        "name": "Takahiro Wakao",
                        "slug": "Takahiro-Wakao",
                        "structuredName": {
                            "firstName": "Takahiro",
                            "lastName": "Wakao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takahiro Wakao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899984"
                        ],
                        "name": "Scott Waterman",
                        "slug": "Scott-Waterman",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Waterman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Waterman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48309893"
                        ],
                        "name": "Yorick Wilks",
                        "slug": "Yorick-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yorick Wilks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1889753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c887ec6570875d0e58ac103c750f012d2845012b",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Diderot is an information extraction system built at CRL and Brandeis University over the past two years. It was produced as part of our efforts in the Tipster project. The same overall system architecture has been used for English and Japanese and for the micro-electronics and joint venture domains."
            },
            "slug": "CRL/BRANDEIS:-The-Diderot-System-Cowie-Guthrie",
            "title": {
                "fragments": [],
                "text": "CRL/BRANDEIS: The Diderot System"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Diderot is an information extraction system built at CRL and Brandeis University over the past two years and was produced as part of the Tipster project."
            },
            "venue": {
                "fragments": [],
                "text": "TIPSTER"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2425578"
                        ],
                        "name": "L. Karttunen",
                        "slug": "L.-Karttunen",
                        "structuredName": {
                            "firstName": "Lauri",
                            "lastName": "Karttunen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Karttunen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736675"
                        ],
                        "name": "J. Chanod",
                        "slug": "J.-Chanod",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Chanod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chanod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146185957"
                        ],
                        "name": "A. Schille",
                        "slug": "A.-Schille",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Schille",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18206987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af9e0efaaab6927fd256bda15c7fb33fc6df8b62",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Many of the processing steps in natural language engineering can be performed using finite state transducers. An optimal way to create such transducers is to compile them from regular expressions. This paper is an introduction to the regular expression calculus, extended with certain operators that have proved very useful in natural language applications ranging from tokenization to light parsing. The examples in the paper illustrate in concrete detail some of these applications."
            },
            "slug": "Regular-expressions-for-language-engineering-Karttunen-Chanod",
            "title": {
                "fragments": [],
                "text": "Regular expressions for language engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper is an introduction to the regular expression calculus, extended with certain operators that have proved very useful in natural language applications ranging from tokenization to light parsing."
            },
            "venue": {
                "fragments": [],
                "text": "Nat. Lang. Eng."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867844"
                        ],
                        "name": "Nancy A. Chinchor",
                        "slug": "Nancy-A.-Chinchor",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Chinchor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy A. Chinchor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 53750613,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4cc85dd2abb8564f4fb37dbc301b5526eb239c4a",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The MUC-4 scores of recall, precision, and the F-measures are used to measure the performance of the participating systems. The differences in the scores between any two systems may be due to chance or may be due to a significant difference between the two systems. To rule out the possibility that the difference is due to chance, statistical hypothesis testing is used. The method of hypothesis testing used is a computationally-intensive method known as approximate randomization. The method and the statistical significance of the results for the two MUC-4 test sets, TST3 and TST4, will be discussed in this paper."
            },
            "slug": "The-statistical-significance-of-the-MUC-5-results-Chinchor",
            "title": {
                "fragments": [],
                "text": "The statistical significance of the MUC-5 results"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The MUC-4 scores of recall, precision, and the F-measures are used to measure the performance of the participating systems and the method of hypothesis testing used is a computationally-intensive method known as approximate randomization."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78659204"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5548799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4cc5563c694355ddcf746ff9a55ccdb22d86a98",
            "isKey": false,
            "numCitedBy": 1040,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Finite-machines have been used in various domains of natural language processing. We consider here the use of a type of transducer that supports very efficient programs: sequential transducers. We recall classical theorems and give new ones characterizing sequential string-to-string transducers. Transducers that outpur weights also play an important role in language and speech processing. We give a specific study of string-to-weight transducers, including algorithms for determinizing and minizizing these transducers very efficiently, and characterizations of the transducers admitting determinization and the corresponding algorithms. Some applications of these algorithms in speech recognition are described and illustrated."
            },
            "slug": "Finite-State-Transducers-in-Language-and-Speech-Mohri",
            "title": {
                "fragments": [],
                "text": "Finite-State Transducers in Language and Speech Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work recalls classical theorems and gives new ones characterizing sequential string-to-string transducers, including algorithms for determinizing and minizizing these transducers very efficiently, and characterizations of the transducers admitting determinization and the corresponding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912437"
                        ],
                        "name": "L. Dini",
                        "slug": "L.-Dini",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Dini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868842"
                        ],
                        "name": "V. D. Tomaso",
                        "slug": "V.-D.-Tomaso",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Tomaso",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Tomaso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189921"
                        ],
                        "name": "F. Segond",
                        "slug": "F.-Segond",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9rique",
                            "lastName": "Segond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Segond"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39451769,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "21acdc103e4932b8178e5bb44d2c50918ff438d8",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "GINGER II traite la desambiguisation du sens des mots non supervisee pour l'anglais, en exploitant l'information des dictionnaires electroniques. A partir d'un corpus etiquete semantiquement ayant ete genere gr\u00e2ce a des exemples de phrases trouves dans le texte des entrees, et associes a des etiquettes de sens, le systeme construit une base de donnees de regles de desambiguisation semantique en extrayant les relations fonctionnelles entre les mots de ce corpus de phrases"
            },
            "slug": "GINGER-II:-An-Example-Driven-Word-Sense-Dini-Tomaso",
            "title": {
                "fragments": [],
                "text": "GINGER II: An Example-Driven Word Sense Disambiguator"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Le systeme construit une base de donnees de regles de desambiguisation semantique en extrayant les relations fonctionnelles entre les mots de ce corpus de phrases."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023469"
                        ],
                        "name": "D. Bikel",
                        "slug": "D.-Bikel",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bikel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bikel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 115174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9292ba3230f01b9f6990362fdf06783b9347bf6",
            "isKey": false,
            "numCitedBy": 919,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a statistical, learned approach to finding names and other nonrecursive entities in text (as per the MUC-6 definition of the NE task), using a variant of the standard hidden Markov model. We present our justification for the problem and our approach, a detailed discussion of the model itself and finally the successful results of this new approach."
            },
            "slug": "Nymble:-a-High-Performance-Learning-Name-finder-Bikel-Miller",
            "title": {
                "fragments": [],
                "text": "Nymble: a High-Performance Learning Name-finder"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a statistical, learned approach to finding names and other nonrecursive entities in text (as per the MUC-6 definition of the NE task), using a variant of the standard hidden Markov model."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867844"
                        ],
                        "name": "Nancy A. Chinchor",
                        "slug": "Nancy-A.-Chinchor",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Chinchor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy A. Chinchor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2620384"
                        ],
                        "name": "B. Sundheim",
                        "slug": "B.-Sundheim",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Sundheim",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sundheim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14454803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f898e821bbf4157d857dc512a85f49610638f1aa",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The metrics used for the Fifth Message Understanding Conference (MUC-5) evaluation are a major update to those used for MUC-4 in 1992. The official MUC-5 metrics express error rates while the official MUC-4 metrics express performance in terms of recall and precision (used for MUC-5 only as \"unofficial\" metrics). This paper discusses the current metrics and the reasons for their adoption."
            },
            "slug": "MUC-5-evaluation-metrics-Chinchor-Sundheim",
            "title": {
                "fragments": [],
                "text": "MUC-5 evaluation metrics"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The metrics used for the Fifth Message Understanding Conference (MUC-5) evaluation are a major update to those used for MUC-4 in 1992, and the reasons for their adoption are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803660"
                        ],
                        "name": "R. Kaplan",
                        "slug": "R.-Kaplan",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaplan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15971472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c3f94fc15407398c8f9d4bec893b02ed0dbe452",
            "isKey": false,
            "numCitedBy": 828,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a set of mathematical and computational tools for manipulating and reasoning about regular languages and regular relations and argues that they provide a solid basis for computational phonology. It shows in detail how this framework applies to ordered sets of context-sensitive rewriting rules and also to grammars in Koskenniemi's two-level formalism. This analysis provides a common representation of phonological constraints that supports efficient generation and recognition by a single simple interpreter."
            },
            "slug": "Regular-Models-of-Phonological-Rule-Systems-Kaplan-Kay",
            "title": {
                "fragments": [],
                "text": "Regular Models of Phonological Rule Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows in detail how this framework applies to ordered sets of context-sensitive rewriting rules and also to grammars in Koskenniemi's two-level formalism."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736675"
                        ],
                        "name": "J. Chanod",
                        "slug": "J.-Chanod",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Chanod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chanod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9591652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87c242c0ef2c82d37e00fc44c363defc4e254dcd",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a non-deterministic tokeniser implemented and used for the development of a French finite-state grammar. The tokeniser includes a finite-state automaton for simple tokens and a lexical transducer that encodes a wide variety of multiword expressions, associated with multiple lexical descriptions when required."
            },
            "slug": "A-Non-deterministic-Tokeniser-for-Finite-State-Chanod",
            "title": {
                "fragments": [],
                "text": "A Non-deterministic Tokeniser for Finite-State Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The tokeniser includes a finite-state automaton for simple tokens and a lexical transducer that encodes a wide variety of multiword expressions, associated with multiple lexical descriptions when required."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2425578"
                        ],
                        "name": "L. Karttunen",
                        "slug": "L.-Karttunen",
                        "structuredName": {
                            "firstName": "Lauri",
                            "lastName": "Karttunen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Karttunen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1045826,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "55e3553a825f9a307245016e735d9df37ea1ae41",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces to the calculus of regular expressions a replace operator and defines a set of replacement expressions that concisely encode alternate variations of the operation. Replace expressions denote regular relations, defined in terms of other regular expression operators. The basic case is unconditional obligatory replacement. We develop several versions of conditional replacement that allow the operation to be constrained by context."
            },
            "slug": "The-Replace-Operator-Karttunen",
            "title": {
                "fragments": [],
                "text": "The Replace Operator"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The calculus of regular expressions a replace operator is introduced and a set of replacement expressions that concisely encode alternate variations of the operation are defined that allow the operation to be constrained by context."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002335"
                        ],
                        "name": "Jan Hajic",
                        "slug": "Jan-Hajic",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Hajic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Hajic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1963585"
                        ],
                        "name": "B. Hladk\u00e1",
                        "slug": "B.-Hladk\u00e1",
                        "structuredName": {
                            "firstName": "Barbora",
                            "lastName": "Hladk\u00e1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hladk\u00e1"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63255574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5b6b646a707216950447753ce3cd2ee6eca7d1e",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Czech-language-processing,-POS-tagging-Hajic-Hladk\u00e1",
            "title": {
                "fragments": [],
                "text": "Czech language processing, POS tagging"
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37724116"
                        ],
                        "name": "R. Collier",
                        "slug": "R.-Collier",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Collier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Collier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26999255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69dd66f8d6b6f4cf3a40fa80a357028c1362fde2",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-template-creation-for-information-Collier",
            "title": {
                "fragments": [],
                "text": "Automatic template creation for information extraction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189921"
                        ],
                        "name": "F. Segond",
                        "slug": "F.-Segond",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9rique",
                            "lastName": "Segond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Segond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46344929"
                        ],
                        "name": "P. Tapanainen",
                        "slug": "P.-Tapanainen",
                        "structuredName": {
                            "firstName": "Pasi",
                            "lastName": "Tapanainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tapanainen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59908891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee5c5fc77407d8f25eb1d02f8c5eca82aa0fbb3c",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-a-Finite-State-Based-Formalism-to-Identify-Segond-Tapanainen",
            "title": {
                "fragments": [],
                "text": "Using a Finite-State Based Formalism to Identify and Generate Multiword Expressions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145435830"
                        ],
                        "name": "H. Cunningham",
                        "slug": "H.-Cunningham",
                        "structuredName": {
                            "firstName": "Hamish",
                            "lastName": "Cunningham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Cunningham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718590"
                        ],
                        "name": "R. Gaizauskas",
                        "slug": "R.-Gaizauskas",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gaizauskas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gaizauskas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7770390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "416561572fc21564be1f226b98af5464c7455d4d",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-General-Architecture-for-Text-Engineering-(gate)-Cunningham-Gaizauskas",
            "title": {
                "fragments": [],
                "text": "A General Architecture for Text Engineering (gate) { a New Approach to Language Engineering R&d a General Architecture for Text Engineering (gate) | a New Approach to Language Engineering R&d a E G T"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information retrieval and virtual libraries : the callimaque model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Locolex : the translation rolls off your tongue"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information extraction. Special NLP Issue of the Communications of the ACM"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A practical partofspeech tagger"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tagging frenchcomparing a statistical and a constraintbased method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Default inheritance in unificationbased approaches to the lexicon"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TiMBL: Tilburg memory based learner version 1.0"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Aquisition of selectional patterns from sub-langauges. Machine Translation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "JAPE -a Jolly Advanced Pattern Engine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Domain Modelling for AVENTINUS (WP 4.2). LE project LE1-2238 AVENTINUS internal technical report"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XI: A Knowledge Representation Language Based on Cross-Classification and Inheritance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 55,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Information-Extraction-Pazienza/06894f06b6411af67a0ffde61d27efd86a5d31c7?sort=total-citations"
}