{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A preliminary version of this work appeared in [8, 9 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5923591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cc765a48bcb7793308011523714dbbf1dbfe1ba",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel Object Recognition approach based on affine invariant regions. It actively counters the problems related to the limited repeatability of the region detectors, and the difficulty of matching, in the presence of large amounts of background clutter and particularly challenging viewing conditions. After producing an initial set of matches, the method gradually explores the surrounding image areas, recursively constructing more and more matching regions, increasingly farther from the initial ones. This process covers the object with matches, and simultaneously separates the correct matches from the wrong ones. Hence, recognition and segmentation are achieved at the same time. The approach includes a mechanism for capturing the relationships between multiple model views and exploiting these for integrating the contributions of the views at recognition time. This is based on an efficient algorithm for partitioning a set of region matches into groups lying on smooth surfaces. Integration is achieved by measuring the consistency of configurations of groups arising from different model views. Experimental results demonstrate the stronger power of the approach in dealing with extensive clutter, dominant occlusion, and large scale and viewpoint changes. Non-rigid deformations are explicitly taken into account, and the approximative contours of the object are produced. All presented techniques can extend any view-point invariant feature extractor."
            },
            "slug": "Simultaneous-Object-Recognition-and-Segmentation-or-Ferrari-Tuytelaars",
            "title": {
                "fragments": [],
                "text": "Simultaneous Object Recognition and Segmentation from Single or Multiple Model Views"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A novel Object Recognition approach based on affine invariant regions that actively counters the problems related to the limited repeatability of the region detectors, and the difficulty of matching, in the presence of large amounts of background clutter and particularly challenging viewing conditions."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40316280"
                        ],
                        "name": "Dennis Tell",
                        "slug": "Dennis-Tell",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Tell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis Tell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Topological configurations of points and lines were also used by Tell and Carlsson [ 28 ] in the wide-baseline stereo context, as a mean for guiding the matching process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar constraint, testing the cyclic ordering of points, was used for wide-baseline matching in [ 28 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32487961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "835ddd57d615cc7e93a2b7589bbcbe49992ad14d",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of establishing image-to-image correspondences is fundamental in computer vision. Recently, several wide baseline matching algorithms capable of handling large changes of viewpoint have appeared. By computing feature values from image data, these algorithms mainly use appearance as a cue for matching. Topological information, i.e. spatial relations between features, has also been used, but not nearly to the same extent as appearance. In this paper, we incorporate topological constraints into an existing matching algorithm [1] which matches image intensity profiles between interest points. We show that the algorithm can be improved by exploiting the constraint that the intensity profiles around each interest point should be cyclically ordered. String matching techniques allows for an efficient implementation of the ordering constraint. Experiments with real data indicate that the modified algorithm indeed gives superior results to the original one. The method of enforcing the spatial constraints is not limited to the presented case, but can be used on any algorithm where interest point correspondences are sought."
            },
            "slug": "Combining-Appearance-and-Topology-for-Wide-Baseline-Tell-Carlsson",
            "title": {
                "fragments": [],
                "text": "Combining Appearance and Topology for Wide Baseline Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper incorporates topological constraints into an existing matching algorithm which matches image intensity profiles between interest points, and shows that the algorithm can be improved by exploiting the constraint that the intensity profiles around each interest point should be cyclically ordered."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7358807,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc3fdbe76fd39d87bbb5565efeca213f9395896c",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "Many problems in Computer Vision require the computation of correspondences between images. In order to cope with large differences in viewing conditions, several affine invariant region detectors have been developed in the last few years. These regions automatically adapt their shape so as to cover the same scene surface in any view. This dissertation builds upon existing detectors and develops various novel techniques which extend the power and functionalities of the regions. The advances relate to different subfields of Vision, and can be summarized as four main contributions. First and foremost, the thesis presents a powerful Object Recognition system capable of working with large amounts of background clutter, severe occlusion, and strong viewpoint and scale changes. It can handle non-rigid deformations, and also finds the contours of the visible parts of the object. The second innovation consists of a method to obtain region correspondences across several images taken from different viewpoints. These multi-view correspondences are important as they enable the automatic reconstruction of a 3D model given only a few still images. In constrast, traditionally this task requires a complete video as input. Another branch of the thesis introduces a real-time algorithm which tracks the full affine shape of a region as it evolves through a video, and its application for markerless Augmented Reality. Most prior works instead rely on adding special markers to the scene. Lastly, a technique to automatically find groups of regions correspondences lying on planar surfaces is presented. This allow to detect planar scene structures and their geometric transformation between views, which in turn can considerably simplify 3D reconstruction procedures, and is useful for robot navigation. Acknowledgements Four years is a long period of time. During this period I have met a number of wonderful people who influenced my work in various ways. First and foremost, I extend my deepest gratitude to Dr. Tinne Tuytelaars, who was always next to me, even thought a thousand kilometers divided our working places. Throughout the whole PhD, her brilliant intellectual support was second only to her amazing capacities to keep up a challenging and exciting working atmosphere, savour the successes, and react positively to defeats. My heartfelt thanks go to my supervisor, Prof. Luc Van Gool, whose enormous drive was a true inspiration. His expert advice, extensive knowledge of the Computer Vision field, and continuous incentives to improve my work were invaluable. I am grateful to my co-referee, Prof. \u2026"
            },
            "slug": "Affine-invariant-regions++-Ferrari",
            "title": {
                "fragments": [],
                "text": "Affine invariant regions++"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This dissertation presents a powerful Object Recognition system capable of working with large amounts of background clutter, severe occlusion, and strong viewpoint and scale changes, and builds upon existing detectors and develops various novel techniques which extend the power and functionalities of the regions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Feature extractors have appeared [ 12 ,14] which are invariant also under scale changes, and more recently recognition under general viewpoint changes has become possible, thanks to extractors adapting the complete affine shape of the feature to the viewing conditions [1,13,15,23,31,30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although we plan a number of speedups, the method is unlikely to reach the speed of the fastest other systems (the system of Lowe [ 12 ] is reported to perform recognition within seconds)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This contrasts with previous works [1, 12 ,15,18,30], but there are two good reasons for it. First, the scene might contain repeated, or visually similar elements."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "How to proceed ? Global, robust geometry filtering methods, like detecting outliers to the epipolar geometry through RANSAC [29] fail, as they need a minimal portion of inliers of about 1/3 [3, 12 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "described the regions with the SIFT [ 12 ] descriptor 7 , which has recently been"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 12 ,15,18,21,30]). In the basic common scheme a number of features are extracted independently from both a model and a test image, then characterized by invariant descriptors and finally matched."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The matching is carried out by the \u2019unambiguous nearest-neighbor\u2019 approach 8 advocated in [1, 12 ]: a model region is matched"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221242327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c04f169203f9e55056a6f7f956695babe622a38",
            "isKey": true,
            "numCitedBy": 12997,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene and can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an advantage over the (semi-) local filter proposed by [ 24 ], and later also used by others [22,26], which verifies if a minimal amount of regions in an area around Rm in the model image also match near Rt in the test image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[25]). After the influential work of Schmid [ 24 ], who proposed the use of rotation-invariant features, there has been important evolution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10291007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a221ae60093283ef438e8b69e26094a2480a6299",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of recognizing objects in large image databases. The method is based on local characteristics which are invariant to similarity transformations in the image. These characteristics are computed at automatically detected keypoints using the greyvalue signal. The method therefore works on images such as paintings for which geometry based recognition fails. Due to the locality of the method, images can be recognized being given part of an image and in the presence of occlusions. Applying a voting algorithm and semi-local constraints makes the method robust to noise, scene clutter and small perspective deformations. Experiments show an efficient recognition for different types of images. The approach has been validated on an image database containing 1020 images, some of them being very similar by structure, texture or shape."
            },
            "slug": "Combining-greyvalue-invariants-with-local-for-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Combining greyvalue invariants with local constraints for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The method is based on local characteristics which are invariant to similarity transformations in the image and computed at automatically detected keypoints using the greyvalue signal and works on images such as paintings for which geometry based recognition fails."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 552096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ad20e6f6f89631caf6960516bb9939b9430bba0",
            "isKey": false,
            "numCitedBy": 568,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "\u2018Invariant regions\u2019 are image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions are then described by a set of invariant features, which makes it relatively easy to match them between views and under changing illumination. In previous work, we have presented invariant regions that are based on a combination of corners and edges. The application discussed then was image database retrieval. Here, an alternative method for extracting (affinely) invariant regions is given, that does not depend on the presence of edges or corners in the image but is purely intensity-based. Also, we demonstrate the use of such regions for another application, which is wide baseline stereo matching. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system even further, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions."
            },
            "slug": "Wide-Baseline-Stereo-Matching-based-on-Local,-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents an alternative method for extracting invariant regions that does not depend on the presence of edges or corners in the image but is purely intensity-based, and demonstrates the use of such regions for another application, which is wide baseline stereo matching."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "similarity. Including appearance makes the filter more robust to low correctratios, and remedies the potential drawback (parallax-violations) of a purely topological filter [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The registration of the tentative matches is now refined using our algorithm [ 6 ], that efficiently looks for the affine transformation that maximizes the similarity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10028193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c4c1b49055ff7a99c37118e754f43955d16f86d",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for establishing multiple-view feature correspondences along an unordered set of images taken from substantially different viewpoints. Several wide-baseline stereo (WBS) algorithms have appeared, the N-view case is largely unexplored. In this paper, an established WBS algorithm is used to extract and match features in pairs of views. The pairwise matches are first integrated into disjoint feature tracks, each representing a single physical surface patch in several views. By exploiting the interplay between the tracks, they are extended over more views, while unrelated image features are removed. Similarity and spatial relationships between the features are simultaneously used. The output consists of many reliable and accurate feature tracks, strongly connecting the input views. Applications include 3D reconstruction and object recognition. The proposed approach is not restricted to the particular choice of features and matching criteria. It can extend any method that provides feature correspondences between pairs of images."
            },
            "slug": "Wide-baseline-multiple-view-correspondences-Ferrari-Tuytelaars",
            "title": {
                "fragments": [],
                "text": "Wide-baseline multiple-view correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper presents a novel approach for establishing multiple-view feature correspondences along an unordered set of images taken from substantially different viewpoints, using an established WBS algorithm to extract and match features in pairs of views."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189557"
                        ],
                        "name": "Step\u00e1n Obdrz\u00e1lek",
                        "slug": "Step\u00e1n-Obdrz\u00e1lek",
                        "structuredName": {
                            "firstName": "Step\u00e1n",
                            "lastName": "Obdrz\u00e1lek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Step\u00e1n Obdrz\u00e1lek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Even in easier cases, to suit the needs for repeatability in spite of viewpoint changes, only a sparse set of distinguished features [18] are extracted."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 52
                            }
                        ],
                        "text": "8 We have also tried the standard approach, used in [15,4,18,30], which simply matches two nearest-neighbors if their distance is below a threshold, but it produced slightly"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "For comparison, we processed the dataset also with 4 state-of-the-art affine region extractors [1,15,18,30], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 35
                            }
                        ],
                        "text": "This contrasts with previous works [1,12,15,18,30], but there are two good reasons for it."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "As a comparison with the traditional methods, the standard matching of regions of [18], based on the SIFT descriptor, yields two hardly separable distributions (figure 8-top-right), and hence the unsatisfactory performance in the ROC plot."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6400968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16cf7026acfdbcef00a6524c72dc7ee5a0660ef8",
            "isKey": true,
            "numCitedBy": 241,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach to appearance based object recognition is introduced. The proposed method, based on matching of local image features, reliably recognises objects under very different viewing conditions. First, distinguished regions of data-dependent shape are robustly detected. On these regions, local affine frames are established using several affine invariant constructions. Direct comparison of photometrically normalised colour intensities in local, geometrically aligned frames results in a matching scheme that is invariant to piecewise-affine image deformations, but still remains very discriminative. The potential of the approach is experimentally verified on COIL-100 and SOIL-47 \u2010 publicly available image databases. On SOIL-47, 100% recognition rate is achieved for single training view per object. On COIL-100, 99.9% recognition rate is obtained for 18 training views per object. Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
            },
            "slug": "Object-Recognition-using-Local-Affine-Frames-on-Obdrz\u00e1lek-Matas",
            "title": {
                "fragments": [],
                "text": "Object Recognition using Local Affine Frames on Distinguished Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A novel approach to appearance based object recognition based on matching of local image features, reliably recognises objects under very different viewing conditions that is invariant to piecewise-affine image deformations, but still remains very discriminative."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398773259"
                        ],
                        "name": "L. D'haene",
                        "slug": "L.-D'haene",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "D'haene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D'haene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144839904"
                        ],
                        "name": "R. Koch",
                        "slug": "R.-Koch",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 267
                            }
                        ],
                        "text": "Feature extractors have appeared [12,14] which are invariant also under scale changes, and more recently recognition under general viewpoint changes has become possible, thanks to extractors adapting the complete affine shape of the feature to the viewing conditions [1,13,15,23,31,30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206541238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c794d7a7315ab87e5477b2abdaf84a06c86adb",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops new image matching techniques for visual servoing based on affine invariants which allow one to deal with large viewpoint changes and that do not rely on specific markers. The only assumption is that there are some locally planar and unoccluded scene regions that have enough structure to be detected in the image. Those regions are classified by a set of illumination and viewpoint invariant features. The features represent the image in a very compact way and allow fast comparison and feature matching between quite different viewpoints. The matching procedure is embedded in a visual servoing system for a mobile robot. Experiments show its potential for navigation with large camera rotations and view point changes in a cluttered environment without the need for artificial landmarks."
            },
            "slug": "Matching-of-affinely-invariant-regions-for-visual-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Matching of affinely invariant regions for visual servoing"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "New image matching techniques for visual servoing based on affine invariants which allow one to deal with large viewpoint changes and that do not rely on specific markers are developed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107881808"
                        ],
                        "name": "Stella X. Yu",
                        "slug": "Stella-X.-Yu",
                        "structuredName": {
                            "firstName": "Stella",
                            "lastName": "Yu",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stella X. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33731953"
                        ],
                        "name": "R. Gross",
                        "slug": "R.-Gross",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [ 32 ], low-level grouping cues based on edge responses, high-level cues from a part detector and spatial consistency of detected parts, are combined in a graph partitioning framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1761618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e0e519dbf9aa58e153fb7c887935a371e24d7e3",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation and recognition have long been treated as two separate processes. We propose a mechanism based on spectral graph partitioning that readily combine the two processes into one. A part-based recognition system detects object patches, supplies their partial segmentations as well as knowledge about the spatial configurations of the object. The goal of patch grouping is to find a set of patches that conform best to the object configuration, while the goal of pixel grouping is to find a set of pixels that have the best low-level feature similarity. Through pixel-patch interactions and between-pateh competition encoded in the solution space, these two processes are realized in one joint optimization problem. The globally optima] partition is obtained by solving a constrained eigenvalue problem. We demonstrate that the resulting object segmentation eliminates false positives for the part detection, while overcoming occlusion and weak contours for the low-level edge detection."
            },
            "slug": "Concurrent-Object-Recognition-and-Segmentation-by-Yu-Gross",
            "title": {
                "fragments": [],
                "text": "Concurrent Object Recognition and Segmentation by Graph Partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that the resulting object segmentation eliminates false positives for the part detection, while overcoming occlusion and weak contours for the low-level edge detection."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076817912"
                        ],
                        "name": "P. Pritchett",
                        "slug": "P.-Pritchett",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Pritchett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pritchett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, the \u2018propagation attempt\u2019 at the heart of the expansion phases is an evolution of the idea of \u2018growing matches\u2019 proposed by [ 20 ,23,22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46527015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da91ba2e80a4d8deb597b1c884cda890f086653",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic."
            },
            "slug": "Wide-baseline-stereo-matching-Pritchett-Zisserman",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo matching"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically, and to facilitate matching between quite disparate views-wide baseline stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 2
                            }
                        ],
                        "text": "g [4,17,27]), and are therefore very sensitive to background clutter and partial occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6611218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef768a5c9bd0aaeddafea1d56b08b0c8180760c0",
            "isKey": false,
            "numCitedBy": 1493,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of automatically learning object models for recognition and pose estimation is addressed. In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties and constant for a rigid object, pose and illumination vary from scene to scene. A compact representation of object appearance is proposed that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a manifold. Given an unknown input image, the recognition system projects the image to eigenspace. The object is recognized based on the manifold it lies on. The exact position of the projection on the manifold determines the object's pose in the image.A variety of experiments are conducted using objects with complex appearance characteristics. The performance of the recognition and pose estimation algorithms is studied using over a thousand input images of sample objects. Sensitivity of recognition to the number of eigenspace dimensions and the number of learning samples is analyzed. For the objects used, appearance representation in eigenspaces with less than 20 dimensions produces accurate recognition results with an average pose estimation error of about 1.0 degree. A near real-time recognition system with 20 complex objects in the database has been developed. The paper is concluded with a discussion on various issues related to the proposed learning and recognition methodology."
            },
            "slug": "Visual-learning-and-recognition-of-3-d-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Visual learning and recognition of 3-d objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A near real-time recognition system with 20 complex objects in the database has been developed and a compact representation of object appearance is proposed that is parametrized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The matching is carried out by the \u2019unambiguous nearest-neighbor\u2019 approach 8 advocated in [ 1 ,12]: a model region is matched"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similar histograms are produced based on the other feature extractors [ 1 ,15,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Feature extractors have appeared [12,14] which are invariant also under scale changes, and more recently recognition under general viewpoint changes has become possible, thanks to extractors adapting the complete affine shape of the feature to the viewing conditions [ 1 ,13,15,23,31,30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This contrasts with previous works [ 1 ,12,15,18,30], but there are two good reasons for it. First, the scene might contain repeated, or visually similar elements."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For comparison, we processed the dataset also with 4 state-of-the-art affine region extractors [ 1 ,15,18,30], and Simultaneous Object Recognition and Segmentation by Image Exploration 163"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, the method works in conjunction with any affine invariant region extractor [ 1 ,13,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15626261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f693427d956c0dbc822e7f3452aee8ca36204b",
            "isKey": true,
            "numCitedBy": 767,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "slug": "Reliable-feature-matching-across-widely-separated-Baumberg",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely separated views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints that is optimised for a structure-from-motion application where it wishes to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Worse yet, inaccurate localization of some regions might compromise the quality of the fundamental matrix, and therefore even cause rejection of many accurate regions [ 33 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5858737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3ec4ceea040b7b4129ee5d71b4f95539bf876b7",
            "isKey": false,
            "numCitedBy": 1625,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Robust-Technique-for-Matching-two-Uncalibrated-of-Zhang-Deriche",
            "title": {
                "fragments": [],
                "text": "A Robust Technique for Matching two Uncalibrated Images Through the Recovery of the Unknown Epipolar Geometry"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067522034"
                        ],
                        "name": "Martin Urban",
                        "slug": "Martin-Urban",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Urban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Urban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758039"
                        ],
                        "name": "T. Pajdla",
                        "slug": "T.-Pajdla",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Pajdla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pajdla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Feature extractors have appeared [12,14] which are invariant also under scale changes, and more recently recognition under general viewpoint changes has become possible, thanks to extractors adapting the complete affine shape of the feature to the viewing conditions [1, 13 ,15,23,31,30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, the method works in conjunction with any affine invariant region extractor [1, 13 ,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The proposed filter has various attractive properties, and offers several advantages over detecting outliers to the epipolar geometry through RANSAC [29], which is traditionally used in the matching literature [ 13 ,15,22,23,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2104851,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d5ea177c7fcaf88ec6f56cbeb3e9b74c08e98a3",
            "isKey": true,
            "numCitedBy": 3922,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under 1. continuous (and thus projective) transformation of image coordinates and 2. monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely-invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5\u00d7), illumination conditions, out-of-plane rotation, occlusion , locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained."
            },
            "slug": "Robust-Wide-Baseline-Stereo-from-Maximally-Stable-Matas-Chum",
            "title": {
                "fragments": [],
                "text": "Robust Wide Baseline Stereo from Maximally Stable Extremal Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints, is studied and an efficient and practically fast detection algorithm is presented for an affinely-invariant stable subset of extremal regions, the maximally stable extremal region (MSER)."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736489"
                        ],
                        "name": "Fred Rothganger",
                        "slug": "Fred-Rothganger",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Rothganger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred Rothganger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 168
                            }
                        ],
                        "text": "Moreover, non-rigid deformations are explicitly taken into account, and the approximate boundaries of the object is found, two features lacking in competing approaches [4, 8, 2, 7, 11, 5, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 112
                            }
                        ],
                        "text": "Recently, object recognition (OR) approaches based on local invariant features have become increasingly popular [8, 5, 2, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 120
                            }
                        ],
                        "text": "The proposed method offers two main advantages over rigid-motion filters, traditionally used in the matching literature [2, 5, 4, 13, 7, 14], e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2046294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1468251456faef0ef2dfa87937fda2aea0bacb90",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships. Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint. The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes. Preliminary modeling and recognition results are presented."
            },
            "slug": "3D-object-modeling-and-recognition-using-patches-Rothganger-Lazebnik",
            "title": {
                "fragments": [],
                "text": "3D object modeling and recognition using affine-invariant patches and multi-view spatial constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "When there is also extensive clutter, it might be impossible, based purely on local appearance [ 22 ], to decide which of the best 3 matches is correct, as several competing regions might appear very similar, and score higher than the correct match."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, the \u2018propagation attempt\u2019 at the heart of the expansion phases is an evolution of the idea of \u2018growing matches\u2019 proposed by [20,23, 22 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The proposed filter has various attractive properties, and offers several advantages over detecting outliers to the epipolar geometry through RANSAC [29], which is traditionally used in the matching literature [13,15, 22 ,23,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an advantage over the (semi-) local filter proposed by [24], and later also used by others [ 22 ,26], which verifies if a minimal amount of regions in an area around Rm in the model image also match near Rt in the test image."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14920652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f091b49d6a695a1f47087cf4c7c28f9eb219167e",
            "isKey": true,
            "numCitedBy": 77,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe progress in matching shots which are images of the same 3D scene in a film. The problem is hard because the camera viewpoint may change substantially between shots, with consequent changes in the imaged appearance of the scene due to foreshortening, scale changes and partial occlusion.We demonstrate that wide baseline matching techniques can be successfully employed for this task by matching key frames between shots. The wide baseline method represents each frame by a set of viewpoint invariant local feature vectors. The local spatial support of the features means that segmentation of the frame (e.g. into foreground/background) is not required, and partial occlusion is tolerated.Results of matching shots for a number of different scene types are illustrated on a commercial film."
            },
            "slug": "Automated-Scene-Matching-in-Movies-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Automated Scene Matching in Movies"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated that wide baseline matching techniques can be successfully employed for this task by matching key frames between shots by representing each frame by a set of viewpoint invariant local feature vectors."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736489"
                        ],
                        "name": "Fred Rothganger",
                        "slug": "Fred-Rothganger",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Rothganger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred Rothganger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Conversely, we have processed the dataset of [21] with our complete system (including multi-view integration [7])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "It performed well, and achieved 95% detection rate for 6% false-positives (see [21] for more details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "As last comparison, we consider the recent system [21], which constructs a 3D model of each object prior to recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1330784,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6f3b1d94193a76f9f06d26e67cb22fd31aa735f",
            "isKey": true,
            "numCitedBy": 402,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.This article introduces a novel representation for three-dimensional (3D) objects in terms of local affine-invariant descriptors of their images and the spatial relationships between the corresponding surface patches. Geometric constraints associated with different views of the same patches under affine projection are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true 3D affine and Euclidean models from multiple unregistered images, as well as their recognition in photographs taken from arbitrary viewpoints. The proposed approach does not require a separate segmentation stage, and it is applicable to highly cluttered scenes. Modeling and recognition results are presented."
            },
            "slug": "3D-Object-Modeling-and-Recognition-Using-Local-and-Rothganger-Lazebnik",
            "title": {
                "fragments": [],
                "text": "3D Object Modeling and Recognition Using Local Affine-Invariant Image Descriptors and Multi-View Spatial Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel representation for three-dimensional objects in terms of local affine-invariant descriptors of their images and the spatial relationships between the corresponding surface patches is introduced, allowing the acquisition of true 3D affine and Euclidean models from multiple unregistered images, as well as their recognition in photographs taken from arbitrary viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 2
                            }
                        ],
                        "text": "g [4,17,27]), and are therefore very sensitive to background clutter and partial occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8167136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b1e1696564e5a3021ac3a501c9deeb6c0fbc637",
            "isKey": false,
            "numCitedBy": 5039,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision is embracing a new research focus in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, realistic environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the location of a known object. Color can be successfully used for both tasks.This article demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique calledHistogram Intersection, which matches model and image histograms and a fast incremental version of Histogram Intersection, which allows real-time indexing into a large database of stored models. For solving the location problem it introduces an algorithm calledHistogram Backprojection, which performs this task efficiently in crowded scenes."
            },
            "slug": "Color-indexing-Swain-Ballard",
            "title": {
                "fragments": [],
                "text": "Color indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models and that they can differentiate among a large number of objects."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Leibe and Schiele [ 10 ] present a method to detect an unknown object instance of a given category and segment it from a test image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18901556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49a7ff6c753a79ed063fe2c4bf3eca3fa03c2f7e",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of our work is object categorization in real-world scenes. That is, given a novel image we want to recognize and localize unseen-before objects based on their similarity to a learned object category. For use in a real-world system, it is important that this includes the ability to recognize objects at multiple scales. In this paper, we present an approach to multi-scale object categorization using scale-invariant interest points and a scale-adaptive Mean-Shift search. The approach builds on the method from [12], which has been demonstrated to achieve excellent results for the single-scale case, and extends it to multiple scales. We present an experimental comparison of the influence of different interest point operators and quantitatively show the method's robustness to large scale changes."
            },
            "slug": "Scale-Invariant-Object-Categorization-Using-a-Leibe-Schiele",
            "title": {
                "fragments": [],
                "text": "Scale-Invariant Object Categorization Using a Scale-Adaptive Mean-Shift Search"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents an approach to multi-scale object categorization using scale-invariant interest points and a scale-adaptive Mean-Shift search, and presents an experimental comparison of the influence of different interest point operators and quantitatively shows the method's robustness to large scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2745663"
                        ],
                        "name": "M. Lhuillier",
                        "slug": "M.-Lhuillier",
                        "structuredName": {
                            "firstName": "Maxime",
                            "lastName": "Lhuillier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lhuillier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144645904"
                        ],
                        "name": "Long Quan",
                        "slug": "Long-Quan",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Quan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, a different, pixel-bypixel propagation strategy was previously proposed in [ 11 ], but it is applicable only in case of small differences between the images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12723279,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "def7a518955e44d7c7323e2faa1ba1d7a28cac9b",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a quasi-dense matching algorithm between images based on the match propagation principle. The algorithm starts from a set of sparse seed matches, then propagates to the neighboring pixels by the best-first strategy, and produces a quasi-dense disparity map. The quasi-dense matching aims at broad modeling and visualization applications which rely heavily on matching information. Our algorithm is robust to initial sparse match outliers due to the best-first strategy. It is efficient in time and space as it is only output sensitive. It handles half-occluded areas because of the simultaneous enforcement of newly introduced discrete 2D gradient disparity limit and the uniqueness constraint. The properties of the algorithm are discussed and empirically demonstrated. The quality of quasi-dense matching are validated through intensive real examples."
            },
            "slug": "Match-Propagation-for-Image-Based-Modeling-and-Lhuillier-Quan",
            "title": {
                "fragments": [],
                "text": "Match Propagation for Image-Based Modeling and Rendering"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The algorithm starts from a set of sparse seed matches, then propagates to the neighboring pixels by the best-first strategy, and produces a quasi-dense disparity map, which aims at broad modeling and visualization applications which rely heavily on matching information."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356443"
                        ],
                        "name": "Michal Perdoch",
                        "slug": "Michal-Perdoch",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Perdoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michal Perdoch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "How to proceed ? Global, robust geometry filtering methods, like detecting outliers to the epipolar geometry through RANSAC [29] fail, as they need a minimal portion of inliers of about 1/3 [ 3 ,12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17226968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78c376ea31a5acea0a160e45e0ab5b3400d5a488",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel algorithm for robust RANSAC-like estimation of epipolar geometry (of uncalibrated camera pair) from two correspondences of local affine frames (LAFs) is presented. Each LAF is constructed from three points independently detected on a maximally stable extremal region. The algorithm assumes that a sufficiently accurate approximation of the fundamental matrix is obtained from two LAF correspondences by the 6-point algorithm of Stewenius et al. The so-far-the-best hypotheses are further processed by so-called local optimization to estimate the epipolar geometry. Special attention is paid to planar sample degeneracy, since the probability of drawing two coplanar LAF correspondences is not negligible. Combining the 6-point solver, local optimization, and the degeneracy test enables RANSAC to draw samples of only two LAFs to generate hypotheses and thus to reduce the number of samples drawn. We experimentally show that using the 6-point algorithm (approximating the real camera by camera with unit aspect ratio, zero skew, principal point in the center of image, and a common unknown focal length) generates hypotheses that are sufficient for EG estimation in LO-RANSAC framework"
            },
            "slug": "Epipolar-Geometry-from-Two-Correspondences-Perdoch-Matas",
            "title": {
                "fragments": [],
                "text": "Epipolar Geometry from Two Correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is experimentally shown that using the 6-point algorithm (approximating the real camera by camera with unit aspect ratio, zero skew, principal point in the center of image, and a common unknown focal length) generates hypotheses that are sufficient for EG estimation in LO-RANSAC framework."
            },
            "venue": {
                "fragments": [],
                "text": "18th International Conference on Pattern Recognition (ICPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12031059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c72ce4ef9f433db764b1c52f03412e4d0400dca",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper has two goals. The first is to develop a variety of robust methods for the computation of the Fundamental Matrix, the calibration-free representation of camera motion. The methods are drawn from the principal categories of robust estimators, viz. case deletion diagnostics, M-estimators and random sampling, and the paper develops the theory required to apply them to non-linear orthogonal regression problems. Although a considerable amount of interest has focussed on the application of robust estimation in computer vision, the relative merits of the many individual methods are unknown, leaving the potential practitioner to guess at their value. The second goal is therefore to compare and judge the methods.Comparative tests are carried out using correspondences generated both synthetically in a statistically controlled fashion and from feature matching in real imagery. In contrast with previously reported methods the goodness of fit to the synthetic observations is judged not in terms of the fit to the observations per se but in terms of fit to the ground truth. A variety of error measures are examined. The experiments allow a statistically satisfying and quasi-optimal method to be synthesized, which is shown to be stable with up to 50 percent outlier contamination, and may still be used if there are more than 50 percent outliers. Performance bounds are established for the method, and a variety of robust methods to estimate the standard deviation of the error and covariance matrix of the parameters are examined.The results of the comparison have broad applicability to vision algorithms where the input data are corrupted not only by noise but also by gross outliers."
            },
            "slug": "The-Development-and-Comparison-of-Robust-Methods-Torr-Murray",
            "title": {
                "fragments": [],
                "text": "The Development and Comparison of Robust Methods for Estimating the Fundamental Matrix"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A variety of robust methods for the computation of the Fundamental Matrix, the calibration-free representation of camera motion, are developed from the principal categories of robust estimators, viz. case deletion diagnostics, M-estimators and random sampling, and the theory required to apply them to non-linear orthogonal regression problems is developed."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 99
                            }
                        ],
                        "text": "This is an advantage over the (semi-) local filter proposed by [24], and later also used by others [22,26], which verifies if a minimal amount of regions in an area around Rm in the model image also match near Rt in the test image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14457153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642e328cae81c5adb30069b680cf60ba6b475153",
            "isKey": false,
            "numCitedBy": 6760,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films."
            },
            "slug": "Video-Google:-a-text-retrieval-approach-to-object-Sivic-Zisserman",
            "title": {
                "fragments": [],
                "text": "Video Google: a text retrieval approach to object matching in videos"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video, represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086511361"
                        ],
                        "name": "J\u01d0r\u0131\u0301Matas",
                        "slug": "J\u01d0r\u0131\u0301Matas",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "J\u01d0r\u0131\u0301Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u01d0r\u0131\u0301Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189557"
                        ],
                        "name": "Step\u00e1n Obdrz\u00e1lek",
                        "slug": "Step\u00e1n-Obdrz\u00e1lek",
                        "structuredName": {
                            "firstName": "Step\u00e1n",
                            "lastName": "Obdrz\u00e1lek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Step\u00e1n Obdrz\u00e1lek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 190
                            }
                        ],
                        "text": "How to proceed ? Global, robust geometry filtering methods, like detecting outliers to the epipolar geometry through RANSAC [29] fail, as they need a minimal portion of inliers of about 1/3 [3,12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8331196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6c3b452b0e6c4f6f376ce142cf436c42c02a7ec",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, LO-RANSAC 3-LAF \u2013 a new algorithm for the correspondence problem \u2013 is described. Exploiting processes proposed for computation of affineinvariant local frames, three point-to-point correspondences are found for each region-to-region correspondence. Consequently, it is sufficient to select only triplets of region correspondences in the hypothesis stage of epipolar geometry estimation by RANSAC. We experimentally show that: 1. LO-RANSAC 3-LAF estimates epipolar geometry in time that is orders of magnitude faster than the standard method, 2. that the precision of the LO-RANSAC 3-LAF and the standard method are comparable, and 3. that RANSAC without local optimisation applied to triplets of points from a single region is significantly less precise than the new LO-RANSAC 3-LAF algorithm. In the experiments, a speed-up factor in orders of thousands is achieved on the problem of epipolar geometry estimation. The proposed method is pushing the limit of solvable problems, allowing EG estimation in correspondence problems with the number of inliers below 10%."
            },
            "slug": "Epipolar-Geometry-from-Three-Correspondences-Chum-J\u01d0r\u0131\u0301Matas",
            "title": {
                "fragments": [],
                "text": "Epipolar Geometry from Three Correspondences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 52
                            }
                        ],
                        "text": "3 We have also tried the standard approach, used in [7, 5, 2, 12], which simply matches two nearestneighbors if their distance is below a threshold, but it produced slightly worse results."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 222
                            }
                        ],
                        "text": "For comparison, we processed the dataset also with 4 state-of-the-art affine region extractors [7, 5, 11, 2], and described the regions with the SIFT [8] descriptor 2 , which has recently been demonstrated to perform best [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2572455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69401bfdafab7cde00bb8e5b2f6c28e9d72d8cfb",
            "isKey": false,
            "numCitedBy": 3666,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "slug": "A-performance-evaluation-of-local-descriptors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "A performance evaluation of local descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is observed that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best and Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7785990"
                        ],
                        "name": "A. Salgian",
                        "slug": "A.-Salgian",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Salgian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Salgian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 57
                            }
                        ],
                        "text": "They should be addressed by techniques based on contours [4,25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15555340,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "15074808e5409638e7735c45ee0c1b7825405617",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider the problem of 3D object recognition and the role that perceptual grouping processes must play. In particular, we argue that reliance on a single level of perceptual grouping is inadequate, since it is responsible for the specific weaknesses of several well-known recognition techniques. Instead, recognition must use a hierarchy of perceptual grouping processes. We describe an appearance-based system that uses four distinct levels of perceptual grouping to represent 3D objects in a form that allows not only recognition, but reasoning about 3D manipulation of a sort that has been supported in the past only by 3D geometric models. The results of the algorithms have been previously reported, and the main contribution of this paper is the development of the perceptual organization hierarchy."
            },
            "slug": "A-Perceptual-Grouping-Hierarchy-for-3D-Object-Salgian-Nelson",
            "title": {
                "fragments": [],
                "text": "A Perceptual Grouping Hierarchy for Appearance-Based 3D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An appearance-based system that uses four distinct levels of perceptual grouping to represent 3D objects in a form that allows not only recognition, but reasoning about 3D manipulation of a sort that has been supported in the past only by 3D geometric models is described."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 134
                            }
                        ],
                        "text": "Moreover, the \u2018propagation attempt\u2019 at the heart of the expansion phases is an evolution of the idea of \u2018growing matches\u2019 proposed by [20,23,22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 267
                            }
                        ],
                        "text": "Feature extractors have appeared [12,14] which are invariant also under scale changes, and more recently recognition under general viewpoint changes has become possible, thanks to extractors adapting the complete affine shape of the feature to the viewing conditions [1,13,15,23,31,30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "The benefits of exploiting previously established geometric transformations was also noted by [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 210
                            }
                        ],
                        "text": "The proposed filter has various attractive properties, and offers several advantages over detecting outliers to the epipolar geometry through RANSAC [29], which is traditionally used in the matching literature [13,15,22,23,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1699616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e81996384b030b580a0e02c0dc367d59c0c15ba",
            "isKey": true,
            "numCitedBy": 697,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been considerable success in automated reconstruction for image sequences where small baseline algorithms can be used to establish matches across a number of images. In contrast in the case of widely separated views, methods have generally been restricted to two or three views.In this paper we investigate the problem of establishing relative viewpoints given a large number of images where no ordering information is provided. A typical application would be where images are obtained from different sources or at different times: both the viewpoint (position, orientation, scale) and lighting conditions may vary significantly over the data set.Such a problem is not fundamentally amenable to exhaustive pair wise and triplet wide baseline matching because this would be prohibitively expensive as the number of views increases. Instead, we investiate how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching. The result is a matching algorithm which is linear in the number of views.The methods are illustrated on several real image data sets. The output enables an image based technique for navigating in a 3D scene, moving from one image to whichever image is the next most appropriate."
            },
            "slug": "Multi-view-Matching-for-Unordered-Image-Sets,-or-Do-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Multi-view Matching for Unordered Image Sets, or \"How Do I Organize My Holiday Snaps?\""
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper invests how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching and produces a matching algorithm which is linear in the number of views."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 267
                            }
                        ],
                        "text": "Feature extractors have appeared [12,14] which are invariant also under scale changes, and more recently recognition under general viewpoint changes has become possible, thanks to extractors adapting the complete affine shape of the feature to the viewing conditions [1,13,15,23,31,30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 52
                            }
                        ],
                        "text": "8 We have also tried the standard approach, used in [15,4,18,30], which simply matches two nearest-neighbors if their distance is below a threshold, but it produced slightly"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "For comparison, we processed the dataset also with 4 state-of-the-art affine region extractors [1,15,18,30], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 70
                            }
                        ],
                        "text": "Similar histograms are produced based on the other feature extractors [1,15,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 35
                            }
                        ],
                        "text": "This contrasts with previous works [1,12,15,18,30], but there are two good reasons for it."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 210
                            }
                        ],
                        "text": "The proposed filter has various attractive properties, and offers several advantages over detecting outliers to the epipolar geometry through RANSAC [29], which is traditionally used in the matching literature [13,15,22,23,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 84
                            }
                        ],
                        "text": "However, the method works in conjunction with any affine invariant region extractor [1,13,15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": true,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808451"
                        ],
                        "name": "G. Bebis",
                        "slug": "G.-Bebis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Bebis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bebis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085046"
                        ],
                        "name": "M. Georgiopoulos",
                        "slug": "M.-Georgiopoulos",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Georgiopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Georgiopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700665"
                        ],
                        "name": "N. Lobo",
                        "slug": "N.-Lobo",
                        "structuredName": {
                            "firstName": "Niels",
                            "lastName": "Lobo",
                            "middleNames": [
                                "da",
                                "Vitoria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lobo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 2 ]), which require a 3D model of the object as input, in favor of appearancebased ones, where some example images suffice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24292032,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "cd4f1eb39b82922b85a83c0b7b85a2423de9a6ff",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A major problem associated with geometric hashing and methods which have emerged from it is the non-uniform distribution of invariants over the hash space. This problem can affect the performance of the method significantly. Finding a \"good\" geometric hash function which redistributes the invariants uniformly over the hash space is not easy. In this paper, a new approach is proposed for alleviating the above problem. It is based on the use of an \"elastic hash table\" which is implemented as a self-organizing feature map neural network (SOFM-NN). In contrast to existing approaches which try to redistribute the invariants over the hash bins, we proceed oppositely, spreading the hash bins over the invariants. During training, the SOFM-NN resembles an elastic net which deforms over the hash space. The objective of the deformation process is to spread more hash bins in hash space areas which are heavily occupied and less hash bins in lower density areas. The advantage of the proposed approach is that it is a process that adapts to the invariants through learning. Hence, it makes absolutely no assumptions about the statistical characteristics of the invariants and the geometric hash function is actually computed through learning. Furthermore, the well known \"topology preserving\" property of the SOFM-NN guarantees that the computed geometric hash function should be well behaved. Finally, the proposed approach is inherently parallelizable.<<ETX>>"
            },
            "slug": "Learning-geometric-hashing-functions-for-object-Bebis-Georgiopoulos",
            "title": {
                "fragments": [],
                "text": "Learning geometric hashing functions for model-based object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new approach is proposed for alleviating the problem of non-uniform distribution of invariants over the hash space based on the use of an \"elastic hash table\" which is implemented as a self-organizing feature map neural network (SOFM-NN)."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2938357"
                        ],
                        "name": "Mihai Osian",
                        "slug": "Mihai-Osian",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Osian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mihai Osian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "At recognition time the test video is segmented into shots, and a few representative keyframes are selected in each shot by the algorithm of [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18078398,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "b3016e03eb676f7f286aa038ad9f292605349d8c",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.This paper presents a practical approach to detecting shot cuts and extracting keyframes from video sequences. Shot cut detection has two stages - global motion compensation, followed by an adaptive thresholding algorithm. The motion information is further utilized to extract representative keyframes. Special consideration has been given to achieving real-time performance on a regular PC, which led to a motion estimation algorithm of linear complexity."
            },
            "slug": "Video-shot-characterization-Osian-Gool",
            "title": {
                "fragments": [],
                "text": "Video shot characterization"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper presents a practical approach to detecting shot cuts and extracting keyframes from video sequences using a motion estimation algorithm of linear complexity."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 95
                            }
                        ],
                        "text": "For comparison, we processed the dataset also with 4 state-of-the-art affine region extractors [7, 5, 11, 2], and described the regions with the SIFT [8] descriptor 2 , which has recently been demonstrated to perform best [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "The feature extraction algorithm [2] is applied to both a model image Im and a test image It independently, producing two sets of regions \u03a6m, \u03a6t."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 112
                            }
                        ],
                        "text": "Recently, object recognition (OR) approaches based on local invariant features have become increasingly popular [8, 5, 2, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 120
                            }
                        ],
                        "text": "The proposed method offers two main advantages over rigid-motion filters, traditionally used in the matching literature [2, 5, 4, 13, 7, 14], e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 52
                            }
                        ],
                        "text": "3 We have also tried the standard approach, used in [7, 5, 2, 12], which simply matches two nearestneighbors if their distance is below a threshold, but it produced slightly worse results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 189
                            }
                        ],
                        "text": "The important improvement brought by the proposed method is best quantified by the difference between the highest curve and the central thick curve, representing the system we started from [2] (labeled \u2019[2] org\u2019 in the plot)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "We build upon a multi-scale extension of the affine invariant region extractor of [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "For each test region T \u2208 \u03a6t we compute the Mahalanobis distance of the invariant descriptors [2] to all model regions M \u2208 \u03a6m."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 45
                            }
                        ],
                        "text": "This contrasts with classic matching methods [7, 2, 5, 11, 8], but there are two good reasons for it."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Stereo based on Local, Affinely invariant Regions Brit"
            },
            "venue": {
                "fragments": [],
                "text": "Mach. Vis. Conf., pp. 412-422,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 100
                            }
                        ],
                        "text": "Global, robust geometry filtering methods, like detecting outliers to the epipolar geometry through RANSAC [3] fail, as they need a minimal amount of inliers of about 30% [8]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "How to proceed ? Global, robust geometry filtering methods, like detecting outliers to the epipolar geometry through RANSAC [3] fail, as they need a minimal amount of inliers of about 30% [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": ": detecting outliers to the epipolar geometry through RANSAC [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 200
                            }
                        ],
                        "text": "The proposed method offers two main advantages over rigid-motion filters, traditionally used in the matching literature [2, 5, 4, 13, 7, 14], e.g.: detecting outliers to the epipolar geometry through RANSAC [3]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "development and comparison of robust methods for estimating the fundamental matrix IJCV, 24(3), pp"
            },
            "venue": {
                "fragments": [],
                "text": "271-300,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 267
                            }
                        ],
                        "text": "Feature extractors have appeared [12,14] which are invariant also under scale changes, and more recently recognition under general viewpoint changes has become possible, thanks to extractors adapting the complete affine shape of the feature to the viewing conditions [1,13,15,23,31,30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 52
                            }
                        ],
                        "text": "8 We have also tried the standard approach, used in [15,4,18,30], which simply matches two nearest-neighbors if their distance is below a threshold, but it produced slightly"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "For comparison, we processed the dataset also with 4 state-of-the-art affine region extractors [1,15,18,30], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "We build upon a multiscale extension of the extractor of [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 70
                            }
                        ],
                        "text": "Similar histograms are produced based on the other feature extractors [1,15,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 35
                            }
                        ],
                        "text": "This contrasts with previous works [1,12,15,18,30], but there are two good reasons for it."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "The region extraction algorithm [30] is applied to both images independently, producing two sets of regions \u03a6m, \u03a6t, and a vector of invariants describing each region [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "The important improvement brought by the proposed method is best quantified by the difference between the highest curve and the central thick curve, representing the system we started from [30] (\u2019TVG00 org\u2019 in the plot)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 210
                            }
                        ],
                        "text": "The proposed filter has various attractive properties, and offers several advantages over detecting outliers to the epipolar geometry through RANSAC [29], which is traditionally used in the matching literature [13,15,22,23,30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo based on local, affinely invariant regions"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the British Machine Vision Conference,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "It does not hold for non-coplanar triples in presence of strong parallax in a few cases, coined parallax-violations [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "This sidedness constraint holds for all correctly matched triples of coplanar regions and also for most noncoplanar ones [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 133
                            }
                        ],
                        "text": "makes the filter more robust to low correct-ratios, and remedies the drawback (parallax-violations) of the purely topological filter [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "The registration of the tentative matches is refined using our recently proposed algorithm [1], that efficiently looks for the affine transformation that maximizes the similarity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "The algorithm extends our topological filter in [1] to include also appearance similarity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "As a novel extension to [1], the topological error share (1) is combined with an appearance term, giving the total error"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide-baseline Multiple-view Correspondences IEEE Comp"
            },
            "venue": {
                "fragments": [],
                "text": "Vis. and Patt. Rec"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 95
                            }
                        ],
                        "text": "For comparison, we processed the dataset also with 4 state-of-the-art affine region extractors [7, 5, 11, 2], and described the regions with the SIFT [8] descriptor 2 , which has recently been demonstrated to perform best [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 133
                            }
                        ],
                        "text": "Even in easier cases, to suit the needs for repeatability in spite of viewpoint changes, only a sparse set of distinguished features [7] are extracted."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 168
                            }
                        ],
                        "text": "Moreover, non-rigid deformations are explicitly taken into account, and the approximate boundaries of the object is found, two features lacking in competing approaches [4, 8, 2, 7, 11, 5, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 112
                            }
                        ],
                        "text": "Recently, object recognition (OR) approaches based on local invariant features have become increasingly popular [8, 5, 2, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 120
                            }
                        ],
                        "text": "The proposed method offers two main advantages over rigid-motion filters, traditionally used in the matching literature [2, 5, 4, 13, 7, 14], e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 52
                            }
                        ],
                        "text": "3 We have also tried the standard approach, used in [7, 5, 2, 12], which simply matches two nearestneighbors if their distance is below a threshold, but it produced slightly worse results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 45
                            }
                        ],
                        "text": "This contrasts with classic matching methods [7, 2, 5, 11, 8], but there are two good reasons for it."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object Recognition using Local Affine Frames on Distinguished Regions Brit"
            },
            "venue": {
                "fragments": [],
                "text": "Object Recognition using Local Affine Frames on Distinguished Regions Brit"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 52
                            }
                        ],
                        "text": "8 We have also tried the standard approach, used in [15,4,18,30], which simply matches two nearest-neighbors if their distance is below a threshold, but it produced slightly"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "described the regions with the SIFT [12] descriptor7 , which has recently been demonstrated to perform best [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 57
                            }
                        ],
                        "text": "They should be addressed by techniques based on contours [4,25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 2
                            }
                        ],
                        "text": "g [4,17,27]), and are therefore very sensitive to background clutter and partial occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3d object recognition using similarity-based aspect graph"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the International Conference on Computer Vision,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zisserman Multi-view matching for unordered image sets European Conf"
            },
            "venue": {
                "fragments": [],
                "text": "Zisserman Multi-view matching for unordered image sets European Conf"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gool Wide Baseline Stereo based on Local"
            },
            "venue": {
                "fragments": [],
                "text": "Affinely invariant Regions Brit. Mach. Vis. Conf"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Topological configurations of points and lines are also used in [15], which enforces the cyclic ordering of line segments connecting corners as a mean for steering the matching process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Appearance and Topology for Wide Baseline Matching European Conf"
            },
            "venue": {
                "fragments": [],
                "text": "on Comp. Vis., pp. 68-81,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "The benefits of exploiting previously established geometric transformations was also noted by [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 120
                            }
                        ],
                        "text": "The proposed method offers two main advantages over rigid-motion filters, traditionally used in the matching literature [2, 5, 4, 13, 7, 14], e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "matching for unordered image sets European Conf"
            },
            "venue": {
                "fragments": [],
                "text": "on Comp. Vis., pp. 414-431,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Carlsson Combining Appearance and Topology for Wide Baseline Matching European Conf"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Carlsson Combining Appearance and Topology for Wide Baseline Matching European Conf"
            },
            "venue": {
                "fragments": [],
                "text": "Carlsson Combining Appearance and Topology for Wide Baseline Matching European Conf"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Murray The development and comparison of robust methods for estimating the fundamental matrix IJCV"
            },
            "venue": {
                "fragments": [],
                "text": "Murray The development and comparison of robust methods for estimating the fundamental matrix IJCV"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "In this respect, global methods, both contour-based [9] and appearance-based [10], are a step behind."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual Learning and Recognition of 3D Objects from Appearence Intl"
            },
            "venue": {
                "fragments": [],
                "text": "Journ. of Comp. Vis"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The development and comparison of robust methods for estimating the fundamental matrix IJCV"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D Object Recognition Using Similarity-Based Aspect Graph Intl"
            },
            "venue": {
                "fragments": [],
                "text": "Conf. on Comp. Vis"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zisserman Automated Scene Matching in Movies CIVR"
            },
            "venue": {
                "fragments": [],
                "text": "Zisserman Automated Scene Matching in Movies CIVR"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Van Gool Wide Baseline Stereo based on Local, Affinely invariant Regions Brit"
            },
            "venue": {
                "fragments": [],
                "text": "Van Gool Wide Baseline Stereo based on Local, Affinely invariant Regions Brit"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Affine Invariant Regions ++. PhD Thesis, Selected Readings in Vision and Graphics"
            },
            "venue": {
                "fragments": [],
                "text": "Affine Invariant Regions ++. PhD Thesis, Selected Readings in Vision and Graphics"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "In this respect, global methods, both contour-based [9] and appearance-based [10], are a step behind."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D Object Recognition Using Similarity-Based Aspect"
            },
            "venue": {
                "fragments": [],
                "text": "Graph Intl. Conf. on Comp. Vis.,"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 27,
            "methodology": 28,
            "result": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 51,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Simultaneous-Object-Recognition-and-Segmentation-by-Ferrari-Tuytelaars/7706afc51a71a20d088b494672085f763798ba7a?sort=total-citations"
}