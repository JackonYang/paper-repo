{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 98
                            }
                        ],
                        "text": "A suitable lter will be that of a second derivative Gaussian, elongated at anaspect ratio of 3:1 (Yow and Cipolla [35])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "[14], Sumi and Ohta [27], and Yow and Cipolla [35] reported work using this approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "A suitable lter will be that of a second derivative Gaussian, elongated at an aspect ratio of 3:1 (Yow and Cipolla [35])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "[14], Yow and Cipolla [35] addresses the problem of orientation invariance by using the inter-feature distance or the a ne geometry between the facial features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 53
                            }
                        ],
                        "text": "These groups are called Partial Face Groups or PFGs (Yow and Cipolla [34])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "11 Viewpoint Invariance In Yow and Cipolla [35] we have shown that the Gaussian derivative lter (the preattentive lter described in this paper) is able to detect facial features under di erent viewpoint, even under pro le view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 224
                            }
                        ],
                        "text": "We can simply use only one single orientation of the preattentive lter and justexamine the vicinity of the attention points for pairs of edges that are roughlyparallel and have the correct polarity.11 Viewpoint InvarianceIn Yow and Cipolla [35] we have shown that the Gaussian derivative lter (thepreattentive lter described in this paper) is able to detect facial features underdi erent viewpoint, even under pro le view.21\n(a) (b) (c)Figure 18: Detecting features in pro le views."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "In our previous approaches [34, 35], we used a belief network composed of 4 child nodes, one for each of the 4 partial face groups ( g."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 30
                            }
                        ],
                        "text": "[14], Sumi and Ohta [27], and Yow and Cipolla [35] re-ported work using this approach."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 6
                            }
                        ],
                        "text": "[14], Yow and Cipolla [35]addresses the problem of orientation invariance by using the inter-feature dis-tance or the a ne geometry between the facial features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "The main di erence between this propagation algorithm and the one for trees (used in our previous work [34], [35]) is that nodes in a singly connected network can have more than one parent."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16589495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0396726af5d0ef40beb4eb4f2e50ef38279a7f6d",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method to detect and locate human faces in an image given no prior information about the size, orientation, and viewpoint of the faces in the image. This method uses a family of Gaussian derivative filters to search and extract human facial features from the image and then group them together into a set of partial faces using their geometric relationship. A belief network is then constructed for each possible face candidate and the belief values updated by evidences propagating through the network. Different instances of detected faces are then compared using their belief values and improbable face candidates discarded. The algorithm is tested on different instances of faces with varying sizes, orientation and viewpoint and the results indicate a 91% success rate in detection under viewpoint variation."
            },
            "slug": "Towards-an-Automatic-Human-Face-Localizations-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Towards an Automatic Human Face Localizations System"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This method uses a family of Gaussian derivative filters to search and extract human facial features from the image and then group them together into a set of partial faces using their geometric relationship."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": "[34] K. C. Yow and R. Cipolla."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 106
                            }
                        ],
                        "text": "A suitable lter will be that of a second derivative Gaussian, elongated at anaspect ratio of 3:1 (Yow and Cipolla [35])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 61
                            }
                        ],
                        "text": "Feature-Based Human Face DetectionKin Choong Yow and Roberto CipollaDepartment of EngineeringUniversity of CambridgeCambridge CB2 1PZ, EnglandAbstractHuman face detection has always been an important problem for face,expression and gesture recognition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "These groups are called Partial Face Groups or PFGs (Yow and Cipolla [34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 232
                            }
                        ],
                        "text": "We can simply use only one single orientation of the preattentive lter and justexamine the vicinity of the attention points for pairs of edges that are roughlyparallel and have the correct polarity.11 Viewpoint InvarianceIn Yow and Cipolla [35] we have shown that the Gaussian derivative lter (thepreattentive lter described in this paper) is able to detect facial features underdi erent viewpoint, even under pro le view.21\n(a) (b) (c)Figure 18: Detecting features in pro le views."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": "[35] K. C. Yow and R. Cipolla."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "In our previous approaches [34, 35], we used a belief network composed of 4 child nodes, one for each of the 4 partial face groups ( g."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 38
                            }
                        ],
                        "text": "[14], Sumi and Ohta [27], and Yow and Cipolla [35] re-ported work using this approach."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 14
                            }
                        ],
                        "text": "[14], Yow and Cipolla [35]addresses the problem of orientation invariance by using the inter-feature dis-tance or the a ne geometry between the facial features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "The main di erence between this propagation algorithm and the one for trees (used in our previous work [34], [35]) is that nodes in a singly connected network can have more than one parent."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1899890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9373753a64a6477cbf2751fa5333a7f8e64de92",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method to nd initial estimates of face location in an image where the orientation and viewpoint of the faces are not known. Features such as eyes, nose and mouth are detected from the image using quadrature phase lters and grouped into potential face candidates. AAne invariants are used in grouping to overcome the problem of variation in viewpoint. An eecient searching algorithm is proposed to group these features based on the constraints in the geometry. Each face candidate is then evaluated using a belief network which assigns probabilities to each face candidate and rejects improbable ones. A result of 93% accuracy in detecting viewpoint variations is obtained. Human face recognition has been an interesting problem attempted by numerous researchers over the years. There are many important applications such as criminal identiication, visual surveillance and human computer interfacing which continuously provide the drive and motivation for research in this area. Most human face recognition algorithms have assumed that the location of human face in the image is known, or that the face can be easily extracted from the background. However, this is not true of most applications. Hence, face detection and localization still remains as an important problem to be solved. Recent work on face detection are attempted using various techniques: neural networks (Rowley et al. 9]), shape statistics (Leung et al. 5]), bandpass ltering (Graf et al. 3]), ellipse tting (Jacquin and Elefthe-riadis 4]), and colour (Wu et al. 11]). The neural networks and shape statistics approach works only for fronto-parallel faces with little variation in viewpoint. The methods based on bandpass ltering and ellipse tting works only for head and shoulder images with very little background clutter. Wu et al. 's method of using colour and fuzzy logic works for more general scenes but it cannot cope with diierent hair colour, or when the skin coloured regions in the image doesn't form an elliptical shape of a face. Yow and Cipolla 12]'s work on face detection under diierent viewpoints makes use of Gaussian derivative lters to detect features. This technique has been shown to work well but it has the problem of having too many false candidates and being unable to reject false candidates. In this paper, we describe the use of quadrature phase lters in feature detection which can signiicantly improve the robustness of the system and reduce the number of false detection. A \u2026"
            },
            "slug": "Finding-initial-estimates-of-human-face-location-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Finding initial estimates of human face location"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The use of quadrature phase lters in feature detection is described which can signiicantly improve the robustness of the system and reduce the number of false detection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Recent work was reported by Sung and Poggio [28], and Rowley et."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 14
                            }
                        ],
                        "text": "[13], Sung andPoggio [28], Yang and Huang [33]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 38
                            }
                        ],
                        "text": "In theneural network approach used by Sung and Poggio [28], almost every single pixelin a 19x19 subimage is used, leading to a 283-dimensional space."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 28
                            }
                        ],
                        "text": "Recent work was reported by Sung and Poggio [28], and Row-ley et.al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "In the neural network approach used by Sung and Poggio [28], almost every single pixel in a 19x19 subimage is used, leading to a 283-dimensional space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "[13], Sung and Poggio [28], Yang and Huang [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Sung and Poggio's methodworks very well too because almost every pixel in a 19x19 subimage is usedto evaluate the output, and many of these pixels encode spatial and gray-levelinformation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "[28] K. K. Sung and T. Poggio."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": true,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085062"
                        ],
                        "name": "Gloria Chow",
                        "slug": "Gloria-Chow",
                        "structuredName": {
                            "firstName": "Gloria",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gloria Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109348440"
                        ],
                        "name": "Xiaobo Li",
                        "slug": "Xiaobo-Li",
                        "structuredName": {
                            "firstName": "Xiaobo",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobo Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 167
                            }
                        ],
                        "text": "[6], Turk and Pentland [31]), or they have assumed some constraints about the face and/or background such that the face detection process becomes trivial (Chow and Li [4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27552346,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca6393f736e59be460288e71590e75aa3bfc1091",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Towards-a-system-for-automatic-facial-feature-Chow-Li",
            "title": {
                "fragments": [],
                "text": "Towards a system for automatic facial feature detection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48636477"
                        ],
                        "name": "G. Yang",
                        "slug": "G.-Yang",
                        "structuredName": {
                            "firstName": "Guangzheng",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 27
                            }
                        ],
                        "text": "[13], Sung andPoggio [28], Yang and Huang [33]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 62
                            }
                        ],
                        "text": "Some of the work using this approach were reported by Yang andHuang [33], and Lanitis et.al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 23
                            }
                        ],
                        "text": "[33] G. Yang and T. S. Huang."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Some of the work using this approach were reported by Yang and Huang [33], and Lanitis et."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "[13], Sung and Poggio [28], Yang and Huang [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38060615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bb1ba70d48561ce8c3fbf59739fabc95e7b3d50",
            "isKey": true,
            "numCitedBy": 661,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-face-detection-in-a-complex-background-Yang-Huang",
            "title": {
                "fragments": [],
                "text": "Human face detection in a complex background"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122439944"
                        ],
                        "name": "Qian Chen",
                        "slug": "Qian-Chen",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794240"
                        ],
                        "name": "Haiyuan Wu",
                        "slug": "Haiyuan-Wu",
                        "structuredName": {
                            "firstName": "Haiyuan",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haiyuan Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735941"
                        ],
                        "name": "M. Yachida",
                        "slug": "M.-Yachida",
                        "structuredName": {
                            "firstName": "Masahiko",
                            "lastName": "Yachida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yachida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] extended the matching to 3 views (1 fronto-parallel and 2 pro le views) using a fuzzy pattern matcher based on colour."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3]) but it is sensitive to skin colour and the face shape."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31690449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "857b32ba2a3b10855db4051adc379af7c74cb795",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes an approach to detect faces whose size and position are unknown in an image with a complex background. The candidates of faces are detected by finding out \"face like\" regions in the input image using the fuzzy pattern matching method. The perceptually uniform color space is used in our research in order to obtain reliable results. The skin color that is used to detect face like regions, is represented by a model developed by us called skin color distribution function. The skin color regions are then extracted by estimating a measure that describes how well the color of a pixel looks like the skin color for each pixel in the input image. The faces which appear in images are modeled as several 2 dimensional patterns. The face like regions are extracted by a fuzzy pattern matching approach using these face models. The face candidates are then verified by estimating how well the extracted facial features fit a face model which describes the geometrical relations among facial features.<<ETX>>"
            },
            "slug": "Face-detection-by-fuzzy-pattern-matching-Chen-Wu",
            "title": {
                "fragments": [],
                "text": "Face detection by fuzzy pattern matching"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The paper describes an approach to detect faces whose size and position are unknown in an image with a complex background by finding out \"face like\" regions in the input image using the fuzzy pattern matching method."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10293011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bc436d2892be45fd16ba2620ca0a620bf9f52d7",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the use of flexible models for representing the shape and grey-level appearance of human faces. These models are controlled by a small number of parameters which can be used to code the overall appearance of a face for image compression and classification purposes. The model parameters control both inter-class and within-class variation. Discriminant analysis techniques are employed to enhance the effect of those parameters affecting inter-class variation, which are useful for classification. We have performed experiments on face coding and reconstruction and automatic face identification. Good recognition rates are obtained even when significant variation in lighting, expression and 3D viewpoint, is allowed. Human faces display significant variation in appearance due to changes in expression, 3D orientation, lighting conditions, hairstyles and so on. A successful automatic face identification system should be capable of suppressing the effect of these factors allowing any face image to be rendered expression-free with standardised 3D orientation and lighting. We describe how the variations in shape and grey-level appearance in face images can be modelled, and present results for a fully automatic face identification system which tolerates changes in expression, viewpoint and lighting."
            },
            "slug": "An-Automatic-Face-Identification-System-Using-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "An Automatic Face Identification System Using Flexible Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "How the variations in shape and grey-level appearance in face images can be modelled are described, and results for a fully automatic face identification system which tolerates changes in expression, viewpoint and lighting are presented."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 676887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6af749b2b813af20c2f26962249fafdccdc6a1e",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with another state-of-the-art face detection system are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Human-Face-Detection-in-Visual-Scenes-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Human Face Detection in Visual Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that uses a bootstrap algorithm for training, which adds false detections into the training set as training progresses, and has better performance in terms of detection and false-positive rates than other state-of-the-art face detection systems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 5
                            }
                        ],
                        "text": "[6], Turk and Pentland [31]), or they have assumed some constraints aboutthe face and/or background such that the face detection process becomes trivial(Chow and Li [4])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 6
                            }
                        ],
                        "text": "In A. Pentland, editor, From Pixels toPredicates, pages 5{19."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 20
                            }
                        ],
                        "text": "[31] M. Turk and A. Pentland."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "[6], Turk and Pentland [31]), or they have assumed some constraints about the face and/or background such that the face detection process becomes trivial (Chow and Li [4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": true,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13], Sung and Poggio [28], Yang and Huang [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122941737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b65b06ecdd9df916d8f688e73ac41a2bb0fd63f",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-face-identification-system-using-flexible-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "Automatic face identification system using flexible appearance models"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15242659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f731b6745d829241941307c3ebf163e90e200318",
            "isKey": false,
            "numCitedBy": 7909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN."
            },
            "slug": "Active-Shape-Models-Their-Training-and-Application-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models-Their Training and Application"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes a method for building models by learning patterns of variability from a training set of correctly annotated images that can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "[29]) or the colour of the di erenced image (Schiele and Waibel [26])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "[26] B. Schiele and A. Waibel."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 56
                            }
                        ],
                        "text": "[29]) or the colour of the di erenced image (Schiele andWaibel [26])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18547916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74002c1608746c77b85229f7b001975502c3fab3",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In many practical situations, a desirable user interface to a computer system should have a model of where a person is looking at and what he/she is paying attention to. This is particularly important if a system is providing multi-modal communication cues, speech, gesture, lipreading , etc., 2, 3, 8] and the system must identify, whether the cues are aimed at it, or at someone else in the room. This paper describes a system that identiies user focus of attention by visually determining where a person is looking. While other attempts at gaze tracking usually assume a xed or limited location of a per-son's face, the approach presented here allows for complete freedom of movement in a room. The gaze-tracking system, uses several connectionist modules, that track a person's face using a software controlled pan-tilt camera with zoom and identiies the focus of attention from the orientation and direction of the face."
            },
            "slug": "Gaze-Tracking-Based-on-Face\u2010Color-Schiele-Waibel",
            "title": {
                "fragments": [],
                "text": "Gaze Tracking Based on Face\u2010Color"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The gaze-tracking system, uses several connectionist modules, that track a person's face using a software controlled pan-tilt camera with zoom and identiies the focus of attention from the orientation and direction of the face."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48926774"
                        ],
                        "name": "Ying Dai",
                        "slug": "Ying-Dai",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737939"
                        ],
                        "name": "Y. Nakano",
                        "slug": "Y.-Nakano",
                        "structuredName": {
                            "firstName": "Yasuaki",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nakano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12479014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e47dcdcd15180d9218fa80f107675a0d5cb74e",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-texture-model-based-on-SGLD-and-its-in-face-in-Dai-Nakano",
            "title": {
                "fragments": [],
                "text": "Face-texture model based on SGLD and its application in face detection in a color scene"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153281777"
                        ],
                        "name": "D. Marr",
                        "slug": "D.-Marr",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Marr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31857045"
                        ],
                        "name": "E. Hildreth",
                        "slug": "E.-Hildreth",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Hildreth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hildreth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 142
                            }
                        ],
                        "text": "(d) Face detected (same for all 3 cases of ).19\nThe Gaussian functional minimizes the product of localization in space andfrequency (Marr and Hildreth [16]), but its trade-o between the signal-to-noiseratio and the accuracy of localization is well studied (Canny [2])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "[16] D. Marr and E. C. Hildreth."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "The Gaussian functional minimizes the product of localization in space and frequency (Marr and Hildreth [16]), but its trade-o between the signal-to-noise ratio and the accuracy of localization is well studied (Canny [2])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2150419,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9009c9685754346deb93f316144a9da1f70ffcd8",
            "isKey": false,
            "numCitedBy": 7031,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "A theory of edge detection is presented. The analysis proceeds in two parts. (1) Intensity changes, which occur in a natural image over a wide range of scales, are detected separately at different scales. An appropriate filter for this purpose at a given scale is found to be the second derivative of a Gaussian, and it is shown that, provided some simple conditions are satisfied, these primary filters need not be orientation-dependent. Thus, intensity changes at a given scale are best detected by finding the zero values of \u22072G(x, y)* I(x, y) for image I, where G(x, y) is a two-dimensional Gaussian distribution and \u22072 is the Laplacian. The intensity changes thus discovered in each of the channels are then represented by oriented primitives called zero-crossing segments, and evidence is given that this representation is complete. (2) Intensity changes in images arise from surface discontinuities or from reflectance or illumination boundaries, and these all have the property that they are spatially localized. Because of this, the zero-crossing segments from the different channels are not independent, and rules are deduced for combining them into a description of the image. This description is called the raw primal sketch. The theory explains several basic psychophysical findings, and the operation of forming oriented zero-crossing segments from the output of centre-surround \u22072G filters acting on the image forms the basis for a physiological model of simple cells (see Marr & Ullman 1979)."
            },
            "slug": "Theory-of-edge-detection-Marr-Hildreth",
            "title": {
                "fragments": [],
                "text": "Theory of edge detection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The theory of edge detection explains several basic psychophysical findings, and the operation of forming oriented zero-crossing segments from the output of centre-surround \u22072G filters acting on the image forms the basis for a physiological model of simple cells."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B. Biological Sciences"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 217
                            }
                        ],
                        "text": "The Gaussian functional minimizes the product of localization in space and frequency (Marr and Hildreth [16]), but its trade-o between the signal-to-noise ratio and the accuracy of localization is well studied (Canny [2])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27662,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144986880"
                        ],
                        "name": "I. Craw",
                        "slug": "I.-Craw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Craw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Craw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3263505"
                        ],
                        "name": "D. Tock",
                        "slug": "D.-Tock",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056963263"
                        ],
                        "name": "Alan Bennett",
                        "slug": "Alan-Bennett",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Bennett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6], Turk and Pentland [31]), or they have assumed some constraints about the face and/or background such that the face detection process becomes trivial (Chow and Li [4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17481367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2e6bc4db498566a9f95f122970fb4488eaf3392",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a computer program which understands a greyscale image of a face well enough to locate individual face features such as eyes and mouth. The program has two distinct components: modules designed to locate particular face features, usually in a restricted area; and the overall control strategy which activates modules on the basis of the current solution state, and assesses and integrates the results of each module."
            },
            "slug": "Finding-Face-Features-Craw-Tock",
            "title": {
                "fragments": [],
                "text": "Finding Face Features"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A computer program which understands a greyscale image of a face well enough to locate individual face features such as eyes and mouth is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48926774"
                        ],
                        "name": "Ying Dai",
                        "slug": "Ying-Dai",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737939"
                        ],
                        "name": "Y. Nakano",
                        "slug": "Y.-Nakano",
                        "structuredName": {
                            "firstName": "Yasuaki",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nakano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34593830"
                        ],
                        "name": "H. Miyao",
                        "slug": "H.-Miyao",
                        "structuredName": {
                            "firstName": "Hidetoshi",
                            "lastName": "Miyao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Miyao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46946093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8043ff328e0babf4a4165c4ad05af984df0c561",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposed a new method for the face extraction from a complex background. Based on the space gray level dependence (SGLD) matrices, the facial texture model composed by a set of inequalities was derived. Using this textural model, the authors designed a kind of scanning scheme for face detection in the complex backgrounds. An experiment using 60 images containing 150 faces gave the error rate 0% with the false alarm rate 5.4%."
            },
            "slug": "Extraction-of-facial-images-from-a-complex-using-Dai-Nakano",
            "title": {
                "fragments": [],
                "text": "Extraction of facial images from a complex background using SGLD matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper proposed a new method for the face extraction from a complex background based on the space gray level dependence (SGLD) matrices, the facial texture model composed by a set of inequalities was derived."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3144171"
                        ],
                        "name": "K. Shanmugam",
                        "slug": "K.-Shanmugam",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Shanmugam",
                            "middleNames": [
                                "Sam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shanmugam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686153"
                        ],
                        "name": "I. Dinstein",
                        "slug": "I.-Dinstein",
                        "structuredName": {
                            "firstName": "Its'hak",
                            "lastName": "Dinstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dinstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206786900,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1fdb62555eb650662dbe2a6f3985d390861597c2",
            "isKey": false,
            "numCitedBy": 19248,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications."
            },
            "slug": "Textural-Features-for-Image-Classification-Haralick-Shanmugam",
            "title": {
                "fragments": [],
                "text": "Textural Features for Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "These results indicate that the easily computable textural features based on gray-tone spatial dependancies probably have a general applicability for a wide variety of image-classification applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "The signi cance of this is that we can steer a 1:1 second derivative Gaussian exactly by using only 3 basis lters (Freeman and Adelson [9]), instead of using 16 basis lters to give a 1% error approximation for a 3:1 lter (Perona [21]) - a huge saving in computational requirements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "This family of lters can be e ciently implemented using steerable-scalable basis lters (Perona [21], Freeman and Adelson [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 422916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "547382fa365c1525c6c9eb40c3de66e18c90ca3b",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Steerable-scalable-kernels-for-edge-detection-and-Perona",
            "title": {
                "fragments": [],
                "text": "Steerable-scalable kernels for edge detection and junction analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057667806"
                        ],
                        "name": "R. Mohan",
                        "slug": "R.-Mohan",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 74
                            }
                        ],
                        "text": "Many good perceptual grouping algorithms (Sarkar and Boyer [25], Mohanand Nevatia [17]) make use of such principles for e ective grouping and highperformance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Many good perceptual grouping algorithms (Sarkar and Boyer [25], Mohan and Nevatia [17]) make use of such principles for e ective grouping and high performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "[17] R. Mohan and R. Nevatia."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206417170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43545912c783c84d982f5c5c4b8ebbac8822a3b2",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "A data-driven system for segmenting scenes into objects and their components is presented. This segmentation system generates hierarchies of features that correspond to structural elements such as boundaries and surfaces of objects. The technique is based on perceptual organization, implemented as a mechanism for exploiting geometrical regularities in the shapes of objects as projected on images. Edges are recursively grouped on geometrical relationships into a description hierarchy ranging from edges to the visible surfaces of objects. These edge groupings, which are termed collated features, are abstract descriptors encoding structural information. The geometrical relationships employed are quasi-invariant over 2-D projections and are common to structures of most objects. Thus, collations have a high likelihood of corresponding to parts of objects. Collations serve as intermediate and high-level features for various visual processes. Applications of collations to stereo correspondence, object-level segmentation, and shape description are illustrated. >"
            },
            "slug": "Perceptual-Organization-for-Scene-Segmentation-and-Mohan-Nevatia",
            "title": {
                "fragments": [],
                "text": "Perceptual Organization for Scene Segmentation and Description"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A data-driven system for segmenting scenes into objects and their components is presented, and applications of collations to stereo correspondence, object-level segmentation, and shape description are illustrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Triesman [30] also proposed a two stage model of perception."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17463498,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e543af6f1f29661a43a2cc7706e4a95639327d68",
            "isKey": false,
            "numCitedBy": 908,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This article explores the effects of perceptual grouping on search for targets defined by separate features or by conjunction of features. Treisman and Gelade proposed a feature-integration theory of attention, which claims that in the absence of prior knowledge, the separable features of objects are correctly combined only when focused attention is directed to each item in turn. If items are preattentively grouped, however, attention may be directed to groups rather than to single items whenever no recombination of features within a group could generate an illusory target. This prediction is confirmed: In search for conjunctions, subjects appear to scan serially between groups rather than items. The scanning rate shows little effect of the spatial density of distractors, suggesting that it reflects serial fixations of attention rather than eye movements. Search for features, on the other hand, appears to independent of perceptual grouping, suggesting that features are detected preattentively. A conjunction target can be camouflaged at the preattentive level by placing it at the boundary between two adjacent groups, each of which shares one of its features. This suggests that preattentive grouping creates separate feature maps within each separable dimension rather than one global configuration."
            },
            "slug": "Perceptual-grouping-and-attention-in-visual-search-Treisman",
            "title": {
                "fragments": [],
                "text": "Perceptual grouping and attention in visual search for features and for objects."
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The effects of perceptual grouping on search for targets defined by separate features or by conjunction of features is explored, suggesting that preattentive grouping creates separate feature maps within each separable dimension rather than one global configuration."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306925"
                        ],
                        "name": "Sudeep Sarkar",
                        "slug": "Sudeep-Sarkar",
                        "structuredName": {
                            "firstName": "Sudeep",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sudeep Sarkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734012"
                        ],
                        "name": "K. Boyer",
                        "slug": "K.-Boyer",
                        "structuredName": {
                            "firstName": "Kim",
                            "lastName": "Boyer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Boyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39048769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d0d7e37cdb839cc15decefe2540b8741be7c415",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The formalism of Bayesian networks provides a very elegant solution, in a probabilistic framework, to the problem of integrating top-down and bottom-up visual processes, as well serving as a knowledge base. The formalism is modified to handle spatial data, and thus the application of Bayesian networks is extended to visual processing. The modified form is called the perceptual inference network (PIN). The theoretical background of a PIN is presented, and its viability is demonstrated in the context of perceptual organization. Perceptual organization imparts robustness, efficiency, and a qualitative and holistic nature to vision. Thus far, the approaches to the problem of perceptual organization have been purely bottom up, without much top-down knowledge-base influence, and are therefore entirely dependent on the inputs, which are obviously imperfect. The knowledge base, besides coping with such input imperfection, also makes it possible to integrate multiple organizations and form a composite organization hypothesis. The PIN imparts an active inferential and integrating nature to perceptual organization in an elegant probabilistic framework. >"
            },
            "slug": "Integration,-Inference,-and-Management-of-Spatial-Sarkar-Boyer",
            "title": {
                "fragments": [],
                "text": "Integration, Inference, and Management of Spatial Information Using Bayesian Networks: Perceptual Organization"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The formalism of Bayesian networks provides a very elegant solution, in a probabilistic framework, to the problem of integrating top-down and bottom-up visual processes, as well as serving as a knowledge base, to create a composite organization hypothesis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "The signi cance of this is that we can steer a 1:1 second derivative Gaussian exactly by using only 3 basis lters (Freeman and Adelson [9]), instead of using 16 basis lters to give a 1% error approximation for a 3:1 lter (Perona [21]) - a huge saving in computational requirements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "This family of lters can be e ciently implemented using steerable-scalable basis lters (Perona [21], Freeman and Adelson [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "The signi cance of this is that we can steer a 1:1 second derivativeGaussian exactly by using only 3 basis lters (Freeman and Adelson [9]), insteadof using 16 basis lters to give a 1% error approximation for a 3:1 lter (Perona[21]) - a huge saving in computational requirements."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 100
                            }
                        ],
                        "text": "Thisfamily of lters can be e ciently implemented using steerable-scalable basis lters (Perona [21], Freeman and Adelson [9])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 28
                            }
                        ],
                        "text": "[9] W. T. Freeman and E. H. Adelson."
                    },
                    "intents": []
                }
            ],
            "corpusId": 29187618,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "993b1083455b5c4d631eaf44f230b061994e75c3",
            "isKey": true,
            "numCitedBy": 3379,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. The authors show how to design and steer the filters and present examples of their use in the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters. >"
            },
            "slug": "The-Design-and-Use-of-Steerable-Filters-Freeman-Adelson",
            "title": {
                "fragments": [],
                "text": "The Design and Use of Steerable Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809905"
                        ],
                        "name": "A. Witkin",
                        "slug": "A.-Witkin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Witkin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Witkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7096897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a26f893c224ed6e3df1f37479de0e774a4cae237",
            "isKey": false,
            "numCitedBy": 2873,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scale-Space-Filtering-Witkin",
            "title": {
                "fragments": [],
                "text": "Scale-Space Filtering"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107788"
                        ],
                        "name": "T. Trew",
                        "slug": "T.-Trew",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Trew",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Trew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143851026"
                        ],
                        "name": "R. Gallery",
                        "slug": "R.-Gallery",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Gallery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gallery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2616535"
                        ],
                        "name": "D. Thanassas",
                        "slug": "D.-Thanassas",
                        "structuredName": {
                            "firstName": "Dimitrios",
                            "lastName": "Thanassas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Thanassas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2942321"
                        ],
                        "name": "E. Badiqu\u00e9",
                        "slug": "E.-Badiqu\u00e9",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Badiqu\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Badiqu\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 329871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41ef1e226e88e2b588b554f122192f1f1f77cebe",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "New video communication and multi-media products open up a range of machine vision applications, in which the potential size of the market can justify a substantial investment in the development of sophisticated algorithms. Face location can be used to enhance the subjective performance of videophones, while still conforming with international video compression standards. This paper gives an overview of the location techniques employed, describes a real-time implementation, and presents the results of the subjective tests which conftrmed the improvement in picture quality."
            },
            "slug": "Automatic-Face-Location-to-Enhance-Videophone-Trew-Gallery",
            "title": {
                "fragments": [],
                "text": "Automatic Face Location to Enhance Videophone Picture Quality"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An overview of the location techniques employed, a real-time implementation, and the results of the subjective tests which conftrmed the improvement in picture quality are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2359839"
                        ],
                        "name": "S. Palmer",
                        "slug": "S.-Palmer",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Palmer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 62
                            }
                        ],
                        "text": "Excellent surveysof these works can be found in Lowe [15] and Palmer [19].5\nThe Gestalt laws of organization (Ko ka [11], Kohler [12]) states the com-mon rules by which our visual system attempts to group information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "[19] S. E. Palmer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Excellent surveys of these works can be found in Lowe [15] and Palmer [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118772290,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c95b58f49f3818139551a34f6e1e0d456fc6588e",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Psychology-of-Perceptual-Organization:-A-Palmer",
            "title": {
                "fragments": [],
                "text": "The Psychology of Perceptual Organization: A Transformational Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820860"
                        ],
                        "name": "R. Neapolitan",
                        "slug": "R.-Neapolitan",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Neapolitan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neapolitan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 117
                            }
                        ],
                        "text": "An example illustrating the useof the above equations to propagate evidence in a singly connected network isgiven in Neapolitan [18]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "An example illustrating the use of the above equations to propagate evidence in a singly connected network is given in Neapolitan [18]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 11
                            }
                        ],
                        "text": "[18] R. E. Neapolitan."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5473785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e1c26d71c62120ecfa0784bdf0b417ba6c6a982",
            "isKey": true,
            "numCitedBy": 703,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This text is a reprint of the seminal 1989 book Probabilistic Reasoning in Expert systems: Theory and Algorithms, which helped serve to create the field we now call Bayesian networks. It introduces the properties of Bayesian networks (called causal networks in the text), discusses algorithms for doing inference in Bayesian networks, covers abductive inference, and provides an introduction to decision analysis. Furthermore, it compares rule-base experts systems to ones based on Bayesian networks, and it introduces the frequentist and Bayesian approaches to probability. Finally, it provides a critique of the maximum entropy formalism. Probabilistic Reasoning in Expert Systems was written from the perspective of a mathematician with the emphasis being on the development of theorems and algorithms. Every effort was made to make the material accessible. There are ample examples throughout the text. This text is important reading for anyone interested in both the fundamentals of Bayesian networks and in the history of how they came to be. It also provides an insightful comparison of the two most prominent approaches to probability."
            },
            "slug": "Probabilistic-reasoning-in-expert-systems-theory-Neapolitan",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in expert systems - theory and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This text is a reprint of the seminal 1989 book Probabilistic Reasoning in Expert systems: Theory and Algorithms, which helped serve to create the field the authors now call Bayesian networks and provides an insightful comparison of the two most prominent approaches to probability."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624867"
                        ],
                        "name": "John Binder",
                        "slug": "John-Binder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Binder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Binder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40359484"
                        ],
                        "name": "K. Kanazawa",
                        "slug": "K.-Kanazawa",
                        "structuredName": {
                            "firstName": "Keiji",
                            "lastName": "Kanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kanazawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1773555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06c27c96b5201f6fc57c434856c1865135f4bbb5",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic networks which provide compact descriptions of complex stochastic relationships among several random variables are rapidly becoming the tool of choice for uncertain reasoning in artificial intelligence. We show that networks with fixed structure containing hidden variables can be learned automatically from data using a gradient-descent mechanism similar to that used in neural networks We also extend the method to networks with intensionally represented distributions, including networks with continuous variables and dynamic probabilistic networks Because probabilistic networks provide explicit representations of causal structure human experts can easily contribute pnor knowledge to the training process, thereby significantly improving the learning rate Adaptive probabilistic networks (APNs) may soon compete directly with neural networks as models in computational neuroscience as well as in industrial and financial applications."
            },
            "slug": "Local-Learning-in-Probabilistic-Networks-with-Russell-Binder",
            "title": {
                "fragments": [],
                "text": "Local Learning in Probabilistic Networks with Hidden Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that networks with fixed structure containing hidden variables can be learned automatically from data using a gradient-descent mechanism similar to that used in neural networks, which is extended to networks with intensionally represented distributions."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "[24] S. Russell and P. Norvig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Bayesian networks do not assume independence among features, they encode the dependencies among features (Russell and Norvig [24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 120
                            }
                        ],
                        "text": "Bayesian net-works do not assume independence among features, they encode the dependen-cies among features (Russell and Norvig [24])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53142908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3524cdf7cf8344e7eb74886f71fcbb5c6732c337",
            "isKey": true,
            "numCitedBy": 26735,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence."
            },
            "slug": "Artificial-Intelligence:-A-Modern-Approach-Russell-Norvig",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence: A Modern Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115044673"
                        ],
                        "name": "W. Ko\u0308hler",
                        "slug": "W.-Ko\u0308hler",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Ko\u0308hler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ko\u0308hler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 122
                            }
                        ],
                        "text": "Excellent surveysof these works can be found in Lowe [15] and Palmer [19].5\nThe Gestalt laws of organization (Ko ka [11], Kohler [12]) states the com-mon rules by which our visual system attempts to group information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "[12] W. Kohler."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "The Gestalt laws of organization (Ko ka [11], Kohler [12]) states the common rules by which our visual system attempts to group information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 198144477,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "346cb4edea6785e3935cade9f52552e2bd838e03",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Gestalt theory was introduced as a contrast to at the time dominant structuralism, which claimed that complex perceptions could be understood through breaking them into smaller elementary parts of experience, like splitting graphical forms into sets of dots or melody into sequence of sounds. Gestaltists attacked this theory: same melody can be recognized if transposed into another key and perception of a rectangle can be achieved through other forms than four lines. The idea of Wertheimer was that the ability to perceive objects was an ability of the nervous system, which tends to group together objects that are nearby, similar, form smooth lines, form most of the shape we can recognize. These are the four Wertheimer's laws of grouping:"
            },
            "slug": "Gestalt-psychology-Ko\u0308hler",
            "title": {
                "fragments": [],
                "text": "Gestalt psychology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114409274"
                        ],
                        "name": "K. Koffka",
                        "slug": "K.-Koffka",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Koffka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koffka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1775179,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c6688c195b3f30267f4a832605e4d8904de9bd64",
            "isKey": false,
            "numCitedBy": 3012,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Routledge is now re-issuing this prestigious series of 204 volumes originally published between 1910 and 1965. The titles include works by key figures such asC.G. Jung, Sigmund Freud, Jean Piaget, Otto Rank, James Hillman, Erich Fromm, Karen Horney and Susan Isaacs. Each volume is available on its own, as part of a themed mini-set, or as part of a specially-priced 204-volume set. A brochure listing each title in the \"International Library of Psychology\" series is available upon request."
            },
            "slug": "Principles-Of-Gestalt-Psychology-Koffka",
            "title": {
                "fragments": [],
                "text": "Principles of Gestalt Psychology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1936
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "We use a propagation algorithm for singly connected networks given byPearl [20] which does not make any unfounded assumption of the conditionalindependence of the system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "[20] J. Pearl."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "We use a propagation algorithm for singly connected networks given by Pearl [20] which does not make any unfounded assumption of the conditional independence of the system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In Pearl's algorithm, each node when instantiatedwith a piece of evidence will modify its parent or child nodes by sending 10\nor messages to them."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57437891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bf6f01402e1648b7d1e6c9200ede6cb1af30123",
            "isKey": true,
            "numCitedBy": 4579,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 52
                            }
                        ],
                        "text": "A standardboundary algorithm (such as that given in Ballard and Brown [1]) will su ce."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "We use a boundary following algorithm given in Ballad and Brown [1] to link the edges."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 48
                            }
                        ],
                        "text": "We use a boundary following al-gorithm given in Ballad and Brown [1] to link the edges."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "A standard boundary algorithm (such as that given in Ballard and Brown [1]) will su ce."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 225
                            }
                        ],
                        "text": "The framework can be further extended to moredi cult imaging conditions by adding more components to the face model and nding more evidence in the image to support the face hypotheses.27\nReferences[1] C. H. Ballard and C. M. Brown."
                    },
                    "intents": []
                }
            ],
            "corpusId": 195995446,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e26162d70f04da2091d1aa011f6999b76cbddff",
            "isKey": true,
            "numCitedBy": 4640,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-Ballard-Brown",
            "title": {
                "fragments": [],
                "text": "Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Sumi and Ohta [27] also attempted detection of pro leviews but their approach is largely based on image correlation.9 Scale InvarianceIn this section, we will look at the e ects of varying scale on the detection offaces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Sumi and Ohta [27] also attempted detection of pro le views but their approach is largely based on image correlation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 96
                            }
                        ],
                        "text": "Leung et.al. use the response from a set of steerable-scalable lters to nd facial features, and Sumi and Ohta use template matching to identify eyes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "[14], Sumi and Ohta [27], and Yow and Cipolla [35] reported work using this approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 4
                            }
                        ],
                        "text": "'s, Sumi and Ohta's methoddid not perform as well."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 6
                            }
                        ],
                        "text": "[14], Sumi and Ohta [27], and Yow and Cipolla [35] re-ported work using this approach."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "[27] Y. Sumi and Y. Ohta."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detection of face orientation and facial components  using distributed appreance modeling"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Workshop on Auto.  Face and Gesture Recog., pages 254{259, Zurich"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 166
                            }
                        ],
                        "text": "Faces are detectedby examining the spatial distribution of the gray-level information in the subim-age (using Space Gray Level Dependency (SGLD) matrices proposed by Haralick[10])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "[10] R. M. Haralick."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 175
                            }
                        ],
                        "text": "Faces are detected by examining the spatial distribution of the gray-level information in the subimage (using Space Gray Level Dependency (SGLD) matrices proposed by Haralick [10])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 208113339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a150c6f1c967e4c454267e7ecdb87412ecaa91d5",
            "isKey": true,
            "numCitedBy": 300,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Textural-features-for-image-classification.-IEEE-on-Haralick",
            "title": {
                "fragments": [],
                "text": "Textural features for image classification. IEEE Transaction on Systems, Man, and Cybernetics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141437395"
                        ],
                        "name": "Thomas Leung",
                        "slug": "Thomas-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14], Yow and Cipolla [35] addresses the problem of orientation invariance by using the inter-feature distance or the a ne geometry between the facial features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "'s [14], and yet it spans a larger area over the actual face, thus making the detection more robust and reliable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14], Sumi and Ohta [27], and Yow and Cipolla [35] reported work using this approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14] model the face as a statistical graph consisting of 5 points, namely the eyes, nostrils and nose tip."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 203665849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9232bfb8109b3d3237be4a2cf870e6201519ce5d",
            "isKey": true,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Finding-Faces-in-Cluttered-Scenes-Using-Labeled-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding Faces in Cluttered Scenes Using Labeled Random Graph Matching."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV 1995"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143863790"
                        ],
                        "name": "J. Beck",
                        "slug": "J.-Beck",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Beck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69522882"
                        ],
                        "name": "B. Hope",
                        "slug": "B.-Hope",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Hope",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hope"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60365087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4969a400aef019c0ca64b8853a7eee5de8d80717",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-and-Machine-Vision-Beck-Hope",
            "title": {
                "fragments": [],
                "text": "Human and Machine Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "The Gestalt laws of organization (Ko ka [11], Kohler [12]) states the common rules by which our visual system attempts to group information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ka. Principles of Gestalt Psychology"
            },
            "venue": {
                "fragments": [],
                "text": "Harcourt, Brace and World,"
            },
            "year": 1935
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[29]) or the colour of the di erenced image (Schiele and Waibel [26])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and E"
            },
            "venue": {
                "fragments": [],
                "text": "Badiqu  e. Automatic  face location to enhance videophone picture quality. In Proc. 4th British  Machine Vision Conference, pages 488{497. Springer{Verlag"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An automatic face identiication system using exible appearance models"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scale space ltering"
            },
            "venue": {
                "fragments": [],
                "text": "A. Pentland, editor, From Pixels to  Predicates, pages 5{19. Ablex Publishing Corp., New Jersey"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scale space ltering From Pixels to Predicates, pages 5{19"
            },
            "venue": {
                "fragments": [],
                "text": "Scale space ltering From Pixels to Predicates, pages 5{19"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Texture features for image classiication"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst, Man and Cybern"
            },
            "year": 1973
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 21,
            "methodology": 10,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 43,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Feature-based-human-face-detection-Yow-Cipolla/30e2f29d26f31846d6e0294cfa3733adfc618bbb?sort=total-citations"
}