{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144514048"
                        ],
                        "name": "Antonio Toral",
                        "slug": "Antonio-Toral",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Toral",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Toral"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143666773"
                        ],
                        "name": "R. Mu\u00f1oz",
                        "slug": "R.-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mu\u00f1oz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 204
                            }
                        ],
                        "text": "It turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance (Cohen, 2004; Kazama and Torisawa, 2007a; Toral and Munoz, 2006; Florian et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 10
                            }
                        ],
                        "text": "Recently, (Toral and Munoz, 2006; Kazama and Torisawa, 2007a) have successfully constructed high quality and high coverage gazetteers from Wikipedia."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 5
                            }
                        ],
                        "text": "Both (Toral and Munoz, 2006) and (Kazama and Torisawa, 2007a) used the free-text description of the Wikipedia entity to reason about the entity type."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15388570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3db752c82d5c07ddac056eb3d04b0db59aede57f",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method to automatically create and maintain gazetteers for Named Entity Recognition (NER). This method extracts the necessary information from linguistic resources. Our approach is based on the analysis of an on-line encyclopedia entries by using a noun hierarchy and optionally a PoS tagger. An important motivation is to reach a high level of language independence. This restricts the techniques that can be used but makes the method useful for languages with few resources. The evaluation carried out proves that this approach can be successfully used to build NER gazetteers for location (F 78%) and person (F 68%) categories."
            },
            "slug": "A-proposal-to-automatically-build-and-maintain-for-Toral-Mu\u00f1oz",
            "title": {
                "fragments": [],
                "text": "A proposal to automatically build and maintain gazetteers for Named Entity Recognition by using Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper describes a method to automatically create and maintain gazetteers for Named Entity Recognition (NER) based on the analysis of an on-line encyclopedia entries by using a noun hierarchy and optionally a PoS tagger."
            },
            "venue": {
                "fragments": [],
                "text": "Workshop On New Text Wikis And Blogs And Other Dynamic Text Sources"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761994"
                        ],
                        "name": "Jun'ichi Kazama",
                        "slug": "Jun'ichi-Kazama",
                        "structuredName": {
                            "firstName": "Jun'ichi",
                            "lastName": "Kazama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun'ichi Kazama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768754"
                        ],
                        "name": "Kentaro Torisawa",
                        "slug": "Kentaro-Torisawa",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Torisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kentaro Torisawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 204
                            }
                        ],
                        "text": "It turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance (Cohen, 2004; Kazama and Torisawa, 2007a; Toral and Munoz, 2006; Florian et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 10
                            }
                        ],
                        "text": "Recently, (Toral and Munoz, 2006; Kazama and Torisawa, 2007a) have successfully constructed high quality and high coverage gazetteers from Wikipedia."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 33
                            }
                        ],
                        "text": "Both (Toral and Munoz, 2006) and (Kazama and Torisawa, 2007a) used the free-text description of the Wikipedia entity to reason about the entity type."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14343843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fc360befecd3ca2fa9bddd799e4c16211299fa3",
            "isKey": false,
            "numCitedBy": 335,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the use of Wikipedia as external knowledge to improve named entity recognition (NER). Our method retrieves the corresponding Wikipedia entry for each candidate word sequence and extracts a category label from the first sentence of the entry, which can be thought of as a definition part. These category labels are used as features in a CRF-based NE tagger. We demonstrate using the CoNLL 2003 dataset that the Wikipedia category labels extracted by such a simple method actually improve the accuracy of NER."
            },
            "slug": "Exploiting-Wikipedia-as-External-Knowledge-for-Kazama-Torisawa",
            "title": {
                "fragments": [],
                "text": "Exploiting Wikipedia as External Knowledge for Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated using the CoNLL 2003 dataset that the Wikipedia category labels extracted by such a simple method actually improve the accuracy of NER."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058666135"
                        ],
                        "name": "Vijay Krishnan",
                        "slug": "Vijay-Krishnan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Krishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Krishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 81
                            }
                        ],
                        "text": "We implemented the token-majority and the entity-majority features discussed in (Krishnan and Manning, 2006); however, instead of document and corpus majority tags, we used relative frequency of the tags in a 1000 token window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 1
                            }
                        ],
                        "text": "(Krishnan and Manning, 2006) used the intuition that some instances of a token appear in easily-identifiable contexts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14735038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2e65df02ae308402a6376dce0a2970bfb4980c3",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows that a simple two-stage approach to handle non-local dependencies in Named Entity Recognition (NER) can outperform existing approaches that handle non-local dependencies, while being much more computationally efficient. NER systems typically use sequence models for tractable inference, but this makes them unable to capture the long distance structure present in text. We use a Conditional Random Field (CRF) based NER system using local features to make predictions and then train another CRF which uses both local information and features extracted from the output of the first CRF. Using features capturing non-local dependencies from the same document, our approach yields a 12.6% relative error reduction on the F1 score, over state-of-the-art NER systems using local-information alone, when compared to the 9.3% relative error reduction offered by the best systems that exploit non-local information. Our approach also makes it easy to incorporate non-local information from other documents in the test corpus, and this gives us a 13.3% error reduction over NER systems using local-information alone. Additionally, our running time for inference is just the inference time of two sequential CRFs, which is much less than that directly model the dependencies and do approximate inference."
            },
            "slug": "An-Effective-Two-Stage-Model-for-Exploiting-in-Krishnan-Manning",
            "title": {
                "fragments": [],
                "text": "An Effective Two-Stage Model for Exploiting Non-Local Dependencies in Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper shows that a simple two-stage approach to handle non-local dependencies in Named Entity Recognition (NER) can outperform existing approaches that handleNon- local dependencies, while being much more computationally efficient."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770124"
                        ],
                        "name": "Sunita Sarawagi",
                        "slug": "Sunita-Sarawagi",
                        "structuredName": {
                            "firstName": "Sunita",
                            "lastName": "Sarawagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunita Sarawagi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 204
                            }
                        ],
                        "text": "It turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance (Cohen, 2004; Kazama and Torisawa, 2007a; Toral and Munoz, 2006; Florian et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4108765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2559417f8a3d6ab922cfa824b43f9f0c642a1dae",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of improving named entity recognition (NER) systems by using external dictionaries---more specifically, the problem of extending state-of-the-art NER systems by incorporating information about the similarity of extracted entities to entities in an external dictionary. This is difficult because most high-performance named entity recognition systems operate by sequentially classifying words as to whether or not they participate in an entity name; however, the most useful similarity measures score entire candidate names. To correct this mismatch we formalize a semi-Markov extraction process, which is based on sequentially classifying segments of several adjacent words, rather than single words. In addition to allowing a natural way of coupling high-performance NER methods and high-performance similarity functions, this formalism also allows the direct use of other useful entity-level features, and provides a more natural formulation of the NER problem than sequential word classification. Experiments in multiple domains show that the new model can substantially improve extraction performance over previous methods for using external dictionaries in NER."
            },
            "slug": "Exploiting-dictionaries-in-named-entity-extraction:-Cohen-Sarawagi",
            "title": {
                "fragments": [],
                "text": "Exploiting dictionaries in named entity extraction: combining semi-Markov extraction processes and data integration methods"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A semi-Markov extraction process is formalized, which is based on sequentially classifying segments of several adjacent words, rather than single words, and provides a more natural formulation of the NER problem than sequential word classification."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444687"
                        ],
                        "name": "David E. Johnson",
                        "slug": "David-E.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David E. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 107
                            }
                        ],
                        "text": "This conditional probability distribution is estimated in NER using the following baseline set of features (Zhang and Johnson, 2003): (1) previous two predictions yi\u22121 and yi\u22122 (2) current word xi (3) xi word type (all-capitalized, is-capitalized, all-digits, alphanumeric, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7896577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "207df123e3c24e6e25019d4b86f8efaad5d6f13c",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a robust linear classification system for Named Entity Recognition. A similar system has been applied to the CoNLL text chunking shared task with state of the art performance. By using different linguistic features, we can easily adapt this system to other token-based linguistic tagging problems. The main focus of the current paper is to investigate the impact of various local linguistic features for named entity recognition on the CoNLL-2003 (Tjong Kim Sang and De Meulder, 2003) shared task data. We show that the system performance can be enhanced significantly with some relative simple token-based features that are available for many languages. Although more sophisticated linguistic features will also be helpful, they provide much less improvement than might be expected."
            },
            "slug": "A-Robust-Risk-Minimization-based-Named-Entity-Zhang-Johnson",
            "title": {
                "fragments": [],
                "text": "A Robust Risk Minimization based Named Entity Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that the system performance can be enhanced significantly with some relative simple token-based features that are available for many languages, and more sophisticated linguistic features provide much less improvement than might be expected."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024630"
                        ],
                        "name": "Hai Leong Chieu",
                        "slug": "Hai-Leong-Chieu",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Chieu",
                            "middleNames": [
                                "Leong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Leong Chieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "(Chieu and Ng, 2003) used features that aggregate, for each document, the context tokens appear in."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16619357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03c03dec975554cb02aca1e076106178dbe0a8a0",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The named entity recognition (NER) task involves identifying noun phrases that are names, and assigning a class to each name. This task has its origin from the Message Understanding Conferences (MUC) in the 1990s, a series of conferences aimed at evaluating systems that extract information from natural language texts. It became evident that in order to achieve good performance in information extraction, a system needs to be able to recognize names. A separate subtask on NER was created in MUC-6 and MUC-7 (Chinchor, 1998)."
            },
            "slug": "Named-Entity-Recognition-with-a-Maximum-Entropy-Chieu-Ng",
            "title": {
                "fragments": [],
                "text": "Named Entity Recognition with a Maximum Entropy Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The named entity recognition (NER) task involves identifying noun phrases that are names, and assigning a class to each name."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145612610"
                        ],
                        "name": "Doug Downey",
                        "slug": "Doug-Downey",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Downey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Downey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3296031"
                        ],
                        "name": "Tal Shaked",
                        "slug": "Tal-Shaked",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Shaked"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 169
                            }
                        ],
                        "text": "Given these findings, several approaches have been proposed to automatically extract comprehensive gazetteers from the web and from large collections of unlabeled text (Etzioni et al., 2005; Riloff and Jones, 1999) with limited impact on NER."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 168
                            }
                        ],
                        "text": "Given these findings, several approaches have been proposed to automatically extract comprehensive gazetteers from the web and from large collections of unlabeled text (Etzioni et al., 2005; Riloff and Jones, 1999) with lim-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7162988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "421151fa75e40dd86414215abf29d9f2c052a2e1",
            "isKey": false,
            "numCitedBy": 1229,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Unsupervised-named-entity-extraction-from-the-Web:-Etzioni-Cafarella",
            "title": {
                "fragments": [],
                "text": "Unsupervised named-entity extraction from the Web: An experimental study"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2265224"
                        ],
                        "name": "Nicholas Rizzolo",
                        "slug": "Nicholas-Rizzolo",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Rizzolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas Rizzolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 59
                            }
                        ],
                        "text": ", 2003) We specify the model and the features with the LBJ (Rizzolo and Roth, 2007) modeling language."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 213
                            }
                        ],
                        "text": "Systems based on perceptron have been shown to be competitive in NER and text chunking (Kazama and Torisawa, 2007b; Punyakanok and Roth, 2001; Carreras et al., 2003) We specify the model and the features with the LBJ (Rizzolo and Roth, 2007) modeling language."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "\u2021 We thank Nicholas Rizzolo for the baseline LBJ NER system, Xavier Carreras for suggesting the word class models, and multiple reviewers for insightful comments."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14287496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "def1f9b9457640bf267b1ce4efc99b82a3f0f1e7",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Many recent advances in complex domains such as natural language processing (NLP) have taken a discriminative approach in conjunction with the global application of structural and domain specific constraints. We introduce LBJ, a new modeling language for specifying exact inference systems of this type, combining ideas from machine learning, optimization, first order logic (FOL), and object oriented programming (OOP). Expressive constraints are specified declaratively as arbitrary FOL formulas over functions and objects. The language's run-time library translates them to a mathematical programming representation from which an exact solution is computed. In addition, the compiler leverages an existing OOP language: objects and functions are grounded as the OOP objects and methods that encapsulate the user's data."
            },
            "slug": "Modeling-Discriminative-Global-Inference-Rizzolo-Roth",
            "title": {
                "fragments": [],
                "text": "Modeling Discriminative Global Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "LBJ is introduced, a new modeling language for specifying exact inference systems of this type, combining ideas from machine learning, optimization, first order logic (FOL), and object oriented programming (OOP)."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Semantic Computing (ICSC 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060101052"
                        ],
                        "name": "Terry Koo",
                        "slug": "Terry-Koo",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Koo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terry Koo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701734"
                        ],
                        "name": "X. Carreras",
                        "slug": "X.-Carreras",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Carreras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Carreras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 165
                            }
                        ],
                        "text": "In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al., 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1916754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "790ecefeaf2b471b439743a772ccce026131bef5",
            "isKey": false,
            "numCitedBy": 494,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple and effective semisupervised method for training dependency parsers. We focus on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus. We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank, and we show that the cluster-based features yield substantial gains in performance across a wide range of conditions. For example, in the case of English unlabeled second-order parsing, we improve from a baseline accuracy of 92.02% to 93.16%, and in the case of Czech unlabeled second-order parsing, we improve from a baseline accuracy of 86.13% to 87.13%. In addition, we demonstrate that our method also improves performance when small amounts of training data are available, and can roughly halve the amount of supervised data required to reach a desired level of performance."
            },
            "slug": "Simple-Semi-supervised-Dependency-Parsing-Koo-Carreras",
            "title": {
                "fragments": [],
                "text": "Simple Semi-supervised Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work focuses on the problem of lexical representation, introducing features that incorporate word clusters derived from a large unannotated corpus, and shows that the cluster-based features yield substantial gains in performance across a wide range of conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144042991"
                        ],
                        "name": "Jun Suzuki",
                        "slug": "Jun-Suzuki",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Suzuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789234"
                        ],
                        "name": "Hideki Isozaki",
                        "slug": "Hideki-Isozaki",
                        "structuredName": {
                            "firstName": "Hideki",
                            "lastName": "Isozaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hideki Isozaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 42
                            }
                        ],
                        "text": "Recent successful semi-supervised systems (Ando and Zhang, 2005; Suzuki and Isozaki, 2008) have illustrated that unlabeled text can be used to improve the performance of NER systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 2
                            }
                        ],
                        "text": "- (Suzuki and Isozaki, 2008) Semi-supervised on 1Gword unlabeled data 89."
                    },
                    "intents": []
                }
            ],
            "corpusId": 647664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ece4e8d31f872d928369ac2cf58a616a7182112",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides evidence that the use of more unlabeled data in semi-supervised learning can improve the performance of Natural Language Processing (NLP) tasks, such as part-of-speech tagging, syntactic chunking, and named entity recognition. We first propose a simple yet powerful semi-supervised discriminative model appropriate for handling large scale unlabeled data. Then, we describe experiments performed on widely used test collections, namely, PTB III data, CoNLL\u201900 and \u201903 shared task data for the above three NLP tasks, respectively. We incorporate up to 1G-words (one billion tokens) of unlabeled data, which is the largest amount of unlabeled data ever used for these tasks, to investigate the performance improvement. In addition, our results are superior to the best reported results for all of the above test collections."
            },
            "slug": "Semi-Supervised-Sequential-Labeling-and-Using-Scale-Suzuki-Isozaki",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Sequential Labeling and Segmentation Using Giga-Word Scale Unlabeled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "Evidence that the use of more unlabeled data in semi-supervised learning can improve the performance of Natural Language Processing tasks, such as part-of-speech tagging, syntactic chunking, and named entity recognition is provided."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38070424"
                        ],
                        "name": "R. Ando",
                        "slug": "R.-Ando",
                        "structuredName": {
                            "firstName": "Rie",
                            "lastName": "Ando",
                            "middleNames": [
                                "Kubota"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ando"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 42
                            }
                        ],
                        "text": "Recent successful semi-supervised systems (Ando and Zhang, 2005; Suzuki and Isozaki, 2008) have illustrated that unlabeled text can be used to improve the performance of NER systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 2
                            }
                        ],
                        "text": "- (Ando and Zhang, 2005) Semi-supervised on 27Mword unlabeled data 89."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16629334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4299baa815ca5a815a70fba94a9f6f2b42fff19",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In machine learning, whether one can build a more accurate classifier by using unlabeled data (semi-supervised learning) is an important issue. Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear. This paper presents a novel semi-supervised method that employs a learning paradigm which we call structural learning. The idea is to find \"what good classifiers are like\" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data. By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem. The method produces performance higher than the previous best results on CoNLL'00 syntactic chunking and CoNLL'03 named entity chunking (English and German)."
            },
            "slug": "A-High-Performance-Semi-Supervised-Learning-Method-Ando-Zhang",
            "title": {
                "fragments": [],
                "text": "A High-Performance Semi-Supervised Learning Method for Text Chunking"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel semi-supervised method that employs a learning paradigm which is to find \"what good classifiers are like\" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data, which produces performance higher than the previous best results."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105414"
                        ],
                        "name": "F. D. Meulder",
                        "slug": "F.-D.-Meulder",
                        "structuredName": {
                            "firstName": "Fien",
                            "lastName": "Meulder",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Meulder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2470716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb",
            "isKey": false,
            "numCitedBy": 2960,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance."
            },
            "slug": "Introduction-to-the-CoNLL-2003-Shared-Task:-Named-Sang-Meulder",
            "title": {
                "fragments": [],
                "text": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The CoNLL-2003 shared task: language-independent named entity recognition is described and a general overview of the systems that have taken part in the task and discuss their performance is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143667674"
                        ],
                        "name": "J. Veenstra",
                        "slug": "J.-Veenstra",
                        "structuredName": {
                            "firstName": "Jorn",
                            "lastName": "Veenstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veenstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 184
                            }
                        ],
                        "text": "Another important question that has been studied extensively in the context of shallow parsing and was somewhat overlooked in the NER literature is the representation of text segments (Veenstra, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1845735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "008a2291a257072f22764196a3acf0a394bf203a",
            "isKey": false,
            "numCitedBy": 392,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Dividing sentences in chunks of words is a useful preprocessing step for parsing, information extraction and information retrieval. (Ramshaw and Marcus, 1995) have introduced a \"convenient\" data representation for chunking by converting it to a tagging task. In this paper we will examine seven different data representations for the problem of recognizing noun phrase chunks. We will show that the the data representation choice has a minor influence on chunking performance. However, equipped with the most suitable data representation, our memory-based learning chunker was able to improve the best published chunking results for a standard data set."
            },
            "slug": "Representing-Text-Chunks-Sang-Veenstra",
            "title": {
                "fragments": [],
                "text": "Representing Text Chunks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the the data representation choice has a minor influence on chunking performance, however, equipped with the most suitable data representation, the memory-based learning chunker was able to improve the best published chunking results for a standard data set."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110817312"
                        ],
                        "name": "Hong Shen",
                        "slug": "Hong-Shen",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3028658"
                        ],
                        "name": "Anoop Sarkar",
                        "slug": "Anoop-Sarkar",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anoop Sarkar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 68
                            }
                        ],
                        "text": "Related works include voting between several representation schemes (Shen and Sarkar, 2005), lexicalizing the schemes (Molina and Pla, 2002) and automatically searching for best encoding (Edward, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 729229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8334df0103443b78546a3cec9284f668106774fc",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers the hypothesis that voting between multiple data representations can be more accurate than voting between multiple learning models This hypothesis has been considered before (cf [San00]) but the focus was on voting methods rather than the data representations In this paper, we focus on choosing specific data representations combined with simple majority voting On the community standard CoNLL-2000 data set, using no additional knowledge sources apart from the training data, we achieved 94.01 F\u03b2=1 score for arbitrary phrase identification compared to the previous best F\u03b2=1 93.90 We also obtained 95.23 F\u03b2=1 score for Base NP identification Significance tests show that our Base NP identification score is significantly better than the previous comparable best F\u03b2=1 score of 94.22 Our main contribution is that our model is a fast linear time approach and the previous best approach is significantly slower than our system."
            },
            "slug": "Voting-Between-Multiple-Data-Representations-for-Shen-Sarkar",
            "title": {
                "fragments": [],
                "text": "Voting Between Multiple Data Representations for Text Chunking"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper focuses on choosing specific data representations combined with simple majority voting and achieves high scores for arbitrary phrase identification and Base NP identification on the community standard CoNLL-2000 data set."
            },
            "venue": {
                "fragments": [],
                "text": "Canadian Conference on AI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 105
                            }
                        ],
                        "text": "Surprisingly, the greedy policy performs well, this phenmenon was also observed in the POS tagging task (Toutanova et al., 2003; Roth and Zelenko, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14835360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42a490cf4f186d3383c92963817d100afd81e2",
            "isKey": false,
            "numCitedBy": 3438,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag contexts via a dependency network representation, (ii) broad use of lexical features, including jointly conditioning on multiple consecutive words, (iii) effective use of priors in conditional loglinear models, and (iv) fine-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result."
            },
            "slug": "Feature-Rich-Part-of-Speech-Tagging-with-a-Cyclic-Toutanova-Klein",
            "title": {
                "fragments": [],
                "text": "Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A new part-of-speech tagger is presented that demonstrates the following ideas: explicit use of both preceding and following tag contexts via a dependency network representation, broad use of lexical features, and effective use of priors in conditional loglinear models."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 35
                            }
                        ],
                        "text": ", 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 69
                            }
                        ],
                        "text": "In this work, we use the implementation and the clusters obtained in (Liang, 2005) from running the algorithm on the Reuters 1996 dataset, a superset of the CoNLL03 NER dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14740218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31b4c03d721dc10b87c178277c1d369f91db8f0e",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical supervised learning techniques have been successful for many natural language processing tasks, but they require labeled datasets, which can be expensive to obtain. On the other hand, unlabeled data (raw text) is often available \"for free\" in large quantities. Unlabeled data has shown promise in improving the performance of a number of tasks, e.g. word sense disambiguation, information extraction, and natural language parsing. In this thesis, we focus on two segmentation tasks, named-entity recognition and Chinese word segmentation. The goal of named-entity recognition is to detect and classify names of people, organizations, and locations in a sentence. The goal of Chinese word segmentation is to find the word boundaries in a sentence that has been written as a string of characters without spaces. Our approach is as follows: In a preprocessing step, we use raw text to cluster words and calculate mutual information statistics. The output of this step is then used as features in a supervised model, specifically a global linear model trained using the Perceptron algorithm. We also compare Markov and semi-Markov models on the two segmentation tasks. Our results show that features derived from unlabeled data substantially improves performance, both in terms of reducing the amount of labeled data needed to achieve a certain performance level and in terms of reducing the error using a fixed amount of labeled data. We find that sometimes semi-Markov models can also improve performance over Markov models. Thesis Supervisor: Michael Collins Title: Assistant Professor, CSAIL"
            },
            "slug": "Semi-Supervised-Learning-for-Natural-Language-Liang",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis focuses on two segmentation tasks, named-entity recognition and Chinese word segmentation, and shows that features derived from unlabeled data substantially improves performance, both in terms of reducing the amount of labeled data needed to achieve a certain performance level and in termsof reducing the error using a fixed amount of labeling data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761994"
                        ],
                        "name": "Jun'ichi Kazama",
                        "slug": "Jun'ichi-Kazama",
                        "structuredName": {
                            "firstName": "Jun'ichi",
                            "lastName": "Kazama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun'ichi Kazama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768754"
                        ],
                        "name": "Kentaro Torisawa",
                        "slug": "Kentaro-Torisawa",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Torisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kentaro Torisawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 87
                            }
                        ],
                        "text": "Systems based on perceptron have been shown to be competitive in NER and text chunking (Kazama and Torisawa, 2007b; Punyakanok and Roth, 2001; Carreras et al., 2003) We specify the model and the features with the LBJ (Rizzolo and Roth, 2007) modeling language."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 478797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b587491522d8887b347b1dabff005609e3091181",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We cannot use non-local features with current major methods of sequence labeling such as CRFs due to concerns about complexity. We propose a new perceptron algorithm that can use non-local features. Our algorithm allows the use of all types of non-local features whose values are determined from the sequence and the labels. The weights of local and non-local features are learned together in the training process with guaranteed convergence. We present experimental results from the CoNLL 2003 named entity recognition (NER) task to demonstrate the performance of the proposed algorithm."
            },
            "slug": "A-New-Perceptron-Algorithm-for-Sequence-Labeling-Kazama-Torisawa",
            "title": {
                "fragments": [],
                "text": "A New Perceptron Algorithm for Sequence Labeling with Non-Local Features"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a new perceptron algorithm that can use non-local features whose values are determined from the sequence and the labels and presents experimental results from the CoNLL 2003 named entity recognition (NER) task."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145621529"
                        ],
                        "name": "Antonio Molina",
                        "slug": "Antonio-Molina",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144300985"
                        ],
                        "name": "Ferran Pl\u00e0",
                        "slug": "Ferran-Pl\u00e0",
                        "structuredName": {
                            "firstName": "Ferran",
                            "lastName": "Pl\u00e0",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ferran Pl\u00e0"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 118
                            }
                        ],
                        "text": "Related works include voting between several representation schemes (Shen and Sarkar, 2005), lexicalizing the schemes (Molina and Pla, 2002) and automatically searching for best encoding (Edward, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15949463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca88f3fc9f50c645c43dd37b6cf637e18c30e0cf",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified technique to solve different shallow parsing tasks as a tagging problem using a Hidden Markov Model-based approach (HMM). This technique consists of the incorporation of the relevant information for each task into the models. To do this, the training corpus is transformed to take into account this information. In this way, no change is necessary for either the training or tagging process, so it allows for the use of a standard HMM approach. Taking into account this information, we construct a Specialized HMM which gives more complete contextual models. We have tested our system on chunking and clause identification tasks using different specialization criteria. The results obtained are in line with the results reported for most of the relevant state-of-the-art approaches."
            },
            "slug": "Shallow-Parsing-using-Specialized-HMMs-Molina-Pl\u00e0",
            "title": {
                "fragments": [],
                "text": "Shallow Parsing using Specialized HMMs"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A unified technique to solve different shallow parsing tasks as a tagging problem using a Hidden Markov Model-based approach (HMM), which constructs a Specialized HMM which gives more complete contextual models."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474158"
                        ],
                        "name": "Vasin Punyakanok",
                        "slug": "Vasin-Punyakanok",
                        "structuredName": {
                            "firstName": "Vasin",
                            "lastName": "Punyakanok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasin Punyakanok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 87
                            }
                        ],
                        "text": "Systems based on perceptron have been shown to be competitive in NER and text chunking (Kazama and Torisawa, 2007b; Punyakanok and Roth, 2001; Carreras et al., 2003) We specify the model and the features with the LBJ (Rizzolo and Roth, 2007) modeling language."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14509422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fab92869cfab684b3ffb1c16a771e9c3b774acd",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of combining the outcomes of several different classifiers in a way that provides a coherent inference that satisfies some constraints. In particular, we develop two general approaches for an important subproblem - identifying phrase structure. The first is a Markovian approach that extends standard HMMs to allow the use of a rich observation structure and of general classifiers to model state-observation dependencies. The second is an extension of constraint satisfaction formalisms. We develop efficient combination algorithms under both models and study them experimentally in the context of shallow parsing."
            },
            "slug": "The-Use-of-Classifiers-in-Sequential-Inference-Punyakanok-Roth",
            "title": {
                "fragments": [],
                "text": "The Use of Classifiers in Sequential Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A Markovian approach is developed that extends standard HMMs to allow the use of a rich observation structure and of general classifiers to model state-observation dependencies and an extension of constraint satisfaction formalisms are extended."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 58
                            }
                        ],
                        "text": "The technique is based on word class models, pioneered by (Brown et al., 1992), which hierarchically"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 59
                            }
                        ],
                        "text": "The technique is based on word class models, pioneered by (Brown et al., 1992), which hierarchically\nclusters words, producing a binary tree as in Figure 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 92
                            }
                        ],
                        "text": "The approach is related, but not identical, to distributional similarity (for details, see (Brown et al., 1992) and (Liang, 2005))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10986188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de5d40b60742e3dfa86b19e7f660962298492af",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."
            },
            "slug": "Class-Based-n-gram-Models-of-Natural-Language-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Class-Based n-gram Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work addresses the problem of predicting a word from previous words in a sample of text and discusses n-gram models based on classes of words, finding that these models are able to extract classes that have the flavor of either syntactically based groupings or semanticallybased groupings, depending on the nature of the underlying statistics."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3213150"
                        ],
                        "name": "E. Loper",
                        "slug": "E.-Loper",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Loper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Loper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 187
                            }
                        ],
                        "text": "Related works include voting between several representation schemes (Shen and Sarkar, 2005), lexicalizing the schemes (Molina and Pla, 2002) and automatically searching for best encoding (Edward, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6139243,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32d41b379b3d6b59ddf00cbc9a7c60ba6f3cf95a",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In Sequential Viterbi Models, such as HMMs, MEMMs, and Linear Chain CRFs, the type of patterns over output sequences that can be learned by the model depend directly on the model\u2019s structure: any pattern that spans more output tags than are covered by the models\u2019 order will be very difficult to learn. However, increasing a model\u2019s order can lead to an increase in the number of model parameters, making the model more susceptible to sparse data problems. This paper shows how the notion of output transformation can be used to explore a variety of alternative model structures. Using output transformations, we can selectively increase the amount of contextual information available for some conditions, but not for others, thus allowing us to capture longer-distance consistencies while avoiding unnecessary increases to the model\u2019s parameter space. The appropriate output transformation for a given task can be selected by applying a hill-climbing approach to heldout data. On the NP Chunking task, our hill-climbing system finds a model structure that outperformsbothfirst-orderand secondorder models with the same input feature set."
            },
            "slug": "Finding-Good-Sequential-Model-Structures-using-Loper",
            "title": {
                "fragments": [],
                "text": "Finding Good Sequential Model Structures using Output Transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper shows how the notion of output transformation can be used to explore a variety of alternative model structures, thus allowing us to capture longer-distance consistencies while avoiding unnecessary increases to the model\u2019s parameter space."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP-CoNLL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701734"
                        ],
                        "name": "X. Carreras",
                        "slug": "X.-Carreras",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Carreras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Carreras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049328"
                        ],
                        "name": "Llu\u00eds M\u00e0rquez i Villodre",
                        "slug": "Llu\u00eds-M\u00e0rquez-i-Villodre",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Villodre",
                            "middleNames": [
                                "M\u00e0rquez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds M\u00e0rquez i Villodre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778523"
                        ],
                        "name": "Llu\u00eds Padr\u00f3",
                        "slug": "Llu\u00eds-Padr\u00f3",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Padr\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds Padr\u00f3"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "Systems based on perceptron have been shown to be competitive in NER and text chunking (Kazama and Torisawa, 2007b; Punyakanok and Roth, 2001; Carreras et al., 2003) We specify the model and the features with the LBJ (Rizzolo and Roth, 2007) modeling language."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 386913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f319a6ca2930a40632b7272c55ec277e8e1ff59e",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for the problem of Named Entity Recognition and Classification (NERC), in the context of the CoNLL-2003 Shared Task."
            },
            "slug": "Learning-a-Perceptron-Based-Named-Entity-Chunker-Carreras-Villodre",
            "title": {
                "fragments": [],
                "text": "Learning a Perceptron-Based Named Entity Chunker via Online Recognition Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel approach for the problem of Named Entity Recognition and Classification (NERC) is presented, in the context of the CoNLL-2003 Shared Task."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3190501"
                        ],
                        "name": "D. Zelenko",
                        "slug": "D.-Zelenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Zelenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zelenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 104
                            }
                        ],
                        "text": "Surprisingly, the greedy policy performs well, this phenmenon was also observed in the POS tagging task (Toutanova et al., 2003; Roth and Zelenko, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1177419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1d3c5653dd4717df19b99709d81b08be44f268a",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an architecture and an on-line learning algorithm and apply it to the problem of part-of-speech tagging. The architecture presented, SNOW, is a network of linear separators in the feature space, utilizing the Winnow update algorithm.Multiplicative weight-update algorithms such as Winnow have been shown to have exceptionally good behavior when applied to very high dimensional problems, and especially when the target concepts depend on only a small subset of the features in the feature space. In this paper we describe an architecture that utilizes this mistake-driven algorithm for multi-class prediction-selecting the part of speech of a word. The experimental analysis presented here provides more evidence to that these algorithms are suitable for natural language problems.The algorithm used is an on-line algorithm: every example is used by the algorithm only once, and is then discarded. This has significance in terms of efficiency, as well as quick adaptation to new contexts.We present an extensive experimental study of our algorithm under various conditions; in particular, it is shown that the algorithm performs comparably to the best known algorithms for POS."
            },
            "slug": "Part-of-Speech-Tagging-Using-a-Network-of-Linear-Roth-Zelenko",
            "title": {
                "fragments": [],
                "text": "Part of Speech Tagging Using a Network of Linear Separators"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "An architecture and an on-line learning algorithm are presented that utilizes this mistake-driven algorithm for multi-class prediction-selecting the part of speech of a word and it is shown that the algorithm performs comparably to the best known algorithms for POS."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707117"
                        ],
                        "name": "Radu Florian",
                        "slug": "Radu-Florian",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Florian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radu Florian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683685"
                        ],
                        "name": "Abraham Ittycheriah",
                        "slug": "Abraham-Ittycheriah",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Ittycheriah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abraham Ittycheriah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40544823"
                        ],
                        "name": "Hongyan Jing",
                        "slug": "Hongyan-Jing",
                        "structuredName": {
                            "firstName": "Hongyan",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongyan Jing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 269
                            }
                        ],
                        "text": "It turns out that while problems of coverage and ambiguity prevent straightforward lookup, injection of gazetteer matches as features in machine-learning based approaches is critical for good performance (Cohen, 2004; Kazama and Torisawa, 2007a; Toral and Munoz, 2006; Florian et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10606201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1ba322f795adbdc706651dbc76ad53b9c5f9468",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden Markov model) are combined under different conditions. When no gazetteer or other additional training resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data."
            },
            "slug": "Named-Entity-Recognition-through-Classifier-Florian-Ittycheriah",
            "title": {
                "fragments": [],
                "text": "Named Entity Recognition through Classifier Combination"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden Markov model) are combined under different conditions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111931"
                        ],
                        "name": "J. Guinness",
                        "slug": "J.-Guinness",
                        "structuredName": {
                            "firstName": "Jethran",
                            "lastName": "Guinness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Guinness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885046"
                        ],
                        "name": "Alex Zamanian",
                        "slug": "Alex-Zamanian",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Zamanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Zamanian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 233
                            }
                        ],
                        "text": "In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al., 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": ", 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15548439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad269ba941949a1d66b6649a71d752784c576dc3",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus. Cluster membership is encoded in features that are incorporated in a discriminatively trained tagging model. Active learning is used to select training examples. We evaluate the technique for named-entity tagging. Compared with a state-of-the-art HMM-based name finder, the presented technique requires only 13% as much annotated data to achieve the same level of performance. Given a large annotated training set of 1,000,000 words, the technique achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material."
            },
            "slug": "Name-Tagging-with-Word-Clusters-and-Discriminative-Miller-Guinness",
            "title": {
                "fragments": [],
                "text": "Name Tagging with Word Clusters and Discriminative Training"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus that achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784228"
                        ],
                        "name": "J. Finkel",
                        "slug": "J.-Finkel",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Finkel",
                            "middleNames": [
                                "Rose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Finkel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050250"
                        ],
                        "name": "Trond Grenager",
                        "slug": "Trond-Grenager",
                        "structuredName": {
                            "firstName": "Trond",
                            "lastName": "Grenager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trond Grenager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 91
                            }
                        ],
                        "text": "The results we obtained on the CoNLL03 test set were consistent with what was reported in (Finkel et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 10977241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f410ab5c8b12b34b38421241366ee456bbebab9",
            "isKey": false,
            "numCitedBy": 3246,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current statistical natural language processing models use only local features so as to permit dynamic programming in inference, but this makes them unable to fully account for the long distance structure that is prevalent in language use. We show how to solve this dilemma with Gibbs sampling, a simple Monte Carlo method used to perform approximate inference in factored probabilistic models. By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference. We use this technique to augment an existing CRF-based information extraction system with long-distance dependency models, enforcing label consistency and extraction template consistency constraints. This technique results in an error reduction of up to 9% over state-of-the-art systems on two established information extraction tasks."
            },
            "slug": "Incorporating-Non-local-Information-into-Extraction-Finkel-Grenager",
            "title": {
                "fragments": [],
                "text": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144494993"
                        ],
                        "name": "R. Jones",
                        "slug": "R.-Jones",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 168
                            }
                        ],
                        "text": "Given these findings, several approaches have been proposed to automatically extract comprehensive gazetteers from the web and from large collections of unlabeled text (Etzioni et al., 2005; Riloff and Jones, 1999) with lim-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1053009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41e936981f5a2d55bfec0143e9a15e23ad96436b",
            "isKey": false,
            "numCitedBy": 890,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction systems usually require two dictionaries: a semantic lexicon and a dictionary of extraction patterns for the domain. We present a multilevel bootstrapping algorithm that generates both the semantic lexicon and extraction patterns simultaneously. As input, our technique requires only unannotated training texts and a handful of seed words for a category. We use a mutual bootstrapping technique to alternately select the best extraction pattern for the category and bootstrap its extractions into the semantic lexicon, which is the basis for selecting the next extraction pattern. To make this approach more robust, we add a second level of bootstrapping (metabootstrapping) that retains only the most reliable lexicon entries produced by mutual bootstrapping and then restarts the process. We evaluated this multilevel bootstrapping technique on a collection of corporate web pages and a corpus of terrorism news articles. The algorithm produced high-quality dictionaries for several semantic categories."
            },
            "slug": "Learning-Dictionaries-for-Information-Extraction-by-Riloff-Jones",
            "title": {
                "fragments": [],
                "text": "Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A multilevel bootstrapping algorithm is presented that generates both the semantic lexicon and extraction patterns simultaneously simultaneously and produces high-quality dictionaries for several semantic categories."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 113
                            }
                        ],
                        "text": "NER is typically viewed as a sequential prediction problem, the typical models include HMM (Rabiner, 1989), CRF (Lafferty et al., 2001), and sequential application of Perceptron or Winnow (Collins, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13410,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 181
                            }
                        ],
                        "text": "NER is typically viewed as a sequential prediction problem, the typical models include HMM (Rabiner, 1989), CRF (Lafferty et al., 2001), and sequential application of Perceptron or Winnow (Collins, 2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 60
                            }
                        ],
                        "text": ", 2001), and sequential application of Perceptron or Winnow (Collins, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10888973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a7958b418bceb48a315384568091ab1898b1640",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe new algorithms for training tagging models, as an alternative to maximum-entropy models or conditional random fields (CRFs). The algorithms rely on Viterbi decoding of training examples, combined with simple additive updates. We describe theory justifying the algorithms through a modification of the proof of convergence of the perceptron algorithm for classification problems. We give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "slug": "Discriminative-Training-Methods-for-Hidden-Markov-Collins",
            "title": {
                "fragments": [],
                "text": "Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results on part-of-speech tagging and base noun phrase chunking are given, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 63
                            }
                        ],
                        "text": "Our baseline NER system uses a regularized averaged perceptron (Freund and Schapire, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5885617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2479a5cf6cefefb83166c612564787414e47131f",
            "isKey": false,
            "numCitedBy": 811,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce and analyze a new algorithm for linear classification which combines Rosenblatt's perceptron algorithm with Helmbold and Warmuth's leave-one-out method. Like Vapnik's maximal-margin classifier, our algorithm takes advantage of data that are linearly separable with large margins. Compared to Vapnik's algorithm, however, ours is much simpler to implement, and much more efficient in terms of computation time. We also show that our algorithm can be efficiently used in very high dimensional spaces using kernel functions. We performed some experiments using our algorithm, and some variants of it, for classifying images of handwritten digits. The performance of our algorithm is close to, but not as good as, the performance of maximal-margin classifiers on the same problem, while saving significantly on computation time and programming effort."
            },
            "slug": "Large-Margin-Classification-Using-the-Perceptron-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "Large Margin Classification Using the Perceptron Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new algorithm for linear classification which combines Rosenblatt's perceptron algorithm with Helmbold and Warmuth's leave-one-out method is introduced, which is much simpler to implement, and much more efficient in terms of computation time."
            },
            "venue": {
                "fragments": [],
                "text": "COLT' 98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399048849"
                        ],
                        "name": "Alexandru Niculescu-Mizil",
                        "slug": "Alexandru-Niculescu-Mizil",
                        "structuredName": {
                            "firstName": "Alexandru",
                            "lastName": "Niculescu-Mizil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandru Niculescu-Mizil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207158152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eae3948747c9d051314c1f5851957b833aa83eca",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine the relationship between the predictions made by different learning algorithms and true posterior probabilities. We show that maximum margin methods such as boosted trees and boosted stumps push probability mass away from 0 and 1 yielding a characteristic sigmoid shaped distortion in the predicted probabilities. Models such as Naive Bayes, which make unrealistic independence assumptions, push probabilities toward 0 and 1. Other models such as neural nets and bagged trees do not have these biases and predict well calibrated probabilities. We experiment with two ways of correcting the biased probabilities predicted by some learning methods: Platt Scaling and Isotonic Regression. We qualitatively examine what kinds of distortions these calibration methods are suitable for and quantitatively examine how much data they need to be effective. The empirical results show that after calibration boosted trees, random forests, and SVMs predict the best probabilities."
            },
            "slug": "Predicting-good-probabilities-with-supervised-Niculescu-Mizil-Caruana",
            "title": {
                "fragments": [],
                "text": "Predicting good probabilities with supervised learning"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The relationship between the predictions made by different learning algorithms and true posterior probabilities is examined, showing that maximum margin methods such as boosted trees and boosted stumps push probability mass away from 0 and 1 yielding a characteristic sigmoid shaped distortion in the predicted probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 91
                            }
                        ],
                        "text": "NER is typically viewed as a sequential prediction problem, the typical models include HMM (Rabiner, 1989), CRF (Lafferty et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "Second, this result reinforces the intuition that global inference over the second-order HMM features does not capture the non-local properties of the task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "NER is typically viewed as a sequential prediction problem, the typical models include HMM (Rabiner, 1989), CRF (Lafferty et al., 2001), and sequential application of Perceptron or Winnow (Collins, 2002)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "(Chieu and Ng, 2003) used features that aggregate, for each document, the context tokens appear in. Sample features are: the longest capitilized sequence of words in the document which contains the current token and the token appears before a company marker such as ltd. elsewhere in text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learn - ing a perceptron - based named entity chunker via on - line recognition feedback"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 80
                            }
                        ],
                        "text": "We implemented the token-majority and the entity-majority features discussed in (Krishnan and Manning, 2006); however, instead of document and corpus majority tags, we used relative frequency of the tags in a 1000 token window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "(Krishnan and Manning, 2006) used the intuition that some instances of a token appear in easily-identifiable contexts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An effective twostage model for exploiting non-local dependencies in named entity recognition"
            },
            "venue": {
                "fragments": [],
                "text": "ACL."
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 165
                            }
                        ],
                        "text": "In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al., 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 164
                            }
                        ],
                        "text": "In this work, we analyze a simple technique of using word clusters generated from unlabeled text, which has been shown to improve performance of dependency parsing (Koo et al., 2008), Chinese word segmentation (Liang, 2005) and NER (Miller et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simple semisupervised dependency parsing"
            },
            "venue": {
                "fragments": [],
                "text": "ACL."
            },
            "year": 2008
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 22,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 35,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Design-Challenges-and-Misconceptions-in-Named-Ratinov-Roth/aa9efc8b2737eac0675ba5abb5feab8305482c12?sort=total-citations"
}