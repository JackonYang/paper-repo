{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271847"
                        ],
                        "name": "Carmen Banea",
                        "slug": "Carmen-Banea",
                        "structuredName": {
                            "firstName": "Carmen",
                            "lastName": "Banea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carmen Banea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748501"
                        ],
                        "name": "Claire Cardie",
                        "slug": "Claire-Cardie",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Cardie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Cardie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46724030"
                        ],
                        "name": "Daniel Matthew Cer",
                        "slug": "Daniel-Matthew-Cer",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cer",
                            "middleNames": [
                                "Matthew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Matthew Cer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403836100"
                        ],
                        "name": "A. Gonzalez-Agirre",
                        "slug": "A.-Gonzalez-Agirre",
                        "structuredName": {
                            "firstName": "Aitor",
                            "lastName": "Gonzalez-Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gonzalez-Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579583"
                        ],
                        "name": "Weiwei Guo",
                        "slug": "Weiwei-Guo",
                        "structuredName": {
                            "firstName": "Weiwei",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiwei Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405529953"
                        ],
                        "name": "I. Lopez-Gazpio",
                        "slug": "I.-Lopez-Gazpio",
                        "structuredName": {
                            "firstName": "I\u00f1igo",
                            "lastName": "Lopez-Gazpio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Lopez-Gazpio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156201"
                        ],
                        "name": "M. Maritxalar",
                        "slug": "M.-Maritxalar",
                        "structuredName": {
                            "firstName": "Montse",
                            "lastName": "Maritxalar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maritxalar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785173"
                        ],
                        "name": "German Rigau",
                        "slug": "German-Rigau",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Rigau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "German Rigau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2962373"
                        ],
                        "name": "L. Uria",
                        "slug": "L.-Uria",
                        "structuredName": {
                            "firstName": "Larraitz",
                            "lastName": "Uria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Uria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 178
                            }
                        ],
                        "text": "To encourage and support research in this area, the STS shared task has been held annually since 2012, providing a venue for evaluation of state-ofthe-art algorithms and models (Agirre et al., 2012, 2013, 2014, 2015, 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11879061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6346f4fb03a25ff3a4bd887ba45d627a01983ea4",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In semantic textual similarity (STS), systems rate the degree of semantic equivalence between two text snippets. This year, the participants were challenged with new datasets in English and Spanish. The annotations for both subtasks leveraged crowdsourcing. The English subtask attracted 29 teams with 74 system runs, and the Spanish subtask engaged 7 teams participating with 16 system runs. In addition, this year we ran a pilot task on interpretable STS, where the systems needed to add an explanatory layer, that is, they had to align the chunks in the sentence pair, explicitly annotating the kind of relation and the score of the chunk pair. The train and test data were manually annotated by an expert, and included headline and image sentence pairs from previous years. 7 teams participated with 29 runs."
            },
            "slug": "SemEval-2015-Task-2:-Semantic-Textual-Similarity,-Agirre-Banea",
            "title": {
                "fragments": [],
                "text": "SemEval-2015 Task 2: Semantic Textual Similarity, English, Spanish and Pilot on Interpretability"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This year, the participants were challenged with new datasets in English and Spanish, and the annotations for both subtasks leveraged crowdsourcing, and a pilot task on interpretable STS, where systems needed to add an explanatory layer."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@NAACL-HLT"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870229"
                        ],
                        "name": "Nabin Maharjan",
                        "slug": "Nabin-Maharjan",
                        "structuredName": {
                            "firstName": "Nabin",
                            "lastName": "Maharjan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nabin Maharjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3341606"
                        ],
                        "name": "Rajendra Banjade",
                        "slug": "Rajendra-Banjade",
                        "structuredName": {
                            "firstName": "Rajendra",
                            "lastName": "Banjade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajendra Banjade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2165624"
                        ],
                        "name": "D. Gautam",
                        "slug": "D.-Gautam",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Gautam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gautam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37229526"
                        ],
                        "name": "L. Tamang",
                        "slug": "L.-Tamang",
                        "structuredName": {
                            "firstName": "Lasang",
                            "lastName": "Tamang",
                            "middleNames": [
                                "Jimba"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tamang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145154896"
                        ],
                        "name": "V. Rus",
                        "slug": "V.-Rus",
                        "structuredName": {
                            "firstName": "Vasile",
                            "lastName": "Rus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Rus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 26
                            }
                        ],
                        "text": "2 and skip-thought models (Maharjan et al., 2017) UdL Feature eng."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component\n18RTV took first place on track 5, English, but submitted no system description paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 8
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 9
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "LIM-LIG and DT Team only participate in monolingual tracks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "RTV has the best system for the track 5 English data (r: 0.8547), followed closely by DT Team (r: 0.8536)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23591179,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e670edfe52bafd239cec9ec2144db9695ac7a056",
            "isKey": true,
            "numCitedBy": 14,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our system (DT Team) submitted at SemEval-2017 Task 1, Semantic Textual Similarity (STS) challenge for English (Track 5). We developed three different models with various features including similarity scores calculated using word and chunk alignments, word/sentence embeddings, and Gaussian Mixture Model(GMM). The correlation between our system\u2019s output and the human judgments were up to 0.8536, which is more than 10% above baseline, and almost as good as the best performing system which was at 0.8547 correlation (the difference is just about 0.1%). Also, our system produced leading results when evaluated with a separate STS benchmark dataset. The word alignment and sentence embeddings based features were found to be very effective."
            },
            "slug": "DT_Team-at-SemEval-2017-Task-1:-Semantic-Similarity-Maharjan-Banjade",
            "title": {
                "fragments": [],
                "text": "DT_Team at SemEval-2017 Task 1: Semantic Similarity Using Alignments, Sentence-Level Embeddings and Gaussian Mixture Model Output"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This system developed three different models with various features including similarity scores calculated using word and chunk alignments, word/sentence embeddings, and Gaussian Mixture Model which were found to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144210181"
                        ],
                        "name": "Basma Hassan",
                        "slug": "Basma-Hassan",
                        "structuredName": {
                            "firstName": "Basma",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Basma Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144227123"
                        ],
                        "name": "S. Abdelrahman",
                        "slug": "S.-Abdelrahman",
                        "structuredName": {
                            "firstName": "Samir",
                            "lastName": "Abdelrahman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abdelrahman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917451"
                        ],
                        "name": "R. Bahgat",
                        "slug": "R.-Bahgat",
                        "structuredName": {
                            "firstName": "Reem",
                            "lastName": "Bahgat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bahgat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144601531"
                        ],
                        "name": "Ibrahim Farag",
                        "slug": "Ibrahim-Farag",
                        "structuredName": {
                            "firstName": "Ibrahim",
                            "lastName": "Farag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ibrahim Farag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 7
                            }
                        ],
                        "text": "FCICU (Hassan et al., 2017) Fifth place overall is FCICU that computes a sense-base alignment using BabelNet (Navigli and Ponzetto, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36718281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de79088f43f3a8cf0b0ba9c4d64f20b82fd553c",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes FCICU team systems that participated in SemEval-2017 Semantic Textual Similarity task (Task1) for monolingual and cross-lingual sentence pairs. A sense-based language independent textual similarity approach is presented, in which a proposed alignment similarity method coupled with new usage of a semantic network (BabelNet) is used. Additionally, a previously proposed integration between sense-based and sur-face-based semantic textual similarity approach is applied together with our proposed approach. For all the tracks in Task1, Run1 is a string kernel with alignments metric and Run2 is a sense-based alignment similarity method. The first run is ranked 10th, and the second is ranked 12th in the primary track, with correlation 0.619 and 0.617 respectively"
            },
            "slug": "FCICU-at-SemEval-2017-Task-1:-Sense-Based-Language-Hassan-Abdelrahman",
            "title": {
                "fragments": [],
                "text": "FCICU at SemEval-2017 Task 1: Sense-Based Language Independent Semantic Textual Similarity Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A sense-based language independent textual similarity approach is presented, in which a proposed alignment similarity method coupled with new usage of a semantic network (BabelNet) is used."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271847"
                        ],
                        "name": "Carmen Banea",
                        "slug": "Carmen-Banea",
                        "structuredName": {
                            "firstName": "Carmen",
                            "lastName": "Banea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carmen Banea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748501"
                        ],
                        "name": "Claire Cardie",
                        "slug": "Claire-Cardie",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Cardie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Cardie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46724030"
                        ],
                        "name": "Daniel Matthew Cer",
                        "slug": "Daniel-Matthew-Cer",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cer",
                            "middleNames": [
                                "Matthew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Matthew Cer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403836100"
                        ],
                        "name": "A. Gonzalez-Agirre",
                        "slug": "A.-Gonzalez-Agirre",
                        "structuredName": {
                            "firstName": "Aitor",
                            "lastName": "Gonzalez-Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gonzalez-Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579583"
                        ],
                        "name": "Weiwei Guo",
                        "slug": "Weiwei-Guo",
                        "structuredName": {
                            "firstName": "Weiwei",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiwei Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785173"
                        ],
                        "name": "German Rigau",
                        "slug": "German-Rigau",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Rigau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "German Rigau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 178
                            }
                        ],
                        "text": "To encourage and support research in this area, the STS shared task has been held annually since 2012, providing a venue for evaluation of state-ofthe-art algorithms and models (Agirre et al., 2012, 2013, 2014, 2015, 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11650107,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16084914bc3729f86f46ac6267ea7a42e7951d41",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In Semantic Textual Similarity, systems rate the degree of semantic equivalence between two text snippets. This year, the participants were challenged with new data sets for English, as well as the introduction of Spanish, as a new language in which to assess semantic similarity. For the English subtask, we exposed the systems to a diversity of testing scenarios, by preparing additional OntoNotesWordNet sense mappings and news headlines, as well as introducing new genres, including image descriptions, DEFT discussion forums, DEFT newswire, and tweet-newswire headline mappings. For Spanish, since, to our knowledge, this is the first time that official evaluations are conducted, we used well-formed text, by featuring sentences extracted from encyclopedic content and newswire. The annotations for both tasks leveraged crowdsourcing. The Spanish subtask engaged 9 teams participating with 22 system runs, and the English subtask attracted 15 teams with 38 system runs."
            },
            "slug": "SemEval-2014-Task-10:-Multilingual-Semantic-Textual-Agirre-Banea",
            "title": {
                "fragments": [],
                "text": "SemEval-2014 Task 10: Multilingual Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This year, the participants were challenged with new data sets for English, as well as the introduction of Spanish, as a new language in which to assess semantic similarity, and the annotations for both tasks leveraged crowdsourcing."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3336895"
                        ],
                        "name": "Johannes Bjerva",
                        "slug": "Johannes-Bjerva",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Bjerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johannes Bjerva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141689"
                        ],
                        "name": "Robert \u00d6stling",
                        "slug": "Robert-\u00d6stling",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "\u00d6stling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert \u00d6stling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "55 ResSim (Bjerva and \u00d6stling, 2017) 31."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11047443,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "9249580ef014d9d433d8d0d2617e36ed52e3bba6",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Shared Task 1 at SemEval-2017 deals with assessing the semantic similarity between sentences, either in the same or in different languages. In our system submission, we employ multilingual word representations, in which similar words in different languages are close to one another. Using such representations is advantageous, since the increasing amount of available parallel data allows for the application of such methods to many of the languages in the world. Hence, semantic similarity can be inferred even for languages for which no annotated data exists. Our system is trained and evaluated on all language pairs included in the shared task (English, Spanish, Arabic, and Turkish). Although development results are promising, our system does not yield high performance on the shared task test sets."
            },
            "slug": "ResSim-at-SemEval-2017-Task-1:-Multilingual-Word-Bjerva-\u00d6stling",
            "title": {
                "fragments": [],
                "text": "ResSim at SemEval-2017 Task 1: Multilingual Word Representations for Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This system submission employs multilingual word representations, in which similar words in different languages are close to one another, so semantic similarity can be inferred even for languages for which no annotated data exists."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46724030"
                        ],
                        "name": "Daniel Matthew Cer",
                        "slug": "Daniel-Matthew-Cer",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cer",
                            "middleNames": [
                                "Matthew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Matthew Cer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403836100"
                        ],
                        "name": "A. Gonzalez-Agirre",
                        "slug": "A.-Gonzalez-Agirre",
                        "structuredName": {
                            "firstName": "Aitor",
                            "lastName": "Gonzalez-Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gonzalez-Agirre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 178
                            }
                        ],
                        "text": "To encourage and support research in this area, the STS shared task has been held annually since 2012, providing a venue for evaluation of state-ofthe-art algorithms and models (Agirre et al., 2012, 2013, 2014, 2015, 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12549805,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "528fa9bb03644ba752fb9491be49b9dd1bce1d52",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two texts. This paper presents the results of the STS pilot task in Semeval. The training data contained 2000 sentence pairs from previously existing paraphrase datasets and machine translation evaluation resources. The test data also comprised 2000 sentences pairs for those datasets, plus two surprise datasets with 400 pairs from a different machine translation evaluation corpus and 750 pairs from a lexical resource mapping exercise. The similarity of pairs of sentences was rated on a 0-5 scale (low to high similarity) by human judges using Amazon Mechanical Turk, with high Pearson correlation scores, around 90%. 35 teams participated in the task, submitting 88 runs. The best results scored a Pearson correlation >80%, well above a simple lexical baseline that only scored a 31% correlation. This pilot task opens an exciting way ahead, although there are still open issues, specially the evaluation metric."
            },
            "slug": "SemEval-2012-Task-6:-A-Pilot-on-Semantic-Textual-Agirre-Cer",
            "title": {
                "fragments": [],
                "text": "SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results of the STS pilot task in Semeval open an exciting way ahead, although there are still open issues, specially the evaluation metric."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2905473"
                        ],
                        "name": "S. Kohail",
                        "slug": "S.-Kohail",
                        "structuredName": {
                            "firstName": "Sarah",
                            "lastName": "Kohail",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kohail"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49643268"
                        ],
                        "name": "A. R. Salama",
                        "slug": "A.-R.-Salama",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Salama",
                            "middleNames": [
                                "Rekaby"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. R. Salama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31565315"
                        ],
                        "name": "Chris Biemann",
                        "slug": "Chris-Biemann",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Biemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Biemann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "90 STS-UHH (Kohail et al., 2017) 60."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30228404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0151e59c3470f2210c878bdee5e45eef7ca5ed52",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the STS-UHH participation in the SemEval 2017 shared Task 1 of Semantic Textual Similarity (STS). Overall, we submitted 3 runs covering monolingual and cross-lingual STS tracks. Our participation involves two approaches: unsupervised approach, which estimates a word alignment-based similarity score, and supervised approach, which combines dependency graph similarity and coverage features with lexical similarity measures using regression methods. We also present a way on ensembling both models. Out of 84 submitted runs, our team best multi-lingual run has been ranked 12th in overall performance with correlation of 0.61, 7th among 31 participating teams."
            },
            "slug": "STS-UHH-at-SemEval-2017-Task-1:-Scoring-Semantic-Kohail-Salama",
            "title": {
                "fragments": [],
                "text": "STS-UHH at SemEval-2017 Task 1: Scoring Semantic Textual Similarity Using Supervised and Unsupervised Ensemble"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The STS-UHH participation in the SemEval 2017 shared Task 1 of Semantic Textual Similarity (STS) involves two approaches: unsupervised approach, which estimates a word alignment-based similarity score, and supervised approach which combines dependency graph similarity and coverage features with lexical similarity measures using regression methods."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30424564"
                        ],
                        "name": "W. Xu",
                        "slug": "W.-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 208
                            }
                        ],
                        "text": "Semantic inference tasks related to\nSTS include textual entailment (Bentivogli et al., 2016; Bowman et al., 2015; Dagan et al., 2010), semantic relatedness (Bentivogli et al., 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15213264,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "c75cdf042e42dae19399d393b5f3d24c10054a10",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "In this shared task, we present evaluations on two related tasks Paraphrase Identification (PI) and Semantic Textual Similarity (SS) systems for the Twitter data. Given a pair of sentences, participants are asked to produce a binary yes/no judgement or a graded score to measure their semantic equivalence. The task features a newly constructed Twitter Paraphrase Corpus that contains 18,762 sentence pairs. A total of 19 teams participated, submitting 36 runs to the PI task and 26 runs to the SS task. The evaluation shows encouraging results and open challenges for future research. The best systems scored a F1-measure of 0.674 for the PI task and a Pearson correlation of 0.619 for the SS task respectively, comparing to a strong baseline using logistic regression model of 0.589 F1 and 0.511 Pearson; while the best SS systems can often reach >0.80 Pearson on well-formed text. This shared task also provides insights into the relation between the PI and SS tasks and suggests the importance to bringing these two research areas together. We make all the data, baseline systems and evaluation scripts publicly available. 1"
            },
            "slug": "SemEval-2015-Task-1:-Paraphrase-and-Semantic-in-Xu-Callison-Burch",
            "title": {
                "fragments": [],
                "text": "SemEval-2015 Task 1: Paraphrase and Semantic Similarity in Twitter (PIT)"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "In this shared task, evaluations on two related tasks Paraphrase Identification and Semantic Textual Similarity (SS) systems for the Twitter data are presented and the importance to bringing these two research areas together is suggested."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145035103"
                        ],
                        "name": "John C. Henderson",
                        "slug": "John-C.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3466990"
                        ],
                        "name": "Elizabeth M. Merkhofer",
                        "slug": "Elizabeth-M.-Merkhofer",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Merkhofer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth M. Merkhofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3465337"
                        ],
                        "name": "Laura Strickhart",
                        "slug": "Laura-Strickhart",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Strickhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura Strickhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983465"
                        ],
                        "name": "Guido Zarrella",
                        "slug": "Guido-Zarrella",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Zarrella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guido Zarrella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 7
                            }
                        ],
                        "text": "MITRE (Henderson et al., 2017) Fourth place overall is MITRE that, like ECNU, takes an ambitious feature engineering approach complemented by deep learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 6
                            }
                        ],
                        "text": "MITRE (Henderson et al., 2017) Fourth place overall is MITRE that, like ECNU, took an ambitious feature engineering approach with some of the features based on deep learning models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 116
                            }
                        ],
                        "text": "15Within the highlighted submissions, the following use a monolingual English system fed by MT: ECNU, BIT, HCTI and MITRE."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11647185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8768bd378efa339bb420da8d328b523c3e13f859",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes MITRE\u2019s participation in the Semantic Textual Similarity task (SemEval-2017 Task 1), which evaluated machine learning approaches to the identification of similar meaning among text snippets in English, Arabic, Spanish, and Turkish. We detail the techniques we explored ranging from simple bag-of-ngrams classifiers to neural architectures with varied attention and alignment mechanisms. Linear regression is used to tie the systems together into an ensemble submitted for evaluation. The resulting system is capable of matching human similarity ratings of image captions with correlations of 0.73 to 0.83 in monolingual settings and 0.68 to 0.78 in cross-lingual conditions, demonstrating the power of relatively simple approaches."
            },
            "slug": "MITRE-at-SemEval-2017-Task-1:-Simple-Semantic-Henderson-Merkhofer",
            "title": {
                "fragments": [],
                "text": "MITRE at SemEval-2017 Task 1: Simple Semantic Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper describes MITRE\u2019s participation in the Semantic Textual Similarity task (SemEval-2017 Task 1), which evaluated machine learning approaches to the identification of similar meaning among text snippets in English, Arabic, Spanish, and Turkish."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1930815"
                        ],
                        "name": "I-Ta Lee",
                        "slug": "I-Ta-Lee",
                        "structuredName": {
                            "firstName": "I-Ta",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I-Ta Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22176776"
                        ],
                        "name": "Mahak Goindani",
                        "slug": "Mahak-Goindani",
                        "structuredName": {
                            "firstName": "Mahak",
                            "lastName": "Goindani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mahak Goindani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144656120"
                        ],
                        "name": "Chang Li",
                        "slug": "Chang-Li",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068347799"
                        ],
                        "name": "Di Jin",
                        "slug": "Di-Jin",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Di Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49808204"
                        ],
                        "name": "Kristen Marie Johnson",
                        "slug": "Kristen-Marie-Johnson",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Marie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristen Marie Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115477582"
                        ],
                        "name": "Xiao Zhang",
                        "slug": "Xiao-Zhang",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32727925"
                        ],
                        "name": "Maria Leonor Pacheco",
                        "slug": "Maria-Leonor-Pacheco",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Pacheco",
                            "middleNames": [
                                "Leonor"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maria Leonor Pacheco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2877164"
                        ],
                        "name": "Dan Goldwasser",
                        "slug": "Dan-Goldwasser",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Goldwasser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Goldwasser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "96 PurdueNLP (Lee et al., 2017) 79."
                    },
                    "intents": []
                }
            ],
            "corpusId": 258621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "229d7dc4514603ad0ffb6bcb64df8f2f49c487e8",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes our proposed solution for SemEval 2017 Task 1: Semantic Textual Similarity (Daniel Cer and Specia, 2017). The task aims at measuring the degree of equivalence between sentences given in English. Performance is evaluated by computing Pearson Correlation scores between the predicted scores and human judgements. Our proposed system consists of two subsystems and one regression model for predicting STS scores. The two subsystems are designed to learn Paraphrase and Event Embeddings that can take the consideration of paraphrasing characteristics and sentence structures into our system. The regression model associates these embeddings to make the final predictions. The experimental result shows that our system acquires 0.8 of Pearson Correlation Scores in this task."
            },
            "slug": "PurdueNLP-at-SemEval-2017-Task-1:-Predicting-with-Lee-Goindani",
            "title": {
                "fragments": [],
                "text": "PurdueNLP at SemEval-2017 Task 1: Predicting Semantic Textual Similarity with Paraphrase and Event Embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The proposed system consists of two subsystems and one regression model for predicting STS scores, designed to learn Paraphrase and Event Embeddings that can take the consideration of paraphrasing characteristics and sentence structures into the system."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5704461"
                        ],
                        "name": "J. Ferrero",
                        "slug": "J.-Ferrero",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00e9my",
                            "lastName": "Ferrero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ferrero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823463"
                        ],
                        "name": "L. Besacier",
                        "slug": "L.-Besacier",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Besacier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Besacier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2504683"
                        ],
                        "name": "D. Schwab",
                        "slug": "D.-Schwab",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Schwab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Schwab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37903642"
                        ],
                        "name": "Fr\u00e9d\u00e9ric Agn\u00e8s",
                        "slug": "Fr\u00e9d\u00e9ric-Agn\u00e8s",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Agn\u00e8s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fr\u00e9d\u00e9ric Agn\u00e8s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 9
                            }
                        ],
                        "text": "CompiLIG (Ferrero et al., 2017) The best Spanish-English performance on SNLI sentences was achieved by CompiLIG using the following cross-lingual features: conceptual similarity using"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 10
                            }
                        ],
                        "text": "CompiLIG (Ferrero et al., 2017) The best Spanish-English performance on SNLI sentences was achieved by CompiLIG using the following cross-lingual features: conceptual similarity using DBNary (Serasset, 2015), MultiVec word embeddings (Berard et al., 2016) and character n-grams."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14076822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa332aefba9048515f99c28d93720fc43a4fea3c",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present our submitted systems for Semantic Textual Similarity (STS) Track 4 at SemEval-2017. Given a pair of Spanish-English sentences, each system must estimate their semantic similarity by a score between 0 and 5. In our submission, we use syntax-based, dictionary-based, context-based, and MT-based methods. We also combine these methods in unsupervised and supervised way. Our best run ranked 1st on track 4a with a correlation of 83.02% with human annotations."
            },
            "slug": "CompiLIG-at-SemEval-2017-Task-1:-Cross-Language-for-Ferrero-Besacier",
            "title": {
                "fragments": [],
                "text": "CompiLIG at SemEval-2017 Task 1: Cross-Language Plagiarism Detection Methods for Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The submitted systems for Semantic Textual Similarity Track 4 are used to estimate a pair of Spanish-English sentences and their semantic similarity by using syntax- based, dictionary-based, context-Based, and MT-based methods."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2029351458"
                        ],
                        "name": "Fanqing Meng",
                        "slug": "Fanqing-Meng",
                        "structuredName": {
                            "firstName": "Fanqing",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fanqing Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2918103"
                        ],
                        "name": "Wenpeng Lu",
                        "slug": "Wenpeng-Lu",
                        "structuredName": {
                            "firstName": "Wenpeng",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenpeng Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13584916"
                        ],
                        "name": "Yuteng Zhang",
                        "slug": "Yuteng-Zhang",
                        "structuredName": {
                            "firstName": "Yuteng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuteng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678189"
                        ],
                        "name": "Jinyong Cheng",
                        "slug": "Jinyong-Cheng",
                        "structuredName": {
                            "firstName": "Jinyong",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinyong Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111745291"
                        ],
                        "name": "Yuehan Du",
                        "slug": "Yuehan-Du",
                        "structuredName": {
                            "firstName": "Yuehan",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuehan Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109751124"
                        ],
                        "name": "Shuwang Han",
                        "slug": "Shuwang-Han",
                        "structuredName": {
                            "firstName": "Shuwang",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuwang Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8120559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d202e237884f8068915f8e533ae0f5cb97380fe",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the details of our submissions in the task 1 of SemEval 2017. This task aims at assessing the semantic textual similarity of two sentences or texts. We submit three unsupervised systems based on word embeddings. The differences between these runs are the various preprocessing on evaluation data. The best performance of these systems on the evaluation of Pearson correlation is 0.6887. Unsurprisingly, results of our runs demonstrate that data preprocessing, such as tokenization, lemmatization, extraction of content words and removing stop words, is helpful and plays a significant role in improving the performance of models."
            },
            "slug": "QLUT-at-SemEval-2017-Task-1:-Semantic-Textual-Based-Meng-Lu",
            "title": {
                "fragments": [],
                "text": "QLUT at SemEval-2017 Task 1: Semantic Textual Similarity Based on Word Embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results of these runs demonstrate that data preprocessing, such as tokenization, lemmatization, extraction of content words and removing stop words, is helpful and plays a significant role in improving the performance of models."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403976844"
                        ],
                        "name": "Hussein T. Al-Natsheh",
                        "slug": "Hussein-T.-Al-Natsheh",
                        "structuredName": {
                            "firstName": "Hussein",
                            "lastName": "Al-Natsheh",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hussein T. Al-Natsheh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14610639"
                        ],
                        "name": "Lucie Martinet",
                        "slug": "Lucie-Martinet",
                        "structuredName": {
                            "firstName": "Lucie",
                            "lastName": "Martinet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucie Martinet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160416"
                        ],
                        "name": "Fabrice Muhlenbach",
                        "slug": "Fabrice-Muhlenbach",
                        "structuredName": {
                            "firstName": "Fabrice",
                            "lastName": "Muhlenbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabrice Muhlenbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678550"
                        ],
                        "name": "D. Zighed",
                        "slug": "D.-Zighed",
                        "structuredName": {
                            "firstName": "Djamel",
                            "lastName": "Zighed",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zighed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 41
                            }
                        ],
                        "text": "cosine over PoS and NER based alignments (Al-Natsheh et al., 2017) HCTI Deep learning model with sent."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1222366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ef902f3c427d697f3579cd79844b44de99bc93c",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the model UdL we proposed to solve the semantic textual similarity task of SemEval 2017 workshop. The track we participated in was estimating the semantics relatedness of a given set of sentence pairs in English. The best run out of three submitted runs of our model achieved a Pearson correlation score of 0.8004 compared to a hidden human annotation of 250 pairs. We used random forest ensemble learning to map an expandable set of extracted pairwise features into a semantic similarity estimated value bounded between 0 and 5. Most of these features were calculated using word embedding vectors similarity to align Part of Speech (PoS) and Name Entities (NE) tagged tokens of each sentence pair. Among other pairwise features, we experimented a classical tf-idf weighted Bag of Words (BoW) vector model but with character-based range of n-grams instead of words. This sentence vector BoW-based feature gave a relatively high importance value percentage in the feature importances analysis of the ensemble learning."
            },
            "slug": "UdL-at-SemEval-2017-Task-1:-Semantic-Textual-of-Al-Natsheh-Martinet",
            "title": {
                "fragments": [],
                "text": "UdL at SemEval-2017 Task 1: Semantic Textual Similarity Estimation of English Sentence Pairs Using Regression Model over Pairwise Features"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The model UdL, proposed to solve the semantic textual similarity task of SemEval 2017 workshop, used random forest ensemble learning to map an expandable set of extracted pairwise features into a semantic similarity estimated value bounded between 0 and 5."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2401976"
                        ],
                        "name": "Wenjie Liu",
                        "slug": "Wenjie-Liu",
                        "structuredName": {
                            "firstName": "Wenjie",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenjie Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913207"
                        ],
                        "name": "Chengjie Sun",
                        "slug": "Chengjie-Sun",
                        "structuredName": {
                            "firstName": "Chengjie",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengjie Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40129683"
                        ],
                        "name": "Lei Lin",
                        "slug": "Lei-Lin",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144174277"
                        ],
                        "name": "Bingquan Liu",
                        "slug": "Bingquan-Liu",
                        "structuredName": {
                            "firstName": "Bingquan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bingquan Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "17 ITNLPAiKF (Liu et al., 2017) 82."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3261600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98d7d8fa5835ea1f214b49a4c1a22ed88d7922d1",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic Textual Similarity (STS) devotes to measuring the degree of equivalence in the underlying semantic of the sentence pair. We proposed a new system, ITNLP-AiKF, which applies in the SemEval 2017 Task1 Semantic Textual Similarity track 5 English monolingual pairs. In our system, rich features are involved, including Ontology based, word embedding based, Corpus based, Alignment based and Literal based feature. We leveraged the features to predict sentence pair similarity by a Support Vector Regression (SVR) model. In the result, a Pearson Correlation of 0.8231 is achieved by our system, which is a competitive result in the contest of this track."
            },
            "slug": "ITNLP-AiKF-at-SemEval-2017-Task-1:-Rich-Features-Liu-Sun",
            "title": {
                "fragments": [],
                "text": "ITNLP-AiKF at SemEval-2017 Task 1: Rich Features Based SVR for Semantic Textual Similarity Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new system, ITNLP-AiKF, is proposed, which applies in the SemEval 2017 Task1 Semantic Textual Similarity track 5 English monolingual pairs, and achieves a competitive result in the contest of this track."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2819966"
                        ],
                        "name": "Pedro Fialho",
                        "slug": "Pedro-Fialho",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Fialho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro Fialho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145150568"
                        ],
                        "name": "Hugo Rodrigues",
                        "slug": "Hugo-Rodrigues",
                        "structuredName": {
                            "firstName": "Hugo",
                            "lastName": "Rodrigues",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hugo Rodrigues"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771718"
                        ],
                        "name": "Lu\u00edsa Coheur",
                        "slug": "Lu\u00edsa-Coheur",
                        "structuredName": {
                            "firstName": "Lu\u00edsa",
                            "lastName": "Coheur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lu\u00edsa Coheur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792648"
                        ],
                        "name": "P. Quaresma",
                        "slug": "P.-Quaresma",
                        "structuredName": {
                            "firstName": "Paulo",
                            "lastName": "Quaresma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Quaresma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "59 L2F/INESC-ID (Fialho et al., 2017)* 76."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23316954,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "6a9c0bf49d4af58b5c1194a739e3443105e05a9b",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes our approach to the SemEval-2017 \u201cSemantic Textual Similarity\u201d and \u201cMultilingual Word Similarity\u201d tasks. In the former, we test our approach in both English and Spanish, and use a linguistically-rich set of features. These move from lexical to semantic features. In particular, we try to take advantage of the recent Abstract Meaning Representation and SMATCH measure. Although without state of the art results, we introduce semantic structures in textual similarity and analyze their impact. Regarding word similarity, we target the English language and combine WordNet information with Word Embeddings. Without matching the best systems, our approach proved to be simple and effective."
            },
            "slug": "L2F/INESC-ID-at-SemEval-2017-Tasks-1-and-2:-Lexical-Fialho-Rodrigues",
            "title": {
                "fragments": [],
                "text": "L2F/INESC-ID at SemEval-2017 Tasks 1 and 2: Lexical and semantic features in word and textual similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper describes the approach to the SemEval-2017 \u201cSemantic Textual Similarity\" and \u201cMultilingual Word Similarity\u201d tasks, and uses a linguistically-rich set of features to take advantage of the recent Abstract Meaning Representation and SMATCH measure."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31965079"
                        ],
                        "name": "M. Duma",
                        "slug": "M.-Duma",
                        "structuredName": {
                            "firstName": "Mirela-Stefania",
                            "lastName": "Duma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Duma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153502408"
                        ],
                        "name": "W. Menzel",
                        "slug": "W.-Menzel",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Menzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Menzel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 8
                            }
                        ],
                        "text": "SEF@UHH (Duma and Menzel, 2017) First place on the challenging Spanish-English MT pairs (Track 4b) is SEF@UHH."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24127328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "794f2ab9d4bf5f37ad68029b5cb478ae4a0c9c50",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes our unsupervised knowledge-free approach to the SemEval-2017 Task 1 Competition. The proposed method makes use of Paragraph Vector for assessing the semantic similarity between pairs of sentences. We experimented with various dimensions of the vector and three state-of-the-art similarity metrics. Given a cross-lingual task, we trained models corresponding to its two languages and combined the models by averaging the similarity scores. The results of our submitted runs are above the median scores for five out of seven test sets by means of Pearson Correlation. Moreover, one of our system runs performed best on the Spanish-English-WMT test set ranking first out of 53 runs submitted in total by all participants."
            },
            "slug": "SEF@UHH-at-SemEval-2017-Task-1:-Unsupervised-via-Duma-Menzel",
            "title": {
                "fragments": [],
                "text": "SEF@UHH at SemEval-2017 Task 1: Unsupervised Knowledge-Free Semantic Textual Similarity via Paragraph Vector"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This paper describes the unsupervised knowledge-free approach to the SemEval-2017 Task 1 Competition, which makes use of Paragraph Vector for assessing the semantic similarity between pairs of sentences."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119797274"
                        ],
                        "name": "Hao Wu",
                        "slug": "Hao-Wu",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4590286"
                        ],
                        "name": "Heyan Huang",
                        "slug": "Heyan-Huang",
                        "structuredName": {
                            "firstName": "Heyan",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heyan Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46302667"
                        ],
                        "name": "Ping Jian",
                        "slug": "Ping-Jian",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Jian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Jian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151864"
                        ],
                        "name": "Yuhang Guo",
                        "slug": "Yuhang-Guo",
                        "structuredName": {
                            "firstName": "Yuhang",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhang Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144733661"
                        ],
                        "name": "Chao Su",
                        "slug": "Chao-Su",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chao Su"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "BIT attains the best performance on track 1, Arabic (r: 0.7543)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "20ECNU, BIT and LIM-LIG are scaled to the range 0-5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "15Within the highlighted submissions, the following use a monolingual English system fed by MT: ECNU, BIT, HCTI and MITRE."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "BIT (Wu et al., 2017) Second place overall is achieved by BIT primarily using sentence informa-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 26
                            }
                        ],
                        "text": "with IDF weighting scheme (Wu et al., 2017) DT TEAM Ensembles feature eng."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 101
                            }
                        ],
                        "text": "The ensemble averages scores from the four deep learning and three feature engineered models.16\nBIT (Wu et al., 2017) Second place overall is achieved by BIT primarily using sentence information content (IC) informed by WordNet and BNC word frequencies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36266172,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a915edfec84da786d270c162a4155ecf1a9f94a",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents three systems for semantic textual similarity (STS) evaluation at SemEval-2017 STS task. One is an unsupervised system and the other two are supervised systems which simply employ the unsupervised one. All our systems mainly depend on the (SIS), which is constructed based on the semantic hierarchical taxonomy in WordNet, to compute non-overlapping information content (IC) of sentences. Our team ranked 2nd among 31 participating teams by the primary score of Pearson correlation coefficient (PCC) mean of 7 tracks and achieved the best performance on Track 1 (AR-AR) dataset."
            },
            "slug": "BIT-at-SemEval-2017-Task-1:-Using-Semantic-Space-to-Wu-Huang",
            "title": {
                "fragments": [],
                "text": "BIT at SemEval-2017 Task 1: Using Semantic Information Space to Evaluate Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper presents three systems for semantic textual similarity (STS) evaluation at SemEval-2017 STS task, which mainly depend on the (SIS), which is constructed based on the semantic hierarchical taxonomy in WordNet, to compute non-overlapping information content (IC) of sentences."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40080808"
                        ],
                        "name": "Joe Barrow",
                        "slug": "Joe-Barrow",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Barrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joe Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21317593"
                        ],
                        "name": "Denis Peskov",
                        "slug": "Denis-Peskov",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Peskov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Peskov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 8
                            }
                        ],
                        "text": "UMDeep (Barrow and Peskov, 2017) took a similar approach using LSTMs rather than CNNs for the sentence embeddings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19570708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c007fcb3958d371c0869dee329cc6c08332e92d7",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a modified shared-LSTM network for the Semantic Textual Similarity (STS) task at SemEval-2017. The network builds on previously explored Siamese network architectures. We treat max sentence length as an additional hyperparameter to be tuned (beyond learning rate, regularization, and dropout). Our results demonstrate that hand-tuning max sentence training length significantly improves final accuracy. After optimizing hyperparameters, we train the network on the multilingual semantic similarity task using pre-translated sentences. We achieved a correlation of 0.4792 for all the subtasks. We achieved the fourth highest team correlation for Task 4b, which was our best relative placement."
            },
            "slug": "UMDeep-at-SemEval-2017-Task-1:-End-to-End-Shared-Barrow-Peskov",
            "title": {
                "fragments": [],
                "text": "UMDeep at SemEval-2017 Task 1: End-to-End Shared Weight LSTM Model for Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work describes a modified shared-LSTM network for the Semantic Textual Similarity (STS) task at SemEval-2017 and demonstrates that hand-tuning max sentence training length significantly improves final accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22616531"
                        ],
                        "name": "Martyna Spiewak",
                        "slug": "Martyna-Spiewak",
                        "structuredName": {
                            "firstName": "Martyna",
                            "lastName": "Spiewak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martyna Spiewak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19266193"
                        ],
                        "name": "Piotr Sobecki",
                        "slug": "Piotr-Sobecki",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Sobecki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Sobecki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064223453"
                        ],
                        "name": "Daniel Karas",
                        "slug": "Daniel-Karas",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Karas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Karas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "04 OPI-JSA (\u015apiewak et al., 2017) 78."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5981377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c3cae1a19633040494df5013b0523df39c74fc4",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic Textual Similarity (STS) evaluation assesses the degree to which two parts of texts are similar, based on their semantic evaluation. In this paper, we describe three models submitted to STS SemEval 2017. Given two English parts of a text, each of proposed methods outputs the assessment of their semantic similarity. We propose an approach for computing monolingual semantic textual similarity based on an ensemble of three distinct methods. Our model consists of recursive neural network (RNN) text auto-encoders ensemble with supervised a model of vectorized sentences using reduced part of speech (PoS) weighted word embeddings as well as unsupervised a method based on word coverage (TakeLab). Additionally, we enrich our model with additional features that allow disambiguation of ensemble methods based on their efficiency. We have used Multi-Layer Perceptron as an ensemble classifier basing on estimations of trained Gradient Boosting Regressors. Results of our research proves that using such ensemble leads to a higher accuracy due to a fact that each member-algorithm tends to specialize in particular type of sentences. Simple model based on PoS weighted Word2Vec word embeddings seem to improve performance of more complex RNN based auto-encoders in the ensemble. In the monolingual English-English STS subtask our Ensemble based model achieved mean Pearson correlation of .785 compared with human annotators."
            },
            "slug": "OPI-JSA-at-SemEval-2017-Task-1:-Application-of-for-Spiewak-Sobecki",
            "title": {
                "fragments": [],
                "text": "OPI-JSA at SemEval-2017 Task 1: Application of Ensemble learning for computing semantic textual similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes an approach for computing monolingual semantic textual similarity based on an ensemble of three distinct methods and proves that using such ensemble leads to a higher accuracy due to a fact that each member-algorithm tends to specialize in particular type of sentences."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46724030"
                        ],
                        "name": "Daniel Matthew Cer",
                        "slug": "Daniel-Matthew-Cer",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cer",
                            "middleNames": [
                                "Matthew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Matthew Cer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403836100"
                        ],
                        "name": "A. Gonzalez-Agirre",
                        "slug": "A.-Gonzalez-Agirre",
                        "structuredName": {
                            "firstName": "Aitor",
                            "lastName": "Gonzalez-Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gonzalez-Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579583"
                        ],
                        "name": "Weiwei Guo",
                        "slug": "Weiwei-Guo",
                        "structuredName": {
                            "firstName": "Weiwei",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiwei Guo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 178
                            }
                        ],
                        "text": "To encourage and support research in this area, the STS shared task has been held annually since 2012, providing a venue for evaluation of state-ofthe-art algorithms and models (Agirre et al., 2012, 2013, 2014, 2015, 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10241043,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "ff5cbefc6766df788919db4c060daedb303ed3e3",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In Semantic Textual Similarity (STS), systems rate the degree of semantic equivalence, on a graded scale from 0 to 5, with 5 being the most similar. This year we set up two tasks: (i) a core task (CORE), and (ii) a typed-similarity task (TYPED). CORE is similar in set up to SemEval STS 2012 task with pairs of sentences from sources related to those of 2012, yet different in genre from the 2012 set, namely, this year we included newswire headlines, machine translation evaluation datasets and multiple lexical resource glossed sets. TYPED, on the other hand, is novel and tries to characterize why two items are deemed similar, using cultural heritage items which are described with metadata such as title, author or description. Several types of similarity have been defined, including similar author, similar time period or similar location. The annotation for both tasks leverages crowdsourcing, with relative high interannotator correlation, ranging from 62% to 87%. The CORE task attracted 34 participants with 89 runs, and the TYPED task attracted 6 teams with 14 runs."
            },
            "slug": "*SEM-2013-shared-task:-Semantic-Textual-Similarity-Agirre-Cer",
            "title": {
                "fragments": [],
                "text": "*SEM 2013 shared task: Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "The CORE task attracted 34 participants with 89 runs, and the TYPED task attracted 6 teams with 14 runs, with relative high interannotator correlation, ranging from 62% to 87%."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402921001"
                        ],
                        "name": "C. Espa\u00f1a-Bonet",
                        "slug": "C.-Espa\u00f1a-Bonet",
                        "structuredName": {
                            "firstName": "Cristina",
                            "lastName": "Espa\u00f1a-Bonet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Espa\u00f1a-Bonet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397442049"
                        ],
                        "name": "Alberto Barr\u00f3n-Cede\u00f1o",
                        "slug": "Alberto-Barr\u00f3n-Cede\u00f1o",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Barr\u00f3n-Cede\u00f1o",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alberto Barr\u00f3n-Cede\u00f1o"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 945767,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "d2fe8761dad44e8cc40c0b0a373c9c59dcf484c4",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This is the Lump team participation at SemEval 2017 Task 1 on Semantic Textual Similarity. Our supervised model relies on features which are multilingual or interlingual in nature. We include lexical similarities, cross-language explicit semantic analysis, internal representations of multilingual neural networks and interlingual word embeddings. Our representations allow to use large datasets in language pairs with many instances to better classify instances in smaller language pairs avoiding the necessity of translating into a single language. Hence we can deal with all the languages in the task: Arabic, English, Spanish, and Turkish."
            },
            "slug": "Lump-at-SemEval-2017-Task-1:-Towards-an-Interlingua-Espa\u00f1a-Bonet-Barr\u00f3n-Cede\u00f1o",
            "title": {
                "fragments": [],
                "text": "Lump at SemEval-2017 Task 1: Towards an Interlingua Semantic Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The Lump team participation at SemEval 2017 Task 1 on Semantic Textual Similarity includes lexical similarities, cross-language explicit semantic analysis, internal representations of multilingual neural networks and interlingual word embeddings, and can deal with all the languages in the task."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409249154"
                        ],
                        "name": "Ignacio Arroyo-Fern\u00e1ndez",
                        "slug": "Ignacio-Arroyo-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Ignacio",
                            "lastName": "Arroyo-Fern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ignacio Arroyo-Fern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403616824"
                        ],
                        "name": "Ivan Vladimir Meza Ruiz",
                        "slug": "Ivan-Vladimir-Meza-Ruiz",
                        "structuredName": {
                            "firstName": "Ivan Vladimir",
                            "lastName": "Meza Ruiz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Vladimir Meza Ruiz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 334369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a640fb4a11fc767f4bf801f7a7320b92efc807d3",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we report our attempt to use, on the one hand, state-of-the-art neural approaches that are proposed to measure Semantic Textual Similarity (STS). On the other hand, we propose an unsupervised cross-word alignment approach, which is linguistically motivated. The neural approaches proposed herein are divided into two main stages. The first stage deals with constructing neural word embeddings, the components of sentence embeddings. The second stage deals with constructing a semantic similarity function relating pairs of sentence embeddings. Unfortunately our competition results were poor in all tracks, therefore we concentrated our research to improve them for Track 5 (EN-EN)."
            },
            "slug": "LIPN-IIMAS-at-SemEval-2017-Task-1:-Subword-Neural-Arroyo-Fern\u00e1ndez-Ruiz",
            "title": {
                "fragments": [],
                "text": "LIPN-IIMAS at SemEval-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The attempt to use, on the one hand, state-of-the-art neural approaches that are proposed to measure Semantic Textual Similarity (STS) and an unsupervised cross-word alignment approach, which is linguistically motivated, is reported."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17771023"
                        ],
                        "name": "E. Nagoudi",
                        "slug": "E.-Nagoudi",
                        "structuredName": {
                            "firstName": "El",
                            "lastName": "Nagoudi",
                            "middleNames": [
                                "Moatez",
                                "Billah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nagoudi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5704461"
                        ],
                        "name": "J. Ferrero",
                        "slug": "J.-Ferrero",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00e9my",
                            "lastName": "Ferrero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ferrero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2504683"
                        ],
                        "name": "D. Schwab",
                        "slug": "D.-Schwab",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Schwab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Schwab"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 16
                            }
                        ],
                        "text": "20ECNU, BIT and LIM-LIG are scaled to the range 0-5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 9
                            }
                        ],
                        "text": "LIM-LIG (Nagoudi et al., 2017) Using only weighted word embeddings, LIM-LIG took second place on Arabic.17 Arabic word embeddings are summed into sentence embeddings using uniform, POS and IDF weighting schemes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 8
                            }
                        ],
                        "text": "LIM-LIG (Nagoudi et al., 2017) Using only weighted word embeddings, LIM-LIG took second place on Arabic."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "Combining the IDF and POS weights by multiplication is reported by LIM-LIG to achieve r 0.7667, higher than all submitted Arabic (track 1) systems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "LIM-LIG and DT Team only participate in monolingual tracks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7167272,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "696dfcfe668872bfd823c5dc21b84bedabe127eb",
            "isKey": true,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes our proposed system named LIM-LIG. This system is designed for SemEval 2017 Task1: Semantic Textual Similarity (Track1). LIM-LIG proposes an innovative enhancement to word embedding-based model devoted to measure the semantic similarity in Arabic sentences. The main idea is to exploit the word representations as vectors in a multidimensional space to capture the semantic and syntactic properties of words. IDF weighting and Part-of-Speech tagging are applied on the examined sentences to support the identification of words that are highly descriptive in each sentence. LIM-LIG system achieves a Pearson\u2019s correlation of 0.74633, ranking 2nd among all participants in the Arabic monolingual pairs STS task organized within the SemEval 2017 evaluation campaign"
            },
            "slug": "LIM-LIG-at-SemEval-2017-Task1:-Enhancing-the-for-Nagoudi-Ferrero",
            "title": {
                "fragments": [],
                "text": "LIM-LIG at SemEval-2017 Task1: Enhancing the Semantic Similarity for Arabic Sentences with Vectors Weighting"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "LIG proposes an innovative enhancement to word embedding-based model devoted to measure the semantic similarity in Arabic sentences to exploit the word representations as vectors in a multidimensional space to capture the semantic and syntactic properties of words."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111892870"
                        ],
                        "name": "Hua He",
                        "slug": "Hua-He",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771118"
                        ],
                        "name": "J. Wieting",
                        "slug": "J.-Wieting",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wieting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wieting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30586030"
                        ],
                        "name": "J. Rao",
                        "slug": "J.-Rao",
                        "structuredName": {
                            "firstName": "Jinfeng",
                            "lastName": "Rao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 96
                            }
                        ],
                        "text": "More recently, deep learning became competitive with top performing feature engineered systems (He et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1090122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00b874f8346cedadc2a6366c4b72e60140f99556",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an attention-based convolutional neural network for the English semantic textual similarity (STS) task in the SemEval2016 competition (Agirre et al., 2016). We develop an attention-based input interaction layer and incorporate it into our multiperspective convolutional neural network (He et al., 2015), using the PARAGRAM-PHRASE word embeddings (Wieting et al., 2016) trained on paraphrase pairs. Without using any sparse features, our final model outperforms the winning entry in STS2015 when evaluated on the STS2015 data."
            },
            "slug": "UMD-TTIC-UW-at-SemEval-2016-Task-1:-Attention-Based-He-Wieting",
            "title": {
                "fragments": [],
                "text": "UMD-TTIC-UW at SemEval-2016 Task 1: Attention-Based Multi-Perspective Convolutional Neural Networks for Textual Similarity Measurement"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An attention-based convolutional neural network for the English semantic textual similarity (STS) task in the SemEval2016 competition outperforms the winning entry in STS 2015 when evaluated on the STS2015 data."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644577"
                        ],
                        "name": "S. Menini",
                        "slug": "S.-Menini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Menini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Menini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 50
                            }
                        ],
                        "text": "entailment strongly cues for semantic relatedness (Marelli et al., 2014), we construct our own sentence pairings to deter gold entailment labels from informing evaluation set STS scores."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "However, since entailment strongly cues for semantic relatedness (Marelli et al., 2014), we construct our own sentence pairings to deter gold entailment labels from informing evaluation set STS scores."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 762228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c333778104f648c385b4631f7b4a859787e9d3d3",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Shared and internationally recognized benchmarks are fundamental for the development of any computational system. We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them. SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs. By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral). The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes."
            },
            "slug": "A-SICK-cure-for-the-evaluation-of-compositional-Marelli-Menini",
            "title": {
                "fragments": [],
                "text": "A SICK cure for the evaluation of compositional distributional semantic models"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work aims to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48119717"
                        ],
                        "name": "Barbara Rychalska",
                        "slug": "Barbara-Rychalska",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Rychalska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara Rychalska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47021012"
                        ],
                        "name": "Katarzyna Pakulska",
                        "slug": "Katarzyna-Pakulska",
                        "structuredName": {
                            "firstName": "Katarzyna",
                            "lastName": "Pakulska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katarzyna Pakulska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3474148"
                        ],
                        "name": "Krystyna Chodorowska",
                        "slug": "Krystyna-Chodorowska",
                        "structuredName": {
                            "firstName": "Krystyna",
                            "lastName": "Chodorowska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Krystyna Chodorowska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092456385"
                        ],
                        "name": "Wojciech Walczak",
                        "slug": "Wojciech-Walczak",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Walczak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Walczak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3103504"
                        ],
                        "name": "P. Andruszkiewicz",
                        "slug": "P.-Andruszkiewicz",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Andruszkiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Andruszkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 101
                            }
                        ],
                        "text": "The best performance tends to be obtained by ensembling feature engineered and deep learning models (Rychalska et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15784336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99bec22932e6a3e84d786a31d36a0e9217b91ad5",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes our proposed solutions designed for a STS core track within the SemEval 2016 English Semantic Textual Similarity (STS) task. Our method of similarity detection combines recursive autoencoders with a WordNet award-penalty system that accounts for semantic relatedness, and an SVM classifier, which produces the final score from similarity matrices. This solution is further supported by an ensemble classifier, combining an aligner with a bi-directional Gated Recurrent Neural Network and additional features, which then performs Linear Support Vector Regression to determine another set of scores."
            },
            "slug": "Samsung-Poland-NLP-Team-at-SemEval-2016-Task-1:-for-Rychalska-Pakulska",
            "title": {
                "fragments": [],
                "text": "Samsung Poland NLP Team at SemEval-2016 Task 1: Necessity for diversity; combining recursive autoencoders, WordNet and ensemble methods to measure semantic similarity."
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This paper describes the proposed solutions designed for a STS core track within the SemEval 2016 English Semantic Textual Similarity task, which combines recursive autoencoders with a WordNet award-penalty system that accounts for semantic relatedness, and an SVM classifier, which produces the final score from similarity matrices."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2237884"
                        ],
                        "name": "Ergun Bi\u00e7ici",
                        "slug": "Ergun-Bi\u00e7ici",
                        "structuredName": {
                            "firstName": "Ergun",
                            "lastName": "Bi\u00e7ici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ergun Bi\u00e7ici"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "46 RTM (Bi\u00e7ici, 2017)* 36."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30423603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cddaa72cd23edbb7c4a77a62c509bf5dbcaf93d",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We use referential translation machines for predicting the semantic similarity of text in all STS tasks which contain Arabic, English, Spanish, and Turkish this year. RTMs pioneer a language independent approach to semantic similarity and remove the need to access any task or domain specific information or resource. RTMs become 6th out of 52 submissions in Spanish to English STS. We average prediction scores using weights based on the training performance to improve the overall performance."
            },
            "slug": "RTM-at-SemEval-2017-Task-1:-Referential-Translation-Bi\u00e7ici",
            "title": {
                "fragments": [],
                "text": "RTM at SemEval-2017 Task 1: Referential Translation Machines for Predicting Semantic Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work uses referential translation machines for predicting the semantic similarity of text in all STS tasks which contain Arabic, English, Spanish, and Turkish this year."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771118"
                        ],
                        "name": "J. Wieting",
                        "slug": "J.-Wieting",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wieting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wieting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2924113"
                        ],
                        "name": "Karen Livescu",
                        "slug": "Karen-Livescu",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Livescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Livescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 281
                            }
                        ],
                        "text": "Ensembled components include: alignment similarity; TakeLab STS (S\u030caric\u0301 et al., 2012b); string similarity measures such as matching n-grams, summarization and MT metrics (BLEU, WER, PER, ROUGE); a RNN and recurrent convolutional neural networks (RCNN) over word alignments; and a BiLSTM that is state-ofthe-art for textual entailment (Chen et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "UMDeep (Barrow and Peskov, 2017) took a similar approach using LSTMs rather than CNNs for the sentence embeddings."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "ECNU\u2019s deep learning models are differentiated by their approach to sentence embeddings using either: averaged word embeddings, projected word embeddings, a deep averaging network (DAN) (Iyyer et al., 2015) or LSTM (Hochreiter and Schmidhuber, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 199
                            }
                        ],
                        "text": "Deep learning similarity scores are computed using a variety of paraphrastic sentence embeddings methods: averaged word embeddings, projected word embeddings, a deep averaging network (DAN) and LSTM (Wieting et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5882977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "395044a2e3f5624b2471fb28826e7dbb1009356e",
            "isKey": true,
            "numCitedBy": 479,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning general-purpose, paraphrastic sentence embeddings based on supervision from the Paraphrase Database (Ganitkevitch et al., 2013). We compare six compositional architectures, evaluating them on annotated textual similarity datasets drawn both from the same distribution as the training data and from a wide range of other domains. We find that the most complex architectures, such as long short-term memory (LSTM) recurrent neural networks, perform best on the in-domain data. However, in out-of-domain scenarios, simple architectures such as word averaging vastly outperform LSTMs. Our simplest averaging model is even competitive with systems tuned for the particular tasks while also being extremely efficient and easy to use. \nIn order to better understand how these architectures compare, we conduct further experiments on three supervised NLP tasks: sentence similarity, entailment, and sentiment classification. We again find that the word averaging models perform well for sentence similarity and entailment, outperforming LSTMs. However, on sentiment classification, we find that the LSTM performs very strongly-even recording new state-of-the-art performance on the Stanford Sentiment Treebank. \nWe then demonstrate how to combine our pretrained sentence embeddings with these supervised tasks, using them both as a prior and as a black box feature extractor. This leads to performance rivaling the state of the art on the SICK similarity and entailment tasks. We release all of our resources to the research community with the hope that they can serve as the new baseline for further work on universal sentence embeddings."
            },
            "slug": "Towards-Universal-Paraphrastic-Sentence-Embeddings-Wieting-Bansal",
            "title": {
                "fragments": [],
                "text": "Towards Universal Paraphrastic Sentence Embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work considers the problem of learning general-purpose, paraphrastic sentence embeddings based on supervision from the Paraphrase Database, and compares six compositional architectures, finding that the most complex architectures, such as long short-term memory (LSTM) recurrent neural networks, perform best on the in-domain data."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2338841"
                        ],
                        "name": "Junfeng Tian",
                        "slug": "Junfeng-Tian",
                        "structuredName": {
                            "firstName": "Junfeng",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junfeng Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800668"
                        ],
                        "name": "Zhi-Min Zhou",
                        "slug": "Zhi-Min-Zhou",
                        "structuredName": {
                            "firstName": "Zhi-Min",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Min Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143745020"
                        ],
                        "name": "Man Lan",
                        "slug": "Man-Lan",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Lan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Man Lan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3174675"
                        ],
                        "name": "Yuanbin Wu",
                        "slug": "Yuanbin-Wu",
                        "structuredName": {
                            "firstName": "Yuanbin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuanbin Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "ECNU\u2019s deep learning models are differentiated by their approach to sentence embeddings using either: averaged word embeddings, projected word embeddings, a deep averaging network (DAN) (Iyyer et al., 2015) or LSTM (Hochreiter and Schmidhuber, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": "20ECNU, BIT and LIM-LIG are scaled to the range 0-5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "15Within the highlighted submissions, the following use a monolingual English system fed by MT: ECNU, BIT, HCTI and MITRE."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "ECNU\u2019s top ranking entry performs slightly better on Arabic-English than Arabic, with a slight drop from Spanish to Spanish-English (SNLI)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "The architecture is abstractly similar to ECNU\u2019s deep learning models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Sentence IC in isolation outperforms all systems except those from ECNU."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 6
                            }
                        ],
                        "text": "ECNU (Tian et al., 2017) The best overall system is from ENCU and ensembles well performing a feature engineered models with deep learning methods."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "MITRE (Henderson et al., 2017) Fourth place overall is MITRE that, like ECNU, takes an ambitious feature engineering approach complemented by deep learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "16The two remaining ECNU runs only use either RF or GB and exclude the deep learning models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "ECNU is best overall (avg r: 0.7316) and achieves the highest participant evaluation score on: track 2, Arabic-English (r: 0.7493); track 3, Spanish (r: 0.8559); and track 6, Turkish-English (r: 0.7706)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31826507,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "caa8a41d58e386c56f56d46bbe79df9cb1087338",
            "isKey": true,
            "numCitedBy": 60,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "To address semantic similarity on multilingual and cross-lingual sentences, we firstly translate other foreign languages into English, and then feed our monolingual English system with various interactive features. Our system is further supported by combining with deep learning semantic similarity and our best run achieves the mean Pearson correlation 73.16% in primary track."
            },
            "slug": "ECNU-at-SemEval-2017-Task-1:-Leverage-Kernel-based-Tian-Zhou",
            "title": {
                "fragments": [],
                "text": "ECNU at SemEval-2017 Task 1: Leverage Kernel-based Traditional NLP features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "To address semantic similarity on multilingual and cross-lingual sentences, this work firstly translates other foreign languages into English, and then feeds the monolingual English system with various interactive features to support semantic similarity."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112573446"
                        ],
                        "name": "Yang Shao",
                        "slug": "Yang-Shao",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Shao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Shao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "15Within the highlighted submissions, the following use a monolingual English system fed by MT: ECNU, BIT, HCTI and MITRE."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "4 (CNN) and then compared using fully connected layers (Shao, 2017) RTM Referential translation machines (RTM) use a feature eng."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 5
                            }
                        ],
                        "text": "HCTI (Shao, 2017) Third place overall is obtained by HCTI with a model similar to a convolutional Deep Structured Semantic Model (CDSSM) (Chen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "HCTI (Shao, 2017) Third place overall is obtained by HCTI with a model similar to a convolutional Deep Structured Semantic Model (CDSSM) (Chen et al., 2015; Huang et al., 2013)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "HCTI submitted a separate run using ar, es and en trained models that underperformed using their en model with MT for ar and es."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30958369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8a3026ae7a425caf36064a484a6a1eb5c175754",
            "isKey": true,
            "numCitedBy": 57,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes our convolutional neural network (CNN) system for the Semantic Textual Similarity (STS) task. We calculated semantic similarity score between two sentences by comparing their semantic vectors. We generated a semantic vector by max pooling over every dimension of all word vectors in a sentence. There are two key design tricks used by our system. One is that we trained a CNN to transfer GloVe word vectors to a more proper form for the STS task before pooling. Another is that we trained a fully-connected neural network (FCNN) to transfer the difference of two semantic vectors to the probability distribution over similarity scores. All hyperparameters were empirically tuned. In spite of the simplicity of our neural network system, we achieved a good accuracy and ranked 3rd on primary track of SemEval 2017."
            },
            "slug": "HCTI-at-SemEval-2017-Task-1:-Use-convolutional-to-Shao",
            "title": {
                "fragments": [],
                "text": "HCTI at SemEval-2017 Task 1: Use convolutional neural network to evaluate Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The convolutional neural network system for the Semantic Textual Similarity (STS) task achieved a good accuracy and ranked 3rd on primary track of SemEval 2017."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2959414"
                        ],
                        "name": "Nils Reimers",
                        "slug": "Nils-Reimers",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Reimers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nils Reimers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066764584"
                        ],
                        "name": "Philip Beyer",
                        "slug": "Philip-Beyer",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Beyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip Beyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730400"
                        ],
                        "name": "Iryna Gurevych",
                        "slug": "Iryna-Gurevych",
                        "structuredName": {
                            "firstName": "Iryna",
                            "lastName": "Gurevych",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iryna Gurevych"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 8
                            }
                        ],
                        "text": "14e.g., Reimers et al. (2016) report success using STS labels with alternative metrics such as normalized Cumulative Gain (nCG), normalized Discounted Cumulative Gain (nDCG) and F1 to more accurately predict performance on the downstream tasks: text reuse detection, binary classification of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", Reimers et al. (2016) report success using STS labels with alternative metrics such as normalized Cumulative Gain (nCG), normalized Discounted Cumulative Gain (nDCG) and F1 to more accurately predict performance on the downstream tasks: text reuse detection, binary classification of document relatedness and document relatedness within a corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18283203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c194183ce1485f76ad0544d62d3d5f62da41cbe",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic Textual Similarity (STS) is a foundational NLP task and can be used in a wide range of tasks. To determine the STS of two texts, hundreds of different STS systems exist, however, for an NLP system designer, it is hard to decide which system is the best one. To answer this question, an intrinsic evaluation of the STS systems is conducted by comparing the output of the system to human judgments on semantic similarity. The comparison is usually done using Pearson correlation. In this work, we show that relying on intrinsic evaluations with Pearson correlation can be misleading. In three common STS based tasks we could observe that the Pearson correlation was especially ill-suited to detect the best STS system for the task and other evaluation measures were much better suited. In this work we define how the validity of an intrinsic evaluation can be assessed and compare different intrinsic evaluation methods. Understanding of the properties of the targeted task is crucial and we propose a framework for conducting the intrinsic evaluation which takes the properties of the targeted task into account."
            },
            "slug": "Task-Oriented-Intrinsic-Evaluation-of-Semantic-Reimers-Beyer",
            "title": {
                "fragments": [],
                "text": "Task-Oriented Intrinsic Evaluation of Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work defines how the validity of an intrinsic evaluation can be assessed and compares different intrinsic evaluation methods and proposes a framework for conducting the intrinsic evaluation which takes the properties of the targeted task into account."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644577"
                        ],
                        "name": "S. Menini",
                        "slug": "S.-Menini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Menini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Menini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 235
                            }
                        ],
                        "text": "CompiLIG (Ferrero et al., 2017) The best Spanish-English performance on SNLI sentences was achieved by CompiLIG using the following cross-lingual features: conceptual similarity using DBNary (Serasset, 2015), MultiVec word embeddings (Berard et al., 2016) and character n-grams."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8897969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb93bc031fede3d53ee01a1b66ca3b24fc8a10d7",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractThis paper is an extended description of SemEval-2014 Task 1, the task on the evaluation of Compositional Distributional Semantics Models on full sentences. Systems participating in the task were presented with pairs of sentences and were evaluated on their ability to predict human judgments on (1) semantic relatedness and (2) entailment.\n Training and testing data were subsets of the SICK (Sentences Involving Compositional Knowledge) data set. SICK was developed with the aim of providing a proper benchmark to evaluate compositional semantic systems, though task participation was open to systems based on any approach. Taking advantage of the SemEval experience, in this paper we analyze the SICK data set, in order to evaluate the extent to which it meets its design goal and to shed light on the linguistic phenomena that are still challenging for state-of-the-art computational semantic systems.\n Qualitative and quantitative error analyses show that many systems are quite sensitive to changes in the proportion of sentence pair types, and degrade in the presence of additional lexico-syntactic complexities which do not affect human judgements. More compositional systems seem to perform better when the task proportions are changed, but the effect needs further confirmation.\n"
            },
            "slug": "SICK-through-the-SemEval-glasses.-Lesson-learned-of-Bentivogli-Bernardi",
            "title": {
                "fragments": [],
                "text": "SICK through the SemEval glasses. Lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Qualitative and quantitative error analyses show that many systems are quite sensitive to changes in the proportion of sentence pair types, and degrade in the presence of additional lexico-syntactic complexities which do not affect human judgements, but the effect needs further confirmation."
            },
            "venue": {
                "fragments": [],
                "text": "Lang. Resour. Evaluation"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32809621"
                        ],
                        "name": "Wenli Zhuang",
                        "slug": "Wenli-Zhuang",
                        "structuredName": {
                            "firstName": "Wenli",
                            "lastName": "Zhuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenli Zhuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48025720"
                        ],
                        "name": "Ernie Chang",
                        "slug": "Ernie-Chang",
                        "structuredName": {
                            "firstName": "Ernie",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernie Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "52 neobility (Zhuang and Chang, 2017) 61."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5986178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c96f22dd1d68381c58cab4c71ce72c6708fa21e7",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task. Our system employs an attention-based recurrent neural network model that optimizes the sentence similarity. In this paper, we describe our participation in the multilingual STS task which measures similarity across English, Spanish, and Arabic."
            },
            "slug": "Neobility-at-SemEval-2017-Task-1:-An-Sentence-Model-Zhuang-Chang",
            "title": {
                "fragments": [],
                "text": "Neobility at SemEval-2017 Task 1: An Attention-based Sentence Similarity Model"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task is described, employing an attention-based recurrent neural network model that optimizes the sentence similarity."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917913"
                        ],
                        "name": "Tomas Brychcin",
                        "slug": "Tomas-Brychcin",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Brychcin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Brychcin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065725861"
                        ],
                        "name": "Luk\u00e1s Svoboda",
                        "slug": "Luk\u00e1s-Svoboda",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Svoboda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Svoboda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18720573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a75ef477b09fb868ee80c76602efa9e03696a67",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present our UWB system for Semantic Textual Similarity (STS) task at SemEval 2016. Given two sentences, the system estimates the degree of their semantic similarity. We use state-of-the-art algorithms for the meaning representation and combine them with the best performing approaches to STS from previous years. These methods benefit from various sources of information, such as lexical, syntactic, and semantic. In the monolingual task, our system achieve mean Pearson correlation 75.7% compared with human annotators. In the cross-lingual task, our system has correlation 86.3% and is ranked first among 26 systems."
            },
            "slug": "UWB-at-SemEval-2016-Task-1:-Semantic-Textual-using-Brychcin-Svoboda",
            "title": {
                "fragments": [],
                "text": "UWB at SemEval-2016 Task 1: Semantic Textual Similarity using Lexical, Syntactic, and Semantic Information"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work uses state-of-the-art algorithms for the meaning representation and combines them with the best performing approaches to STS from previous years to create a UWB system for Semantic Textual Similarity (STS) task."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2759903"
                        ],
                        "name": "F. Saric",
                        "slug": "F.-Saric",
                        "structuredName": {
                            "firstName": "Frane",
                            "lastName": "Saric",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Saric"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472657"
                        ],
                        "name": "Goran Glavas",
                        "slug": "Goran-Glavas",
                        "structuredName": {
                            "firstName": "Goran",
                            "lastName": "Glavas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Goran Glavas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065433122"
                        ],
                        "name": "Mladen Karan",
                        "slug": "Mladen-Karan",
                        "structuredName": {
                            "firstName": "Mladen",
                            "lastName": "Karan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mladen Karan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143809437"
                        ],
                        "name": "J. \u0160najder",
                        "slug": "J.-\u0160najder",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "\u0160najder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. \u0160najder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747163"
                        ],
                        "name": "B. D. Basic",
                        "slug": "B.-D.-Basic",
                        "structuredName": {
                            "firstName": "Bojana",
                            "lastName": "Basic",
                            "middleNames": [
                                "Dalbelo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Basic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 116
                            }
                        ],
                        "text": "Early methods focused on lexical semantics, surface form matching and basic syntactic similarity (Ba\u0308r et al., 2012; S\u030caric\u0301 et al., 2012a; Jimenez et al., 2012a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 52
                            }
                        ],
                        "text": "Ensembled components include: alignment similarity; TakeLab STS (S\u030caric\u0301 et al., 2012b); string similarity measures such as matching n-grams, summarization and MT metrics (BLEU, WER, PER, ROUGE); a RNN and recurrent convolutional neural networks (RCNN) over word alignments; and a BiLSTM that is state-ofthe-art for textual entailment (Chen et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 65
                            }
                        ],
                        "text": "Ensembled components include: alignment similarity; TakeLab STS (S\u030caric\u0301 et al., 2012b); string similarity measures such as matching n-grams, summarization and MT metrics (BLEU, WER, PER, ROUGE); a RNN and recurrent convolutional neural networks (RCNN) over word alignments; and a BiLSTM that is\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "Ensembled components include: alignment similarity; TakeLab STS (\u0160ari\u0107 et al., 2012b); string similarity measures such as"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12233462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfc214ce7ab5b101425e5cabd631176bb427adff",
            "isKey": true,
            "numCitedBy": 224,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the two systems for determining the semantic similarity of short texts submitted to the SemEval 2012 Task 6. Most of the research on semantic similarity of textual content focuses on large documents. However, a fair amount of information is condensed into short text snippets such as social media posts, image captions, and scientific abstracts. We predict the human ratings of sentence similarity using a support vector regression model with multiple features measuring word-overlap similarity and syntax similarity. Out of 89 systems submitted, our two systems ranked in the top 5, for the three overall evaluation metrics used (overall Pearson -- 2nd and 3rd, normalized Pearson -- 1st and 3rd, weighted mean -- 2nd and 5th)."
            },
            "slug": "TakeLab:-Systems-for-Measuring-Semantic-Text-Saric-Glavas",
            "title": {
                "fragments": [],
                "text": "TakeLab: Systems for Measuring Semantic Text Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The two systems for determining the semantic similarity of short texts submitted to the SemEval 2012 Task 6 ranked in the top 5, for the three overall evaluation metrics used."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145563465"
                        ],
                        "name": "Sanjeev Arora",
                        "slug": "Sanjeev-Arora",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Arora",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjeev Arora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40609253"
                        ],
                        "name": "Yingyu Liang",
                        "slug": "Yingyu-Liang",
                        "structuredName": {
                            "firstName": "Yingyu",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yingyu Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901958"
                        ],
                        "name": "Tengyu Ma",
                        "slug": "Tengyu-Ma",
                        "structuredName": {
                            "firstName": "Tengyu",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tengyu Ma"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 31
                            }
                        ],
                        "text": "The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component (18)RTV took first place on track 5, English, but submitted no system description paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "\u2026deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component\n18RTV took first place on track 5, English, but submitted no system\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 180
                            }
                        ],
                        "text": "This year\u2019s shared task differed substantially from previous iterations of STS in that the primary emphasis of the task shifted from English to multilingual and cross-lingual STS in-\nSIF: PTB tokenization provided by Stanford CoreNLP (Manning et al., 2014) with post-processing based on dev OOVs; Word2vec: Similar to FastText, to our knownledge, the preprocessing for the pre-trained Word2vec embeddings is not publicly described."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 270
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component\n18RTV took first place on track 5, English, but submitted no system description paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 37
                            }
                        ],
                        "text": "sum with principle component removal (Arora et al., 2017) 80."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "25Sent2Vec: https://github.com/epfml/ sent2vec, trained model Sent2Vec twitter unigrams; SIF: https://github.com/epfml/sent2vec Wikipedia trained word frequencies enwiki vocab min200.txt, https://github.com/alexandres/lexvec embeddings from lexvec.commoncrawl.300d.W+C.pos.vectors, first 15 principle components removed, \u03b1 = 0.001, dev experiments varied \u03b1, principle components removed and\nuses the model from Lau and Baldwin (2016) and InferSent which was reported independently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 131
                            }
                        ],
                        "text": "STS shared task data sets have been used extensively for research on sentence level similarity and semantic representations (i.a., Arora et al. (2017); Conneau et al. (2017); Mu et al. (2017); Pagliardini et al. (2017); Wieting and Gimpel (2017); He and Lin (2016); Hill et al. (2016); Kenter et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64908139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f1802d3f4f5f6d66875dac09112f978f12e1e1e",
            "isKey": true,
            "numCitedBy": 986,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Simple-but-Tough-to-Beat-Baseline-for-Sentence-Arora-Liang",
            "title": {
                "fragments": [],
                "text": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596310"
                        ],
                        "name": "Chris Quirk",
                        "slug": "Chris-Quirk",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 252
                            }
                        ],
                        "text": "Semantic inference tasks related to\nSTS include textual entailment (Bentivogli et al., 2016; Bowman et al., 2015; Dagan et al., 2010), semantic relatedness (Bentivogli et al., 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10181753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7acfdc905f734abf966aed58abb983bc015ff7fe",
            "isKey": false,
            "numCitedBy": 794,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources. Two techniques are employed: (1) simple string edit distance, and (2) a heuristic strategy that pairs initial (presumably summary) sentences from different news stories in the same cluster. We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation. Results show that edit distance data is cleaner and more easily-aligned than the heuristic data, with an overall alignment error rate (AER) of 11.58% on a similarly-extracted test set. On test data extracted by the heuristic strategy, however, performance of the two training sets is similar, with AERs of 13.2% and 14.7% respectively. Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase. The summary sentences, while less readily alignable, retain more of the non-trivial alternations that are of greatest interest learning paraphrase relationships."
            },
            "slug": "Unsupervised-Construction-of-Large-Paraphrase-News-Dolan-Quirk",
            "title": {
                "fragments": [],
                "text": "Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Investigation of unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources shows that edit distance data is cleaner and more easily-aligned than the heuristic data."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3449364"
                        ],
                        "name": "Alexandre Berard",
                        "slug": "Alexandre-Berard",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Berard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandre Berard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890220"
                        ],
                        "name": "Christophe Servan",
                        "slug": "Christophe-Servan",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Servan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Servan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721354"
                        ],
                        "name": "O. Pietquin",
                        "slug": "O.-Pietquin",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Pietquin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Pietquin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823463"
                        ],
                        "name": "L. Besacier",
                        "slug": "L.-Besacier",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Besacier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Besacier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 50
                            }
                        ],
                        "text": "DBNary (Serasset, 2015), MultiVec word embeddings (Berard et al., 2016) and character n-grams."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 235
                            }
                        ],
                        "text": "CompiLIG (Ferrero et al., 2017) The best Spanish-English performance on SNLI sentences was achieved by CompiLIG using the following cross-lingual features: conceptual similarity using DBNary (Serasset, 2015), MultiVec word embeddings (Berard et al., 2016) and character n-grams."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6682953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "233ca02cd479c3f2da8e74f431854ca3a326d377",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present MultiVec, a new toolkit for computing continuous representations for text at different granularity levels (word-level or sequences of words). MultiVec includes Mikolov et al. [2013b]'s word2vec features, Le and Mikolov [2014]'s paragraph vector (batch and online) and Luong et al. [2015]'s model for bilingual distributed representations. MultiVec also includes different distance measures between words and sequences of words. The toolkit is written in C++ and is aimed at being fast (in the same order of magnitude as word2vec), easy to use, and easy to extend. It has been evaluated on several NLP tasks: the analogical reasoning task, sentiment analysis, and crosslingual document classification."
            },
            "slug": "MultiVec:-a-Multilingual-and-Multilevel-Learning-Berard-Servan",
            "title": {
                "fragments": [],
                "text": "MultiVec: a Multilingual and Multilevel Representation Learning Toolkit for NLP"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The toolkit is aimed at being fast (in the same order of magnitude as word2vec), easy to use, and easy to extend and has been evaluated on several NLP tasks: the analogical reasoning task, sentiment analysis, and crosslingual document classification."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271847"
                        ],
                        "name": "Carmen Banea",
                        "slug": "Carmen-Banea",
                        "structuredName": {
                            "firstName": "Carmen",
                            "lastName": "Banea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carmen Banea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46724030"
                        ],
                        "name": "Daniel Matthew Cer",
                        "slug": "Daniel-Matthew-Cer",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cer",
                            "middleNames": [
                                "Matthew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Matthew Cer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403836100"
                        ],
                        "name": "A. Gonzalez-Agirre",
                        "slug": "A.-Gonzalez-Agirre",
                        "structuredName": {
                            "firstName": "Aitor",
                            "lastName": "Gonzalez-Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gonzalez-Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785173"
                        ],
                        "name": "German Rigau",
                        "slug": "German-Rigau",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Rigau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "German Rigau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 65
                            }
                        ],
                        "text": "The word embedding similarity selection heuristic from STS 2016 (Agirre et al., 2016) is used to find interesting pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 58
                            }
                        ],
                        "text": "The annotation instructions and template are identical to Agirre et al. (2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 178
                            }
                        ],
                        "text": "To encourage and support research in this area, the STS shared task has been held annually since 2012, providing a venue for evaluation of state-ofthe-art algorithms and models (Agirre et al., 2012, 2013, 2014, 2015, 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "The word embedding similarity selection heuristic from STS 2016 (Agirre et al., 2016) is used to help find interesting pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 646594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e555b6054aa6fd4b46f87cd632668aaf8a91db6",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Comunicacio presentada al 10th International Workshop on Semantic Evaluation (SemEval-2016), celebrat els dies 16 i 17 de juny de 2016 a San Diego, California."
            },
            "slug": "SemEval-2016-Task-1:-Semantic-Textual-Similarity,-Agirre-Banea",
            "title": {
                "fragments": [],
                "text": "SemEval-2016 Task 1: Semantic Textual Similarity, Monolingual and Cross-Lingual Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Comunicacio presentada al 10th International Workshop on Semantic Evaluation (SemEval-2016), celebrat els dies 16 i 17 de juny de 2016 a San Diego, California."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66648221"
                        ],
                        "name": "Bill Dolan",
                        "slug": "Bill-Dolan",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Dolan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 114
                            }
                        ],
                        "text": "Semantic inference tasks related to\nSTS include textual entailment (Bentivogli et al., 2016; Bowman et al., 2015; Dagan et al., 2010), semantic relatedness (Bentivogli et al., 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 125
                            }
                        ],
                        "text": "Using reasonable human interpretations of natural language semantics was popularized by the related textual entailment task (Dagan et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 67
                            }
                        ],
                        "text": "Semantic inference tasks related to STS include textual entailment (Bentivogli et al., 2016; Bowman et al., 2015; Dagan et al., 2010), semantic relatedness (Bentivogli et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18717799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41aa047d94c91674cccad645759fd4e06ad8f6be",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The goal of identifying textual entailment \u2013 whether one piece of text can be plausibly inferred from another \u2013 has emerged in recent years as a generic core problem in natural language understanding. Work in this area has been largely driven by the PASCAL Recognizing Textual Entailment (RTE) challenges, which are a series of annual competitive meetings. The current work exhibits strong ties to some earlier lines of research, particularly automatic acquisition of paraphrases and lexical semantic relationships and unsupervised inference in applications such as question answering, information extraction and summarization. It has also opened the way to newer lines of research on more involved inference methods, on knowledge representations needed to support this natural language understanding challenge and on the use of learning methods in this context. RTE has fostered an active and growing community of researchers focused on the problem of applied entailment. This special issue of the JNLE provides an opportunity to showcase some of the most important work in this emerging area."
            },
            "slug": "Recognizing-textual-entailment:-Rational,-and-Dagan-Dolan",
            "title": {
                "fragments": [],
                "text": "Recognizing textual entailment: Rational, evaluation and approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This special issue of the JNLE provides an opportunity to showcase some of the most important work in this emerging area of textual entailment, particularly automatic acquisition of paraphrases and lexical semantic relationships and unsupervised inference in applications such as question answering, information extraction and summarization."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145507021"
                        ],
                        "name": "Daniel B\u00e4r",
                        "slug": "Daniel-B\u00e4r",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "B\u00e4r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel B\u00e4r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31565315"
                        ],
                        "name": "Chris Biemann",
                        "slug": "Chris-Biemann",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Biemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Biemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730400"
                        ],
                        "name": "Iryna Gurevych",
                        "slug": "Iryna-Gurevych",
                        "structuredName": {
                            "firstName": "Iryna",
                            "lastName": "Gurevych",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iryna Gurevych"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780779"
                        ],
                        "name": "Torsten Zesch",
                        "slug": "Torsten-Zesch",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Zesch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Torsten Zesch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 98
                            }
                        ],
                        "text": "Early methods focused on lexical semantics, surface form matching and basic syntactic similarity (Ba\u0308r et al., 2012; S\u030caric\u0301 et al., 2012a; Jimenez et al., 2012a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 97
                            }
                        ],
                        "text": "Early methods focused on lexical semantics, surface form matching and basic syntactic similarity (B\u00e4r et al., 2012; \u0160ari\u0107 et al., 2012a; Jimenez et al., 2012a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6964767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c97a26fd66d7413681cb74041347a47d0c97178",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the UKP system which performed best in the Semantic Textual Similarity (STS) task at SemEval-2012 in two out of three metrics. It uses a simple log-linear regression model, trained on the training data, to combine multiple text similarity measures of varying complexity. These range from simple character and word n-grams and common subsequences to complex features such as Explicit Semantic Analysis vector comparisons and aggregation of word similarity based on lexical-semantic resources. Further, we employ a lexical substitution system and statistical machine translation to add additional lexemes, which alleviates lexical gaps. Our final models, one per dataset, consist of a log-linear combination of about 20 features, out of the possible 300+ features implemented."
            },
            "slug": "UKP:-Computing-Semantic-Textual-Similarity-by-B\u00e4r-Biemann",
            "title": {
                "fragments": [],
                "text": "UKP: Computing Semantic Textual Similarity by Combining Multiple Content Similarity Measures"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This work uses a simple log-linear regression model, trained on the training data, to combine multiple text similarity measures of varying complexity, which range from simple character and word n-grams and common subsequences to complex features such as Explicit Semantic Analysis vector comparisons and aggregation of word similarity based on lexical-semantic resources."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2937809"
                        ],
                        "name": "Md Arafat Sultan",
                        "slug": "Md-Arafat-Sultan",
                        "structuredName": {
                            "firstName": "Md Arafat",
                            "lastName": "Sultan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Md Arafat Sultan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105138"
                        ],
                        "name": "Steven Bethard",
                        "slug": "Steven-Bethard",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Bethard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Bethard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2184912"
                        ],
                        "name": "T. Sumner",
                        "slug": "T.-Sumner",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Sumner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sumner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 158
                            }
                        ],
                        "text": "Alignment similarity scores are used with two runs: one that combines the scores within a string kernel and another that uses them with a weighted variant of Sultan et al. (2015)\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Three feature engineered models use Random Forest (RF), Gradient Boosting (GB) and XGBoost (XGB) regression methods with features based on: n-gram overlap; edit distance; longest common prefix/suffix/substring; tree kernels (Moschitti, 2006); word alignments (Sultan et al., 2015); summarization and MT evaluation metrics (BLEU, GTM-3, NIST, WER, METEOR, ROUGE); and kernel similarity of bagsof-words, bags-of-dependencies and pooled wordembeddings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 78
                            }
                        ],
                        "text": "During subsequent evaluations, strong new similarity signals emerged, such as Sultan et al. (2015)\u2019s alignment based method."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "\u2026with features based on: n-gram overlap; edit distance; longest common prefix/suffix/substring; tree kernels (Moschitti, 2006); word alignments (Sultan et al., 2015); summarization and MT evaluation metrics (BLEU, GTM-3, NIST, WER, METEOR, ROUGE); and kernel similarity of bagsof-words,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 26
                            }
                        ],
                        "text": "Another ensembles IC with Sultan et al. (2015)\u2019s alignment method, while a third ensembles IC with cosine similarity of summed word embeddings with an IDF weighting scheme."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another ensembles IC with Sultan et al. (2015)\u2019s alignment method, while a third ensembles IC with cosine similarity of summed"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 99
                            }
                        ],
                        "text": "MT is used to incorporate a similarity score based on Brychcin and Svoboda (2016)\u2019s improvements to Sultan et al. (2015)\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7450224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0fb3ab6dfdf9c351e2c837e480850b4186aa961",
            "isKey": true,
            "numCitedBy": 109,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a set of top-performing systems at the SemEval 2015 English Semantic Textual Similarity (STS) task. Given two English sentences, each system outputs the degree of their semantic similarity. Our unsupervised system, which is based on word alignments across the two input sentences, ranked 5th among 73 submitted system runs with a mean correlation of 79.19% with human annotations. We also submitted two runs of a supervised system which uses word alignments and similarities between compositional sentence vectors as its features. Our best supervised run ranked 1st with a mean correlation of 80.15%."
            },
            "slug": "DLS@CU:-Sentence-Similarity-from-Word-Alignment-and-Sultan-Bethard",
            "title": {
                "fragments": [],
                "text": "DLS@CU: Sentence Similarity from Word Alignment and Semantic Vector Composition"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A set of top-performing systems at the SemEval 2015 English Semantic Textual Similarity (STS) task, which uses word alignments and similarities between compositional sentence vectors as its features."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111892870"
                        ],
                        "name": "Hua He",
                        "slug": "Hua-He",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 260
                            }
                        ],
                        "text": "\u2026semantic representations (i.a., Arora et al. (2017); Conneau et al. (2017); Mu et al. (2017); Pagliardini et al. (2017); Wieting and Gimpel (2017); He and Lin (2016); Hill et al. (2016); Kenter et al. (2016); Lau and Baldwin (2016); Wieting et al. (2016a,b); He et al. (2015); Pham et al. (2015))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7413367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae3e2451491f7d6ea1ee0c587fd8c811b4200c07",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling sentence similarity is complicated by the ambiguity and variability of linguistic expression. To cope with these challenges, we propose a model for comparing sentences that uses a multiplicity of perspectives. We first model each sentence using a convolutional neural network that extracts features at multiple levels of granularity and uses multiple types of pooling. We then compare our sentence representations at several granularities using multiple similarity metrics. We apply our model to three tasks, including the Microsoft Research paraphrase identification task and two SemEval semantic textual similarity tasks. We obtain strong performance on all tasks, rivaling or exceeding the state of the art without using external resources such as WordNet or parsers."
            },
            "slug": "Multi-Perspective-Sentence-Similarity-Modeling-with-He-Gimpel",
            "title": {
                "fragments": [],
                "text": "Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a model for comparing sentences that uses a multiplicity of perspectives, first model each sentence using a convolutional neural network that extracts features at multiple levels of granularity and uses multiple types of pooling."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771118"
                        ],
                        "name": "J. Wieting",
                        "slug": "J.-Wieting",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wieting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wieting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10668422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a6d2e134b3b2df6291af8e36e126ae55d50649c",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning general-purpose, paraphrastic sentence embeddings, revisiting the setting of Wieting et al. (2016b). While they found LSTM recurrent networks to underperform word averaging, we present several developments that together produce the opposite conclusion. These include training on sentence pairs rather than phrase pairs, averaging states to represent sequences, and regularizing aggressively. These improve LSTMs in both transfer learning and supervised settings. We also introduce a new recurrent architecture, the Gated Recurrent Averaging Network, that is inspired by averaging and LSTMs while outperforming them both. We analyze our learned models, finding evidence of preferences for particular parts of speech and dependency relations."
            },
            "slug": "Revisiting-Recurrent-Networks-for-Paraphrastic-Wieting-Gimpel",
            "title": {
                "fragments": [],
                "text": "Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work considers the problem of learning general-purpose, paraphrastic sentence embeddings, revisiting the setting of Wieting et al. (2016b), and presents several developments that together produce the opposite conclusion."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3450996"
                        ],
                        "name": "Ryan Kiros",
                        "slug": "Ryan-Kiros",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Kiros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844940337"
                        ],
                        "name": "Yukun Zhu",
                        "slug": "Yukun-Zhu",
                        "structuredName": {
                            "firstName": "Yukun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yukun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37895334"
                        ],
                        "name": "S. Fidler",
                        "slug": "S.-Fidler",
                        "structuredName": {
                            "firstName": "Sanja",
                            "lastName": "Fidler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fidler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9126867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "isKey": false,
            "numCitedBy": 1928,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice."
            },
            "slug": "Skip-Thought-Vectors-Kiros-Zhu",
            "title": {
                "fragments": [],
                "text": "Skip-Thought Vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The approach for unsupervised learning of a generic, distributed sentence encoder is described, using the continuity of text from books to train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800564"
                        ],
                        "name": "Jey Han Lau",
                        "slug": "Jey-Han-Lau",
                        "structuredName": {
                            "firstName": "Jey",
                            "lastName": "Lau",
                            "middleNames": [
                                "Han"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jey Han Lau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145465286"
                        ],
                        "name": "Timothy Baldwin",
                        "slug": "Timothy-Baldwin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Baldwin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Baldwin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 38
                            }
                        ],
                        "text": "0 PV-DBOW Paragraph vectors (PV-DBOW) (Le and Mikolov, 2014; Lau and Baldwin, 2016) 72."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 149
                            }
                        ],
                        "text": "All baselines were run by the organizers using canonical pre-trained models made available by the originator of each method,25 with the exception of PV-DBOW that\n23Similar to the STS shared task, while the training set is provided as a convenience, researchers are encourage to incorporate other supervised and unsupervised data as long as no supervised annotations of the test partitions are used."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 333,
                                "start": 326
                            }
                        ],
                        "text": "LexVec: numbers were converted into words, all punctuation was removed, and text is lowercased; FastText: sentences are prepared using the normalize text() function within FastText\u2019s get-wikimedia.sh script and lowercased; Paragram: Joshua (Matt Post, 2015) pipeline to pre-process and tokenized English text; C-PHRASE, GloVe, PV-DBOW &\ninference hyperparameters are used unless noted otherwise."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5163433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d0c1a5933caa3e5f1e21d7cb676ca2bfab32ab",
            "isKey": false,
            "numCitedBy": 482,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al., 2013a) to learn document-level embeddings. Despite promising results in the original paper, others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models."
            },
            "slug": "An-Empirical-Evaluation-of-doc2vec-with-Practical-Lau-Baldwin",
            "title": {
                "fragments": [],
                "text": "An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings."
            },
            "venue": {
                "fragments": [],
                "text": "Rep4NLP@ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725643"
                        ],
                        "name": "Yun-Nung (Vivian) Chen",
                        "slug": "Yun-Nung-(Vivian)-Chen",
                        "structuredName": {
                            "firstName": "Yun-Nung",
                            "lastName": "Chen",
                            "middleNames": [
                                "(Vivian)"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yun-Nung (Vivian) Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395813836"
                        ],
                        "name": "Dilek Z. Hakkani-T\u00fcr",
                        "slug": "Dilek-Z.-Hakkani-T\u00fcr",
                        "structuredName": {
                            "firstName": "Dilek",
                            "lastName": "Hakkani-T\u00fcr",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dilek Z. Hakkani-T\u00fcr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50045602"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 138
                            }
                        ],
                        "text": "HCTI (Shao, 2017) Third place overall is obtained by HCTI with a model similar to a convolutional Deep Structured Semantic Model (CDSSM) (Chen et al., 2015; Huang et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 182
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component\n18RTV took first place on track 5, English, but submitted no system description paper."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8899626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da9b26a465cae37c93c7c68b0208b8e116c2a05",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent surge of intelligent personal assistants motivates spoken language understanding of dialogue systems. Considering high-level semantics, intent embeddings can be viewed as the universal representations that help derive a more flexible intent schema to overcome the domain constraint and the genre mismatch. A convolutional deep structured semantic model (CDSSM) is applied to jointly learn the representations for human intents and associated utterances. Two sets of experiments, intent expansion and actionable item detection, are conducted to evaluate the power of the learned intent embeddings. The representations bridge the semantic relation between seen and unseen intents for intent expansion, and connect intents from different genres for actionable item detection. The discussion and analysis of experiments provide a future direction for reducing human effort of data annotation and eliminating domain and genre constraints for spoken language understanding."
            },
            "slug": "Learning-Bidirectional-Intent-Embeddings-by-Deep-Chen-Hakkani-T\u00fcr",
            "title": {
                "fragments": [],
                "text": "Learning Bidirectional Intent Embeddings by Convolutional Deep Structured Semantic Models for Spoken Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A convolutional deep structured semantic model (CDSSM) is applied to jointly learn the representations for human intents and associated utterances that bridge the semantic relation between seen and unseen intents for intent expansion, and connect intents from different genres for actionable item detection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136562"
                        ],
                        "name": "Mohit Iyyer",
                        "slug": "Mohit-Iyyer",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Iyyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Iyyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1977256"
                        ],
                        "name": "Varun Manjunatha",
                        "slug": "Varun-Manjunatha",
                        "structuredName": {
                            "firstName": "Varun",
                            "lastName": "Manjunatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varun Manjunatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389036863"
                        ],
                        "name": "Jordan L. Boyd-Graber",
                        "slug": "Jordan-L.-Boyd-Graber",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Boyd-Graber",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordan L. Boyd-Graber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 186
                            }
                        ],
                        "text": "ECNU\u2019s deep learning models are differentiated by their approach to sentence embeddings using either: averaged word embeddings, projected word embeddings, a deep averaging network (DAN) (Iyyer et al., 2015) or LSTM (Hochreiter and Schmidhuber, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 11
                            }
                        ],
                        "text": "work (DAN) (Iyyer et al., 2015) or LSTM (Hochreiter and Schmidhuber, 1997)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 216848261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d86227948b6000e5d7ed63cf2054ad600b7994a0",
            "isKey": false,
            "numCitedBy": 672,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Many existing deep learning models for natural language processing tasks focus on learning the compositionality of their inputs, which requires many expensive computations. We present a simple deep neural network that competes with and, in some cases, outperforms such models on sentiment analysis and factoid question answering tasks while taking only a fraction of the training time. While our model is syntactically-ignorant, we show significant improvements over previous bag-of-words models by deepening our network and applying a novel variant of dropout. Moreover, our model performs better than syntactic models on datasets with high syntactic variance. We show that our model makes similar errors to syntactically-aware models, indicating that for the tasks we consider, nonlinearly transforming the input is more important than tailoring a network to incorporate word order and syntax."
            },
            "slug": "Deep-Unordered-Composition-Rivals-Syntactic-Methods-Iyyer-Manjunatha",
            "title": {
                "fragments": [],
                "text": "Deep Unordered Composition Rivals Syntactic Methods for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents a simple deep neural network that competes with and, in some cases, outperforms such models on sentiment analysis and factoid question answering tasks while taking only a fraction of the training time."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064348170"
                        ],
                        "name": "C. Buck",
                        "slug": "C.-Buck",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3359291"
                        ],
                        "name": "C. Federmann",
                        "slug": "C.-Federmann",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Federmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Federmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259100"
                        ],
                        "name": "B. Haddow",
                        "slug": "B.-Haddow",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Haddow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Haddow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696402"
                        ],
                        "name": "Christof Monz",
                        "slug": "Christof-Monz",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Monz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Monz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38842528"
                        ],
                        "name": "Matt Post",
                        "slug": "Matt-Post",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Post",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Post"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737285"
                        ],
                        "name": "Radu Soricut",
                        "slug": "Radu-Soricut",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Soricut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radu Soricut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702974"
                        ],
                        "name": "Lucia Specia",
                        "slug": "Lucia-Specia",
                        "structuredName": {
                            "firstName": "Lucia",
                            "lastName": "Specia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucia Specia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 145
                            }
                        ],
                        "text": "We release one thousand new SpanishEnglish STS pairs sourced from the 2013 WMT translation task and produced by a phrase-based Moses SMT system (Bojar et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1009868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7de66a09cd23f05859a95fa55616b515acab71e9",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task. This year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. The quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries."
            },
            "slug": "Findings-of-the-2013-Workshop-on-Statistical-Bojar-Buck",
            "title": {
                "fragments": [],
                "text": "Findings of the 2013 Workshop on Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task are presented."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2457790"
                        ],
                        "name": "Jiaqi Mu",
                        "slug": "Jiaqi-Mu",
                        "structuredName": {
                            "firstName": "Jiaqi",
                            "lastName": "Mu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiaqi Mu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145355558"
                        ],
                        "name": "S. Bhat",
                        "slug": "S.-Bhat",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Bhat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768649"
                        ],
                        "name": "P. Viswanath",
                        "slug": "P.-Viswanath",
                        "structuredName": {
                            "firstName": "Pramod",
                            "lastName": "Viswanath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Viswanath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 150
                            }
                        ],
                        "text": "\u2026have been used extensively for research on sentence level similarity and semantic representations (i.a., Arora et al. (2017); Conneau et al. (2017); Mu et al. (2017); Pagliardini et al. (2017); Wieting and Gimpel (2017); He and Lin (2016); Hill et al. (2016); Kenter et al. (2016); Lau and Baldwin\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14193214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93924b5fa5c54bda5a405ffb04f5ff37e0473088",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Sentences are important semantic units of natural language. A generic, distributional representation of sentences that can capture the latent semantics is beneficial to multiple downstream applications. We observe a simple geometry of sentences \u2013 the word representations of a given sentence (on average 10.23 words in all SemEval datasets with a standard deviation 4.84) roughly lie in a low-rank subspace (roughly, rank 4). Motivated by this observation, we represent a sentence by the low-rank subspace spanned by its word vectors. Such an unsupervised representation is empirically validated via semantic textual similarity tasks on 19 different datasets, where it outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average."
            },
            "slug": "Representing-Sentences-as-Low-Rank-Subspaces-Mu-Bhat",
            "title": {
                "fragments": [],
                "text": "Representing Sentences as Low-Rank Subspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work represents a sentence by the low-rank subspace spanned by its word vectors, and finds that this unsupervised representation outperforms the sophisticated neural network models, including skip-thought vectors, by 15% on average."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752875"
                        ],
                        "name": "Yelong Shen",
                        "slug": "Yelong-Shen",
                        "structuredName": {
                            "firstName": "Yelong",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yelong Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1935910"
                        ],
                        "name": "G. Mesnil",
                        "slug": "G.-Mesnil",
                        "structuredName": {
                            "firstName": "Gr\u00e9goire",
                            "lastName": "Mesnil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mesnil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 130
                            }
                        ],
                        "text": "HCTI (Shao, 2017) Third place overall is obtained by HCTI with a model similar to a convolutional Deep Structured Semantic Model (CDSSM) (Chen et al., 2015; Huang et al., 2013)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": ", 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 182
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component\n18RTV took first place on track 5, English, but submitted no system description paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 145
                            }
                        ],
                        "text": "\u2026on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207218382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e8d5a108c28cdfb92f419ce919fbf7993dfebfc",
            "isKey": true,
            "numCitedBy": 590,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new latent semantic model that incorporates a convolutional-pooling structure over word sequences to learn low-dimensional, semantic vector representations for search queries and Web documents. In order to capture the rich contextual structures in a query or a document, we start with each word within a temporal context window in a word sequence to directly capture contextual features at the word n-gram level. Next, the salient word n-gram features in the word sequence are discovered by the model and are then aggregated to form a sentence-level feature vector. Finally, a non-linear transformation is applied to extract high-level semantic information to generate a continuous vector representation for the full text string. The proposed convolutional latent semantic model (CLSM) is trained on clickthrough data and is evaluated on a Web document ranking task using a large-scale, real-world data set. Results show that the proposed model effectively captures salient semantic information in queries and documents for the task while significantly outperforming previous state-of-the-art semantic models."
            },
            "slug": "A-Latent-Semantic-Model-with-Convolutional-Pooling-Shen-He",
            "title": {
                "fragments": [],
                "text": "A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new latent semantic model that incorporates a convolutional-pooling structure over word sequences to learn low-dimensional, semantic vector representations for search queries and Web documents is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111892870"
                        ],
                        "name": "Hua He",
                        "slug": "Hua-He",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16787742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29006d8c9c2247fca4cd3a22822c2b042e85572d",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Textual similarity measurement is a challenging problem, as it requires understanding the semantics of input sentences. Most previous neural network models use coarse-grained sentence modeling, which has difficulty capturing fine-grained word-level information for semantic comparisons. As an alternative, we propose to explicitly model pairwise word interactions and present a novel similarity focus mechanism to identify important correspondences for better similarity measurement. Our ideas are implemented in a novel neural network architecture that demonstrates state-ofthe-art accuracy on three SemEval tasks and two answer selection tasks."
            },
            "slug": "Pairwise-Word-Interaction-Modeling-with-Deep-Neural-He-Lin",
            "title": {
                "fragments": [],
                "text": "Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to explicitly model pairwise word interactions and present a novel similarity focus mechanism to identify important correspondences for better similarity measurement."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421691"
                        ],
                        "name": "Po-Sen Huang",
                        "slug": "Po-Sen-Huang",
                        "structuredName": {
                            "firstName": "Po-Sen",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Po-Sen Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46819684"
                        ],
                        "name": "Larry Heck",
                        "slug": "Larry-Heck",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Heck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Larry Heck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 157
                            }
                        ],
                        "text": "HCTI (Shao, 2017) Third place overall is obtained by HCTI with a model similar to a convolutional Deep Structured Semantic Model (CDSSM) (Chen et al., 2015; Huang et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 182
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component\n18RTV took first place on track 5, English, but submitted no system description paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 144
                            }
                        ],
                        "text": "\u2026et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 136
                            }
                        ],
                        "text": ", 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8384258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdb813d8b927bdd21ae1858cafa6c34b66a36268",
            "isKey": true,
            "numCitedBy": 1451,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent semantic models, such as LSA, intend to map a query to its relevant documents at the semantic level where keyword-based matching often fails. In this study we strive to develop a series of new latent semantic models with a deep structure that project queries and documents into a common low-dimensional space where the relevance of a document given a query is readily computed as the distance between them. The proposed deep structured semantic models are discriminatively trained by maximizing the conditional likelihood of the clicked documents given a query using the clickthrough data. To make our models applicable to large-scale Web search applications, we also use a technique called word hashing, which is shown to effectively scale up our semantic models to handle large vocabularies which are common in such tasks. The new models are evaluated on a Web document ranking task using a real-world data set. Results show that our best model significantly outperforms other latent semantic models, which were considered state-of-the-art in the performance prior to the work presented in this paper."
            },
            "slug": "Learning-deep-structured-semantic-models-for-web-Huang-He",
            "title": {
                "fragments": [],
                "text": "Learning deep structured semantic models for web search using clickthrough data"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A series of new latent semantic models with a deep structure that project queries and documents into a common low-dimensional space where the relevance of a document given a query is readily computed as the distance between them are developed."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2237884"
                        ],
                        "name": "Ergun Bi\u00e7ici",
                        "slug": "Ergun-Bi\u00e7ici",
                        "structuredName": {
                            "firstName": "Ergun",
                            "lastName": "Bi\u00e7ici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ergun Bi\u00e7ici"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 94635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc05bc231e843697b0013121618535c77c3b3bf0",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Referential translation machines achieve top performance in both bilingual and monolingual settings without accessing any task or domain specific information or resource. RTMs achieve the 3rd system results for German to English sentence-level prediction of translation quality and the 2nd system results according to root mean squared error. In addition to the new features about substring distances, punctuation tokens, character n-grams, and alignment crossings, and additional learning models, we average prediction scores from different models using weights based on their training performance for improved results."
            },
            "slug": "Predicting-Translation-Performance-with-Referential-Bi\u00e7ici",
            "title": {
                "fragments": [],
                "text": "Predicting Translation Performance with Referential Translation Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "In addition to the new features about substring distances, punctuation tokens, character n-grams, and alignment crossings, and additional learning models, average prediction scores from different models using weights based on their training performance for improved results."
            },
            "venue": {
                "fragments": [],
                "text": "WMT"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922461"
                        ],
                        "name": "Tom Kenter",
                        "slug": "Tom-Kenter",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kenter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Kenter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143997426"
                        ],
                        "name": "Alexey Borisov",
                        "slug": "Alexey-Borisov",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Borisov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexey Borisov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696030"
                        ],
                        "name": "M. de Rijke",
                        "slug": "M.-de-Rijke",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "de Rijke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. de Rijke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 188
                            }
                        ],
                        "text": "\u2026semantic representations (i.a., Arora et al. (2017); Conneau et al. (2017); Mu et al. (2017); Pagliardini et al. (2017); Wieting and Gimpel (2017); He and Lin (2016); Hill et al. (2016); Kenter et al. (2016); Lau and Baldwin (2016); Wieting et al. (2016a,b); He et al. (2015); Pham et al. (2015))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12998432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f5d5a74572f272b919ca383ee47cb6663d38d62",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the Siamese Continuous Bag of Words (Siamese CBOW) model, a neural network for efficient estimation of high-quality sentence embeddings. Averaging the embeddings of words in a sentence has proven to be a surprisingly successful and efficient way of obtaining sentence embeddings. However, word embeddings trained with the methods currently available are not optimized for the task of sentence representation, and, thus, likely to be suboptimal. Siamese CBOW handles this problem by training word embeddings directly for the purpose of being averaged. The underlying neural network learns word embeddings by predicting, from a sentence representation, its surrounding sentences. We show the robustness of the Siamese CBOW model by evaluating it on 20 datasets stemming from a wide variety of sources."
            },
            "slug": "Siamese-CBOW:-Optimizing-Word-Embeddings-for-Kenter-Borisov",
            "title": {
                "fragments": [],
                "text": "Siamese CBOW: Optimizing Word Embeddings for Sentence Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The Siamese Continuous Bag of Words model is presented, a neural network for efficient estimation of high-quality sentence embeddings and the robustness of theSiamese CBOW model is shown by evaluating it on 20 datasets stemming from a wide variety of sources."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32278254"
                        ],
                        "name": "Matthew G. Snover",
                        "slug": "Matthew-G.-Snover",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Snover",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew G. Snover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752326"
                        ],
                        "name": "B. Dorr",
                        "slug": "B.-Dorr",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Dorr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dorr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333779"
                        ],
                        "name": "L. Micciulla",
                        "slug": "L.-Micciulla",
                        "structuredName": {
                            "firstName": "Linnea",
                            "lastName": "Micciulla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Micciulla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14226,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a5899f1ec92af7d01f35225161430116a6eabbea",
            "isKey": false,
            "numCitedBy": 1633,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a new, intuitive measure for evaluating machine translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments. Translation Error Rate (TER) measures the amount of editing that a human would have to perform to change a system output so it exactly matches a reference translation. We also compute a human-targeted TER (or HTER), where the minimum TER of the translation is computed against a human \u2018targeted reference\u2019 that preserves the meaning (provided by the reference translations) and is fluent, but is chosen to minimize the TER score for a particular system output. We show that: (1) The single-reference variant of TER correlates as well with human judgments of MT quality as the four-reference variant of BLEU; (2) The human-targeted HTER yields a 33% error-rate reduction and is shown to be very well correlated with human judgments; (3) The four-reference variant of TER and the single-reference variant of HTER yield higher correlations with human judgments than BLEU; (4) HTER yields higher correlations with human judgments than METEOR or its human-targeted variant (HMETEOR); and (5) The four-reference variant of TER correlates as well with a single human judgment as a second human judgment does, while HTER, HBLEU, and HMETEOR correlate significantly better with a human judgment than a second human judgment does."
            },
            "slug": "A-STUDY-OF-TRANSLATION-ERROR-RATE-WITH-TARGETED-Snover-Dorr",
            "title": {
                "fragments": [],
                "text": "A STUDY OF TRANSLATION ERROR RATE WITH TARGETED HUMAN ANNOTATION"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A new, intuitive measure for evaluating machine translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments is defined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064348170"
                        ],
                        "name": "C. Buck",
                        "slug": "C.-Buck",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3359291"
                        ],
                        "name": "C. Federmann",
                        "slug": "C.-Federmann",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Federmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Federmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259100"
                        ],
                        "name": "B. Haddow",
                        "slug": "B.-Haddow",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Haddow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Haddow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725514"
                        ],
                        "name": "Johannes Leveling",
                        "slug": "Johannes-Leveling",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Leveling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johannes Leveling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696402"
                        ],
                        "name": "Christof Monz",
                        "slug": "Christof-Monz",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Monz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Monz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758528"
                        ],
                        "name": "Pavel Pecina",
                        "slug": "Pavel-Pecina",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Pecina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pavel Pecina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38842528"
                        ],
                        "name": "Matt Post",
                        "slug": "Matt-Post",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Post",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Post"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404569159"
                        ],
                        "name": "Herve Saint-Amand",
                        "slug": "Herve-Saint-Amand",
                        "structuredName": {
                            "firstName": "Herve",
                            "lastName": "Saint-Amand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herve Saint-Amand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737285"
                        ],
                        "name": "Radu Soricut",
                        "slug": "Radu-Soricut",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Soricut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radu Soricut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702974"
                        ],
                        "name": "Lucia Specia",
                        "slug": "Lucia-Specia",
                        "structuredName": {
                            "firstName": "Lucia",
                            "lastName": "Specia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucia Specia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2211536"
                        ],
                        "name": "A. Tamchyna",
                        "slug": "A.-Tamchyna",
                        "structuredName": {
                            "firstName": "Ales",
                            "lastName": "Tamchyna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tamchyna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15535376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc",
            "isKey": false,
            "numCitedBy": 429,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of the WMT14 shared tasks, which included a standard news translation task, a separate medical translation task, a task for run-time estimation of machine translation quality, and a metrics task. This year, 143 machine translation systems from 23 institutions were submitted to the ten translation directions in the standard translation task. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had four subtasks, with a total of 10 teams, submitting 57 entries"
            },
            "slug": "Findings-of-the-2014-Workshop-on-Statistical-Bojar-Buck",
            "title": {
                "fragments": [],
                "text": "Findings of the 2014 Workshop on Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The results of the WMT14 shared tasks, which included a standard news translation task, a separate medical translationtask, a task for run-time estimation of machine translation quality, and a metrics task, are presented."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480903"
                        ],
                        "name": "A. Conneau",
                        "slug": "A.-Conneau",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Conneau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Conneau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743722"
                        ],
                        "name": "Douwe Kiela",
                        "slug": "Douwe-Kiela",
                        "structuredName": {
                            "firstName": "Douwe",
                            "lastName": "Kiela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douwe Kiela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934336"
                        ],
                        "name": "Lo\u00efc Barrault",
                        "slug": "Lo\u00efc-Barrault",
                        "structuredName": {
                            "firstName": "Lo\u00efc",
                            "lastName": "Barrault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lo\u00efc Barrault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026shared task data sets have been used extensively for research on sentence level similarity and semantic representations (i.a., Arora et al. (2017); Conneau et al. (2017); Mu et al. (2017); Pagliardini et al. (2017); Wieting and Gimpel (2017); He and Lin (2016); Hill et al. (2016); Kenter et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 41
                            }
                        ],
                        "text": "from bi-directional LSTM trained on SNLI (Conneau et al., 2017) 80."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28971531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c",
            "isKey": false,
            "numCitedBy": 1513,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available."
            },
            "slug": "Supervised-Learning-of-Universal-Sentence-from-Data-Conneau-Kiela",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32301760"
                        ],
                        "name": "Gabor Angeli",
                        "slug": "Gabor-Angeli",
                        "structuredName": {
                            "firstName": "Gabor",
                            "lastName": "Angeli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabor Angeli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 138
                            }
                        ],
                        "text": "HCTI (Shao, 2017) Third place overall is obtained by HCTI with a model similar to a convolutional Deep Structured Semantic Model (CDSSM) (Chen et al., 2015; Huang et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 182
                            }
                        ],
                        "text": "DT Team (Maharjan et al., 2017) Second place on English (track 5)18 is DT Team using feature engineering combined with the following deep learning models: DSSM (Huang et al., 2013), CDSSM (Shen et al., 2014) and skip-thoughts (Kiros et al.,\n17The approach is similar to SIF (Arora et al., 2017) but without removal of the common principle component\n18RTV took first place on track 5, English, but submitted no system description paper."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14604520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f04df4e20a18358ea2f689b4c129781628ef7fc1",
            "isKey": false,
            "numCitedBy": 2518,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time."
            },
            "slug": "A-large-annotated-corpus-for-learning-natural-Bowman-Angeli",
            "title": {
                "fragments": [],
                "text": "A large annotated corpus for learning natural language inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Stanford Natural Language Inference corpus is introduced, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning, which allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32278254"
                        ],
                        "name": "Matthew G. Snover",
                        "slug": "Matthew-G.-Snover",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Snover",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew G. Snover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752326"
                        ],
                        "name": "B. Dorr",
                        "slug": "B.-Dorr",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Dorr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dorr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901366"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333779"
                        ],
                        "name": "L. Micciulla",
                        "slug": "L.-Micciulla",
                        "structuredName": {
                            "firstName": "Linnea",
                            "lastName": "Micciulla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Micciulla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 123
                            }
                        ],
                        "text": "are annotated with the time required for human correction by post-editing and Human-targeted Translation Error Rate (HTER) (Snover et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 1
                            }
                        ],
                        "text": "4HTER is the minimal number of edits required for correction of a translation divided by its length after correction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 137
                            }
                        ],
                        "text": "Translations are annotated with the time required for human correction by post-editing and Human-targeted Translation Error Rate (HTER) (Snover et al., 2006).4 Participants are not allowed to use the gold quality estimation annotations to inform STS scores."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8938789,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "51951073580f6995e55be873db9a7f6a9736ca86",
            "isKey": true,
            "numCitedBy": 2219,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine a new, intuitive measure for evaluating machine-translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments. Translation Edit Rate (TER) measures the amount of editing that a human would have to perform to change a system output so it exactly matches a reference translation. We show that the single-reference variant of TER correlates as well with human judgments of MT quality as the four-reference variant of BLEU. We also define a human-targeted TER (or HTER) and show that it yields higher correlations with human judgments than BLEU\u2014even when BLEU is given human-targeted references. Our results indicate that HTER correlates with human judgments better than HMETEOR and that the four-reference variants of TER and HTER correlate with human judgments as well as\u2014or better than\u2014a second human judgment does."
            },
            "slug": "A-Study-of-Translation-Edit-Rate-with-Targeted-Snover-Dorr",
            "title": {
                "fragments": [],
                "text": "A Study of Translation Edit Rate with Targeted Human Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new, intuitive measure for evaluating machine-translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments is examined, which indicates that HTER correlates with human judgments better than HMETEOR and that the four-reference variants of TER and HTER correlate withhuman judgments as well as\u2014or better than\u2014a second human judgment does."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145410481"
                        ],
                        "name": "Sergio Jim\u00e9nez",
                        "slug": "Sergio-Jim\u00e9nez",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Jim\u00e9nez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergio Jim\u00e9nez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20957851"
                        ],
                        "name": "C. Becerra",
                        "slug": "C.-Becerra",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Becerra",
                            "middleNames": [
                                "Jeanneth"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Becerra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747784"
                        ],
                        "name": "Alexander Gelbukh",
                        "slug": "Alexander-Gelbukh",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Gelbukh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Gelbukh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7640960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78b3d9cd136bb04e79d5d52ec7e4f5d068759d88",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for the construction of text similarity functions using a parameterized resemblance coefficient in combination with a softened cardinality function called soft cardinality. Our approach provides a consistent and recursive model, varying levels of granularity from sentences to characters. Therefore, our model was used to compare sentences divided into words, and in turn, words divided into q-grams of characters. Experimentally, we observed that a performance correlation function in a space defined by all parameters was relatively smooth and had a single maximum achievable by \"hill climbing.\" Our approach used only surface text information, a stop-word remover, and a stemmer to tackle the semantic text similarity task 6 at SEMEVAL 2012. The proposed method ranked 3rd (average), 5th (normalized correlation), and 15th (aggregated correlation) among 89 systems submitted by 31 teams."
            },
            "slug": "Soft-Cardinality:-A-Parameterized-Similarity-for-Jim\u00e9nez-Becerra",
            "title": {
                "fragments": [],
                "text": "Soft Cardinality: A Parameterized Similarity Function for Text Comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work presents an approach for the construction of text similarity functions using a parameterized resemblance coefficient in combination with a softened cardinality function called soft cardinality, which provides a consistent and recursive model, varying levels of granularity from sentences to characters."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 44
                            }
                        ],
                        "text": "We use 50-dimensional GloVe word embeddings (Pennington et al., 2014) trained on a combination of Gigaword 5 (Parker et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 48
                            }
                        ],
                        "text": "1 GloVe Word co-occurrence count fit embeddings (Pennington et al., 2014) 52."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 46
                            }
                        ],
                        "text": "7We use 50-dimensional GloVe word embeddings (Pennington et al., 2014) trained on a combination of Gigaword 5 (Parker et al., 2011) and English Wikipedia available at http://nlp.stanford.edu/projects/glove/."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": false,
            "numCitedBy": 22536,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733928"
                        ],
                        "name": "R. Navigli",
                        "slug": "R.-Navigli",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Navigli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Navigli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801255"
                        ],
                        "name": "Simone Paolo Ponzetto",
                        "slug": "Simone-Paolo-Ponzetto",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Ponzetto",
                            "middleNames": [
                                "Paolo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simone Paolo Ponzetto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "BabelNet synsets are multilingual allowing non-English and cross-lingual pairs to be processed similarly to English pairs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 89
                            }
                        ],
                        "text": ", 2017) Fifth place overall is FCICU that computes a sense-base alignment using BabelNet (Navigli and Ponzetto, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 100
                            }
                        ],
                        "text": "FCICU (Hassan et al., 2017) Fifth place overall is FCICU that computes a sense-base alignment using BabelNet (Navigli and Ponzetto, 2010)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2085726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31d33747d8fff0b7a0c40dcf9944015af9a15b1a",
            "isKey": false,
            "numCitedBy": 529,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present BabelNet -- a very large, wide-coverage multilingual semantic network. The resource is automatically constructed by means of a methodology that integrates lexicographic and encyclopedic knowledge from WordNet and Wikipedia. In addition Machine Translation is also applied to enrich the resource with lexical information for all languages. We conduct experiments on new and existing gold-standard datasets to show the high quality and coverage of the resource."
            },
            "slug": "BabelNet:-Building-a-Very-Large-Multilingual-Navigli-Ponzetto",
            "title": {
                "fragments": [],
                "text": "BabelNet: Building a Very Large Multilingual Semantic Network"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A very large, wide-coverage multilingual semantic network that integrates lexicographic and encyclopedic knowledge from WordNet and Wikipedia and Machine Translation is also applied to enrich the resource with lexical information for all languages."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146380510"
                        ],
                        "name": "Qian Chen",
                        "slug": "Qian-Chen",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854999"
                        ],
                        "name": "Xiao-Dan Zhu",
                        "slug": "Xiao-Dan-Zhu",
                        "structuredName": {
                            "firstName": "Xiao-Dan",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Dan Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749989"
                        ],
                        "name": "Zhenhua Ling",
                        "slug": "Zhenhua-Ling",
                        "structuredName": {
                            "firstName": "Zhenhua",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenhua Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572674"
                        ],
                        "name": "Si Wei",
                        "slug": "Si-Wei",
                        "structuredName": {
                            "firstName": "Si",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Si Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36357862"
                        ],
                        "name": "Hui Jiang",
                        "slug": "Hui-Jiang",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Jiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 211
                            }
                        ],
                        "text": "matching n-grams, summarization and MT metrics (BLEU, WER, PER, ROUGE); a RNN and recurrent convolutional neural networks (RCNN) over word alignments; and a BiLSTM that is state-ofthe-art for textual entailment (Chen et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 275
                            }
                        ],
                        "text": "\u2026STS (S\u030caric\u0301 et al., 2012b); string similarity measures such as matching n-grams, summarization and MT metrics (BLEU, WER, PER, ROUGE); a RNN and recurrent convolutional neural networks (RCNN) over word alignments; and a BiLSTM that is state-ofthe-art for textual entailment (Chen et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15096632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162db03ef3cb50a07ff54ae4a1d4ea120e4162f2",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is notoriously challenging but is fundamental to natural language understanding and many applications. With the availability of large annotated data, neural network models have recently advanced the field significantly. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.3% on the standard benchmark, the Stanford Natural Language Inference dataset. This result is achieved first through our enhanced sequential encoding model, which outperforms the previous best model that employs more complicated network architectures, suggesting that the potential of sequential LSTM-based models have not been fully explored yet in previous work. We further show that by explicitly considering recursive architectures, we achieve additional improvement. Particularly, incorporating syntactic parse information contributes to our best result; it improves the performance even when the parse information is added to an already very strong system."
            },
            "slug": "Enhancing-and-Combining-Sequential-and-Tree-LSTM-Chen-Zhu",
            "title": {
                "fragments": [],
                "text": "Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a new state-of-the-art result, achieving the accuracy of 88.3% on the standard benchmark, the Stanford Natural Language Inference dataset, through an enhanced sequential encoding model, which outperforms the previous best model that employs more complicated network architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2267212"
                        ],
                        "name": "Juri Ganitkevitch",
                        "slug": "Juri-Ganitkevitch",
                        "structuredName": {
                            "firstName": "Juri",
                            "lastName": "Ganitkevitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juri Ganitkevitch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 225
                            }
                        ],
                        "text": "Semantic inference tasks related to\nSTS include textual entailment (Bentivogli et al., 2016; Bowman et al., 2015; Dagan et al., 2010), semantic relatedness (Bentivogli et al., 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6067240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef12383f516840ec1ec998cd5921dfc6e197c9b2",
            "isKey": false,
            "numCitedBy": 691,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the 1.0 release of our paraphrase database, PPDB. Its English portion, PPDB:Eng, contains over 220 million paraphrase pairs, consisting of 73 million phrasal and 8 million lexical paraphrases, as well as 140 million paraphrase patterns, which capture many meaning-preserving syntactic transformations. The paraphrases are extracted from bilingual parallel corpora totaling over 100 million sentence pairs and over 2 billion English words. We also release PPDB:Spa, a collection of 196 million Spanish paraphrases. Each paraphrase pair in PPDB contains a set of associated scores, including paraphrase probabilities derived from the bitext data and a variety of monolingual distributional similarity scores computed from the Google n-grams and the Annotated Gigaword corpus. Our release includes pruning tools that allow users to determine their own precision/recall tradeoff."
            },
            "slug": "PPDB:-The-Paraphrase-Database-Ganitkevitch-Durme",
            "title": {
                "fragments": [],
                "text": "PPDB: The Paraphrase Database"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The 1.0 release of the paraphrase database, PPDB, contains over 220 million paraphrase pairs, consisting of 73 million phrasal and 8 million lexical paraphrases, as well as 140million paraphrase patterns, which capture many meaning-preserving syntactic transformations."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2702980"
                        ],
                        "name": "N. Pham",
                        "slug": "N.-Pham",
                        "structuredName": {
                            "firstName": "Nghia",
                            "lastName": "Pham",
                            "middleNames": [
                                "The"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067996"
                        ],
                        "name": "Germ\u00e1n Kruszewski",
                        "slug": "Germ\u00e1n-Kruszewski",
                        "structuredName": {
                            "firstName": "Germ\u00e1n",
                            "lastName": "Kruszewski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Germ\u00e1n Kruszewski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672644"
                        ],
                        "name": "Angeliki Lazaridou",
                        "slug": "Angeliki-Lazaridou",
                        "structuredName": {
                            "firstName": "Angeliki",
                            "lastName": "Lazaridou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angeliki Lazaridou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "8 C-PHRASE Prediction of syntactic constituent context words (Pham et al., 2015) 74."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10028211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55ba959b0193c418399fdda2a38d913a7f0b6ac4",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce C-PHRASE, a distributional semantic model that learns word representations by optimizing context prediction for phrases at all levels in a syntactic tree, from single words to full sentences. C-PHRASE outperforms the state-of-theart C-BOW model on a variety of lexical tasks. Moreover, since C-PHRASE word vectors are induced through a compositional learning objective (modeling the contexts of words combined into phrases), when they are summed, they produce sentence representations that rival those generated by ad-hoc compositional models."
            },
            "slug": "Jointly-optimizing-word-representations-for-lexical-Pham-Kruszewski",
            "title": {
                "fragments": [],
                "text": "Jointly optimizing word representations for lexical and sentential tasks with the C-PHRASE model"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "C-PHRASE, a distributional semantic model that learns word representations by optimizing context prediction for phrases at all levels in a syntactic tree, outperforms the state-of-theart C-BOW model on a variety of lexical tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749194"
                        ],
                        "name": "Collin F. Baker",
                        "slug": "Collin-F.-Baker",
                        "structuredName": {
                            "firstName": "Collin",
                            "lastName": "Baker",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Collin F. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406118956"
                        ],
                        "name": "John B. Lowe",
                        "slug": "John-B.-Lowe",
                        "structuredName": {
                            "firstName": "John B.",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John B. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 228
                            }
                        ],
                        "text": "Significant research effort has focused on STS over English sentence pairs.2 English STS is a\n1i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion fora, plagiarism, MT post-editing and Q&A data sets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 179
                            }
                        ],
                        "text": "\u2026sentence pairs.2 English STS is a\n1i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion fora, plagiarism, MT post-editing and Q&A data sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": ", news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2505531,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "547f23597f9ec8a93f66cedaa6fbfb73960426b1",
            "isKey": false,
            "numCitedBy": 2882,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, \"Tools for Lexicon Building\"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between \"frame elements\" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "slug": "The-Berkeley-FrameNet-Project-Baker-Fillmore",
            "title": {
                "fragments": [],
                "text": "The Berkeley FrameNet Project"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2435537"
                        ],
                        "name": "Matteo Pagliardini",
                        "slug": "Matteo-Pagliardini",
                        "structuredName": {
                            "firstName": "Matteo",
                            "lastName": "Pagliardini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matteo Pagliardini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46479926"
                        ],
                        "name": "Prakhar Gupta",
                        "slug": "Prakhar-Gupta",
                        "structuredName": {
                            "firstName": "Prakhar",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prakhar Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2456863"
                        ],
                        "name": "Martin Jaggi",
                        "slug": "Martin-Jaggi",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Jaggi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Jaggi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "7We use 50-dimensional GloVe word embeddings (Pennington et al., 2014) trained on a combination of Gigaword 5 (Parker et al., 2011) and English Wikipedia available at http://nlp.stanford.edu/projects/glove/."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16251657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7228d90f4241c7da5ca8e53182a2d89bf74db565",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings."
            },
            "slug": "Unsupervised-Learning-of-Sentence-Embeddings-Using-Pagliardini-Gupta",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Sentence Embeddings Using Compositional n-Gram Features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a simple but efficient unsupervised objective to train distributed representations of sentences, which outperforms the state-of-the-art un supervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771118"
                        ],
                        "name": "J. Wieting",
                        "slug": "J.-Wieting",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wieting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wieting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2924113"
                        ],
                        "name": "Karen Livescu",
                        "slug": "Karen-Livescu",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Livescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Livescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3202289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12e9d005c77f76e344361f79c4b008034ae547eb",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Charagram embeddings, a simple approach for learning character-based compositional models to embed textual sequences. A word or sentence is represented using a character n-gram count vector, followed by a single nonlinear transformation to yield a low-dimensional embedding. We use three tasks for evaluation: word similarity, sentence similarity, and part-of-speech tagging. We demonstrate that Charagram embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks."
            },
            "slug": "Charagram:-Embedding-Words-and-Sentences-via-Wieting-Bansal",
            "title": {
                "fragments": [],
                "text": "Charagram: Embedding Words and Sentences via Character n-grams"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is demonstrated that Charagram embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17089661"
                        ],
                        "name": "Alexandre Salle",
                        "slug": "Alexandre-Salle",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Salle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandre Salle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143974276"
                        ],
                        "name": "M. Idiart",
                        "slug": "M.-Idiart",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Idiart",
                            "middleNames": [
                                "A",
                                "P"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Idiart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145585242"
                        ],
                        "name": "Aline Villavicencio",
                        "slug": "Aline-Villavicencio",
                        "structuredName": {
                            "firstName": "Aline",
                            "lastName": "Villavicencio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aline Villavicencio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2333787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7867578988f79c552d25ff50bdac1cf398fa8324",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we take a state-of-the-art model for distributed word representation that explicitly factorizes the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling and address two of its shortcomings. We improve syntactic performance by using positional contexts, and solve the need to store the PPMI matrix in memory by working on aggregate data in external memory. The effectiveness of both modifications is shown using word similarity and analogy tasks."
            },
            "slug": "Enhancing-the-LexVec-Distributed-Word-Model-Using-Salle-Idiart",
            "title": {
                "fragments": [],
                "text": "Enhancing the LexVec Distributed Word Representation Model Using Positional Contexts and External Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper takes a state-of-the-art model for distributed word representation that explicitly factorizes the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling and addresses two of its shortcomings."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753940"
                        ],
                        "name": "Gilles S\u00e9rasset",
                        "slug": "Gilles-S\u00e9rasset",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "S\u00e9rasset",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles S\u00e9rasset"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 7
                            }
                        ],
                        "text": "DBNary (Serasset, 2015), MultiVec word embeddings (Berard et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6081690,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "eb8b4ae440b8f015f08416afaeb0b374620bd7e5",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Contributive resources, such as Wikipedia, have proved to be valuable to Natural Language Processing or multilingual Information Retrieval applications. This work focusses on Wiktionary, the dictionary part of the resources sponsored by the Wikimedia foundation. In this article, we present our extraction of multilingual lexical data from Wiktionary data and to provide it to the community as a Multilingual Lexical Linked Open Data (MLLOD). This lexical resource is structured using the LEMON Model. This data, called DBnary, is registered at http://thedatahub.org/dataset/dbnary."
            },
            "slug": "DBnary:-Wiktionary-as-a-Lemon-based-multilingual-in-S\u00e9rasset",
            "title": {
                "fragments": [],
                "text": "DBnary: Wiktionary as a Lemon-based multilingual lexical resource in RDF"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This article presents the extraction of multilingual lexical data from Wiktionary data and to provide it to the community as a Multilingual Lexical Linked Open Data (MLLOD)."
            },
            "venue": {
                "fragments": [],
                "text": "Semantic Web"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 168
                            }
                        ],
                        "text": "\u2026semantic representations (i.a., Arora et al. (2017); Conneau et al. (2017); Mu et al. (2017); Pagliardini et al. (2017); Wieting and Gimpel (2017); He and Lin (2016); Hill et al. (2016); Kenter et al. (2016); Lau and Baldwin (2016); Wieting et al. (2016a,b); He et al. (2015); Pham et al. (2015))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2937095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26e743d5bd465f49b9538deaf116c15e61b7951f",
            "isKey": false,
            "numCitedBy": 458,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance."
            },
            "slug": "Learning-Distributed-Representations-of-Sentences-Hill-Cho",
            "title": {
                "fragments": [],
                "text": "Learning Distributed Representations of Sentences from Unlabelled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A systematic comparison of models that learn distributed phrase or sentence representations from unlabelled data finds that the optimal approach depends critically on the intended application."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 38
                            }
                        ],
                        "text": "0 PV-DBOW Paragraph vectors (PV-DBOW) (Le and Mikolov, 2014; Lau and Baldwin, 2016) 72."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 4
                            }
                        ],
                        "text": "els (Le and Mikolov, 2014) are trained for Arabic, English, Spanish and Turkish."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 149
                            }
                        ],
                        "text": "All baselines were run by the organizers using canonical pre-trained models made available by the originator of each method,25 with the exception of PV-DBOW that\n23Similar to the STS shared task, while the training set is provided as a convenience, researchers are encourage to incorporate other supervised and unsupervised data as long as no supervised annotations of the test partitions are used."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 333,
                                "start": 326
                            }
                        ],
                        "text": "LexVec: numbers were converted into words, all punctuation was removed, and text is lowercased; FastText: sentences are prepared using the normalize text() function within FastText\u2019s get-wikimedia.sh script and lowercased; Paragram: Joshua (Matt Post, 2015) pipeline to pre-process and tokenized English text; C-PHRASE, GloVe, PV-DBOW &\ninference hyperparameters are used unless noted otherwise."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2407601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f527bcfb09f32e6a4a8afc0b37504941c1ba2cee",
            "isKey": true,
            "numCitedBy": 7044,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \"powerful,\" \"strong\" and \"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks."
            },
            "slug": "Distributed-Representations-of-Sentences-and-Le-Mikolov",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Sentences and Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Paragraph Vector is an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents, and its construction gives the algorithm the potential to overcome the weaknesses of bag-of-words models."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17089661"
                        ],
                        "name": "Alexandre Salle",
                        "slug": "Alexandre-Salle",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Salle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandre Salle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113791974"
                        ],
                        "name": "A. Villavicencio",
                        "slug": "A.-Villavicencio",
                        "structuredName": {
                            "firstName": "Aline",
                            "lastName": "Villavicencio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Villavicencio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143974276"
                        ],
                        "name": "M. Idiart",
                        "slug": "M.-Idiart",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Idiart",
                            "middleNames": [
                                "A",
                                "P"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Idiart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3158692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bdd4b7d879a68a143edba8f7f35839bfa5241f6",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose LexVec, a new method for generating distributed word representations that uses low-rank, weighted factorization of the Positive Point-wise Mutual Information matrix via stochastic gradient descent, employing a weighting scheme that assigns heavier penalties for errors on frequent co-occurrences while still accounting for negative co-occurrence. Evaluation on word similarity and analogy tasks shows that LexVec matches and often outperforms state-of-the-art methods on many of these tasks."
            },
            "slug": "Matrix-Factorization-using-Window-Sampling-and-for-Salle-Villavicencio",
            "title": {
                "fragments": [],
                "text": "Matrix Factorization using Window Sampling and Negative Sampling for Improved Word Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Evaluation on word similarity and analogy tasks shows that LexVec matches and often outperforms state-of-the-art methods on many of these tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38842528"
                        ],
                        "name": "Matt Post",
                        "slug": "Matt-Post",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Post",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Post"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145144022"
                        ],
                        "name": "Yuan Cao",
                        "slug": "Yuan-Cao",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48387892"
                        ],
                        "name": "Manish Kumar",
                        "slug": "Manish-Kumar",
                        "structuredName": {
                            "firstName": "Manish",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manish Kumar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8910334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd60e64cc5c78a05b9652a9e2e51405c95167a9d",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We describe the version six release of Joshua, an open-source statistical machine translation toolkit. The main difference from release five is the introduction of a simple, unlexicalized, phrase-based stack decoder. This phrase-based decoder shares a hypergraph format with the syntax-based systems, permitting a tight coupling with the existing codebase of feature functions and hypergraph tools. Joshua 6 also includes a number of large-scale discriminative tuners and a simplified sparse feature function interface with reflection-based loading, which allows new features to be used by writing a single function. Finally, Joshua includes a number of simplifications and improvements focused on usability for both researchers and end-users, including the release of language packs \u2014 precompiled models that can be run as black boxes."
            },
            "slug": "Joshua-6:-A-phrase-based-and-hierarchical-machine-Post-Cao",
            "title": {
                "fragments": [],
                "text": "Joshua 6: A phrase-based and hierarchical statistical machine translation system"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "The version six release of Joshua includes the introduction of a simple, unlexicalized, phrase-based stack decoder that shares a hypergraph format with the syntax-based systems, permitting a tight coupling with the existing codebase of feature functions and hypergraph tools."
            },
            "venue": {
                "fragments": [],
                "text": "Prague Bull. Math. Linguistics"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 26053,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 188
                            }
                        ],
                        "text": "Significant research effort has focused on STS over English sentence pairs.2 English STS is a\n1i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion fora, plagiarism, MT post-editing and Q&A data sets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 97
                            }
                        ],
                        "text": ", news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 220
                            }
                        ],
                        "text": "The ensemble averages scores from the four deep learning and three feature engineered models.16\nBIT (Wu et al., 2017) Second place overall is achieved by BIT primarily using sentence information content (IC) informed by WordNet and BNC word frequencies."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13573,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 259
                            }
                        ],
                        "text": "Significant research effort has focused on STS over English sentence pairs.2 English STS is a\n1i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion fora, plagiarism, MT post-editing and Q&A data sets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 211
                            }
                        ],
                        "text": "\u2026sentence pairs.2 English STS is a\n1i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion fora, plagiarism, MT post-editing and Q&A data sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 19
                            }
                        ],
                        "text": ", 1998), OntoNotes (Hovy et al., 2006), web discussion fora, plagiarism, MT post-editing and Q&A data sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8508974,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e54d8b07ef659f9ee2671441c4355e414e408836",
            "isKey": false,
            "numCitedBy": 851,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement. An initial portion (300K words of English newswire and 250K words of Chinese newswire) will be made available to the community during 2007."
            },
            "slug": "OntoNotes:-The-90-Solution-Hovy-Marcus",
            "title": {
                "fragments": [],
                "text": "OntoNotes: The 90% Solution"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "It is described the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement, which will be made available to the community during 2007."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5959482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330da625c15427c6e42ccfa3b747fb29e5835bf0",
            "isKey": false,
            "numCitedBy": 21884,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities."
            },
            "slug": "Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Estimation of Word Representations in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Two novel model architectures for computing continuous vector representations of words from very large data sets are proposed and it is shown that these vectors provide state-of-the-art performance on the authors' test set for measuring syntactic and semantic word similarities."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719404"
                        ],
                        "name": "Alessandro Moschitti",
                        "slug": "Alessandro-Moschitti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Moschitti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Moschitti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 100
                            }
                        ],
                        "text": "tures based on: n-gram overlap; edit distance; longest common prefix/suffix/substring; tree kernels (Moschitti, 2006); word alignments (Sultan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 574838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c393c48a2d634acb1daee3567eaaea733a1224fb",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we provide a study on the use of tree kernels to encode syntactic parsing information in natural language learning. In particular, we propose a new convolution kernel, namely the Partial Tree (PT) kernel, to fully exploit dependency trees. We also propose an efficient algorithm for its computation which is futhermore sped-up by applying the selection of tree nodes with non-null kernel. The experiments with Support Vector Machines on the task of semantic role labeling and question classification show that (a) the kernel running time is linear on the average case and (b) the PT kernel improves on the other tree kernels when applied to the appropriate parsing paradigm."
            },
            "slug": "Efficient-Convolution-Kernels-for-Dependency-and-Moschitti",
            "title": {
                "fragments": [],
                "text": "Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new convolution kernel, namely the Partial Tree (PT) kernel, is proposed, to fully exploit dependency trees and an efficient algorithm for its computation is proposed which is futhermore sped-up by applying the selection of tree nodes with non-null kernel."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760868"
                        ],
                        "name": "M. Surdeanu",
                        "slug": "M.-Surdeanu",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Surdeanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Surdeanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661918"
                        ],
                        "name": "John Bauer",
                        "slug": "John-Bauer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784228"
                        ],
                        "name": "J. Finkel",
                        "slug": "J.-Finkel",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Finkel",
                            "middleNames": [
                                "Rose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Finkel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105138"
                        ],
                        "name": "Steven Bethard",
                        "slug": "Steven-Bethard",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Bethard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Bethard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240597"
                        ],
                        "name": "David McClosky",
                        "slug": "David-McClosky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McClosky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David McClosky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 51
                            }
                        ],
                        "text": "SIF: PTB tokenization provided by Stanford CoreNLP (Manning et al., 2014) with post-processing based on dev OOVs; Word2vec: Similar to FastText, to our knownledge, the preprocessing for the pre-trained Word2vec embeddings is not publicly described."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 146
                            }
                        ],
                        "text": "\u2026the primary emphasis of the task shifted from English to multilingual and cross-lingual STS in-\nSIF: PTB tokenization provided by Stanford CoreNLP (Manning et al., 2014) with post-processing based on dev OOVs; Word2vec: Similar to FastText, to our knownledge, the preprocessing for the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 214
                            }
                        ],
                        "text": "This year\u2019s shared task differed substantially from previous iterations of STS in that the primary emphasis of the task shifted from English to multilingual and cross-lingual STS in-\nSIF: PTB tokenization provided by Stanford CoreNLP (Manning et al., 2014) with post-processing based on dev OOVs; Word2vec: Similar to FastText, to our knownledge, the preprocessing for the pre-trained Word2vec embeddings is not publicly described."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14068874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f5102ec3f70d0dea98c957cc2cab4d15d83a2da",
            "isKey": false,
            "numCitedBy": 6057,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
            },
            "slug": "The-Stanford-CoreNLP-Natural-Language-Processing-Manning-Surdeanu",
            "title": {
                "fragments": [],
                "text": "The Stanford CoreNLP Natural Language Processing Toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The design and use of the Stanford CoreNLP toolkit is described, an extensible pipeline that provides core natural language analysis, and it is suggested that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 188
                            }
                        ],
                        "text": "Significant research effort has focused on STS over English sentence pairs.2 English STS is a\n1i.a., news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al., 1998), OntoNotes (Hovy et al., 2006), web discussion fora, plagiarism, MT post-editing and Q&A data sets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 97
                            }
                        ],
                        "text": ", news headlines, video and image descriptions, glosses from lexical resources including WordNet (Miller, 1995; Fellbaum, 1998), FrameNet (Baker et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 220
                            }
                        ],
                        "text": "The ensemble averages scores from the four deep learning and three feature engineered models.16\nBIT (Wu et al., 2017) Second place overall is achieved by BIT primarily using sentence information content (IC) informed by WordNet and BNC word frequencies."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1671874,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "68c03788224000794d5491ab459be0b2a2c38677",
            "isKey": false,
            "numCitedBy": 13888,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4]."
            },
            "slug": "WordNet:-A-Lexical-Database-for-English-Miller",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Database for English"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "WordNet1 provides a more effective combination of traditional lexicographic information and modern computing, and is an online lexical database designed for use under program control."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052690705"
                        ],
                        "name": "Peter Young",
                        "slug": "Peter-Young",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068187980"
                        ],
                        "name": "Alice Lai",
                        "slug": "Alice-Lai",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alice Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170746"
                        ],
                        "name": "M. Hodosh",
                        "slug": "M.-Hodosh",
                        "structuredName": {
                            "firstName": "Micah",
                            "lastName": "Hodosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hodosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 189
                            }
                        ],
                        "text": "\u2026data in ongoing research.\ncross-lingual tracks explores data from the WMT 2014 quality estimation task (Bojar et al., 2014).3\nSentences pairs in SNLI derive from Flickr30k image captions (Young et al., 2014) and are labeled with the entailment relations: entailment, neutral, and contradiction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "image captions (Young et al., 2014) and are labeled with the entailment relations: entailment, neutral, and contradiction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3104920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44040913380206991b1991daf1192942e038fe31",
            "isKey": false,
            "numCitedBy": 1323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to use the visual denotations of linguistic expressions (i.e. the set of images they describe) to define novel denotational similarity metrics, which we show to be at least as beneficial as distributional similarities for two tasks that require semantic inference. To compute these denotational similarities, we construct a denotation graph, i.e. a subsumption hierarchy over constituents and their denotations, based on a large corpus of 30K images and 150K descriptive captions."
            },
            "slug": "From-image-descriptions-to-visual-denotations:-New-Young-Lai",
            "title": {
                "fragments": [],
                "text": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "This work proposes to use the visual denotations of linguistic expressions to define novel denotational similarity metrics, which are shown to be at least as beneficial as distributional similarities for two tasks that require semantic inference."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2015) or LSTM (Hochreiter and Schmidhuber, 1997)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 51694,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319608"
                        ],
                        "name": "Armand Joulin",
                        "slug": "Armand-Joulin",
                        "structuredName": {
                            "firstName": "Armand",
                            "lastName": "Joulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armand Joulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024698"
                        ],
                        "name": "Edouard Grave",
                        "slug": "Edouard-Grave",
                        "structuredName": {
                            "firstName": "Edouard",
                            "lastName": "Grave",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edouard Grave"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329288"
                        ],
                        "name": "Piotr Bojanowski",
                        "slug": "Piotr-Bojanowski",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Bojanowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Bojanowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1210515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "892e53fe5cd39f037cb2a961499f42f3002595dd",
            "isKey": false,
            "numCitedBy": 3062,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU, and classify half a million sentences among 312K classes in less than a minute."
            },
            "slug": "Bag-of-Tricks-for-Efficient-Text-Classification-Joulin-Grave",
            "title": {
                "fragments": [],
                "text": "Bag of Tricks for Efficient Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A simple and efficient baseline for text classification is explored that shows that the fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5564346"
                        ],
                        "name": "Birk Diedenhofen",
                        "slug": "Birk-Diedenhofen",
                        "structuredName": {
                            "firstName": "Birk",
                            "lastName": "Diedenhofen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Birk Diedenhofen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3090049"
                        ],
                        "name": "J. Musch",
                        "slug": "J.-Musch",
                        "structuredName": {
                            "firstName": "Jochen",
                            "lastName": "Musch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Musch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "05 Williams\u2019 t-test (Diedenhofen and Musch, 2015)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 157301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "758e3fbd07ef858b33420aa981ae741a3f0d9a78",
            "isKey": false,
            "numCitedBy": 950,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "A valid comparison of the magnitude of two correlations requires researchers to directly contrast the correlations using an appropriate statistical test. In many popular statistics packages, however, tests for the significance of the difference between correlations are missing. To close this gap, we introduce cocor, a free software package for the R programming language. The cocor package covers a broad range of tests including the comparisons of independent and dependent correlations with either overlapping or nonoverlapping variables. The package also includes an implementation of Zou\u2019s confidence interval for all of these comparisons. The platform independent cocor package enhances the R statistical computing environment and is available for scripting. Two different graphical user interfaces\u2014a plugin for RKWard and a web interface\u2014make cocor a convenient and user-friendly tool."
            },
            "slug": "cocor:-A-Comprehensive-Solution-for-the-Statistical-Diedenhofen-Musch",
            "title": {
                "fragments": [],
                "text": "cocor: A Comprehensive Solution for the Statistical Comparison of Correlations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The cocor package covers a broad range of tests including the comparisons of independent and dependent correlations with either overlapping or nonoverlapping variables, and includes an implementation of Zou\u2019s confidence interval for all of these comparisons."
            },
            "venue": {
                "fragments": [],
                "text": "PloS one"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771118"
                        ],
                        "name": "J. Wieting",
                        "slug": "J.-Wieting",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wieting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wieting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2924113"
                        ],
                        "name": "Karen Livescu",
                        "slug": "Karen-Livescu",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Livescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Livescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 58
                            }
                        ],
                        "text": "9 Paragram Paraphrase Database (PPDB) fit word embeddings (Wieting et al., 2015) 63."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57564106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aed419cb7926218d1ffe378c0fc63b1a82f6302",
            "isKey": false,
            "numCitedBy": 247,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive semantic resource, consisting of a list of phrase pairs with (heuristic) confidence estimates. However, it is still unclear how it can best be used, due to the heuristic nature of the confidences and its necessarily incomplete coverage. We propose models to leverage the phrase pairs from the PPDB to build parametric paraphrase models that score paraphrase pairs more accurately than the PPDB\u2019s internal scores while simultaneously improving its coverage. They allow for learning phrase embeddings as well as improved word embeddings. Moreover, we introduce two new, manually annotated datasets to evaluate short-phrase paraphrasing models. Using our paraphrase model trained using PPDB, we achieve state-of-the-art results on standard word and bigram similarity tasks and beat strong baselines on our new short phrase paraphrase tasks."
            },
            "slug": "From-Paraphrase-Database-to-Compositional-Model-and-Wieting-Bansal",
            "title": {
                "fragments": [],
                "text": "From Paraphrase Database to Compositional Paraphrase Model and Back"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes models to leverage the phrase pairs from the Paraphrase Database to build parametric paraphrase models that score paraphrase pairs more accurately than the PPDB\u2019s internal scores while simultaneously improving its coverage."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 30
                            }
                        ],
                        "text": ", 2010), semantic relatedness (Bentivogli et al., 2016) and paraphrase detection (Xu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 68
                            }
                        ],
                        "text": "Semantic inference tasks related to\nSTS include textual entailment (Bentivogli et al., 2016; Bowman et al., 2015; Dagan et al., 2010), semantic relatedness (Bentivogli et al., 2016) and paraphrase detection (Xu et al., 2015; Ganitkevitch et al., 2013; Dolan et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 67
                            }
                        ],
                        "text": "Semantic inference tasks related to STS include textual entailment (Bentivogli et al., 2016; Bowman et al., 2015; Dagan et al., 2010), semantic relatedness (Bentivogli et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SICK through the SemEval glasses"
            },
            "venue": {
                "fragments": [],
                "text": "lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Raquel Urtasun, and Sanja Fidler"
            },
            "venue": {
                "fragments": [],
                "text": "Skip-thought vectors. CoRR abs/1506.06726"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 101
                            }
                        ],
                        "text": "The best performance tends to be obtained by ensembling feature engineered and deep learning models (Rychalska et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2016. Samsung Poland NLP Team at SemEval-2016 Task 1: Necessity for diversity; combining recursive autoencoders, wordnet and ensemble methods to measure"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 260
                            }
                        ],
                        "text": "\u2026semantic representations (i.a., Arora et al. (2017); Conneau et al. (2017); Mu et al. (2017); Pagliardini et al. (2017); Wieting and Gimpel (2017); He and Lin (2016); Hill et al. (2016); Kenter et al. (2016); Lau and Baldwin (2016); Wieting et al. (2016a,b); He et al. (2015); Pham et al. (2015))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiperspective sentence similarity modeling with convolutional neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of EMNLP. pages 1576\u20131586. http://aclweb.org/anthology/D15-1181."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Take - lab : Systems for measuring semantic text similar"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Take - lab : Systems for measuring semantic text similar"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table 3: English training data. Year Data set Pairs Source"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ans.-student 750 student answers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "7We use 50-dimensional GloVe word embeddings (Pennington et al., 2014) trained on a combination of Gigaword 5 (Parker et al., 2011) and English Wikipedia available at http://nlp.stanford.edu/projects/glove/."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": ", 2014) trained on a combination of Gigaword 5 (Parker et al., 2011) and English Wikipedia available at http://nlp."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gigaword Fifth Edition LDC2011T07"
            },
            "venue": {
                "fragments": [],
                "text": "Linguistic Data Consortium. https://catalog.ldc.upenn.edu/ldc2011t07."
            },
            "year": 2011
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 36,
            "methodology": 35
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 96,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/SemEval-2017-Task-1:-Semantic-Textual-Similarity-Cer-Diab/a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096?sort=total-citations"
}